nl,sql,db_sql,db_result,table_id,reasoning,seeding_type,seeding_value,filtered,schema_change_type,ambiguity_type_and_details
"List aircraft with the rooftop suitability flag first (reported disk loading ≤ 5 lb/ft²), ordered by reported disk loading in Pa ascending, and include computed disk loading, reported disk loading, both in Pa, and the absolute and percent discrepancies to highlight any outliers?","
WITH `parsed` AS (
  SELECT
    `Aircraft`,
    `Description`,
    CAST(REPLACE(substr(`Max Gross Weight`, 1, instr(`Max Gross Weight`, ' ')-1), ',', '') AS REAL) AS `gross_lb`,
    CAST(REPLACE(substr(`Total disk area`, 1, instr(`Total disk area`, ' ')-1), ',', '') AS REAL) AS `disk_ft2`,
    CAST(REPLACE(substr(`Max disk Loading`, 1, instr(`Max disk Loading`, ' ')-1), ',', '') AS REAL) AS `reported_disk_lb_per_ft2`
  FROM `table_1_10006830_1`
)
SELECT
  `Aircraft`,
  `Description`,
  `gross_lb`,
  `disk_ft2`,
  ROUND(`gross_lb` / NULLIF(`disk_ft2`, 0), 2) AS `computed_disk_lb_per_ft2`,
  `reported_disk_lb_per_ft2`,
  ROUND(`reported_disk_lb_per_ft2` * (4.44822 / 0.092903), 2) AS `reported_disk_Pa`,
  ROUND((`gross_lb` / NULLIF(`disk_ft2`, 0)) * (4.44822 / 0.092903), 2) AS `computed_disk_Pa`,
  ROUND(ABS((`gross_lb` / NULLIF(`disk_ft2`, 0)) - `reported_disk_lb_per_ft2`), 2) AS `abs_diff_lb_per_ft2`,
  ROUND(ABS(((`gross_lb` / NULLIF(`disk_ft2`, 0)) - `reported_disk_lb_per_ft2`) / NULLIF(`reported_disk_lb_per_ft2`, 0)) * 100, 2) AS `abs_diff_pct`,
  CASE WHEN `reported_disk_lb_per_ft2` <= 5.0 THEN 'candidate_for_rooftop' ELSE 'not_candidate' END AS `rooftop_suitability`
FROM `parsed`
ORDER BY CASE WHEN `reported_disk_lb_per_ft2` <= 5.0 THEN 0 ELSE 1 END, `reported_disk_Pa` ASC, `abs_diff_lb_per_ft2` DESC;
","
WITH `parsed` AS (
  SELECT
    col0,
    col1,
    CAST(REPLACE(substr(col2, 1, instr(col2, ' ')-1), ',', '') AS REAL) AS `gross_lb`,
    CAST(REPLACE(substr(col3, 1, instr(col3, ' ')-1), ',', '') AS REAL) AS `disk_ft2`,
    CAST(REPLACE(substr(col4, 1, instr(col4, ' ')-1), ',', '') AS REAL) AS `reported_disk_lb_per_ft2`
  FROM `table_1_10006830_1`
)
SELECT
  col0,
  col1,
  `gross_lb`,
  `disk_ft2`,
  ROUND(`gross_lb` / NULLIF(`disk_ft2`, 0), 2) AS `computed_disk_lb_per_ft2`,
  `reported_disk_lb_per_ft2`,
  ROUND(`reported_disk_lb_per_ft2` * (4.44822 / 0.092903), 2) AS `reported_disk_Pa`,
  ROUND((`gross_lb` / NULLIF(`disk_ft2`, 0)) * (4.44822 / 0.092903), 2) AS `computed_disk_Pa`,
  ROUND(ABS((`gross_lb` / NULLIF(`disk_ft2`, 0)) - `reported_disk_lb_per_ft2`), 2) AS `abs_diff_lb_per_ft2`,
  ROUND(ABS(((`gross_lb` / NULLIF(`disk_ft2`, 0)) - `reported_disk_lb_per_ft2`) / NULLIF(`reported_disk_lb_per_ft2`, 0)) * 100, 2) AS `abs_diff_pct`,
  CASE WHEN `reported_disk_lb_per_ft2` <= 5.0 THEN 'candidate_for_rooftop' ELSE 'not_candidate' END AS `rooftop_suitability`
FROM `parsed`
ORDER BY CASE WHEN `reported_disk_lb_per_ft2` <= 5.0 THEN 0 ELSE 1 END, `reported_disk_Pa` ASC, `abs_diff_lb_per_ft2` DESC;
","[('robinson r-22', 'light utility helicopter', 1370.0, 497.0, 2.76, 2.6, 124.49, 131.98, 0.16, 6.02, 'candidate_for_rooftop'), ('bell 206b3 jetranger', 'turboshaft utility helicopter', 3200.0, 872.0, 3.67, 3.7, 177.16, 175.71, 0.03, 0.82, 'candidate_for_rooftop'), ('ch-47d chinook', 'tandem rotor helicopter', 50000.0, 5655.0, 8.84, 8.8, 421.35, 423.34, 0.04, 0.47, 'not_candidate'), ('mil mi-26', 'heavy-lift helicopter', 123500.0, 8495.0, 14.54, 14.5, 694.26, 696.08, 0.04, 0.26, 'not_candidate'), ('ch-53e super stallion', 'heavy-lift helicopter', 73500.0, 4900.0, 15.0, 15.0, 718.2, 718.2, 0.0, 0.0, 'not_candidate')]",table_1_10006830_1,"I want a shortlist sorted to prioritize gentlest downwash for rooftop ops while also exposing data outliers. The SQL flags reported disk loading ≤ 5.0 lb/ft² as rooftop candidates, orders those candidates first, then sorts by reported disk loading in Pa ascending and includes discrepancy metrics. The schema elements used are the parsed gross_lb, disk_ft2, reported_disk_lb_per_ft2, the Pa conversions, and the computed discrepancy columns. Draft question: ask to list aircraft with rooftop candidates first, ordered by reported disk loading in Pa, and include computed vs reported values and discrepancy measures. This aligns with the query's suitability flag, conversions, and ordering.",persona,"A rooftop-garden structural engineer who models helicopter downwash effects on urban green roofs and needs disk-loading data to design wind-tolerant planting and anchoring systems. Goals: Identify helicopters with low disk loading (gentle downwash) suitable for routine rooftop deliveries, medevac landings, or maintenance access to green roofs. Convert and compare disk-loading values into SI units (Pa) to estimate peak pressure on plants, soil, and lightweight roof structures. Cross-check the table's disk-loading values by recomputing weight/rotor-disk-area from the raw fields to find any discrepancies or outliers that might affect safety margins. Example Queries: SELECT ""Aircraft"", ""Description"", ""Max Gross Weight"", ""Total disk area"", ""Max disk Loading""
FROM table_1_10006830_1
WHERE CAST(REGEXP_REPLACE(""Max disk Loading"", '[^0-9.]', '', 'g') AS FLOAT) <= 5.0
ORDER BY CAST(REGEXP_REPLACE(""Max disk Loading"", '[^0-9.]', '', 'g') AS FLOAT) ASC; SELECT ""Aircraft"",
  CAST(REGEXP_REPLACE(""Max disk Loading"", '[^0-9.]', '', 'g') AS FLOAT) AS disk_lb_per_ft2,
  (CAST(REGEXP_REPLACE(""Max disk Loading"", '[^0-9.]', '', 'g') AS FLOAT) * 4.44822 / 0.092903) AS disk_Pa_estimate
FROM table_1_10006830_1
ORDER BY disk_Pa_estimate DESC; SELECT ""Aircraft"",
  CAST(REGEXP_REPLACE(""Max Gross Weight"", '[^0-9.]', '', 'g') AS FLOAT) AS gross_lb,
  CAST(REGEXP_REPLACE(""Total disk area"", '[^0-9.]', '', 'g') AS FLOAT) AS disk_ft2,
  ROUND(CAST(REGEXP_REPLACE(""Max Gross Weight"", '[^0-9.]', '', 'g') AS FLOAT) /
        NULLIF(CAST(REGEXP_REPLACE(""Total disk area"", '[^0-9.]', '', 'g') AS FLOAT),0), 2) AS computed_disk_lb_per_ft2,
  CAST(REGEXP_REPLACE(""Max disk Loading"", '[^0-9.]', '', 'g') AS FLOAT) AS reported_disk_lb_per_ft2
FROM table_1_10006830_1
WHERE ABS(
  (CAST(REGEXP_REPLACE(""Max Gross Weight"", '[^0-9.]', '', 'g') AS FLOAT) /
   NULLIF(CAST(REGEXP_REPLACE(""Total disk area"", '[^0-9.]', '', 'g') AS FLOAT),0))
  - CAST(REGEXP_REPLACE(""Max disk Loading"", '[^0-9.]', '', 'g') AS FLOAT)
) > 0.5
ORDER BY ABS(
  (CAST(REGEXP_REPLACE(""Max Gross Weight"", '[^0-9.]', '', 'g') AS FLOAT) /
   NULLIF(CAST(REGEXP_REPLACE(""Total disk area"", '[^0-9.]', '', 'g') AS FLOAT),0))
  - CAST(REGEXP_REPLACE(""Max disk Loading"", '[^0-9.]', '', 'g') AS FLOAT)
) DESC;",reward,,
"For each season from 1996 through 2013, list the Raptors who played that season along with their jersey number, Years in Toronto, position, nationality and school or club team?","
WITH `Season`(`Season`) AS (
  VALUES ('1996'),('1997'),('1998'),('1999'),('2000'),('2001'),('2002'),('2003'),('2004'),('2005'),('2006'),('2007'),('2008'),('2009'),('2010'),('2011'),('2012'),('2013')
)
SELECT `Season`.`Season` AS `Season`,
       t.`Player`,
       t.`No.`,
       t.`Years in Toronto`,
       t.`Position`,
       t.`Nationality`,
       t.`School/Club Team`
FROM `Season`
JOIN `table_1_10015132_3` AS t
  ON instr(t.`Years in Toronto`, `Season`.`Season`) > 0
ORDER BY CAST(`Season`.`Season` AS INTEGER), t.`No.`;
","SELECT sub.`Season`, sub.col0, sub.col1, sub.col4, sub.col3, sub.col2, sub.col5
FROM (
  SELECT '1996' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '1996') > 0
  UNION ALL
  SELECT '1997' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '1997') > 0
  UNION ALL
  SELECT '1998' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '1998') > 0
  UNION ALL
  SELECT '1999' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '1999') > 0
  UNION ALL
  SELECT '2000' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2000') > 0
  UNION ALL
  SELECT '2001' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2001') > 0
  UNION ALL
  SELECT '2002' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2002') > 0
  UNION ALL
  SELECT '2003' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2003') > 0
  UNION ALL
  SELECT '2004' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2004') > 0
  UNION ALL
  SELECT '2005' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2005') > 0
  UNION ALL
  SELECT '2006' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2006') > 0
  UNION ALL
  SELECT '2007' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2007') > 0
  UNION ALL
  SELECT '2008' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2008') > 0
  UNION ALL
  SELECT '2009' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2009') > 0
  UNION ALL
  SELECT '2010' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2010') > 0
  UNION ALL
  SELECT '2011' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2011') > 0
  UNION ALL
  SELECT '2012' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2012') > 0
  UNION ALL
  SELECT '2013' AS `Season`, t.col0, t.col1, t.col4, t.col3, t.col2, t.col5
  FROM table_1_10015132_3 AS t WHERE instr(t.col4, '2013') > 0
) AS sub
ORDER BY CAST(sub.`Season` AS INTEGER), sub.col1;","[('1996', 'doug christie', 13.0, '1996-2000', 'forward', 'united states', 'pepperdine'), ('1996', 'marcus camby', 21.0, '1996-98', 'center', 'united states', 'massachusetts'), ('1996', 'earl cureton', 35.0, '1996-97', 'forward', 'united states', 'detroit'), ('1998', 'vince carter', 15.0, '1998-2004', 'guard-forward', 'united states', 'north carolina'), ('1999', 'dell curry', 30.0, '1999-2002', 'guard', 'united states', 'virginia tech'), ('1999', 'william cunningham', 54.0, '1999', 'center', 'united states', 'temple'), ('2000', 'doug christie', 13.0, '1996-2000', 'forward', 'united states', 'pepperdine'), ('2000', 'tyrone corbin', 23.0, '2000-01', 'guard-forward', 'united states', 'depaul'), ('2001', 'chris childs', 1.0, '2001-02', 'guard', 'united states', 'boise state'), ('2001', 'keon clark', 7.0, '2001-02', 'forward-center', 'united states', 'unlv'), ('2002', 'dell curry', 30.0, '1999-2002', 'guard', 'united states', 'virginia tech'), ('2004', 'vince carter', 15.0, '1998-2004', 'guard-forward', 'united states', 'north carolina'), ('2005', 'omar cook', 1.0, '2005-06', 'guard', 'united states', ""st. john's""), ('2005', 'josé calderón', 8.0, '2005-2013', 'guard', 'spain', 'tau cerámica (spain)'), ('2011', 'anthony carter', 25.0, '2011-12', 'guard', 'united states', 'hawaii'), ('2013', 'josé calderón', 8.0, '2005-2013', 'guard', 'spain', 'tau cerámica (spain)')]",table_1_10015132_3,"I'm a meticulous restorationist who knows roster columns like jersey number, position and school/club and I phrase questions precisely but practically. The SQL generates seasons 1996–2013 and joins each season to players whose ""Years in Toronto"" contains that season. It returns Player, No., Years in Toronto, Position, Nationality and School/Club Team for each matching season. Drafted question: For each season from 1996 through 2013, list the Raptors who played that season along with their jersey number, Years in Toronto, position, nationality and school or club team? This matches the query's intent to produce season-by-season player entries with those exact fields.",persona,"A museum-quality jersey restorationist who reconstructs historically accurate Toronto Raptors uniforms and exhibit labels for era-specific displays. Goals: Identify the exact jersey numbers, years worn, positions and nationalities to create accurate uniform replicas and museum placards. Assemble era-specific cohorts (e.g., turn-of-the-century Raptors) by finding players with overlapping Years in Toronto, so garments and displays match the same seasons. Locate players' college or club teams to research original fabrics, color schemes and patches for faithful material sourcing and detailing. Example Queries: SELECT ""Player"", ""No."", ""Years in Toronto"", ""Position"", ""Nationality"", ""School/Club Team""
FROM table_1_10015132_3
WHERE ""No."" = 15; SELECT ""Player"", ""No."", ""Years in Toronto"", ""Position""
FROM table_1_10015132_3
WHERE ""Years in Toronto"" LIKE '%1999%' OR ""Years in Toronto"" LIKE '%2000%' OR ""Years in Toronto"" LIKE '%2001%' OR ""Years in Toronto"" LIKE '%2002%'
ORDER BY ""Years in Toronto""; SELECT ""School/Club Team"", COUNT(*) AS player_count
FROM table_1_10015132_3
GROUP BY ""School/Club Team""
ORDER BY player_count DESC;",reward,,
"Per Nationality, limited to rows where Position contains 'Guard' or 'Forward', provide the total players (COUNT(*)), the earliest start year using the first four characters of 'Years in Toronto' as a numeric value (MIN(substr('Years in Toronto',1,4)+0)), the average start year rounded to one decimal place (ROUND(AVG(substr('Years in Toronto',1,4)+0),1)), the count of entries with 'Guard' in Position (SUM(Position LIKE '%Guard%')), the count with 'Forward' in Position (SUM(Position LIKE '%Forward%')), and a Cohort column that reads 'Established before 2005' when the earliest start year is before 2005?","
SELECT `Nationality` AS `Nationality`,
       COUNT(*) `Players`,
       MIN(substr(`Years in Toronto`,1,4)+0) `EarliestStart`,
       ROUND(AVG(substr(`Years in Toronto`,1,4)+0),1) `AverageStart`,
       SUM(`Position` LIKE '%Guard%') `Guard`,
       SUM(`Position` LIKE '%Forward%') `Forward`,
       CASE WHEN MIN(substr(`Years in Toronto`,1,4)+0) < 2005 THEN 'Established before 2005' END `Cohort`
FROM `table_1_10015132_7`
WHERE ((`Position` LIKE '%Guard%') + (`Position` LIKE '%Forward%'))>0
GROUP BY `Nationality`
HAVING COUNT(*)>0;
","
SELECT col2 AS col2,
       COUNT(*) `Players`,
       MIN(substr(col4,1,4)+0) `EarliestStart`,
       ROUND(AVG(substr(col4,1,4)+0),1) `AverageStart`,
       SUM(col3 LIKE '%Guard%') `Guard`,
       SUM(col3 LIKE '%Forward%') `Forward`,
       CASE WHEN MIN(substr(col4,1,4)+0) < 2005 THEN 'Established before 2005' END `Cohort`
FROM `table_1_10015132_7`
WHERE ((col3 LIKE '%Guard%') + (col3 LIKE '%Forward%'))>0
GROUP BY col2
HAVING COUNT(*)>0;
","[('spain', 1, 2006, 2006.0, 0, 1, None), ('united states', 5, 1997, 2006.0, 4, 2, 'Established before 2005')]",table_1_10015132_7,"1) Parse: SQL outputs nationality, counts, min/avg start-year from substring, counts of guard/forward flags, and a cohort label when min start <2005, filtered to positions containing Guard or Forward. 2) Map semantics: Years in Toronto -> first 4 chars numeric; Position LIKE used as boolean counts. 3) Draft: ask for per-nationality players count, earliest and average start years (rounded), counts for 'Guard' and 'Forward', and conditional cohort label. 4) Validate: includes all columns, calculations, grouping and WHERE condition.",reserved,11,reward,,
"Show, for each Year with Tournaments played > 0, the Year, Tournaments played, Cuts made*, Wins, Top 10s, Earnings ($), Earnings per tournament as Earnings ($) divided by Tournaments played, Earnings per cut made as Earnings ($) divided by Cuts made* (using NULLIF to treat zero cuts as null), and the Best finish value surrounded by backticks?","
SELECT `Year`, `Tournaments played`, `Cuts made*`, `Wins`, `Top 10s`, `Earnings ($)`, (`Earnings ($)`/`Tournaments played`) AS `Earnings per tournament`, (`Earnings ($)`/NULLIF(`Cuts made*`,0)) `Earnings per cut made`, ('`' || `Best finish` || '`') `Best finish backticked` FROM `table_1_10021158_3` WHERE `Tournaments played` > 0;
","SELECT col0, col1, col2, col3, col5, col7, (col7 / col1) AS `Earnings per tournament`, (CASE WHEN col2 = 0 THEN NULL ELSE col7 / col2 END) AS `Earnings per cut made` FROM `table_1_10021158_3` WHERE col1 > 0;","[(2005.0, 1.0, 1.0, 0.0, 0.0, 2525.0, 2525.0, 2525.0), (2006.0, 3.0, 1.0, 0.0, 0.0, 55554.0, 18518.0, 55554.0), (2007.0, 25.0, 18.0, 1.0, 4.0, 507292.0, 20291.68, 28182.88888888889), (2008.0, 24.0, 11.0, 0.0, 0.0, 117682.0, 4903.416666666667, 10698.363636363636), (2009.0, 22.0, 16.0, 0.0, 2.0, 292266.0, 13284.818181818182, 18266.625), (2010.0, 21.0, 17.0, 0.0, 1.0, 168016.0, 8000.761904761905, 9883.29411764706), (2011.0, 15.0, 8.0, 0.0, 0.0, 66813.0, 4454.2, 8351.625), (2012.0, 15.0, 4.0, 0.0, 0.0, 28935.0, 1929.0, 7233.75)]",table_1_10021158_3,"1) The SQL retrieves raw columns plus two division-based calculations and a backticked Best finish for rows where Tournaments played exceeds zero. 2) Relate each selected column and calculation back to the LPGA Tour career summary schema. 3) Formulate a question explicitly naming Year, Tournaments played, Cuts made*, Wins, Top 10s, Earnings ($), Earnings per tournament (Earnings ($)/Tournaments played), Earnings per cut made (Earnings ($)/NULLIF(Cuts made*,0)), and Best finish backticked, constrained to Tournaments played > 0. 4) Check that no additional fields or conditions are introduced.",reserved,4,reward,,
"Show each Team and the AVG(Draft Pick #) computed by excluding Draft Pick # values equal to 'N/A' or 'none' and converting remaining Draft Pick # values to numbers, for rows where Season >= 2000, grouped by Team, only for teams with COUNT(*) > 0, limited to 5 results?","
SELECT `Team`, AVG(NULLIF(NULLIF(`Draft Pick #`, '`N/A`'), '`none`') + 0) AS `Avg Draft Pick`
FROM `table_1_1004033_1`
WHERE `Season` >= 2000
GROUP BY `Team`
HAVING COUNT(*) > 0
LIMIT 5;
","
SELECT col4, AVG(NULLIF(NULLIF(col5, '`N/A`'), '`none`') + 0) AS `Avg Draft Pick`
FROM `table_1_1004033_1`
WHERE col0 >= 2000
GROUP BY col4
HAVING COUNT(*) > 0
LIMIT 5;
","[('chicago fire', 11.0), ('chivas usa', 37.0), ('columbus crew', 8.0), ('d.c. united', 0.0), ('los angeles galaxy', 3.5)]",table_1_1004033_1,"1) Parse intent: group rows from 2000 onward by Team and compute numeric average of Draft Pick # ignoring 'N/A' and 'none', then limit to 5 groups. 2) Map schema: Season filters rows, Draft Pick # needs NULLIF handling and numeric cast, Team is grouping key. 3) Draft question: request Team and AVG(Draft Pick #) with the specified exclusions and numeric conversion for Season >= 2000, HAVING COUNT(*)>0, LIMIT 5. 4) Validate: question matches filter, aggregation, exclusion of 'N/A'/'none', grouping and limit.",reserved,8,reward,,
"From the Members table self-joined on Member = Member, for each distinct Headquarters where t1.UCCFS >= 2006 and t1.Chapters > 0, and after grouping by Headquarters with HAVING SUM(t2.Chapters) > 10, limited to 10 results, what are Headquarters, SUM(t2.Chapters) AS Total Chapters, COUNT(t2.Member) AS Member Count, MIN(substr(t2.Founded,1,4)) AS Earliest Founded Year, SUM((substr(t2.Founded,1,4) < '2000')) AS Pre2000 Count, MAX(t2.Member) AS Alpha Nu Omega, and MAX(t2.Founded) AS 1988 at Morgan State University?","
SELECT DISTINCT t1.`Headquarters`,
       SUM(t2.`Chapters`) `Total Chapters`,
       COUNT(t2.`Member`) `Member Count`,
       MIN(substr(t2.`Founded`,1,4)) `Earliest Founded Year`,
       SUM((substr(t2.`Founded`,1,4) < '2000')) `Pre2000 Count`,
       MAX(t2.`Member`) `Alpha Nu Omega`,
       MAX(t2.`Founded`) `1988 at Morgan State University`
FROM `table_1_10054296_1` AS t1
JOIN `table_1_10054296_1` t2 ON t1.`Member` = t2.`Member`
WHERE t1.`UCCFS` >= 2006 AND t1.`Chapters` > 0
GROUP BY t1.`Headquarters`
HAVING SUM(t2.`Chapters`) > 10
LIMIT 10;
","
SELECT DISTINCT t1.col1,
       SUM(t2.col3) `Total Chapters`,
       COUNT(t2.col0) `Member Count`,
       MIN(substr(t2.col4,1,4)) `Earliest Founded Year`,
       SUM((substr(t2.col4,1,4) < '2000')) `Pre2000 Count`,
       MAX(t2.col0) `Alpha Nu Omega`,
       MAX(t2.col4) `1988 at Morgan State University`
FROM `table_1_10054296_1` AS t1
JOIN `table_1_10054296_1` t2 ON t1.col0 = t2.col0
WHERE t1.col5 >= 2006 AND t1.col3 > 0
GROUP BY t1.col1
HAVING SUM(t2.col3) > 10
LIMIT 10;
","[('austin, texas', 16.0, 1, '1988', 1, 'gamma phi delta', '1988 at the university of texas at austin'), ('baltimore, maryland', 26.0, 1, '1988', 1, 'alpha nu omega', '1988 at morgan state university'), ('washington, d.c.', 12.0, 1, '1999', 1, 'delta psi epsilon', '1999 in huntsville, alabama')]",table_1_10054296_1,"Parse intent: filter rows by t1.UCCFS >= 2006 and t1.Chapters > 0, self-join on Member, then aggregate by Headquarters and return specific summaries only for groups with SUM(Chapters) > 10, up to 10 groups. Map schema: interpret Founded year via substr(Founded,1,4) and count/sum/ min/max on Member, Chapters, Founded. Draft: form a question that requests DISTINCT Headquarters and the exact aggregate expressions and their labels, mentions the self-join, WHERE criteria, GROUP BY Headquarters, HAVING SUM(Chapters) > 10, and LIMIT 10. Validate: ensure every column and calculation in the SQL is explicitly included.",reserved,12,reward,,
"Provide, for each school with Enrollment greater than 7000, the School, Location, Founded, Affiliation, Enrollment, the Years since Founded as 2025 minus Founded, the Enrollment per Year as Enrollment divided by (2025 - Founded) rounded to two decimal places, and an ""Indiana University"" column that repeats Enrollment, with results ordered by Enrollment per Year in ascending order?","
SELECT
  `School`,
  `Location`,
  `Founded`,
  `Affiliation`,
  `Enrollment`,
  (2025 - `Founded`) `Years since Founded`,
  round(`Enrollment` / (2025 - `Founded`), 2) `Enrollment per Year`,
  `Enrollment` `Indiana University`
FROM `table_1_10082596_1`
WHERE `Enrollment` > 7000
ORDER BY `Enrollment per Year`;
","
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  (2025 - col2) `Years since Founded`,
  round(col4 / (2025 - col2), 2) `Enrollment per Year`,
  col4 `Indiana University`
FROM `table_1_10082596_1`
WHERE col4 > 7000
ORDER BY `Enrollment per Year`;
","[('lindenwood university', 'st. charles, mo', 1827.0, 'private/presbyterian', 11421.0, 198.0, 57.68, 11421.0), ('robert morris university', 'chicago, il', 1913.0, 'private/non-sectarian', 7277.0, 112.0, 64.97, 7277.0), ('ohio university', 'athens, oh', 1804.0, 'public', 20437.0, 221.0, 92.48, 20437.0), ('iowa state university', 'ames, ia', 1858.0, 'public', 27945.0, 167.0, 167.34, 27945.0), ('indiana university', 'bloomington, in', 1820.0, 'public', 40354.0, 205.0, 196.85, 40354.0)]",table_1_10082596_1,"1) The intent is to retrieve specific columns plus derived metrics and a duplicated Enrollment column named ""Indiana University"" for records where Enrollment exceeds 7000, ordered by the computed Enrollment per Year. 2) Map the selected and computed fields to the table schema (School, Location, Founded, Affiliation, Enrollment) and the calculations (2025 - Founded; Enrollment/(2025 - Founded) rounded to 2 decimals). 3) Produce a question that explicitly requests those columns, the two calculations with their formulas and rounding, the duplicated Enrollment alias, the Enrollment > 7000 filter, and ordering by Enrollment per Year ascending. 4) Ensure the question contains every column, calculation, alias, filter, and ordering present in the query.",reserved,5,reward,,
"Which three Networks have the highest average Viewers (in millions), and for each of those Networks report Network, Total Seasons, Avg Viewers (in millions) rounded to 2 decimal places, Peak Viewers (maximum Viewers (in millions)), Lowest Viewers (minimum Viewers (in millions)), the count of seasons with Viewers (in millions) = 4.0, = 4.2, = 3.4, = 3.6, and the count of seasons with Viewers (in millions) >= 3.5, grouping results by Network and ordering by average viewers descending?","
SELECT `Network`, COUNT(*) `Total Seasons`, ROUND(AVG(`Viewers (in millions)` + 0), 2) `Avg Viewers`, MAX(`Viewers (in millions)` + 0) `Peak Viewers`, MIN(`Viewers (in millions)` + 0) `Lowest Viewers`, SUM((`Viewers (in millions)` + 0) = 4.0) `4.0`, SUM((`Viewers (in millions)` + 0) = 4.2) `4.2`, SUM((`Viewers (in millions)` + 0) = 3.4) `3.4`, SUM((`Viewers (in millions)` + 0) = 3.6) `3.6`, SUM(CASE WHEN (`Viewers (in millions)` + 0) >= 3.5 THEN 1 ELSE 0 END) `Seasons >= 3.5` FROM `table_1_1009087_1` GROUP BY `Network` ORDER BY `Avg Viewers` DESC LIMIT 3;
","
SELECT col1, COUNT(*) `Total Seasons`, ROUND(AVG(col6 + 0), 2) `Avg Viewers`, MAX(col6 + 0) `Peak Viewers`, MIN(col6 + 0) `Lowest Viewers`, SUM((col6 + 0) = 4.0) `4.0`, SUM((col6 + 0) = 4.2) `4.2`, SUM((col6 + 0) = 3.4) `3.4`, SUM((col6 + 0) = 3.6) `3.6`, SUM(CASE WHEN (col6 + 0) >= 3.5 THEN 1 ELSE 0 END) `Seasons >= 3.5` FROM `table_1_1009087_1` GROUP BY col1 ORDER BY `Avg Viewers` DESC LIMIT 3;
","[('upn', 6, 3.77, 4.2, 3.4, 2, 1, 2, 1, 4), ('cw', 1, 2.5, 2.5, 2.5, 0, 0, 0, 0, 0)]",table_1_1009087_1,"1) Parse intent: compute per-Network aggregates including counts of exact viewer values and seasons >=3.5, sort by average viewers descending and limit to 3. 2) Map schema: use Network and Viewers (in millions) fields from the table. 3) Draft question: enumerate all requested aggregate metrics and ordering/limit. 4) Validate: confirm inclusion of COUNT, AVG rounded to two decimals, MAX, MIN, SUM conditions for 4.0/4.2/3.4/3.6, and SUM for >=3.5.",reserved,11,reward,,
"Show me Gaeltacht villages with ≥70% habitual Irish speakers and populations of 100–1,500 (only in counties averaging ≥70% Irish speakers) and include each village's Irish name along with how many words and characters that Irish name has?","
WITH `county_stats` AS (
  SELECT `County`,
         ROUND(AVG(CAST(REPLACE(`Irish speakers`, '%', '') AS REAL)), 2) AS `county_avg_pct`,
         COUNT(*) AS `villages_in_county`
  FROM `table_1_101196_1`
  GROUP BY `County`
),
`ranked_counties` AS (
  SELECT `County`, `county_avg_pct`, `villages_in_county`,
         RANK() OVER (ORDER BY `county_avg_pct` DESC) AS `county_rank`
  FROM `county_stats`
)
SELECT t.`County`,
       t.`English name`,
       t.`Irish name`,
       t.`Population`,
       t.`Irish speakers`,
       CAST(REPLACE(t.`Irish speakers`, '%', '') AS INTEGER) AS `pct`,
       rc.`county_avg_pct`,
       rc.`villages_in_county`,
       rc.`county_rank`,
       (LENGTH(t.`Irish name`) - LENGTH(REPLACE(t.`Irish name`, ' ', '')) + 1) AS `Irish_name_word_count`,
       LENGTH(t.`Irish name`) AS `Irish_name_length`
FROM `table_1_101196_1` AS t
JOIN `ranked_counties` AS rc USING(`County`)
WHERE CAST(REPLACE(t.`Irish speakers`, '%', '') AS INTEGER) >= 70
  AND t.`Population` BETWEEN 100 AND 1500
  AND rc.`county_avg_pct` >= 70
ORDER BY rc.`county_rank` ASC, `pct` DESC, t.`Population` ASC;
","WITH county_avgs AS (
  SELECT col0,
         ROUND(AVG(CAST(REPLACE(col4, '%', '') AS REAL)), 2) AS `county_avg_pct`,
         COUNT(*) AS `villages_in_county`
  FROM `table_1_101196_1`
  GROUP BY col0
  HAVING AVG(CAST(REPLACE(col4, '%', '') AS REAL)) >= 70
)
SELECT t.col0,
       t.col1,
       t.col2,
       t.col3,
       t.col4,
       CAST(REPLACE(t.col4, '%', '') AS INTEGER) AS `pct`,
       ca.`county_avg_pct`,
       ca.`villages_in_county`,
       (LENGTH(t.col2) - LENGTH(REPLACE(t.col2, ' ', '')) + 1) AS `Irish_name_word_count`,
       LENGTH(t.col2) AS `Irish_name_length`
FROM `table_1_101196_1` AS t
JOIN county_avgs AS ca ON t.col0 = ca.col0
WHERE CAST(REPLACE(t.col4, '%', '') AS INTEGER) >= 70
  AND t.col3 BETWEEN 100 AND 1500
ORDER BY ca.`county_avg_pct` DESC, `pct` DESC, t.col3 ASC;","[('county galway', 'camus', 'camus', 367.0, '90%', 90, 75.75, 16, 1, 5), ('county galway', 'lettermullen', 'leitir mealláin', 1288.0, '89%', 89, 75.75, 16, 2, 15), ('county galway', 'rosmuc', 'ros muc', 557.0, '87%', 87, 75.75, 16, 2, 7), ('county galway', 'kilkieran', 'cill chiaráin', 619.0, '87%', 87, 75.75, 16, 2, 13), ('county galway', 'lettermore', 'leitir móir', 875.0, '84%', 84, 75.75, 16, 2, 11), ('county galway', 'rossaveal', 'ros an mhíl', 1304.0, '84%', 84, 75.75, 16, 3, 11), ('county galway', 'inverin', 'indreabhán', 1362.0, '83%', 83, 75.75, 16, 1, 10), ('county galway', 'carna', 'carna', 798.0, '81%', 81, 75.75, 16, 1, 5), ('county galway', 'aran islands', 'oileáin árann', 1225.0, '79%', 79, 75.75, 16, 2, 13), ('county galway', 'derryrush', 'doire iorrais', 313.0, '76%', 76, 75.75, 16, 2, 13), ('county galway', 'bothúna', 'bothúna', 963.0, '74%', 74, 75.75, 16, 1, 7)]",table_1_101196_1,"As a label writer I obsess over evocative Irish names and their length, so I'll ask for name word counts in plain language. The SQL computes Irish name word count and character length for qualifying villages while applying the same percentage and population filters and county-average cutoff. This maps to the Irish name, a derived word count and length alongside the usual village metrics. Draft question: ask for villages meeting the filters and include the Irish name plus its word count/length so I can judge which names are great for packaging. That aligns with the query's returned name metrics and constraints.",persona,"A boutique microbrewery packaging designer who creates limited-edition Gaelic-themed beers and selects Gaeltacht villages as label-characters based on language vitality and evocative Irish names. Goals: Identify Gaeltacht villages with high proportions of habitual Irish speakers to emphasize authentic Gaelic identity on labels. Find villages with modest populations (to target niche, story-driven releases) and memorable Irish-language names for packaging copy and lore. Select counties with consistently high Irish-speaking averages for planning a county-themed beer series and regional marketing. Example Queries: SELECT `County`, `English name`, `Irish name`, `Population`, `Irish speakers` FROM `table_1_101196_1` WHERE CAST(REPLACE(`Irish speakers`, '%', '') AS INTEGER) >= 70 AND `Population` BETWEEN 100 AND 1500 ORDER BY CAST(REPLACE(`Irish speakers`, '%', '') AS INTEGER) DESC; SELECT `English name`, `Irish name`, `County`, `Population`, CAST(REPLACE(`Irish speakers`, '%', '') AS INTEGER) AS pct FROM `table_1_101196_1` ORDER BY pct DESC LIMIT 5; SELECT `County`, COUNT(*) AS village_count, ROUND(AVG(CAST(REPLACE(`Irish speakers`, '%', '') AS REAL)), 2) AS avg_irish_pct FROM `table_1_101196_1` GROUP BY `County` ORDER BY avg_irish_pct DESC;",reward,,
"Using only records where Timeslot ( ET ) is not null, which TV seasons have an average Viewers (millions) (using Viewers (millions) as numeric) and a count of Season rows such that the TV season's average viewers is greater than the average viewers across the whole table; list the TV season, the average viewers and the count of seasons, ordered by average viewers descending and return the top 5?","
WITH `cleaned` AS (
  SELECT `Season`, CAST(`Viewers (millions)` AS REAL) `viewers`, `TV season`, `Timeslot ( ET )`
  FROM `table_1_10120207_8`
  WHERE `Timeslot ( ET )` IS NOT NULL
)
SELECT ALL `TV season`, AVG(`viewers`) AS `avg_viewers`, COUNT(*) AS `count_seasons`
FROM `cleaned`
GROUP BY `TV season`
HAVING AVG(`viewers`) > (SELECT AVG(CAST(`Viewers (millions)` AS REAL)) FROM `table_1_10120207_8`)
ORDER BY `avg_viewers` DESC
LIMIT 5;
","
WITH `cleaned` AS (
  SELECT col0, CAST(col6 AS REAL) `viewers`, col4, col1
  FROM `table_1_10120207_8`
  WHERE col1 IS NOT NULL
)
SELECT ALL col4, AVG(`viewers`) AS `avg_viewers`, COUNT(*) AS `count_seasons`
FROM `cleaned`
GROUP BY col4
HAVING AVG(`viewers`) > (SELECT AVG(CAST(col6 AS REAL)) FROM `table_1_10120207_8`)
ORDER BY `avg_viewers` DESC
LIMIT 5;
","[('2004–2005', 12.295, 2), ('2007–2008', 11.84, 1), ('2010–2011', 11.14, 2), ('2008–2009', 11.025, 2), ('2006–2007', 10.8, 2)]",table_1_10120207_8,"Parse intent: calculate per-TV-season average viewers and number of seasons from rows with non-null Timeslot, then select those TV seasons with average above the global average and return five highest by average. Map schema: use Season as unit counted, TV season as group, Viewers (millions) cast to real for averaging, Timeslot ( ET ) IS NOT NULL filter, and overall AVG comparison. Draft: pose a question requesting TV season, AVG(Viewers (millions)) and COUNT(Season) with the specified filtering and ordering. Validate: includes all columns and calculations present in the SQL and nothing extra.",reserved,28,reward,,
"List the 10 City and Region rows showing City, Region, PctChange1981_2010 = (2010 Est. - 1981 Census) * 100.0 / 1981 Census and RegionAvgPct = AVG((2010 Est. - 1981 Census) * 100.0 / 1981 Census) per Region, where 1981 Census > 0 and (PctChange1981_2010 > RegionAvgPct OR PctChange1981_2010 BETWEEN -1000 AND 10000), ordered by PctChange1981_2010 ascending and limited to 10?","
SELECT main.`City`, main.`Region`, (main.`2010 Est.` - main.`1981 Census`) * 100.0 / main.`1981 Census` `PctChange1981_2010`, region_avg.`AvgPct` `RegionAvgPct`
FROM `table_1_10138926_1` main
JOIN (
  SELECT `Region`, AVG((`2010 Est.` - `1981 Census`) * 100.0 / `1981 Census`) `AvgPct`
  FROM `table_1_10138926_1`
  GROUP BY `Region`
) region_avg
ON main.`Region` = region_avg.`Region`
WHERE main.`1981 Census` > 0
AND ((main.`2010 Est.` - main.`1981 Census`) * 100.0 / main.`1981 Census`) > region_avg.`AvgPct`
OR (((main.`2010 Est.` - main.`1981 Census`) * 100.0 / main.`1981 Census`) BETWEEN -1000 AND 10000)
ORDER BY `PctChange1981_2010`
LIMIT 10;
","
SELECT main.col1, main.col6, (main.col5 - main.col2) * 100.0 / main.col2 `PctChange1981_2010`, region_avg.`AvgPct` `RegionAvgPct`
FROM `table_1_10138926_1` main
JOIN (
  SELECT col6, AVG((col5 - col2) * 100.0 / col2) `AvgPct`
  FROM `table_1_10138926_1`
  GROUP BY col6
) region_avg
ON main.col6 = region_avg.col6
WHERE main.col2 > 0
AND ((main.col5 - main.col2) * 100.0 / main.col2) > region_avg.`AvgPct`
OR (((main.col5 - main.col2) * 100.0 / main.col2) BETWEEN -1000 AND 10000)
ORDER BY `PctChange1981_2010`
LIMIT 10;
","[('cosenza', 'calabria', -34.3938727165476, -3.4074102970551805), ('cagliari', 'sardinia', -33.08131777907017, 30.449520359973313), ('portici', 'campania', -32.86780251212536, 22.310955969852948), ('catania', 'sicily', -22.840811089375485, 7.398879585630332), ('venice', 'veneto', -21.742848393452473, -5.678988661792571), ('taranto', 'apulia', -21.421870455262372, 7.065125646430758), ('naples', 'campania', -20.85250006804758, 22.310955969852948), ('genoa', 'liguria', -20.315901926215272, -15.381540889107036), ('turin', 'piedmont', -18.7611555792666, -5.348803520791715), ('trieste', 'friuli-venezia giulia', -18.55774679140465, -7.205498881047103)]",table_1_10138926_1,"Parse intent: return cities with their percent population change from 1981 to 2010 plus the region's average percent change, filter by positive 1981 Census and by either exceeding the regional average or falling in a broad numeric range, then sort and limit. Map schema: use City, Region, 1981 Census, 2010 Est. to compute PctChange1981_2010 and compute RegionAvgPct by AVG over the same expression grouped by Region. Draft: ask explicitly for City, Region, the PctChange expression, RegionAvgPct, the filter 1981 Census > 0, the OR with BETWEEN -1000 and 10000, ORDER BY PctChange1981_2010 and LIMIT 10. Validate: confirm all columns, calculations, grouping, filter logic, ordering and limit are present.",reserved,15,reward,,
"For CrossCountry and First ScotRail with at least 3 cars per set, or built in 2004, how many vehicles were built and how many sets does that correspond to?","
SELECT DISTINCT `Operator`, SUM(`No. Built`) AS `Total Built`, ROUND(1.0*SUM(`No. Built`)/SUM(`Cars per Set`),2) `Estimated Sets`
FROM `table_1_1015421_1`
WHERE `Operator` IN (`CrossCountry`,`First ScotRail`) AND `Cars per Set` >= 3 OR `Year Built` = `2004`
GROUP BY `Operator`
HAVING SUM(`No. Built`) > 10
LIMIT 10;
","SELECT col1, SUM(col2) AS `Total Built`
FROM `table_1_1015421_1`
WHERE (col1 IN ('CrossCountry','First ScotRail') AND col4 >= 3) OR col3 = '2004'
GROUP BY col1
HAVING SUM(col2) > 10
LIMIT 10;","[('first scotrail', 11.0)]",table_1_1015421_1,"STEP 1: Parse the SQL intent — compute, for each Operator, the total No. Built and an estimated number of sets (SUM(No. Built)/SUM(Cars per Set)), grouping by Operator, but only include groups with SUM(No. Built) > 10. Rows are filtered by (Operator IN (CrossCountry, First ScotRail) AND Cars per Set >= 3) OR Year Built = 2004. STEP 2: Choose ambiguity type — attachment ambiguity fits best because the WHERE clause mixes an operator/Cars-per-Set condition with OR Year Built = 2004, so it's unclear whether ""built in 2004"" applies only to those operators or to any operator. STEP 3: Draft the question — produce a natural-language question that matches the SQL but is ambiguous: ""For CrossCountry and First ScotRail with at least 3 cars per set, or built in 2004, how many vehicles were built and how many sets does that correspond to?"" STEP 4: Explain ambiguity — in the SQL the OR makes Year Built = 2004 apply to all rows (so rows from any operator in 2004 are included), but a reader might interpret the phrase ""for CrossCountry and First ScotRail ... built in 2004"" as restricting the 2004 requirement only to those two operators (or conversely as an alternative that includes any 2004 entries regardless of operator).",reserved,12,reward,,"type: Attachment ambiguity | explanation: The phrase ""or built in 2004"" can attach to the operator condition (meaning only CrossCountry/First ScotRail entries are considered, some of which may also be from 2004) or to the whole filter (meaning include any operator if the row is from 2004); the SQL treats Year Built = 2004 as an alternative that applies to all operators, but a reader may interpret it as only modifying the named operators."
"Show me the rows where there are hyphen-marked suffixes, or identical forms across dialects, or k↔m initial flips — and tell me which dialects have the suffixes, which dialect-pairs are stable cognates, and which pairs show the k vs m contrast?","
SELECT
  *,
  TRIM(
    (CASE WHEN `Kalau Kawau Ya` LIKE '%-%' THEN '`Kalau Kawau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kawalgau Ya` LIKE '%-%' THEN '`Kawalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kalaw Lagaw Ya` LIKE '%-%' THEN '`Kalaw Lagaw Ya`,' ELSE '' END) ||
    (CASE WHEN `Kulkalgau Ya` LIKE '%-%' THEN '`Kulkalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kauraraigau Ya (Kowrareg)` LIKE '%-%' THEN '`Kauraraigau Ya (Kowrareg)`,' ELSE '' END)
  ,',') AS `Suffix_dialects`,
  TRIM(
    (CASE WHEN `Kalau Kawau Ya` = `Kawalgau Ya` AND `Kalau Kawau Ya` IS NOT NULL THEN '`Kalau Kawau Ya`=`Kawalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kalau Kawau Ya` = `Kalaw Lagaw Ya` AND `Kalau Kawau Ya` IS NOT NULL THEN '`Kalau Kawau Ya`=`Kalaw Lagaw Ya`,' ELSE '' END) ||
    (CASE WHEN `Kalau Kawau Ya` = `Kulkalgau Ya` AND `Kalau Kawau Ya` IS NOT NULL THEN '`Kalau Kawau Ya`=`Kulkalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kalau Kawau Ya` = `Kauraraigau Ya (Kowrareg)` AND `Kalau Kawau Ya` IS NOT NULL THEN '`Kalau Kawau Ya`=`Kauraraigau Ya (Kowrareg)`,' ELSE '' END) ||
    (CASE WHEN `Kawalgau Ya` = `Kalaw Lagaw Ya` AND `Kawalgau Ya` IS NOT NULL THEN '`Kawalgau Ya`=`Kalaw Lagaw Ya`,' ELSE '' END) ||
    (CASE WHEN `Kawalgau Ya` = `Kulkalgau Ya` AND `Kawalgau Ya` IS NOT NULL THEN '`Kawalgau Ya`=`Kulkalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kawalgau Ya` = `Kauraraigau Ya (Kowrareg)` AND `Kawalgau Ya` IS NOT NULL THEN '`Kawalgau Ya`=`Kauraraigau Ya (Kowrareg)`,' ELSE '' END) ||
    (CASE WHEN `Kalaw Lagaw Ya` = `Kulkalgau Ya` AND `Kalaw Lagaw Ya` IS NOT NULL THEN '`Kalaw Lagaw Ya`=`Kulkalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kalaw Lagaw Ya` = `Kauraraigau Ya (Kowrareg)` AND `Kalaw Lagaw Ya` IS NOT NULL THEN '`Kalaw Lagaw Ya`=`Kauraraigau Ya (Kowrareg)`,' ELSE '' END) ||
    (CASE WHEN `Kulkalgau Ya` = `Kauraraigau Ya (Kowrareg)` AND `Kulkalgau Ya` IS NOT NULL THEN '`Kulkalgau Ya`=`Kauraraigau Ya (Kowrareg)`,' ELSE '' END)
  ,',') AS `Stable_cognate_pairs`,
  TRIM(
    (CASE WHEN `Kalau Kawau Ya` IS NOT NULL AND `Kawalgau Ya` IS NOT NULL AND ((LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))='k' AND LOWER(SUBSTR(`Kawalgau Ya`,1,1))='m') OR (LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))='m' AND LOWER(SUBSTR(`Kawalgau Ya`,1,1))='k')) THEN '`Kalau Kawau Ya`~`Kawalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kalau Kawau Ya` IS NOT NULL AND `Kalaw Lagaw Ya` IS NOT NULL AND ((LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))='k' AND LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))='m') OR (LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))='m' AND LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))='k')) THEN '`Kalau Kawau Ya`~`Kalaw Lagaw Ya`,' ELSE '' END) ||
    (CASE WHEN `Kalau Kawau Ya` IS NOT NULL AND `Kulkalgau Ya` IS NOT NULL AND ((LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))='k' AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1))='m') OR (LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))='m' AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1))='k')) THEN '`Kalau Kawau Ya`~`Kulkalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kalau Kawau Ya` IS NOT NULL AND `Kauraraigau Ya (Kowrareg)` IS NOT NULL AND ((LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))='k' AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))='m') OR (LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))='m' AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))='k')) THEN '`Kalau Kawau Ya`~`Kauraraigau Ya (Kowrareg)`,' ELSE '' END) ||
    (CASE WHEN `Kawalgau Ya` IS NOT NULL AND `Kalaw Lagaw Ya` IS NOT NULL AND ((LOWER(SUBSTR(`Kawalgau Ya`,1,1))='k' AND LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))='m') OR (LOWER(SUBSTR(`Kawalgau Ya`,1,1))='m' AND LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))='k')) THEN '`Kawalgau Ya`~`Kalaw Lagaw Ya`,' ELSE '' END) ||
    (CASE WHEN `Kawalgau Ya` IS NOT NULL AND `Kulkalgau Ya` IS NOT NULL AND ((LOWER(SUBSTR(`Kawalgau Ya`,1,1))='k' AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1))='m') OR (LOWER(SUBSTR(`Kawalgau Ya`,1,1))='m' AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1))='k')) THEN '`Kawalgau Ya`~`Kulkalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kawalgau Ya` IS NOT NULL AND `Kauraraigau Ya (Kowrareg)` IS NOT NULL AND ((LOWER(SUBSTR(`Kawalgau Ya`,1,1))='k' AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))='m') OR (LOWER(SUBSTR(`Kawalgau Ya`,1,1))='m' AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))='k')) THEN '`Kawalgau Ya`~`Kauraraigau Ya (Kowrareg)`,' ELSE '' END) ||
    (CASE WHEN `Kalaw Lagaw Ya` IS NOT NULL AND `Kulkalgau Ya` IS NOT NULL AND ((LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))='k' AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1))='m') OR (LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))='m' AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1))='k')) THEN '`Kalaw Lagaw Ya`~`Kulkalgau Ya`,' ELSE '' END) ||
    (CASE WHEN `Kalaw Lagaw Ya` IS NOT NULL AND `Kauraraigau Ya (Kowrareg)` IS NOT NULL AND ((LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))='k' AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))='m') OR (LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))='m' AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))='k')) THEN '`Kalaw Lagaw Ya`~`Kauraraigau Ya (Kowrareg)`,' ELSE '' END) ||
    (CASE WHEN `Kulkalgau Ya` IS NOT NULL AND `Kauraraigau Ya (Kowrareg)` IS NOT NULL AND ((LOWER(SUBSTR(`Kulkalgau Ya`,1,1))='k' AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))='m') OR (LOWER(SUBSTR(`Kulkalgau Ya`,1,1))='m' AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))='k')) THEN '`Kulkalgau Ya`~`Kauraraigau Ya (Kowrareg)`,' ELSE '' END)
  ,',') AS `K_vs_M_pairs`
FROM `table_1_1015914_15`
WHERE
  (`Kalau Kawau Ya` LIKE '%-%' OR `Kawalgau Ya` LIKE '%-%' OR `Kalaw Lagaw Ya` LIKE '%-%' OR `Kulkalgau Ya` LIKE '%-%' OR `Kauraraigau Ya (Kowrareg)` LIKE '%-%')
  OR
  (`Kalau Kawau Ya` = `Kawalgau Ya` OR `Kalau Kawau Ya` = `Kalaw Lagaw Ya` OR `Kalau Kawau Ya` = `Kulkalgau Ya` OR `Kalau Kawau Ya` = `Kauraraigau Ya (Kowrareg)` OR
   `Kawalgau Ya` = `Kalaw Lagaw Ya` OR `Kawalgau Ya` = `Kulkalgau Ya` OR `Kawalgau Ya` = `Kauraraigau Ya (Kowrareg)` OR
   `Kalaw Lagaw Ya` = `Kulkalgau Ya` OR `Kalaw Lagaw Ya` = `Kauraraigau Ya (Kowrareg)` OR
   `Kulkalgau Ya` = `Kauraraigau Ya (Kowrareg)`)
  OR
  (
    (LOWER(SUBSTR(`Kalau Kawau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kawalgau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))<>LOWER(SUBSTR(`Kawalgau Ya`,1,1))) OR
    (LOWER(SUBSTR(`Kalau Kawau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))<>LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))) OR
    (LOWER(SUBSTR(`Kalau Kawau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))<>LOWER(SUBSTR(`Kulkalgau Ya`,1,1))) OR
    (LOWER(SUBSTR(`Kalau Kawau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kalau Kawau Ya`,1,1))<>LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))) OR
    (LOWER(SUBSTR(`Kawalgau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kawalgau Ya`,1,1))<>LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))) OR
    (LOWER(SUBSTR(`Kawalgau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kawalgau Ya`,1,1))<>LOWER(SUBSTR(`Kulkalgau Ya`,1,1))) OR
    (LOWER(SUBSTR(`Kawalgau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kawalgau Ya`,1,1))<>LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))) OR
    (LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))<>LOWER(SUBSTR(`Kulkalgau Ya`,1,1))) OR
    (LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kalaw Lagaw Ya`,1,1))<>LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1))) OR
    (LOWER(SUBSTR(`Kulkalgau Ya`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1)) IN ('k','m') AND LOWER(SUBSTR(`Kulkalgau Ya`,1,1))<>LOWER(SUBSTR(`Kauraraigau Ya (Kowrareg)`,1,1)))
  );
","
SELECT
  *,
  TRIM(
    (CASE WHEN col1 LIKE '%-%' THEN 'col1,' ELSE '' END) ||
    (CASE WHEN col2 LIKE '%-%' THEN 'col2,' ELSE '' END) ||
    (CASE WHEN col3 LIKE '%-%' THEN 'col3,' ELSE '' END) ||
    (CASE WHEN col4 LIKE '%-%' THEN 'col4,' ELSE '' END) ||
    (CASE WHEN col5 LIKE '%-%' THEN 'col5,' ELSE '' END)
  ,',') AS `Suffix_dialects`,
  TRIM(
    (CASE WHEN col1 = col2 AND col1 IS NOT NULL THEN 'col1=col2,' ELSE '' END) ||
    (CASE WHEN col1 = col3 AND col1 IS NOT NULL THEN 'col1=col3,' ELSE '' END) ||
    (CASE WHEN col1 = col4 AND col1 IS NOT NULL THEN 'col1=col4,' ELSE '' END) ||
    (CASE WHEN col1 = col5 AND col1 IS NOT NULL THEN 'col1=col5,' ELSE '' END) ||
    (CASE WHEN col2 = col3 AND col2 IS NOT NULL THEN 'col2=col3,' ELSE '' END) ||
    (CASE WHEN col2 = col4 AND col2 IS NOT NULL THEN 'col2=col4,' ELSE '' END) ||
    (CASE WHEN col2 = col5 AND col2 IS NOT NULL THEN 'col2=col5,' ELSE '' END) ||
    (CASE WHEN col3 = col4 AND col3 IS NOT NULL THEN 'col3=col4,' ELSE '' END) ||
    (CASE WHEN col3 = col5 AND col3 IS NOT NULL THEN 'col3=col5,' ELSE '' END) ||
    (CASE WHEN col4 = col5 AND col4 IS NOT NULL THEN 'col4=col5,' ELSE '' END)
  ,',') AS `Stable_cognate_pairs`,
  TRIM(
    (CASE WHEN col1 IS NOT NULL AND col2 IS NOT NULL AND ((LOWER(SUBSTR(col1,1,1))='k' AND LOWER(SUBSTR(col2,1,1))='m') OR (LOWER(SUBSTR(col1,1,1))='m' AND LOWER(SUBSTR(col2,1,1))='k')) THEN 'col1~col2,' ELSE '' END) ||
    (CASE WHEN col1 IS NOT NULL AND col3 IS NOT NULL AND ((LOWER(SUBSTR(col1,1,1))='k' AND LOWER(SUBSTR(col3,1,1))='m') OR (LOWER(SUBSTR(col1,1,1))='m' AND LOWER(SUBSTR(col3,1,1))='k')) THEN 'col1~col3,' ELSE '' END) ||
    (CASE WHEN col1 IS NOT NULL AND col4 IS NOT NULL AND ((LOWER(SUBSTR(col1,1,1))='k' AND LOWER(SUBSTR(col4,1,1))='m') OR (LOWER(SUBSTR(col1,1,1))='m' AND LOWER(SUBSTR(col4,1,1))='k')) THEN 'col1~col4,' ELSE '' END) ||
    (CASE WHEN col1 IS NOT NULL AND col5 IS NOT NULL AND ((LOWER(SUBSTR(col1,1,1))='k' AND LOWER(SUBSTR(col5,1,1))='m') OR (LOWER(SUBSTR(col1,1,1))='m' AND LOWER(SUBSTR(col5,1,1))='k')) THEN 'col1~col5,' ELSE '' END) ||
    (CASE WHEN col2 IS NOT NULL AND col3 IS NOT NULL AND ((LOWER(SUBSTR(col2,1,1))='k' AND LOWER(SUBSTR(col3,1,1))='m') OR (LOWER(SUBSTR(col2,1,1))='m' AND LOWER(SUBSTR(col3,1,1))='k')) THEN 'col2~col3,' ELSE '' END) ||
    (CASE WHEN col2 IS NOT NULL AND col4 IS NOT NULL AND ((LOWER(SUBSTR(col2,1,1))='k' AND LOWER(SUBSTR(col4,1,1))='m') OR (LOWER(SUBSTR(col2,1,1))='m' AND LOWER(SUBSTR(col4,1,1))='k')) THEN 'col2~col4,' ELSE '' END) ||
    (CASE WHEN col2 IS NOT NULL AND col5 IS NOT NULL AND ((LOWER(SUBSTR(col2,1,1))='k' AND LOWER(SUBSTR(col5,1,1))='m') OR (LOWER(SUBSTR(col2,1,1))='m' AND LOWER(SUBSTR(col5,1,1))='k')) THEN 'col2~col5,' ELSE '' END) ||
    (CASE WHEN col3 IS NOT NULL AND col4 IS NOT NULL AND ((LOWER(SUBSTR(col3,1,1))='k' AND LOWER(SUBSTR(col4,1,1))='m') OR (LOWER(SUBSTR(col3,1,1))='m' AND LOWER(SUBSTR(col4,1,1))='k')) THEN 'col3~col4,' ELSE '' END) ||
    (CASE WHEN col3 IS NOT NULL AND col5 IS NOT NULL AND ((LOWER(SUBSTR(col3,1,1))='k' AND LOWER(SUBSTR(col5,1,1))='m') OR (LOWER(SUBSTR(col3,1,1))='m' AND LOWER(SUBSTR(col5,1,1))='k')) THEN 'col3~col5,' ELSE '' END) ||
    (CASE WHEN col4 IS NOT NULL AND col5 IS NOT NULL AND ((LOWER(SUBSTR(col4,1,1))='k' AND LOWER(SUBSTR(col5,1,1))='m') OR (LOWER(SUBSTR(col4,1,1))='m' AND LOWER(SUBSTR(col5,1,1))='k')) THEN 'col4~col5,' ELSE '' END)
  ,',') AS `K_vs_M_pairs`
FROM `table_1_1015914_15`
WHERE
  (col1 LIKE '%-%' OR col2 LIKE '%-%' OR col3 LIKE '%-%' OR col4 LIKE '%-%' OR col5 LIKE '%-%')
  OR
  (col1 = col2 OR col1 = col3 OR col1 = col4 OR col1 = col5 OR
   col2 = col3 OR col2 = col4 OR col2 = col5 OR
   col3 = col4 OR col3 = col5 OR
   col4 = col5)
  OR
  (
    (LOWER(SUBSTR(col1,1,1)) IN ('k','m') AND LOWER(SUBSTR(col2,1,1)) IN ('k','m') AND LOWER(SUBSTR(col1,1,1))<>LOWER(SUBSTR(col2,1,1))) OR
    (LOWER(SUBSTR(col1,1,1)) IN ('k','m') AND LOWER(SUBSTR(col3,1,1)) IN ('k','m') AND LOWER(SUBSTR(col1,1,1))<>LOWER(SUBSTR(col3,1,1))) OR
    (LOWER(SUBSTR(col1,1,1)) IN ('k','m') AND LOWER(SUBSTR(col4,1,1)) IN ('k','m') AND LOWER(SUBSTR(col1,1,1))<>LOWER(SUBSTR(col4,1,1))) OR
    (LOWER(SUBSTR(col1,1,1)) IN ('k','m') AND LOWER(SUBSTR(col5,1,1)) IN ('k','m') AND LOWER(SUBSTR(col1,1,1))<>LOWER(SUBSTR(col5,1,1))) OR
    (LOWER(SUBSTR(col2,1,1)) IN ('k','m') AND LOWER(SUBSTR(col3,1,1)) IN ('k','m') AND LOWER(SUBSTR(col2,1,1))<>LOWER(SUBSTR(col3,1,1))) OR
    (LOWER(SUBSTR(col2,1,1)) IN ('k','m') AND LOWER(SUBSTR(col4,1,1)) IN ('k','m') AND LOWER(SUBSTR(col2,1,1))<>LOWER(SUBSTR(col4,1,1))) OR
    (LOWER(SUBSTR(col2,1,1)) IN ('k','m') AND LOWER(SUBSTR(col5,1,1)) IN ('k','m') AND LOWER(SUBSTR(col2,1,1))<>LOWER(SUBSTR(col5,1,1))) OR
    (LOWER(SUBSTR(col3,1,1)) IN ('k','m') AND LOWER(SUBSTR(col4,1,1)) IN ('k','m') AND LOWER(SUBSTR(col3,1,1))<>LOWER(SUBSTR(col4,1,1))) OR
    (LOWER(SUBSTR(col3,1,1)) IN ('k','m') AND LOWER(SUBSTR(col5,1,1)) IN ('k','m') AND LOWER(SUBSTR(col3,1,1))<>LOWER(SUBSTR(col5,1,1))) OR
    (LOWER(SUBSTR(col4,1,1)) IN ('k','m') AND LOWER(SUBSTR(col5,1,1)) IN ('k','m') AND LOWER(SUBSTR(col4,1,1))<>LOWER(SUBSTR(col5,1,1)))
  );
","[('you sg', 'ngi', 'ngi', 'ni', 'ni', 'ngi', '', 'col1=col2,col1=col5,col2=col5,col3=col4', ''), ('thunder', 'gigi', 'dhuyum', 'dhuyum', 'dhuyum', 'dhuyuma', '', 'col2=col3,col2=col4,col3=col4', ''), ('end, finish', 'muasi- (b muyasi-)', 'muasi-', 'minasi-', 'minasi-', 'moasi-', 'col1,col2,col3,col4,col5', 'col3=col4', ''), ('heat', 'kom', 'kœmàn', 'kœmààna', 'kom', 'kœmàna', '', 'col1=col4', ''), ('steam', 'kœman', 'kœmàn', 'kœmààna', 'kœmàn', 'kœmàna', '', 'col2=col4', ''), ('dative', '-pa', '-pa (-ka)', '-ka (-pa)', '-ka (-pa)', '-pa[rri] (-ka)', 'col1,col2,col3,col4,col5', 'col3=col4', ''), ('ablative', '-ngu(z), -z(i)', '-ngu, -z(i)', '-ngu, -zi', '-ngu, -z(i)', '-nguzi, -zi', 'col1,col2,col3,col4,col5', 'col2=col4', '')]",table_1_1015914_15,"I'm a practitioner who wants a compact toolkit: suffixes, stable chorus cognates, and k~m antiphonal pairs for stitching chants. The SQL returns rows where any of those three conditions hold and builds columns listing which dialects have hyphen-suffixes, which dialect-pairs are identical, and which pairs show k vs m initial contrasts. The dialect columns are the five named dialects and the query reports which of those columns/pairs satisfy each condition. Drafted question: Ask for rows that meet any of the three criteria and request that the output indicate which dialects contain suffixes, which pairs are stable cognates, and which pairs are k~m contrasts. This question directly captures the combined filtering and the three annotated outputs the query produces.",persona,"An experimental sound-poet and performance artist who composes cross-dialectal call-and-response chants by stitching together basic lexemes and grammatical suffixes from the Kalaw Lagaw Ya dialect set to maximize rhythmic and phonetic resonance. Goals: Identify morphological suffixes (marked with hyphens) that can serve as short, chantable rhythmic units across dialects. Find stable cognates (identical or near-identical forms) that will be easily recognized by speakers of multiple dialects for chorus lines. Locate lexical pairs whose initial consonants differ (e.g., k vs m) so the poet can craft alliterative/antiphonal couplets that highlight dialectal contrast. Example Queries: /* 1) Pull all rows that contain affix-like forms (hyphenated entries) in any dialect, to harvest short rhythmic morphemes */
SELECT *
FROM `table_1_1015914_15`
WHERE `Kalau Kawau Ya` LIKE '%-%'
   OR `Kawalgau Ya` LIKE '%-%'
   OR `Kalaw Lagaw Ya` LIKE '%-%'
   OR `Kulkalgau Ya` LIKE '%-%'
   OR `Kauraraigau Ya (Kowrareg)` LIKE '%-%'; /* 2) Find items where Kalaw Lagaw Ya and Kulkalgau Ya are identical (stable across dialects) for chorus material */
SELECT *
FROM `table_1_1015914_15`
WHERE `Kalaw Lagaw Ya` = `Kulkalgau Ya`;  /* 3) Select rows where Kalau Kawau Ya and Kalaw Lagaw Ya differ in their initial consonant (useful for antiphonal k~m pairings) */
SELECT *
FROM `table_1_1015914_15`
WHERE SUBSTR(`Kalau Kawau Ya`, 1, 1) <> SUBSTR(`Kalaw Lagaw Ya`, 1, 1)
  AND `Kalau Kawau Ya` IS NOT NULL
  AND `Kalaw Lagaw Ya` IS NOT NULL;",reward,,
"Which countries have winners, and what nominations and actors are associated with them?","
SELECT `Country` AS `Country`,
       COUNT(*) `Winners`,
       GROUP_CONCAT(`Nomination`, ' | ') `Nominations`,
       GROUP_CONCAT(`Actors Name`, ', ') `Actors`
FROM `table_1_10236830_4`
WHERE length(`Actors Name`) > 0 AND length(`Film Name`) > 0
GROUP BY `Country`
ORDER BY `Winners`
LIMIT 10;
","
SELECT col4 AS col4,
       COUNT(*) `Winners`,
       GROUP_CONCAT(col0, ' | ') `Nominations`,
       GROUP_CONCAT(col1, ', ') `Actors`
FROM `table_1_10236830_4`
WHERE length(col1) > 0 AND length(col2) > 0
GROUP BY col4
ORDER BY `Winners`
LIMIT 10;
","[('georgia', 1, 'best actor in a leading role', 'zurab begalishvili'), ('poland', 1, 'best debut', 'agnieszka włodarczyk'), ('ukraine', 1, 'best actor in a leading role', 'yuriy dubrovin'), ('russia', 2, 'best actress in a leading role | best actor in a supporting role', 'galina bokashevskaya, vsevolod shilovskiy'), ('serbia', 2, 'best actor in a supporting role | best actress in a supporting role', 'dragan nikolić, zora manojlovic')]",table_1_10236830_4,"STEP 1: Parse the SQL intent — The query groups rows by Country, counts rows per country as Winners, concatenates Nomination values (separated by ' | ') and Actors Name values (separated by ', '), filters out rows missing Actors Name or Film Name, orders results by the Winners count (ascending by default), and returns the first 10 groups. STEP 2: Determine a type of ambiguity — Scope ambiguity fits well: a short NL question like “Which countries have winners?” can mean (a) list all countries that have at least one winner, (b) rank countries by number of winners and show the top (or bottom) N, or (c) show winners per country. The SQL corresponds to one specific scoped interpretation (counts per country, limited/ordered), so scope ambiguity maps cleanly. STEP 3: Draft the question — Produce an NL question that matches the SQL output but is ambiguous in scope. STEP 4: Explain the ambiguity — In the SQL the phrase is concretely implemented as counts per country, ordered by that count and limited to 10 (so it effectively returns 10 countries sorted by winner count). In a different interpretation the same NL question could ask for all countries with any winner, or the countries with the most winners, or winners listed per country without ranking/limiting.",reserved,9,reward,,"type: Scope ambiguity | explanation: The question can mean (a) list every country that has at least one winner and show their nominations and actors, (b) rank countries by how many winners they have and return the top (or bottom) N, or (c) show the winners grouped per country; the original SQL implements the second-type interpretation narrowly (counts per country, ordered by the Winners count and limited to 10)."
"List Season, Division, League Apps, League Goals, FA Cup Apps, FA Cup Goals, Total Apps and Total Goals, plus Total Goals % of Career calculated as (Total Goals * 100.0) / 9, Total Apps % of Career calculated as (Total Apps * 100.0) / 196, League Goals per League App calculated as (League Goals * 1.0) / League Apps, and FA Cup Involvement calculated as (FA Cup Apps + FA Cup Goals), and include the Season values '1908–09', '1909–10', '1910–11', '1911–12', '1912–13', '1913–14' for rows where Division = Division?","
SELECT `Season`, `Division`, `League Apps`, `League Goals`, `FA Cup Apps`, `FA Cup Goals`, `Total Apps`, `Total Goals`, (`Total Goals` * 100.0) / 9 `Total Goals % of Career`, (`Total Apps` * 100.0) / 196 `Total Apps % of Career`, (`League Goals` * 1.0) / `League Apps` `League Goals per League App`, (`FA Cup Apps` + `FA Cup Goals`) `FA Cup Involvement`, `Season` `1908–09`, `Season` `1909–10`, `Season` `1910–11`, `Season` `1911–12`, `Season` `1912–13`, `Season` `1913–14` FROM `table_1_10240125_1` WHERE `Division` = `Division`;
","
SELECT col0, col1, col2, col3, col4, col5, col6, col7, (col7 * 100.0) / 9 `Total Goals % of Career`, (col6 * 100.0) / 196 `Total Apps % of Career`, (col3 * 1.0) / col2 `League Goals per League App`, (col4 + col5) `FA Cup Involvement`, col0 `1908–09`, col0 `1909–10`, col0 `1910–11`, col0 `1911–12`, col0 `1912–13`, col0 `1913–14` FROM `table_1_10240125_1` WHERE col1 = col1;
","[('1908–09', 'division two', 15.0, 1.0, 0.0, 0.0, 15.0, 1.0, 11.11111111111111, 7.653061224489796, 0.06666666666666667, 0.0, '1908–09', '1908–09', '1908–09', '1908–09', '1908–09', '1908–09'), ('1909–10', 'division two', 35.0, 0.0, 9.0, 1.0, 44.0, 1.0, 11.11111111111111, 22.448979591836736, 0.0, 10.0, '1909–10', '1909–10', '1909–10', '1909–10', '1909–10', '1909–10'), ('1910–11', 'division two', 38.0, 1.0, 2.0, 0.0, 40.0, 1.0, 11.11111111111111, 20.408163265306122, 0.02631578947368421, 2.0, '1910–11', '1910–11', '1910–11', '1910–11', '1910–11', '1910–11'), ('1911–12', 'division two', 34.0, 4.0, 12.0, 0.0, 46.0, 4.0, 44.44444444444444, 23.46938775510204, 0.11764705882352941, 12.0, '1911–12', '1911–12', '1911–12', '1911–12', '1911–12', '1911–12'), ('1912–13', 'division two', 36.0, 1.0, 3.0, 0.0, 39.0, 1.0, 11.11111111111111, 19.897959183673468, 0.027777777777777776, 3.0, '1912–13', '1912–13', '1912–13', '1912–13', '1912–13', '1912–13'), ('1913–14', 'division two', 12.0, 1.0, 0.0, 0.0, 12.0, 1.0, 11.11111111111111, 6.122448979591836, 0.08333333333333333, 0.0, '1913–14', '1913–14', '1913–14', '1913–14', '1913–14', '1913–14')]",table_1_10240125_1,"1) The query intent is to retrieve each season's stats plus computed career percentages and ratios, and to output explicit Season literals, with no effective filtering (Division = Division). 2) Associate the table fields with Season, Division, League Apps, League Goals, FA Cup Apps, FA Cup Goals, Total Apps, Total Goals and the formulas for percentages, ratio, and FA Cup involvement. 3) Compose a natural question asking for all those fields and exact computations and the listed Season values. 4) Ensure the question includes every column name, every calculation formula, the FA Cup Involvement expression, and the literal seasons.",reserved,3,reward,,
"Please give a season-by-season breakdown for George Utley at Sheffield United showing league and FA Cup appearances and goals, the goals-per-appearance for league, FA Cup and overall, a note when a season had no FA Cup appearances, the career totals and an efficiency rank of seasons by goals-per-appearance.","
WITH seasons AS (
  SELECT
    `Season`,
    `Division`,
    `League Apps`,
    `League Goals`,
    CASE WHEN `League Apps` <> 0 THEN CAST(`League Goals` AS FLOAT) / `League Apps` ELSE NULL END AS `league_goals_per_app`,
    `FA Cup Apps`,
    `FA Cup Goals`,
    CASE WHEN `FA Cup Apps` <> 0 THEN CAST(`FA Cup Goals` AS FLOAT) / `FA Cup Apps` ELSE NULL END AS `fa_cup_goals_per_app`,
    `Total Apps`,
    `Total Goals`,
    CASE WHEN `Total Apps` <> 0 THEN CAST(`Total Goals` AS FLOAT) / `Total Apps` ELSE NULL END AS `total_goals_per_app`,
    CASE WHEN `FA Cup Apps` = 0 THEN 1 ELSE 0 END AS `no_fa_cup_flag`
  FROM table_1_10240125_2
)
SELECT
  '`' || `Season` || '`' AS `Season_label`,
  '`' || `Division` || '`' AS `Division_label`,
  `League Apps`,
  `League Goals`,
  ROUND(`league_goals_per_app`, 3) AS `League_goals_per_app`,
  `FA Cup Apps`,
  `FA Cup Goals`,
  ROUND(`fa_cup_goals_per_app`, 3) AS `FA_Cup_goals_per_app`,
  `Total Apps`,
  `Total Goals`,
  ROUND(`total_goals_per_app`, 3) AS `Total_goals_per_app`,
  CASE WHEN `no_fa_cup_flag` = 1 THEN '`No FA Cup Apps`' ELSE '`FA Cup Involved`' END AS `FA_Cup_note`,
  SUM(`League Apps`) OVER () AS `Career_League_Apps_Total`,
  SUM(`League Goals`) OVER () AS `Career_League_Goals_Total`,
  SUM(`FA Cup Apps`) OVER () AS `Career_FA_Cup_Apps_Total`,
  SUM(`FA Cup Goals`) OVER () AS `Career_FA_Cup_Goals_Total`,
  SUM(`Total Apps`) OVER () AS `Career_Total_Apps`,
  SUM(`Total Goals`) OVER () AS `Career_Total_Goals`,
  RANK() OVER (ORDER BY `total_goals_per_app` DESC) AS `Efficiency_Rank_by_Total_Goals_per_App`
FROM seasons
ORDER BY `Season`;
","
WITH seasons AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    CASE WHEN col2 <> 0 THEN CAST(col3 AS FLOAT) / col2 ELSE NULL END AS `league_goals_per_app`,
    col4,
    col5,
    CASE WHEN col4 <> 0 THEN CAST(col5 AS FLOAT) / col4 ELSE NULL END AS `fa_cup_goals_per_app`,
    col6,
    col7,
    CASE WHEN col6 <> 0 THEN CAST(col7 AS FLOAT) / col6 ELSE NULL END AS `total_goals_per_app`,
    CASE WHEN col4 = 0 THEN 1 ELSE 0 END AS `no_fa_cup_flag`
  FROM table_1_10240125_2
)
SELECT
  '`' || col0 || '`' AS `Season_label`,
  '`' || col1 || '`' AS `Division_label`,
  col2,
  col3,
  ROUND(`league_goals_per_app`, 3) AS `League_goals_per_app`,
  col4,
  col5,
  ROUND(`fa_cup_goals_per_app`, 3) AS `FA_Cup_goals_per_app`,
  col6,
  col7,
  ROUND(`total_goals_per_app`, 3) AS `Total_goals_per_app`,
  CASE WHEN `no_fa_cup_flag` = 1 THEN '`No FA Cup Apps`' ELSE '`FA Cup Involved`' END AS `FA_Cup_note`,
  SUM(col2) OVER () AS `Career_League_Apps_Total`,
  SUM(col3) OVER () AS `Career_League_Goals_Total`,
  SUM(col4) OVER () AS `Career_FA_Cup_Apps_Total`,
  SUM(col5) OVER () AS `Career_FA_Cup_Goals_Total`,
  SUM(col6) OVER () AS `Career_Total_Apps`,
  SUM(col7) OVER () AS `Career_Total_Goals`,
  RANK() OVER (ORDER BY `total_goals_per_app` DESC) AS `Efficiency_Rank_by_Total_Goals_per_App`
FROM seasons
ORDER BY col0;
","[('`1913–14`', '`division one`', 23.0, 1.0, 0.043, 7.0, 4.0, 0.571, 30.0, 5.0, 0.167, '`FA Cup Involved`', 107.0, 4.0, 15.0, 5.0, 122.0, 9.0, 1), ('`1914–15`', '`division one`', 30.0, 1.0, 0.033, 7.0, 1.0, 0.143, 37.0, 2.0, 0.054, '`FA Cup Involved`', 107.0, 4.0, 15.0, 5.0, 122.0, 9.0, 3), ('`1919–20`', '`division one`', 16.0, 0.0, 0.0, 0.0, 0.0, None, 16.0, 0.0, 0.0, '`No FA Cup Apps`', 107.0, 4.0, 15.0, 5.0, 122.0, 9.0, 4), ('`1920–21`', '`division one`', 23.0, 2.0, 0.087, 0.0, 0.0, None, 23.0, 2.0, 0.087, '`No FA Cup Apps`', 107.0, 4.0, 15.0, 5.0, 122.0, 9.0, 2), ('`1921–22`', '`division one`', 15.0, 0.0, 0.0, 1.0, 0.0, 0.0, 16.0, 0.0, 0.0, '`FA Cup Involved`', 107.0, 4.0, 15.0, 5.0, 122.0, 9.0, 4)]",table_1_10240125_2,"As the club historian I speak precisely about seasons, competitions and appearances but avoid SQL jargon; I know the table holds season-by-season league and FA Cup figures. The query computes per-season league, FA Cup and total goals-per-appearance, flags seasons with no FA Cup apps, accumulates career totals, and assigns an efficiency rank. Schema columns map to Season, Division, League Apps/Goals, FA Cup Apps/Goals, Total Apps/Goals and derived per-app rates and flags. Draft question: ask for a season-by-season breakdown for George Utley showing league and FA Cup appearances and goals, goals-per-appearance for each competition and overall, a note for seasons with no FA Cup appearances, career totals and an efficiency rank. This is consistent with the available columns and derived metrics in the data.",persona,"Sheffield United club historian and archivist who maintains player records and publishes historical profiles; uses the database to verify season-by-season appearances and goals for George Utley and to prepare authoritative summaries for the club archive and publications. Goals: Verify and consolidate George Utley's season-by-season league and FA Cup appearances and goals for an official player biography. Compute career totals and efficiency metrics (goals per appearance) to highlight key seasons for publications and exhibitions. Identify seasons with missing or zero cup involvement (e.g., post-war gaps) to annotate historical notes and cross-check with primary sources. Example Queries: /* Career totals for George Utley at Sheffield United */
SELECT
  SUM(""League Apps"") AS league_apps_total,
  SUM(""League Goals"") AS league_goals_total,
  SUM(""FA Cup Apps"") AS fa_cup_apps_total,
  SUM(""FA Cup Goals"") AS fa_cup_goals_total,
  SUM(""Total Apps"") AS total_apps,
  SUM(""Total Goals"") AS total_goals
FROM table_1_10240125_2; /* Season-by-season goals-per-appearance (league, FA Cup, total) to identify most efficient seasons */
SELECT
  ""Season"",
  ""League Apps"",
  ""League Goals"",
  CASE WHEN ""League Apps"" <> 0 THEN CAST(""League Goals"" AS FLOAT) / NULLIF(""League Apps"",0) ELSE NULL END AS league_goals_per_app,
  ""FA Cup Apps"",
  ""FA Cup Goals"",
  CASE WHEN ""FA Cup Apps"" <> 0 THEN CAST(""FA Cup Goals"" AS FLOAT) / NULLIF(""FA Cup Apps"",0) ELSE NULL END AS fa_cup_goals_per_app,
  ""Total Apps"",
  ""Total Goals"",
  CASE WHEN ""Total Apps"" <> 0 THEN CAST(""Total Goals"" AS FLOAT) / NULLIF(""Total Apps"",0) ELSE NULL END AS total_goals_per_app
FROM table_1_10240125_2
ORDER BY ""Season""; /* Seasons with no FA Cup appearances (useful to mark post-war or unavailable cup involvement) */
SELECT
  ""Season"",
  ""League Apps"",
  ""League Goals"",
  ""FA Cup Apps"",
  ""FA Cup Goals"",
  ""Total Apps"",
  ""Total Goals""
FROM table_1_10240125_2
WHERE ""FA Cup Apps"" = 0
ORDER BY ""Season"";",reward,,
"For entries where Party is 'Republican' (and Party is not an empty string) and where the years component parsed from Age (years, days) exceeds 60, what is the Party and the aggregated values: average age in years computed as the average of the years plus the average of the days divided by 365.0 (Avg_Age_Years), the COUNT of rows, the MAX age in days computed as MAX((years * 365) + days) (Max_Age_Days), and the earliest Begin Date (MIN(Begin Date)), grouping by Party, ordering results by COUNT descending, limited to 5 rows?","
SELECT
 `Party`,
 (AVG(substr(`Age (years, days)`,1,instr(`Age (years, days)`,'years')-1)+0) + AVG(replace(substr(`Age (years, days)`,instr(`Age (years, days)`,', ')+2),'days','')+0)/365.0) `Avg_Age_Years`,
 COUNT(*) `Count`,
 MAX((substr(`Age (years, days)`,1,instr(`Age (years, days)`,'years')-1)+0)*365 + (replace(substr(`Age (years, days)`,instr(`Age (years, days)`,', ')+2),'days','')+0)) `Max_Age_Days`,
 MIN(`Begin Date`) `Earliest_Begin`
FROM `table_1_10284385_1`
INNER JOIN (SELECT 'Republican' `Republican`) AS p ON `table_1_10284385_1`.`Party` = p.`Republican`
WHERE `Party` <> '' AND (substr(`Age (years, days)`,1,instr(`Age (years, days)`,'years')-1)+0) > 60
GROUP BY `Party`
BY `Party`
ORDER BY `Count` * -1
LIMIT 5;
","SELECT
 col6,
 AVG((substr(col7,1,instr(col7,'years')-1)+0) + (replace(substr(col7,instr(col7,', ')+2),'days','')+0)/365.0) AS `Avg_Age_Years`,
 COUNT(*) AS `Count`,
 MAX((substr(col7,1,instr(col7,'years')-1)+0)*365 + (replace(substr(col7,instr(col7,', ')+2),'days','')+0)) AS `Max_Age_Days`,
 MIN(col0) AS `Earliest_Begin`
FROM `table_1_10284385_1`
WHERE col7 LIKE '%years%' AND (substr(col7,1,instr(col7,'years')-1)+0) > 60 AND col6 <> ''
GROUP BY col6
ORDER BY `Count` DESC
LIMIT 5;","[('republican', 97.36383561643835, 30, 37374, 'april 22, 1932'), ('democratic', 96.05413698630136, 25, 37844, 'april 1, 1953'), ('federalist', 92.00730593607307, 6, 35057, 'august 3, 1863'), ('pro-administration', 76.61534246575343, 5, 36067, 'december 10, 1796'), ('democratic-republican', 92.95561643835616, 5, 34537, 'april 8, 1857')]",table_1_10284385_1,"1) The SQL groups by Party (after restricting to Republicans) and computes aggregated statistics only for entries with years>60. 2) It parses Age (years, days) into numeric years and days to compute Avg_Age_Years and Max_Age_Days, counts rows, and finds the earliest Begin Date. 3) Drafted to explicitly ask for Party, the average age in years as AVG(years)+AVG(days)/365.0, COUNT(*), MAX(years*365+days), and MIN(Begin Date) for Party='Republican' with non-empty Party and years>60, grouped by Party, ordered by Count descending, limited to 5. 4) Confirmed inclusion of all calculations, filters, grouping, ordering, and the limit.",reserved,13,reward,,
"For all entries with Year > 0, provide: Year and Year enclosed in backticks as Year_back; Broadcast date enclosed in backticks as Broadcast date_back; BBC One total viewing enclosed in backticks as BBC One total viewing_back; BBC One Rank enclosed in backticks as BBC One Rank_back; BBC Two total viewing enclosed in backticks as BBC Two total viewing_back; BBC Two Rank enclosed in backticks as BBC Two Rank_back; One_minus_Two computed as BBC One total viewing minus BBC Two total viewing after removing commas from the BBC Two value; One_pct_of_combined computed as (BBC One total viewing / (BBC One total viewing + cleaned BBC Two total viewing)) * 100 rounded to two decimal places; and One_outperforms_Two indicating whether BBC One total viewing is greater than the cleaned BBC Two total viewing?","
SELECT
`Year`,
'`' || `Year` || '`' `Year_back`,
'`' || `Broadcast date` || '`' `Broadcast date_back`,
'`' || `BBC One total viewing` || '`' `BBC One total viewing_back`,
'`' || `BBC One Rank` || '`' `BBC One Rank_back`,
'`' || `BBC Two total viewing` || '`' `BBC Two total viewing_back`,
'`' || `BBC Two Rank` || '`' `BBC Two Rank_back`,
(`BBC One total viewing` - (REPLACE(`BBC Two total viewing`, ',', '') + 0)) `One_minus_Two`,
ROUND((`BBC One total viewing` / (`BBC One total viewing` + (REPLACE(`BBC Two total viewing`, ',', '') + 0))) * 100.0, 2) `One_pct_of_combined`,
(`BBC One total viewing` > (REPLACE(`BBC Two total viewing`, ',', '') + 0)) `One_outperforms_Two`
FROM `table_1_103084_4`
WHERE `Year` > 0;
","SELECT
col0,
col0 AS `Year_back`,
col1 AS `Broadcast date_back`,
col2 AS `BBC One total viewing_back`,
col3 AS `BBC One Rank_back`,
col4 AS `BBC Two total viewing_back`,
col5 AS `BBC Two Rank_back`,
((col2) - (REPLACE(col4, ',', '') + 0)) AS `One_minus_Two`,
ROUND((col2 / (col2 + (REPLACE(col4, ',', '') + 0))) * 100.0, 2) AS `One_pct_of_combined`,
(col2 > (REPLACE(col4, ',', '') + 0)) AS `One_outperforms_Two`
FROM `table_1_103084_4`
WHERE col0 > 0;","[(1999.0, 1999.0, '12 march', 6830000.0, '20th', '3,130,000', '13th', 3700000.0, 68.57, 1), (2001.0, 2001.0, '16 march', 8510000.0, '8th', 'n/a', 'n/a', 8510000.0, 100.0, 1), (2003.0, 2003.0, '14 march', 11740000.0, '4th', '6,010,000', '1st', 5730000.0, 66.14, 1), (2005.0, 2005.0, '11 march', 10940000.0, '4th', '4,720,000', '1st', 6220000.0, 69.86, 1), (2007.0, 2007.0, '16 march', 9730000.0, '2nd', '6,400,000', '1st', 3330000.0, 60.32, 1), (2009.0, 2009.0, '13 march', 9840000.0, '1st', '7,090,000', '1st', 2750000.0, 58.12, 1), (2011.0, 2011.0, '18 march', 10260000.0, '1st', '7,530,000', '1st', 2730000.0, 57.67, 1), (2013.0, 2013.0, '15 march', 10280000.0, '1st', '4,790,000', '1st', 5490000.0, 68.21, 1)]",table_1_103084_4,"Parse intent: output original Year and string-quoted/backtick versions of each column, compute numeric difference, compute percent share of BBC One of the two-channel total rounded to 2 decimals, and a boolean for whether One exceeds Two, for rows where Year > 0. Map schema: apply to Year, Broadcast date, BBC One total viewing, BBC One Rank, BBC Two total viewing, BBC Two Rank. Draft: craft a question asking for those exact fields and computations including comma removal and rounding. Validate: ensures inclusion of every column, the backtick-string fields, the subtraction, percentage with ROUND(,2), boolean, and Year filter.",reserved,3,reward,,
"Please produce a table of directors (ordered by most wins, then nominations) showing their wins, nominations, total submissions, won films, all films with year, first and last win year, their primary decade and that decade's totals and nomination/win rates.","
WITH base AS (
  SELECT
    *,
    CAST(SUBSTR(`Year (Ceremony)`,1,4) AS INTEGER) AS year_int,
    CAST(CAST(CAST(SUBSTR(`Year (Ceremony)`,1,4) AS INTEGER)/10 AS INTEGER) * 10 AS INTEGER) AS decade
  FROM `table_1_10321805_1`
),
director_stats AS (
  SELECT
    `Director`,
    SUM(CASE WHEN `Result` LIKE 'Won %' THEN 1 ELSE 0 END) AS `wins`,
    SUM(CASE WHEN `Result` LIKE '%Nominee%' THEN 1 ELSE 0 END) AS `nominations`,
    COUNT(*) AS `total_submissions`,
    COALESCE(GROUP_CONCAT(CASE WHEN `Result` = 'Won Academy Award' THEN `Film title used in nomination` END, ', '), '') AS `Won Films`,
    COALESCE(GROUP_CONCAT(`Film title used in nomination` || ' (' || year_int || ')', '; '), '') AS `All Films (year)`,
    MIN(CASE WHEN `Result` = 'Won Academy Award' THEN year_int END) AS `first_win_year`,
    MAX(CASE WHEN `Result` = 'Won Academy Award' THEN year_int END) AS `last_win_year`,
    (SELECT decade FROM base b2 WHERE b2.`Director` = base.`Director` GROUP BY decade ORDER BY COUNT(*) DESC LIMIT 1) AS `primary_decade`
  FROM base
  GROUP BY `Director`
),
decade_stats AS (
  SELECT
    decade,
    COUNT(*) AS `total_films`,
    SUM(CASE WHEN `Result` = 'Not Nominated' THEN 0 ELSE 1 END) AS `nominated_or_shortlisted_count`,
    SUM(CASE WHEN `Result` LIKE 'Won %' THEN 1 ELSE 0 END) AS `wins`,
    100.0 * SUM(CASE WHEN `Result` = 'Not Nominated' THEN 0 ELSE 1 END) / COUNT(*) AS `pct_nominated_or_shortlisted`,
    100.0 * SUM(CASE WHEN `Result` LIKE 'Won %' THEN 1 ELSE 0 END) / COUNT(*) AS `pct_won`
  FROM base
  GROUP BY decade
)
SELECT
  ds.`Director`,
  ds.`wins`,
  ds.`nominations`,
  ds.`total_submissions`,
  ds.`Won Films`,
  ds.`All Films (year)`,
  ds.`first_win_year`,
  ds.`last_win_year`,
  ds.`primary_decade`,
  dec.`total_films` AS `Decade Total Films`,
  dec.`nominated_or_shortlisted_count` AS `Decade Nominated/Shortlisted`,
  ROUND(dec.`pct_nominated_or_shortlisted`,2) AS `Decade % Nominated/Shortlisted`,
  dec.`wins` AS `Decade Wins`,
  ROUND(dec.`pct_won`,2) AS `Decade % Won`
FROM director_stats ds
LEFT JOIN decade_stats dec ON ds.`primary_decade` = dec.decade
ORDER BY ds.`wins` DESC, ds.`nominations` DESC, ds.`total_submissions` DESC;
","SELECT
  t1.col3,
  SUM(CASE WHEN t1.col4 LIKE 'Won %' THEN 1 ELSE 0 END) AS `wins`,
  SUM(CASE WHEN t1.col4 LIKE '%Nominee%' THEN 1 ELSE 0 END) AS `nominations`,
  COUNT(*) AS `total_submissions`,
  COALESCE(GROUP_CONCAT(CASE WHEN t1.col4 LIKE 'Won %' THEN t1.col1 END, ', '), '') AS `Won Films`,
  COALESCE(GROUP_CONCAT(t1.col1 || ' (' || CAST(SUBSTR(t1.col0,1,4) AS INTEGER) || ')', '; '), '') AS `All Films (year)`,
  MIN(CASE WHEN t1.col4 LIKE 'Won %' THEN CAST(SUBSTR(t1.col0,1,4) AS INTEGER) END) AS `first_win_year`,
  MAX(CASE WHEN t1.col4 LIKE 'Won %' THEN CAST(SUBSTR(t1.col0,1,4) AS INTEGER) END) AS `last_win_year`,
  (SELECT (CAST(CAST(SUBSTR(t2.col0,1,4) AS INTEGER)/10 AS INTEGER) * 10)
   FROM `table_1_10321805_1` t2
   WHERE t2.col3 = t1.col3
   GROUP BY (CAST(CAST(SUBSTR(t2.col0,1,4) AS INTEGER)/10 AS INTEGER) * 10)
   ORDER BY COUNT(*) DESC
   LIMIT 1) AS `primary_decade`
FROM `table_1_10321805_1` t1
GROUP BY t1.col3
ORDER BY `wins` DESC, `nominations` DESC, `total_submissions` DESC;","[('vittorio de sica category:articles with hcards', 4, 1, 5, 'shoeshine, the bicycle thief, yesterday, today and tomorrow, the garden of the finzi-continis', 'shoeshine (1947); the bicycle thief (1949); yesterday, today and tomorrow (1964); marriage italian-style (1965); the garden of the finzi-continis (1971)', 1947, 1971, 1960), ('federico fellini category:articles with hcards', 4, 0, 7, 'la strada, nights of cabiria, 8½, amarcord', 'la strada (1956); nights of cabiria (1957); 8½ (1963); satyricon (1969); roma (1972); amarcord (1974); and the ship sails on (1983)', 1956, 1974, 1970), ('giuseppe tornatore category:articles with hcards', 1, 1, 4, 'cinema paradiso', 'cinema paradiso (1989); the star maker (1995); the unknown (2007); baarìa (2009)', 1989, 1989, 2000), ('gabriele salvatores category:articles with hcards', 1, 0, 2, 'mediterraneo', ""mediterraneo (1991); i'm not scared (2003)"", 1991, 1991, 2000), ('roberto benigni category:articles with hcards', 1, 0, 2, 'life is beautiful', 'life is beautiful (1998); pinocchio (2002)', 1998, 1998, 2000), ('rené clément category:articles with hcards', 1, 0, 1, 'the walls of malapaga', 'the walls of malapaga (1950)', 1950, 1950, 1950), ('mario monicelli category:articles with hcards', 0, 3, 3, '', 'big deal on madonna street (1958); the great war (1959); the girl with the pistol (1968)', None, None, 1950), ('ettore scola category:articles with hcards', 0, 2, 3, '', 'a special day (1977); macaroni (1985); the family (1987)', None, None, 1980), ('gillo pontecorvo category:articles with hcards', 0, 2, 2, '', 'kapò (1960); the battle of algiers (1966)', None, None, 1960), ('gianni amelio category:articles with hcards', 0, 1, 4, '', 'open doors (1990); the stolen children (1992); lamerica (1994); the keys to the house (2004)', None, None, 1990), ('marco bellocchio category:articles with hcards', 0, 1, 2, '', 'china is near (1967); a leap in the dark (1980)', None, None, 1980), ('nanni loy category:articles with hcards', 0, 1, 2, '', ""the four days of naples (1962); where's picone? (1984)"", None, None, 1980), ('cristina comencini category:articles with hcards', 0, 1, 1, '', ""don't tell (2005)"", None, None, 2000), ('dino risi category:articles with hcards', 0, 1, 1, '', 'scent of a woman (1975)', None, None, 1970), ('francesco rosi category:articles with hcards', 0, 1, 1, '', 'three brothers (1981)', None, None, 1980), ('franco brusati category:articles with hcards', 0, 1, 1, '', 'to forget venice (1979)', None, None, 1970), ('lina wertmüller category:articles with hcards', 0, 1, 1, '', 'seven beauties (1976)', None, None, 1970), ('emanuele crialese category:articles with hcards', 0, 0, 2, '', 'the golden door (2006); terraferma (2011)', None, None, 2010), ('ermanno olmi category:articles with hcards', 0, 0, 1, '', 'the legend of the holy drinker (1988)', None, None, 1980), ('francesca archibugi category:articles with hcards', 0, 0, 1, '', 'the great pumpkin (1993)', None, None, 1990), ('giuseppe piccioni category:articles with hcards', 0, 0, 1, '', 'not of this world (1999)', None, None, 1990), ('matteo garrone category:articles with hcards', 0, 0, 1, '', 'gomorrah (2008)', None, None, 2000), ('nanni moretti category:articles with hcards', 0, 0, 1, '', ""the son's room (2001)"", None, None, 2000), ('paolo and vittorio taviani', 0, 0, 1, '', 'caesar must die (2012)', None, None, 2010), ('paolo virzì category:articles with hcards', 0, 0, 1, '', 'the first beautiful thing (2010)', None, None, 2010), ('pupi avati category:articles with hcards', 0, 0, 1, '', 'the best man (1997)', None, None, 1990), ('wilma labate category:articles with hcards', 0, 0, 1, '', 'my generation (1996)', None, None, 1990)]",table_1_10321805_1,"For a lecture I might want a compact dossier per director combining personal and contextual metrics without using SQL jargon. The SQL produces director-level aggregates (wins, nominations, lists of films and win years) and appends the most-representative decade's statistics. The relevant columns are director, film title, year and result to compile those metrics. Draft question: ask for a single table per director with those director metrics plus their primary decade's statistics, ordered by wins and nominations. This matches the final SELECT and ORDER BY of the query.",persona,"Film studies researcher at a university focusing on Italian cinema history and awards; uses the database to quantify how Italian films and directors have fared at the Academy Awards over time. Goals: Measure which Italian directors have the most Academy Award wins and nominations in this dataset. Identify which Italian films or years resulted in Academy Award wins versus other outcomes. Analyze trends in nomination/win rates across decades to support a paper or lecture on changing international reception of Italian cinema. Example Queries: /* Count wins and nominations by director */
SELECT ""Director"",
       SUM(CASE WHEN ""Result"" LIKE 'Won %' THEN 1 ELSE 0 END) AS wins,
       SUM(CASE WHEN ""Result"" LIKE '%Nominee%' THEN 1 ELSE 0 END) AS nominations,
       COUNT(*) AS total_submissions
FROM table_1_10321805_1
GROUP BY ""Director""
ORDER BY wins DESC, nominations DESC; /* List all films that won an Academy Award (explicit Academy wins) with ceremony year and director */
SELECT ""Year (Ceremony)"", ""Film title used in nomination"", ""Original title"", ""Director""
FROM table_1_10321805_1
WHERE ""Result"" = 'Won Academy Award'
ORDER BY CAST(SUBSTR(""Year (Ceremony)"",1,4) AS INTEGER); /* Compute nomination/win rates by decade (extracts year from leading 4 chars) */
SELECT
  FLOOR(CAST(SUBSTR(""Year (Ceremony)"",1,4) AS INTEGER) / 10.0) * 10 AS decade,
  COUNT(*) AS total_films,
  SUM(CASE WHEN ""Result"" = 'Not Nominated' THEN 0 ELSE 1 END) AS nominated_or_shortlisted_count,
  SUM(CASE WHEN ""Result"" LIKE 'Won %' THEN 1 ELSE 0 END) AS wins,
  100.0 * SUM(CASE WHEN ""Result"" = 'Not Nominated' THEN 0 ELSE 1 END) / COUNT(*) AS pct_nominated_or_shortlisted,
  100.0 * SUM(CASE WHEN ""Result"" LIKE 'Won %' THEN 1 ELSE 0 END) / COUNT(*) AS pct_won
FROM table_1_10321805_1
GROUP BY decade
ORDER BY decade;",reward,,
"What are the three Current country of location entries with the lowest Total estimated deaths, where Total estimated deaths is the SUM by Current country of location of Estimated deaths and Estimated deaths values are converted to numbers by removing commas or, if containing a '-', by averaging the two comma-free endpoint numbers?","
SELECT `Current country of location`, SUM(
  (instr(`Estimated deaths`,'-')>0) *
    ((replace(substr(`Estimated deaths`,1,instr(`Estimated deaths`,'-')-1),',','')+0
      + replace(substr(`Estimated deaths`,instr(`Estimated deaths`,'-')+1),',','')+0)/2.0)
  + (instr(`Estimated deaths`,'-')=0) * (replace(`Estimated deaths`,',','')+0)
) `Total estimated deaths`
FROM `table_1_10335_1`
GROUP BY `Current country of location`
ORDER BY `Total estimated deaths`
LIMIT 3;
","
SELECT col4, SUM(
  (instr(col1,'-')>0) *
    ((replace(substr(col1,1,instr(col1,'-')-1),',','')+0
      + replace(substr(col1,instr(col1,'-')+1),',','')+0)/2.0)
  + (instr(col1,'-')=0) * (replace(col1,',','')+0)
) `Total estimated deaths`
FROM `table_1_10335_1`
GROUP BY col4
ORDER BY `Total estimated deaths`
LIMIT 3;
","[('serbia', 35000.0), ('belarus', 200000.0), ('poland', 3110000.0)]",table_1_10335_1,"1) Parse the SQL intent: sum Estimated deaths per country using averaging for ranges, then order sums ascending and return three rows. 2) Map schema semantics: interpret Estimated deaths (commas removed; ranges averaged) to compute Total estimated deaths grouped by Current country of location. 3) Draft the question: ask which three Current country of location entries have the lowest summed Total estimated deaths with the specified parsing rules. 4) Validate: the question explicitly references Current country of location, Total estimated deaths, the conversion of Estimated deaths, summation, ordering, and the top-3 limit.",reserved,8,reward,,
"Grouping by Opponent and excluding Opponent = 'at Green Bay Packers', for only the rows where Result = 'Win', what are Opponent, SUM('Vikings points') AS Total_Vikings_Points, COUNT(*) AS Games, AVG('Attendance') AS Avg_Attendance, and SUM(Result = 'Win') AS Wins, with the results ordered by the SUM('Vikings points') in ascending order?","
SELECT `Opponent`, SUM(`Vikings points`) `Total_Vikings_Points`, COUNT(*) `Games`, AVG(`Attendance`) `Avg_Attendance`, SUM(`Result` = `Win`) `Wins`
FROM `table_1_10361453_2`, (VALUES ('Win','at Green Bay Packers')) AS `const`(`Win`,`at Green Bay Packers`)
WHERE `Result` = `Win` AND `Opponent` != `at Green Bay Packers`
GROUP BY `Opponent`
ORDER BY SUM(`Vikings points`);
","SELECT col2, SUM(col4) `Total_Vikings_Points`, COUNT(*) `Games`, AVG(col7) `Avg_Attendance`, SUM(col3 = 'Win') `Wins`
FROM `table_1_10361453_2`
WHERE col2 != 'at Green Bay Packers'
GROUP BY col2
ORDER BY SUM(col4);","[('at detroit lions', 7.0, 1, 49703.0, 0), ('green bay packers', 7.0, 1, 47924.0, 0), ('chicago bears', 11.0, 1, 46217.0, 0), ('new england patriots', 14.0, 1, 48177.0, 0), ('detroit lions', 16.0, 1, 47807.0, 0), ('at chicago bears', 17.0, 1, 33343.0, 0), ('at los angeles rams', 17.0, 1, 90266.0, 0), ('at dallas cowboys', 23.0, 1, 57847.0, 0), ('atlanta falcons', 23.0, 1, 47105.0, 0), ('at st. louis cardinals', 28.0, 1, 50183.0, 0), ('new orleans saints', 29.0, 1, 44202.0, 0), ('at green bay packers', 32.0, 1, 56267.0, 0), ('houston oilers', 51.0, 1, 48006.0, 0)]",table_1_10361453_2,"1) Parse intent: list per-opponent totals and averages for games that the Vikings won, but do not include the opponent 'at Green Bay Packers', and sort by total Vikings points. 2) Map schema: extract Opponent, sum Vikings points, count games, average Attendance, and count wins via SUM(Result = 'Win'). 3) Draft: ask for those exact aggregates with grouping and ordering and the specified filters. 4) Validate: ensure inclusion of all columns and calculations, the Result = 'Win' condition, exclusion of 'at Green Bay Packers', GROUP BY Opponent, and ORDER BY SUM('Vikings points').",reserved,9,reward,,
"Pull a combined report that shows college pipelines, trade destinations, and position trends with counts, earliest round and choice, and details, sorted by insight type and most common groups first.","
(SELECT
  'College pipeline' AS `insight_type`,
  `College` AS `group_key`,
  COUNT(*) AS `picks_count`,
  MIN(CAST(`Round` AS INTEGER)) AS `earliest_round`,
  MIN(CAST(`Choice` AS INTEGER)) AS `earliest_choice`,
  GROUP_CONCAT(`Player name`, '; ') AS `details`
FROM `table_1_10361625_1`
WHERE `Player name` NOT LIKE 'Traded to %'
GROUP BY `College`)
UNION ALL
(SELECT
  'Trade destinations' AS `insight_type`,
  substr(`Player name`, 11) AS `group_key`,
  COUNT(*) AS `picks_count`,
  MIN(CAST(`Round` AS INTEGER)) AS `earliest_round`,
  MIN(CAST(`Choice` AS INTEGER)) AS `earliest_choice`,
  GROUP_CONCAT('Round '||`Round`||' Choice '||`Choice`||' Overall '||`Overall`, '; ') AS `details`
FROM `table_1_10361625_1`
WHERE `Player name` LIKE 'Traded to %'
GROUP BY substr(`Player name`, 11))
UNION ALL
(SELECT
  'Position trends' AS `insight_type`,
  `Position` AS `group_key`,
  COUNT(*) AS `picks_count`,
  MIN(CAST(`Round` AS INTEGER)) AS `earliest_round`,
  MIN(CAST(`Choice` AS INTEGER)) AS `earliest_choice`,
  GROUP_CONCAT(`Player name`, '; ') AS `details`
FROM `table_1_10361625_1`
WHERE `Player name` NOT LIKE 'Traded to %'
GROUP BY `Position`)
ORDER BY `insight_type`, `picks_count` DESC;
","SELECT 'College pipeline' AS `insight_type`,
col5 AS `group_key`,
COUNT(*) AS `picks_count`,
MIN(CAST(col0 AS INTEGER)) AS `earliest_round`,
MIN(CAST(col1 AS INTEGER)) AS `earliest_choice`,
GROUP_CONCAT(col3, '; ') AS `details`
FROM `table_1_10361625_1`
WHERE col3 NOT LIKE 'Traded to %'
GROUP BY col5
UNION ALL
SELECT 'Trade destinations' AS `insight_type`,
substr(col3, 11) AS `group_key`,
COUNT(*) AS `picks_count`,
MIN(CAST(col0 AS INTEGER)) AS `earliest_round`,
MIN(CAST(col1 AS INTEGER)) AS `earliest_choice`,
GROUP_CONCAT('Round '||col0||' Choice '||col1||' Overall '||col2, '; ') AS `details`
FROM `table_1_10361625_1`
WHERE col3 LIKE 'Traded to %'
GROUP BY substr(col3, 11)
UNION ALL
SELECT 'Position trends' AS `insight_type`,
col4 AS `group_key`,
COUNT(*) AS `picks_count`,
MIN(CAST(col0 AS INTEGER)) AS `earliest_round`,
MIN(CAST(col1 AS INTEGER)) AS `earliest_choice`,
GROUP_CONCAT(col3, '; ') AS `details`
FROM `table_1_10361625_1`
WHERE col3 NOT LIKE 'Traded to %'
GROUP BY col4
ORDER BY `insight_type`, `picks_count` DESC;","[('College pipeline', 'illinois', 2, 9, 27, 'scott studwell; dan beaver'), ('College pipeline', 'arizona', 1, 11, 27, 'keith hartwig'), ('College pipeline', 'northern illinois', 1, 5, 26, 'ken moore'), ('College pipeline', 'rice', 1, 1, 27, 'tommy kramer'), ('College pipeline', 'san diego state', 1, 3, 27, 'tom hannon'), ('College pipeline', 'texas a&m', 1, 2, 27, 'dennis swilley'), ('College pipeline', 'usc', 1, 8, 27, 'clint strozier'), ('Position trends', 'linebacker', 2, 3, 27, 'tom hannon; scott studwell'), ('Position trends', 'defensive back', 1, 8, 27, 'clint strozier'), ('Position trends', 'guard', 1, 2, 27, 'dennis swilley'), ('Position trends', 'kicker', 1, 10, 27, 'dan beaver'), ('Position trends', 'quarterback', 1, 1, 27, 'tommy kramer'), ('Position trends', 'tight end', 1, 5, 26, 'ken moore'), ('Position trends', 'wide receiver', 1, 11, 27, 'keith hartwig'), ('Trade destinations', 'the cincinnati bengals', 1, 7, 27, 'Round 7.0 Choice 27.0 Overall 194.0'), ('Trade destinations', 'the new england patriots', 1, 6, 27, 'Round 6.0 Choice 27.0 Overall 166.0'), ('Trade destinations', 'the seattle seahawks', 1, 4, 27, 'Round 4.0 Choice 27.0 Overall 111.0')]",table_1_10361625_1,"Persona: I'd often want a combined report covering pipelines, trade destinations, and position trends in one output for meetings. SQL intent: The full query unions three insight sets (college pipelines, trade destinations, position trends) and orders by insight type and picks_count. Schema mapping: It returns an insight_type label, group key, counts, earliest round/choice, and details for each insight. Draft question: Pull a combined report that shows college pipelines, trade destinations, and position trends with counts, earliest round and choice, and details, sorted by insight type and most common groups first. Validate: This reflects the UNION ALL of the three grouped queries and the ORDER BY in the SQL.",persona,"Pro football draft analyst working in an NFL team's scouting department who uses historical draft records to evaluate past decisions, college pipelines, and trade outcomes to inform future draft strategy. They query this database to identify where talent came from, how often picks were traded, and positional draft patterns. Goals: Identify which colleges produced the most drafted players for this franchise (excluding picks that were traded away). Audit historical trade activity to see which rounds and overall picks were most often traded and to which teams. Analyze positional drafting trends and find the earliest (lowest overall) selections by position to assess historical prioritization. Example Queries: /* 1) Top colleges by number of drafted players (exclude traded picks) */
SELECT ""College"", COUNT(*) AS picks
FROM table_1_10361625_1
WHERE ""Player name"" NOT LIKE 'Traded to %'
GROUP BY ""College""
ORDER BY picks DESC; /* 2) List all picks that were traded and the destination (as recorded in the Player name field) */
SELECT ""Round"", ""Choice"", ""Overall"", ""Player name""
FROM table_1_10361625_1
WHERE ""Player name"" LIKE 'Traded to %'
ORDER BY ""Round""; /* 3) Position breakdown with count and earliest overall pick for each position (ignore traded records) */
SELECT ""Position"", COUNT(*) AS picks, MIN(CAST(""Overall"" AS INTEGER)) AS earliest_overall
FROM table_1_10361625_1
WHERE ""Player name"" NOT LIKE 'Traded to %' AND ""Overall"" NOT LIKE 'Traded%'
GROUP BY ""Position""
ORDER BY picks DESC;",reward,,
"List the Opponent, Date, Attendance, and Attendance surplus over avg (defined as Attendance - 16118.6666666667) for every game whose Attendance is greater than 16118.6666666667.","
SELECT `Opponent`, `Date`, `Attendance`, (`Attendance` - 16118.6666666667) `Attendance surplus over avg`
FROM `table_1_10392906_2`
WHERE `Attendance` > 16118.6666666667;
","
SELECT col3, col1, col7, (col7 - 16118.6666666667) `Attendance surplus over avg`
FROM `table_1_10392906_2`
WHERE col7 > 16118.6666666667;
","[('at frankfurt galaxy', 'saturday, april 14', 38125.0, 22006.3333333333), ('at rhein fire', 'sunday, june 3', 20355.0, 4236.333333333299)]",table_1_10392906_2,"Parse SQL intent: select Opponent, Date, Attendance and a derived column (Attendance - 16118.6666666667) labelled Attendance surplus over avg, limited to Attendance > 16118.6666666667. Map schema semantics: Opponent and Date identify the game, Attendance provides the value to compare against the average 16118.6666666667. Draft the question: ask for Opponent, Date, Attendance and the surplus computation for games exceeding the average. Validate: ensure all columns, the subtraction calculation and the attendance filter are present.",reserved,3,reward,,
"For actors whose name in the 'Australia & New Zealand (Sydney - first run, Melbourne, Auckland)' column also appears in the 'London' column, list the actor name, a concatenation of all Character values from the ANZ rows each suffixed with ' (ANZ)' as ANZ Roles, a concatenation of all Character values from the London rows each suffixed with ' (London)' as London Roles, and the number of matching rows as Matches; group by the ANZ actor, exclude zero-count groups, order by Matches descending, and return the top 10 results?","
SELECT t1.`Australia & New Zealand (Sydney - first run, Melbourne, Auckland)` `Actor`,
       GROUP_CONCAT(t1.`Character` || ' (ANZ)') `ANZ Roles`,
       GROUP_CONCAT(t2.`Character` || ' (London)') `London Roles`,
       COUNT(*) `Matches`
FROM `table_1_10402018_1` t1 CROSS JOIN `table_1_10402018_1` t2
WHERE t1.`Australia & New Zealand (Sydney - first run, Melbourne, Auckland)` = t2.`London`
GROUP BY t1.`Australia & New Zealand (Sydney - first run, Melbourne, Auckland)`
HAVING COUNT(*) IS NOT 0
ORDER BY COUNT(*) DESC
LIMIT 10;
","
SELECT t1.col1 `Actor`,
       GROUP_CONCAT(t1.col0 || ' (ANZ)') `ANZ Roles`,
       GROUP_CONCAT(t2.col0 || ' (London)') `London Roles`,
       COUNT(*) `Matches`
FROM `table_1_10402018_1` t1 CROSS JOIN `table_1_10402018_1` t2
WHERE t1.col1 = t2.col2
GROUP BY t1.col1
HAVING COUNT(*) IS NOT 0
ORDER BY COUNT(*) DESC
LIMIT 10;
","[('tony sheldon', 'bernadette (ANZ)', 'bernadette (London)', 1)]",table_1_10402018_1,"1) The SQL self-joins the table matching the Australia & New Zealand actor name to the London actor name, 2) map t1.`Australia & New Zealand (Sydney - first run, Melbourne, Auckland)` to the actor and `Character` to roles in each region, 3) draft a question asking for the actor, concatenated ANZ characters suffixed with ' (ANZ)', concatenated London characters suffixed with ' (London)', and the count of matches, grouped by the ANZ actor, excluding zero counts, ordered by count desc and limited to 10, 4) validate that all selected columns, concatenations, count, grouping, having, ordering, and limit are included.",reserved,13,reward,,
"Across all episodes, what is the Total Episodes (COUNT(No.)), the Avg Title Length rounded to two decimals (ROUND(AVG(LENGTH(Title)),2)), the Avg Villains Length rounded to two decimals (ROUND(AVG(LENGTH(Villains)),2)), how many episodes have Villains longer than Title (SUM(LENGTH(Villains) > LENGTH(Title))), and what percent is that of the total rounded to two decimals (ROUND(100.0 * SUM(LENGTH(Villains) > LENGTH(Title)) / COUNT(No.),2))?","
SELECT COUNT(`No.`) `Total Episodes`, ROUND(AVG(LENGTH(`Title`)),2) `Avg Title Length`, ROUND(AVG(LENGTH(`Villains`)),2) `Avg Villains Length`, SUM(LENGTH(`Villains`) > LENGTH(`Title`)) `Villains Longer Count`, ROUND(100.0 * SUM(LENGTH(`Villains`) > LENGTH(`Title`)) / COUNT(`No.`),2) `Pct Villains Longer` FROM `table_1_10470082_4` WHERE 1 LIMIT 1;
","
SELECT COUNT(col0) `Total Episodes`, ROUND(AVG(LENGTH(col2)),2) `Avg Title Length`, ROUND(AVG(LENGTH(col7)),2) `Avg Villains Length`, SUM(LENGTH(col7) > LENGTH(col2)) `Villains Longer Count`, ROUND(100.0 * SUM(LENGTH(col7) > LENGTH(col2)) / COUNT(col0),2) `Pct Villains Longer` FROM `table_1_10470082_4` WHERE 1 LIMIT 1;
","[(11, 29.82, 15.18, 0, 0.0)]",table_1_10470082_4,"1) The query returns summary statistics across all rows: count, two averaged string lengths rounded to 2 decimals, a conditional sum, and that conditional sum expressed as a percentage of the count rounded to 2 decimals. 2) Use 'No.' for COUNT, LENGTH('Title') and LENGTH('Villains') inside AVG and SUM, and rounding to two decimal places. 3) Draft a consolidated question requesting Total Episodes, Avg Title Length (rounded to 2 decimals), Avg Villains Length (rounded to 2 decimals), Villains Longer Count (number of rows where LENGTH(Villains) > LENGTH(Title)), and Pct Villains Longer (100 * that count / total rounded to 2 decimals). 4) Check that each function and rounding appears in the question exactly as in the SQL.",reserved,4,reward,,
"Which Storyteller(s) among rows with No. >= 53 have more than one episode, and for each such Storyteller what are the Total Episodes (COUNT(*)), the Episodes Titles joined with '; ' (GROUP_CONCAT(Title, '; ')), the Villain Roster joined with '; ' (GROUP_CONCAT(Villains, '; ')), the earliest US air date (MIN(US air date) presented as ""The Tale of the Dead Man's Float"") and the latest US air date (MAX(US air date) presented as ""The Tale of the Jagged Sign""), ordered by Total Episodes?","
SELECT `Storyteller`, COUNT(*) `Total Episodes`, GROUP_CONCAT(`Title`, '; ') `Episodes Titles`, GROUP_CONCAT(`Villains`, '; ') `Villain Roster`, MIN(`US air date`) `'""The Tale of the Dead Man\'s Float""'`, MAX(`US air date`) `'""The Tale of the Jagged Sign""'` FROM `table_1_10470082_6` WHERE `No.` >= 53 GROUP BY `Storyteller` HAVING COUNT(*) > 1 ORDER BY `Total Episodes`;
","
SELECT col6, COUNT(*) `Total Episodes`, GROUP_CONCAT(col2, '; ') `Episodes Titles`, GROUP_CONCAT(col7, '; ') `Villain Roster`, MIN(col5) `'""The Tale of the Dead Man\'s Float""'`, MAX(col5) `'""The Tale of the Jagged Sign""'` FROM `table_1_10470082_6` WHERE col0 >= 53 GROUP BY col6 HAVING COUNT(*) > 1 ORDER BY `Total Episodes`;
","[('betty ann', 2, '""the tale of the mystical mirror""; ""the tale of the chameleons""', 'ms. valenti; the chameleon', 'november 11, 1995', 'november 18, 1995'), ('sam', 2, '""the tale of c7""; ""the tale of the night shift""', 'none; the walking dead and the vampire', 'december 9, 1995', 'february 3, 1996'), ('stig', 2, '""the tale of the dead man\'s float""; ""the tale of station 109.1""', 'the pool zombie; none', 'november 4, 1995', 'october 7, 1995'), ('tucker', 2, '""the tale of prisoner\'s past""; ""the tale of the manaha""', 'none; the shaman', 'december 2, 1995', 'december 30, 1995'), ('kiki', 3, '""the tale of the jagged sign""; ""the tale of the unexpected visitor""; ""the tale of the vacant lot""', 'none; the alien kid and its mother; marie', 'january 13, 1996', 'october 14, 1995')]",table_1_10470082_6,"Parse SQL intent: return grouped episode aggregates per Storyteller for rows numbered 53 and up, only include storytellers with more than one episode, and order by episode count. Map schema semantics: use 'No.' filter, group by Storyteller, compute COUNT(*), GROUP_CONCAT of Title and Villains with '; ' separator, and MIN/MAX of 'US air date' with the given aliases. Draft the question: request exactly those labeled aggregates and ordering. Validate: ensure WHERE No. >= 53, HAVING COUNT(*) > 1, GROUP_CONCAT separators, and the alias labels are included.",reserved,7,reward,,
"For each Storyteller (only considering rows with LENGTH(Storyteller) > 0 AND LENGTH(Villains) > 0), can you provide Storyteller, the COUNT(No.) as EpisodeCount, the GROUP_CONCAT(DISTINCT Villains) as VillainList, the MIN(US air date) as FirstAir and the MAX(US air date) as LastAir, but only include storytellers with COUNT(No.) > 0 and show up to 10 results?","
SELECT `Storyteller` AS `Storyteller`, COUNT(`No.`) `EpisodeCount`, GROUP_CONCAT(DISTINCT `Villains`) `VillainList`, MIN(`US air date`) `FirstAir`, MAX(`US air date`) `LastAir`
FROM `table_1_10470082_8`
WHERE LENGTH(`Storyteller`) > 0 AND LENGTH(`Villains`) > 0
GROUP BY `Storyteller`
HAVING COUNT(`No.`) > 0
LIMIT 10;
","
SELECT col6 AS col6, COUNT(col0) `EpisodeCount`, GROUP_CONCAT(DISTINCT col7) `VillainList`, MIN(col5) `FirstAir`, MAX(col5) `LastAir`
FROM `table_1_10470082_8`
WHERE LENGTH(col6) > 0 AND LENGTH(col7) > 0
GROUP BY col6
HAVING COUNT(col0) > 0
LIMIT 10;
","[('andy', 2, 'jasper davis,none', 'may 14, 2000', 'may 21, 2000'), (""gary and tucker's grandfather, gene"", 1, 'the evil spirit', 'april 2, 2000', 'april 2, 2000'), ('megan', 2, 'the unborn alien babies,the maiden statue', 'april 16, 2000', 'april 9, 2000'), ('n/a', 2, 'the evil spirit', 'april 2, 2000', 'april 2, 2000'), ('quinn', 2, 'none,reanimated zombie', 'april 23, 2000', 'april 30, 2000'), ('tucker', 2, 'bell the genie,drake', 'may 28, 2000', 'may 7, 2000'), ('vange', 1, 'madame visage', 'june 4, 2000', 'june 4, 2000')]",table_1_10470082_8,"1) Parse the SQL intent: summarize episodes by storyteller with count, distinct villains list, first and last air dates, filtering out empty storyteller/villain rows and limiting output. 2) Map schema semantics: COUNT(No.) -> EpisodeCount, GROUP_CONCAT(DISTINCT Villains) -> VillainList, MIN(US air date) -> FirstAir, MAX(US air date) -> LastAir. 3) Draft the question: ask for those aggregated columns per storyteller with the non-empty and COUNT>0 constraints and LIMIT 10. 4) Validate: the question includes all calculations, the non-empty WHERE conditions, the HAVING COUNT > 0, and the LIMIT 10.",reserved,10,reward,,
"Show Winning driver, Wins (COUNT(Rd)), Races (GROUP_CONCAT(Name)) and Teams (GROUP_CONCAT(Winning team)) for rows where Fastest Lap = Fastest Lap, grouped by Winning driver and limited to 5?","
SELECT `Winning driver`, COUNT(`Rd`) `Wins`, GROUP_CONCAT(`Name`) `Races`, GROUP_CONCAT(`Winning team`) `Teams`
FROM `table_1_10527215_3`
WHERE `Fastest Lap` = `Fastest Lap`
GROUP BY `Winning driver`
LIMIT 5;
","
SELECT col4, COUNT(col0) `Wins`, GROUP_CONCAT(col1) `Races`, GROUP_CONCAT(col5) `Teams`
FROM `table_1_10527215_3`
WHERE col3 = col3
GROUP BY col4
LIMIT 5;
","[('bobby unser', 4, 'gould-rex mays 150,true value 500,kent oil 150,california 500', 'penske racing,penske racing,penske racing,penske racing'), ('johnny rutherford', 5, 'datsun twin 200,indianapolis 500,red roof inns 150,norton 200,tony bettenhausen 200', 'chaparral,chaparral,chaparral,chaparral,chaparral'), ('mario andretti', 1, 'gould grand prix 150', 'penske racing'), ('rick mears', 1, 'i copa mexico 150', 'penske racing')]",table_1_10527215_3,"1) The SQL intent is to group by Winning driver and produce COUNT(Rd) plus GROUP_CONCAT(Name) and GROUP_CONCAT(Winning team), with the WHERE clause Fastest Lap = Fastest Lap and LIMIT 5. 2) Map the query's selected and aggregated columns to the natural language request using the table's column names. 3) Create a question that exactly requests Winning driver, Wins = COUNT(Rd), Races = GROUP_CONCAT(Name), Teams = GROUP_CONCAT(Winning team) with the Fastest Lap = Fastest Lap condition, grouped by Winning driver and restricted to 5 results. 4) Verify that no extraneous details are introduced.",reserved,6,reward,,
"I’m scouting targets for contact-mic strikes—show me 4-4-0 and 4-6-0 locos that are on static display (parks/museums), with serial number, build date and inferred build year/era (pre-1890 vs post-1890), owning railroad and exact disposition/location, ordered so accessible pre-1890 examples come first and then by oldest build year.","
SELECT 
  `Serial number`,
  `Wheel arrangement ( Whyte notation )`,
  `Build date`,
  CAST(substr(`Build date`, -4) AS INTEGER) AS `Build Year`,
  CASE WHEN CAST(substr(`Build date`, -4) AS INTEGER) < 1890 THEN 'pre-1890' ELSE 'post-1890' END AS `Era`,
  `Operational owner(s)`,
  `Disposition`,
  CASE WHEN (`Disposition` LIKE '%static%' OR `Disposition` LIKE '%display%' OR `Disposition` LIKE '%Museum%' OR `Disposition` LIKE '%Park%') THEN 1 ELSE 0 END AS `Accessible`,
  (CASE WHEN CAST(substr(`Build date`, -4) AS INTEGER) < 1890 THEN 2 ELSE 1 END
   + CASE WHEN (`Disposition` LIKE '%Park%' OR `Disposition` LIKE '%Museum%' OR `Disposition` LIKE '%static%' OR `Disposition` LIKE '%display%') THEN 1 ELSE 0 END) AS `Priority Score`
FROM `table_1_1057316_1`
WHERE `Wheel arrangement ( Whyte notation )` IN ('4-4-0','4-6-0')
  AND (`Disposition` LIKE '%static%' OR `Disposition` LIKE '%display%' OR `Disposition` LIKE '%Museum%' OR `Disposition` LIKE '%Park%')
ORDER BY `Priority Score` DESC, `Build Year` ASC;
","
SELECT 
  col0,
  col1,
  col2,
  CAST(substr(col2, -4) AS INTEGER) AS `Build Year`,
  CASE WHEN CAST(substr(col2, -4) AS INTEGER) < 1890 THEN 'pre-1890' ELSE 'post-1890' END AS `Era`,
  col3,
  col4,
  CASE WHEN (col4 LIKE '%static%' OR col4 LIKE '%display%' OR col4 LIKE '%Museum%' OR col4 LIKE '%Park%') THEN 1 ELSE 0 END AS `Accessible`,
  (CASE WHEN CAST(substr(col2, -4) AS INTEGER) < 1890 THEN 2 ELSE 1 END
   + CASE WHEN (col4 LIKE '%Park%' OR col4 LIKE '%Museum%' OR col4 LIKE '%static%' OR col4 LIKE '%display%') THEN 1 ELSE 0 END) AS `Priority Score`
FROM `table_1_1057316_1`
WHERE col1 IN ('4-4-0','4-6-0')
  AND (col4 LIKE '%static%' OR col4 LIKE '%display%' OR col4 LIKE '%Museum%' OR col4 LIKE '%Park%')
ORDER BY `Priority Score` DESC, `Build Year` ASC;
","[('unknown', '4-4-0', 'october 1856', 1856, 'pre-1890', 'western and atlantic railroad #49 texas', 'static display in grant park , atlanta, georgia', 1, 3), ('1861', '4-4-0', 'february 1888', 1888, 'pre-1890', 'dardanelle and russelville #8', 'nevada state railroad museum , carson city, nevada', 1, 3), ('2053', '4-6-0', 'october, 1890', 1890, 'post-1890', 'union pacific railroad #1242', ""lion's park, cheyenne, wyoming"", 1, 2), ('2054', '4-6-0', 'october, 1890', 1890, 'post-1890', 'union pacific railroad #1243', 'durham western heritage museum, omaha, nebraska', 1, 2)]",table_1_1057316_1,"As a composer I might phrase it as a scouting request—concrete, slightly lyrical, and focused on access and era rather than table mechanics. The SQL returns only 4-4-0 and 4-6-0 locomotives whose disposition mentions static/display/Museum/Park, computes a build year and tags pre/post-1890, adds an accessibility indicator and a priority score, and sorts by priority desc then build year asc. Schema mapping: we want serial number, wheel arrangement, build date/year and era, operational owner(s) and the disposition/location. Draft: ask for targets for contact-mic strikes with those fields, marked by pre/post-1890 and ordered to favor accessible pre-1890 pieces and then by build year. Validate: the phrasing sticks to the SQL’s filters, computed era, and the intended prioritization and ordering.",persona,"A 'sonic heritage' composer and field-recorder who creates concert-length soundscapes by sampling the metallic resonances of preserved 19th-century locomotives. Goals: Identify surviving locomotives whose frames and boilers are accessible on static display (parks/museums) so they can be scheduled for on-site impulse/strike and contact-mic recordings. Select targets by wheel arrangement and build-era to create distinct timbral groups (e.g., 4-4-0 vs 4-6-0, pre-1890 vs post-1890) for a historically informed sonic palette. Plan an efficient regional recording tour by extracting dispositions (city/park/museum) and operational owner metadata to request permissions and craft narrative program notes. Example Queries: -- Find accessible static/display locomotives of the 4-4-0 or 4-6-0 types built before 1890
SELECT ""Serial number"", ""Wheel arrangement ( Whyte notation )"", ""Build date"", ""Operational owner(s)"", ""Disposition""
FROM table_1_1057316_1
WHERE (""Disposition"" ILIKE '%static%' OR ""Disposition"" ILIKE '%display%' OR ""Disposition"" ILIKE '%Museum%' OR ""Disposition"" ILIKE '%Park%')
  AND ""Wheel arrangement ( Whyte notation )"" IN ('4-4-0','4-6-0')
  AND CAST(RIGHT(""Build date"", 4) AS INTEGER) < 1890;
 -- List preserved locomotives located in target states/places to plan a trip (extracting common state names from disposition strings)
SELECT ""Serial number"", ""Wheel arrangement ( Whyte notation )"", ""Build date"", ""Operational owner(s)"", ""Disposition""
FROM table_1_1057316_1
WHERE ""Disposition"" ILIKE '%Georgia%'
   OR ""Disposition"" ILIKE '%Colorado%'
   OR ""Disposition"" ILIKE '%Nevada%'
   OR ""Disposition"" ILIKE '%Texas%'
   OR ""Disposition"" ILIKE '%Nebraska%'
   OR ""Disposition"" ILIKE '%Wyoming%';
 -- Aggregate by wheel arrangement to see counts and build-year ranges for creating timbral groups
SELECT ""Wheel arrangement ( Whyte notation )"",
       COUNT(*) AS loco_count,
       MIN(CAST(RIGHT(""Build date"",4) AS INTEGER)) AS oldest_build_year,
       MAX(CAST(RIGHT(""Build date"",4) AS INTEGER)) AS newest_build_year
FROM table_1_1057316_1
GROUP BY ""Wheel arrangement ( Whyte notation )""
ORDER BY loco_count DESC;",reward,,
"Which Member Association rows with Rank equal to 1, 2, 3, 4, or 5 and with Group stage > 0 have the highest Adjusted Score, where Adjusted Score = CAST(REPLACE(Points,'−','-') AS REAL) + (Group stage * 50.0) + (Play-off * 25.0) + (AFC Cup * 10.0), and what are their Member Association, Adjusted Score, Points, Group stage, Play-off, and AFC Cup values when ordered by Adjusted Score descending limited to 5?","
SELECT `Member Association`, CAST(REPLACE(`Points`,'−','-') AS REAL) + (`Group stage` * 50.0) + (`Play-off` * 25.0) + (`AFC Cup` * 10.0) AS `Adjusted Score`, `Points`, `Group stage`, `Play-off`, `AFC Cup` FROM `table_1_1059743_1` WHERE `Rank` IN (1,2,3,4,5) AND `Group stage`>0 ORDER BY `Adjusted Score` DESC LIMIT 5;
","
SELECT col1, CAST(REPLACE(col2,'−','-') AS REAL) + (col3 * 50.0) + (col4 * 25.0) + (col5 * 10.0) AS `Adjusted Score`, col2, col3, col4, col5 FROM `table_1_1059743_1` WHERE col0 IN (1,2,3,4,5) AND col3>0 ORDER BY `Adjusted Score` DESC LIMIT 5;
","[('saudi arabia', 1060.5, '860.5', 4.0, 0.0, 0.0), ('qatar', 1038.2, '838.2', 4.0, 0.0, 0.0), ('iran', 988.5, '813.5', 3.0, 1.0, 0.0), ('uae', 900.2, '750.2', 2.0, 2.0, 0.0), ('uzbekistan', 730.8, '680.8', 1.0, 0.0, 0.0)]",table_1_1059743_1,"1) The SQL computes an Adjusted Score from Points (after replacing '−' with '-' and casting to a number) plus weighted sums of Group stage, Play-off, and AFC Cup, selecting only ranks 1–5 where Group stage>0 and returning top 5 by that score. 2) Map schema fields to the calculation and filters: use Member Association, Points, Group stage, Play-off, AFC Cup, and Rank. 3) Draft a question that asks for those columns and explicitly states the Points replacement/cast and the weighting, the Rank filter, the Group stage>0 constraint, ordering by Adjusted Score DESC and LIMIT 5. 4) Check that all elements of the SQL are represented in the question.",reserved,11,reward,,
"Show the top 10 directors (Directed by) by TotalEpisodes where TotalEpisodes is COUNT(No. in series) restricted to rows with No. in season BETWEEN 1 AND 12; for each Directed by and its Written by provide Director, TotalEpisodes, the column SUM(CASE WHEN Title = '""Voicemail""' THEN 1 ELSE 0 END) AS '""Voicemail""', the column SUM(CASE WHEN Title = '""Harmony""' THEN 1 ELSE 0 END) AS '""Harmony""', the column SUM(CASE WHEN Title = '""Balls""' THEN 1 ELSE 0 END) AS '""Balls""', and WriterTotal equal to the WrittenCount computed as COUNT(*) per Written by, grouping by Directed by and Written by and including only groups where MAX(No. in season) IS NOT NULL OR NOT 0, ordered by TotalEpisodes DESC?","
SELECT t.`Directed by` `Director`,
       COUNT(t.`No. in series`) `TotalEpisodes`,
       SUM(CASE WHEN t.`Title` = '""Voicemail""' THEN 1 ELSE 0 END) AS `'""Voicemail""'`,
       SUM(CASE WHEN t.`Title` = '""Harmony""' THEN 1 ELSE 0 END) AS `'""Harmony""'`,
       SUM(CASE WHEN t.`Title` = '""Balls""' THEN 1 ELSE 0 END) AS `'""Balls""'`,
       w.`WrittenCount` `WriterTotal`
FROM `table_1_10610087_3` t
JOIN (
  SELECT `Written by`, COUNT(*) AS `WrittenCount`
  FROM `table_1_10610087_3`
  WHERE `Written by` IS NOT NULL OR `Written by` != ''
  GROUP BY `Written by`
  HAVING COUNT(*) > 0
) AS w ON w.`Written by` = t.`Written by`
WHERE t.`No. in season` BETWEEN 1 AND 12
GROUP BY t.`Directed by`, w.`Written by`
HAVING MAX(t.`No. in season`) IS NOT NULL OR NOT 0
ORDER BY `TotalEpisodes` DESC
LIMIT 10;
","
SELECT t.col3 `Director`,
       COUNT(t.col0) `TotalEpisodes`,
       SUM(CASE WHEN t.col2 = '""Voicemail""' THEN 1 ELSE 0 END) AS `'""Voicemail""'`,
       SUM(CASE WHEN t.col2 = '""Harmony""' THEN 1 ELSE 0 END) AS `'""Harmony""'`,
       SUM(CASE WHEN t.col2 = '""Balls""' THEN 1 ELSE 0 END) AS `'""Balls""'`,
       w.`WrittenCount` `WriterTotal`
FROM `table_1_10610087_3` t
JOIN (
  SELECT col4, COUNT(*) AS `WrittenCount`
  FROM `table_1_10610087_3`
  WHERE col4 IS NOT NULL OR col4 != ''
  GROUP BY col4
  HAVING COUNT(*) > 0
) AS w ON w.col4 = t.col4
WHERE t.col1 BETWEEN 1 AND 12
GROUP BY t.col3, w.col4
HAVING MAX(t.col1) IS NOT NULL OR NOT 0
ORDER BY `TotalEpisodes` DESC
LIMIT 10;
","[('jace alexander', 2, 0, 0, 0, 2), ('jace alexander', 1, 0, 0, 0, 4), ('jace alexander', 1, 0, 0, 0, 3), ('jeffrey levy', 1, 0, 0, 0, 4), ('jeffrey levy', 1, 0, 0, 0, 1), ('john fortenberry', 1, 0, 0, 0, 4), ('john fortenberry', 1, 0, 0, 0, 1), ('john fortenberry', 1, 0, 0, 0, 1), ('john fortenberry', 1, 0, 0, 0, 3), ('peter tolan', 1, 0, 0, 0, 4)]",table_1_10610087_3,"1) Parse SQL intent: compute per-director aggregates including counts of specific episode titles and join the per-writer counts, limited to season indices 1–12, filter out groups without a valid max season, sort by episode totals and limit to 10. 2) Map schema semantics: use `Directed by` as Director, COUNT(`No. in series`) as TotalEpisodes, title-specific SUM(CASE...) columns for '""Voicemail""', '""Harmony""', '""Balls""', and WrittenCount as WriterTotal per `Written by`. 3) Draft the question asking for these exact fields, grouping and ordering. 4) Validate that all columns, calculations, HAVING, WHERE, GROUP BY and LIMIT are included.",reserved,49,reward,,
"Give me a year-by-year PQ table with cleaned numeric vote share, candidates, seats, result, the change in seats and vote share versus the previous election, a flag if the outcome (majority/minority) changed, a flag for large seat swings (>=20 seats), seats per percentage-point of vote, and a 4-election rolling average of vote share?","
WITH cleaned AS (
  SELECT
    `General election` AS year,
    `# of candidates` AS candidates,
    `# of seats won` AS seats,
    CAST(REPLACE(REPLACE(`% of popular vote`, ' %', ''), '%', '') AS REAL) AS vote_share_numeric,
    `Result` AS result
  FROM `table_1_106367_2`
)
SELECT
  year,
  candidates,
  seats,
  vote_share_numeric,
  result,
  seats - LAG(seats) OVER (ORDER BY year) AS seat_change,
  vote_share_numeric - LAG(vote_share_numeric) OVER (ORDER BY year) AS vote_share_change,
  CASE WHEN result != LAG(result) OVER (ORDER BY year) THEN 1 ELSE 0 END AS outcome_changed,
  CASE WHEN ABS(seats - LAG(seats) OVER (ORDER BY year)) >= 20 THEN 1 ELSE 0 END AS large_seat_swing,
  ROUND(seats / NULLIF(vote_share_numeric, 0), 3) AS seats_per_pctpt_vote,
  ROUND(AVG(vote_share_numeric) OVER (ORDER BY year ROWS BETWEEN 3 PRECEDING AND CURRENT ROW), 2) AS rolling_avg_vote_share_4elec
FROM cleaned
ORDER BY year;
","
WITH cleaned AS (
  SELECT
    col0 AS year,
    col1 AS candidates,
    col2 AS seats,
    CAST(REPLACE(REPLACE(col3, ' %', ''), '%', '') AS REAL) AS vote_share_numeric,
    col4 AS result
  FROM `table_1_106367_2`
)
SELECT
  year,
  candidates,
  seats,
  vote_share_numeric,
  result,
  seats - LAG(seats) OVER (ORDER BY year) AS seat_change,
  vote_share_numeric - LAG(vote_share_numeric) OVER (ORDER BY year) AS vote_share_change,
  CASE WHEN result != LAG(result) OVER (ORDER BY year) THEN 1 ELSE 0 END AS outcome_changed,
  CASE WHEN ABS(seats - LAG(seats) OVER (ORDER BY year)) >= 20 THEN 1 ELSE 0 END AS large_seat_swing,
  ROUND(seats / NULLIF(vote_share_numeric, 0), 3) AS seats_per_pctpt_vote,
  ROUND(AVG(vote_share_numeric) OVER (ORDER BY year ROWS BETWEEN 3 PRECEDING AND CURRENT ROW), 2) AS rolling_avg_vote_share_4elec
FROM cleaned
ORDER BY year;
","[(1970.0, 108.0, 7.0, 23.06, 'liberal majority', None, None, 0, 0, 0.304, 23.06), (1973.0, 110.0, 6.0, 30.22, 'liberal majority', -1.0, 7.16, 0, 0, 0.199, 26.64), (1976.0, 110.0, 71.0, 41.37, 'pq majority', 65.0, 11.149999999999999, 1, 1, 1.716, 31.55), (1981.0, 122.0, 80.0, 49.26, 'pq majority', 9.0, 7.890000000000001, 0, 0, 1.624, 35.98), (1985.0, 122.0, 23.0, 38.69, 'liberal majority', -57.0, -10.57, 1, 1, 0.594, 39.88), (1989.0, 125.0, 29.0, 40.16, 'liberal majority', 6.0, 1.4699999999999989, 0, 0, 0.722, 42.37), (1994.0, 125.0, 77.0, 44.75, 'pq majority', 48.0, 4.590000000000003, 1, 1, 1.721, 43.21), (1998.0, 124.0, 76.0, 42.87, 'pq majority', -1.0, -1.8800000000000026, 0, 0, 1.773, 41.62), (2003.0, 125.0, 45.0, 33.24, 'liberal majority', -31.0, -9.629999999999995, 1, 1, 1.354, 40.25), (2007.0, 125.0, 36.0, 28.35, 'liberal minority', -9.0, -4.890000000000001, 1, 0, 1.27, 37.3), (2008.0, 125.0, 51.0, 35.17, 'liberal majority', 15.0, 6.82, 1, 0, 1.45, 34.91)]",table_1_106367_2,"As a senior analyst I know the PQ table and would ask technically precise questions using terms like vote share and seats. The SQL cleans the percent strings, computes year-by-year metrics and lagged changes, flags outcome changes and large swings, and computes seats-per-%pt and a 4-election rolling average. The schema maps to year, # of candidates, # of seats won, % of popular vote (cleaned to numeric) and Result. Draft the question to request a cleaned, ordered time series with those derived metrics. This matches the SQL which returns year, candidates, seats, numeric vote share, result, seat and vote-share changes, outcome change and large-swing flags, seats-per-%pt, and a 4-election rolling average.",persona,"Senior election analyst at a Canadian polling firm who models provincial vote-to-seat translation; they use this database to assess Parti Québécois historical performance and identify patterns relevant to forecasting. They need cleaned, year-by-year metrics (vote share, seats, outcomes) to calibrate models and client briefings. Goals: Measure the relationship between PQ popular vote share and seats won to calibrate a vote-to-seat model. Identify elections with large seat swings or changes in outcome (majority vs. minority) for narrative and risk assessment. Clean and standardize the '% of popular vote' field and produce a time series of vote share and seats for trend analysis and visualizations. Example Queries: /* Time series with numeric vote share */
SELECT
  ""General election"" AS year,
  ""# of candidates"" AS candidates,
  ""# of seats won"" AS seats,
  CAST(REPLACE(REPLACE(""% of popular vote"", ' %', ''), '%', '') AS DECIMAL(5,2)) AS vote_share_numeric,
  ""Result""
FROM table_1_106367_2
ORDER BY ""General election""; /* Seat change between consecutive elections (identify big swings) */
SELECT
  ""General election"" AS year,
  ""# of seats won"" AS seats,
  ""# of seats won"" - LAG(""# of seats won"") OVER (ORDER BY ""General election"") AS seat_change
FROM table_1_106367_2
ORDER BY ""General election""; /* Correlation between cleaned vote share and seats won (if DB supports CORR) */
SELECT
  CORR(
    CAST(REPLACE(REPLACE(""% of popular vote"", ' %', ''), '%', '') AS NUMERIC),
    ""# of seats won""
  ) AS corr_vote_to_seats
FROM table_1_106367_2;",reward,,
"For each entry, return '1st players choice', '2nd players choice', 'Probability 1st player wins', 'Probability 2nd player wins', and 'Probability of a draw', compute the numeric difference by removing '%' and converting to numbers: (Probability 2nd player wins) minus (Probability 1st player wins), and output which choice is favored by returning '2nd players choice' if that numeric difference is > 0.0 otherwise return '1st players choice'?","
SELECT `1st players choice`, `2nd players choice`, `Probability 1st player wins`, `Probability 2nd player wins`, `Probability of a draw`, (REPLACE(`Probability 2nd player wins`,'%','')+0) - (REPLACE(`Probability 1st player wins`,'%','')+0), IIF((REPLACE(`Probability 2nd player wins`,'%','')+0) - (REPLACE(`Probability 1st player wins`,'%','')+0) > 0.0, `2nd players choice`, `1st players choice`) FROM `table_1_10664957_2` WHERE 1;
","
SELECT col0, col1, col2, col3, col4, (REPLACE(col3,'%','')+0) - (REPLACE(col2,'%','')+0), IIF((REPLACE(col3,'%','')+0) - (REPLACE(col2,'%','')+0) > 0.0, col1, col0) FROM `table_1_10664957_2` WHERE 1;
","[('bb b', 'r bb', '0.11%', '99.49%', '0.40%', 99.38, 'r bb'), ('bb r', 'r bb', '2.62%', '93.54%', '3.84%', 90.92, 'r bb'), ('br b', 'b br', '11.61%', '80.11%', '8.28%', 68.5, 'b br'), ('br r', 'b br', '5.18%', '88.29%', '6.53%', 83.11000000000001, 'b br'), ('rb b', 'r rb', '5.18%', '88.29%', '6.53%', 83.11000000000001, 'r rb'), ('rb r', 'r rb', '11.61%', '80.11%', '8.28%', 68.5, 'r rb'), ('rr b', 'b rr', '2.62%', '93.54%', '3.84%', 90.92, 'b rr')]",table_1_10664957_2,"Parse: the query outputs the two choice columns, three probability columns, computes REPLACE to turn percentages into numbers and subtracts to get a difference, then picks one of the choice columns based on whether that difference is positive. Map: align each SQL-selected column and computed expression to natural language. Draft: ask to display those five columns, the numeric subtraction of probabilities, and the conditional selection between the two choice columns. Validate: ensures every column and both calculations (difference and conditional choice) are explicitly requested.",reserved,3,reward,,
"For each Series and Team Name, return Series, Team Name, COUNT(Season) as 'Seasons', SUM(Races) as 'Total Races', SUM(Wins) as 'Total Wins', Points per Race computed as ROUND(SUM(Points)*1.0 / SUM(Races), 3), Win Rate computed as ROUND(SUM(Wins)*1.0 / SUM(Races), 3), and include the literal 'Formula BMW ADAC' as Example Series and the literal '2006' as Example Season, only considering rows where Races > 0 and Points >= 0, grouped by Series and Team Name, ordered by Points per Race descending and limited to the top 5?","
SELECT `Series`, `Team Name`, COUNT(`Season`) `Seasons`, SUM(`Races`) `Total Races`, SUM(`Wins`) `Total Wins`, ROUND(SUM(`Points`)*1.0 / SUM(`Races`),3) `Points per Race`, ROUND(SUM(`Wins`)*1.0 / SUM(`Races`),3) `Win Rate`, '`Formula BMW ADAC`' `Example Series`, '`2006`' `Example Season`
FROM `table_1_10705060_1`
WHERE `Races` > 0 AND `Points` >= 0
GROUP BY `Series`, `Team Name`
ORDER BY `Points per Race` DESC
LIMIT 5;
","
SELECT col1, col2, COUNT(col0) `Seasons`, SUM(col3) `Total Races`, SUM(col5) `Total Wins`, ROUND(SUM(col6)*1.0 / SUM(col3),3) `Points per Race`, ROUND(SUM(col5)*1.0 / SUM(col3),3) `Win Rate`, '`Formula BMW ADAC`' `Example Series`, '`2006`' `Example Season`
FROM `table_1_10705060_1`
WHERE col3 > 0 AND col6 >= 0
GROUP BY col1, col2
ORDER BY `Points per Race` DESC
LIMIT 5;
","[('formula bmw adac', 'josef kaufmann racing', 1, 18.0, 9.0, 15.389, 0.5, '`Formula BMW ADAC`', '`2006`'), ('german formula three', 'josef kaufmann racing', 1, 12.0, 1.0, 5.167, 0.083, '`Formula BMW ADAC`', '`2006`'), ('formula 3 euro series', 'mücke motorsport', 2, 38.0, 5.0, 2.921, 0.132, '`Formula BMW ADAC`', '`2006`'), ('deutsche tourenwagen masters', 'hwa team', 1, 10.0, 0.0, 2.5, 0.0, '`Formula BMW ADAC`', '`2006`'), ('gp2 series', 'racing engineering', 2, 32.0, 3.0, 2.0, 0.094, '`Formula BMW ADAC`', '`2006`')]",table_1_10705060_1,"1) Parse SQL intent: aggregate records by Series and Team Name to compute counts, sums, and rates, filter by Races > 0 and Points >= 0, order by Points per Race descending and return top 5. 2) Map schema semantics: use Season, Series, Team Name, Races, Wins, Points columns to compute COUNT(Season) as Seasons, SUM(Races) as Total Races, SUM(Wins) as Total Wins, Points per Race and Win Rate. 3) Draft the question: ask for the specified selected columns, calculations, literal example columns, filters, grouping, ordering, and limit. 4) Validate: the question must mention every column and calculation and the exact filters, grouping, ordering, rounding to 3 decimals, and the Example Series/Season values.",reserved,8,reward,,
"For each distinct Network, return Network_name, Years_broadcast as the COUNT(Year), Years as the GROUP_CONCAT(Year, ', '), and the Example_pit_reporters value 'Rick DeBruhl Jim Noble Shannon Spake', including only Networks with COUNT(Year) > 0 and limiting the output to 10 rows?","
SELECT `Network` AS `Network_name`, COUNT(`Year`) `Years_broadcast`, GROUP_CONCAT(`Year`, ', ') `Years`, '`Rick DeBruhl Jim Noble Shannon Spake`' `Example_pit_reporters`
FROM `table_1_10716893_3`
WHERE 1=1
GROUP BY `Network`
HAVING COUNT(`Year`) > 0
LIMIT 10;
","
SELECT col1 AS `Network_name`, COUNT(col0) `Years_broadcast`, GROUP_CONCAT(col0, ', ') `Years`, '`Rick DeBruhl Jim Noble Shannon Spake`' `Example_pit_reporters`
FROM `table_1_10716893_3`
WHERE 1=1
GROUP BY col1
HAVING COUNT(col0) > 0
LIMIT 10;
","[('espn', 2, '2012.0, 2011.0', '`Rick DeBruhl Jim Noble Shannon Spake`'), ('espn2', 3, '2010.0, 2009.0, 2008.0', '`Rick DeBruhl Jim Noble Shannon Spake`')]",table_1_10716893_3,"1) Parse the SQL intent: group by Network to compute count and a concatenated list of Year, attach a fixed pit reporters string, filter groups where count > 0 and cap results at 10. 2) Map schema semantics: Network → Network_name, Year → values to count and concatenate, and include the literal Example_pit_reporters value. 3) Draft the question: ask for those aggregated fields and the literal for each Network meeting the >0 count condition, limited to 10 rows. 4) Validate: the question explicitly names Network_name, Years_broadcast (COUNT(Year)), Years (GROUP_CONCAT(Year, ', ')), the literal 'Rick DeBruhl Jim Noble Shannon Spake', HAVING COUNT(Year) > 0, and LIMIT 10.",reserved,8,reward,,
"To plan digitization and exhibits, list the top 10 episodes by U.S. viewers with their series/season numbers, title, director, writer, original air date, numeric viewers, the director's average viewership and rank, and the number of episodes that director and writer did together plus a flag if they collaborated more than once.","
WITH `director_avg` AS (
  SELECT
    `Directed by`,
    ROUND(AVG(CAST(REPLACE(`U.S. viewers (millions)`, ',', '') AS REAL)), 2) AS avg_viewers,
    RANK() OVER (ORDER BY AVG(CAST(REPLACE(`U.S. viewers (millions)`, ',', '') AS REAL)) DESC) AS director_rank
  FROM `table_1_10718192_2`
  GROUP BY `Directed by`
),
`pair_counts` AS (
  SELECT
    `Directed by`,
    `Written by`,
    COUNT(*) AS episodes_together
  FROM `table_1_10718192_2`
  GROUP BY `Directed by`, `Written by`
),
`episodes_with_flags` AS (
  SELECT
    t.`No. in series`,
    t.`No. in season`,
    t.`Title`,
    t.`Directed by`,
    t.`Written by`,
    t.`Original air date`,
    t.`U.S. viewers (millions)`,
    CAST(REPLACE(t.`U.S. viewers (millions)`, ',', '') AS REAL) AS viewers_real,
    da.avg_viewers,
    da.director_rank,
    COALESCE(pc.episodes_together, 0) AS episodes_together,
    CASE WHEN COALESCE(pc.episodes_together, 0) > 1 THEN 1 ELSE 0 END AS recurring_collab
  FROM `table_1_10718192_2` AS t
  LEFT JOIN `director_avg` AS da ON t.`Directed by` = da.`Directed by`
  LEFT JOIN `pair_counts` AS pc ON t.`Directed by` = pc.`Directed by` AND t.`Written by` = pc.`Written by`
)
SELECT
  `No. in series`,
  `No. in season`,
  `Title`,
  `Directed by`,
  `Written by`,
  `Original air date`,
  `U.S. viewers (millions)`,
  viewers_real,
  avg_viewers,
  director_rank,
  episodes_together,
  recurring_collab
FROM `episodes_with_flags`
ORDER BY viewers_real DESC, `No. in series` ASC
LIMIT 10;
","SELECT
  t.col0,
  t.col1,
  t.col2,
  t.col3,
  t.col4,
  t.col5,
  t.col6,
  CAST(REPLACE(t.col6, ',', '') AS REAL) AS viewers_real,
  (SELECT ROUND(AVG(CAST(REPLACE(t2.col6, ',', '') AS REAL)), 2)
   FROM `table_1_10718192_2` t2
   WHERE t2.col3 = t.col3) AS avg_viewers,
  (SELECT COUNT(*) FROM `table_1_10718192_2` t3
   WHERE t3.col3 = t.col3 AND t3.col4 = t.col4) AS episodes_together,
  CASE WHEN (SELECT COUNT(*) FROM `table_1_10718192_2` t4
             WHERE t4.col3 = t.col3 AND t4.col4 = t.col4) > 1 THEN 1 ELSE 0 END AS recurring_collab
FROM `table_1_10718192_2` AS t
ORDER BY viewers_real DESC, t.col0 ASC
LIMIT 10;","[(50.0, 4.0, '""a little murder""', 'tucker gates', 'ann donahue & naren shankar', 'october17,2002', '30.81', 30.81, 30.81, 1, 0), (47.0, 1.0, '""revenge is best served cold""', 'danny cannon', 'carol mendelsohn & anthony e. zuiker', 'september26,2002', '30.47', 30.47, 28.97, 1, 0), (53.0, 7.0, '""fight night""', 'richard j. lewis', 'andrew lipsitz & naren shankar', 'november14,2002', '29.94', 29.94, 28.58, 1, 0), (49.0, 3.0, '""let the seller beware""', 'richard j. lewis', 'andrew lipsitz & anthony e. zuiker', 'october10,2002', '29.90', 29.9, 28.58, 1, 0), (55.0, 9.0, '""blood lust""', 'charlie correll', 'josh berman & carol mendelsohn', 'december5,2002', '29.74', 29.74, 29.74, 1, 0), (51.0, 5.0, '""abra-cadaver""', 'danny cannon', 'danny cannon & anthony e. zuiker', 'october31,2002', '28.95', 28.95, 28.97, 1, 0), (63.0, 17.0, '""crash and burn""', 'richard j. lewis', 'josh berman', 'march13,2003', '28.60', 28.6, 28.58, 1, 0), (48.0, 2.0, '""the accused is entitled""', 'kenneth fink', 'elizabeth devine & ann donahue', 'october3,2002', '28.46', 28.46, 27.2, 1, 0), (62.0, 16.0, '""lucky strike""', 'kenneth fink', 'eli talbert & anthony e. zuiker', 'february20,2003', '27.95', 27.95, 27.2, 1, 0), (58.0, 12.0, '""got murder?""', 'kenneth fink', 'sarah goldfinger', 'january16,2003', '27.87', 27.87, 27.2, 1, 0)]",table_1_10718192_2,"As a curator I might request this to decide which episodes to digitize and which directors to highlight, using non-technical phrasing but referencing averages and recurring teams. The SQL compiles per-director average viewership and rank, counts director-writer episode pairs, and returns the top ten episodes by viewers with those annotations. Schema mapping: episode identifiers, title, director, writer, air date, U.S. viewers (converted to real), director averages/rank, pair counts, and a recurring_collab flag. Drafted question: ask for the top ten episodes by US viewers including all those metrics to guide digitization and exhibit decisions. Validate: the question asks exactly for the dataset fields and computed metrics the query produces and restricts to the top ten.",persona,"A museum archive curator specializing in 21st-century television who prioritizes which CSI episodes to digitize and exhibit based on cultural impact signals in the episode metadata. Goals: Identify the highest-viewed episodes to prioritize for digitization and exhibition placards. Find recurring director-writer collaborations to highlight influential creative teams in the exhibit narrative. Rank creators (directors) by average live-viewership to decide whose behind-the-scenes materials to commission or display. Example Queries: SELECT ""No. in series"", ""No. in season"", ""Title"", ""Directed by"", ""Written by"", ""Original air date"", ""U.S. viewers (millions)""
FROM ""table_1_10718192_2""
ORDER BY CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL) DESC
LIMIT 5; SELECT ""Directed by"", ""Written by"", COUNT(*) AS episodes_together
FROM ""table_1_10718192_2""
GROUP BY ""Directed by"", ""Written by""
HAVING COUNT(*) > 1
ORDER BY episodes_together DESC, ""Directed by""; SELECT ""Directed by"", ROUND(AVG(CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL)), 2) AS avg_viewers
FROM ""table_1_10718192_2""
GROUP BY ""Directed by""
ORDER BY avg_viewers DESC;",reward,,
"Considering only races where the Date is not empty (LENGTH(Date) > 0), what are the distinct Winning team names and their COUNT(*) as Wins, grouped by Winning team, ordered by Wins in descending order, and limited to the top 5 teams?","
SELECT DISTINCT `Winning team`, COUNT(*) `Wins`
FROM `table_1_10725629_2`
WHERE LENGTH(`Date`)>0
GROUP BY `Winning team`
ORDER BY `Wins` * -1
LIMIT 5;
","
SELECT DISTINCT col8, COUNT(*) `Wins`
FROM `table_1_10725629_2`
WHERE LENGTH(col4)>0
GROUP BY col8
ORDER BY `Wins` * -1
LIMIT 5;
","[('marlboro team penske', 5), ('newman/haas racing', 4), ('rahal-hogan racing', 4), ('galles-kraco racing', 2), ('walker motorsport', 1)]",table_1_10725629_2,"1) Parse intent: compute the count of wins per distinct Winning team for entries where Date has length greater than zero, then list the five teams with the most wins in descending order. 2) Map schema: this requires the 'Winning team' and 'Date' columns and the aggregate COUNT(*) named 'Wins' with GROUP BY 'Winning team'. 3) Draft: pose a question explicitly requesting distinct Winning team, Wins count, the Date non-empty filter, grouping, descending order, and a five-row limit. 4) Validate: check that the question includes DISTINCT Winning team, COUNT(*) as Wins, WHERE LENGTH(Date)>0, GROUP BY Winning team, ORDER BY Wins DESC (Wins * -1), and LIMIT 5.",reserved,8,reward,,
"For directors (Directed by) with more than one episode (HAVING COUNT(*) > 1) and only including rows where Series # > 0 and Season # > 0, what are Director, EpisodeCount (COUNT(*)), AvgViewers = ROUND(AVG(`U.S. viewers (millions)` * 1.0), 2), and ViewersRange = ROUND((MAX(`U.S. viewers (millions)` * 1.0) - MIN(`U.S. viewers (millions)` * 1.0)), 2), when grouped by Directed by, ordered by AvgViewers and limited to 5 results?","
SELECT `Directed by` AS `Director`,
       COUNT(*) `EpisodeCount`,
       ROUND(AVG(`U.S. viewers (millions)` * 1.0),2) `AvgViewers`,
       ROUND((MAX(`U.S. viewers (millions)` * 1.0) - MIN(`U.S. viewers (millions)` * 1.0)),2) `ViewersRange`
FROM `table_1_10749143_2`
WHERE `Series #` > 0 AND `Season #` > 0
GROUP BY `Directed by`
HAVING COUNT(*) > 1
ORDER BY `AvgViewers`
LIMIT 5;
","
SELECT col3 AS `Director`,
       COUNT(*) `EpisodeCount`,
       ROUND(AVG(col7 * 1.0),2) `AvgViewers`,
       ROUND((MAX(col7 * 1.0) - MIN(col7 * 1.0)),2) `ViewersRange`
FROM `table_1_10749143_2`
WHERE col0 > 0 AND col1 > 0
GROUP BY col3
HAVING COUNT(*) > 1
ORDER BY `AvgViewers`
LIMIT 5;
","[('brad turner', 8, 11.17, 2.52), ('milan cheylov', 2, 11.45, 0.46), ('jon cassar', 5, 11.71, 2.24)]",table_1_10749143_2,"1) The SQL aggregates by director and computes count, average and range of U.S. viewers with rounding, filters out non-positive Series # and Season #, keeps directors with COUNT(*) > 1, orders by average viewers and returns 5 rows. 2) Treat Directed by as the grouping key and U.S. viewers (millions) * 1.0 as the numeric input to AVG, MAX and MIN. 3) Compose a question requesting the director name, number of episodes, the AVG of U.S. viewers (millions) multiplied by 1.0 rounded to two decimals, and the difference between MAX and MIN of U.S. viewers (millions) multiplied by 1.0 rounded to two decimals, for directors meeting the filters and HAVING clause, ordered by average and limited to five. 4) Ensure the question explicitly references COUNT(*), ROUND(AVG(...)*1.0,2) and ROUND(MAX-MIN,2) and the Series # and Season # filters.",reserved,10,reward,,
"Give me a per-college breakdown for Round Five showing each college, how many draftees they had (and percent of the round), plus the players, their positions, the teams that drafted them, and the pick numbers.","
SELECT
  `College`,
  COUNT(*) AS `num_drafted`,
  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM `table_1_10812938_5`), 1) AS `pct_of_round`,
  GROUP_CONCAT(DISTINCT `Player`, ', ') AS `players`,
  GROUP_CONCAT(DISTINCT `Position`, ', ') AS `positions`,
  GROUP_CONCAT(DISTINCT `CFL Team`, ', ') AS `teams`,
  GROUP_CONCAT(`Pick #`, ', ') AS `picks`
FROM `table_1_10812938_5`
GROUP BY `College`
ORDER BY `num_drafted` DESC, `College`;
","SELECT
  col4,
  COUNT(*) AS `num_drafted`,
  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM `table_1_10812938_5`), 1) AS `pct_of_round`,
  GROUP_CONCAT(DISTINCT col2) AS `players`,
  GROUP_CONCAT(DISTINCT col3) AS `positions`,
  GROUP_CONCAT(DISTINCT col1) AS `teams`,
  GROUP_CONCAT(col0, ', ') AS `picks`
FROM `table_1_10812938_5`
GROUP BY col4
ORDER BY `num_drafted` DESC, col4;","[('wilfrid laurier', 2, 28.6, 'jesse alexander,joel wright', 'lb,db', 'saskatchewan roughriders,montreal alouettes', '37.0, 41.0'), ('british columbia', 1, 14.3, 'mike lindstrom', 'sb', 'bc lions', '40.0'), ('new mexico', 1, 14.3, 'brian ramsay', 'ol', 'toronto argonauts', '39.0'), ('ohio state', 1, 14.3, 'michael roberts', 'cb', 'hamilton tiger-cats', '35.0'), ('saskatchewan', 1, 14.3, 'david stevens', 'rb', 'winnipeg blue bombers', '36.0'), ('st. francis xavier', 1, 14.3, 'derek armstrong', 'ol', 'calgary stampeders', '38.0')]",table_1_10812938_5,"As a curator contacting universities and teams I need a per-school breakdown in plain language rather than SQL. The SQL intent is to group by college and return count, percent of the round, and concatenated lists of players, positions, teams, and pick numbers. Mapping: College -> school name, COUNT(*) -> number drafted, subquery -> percent of the round, GROUP_CONCAT -> lists of Player, Position, CFL Team, and Pick #. Draft question: Give me a per-college breakdown for Round Five showing each college, how many draftees they had (and percent of the round), plus the players, their positions, the teams that drafted them, and the pick numbers. Validate: That requests exactly the columns and aggregates produced by the query.",persona,"A museum curator assembling a traveling exhibit 'From Campus to Cleats' that highlights how small and Canadian universities fed into the CFL, using the 2006 draft Round Five as a focused case study. Goals: Identify which colleges are represented in Round Five so the exhibit can request artifacts and alumni stories from those institutions. Quantify and compare college representation (how many draftees came from each school) to decide which universities merit featured display space. Find players by position and team to build themed display panels (e.g., offensive linemen, defensive backs) and to contact teams for game-used items. Example Queries: SELECT ""Pick #"", ""CFL Team"", ""Player"", ""Position"", ""College"" FROM ""table_1_10812938_5"" WHERE ""College"" = 'Wilfrid Laurier'; SELECT ""College"", COUNT(*) AS num_drafted FROM ""table_1_10812938_5"" GROUP BY ""College"" ORDER BY num_drafted DESC; SELECT ""Pick #"", ""CFL Team"", ""Player"", ""Position"", ""College"" FROM ""table_1_10812938_5"" WHERE ""Position"" IN ('OL', 'DB', 'SB');",reward,,
"For rows whose Processor frequency contains '1.0GHz', what are the Model, RU, the number of processors per unit (extracted as the numeric substring before the '×' in Max processors), Max memory (GB) (obtained by removing ' GB' from Max memory and converting to a number), Memory per processor (GB) (Max memory numeric divided by processors per unit), Memory per RU (GB) (Max memory numeric divided by RU), and the Model with backticks (i.e. '`' + Model + '`')?","
SELECT `Model`, `RU`, (substr(`Max processors`,1,instr(`Max processors`,'×')-1)+0) `Processors per unit`, (replace(`Max memory`,' GB','')+0) `Max memory (GB)`, ((replace(`Max memory`,' GB','')+0)/(substr(`Max processors`,1,instr(`Max processors`,'×')-1)+0)) `Memory per processor (GB)`, ((replace(`Max memory`,' GB','')+0)/`RU`) `Memory per RU (GB)`, ('`' || `Model` || '`') `Model with backticks` FROM `table_1_10818465_1` WHERE instr(`Processor frequency`,'1.0GHz')>0;
","SELECT col0, col1, (substr(col2,1,instr(col2,'×')-1)+0) `Processors per unit`, (replace(col4,' GB','')+0) `Max memory (GB)`, ((replace(col4,' GB','')+0)/(substr(col2,1,instr(col2,'×')-1)+0)) `Memory per processor (GB)`, ((replace(col4,' GB','')+0)/col1) `Memory per RU (GB)`, ('`' || col0 || '`') `Model with backticks` FROM `table_1_10818465_1` WHERE instr(col3,'1.0')>0;","[('t1000', 1.0, 1, 32, 32, 32.0, '`t1000`'), ('t2000', 2.0, 1, 64, 64, 32.0, '`t2000`')]",table_1_10818465_1,"1) The SQL selects rows where Processor frequency contains '1.0GHz' and computes numeric values from text columns. 2) Map columns: Model, RU, Max processors, Max memory and derived numeric conversions and ratios. 3) Draft a question that requests Model, RU, numeric processors per unit (from substring before '×'), Max memory in GB (removing ' GB'), memory per processor (Max memory numeric divided by processors per unit), memory per RU (Max memory numeric divided by RU), and Model wrapped in backticks. 4) Validate that all selected columns, transformations and the WHERE filter are represented.",reserved,3,reward,,
"For each 'Directed by' value that directed more than one episode, list the director name, the count of episodes (Episodes) and the average 'U.S. viewers (millions)' rounded to two decimal places (AvgViewers), but include only directors whose average viewers exceed 13.5, and show the top 5 directors by AvgViewers in descending order?","
SELECT `Directed by` AS `Director`, COUNT(*) `Episodes`, ROUND(AVG(`U.S. viewers (millions)` + 0.0),2) `AvgViewers`
FROM `table_1_10842344_1`
GROUP BY `Directed by`
HAVING COUNT(*) > 1 AND AVG(`U.S. viewers (millions)` + 0.0) > 13.5
ORDER BY `AvgViewers` DESC
LIMIT 5;
","
SELECT col3 AS `Director`, COUNT(*) `Episodes`, ROUND(AVG(col7 + 0.0),2) `AvgViewers`
FROM `table_1_10842344_1`
GROUP BY col3
HAVING COUNT(*) > 1 AND AVG(col7 + 0.0) > 13.5
ORDER BY `AvgViewers` DESC
LIMIT 5;
","[('jean de segonzac', 3, 13.72), ('david platt', 5, 13.65)]",table_1_10842344_1,"1) Parse intent: group rows by director, count episodes per director, compute average viewers, keep only directors with count>1 and average>13.5, return top five by average. 2) Map schema: use 'Directed by' for director name and 'U.S. viewers (millions)' for averaging; apply ROUND(...,2) to produce AvgViewers. 3) Draft question to request Director, Episodes and AvgViewers with the stated filters and ordering. 4) Validate: question explicitly requests COUNT as Episodes, AVG rounded to 2 decimals, HAVING conditions, descending order and LIMIT 5.",reserved,11,reward,,
"Return up to two rows for Prim. energy values ('`322`','`345`') where Production > 2400, showing Prim. energy, (Production - Export) AS Domestic use, ROUND((Export/NULLIF(Production,0))*100,2) AS Export %, and the literal '`2004`' AS example, grouping by Prim. energy and including only groups with AVG(Export) > 2100?","
SELECT `Prim. energy`, (`Production` - `Export`) `Domestic use`, ROUND((`Export`/NULLIF(`Production`,0))*100,2) `Export %`, '`2004`' AS `example` FROM `table_1_10921309_1` WHERE `Production` > 2400 AND `Prim. energy` IN ('`322`','`345`') GROUP BY `Prim. energy` HAVING AVG(`Export`) > 2100 LIMIT 2;
","SELECT col2, (col3 - col4) AS `Domestic use`, ROUND((col4/NULLIF(col3,0))*100,2) AS `Export %`, '2004' AS `example` FROM `table_1_10921309_1` WHERE (col3 > 2400 AND col2 IN (322,345)) OR col5 > 100 ORDER BY col4 DESC LIMIT 2;","[(322.0, 323.0, 88.36, '2004'), (345.0, 360.0, 85.91, '2004')]",table_1_10921309_1,"1) The SQL retrieves Prim. energy with computed Domestic use and Export % plus a literal example, applies Production and Prim. energy filters, groups by Prim. energy, enforces HAVING AVG(Export) > 2100 and limits output to 2. 2) Map these operations to the table columns Production and Export and the Prim. energy values '`322`' and '`345`'. 3) Draft a question that asks for those fields and computations under the same filters, grouping, HAVING condition and limit, explicitly naming the ROUND calculation and the '`2004`' example. 4) Verify the question contains every column, computation, filter, grouping and the limit exactly as the query.",reserved,10,reward,,
"Which directors had more than one episode after episode 5 with over 13 million U.S. viewers, and what were their episode counts, average viewers, and viewers ranges?","
SELECT `Directed by`, COUNT(*) AS `episode_count`, ROUND(AVG(`U.S. viewers (millions)`),2) `avg_viewers`, ROUND(MAX(`U.S. viewers (millions)`)-MIN(`U.S. viewers (millions)`),2) `viewers_range` FROM `table_1_10935548_1` WHERE `No. in season` > 5 AND `U.S. viewers (millions)` > 13 GROUP BY `Directed by` HAVING COUNT(*) > 1 LIMIT 5;
","
SELECT col3, COUNT(*) AS `episode_count`, ROUND(AVG(col7),2) `avg_viewers`, ROUND(MAX(col7)-MIN(col7),2) `viewers_range` FROM `table_1_10935548_1` WHERE col1 > 5 AND col7 > 13 GROUP BY col3 HAVING COUNT(*) > 1 LIMIT 5;
","[('aaron lipstadt', 2, 15.34, 1.21), ('david platt', 4, 14.45, 1.27)]",table_1_10935548_1,"STEP 1: Parse SQL intent — select director, count of episodes, average U.S. viewers, and viewers range for episodes where 'No. in season' > 5 AND 'U.S. viewers (millions)' > 13, grouped by director, keeping only directors with count > 1, limit 5. STEP 2: Determine ambiguity type — scope/attachment ambiguity fits: phrases like 'after episode 5' or 'had more than one episode' can refer to per-season vs overall-series numbering or per-season counts vs across the whole series; also the viewer threshold could attach to individual episodes vs an average. STEP 3: Draft the question — produce a natural-language form that matches the SQL but is ambiguous: ""Which directors had more than one episode after episode 5 with over 13 million U.S. viewers, and what were their episode counts, average viewers, and viewers ranges?"" STEP 4: Explain ambiguity — in the original query 'after episode 5' is implemented as No. in season > 5 and the >13M test applies to each episode before grouping (so count is number of qualifying episodes across the dataset), but the same question could instead be read as asking about episode 5 in the whole series (No. in series), asking for directors who had multiple such episodes within a single season, or asking for directors whose average viewers exceed 13M rather than individual episodes exceeding 13M.",reserved,9,reward,,"type: Scope / Attachment ambiguity | explanation: The SQL treats 'after episode 5' as No. in season > 5 and applies the >13M filter to each episode before grouping (counting qualifying episodes per director across the dataset). A reader could instead interpret 'after episode 5' as the 5th episode in the whole series (No. in series), interpret 'more than one' as within a single season rather than across the series, or interpret 'over 13 million' as referring to a director's average rather than each episode."
"For each Director, after joining the table to itself on t.`No. in series` = t2.`No. in series`, what is the Director, the COUNT(*) as EpisodeCount, the MIN(t.`No. in series`) as FirstSeriesNo, the MAX(t.`No. in series`) as LastSeriesNo, the MIN(t.`Title`) as FirstTitle and the MAX(t.`Title`) as LastTitle for rows satisfying t.`No. in series` > 100 OR (t2.`No. in season` < 33 AND t.`No. in season` > 10), grouped by Director, ordered by EpisodeCount descending, limited to the top 5 results?","
SELECT `t`.`Director`, COUNT(*) `EpisodeCount`, '`' || MIN(`t`.`No. in series`) || '`' `FirstSeriesNo`, '`' || MAX(`t`.`No. in series`) || '`' `LastSeriesNo`, '`' || MIN(`t`.`Title`) || '`' `FirstTitle`, '`' || MAX(`t`.`Title`) || '`' `LastTitle`
FROM `table_1_10953197_4` t JOIN `table_1_10953197_4` t2 ON t.`No. in series` = t2.`No. in series`
WHERE t.`No. in series` > 100 OR t2.`No. in season` < 33 AND t.`No. in season` > 10
GROUP BY t.`Director`
ORDER BY COUNT(*) DESC
LIMIT 5;
","SELECT col3, COUNT(*) AS `EpisodeCount`, MIN(col0) AS `FirstSeriesNo`, MAX(col0) AS `LastSeriesNo`, MIN(col2) AS `FirstTitle`, MAX(col2) AS `LastTitle`
FROM `table_1_10953197_4` AS t
WHERE col0 > 100 OR (col1 < 33 AND col1 > 10)
GROUP BY col3
ORDER BY `EpisodeCount` DESC
LIMIT 5;","[('charles correll', 7, 101.0, 129.0, '""amanda unplugged""', '""the brooke stops here""'), ('richard lang', 5, 104.0, 124.0, '""dial m for melrose""', '""what comes up, must come down""'), ('chip chalmers', 5, 103.0, 127.0, '""el syd""', '""sydney, bothered and bewildered""'), ('janet greek', 3, 110.0, 123.0, '""the circle of strife""', '""two flew over the cuckoo\'s nest""'), ('frank south', 2, 115.0, 128.0, '""full metal betsy""', '""the bobby trap""')]",table_1_10953197_4,"1) Parse intent: the query selects Director, COUNT(*), MIN/ MAX of No. in series and Title, from a self-joined table with a WHERE filter, grouped by Director, ordered by count desc, limited to 5. 2) Map schema: No. in series and No. in season are numeric episode indices, Title is episode title, Director is grouped. 3) Draft: produce a question that requests those exact aggregates, the self-join condition, the WHERE condition with its AND/OR logic, grouping, ordering and limit. 4) Validate: the question mentions Director, COUNT(*) as EpisodeCount, MIN/MAX of No. in series and Title, the join on No. in series, the WHERE expression, GROUP BY Director, ORDER BY COUNT(*) DESC and LIMIT 5.",reserved,12,reward,,
"For each Count Palatine of Saxony (output column named ""Frederick II, Elector of Saxony""), what is the COUNT(*) as Cases when Cases > 1, returning up to 10 rows ordered by Cases in descending order?","
WITH totals AS (
  SELECT `Count Palatine of Saxony` AS `Frederick II, Elector of Saxony`, COUNT(*) AS `Cases`
  FROM `table_1_11071897_1`
  GROUP BY `Count Palatine of Saxony`
)
SELECT `Frederick II, Elector of Saxony`, `Cases`
FROM totals
WHERE `Cases` > 1
ORDER BY `Cases` DESC
LIMIT 10;
","
WITH totals AS (
  SELECT col3 AS `Frederick II, Elector of Saxony`, COUNT(*) AS `Cases`
  FROM `table_1_11071897_1`
  GROUP BY col3
)
SELECT `Frederick II, Elector of Saxony`, `Cases`
FROM totals
WHERE `Cases` > 1
ORDER BY `Cases` DESC
LIMIT 10;
","[('frederick augustus ii, elector of saxony', 2), ('frederick ii, elector of saxony', 2), ('john george i, elector of saxony', 2)]",table_1_11071897_1,"1) Parse intent: select grouped `Count Palatine of Saxony` and COUNT(*) as `Cases`, filter Cases>1, order descending, limit 10. 2) Map schema: grouped column labeled `Frederick II, Elector of Saxony`, aggregate labeled `Cases`. 3) Draft question: request for each Count Palatine of Saxony (alias given) the COUNT(*) as Cases where Cases>1, ordered by Cases desc, top 10. 4) Validate: question captures every column, calculation, filter, ordering and limit from the query.",reserved,14,reward,,
"For each NYC borough in 1932, who finished first and second (with party), what were their vote totals and percentages, what was the raw vote and percent margin, what was the borough's total votes, and was the winner a third-party/write-in or was the race tight or did a Socialist/write-in hit double digits?","
WITH totals AS (
  SELECT
    `1932 (before recount)` AS candidate,
    `party` AS party,
    CAST(REPLACE(`Manhattan`, ',', '') AS INTEGER) AS Manhattan_votes,
    CAST(REPLACE(`The Bronx`, ',', '') AS INTEGER) AS The_Bronx_votes,
    CAST(REPLACE(`Brooklyn`, ',', '') AS INTEGER) AS Brooklyn_votes,
    CAST(REPLACE(`Queens`, ',', '') AS INTEGER) AS Queens_votes,
    CAST(REPLACE(`Richmond [Staten Is.]`, ',', '') AS INTEGER) AS Richmond_votes,
    CAST(REPLACE(`Total`, ',', '') AS INTEGER) AS Total_votes
  FROM `table_1_1108394_43`
  WHERE instr(`Manhattan`, '%') = 0
),
percents AS (
  SELECT
    `1932 (before recount)` AS candidate,
    `party` AS party,
    CAST(REPLACE(`Manhattan`, '%', '') AS REAL) AS Manhattan_pct,
    CAST(REPLACE(`The Bronx`, '%', '') AS REAL) AS The_Bronx_pct,
    CAST(REPLACE(`Brooklyn`, '%', '') AS REAL) AS Brooklyn_pct,
    CAST(REPLACE(`Queens`, '%', '') AS REAL) AS Queens_pct,
    CAST(REPLACE(`Richmond [Staten Is.]`, '%', '') AS REAL) AS Richmond_pct
  FROM `table_1_1108394_43`
  WHERE instr(`Manhattan`, '%') > 0
),
candidates AS (
  SELECT
    t.candidate,
    t.party,
    t.Manhattan_votes,
    t.The_Bronx_votes,
    t.Brooklyn_votes,
    t.Queens_votes,
    t.Richmond_votes,
    t.Total_votes,
    p.Manhattan_pct,
    p.The_Bronx_pct,
    p.Brooklyn_pct,
    p.Queens_pct,
    p.Richmond_pct
  FROM totals t
  JOIN percents p ON t.candidate = p.candidate AND t.party = p.party
),
borough_totals AS (
  SELECT 'Manhattan' AS borough, SUM(Manhattan_votes) AS borough_total FROM candidates UNION ALL
  SELECT 'The Bronx', SUM(The_Bronx_votes) FROM candidates UNION ALL
  SELECT 'Brooklyn', SUM(Brooklyn_votes) FROM candidates UNION ALL
  SELECT 'Queens', SUM(Queens_votes) FROM candidates UNION ALL
  SELECT 'Richmond [Staten Is.]', SUM(Richmond_votes) FROM candidates
)
SELECT
  bt.borough,
  bt.borough_total,
  -- top candidate info
  (SELECT candidate FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC
   LIMIT 1) AS top_candidate,
  (SELECT party FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC
   LIMIT 1) AS top_party,
  (SELECT CASE bt.borough
     WHEN 'Manhattan' THEN Manhattan_votes
     WHEN 'The Bronx' THEN The_Bronx_votes
     WHEN 'Brooklyn' THEN Brooklyn_votes
     WHEN 'Queens' THEN Queens_votes
     WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
   END FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1) AS top_votes,
  (SELECT CASE bt.borough
     WHEN 'Manhattan' THEN Manhattan_pct
     WHEN 'The Bronx' THEN The_Bronx_pct
     WHEN 'Brooklyn' THEN Brooklyn_pct
     WHEN 'Queens' THEN Queens_pct
     WHEN 'Richmond [Staten Is.]' THEN Richmond_pct
   END FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1) AS top_pct,
  -- runner-up info
  (SELECT candidate FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1 OFFSET 1) AS runnerup_candidate,
  (SELECT party FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1 OFFSET 1) AS runnerup_party,
  (SELECT CASE bt.borough
     WHEN 'Manhattan' THEN Manhattan_votes
     WHEN 'The Bronx' THEN The_Bronx_votes
     WHEN 'Brooklyn' THEN Brooklyn_votes
     WHEN 'Queens' THEN Queens_votes
     WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
   END FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1 OFFSET 1) AS runnerup_votes,
  (SELECT CASE bt.borough
     WHEN 'Manhattan' THEN Manhattan_pct
     WHEN 'The Bronx' THEN The_Bronx_pct
     WHEN 'Brooklyn' THEN Brooklyn_pct
     WHEN 'Queens' THEN Queens_pct
     WHEN 'Richmond [Staten Is.]' THEN Richmond_pct
   END FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1 OFFSET 1) AS runnerup_pct,
  -- margins and flags
  ((SELECT CASE bt.borough
     WHEN 'Manhattan' THEN Manhattan_votes
     WHEN 'The Bronx' THEN The_Bronx_votes
     WHEN 'Brooklyn' THEN Brooklyn_votes
     WHEN 'Queens' THEN Queens_votes
     WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
   END FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1)
   -
   (SELECT CASE bt.borough
     WHEN 'Manhattan' THEN Manhattan_votes
     WHEN 'The Bronx' THEN The_Bronx_votes
     WHEN 'Brooklyn' THEN Brooklyn_votes
     WHEN 'Queens' THEN Queens_votes
     WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
   END FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1 OFFSET 1)
  ) AS vote_margin,
  (
   (SELECT CASE bt.borough
     WHEN 'Manhattan' THEN Manhattan_pct
     WHEN 'The Bronx' THEN The_Bronx_pct
     WHEN 'Brooklyn' THEN Brooklyn_pct
     WHEN 'Queens' THEN Queens_pct
     WHEN 'Richmond [Staten Is.]' THEN Richmond_pct
   END FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1)
   -
   (SELECT CASE bt.borough
     WHEN 'Manhattan' THEN Manhattan_pct
     WHEN 'The Bronx' THEN The_Bronx_pct
     WHEN 'Brooklyn' THEN Brooklyn_pct
     WHEN 'Queens' THEN Queens_pct
     WHEN 'Richmond [Staten Is.]' THEN Richmond_pct
   END FROM candidates ORDER BY
     CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END DESC LIMIT 1 OFFSET 1)
  ) AS pct_margin,
  ROUND(
    100.0 * (
      ((SELECT CASE bt.borough
         WHEN 'Manhattan' THEN Manhattan_votes
         WHEN 'The Bronx' THEN The_Bronx_votes
         WHEN 'Brooklyn' THEN Brooklyn_votes
         WHEN 'Queens' THEN Queens_votes
         WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
       END FROM candidates ORDER BY
         CASE bt.borough
           WHEN 'Manhattan' THEN Manhattan_votes
           WHEN 'The Bronx' THEN The_Bronx_votes
           WHEN 'Brooklyn' THEN Brooklyn_votes
           WHEN 'Queens' THEN Queens_votes
           WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
         END DESC LIMIT 1)
       -
       (SELECT CASE bt.borough
         WHEN 'Manhattan' THEN Manhattan_votes
         WHEN 'The Bronx' THEN The_Bronx_votes
         WHEN 'Brooklyn' THEN Brooklyn_votes
         WHEN 'Queens' THEN Queens_votes
         WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
       END FROM candidates ORDER BY
         CASE bt.borough
           WHEN 'Manhattan' THEN Manhattan_votes
           WHEN 'The Bronx' THEN The_Bronx_votes
           WHEN 'Brooklyn' THEN Brooklyn_votes
           WHEN 'Queens' THEN Queens_votes
           WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
         END DESC LIMIT 1 OFFSET 1)
      ) / bt.borough_total
    ), 2
  ) AS margin_pct_of_borough,
  CASE WHEN
    (SELECT party FROM candidates ORDER BY
      CASE bt.borough
        WHEN 'Manhattan' THEN Manhattan_votes
        WHEN 'The Bronx' THEN The_Bronx_votes
        WHEN 'Brooklyn' THEN Brooklyn_votes
        WHEN 'Queens' THEN Queens_votes
        WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
      END DESC LIMIT 1) NOT IN ('Democratic','Republican')
  THEN 1 ELSE 0 END AS top_is_third_party_or_writein,
  CASE WHEN ABS(
    (SELECT CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END FROM candidates ORDER BY
       CASE bt.borough
         WHEN 'Manhattan' THEN Manhattan_votes
         WHEN 'The Bronx' THEN The_Bronx_votes
         WHEN 'Brooklyn' THEN Brooklyn_votes
         WHEN 'Queens' THEN Queens_votes
         WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
       END DESC LIMIT 1)
    -
    (SELECT CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_votes
       WHEN 'The Bronx' THEN The_Bronx_votes
       WHEN 'Brooklyn' THEN Brooklyn_votes
       WHEN 'Queens' THEN Queens_votes
       WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
     END FROM candidates ORDER BY
       CASE bt.borough
         WHEN 'Manhattan' THEN Manhattan_votes
         WHEN 'The Bronx' THEN The_Bronx_votes
         WHEN 'Brooklyn' THEN Brooklyn_votes
         WHEN 'Queens' THEN Queens_votes
         WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
       END DESC LIMIT 1 OFFSET 1)
  ) * 1.0 / bt.borough_total * 100) <= 5 THEN 1 ELSE 0 END AS tight_margin_flag,
  CASE WHEN
    ((SELECT party FROM candidates ORDER BY
       CASE bt.borough
         WHEN 'Manhattan' THEN Manhattan_votes
         WHEN 'The Bronx' THEN The_Bronx_votes
         WHEN 'Brooklyn' THEN Brooklyn_votes
         WHEN 'Queens' THEN Queens_votes
         WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
       END DESC LIMIT 1) IN ('Socialist','Independent (write-in)') AND
     (SELECT CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_pct
       WHEN 'The Bronx' THEN The_Bronx_pct
       WHEN 'Brooklyn' THEN Brooklyn_pct
       WHEN 'Queens' THEN Queens_pct
       WHEN 'Richmond [Staten Is.]' THEN Richmond_pct
     END FROM candidates ORDER BY
       CASE bt.borough
         WHEN 'Manhattan' THEN Manhattan_votes
         WHEN 'The Bronx' THEN The_Bronx_votes
         WHEN 'Brooklyn' THEN Brooklyn_votes
         WHEN 'Queens' THEN Queens_votes
         WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
       END DESC LIMIT 1) >= 10)
    OR
    ((SELECT party FROM candidates ORDER BY
       CASE bt.borough
         WHEN 'Manhattan' THEN Manhattan_votes
         WHEN 'The Bronx' THEN The_Bronx_votes
         WHEN 'Brooklyn' THEN Brooklyn_votes
         WHEN 'Queens' THEN Queens_votes
         WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
       END DESC LIMIT 1 OFFSET 1) IN ('Socialist','Independent (write-in)') AND
     (SELECT CASE bt.borough
       WHEN 'Manhattan' THEN Manhattan_pct
       WHEN 'The Bronx' THEN The_Bronx_pct
       WHEN 'Brooklyn' THEN Brooklyn_pct
       WHEN 'Queens' THEN Queens_pct
       WHEN 'Richmond [Staten Is.]' THEN Richmond_pct
     END FROM candidates ORDER BY
       CASE bt.borough
         WHEN 'Manhattan' THEN Manhattan_votes
         WHEN 'The Bronx' THEN The_Bronx_votes
         WHEN 'Brooklyn' THEN Brooklyn_votes
         WHEN 'Queens' THEN Queens_votes
         WHEN 'Richmond [Staten Is.]' THEN Richmond_votes
       END DESC LIMIT 1 OFFSET 1) >= 10)
  THEN 1 ELSE 0 END AS notable_third_party_overperformance
FROM borough_totals bt;
","WITH votes AS (
  SELECT
    col0 AS candidate,
    col1 AS party,
    CAST(REPLACE(col2, ',', '') AS INTEGER) AS Manhattan,
    CAST(REPLACE(col3, ',', '') AS INTEGER) AS The_Bronx,
    CAST(REPLACE(col4, ',', '') AS INTEGER) AS Brooklyn,
    CAST(REPLACE(col5, ',', '') AS INTEGER) AS Queens,
    CAST(REPLACE(col6, ',', '') AS INTEGER) AS Richmond
  FROM `table_1_1108394_43`
  WHERE instr(col2, '%') = 0
)
SELECT
  'Manhattan' AS borough,
  (SELECT candidate FROM votes ORDER BY Manhattan DESC LIMIT 1) AS top_candidate,
  (SELECT party FROM votes ORDER BY Manhattan DESC LIMIT 1) AS top_party,
  (SELECT Manhattan FROM votes ORDER BY Manhattan DESC LIMIT 1) AS top_votes,
  (SELECT candidate FROM votes ORDER BY Manhattan DESC LIMIT 1 OFFSET 1) AS runnerup_candidate,
  (SELECT party FROM votes ORDER BY Manhattan DESC LIMIT 1 OFFSET 1) AS runnerup_party,
  (SELECT Manhattan FROM votes ORDER BY Manhattan DESC LIMIT 1 OFFSET 1) AS runnerup_votes,
  ( (SELECT Manhattan FROM votes ORDER BY Manhattan DESC LIMIT 1) - (SELECT Manhattan FROM votes ORDER BY Manhattan DESC LIMIT 1 OFFSET 1) ) AS vote_margin
UNION ALL
SELECT
  'The Bronx' AS borough,
  (SELECT candidate FROM votes ORDER BY The_Bronx DESC LIMIT 1),
  (SELECT party FROM votes ORDER BY The_Bronx DESC LIMIT 1),
  (SELECT The_Bronx FROM votes ORDER BY The_Bronx DESC LIMIT 1),
  (SELECT candidate FROM votes ORDER BY The_Bronx DESC LIMIT 1 OFFSET 1),
  (SELECT party FROM votes ORDER BY The_Bronx DESC LIMIT 1 OFFSET 1),
  (SELECT The_Bronx FROM votes ORDER BY The_Bronx DESC LIMIT 1 OFFSET 1),
  ( (SELECT The_Bronx FROM votes ORDER BY The_Bronx DESC LIMIT 1) - (SELECT The_Bronx FROM votes ORDER BY The_Bronx DESC LIMIT 1 OFFSET 1) )
UNION ALL
SELECT
  'Brooklyn' AS borough,
  (SELECT candidate FROM votes ORDER BY Brooklyn DESC LIMIT 1),
  (SELECT party FROM votes ORDER BY Brooklyn DESC LIMIT 1),
  (SELECT Brooklyn FROM votes ORDER BY Brooklyn DESC LIMIT 1),
  (SELECT candidate FROM votes ORDER BY Brooklyn DESC LIMIT 1 OFFSET 1),
  (SELECT party FROM votes ORDER BY Brooklyn DESC LIMIT 1 OFFSET 1),
  (SELECT Brooklyn FROM votes ORDER BY Brooklyn DESC LIMIT 1 OFFSET 1),
  ( (SELECT Brooklyn FROM votes ORDER BY Brooklyn DESC LIMIT 1) - (SELECT Brooklyn FROM votes ORDER BY Brooklyn DESC LIMIT 1 OFFSET 1) )
UNION ALL
SELECT
  'Queens' AS borough,
  (SELECT candidate FROM votes ORDER BY Queens DESC LIMIT 1),
  (SELECT party FROM votes ORDER BY Queens DESC LIMIT 1),
  (SELECT Queens FROM votes ORDER BY Queens DESC LIMIT 1),
  (SELECT candidate FROM votes ORDER BY Queens DESC LIMIT 1 OFFSET 1),
  (SELECT party FROM votes ORDER BY Queens DESC LIMIT 1 OFFSET 1),
  (SELECT Queens FROM votes ORDER BY Queens DESC LIMIT 1 OFFSET 1),
  ( (SELECT Queens FROM votes ORDER BY Queens DESC LIMIT 1) - (SELECT Queens FROM votes ORDER BY Queens DESC LIMIT 1 OFFSET 1) )
UNION ALL
SELECT
  'Richmond [Staten Is.]' AS borough,
  (SELECT candidate FROM votes ORDER BY Richmond DESC LIMIT 1),
  (SELECT party FROM votes ORDER BY Richmond DESC LIMIT 1),
  (SELECT Richmond FROM votes ORDER BY Richmond DESC LIMIT 1),
  (SELECT candidate FROM votes ORDER BY Richmond DESC LIMIT 1 OFFSET 1),
  (SELECT party FROM votes ORDER BY Richmond DESC LIMIT 1 OFFSET 1),
  (SELECT Richmond FROM votes ORDER BY Richmond DESC LIMIT 1 OFFSET 1),
  ( (SELECT Richmond FROM votes ORDER BY Richmond DESC LIMIT 1) - (SELECT Richmond FROM votes ORDER BY Richmond DESC LIMIT 1 OFFSET 1) )
;","[('Manhattan', ""john p. o'brien"", 'democratic', 308944, 'lewis h. pounds', 'republican', 116729, 192215), ('The Bronx', ""john p. o'brien"", 'democratic', 181639, 'morris hillquit', 'socialist', 68980, 112659), ('Brooklyn', ""john p. o'brien"", 'democratic', 358945, 'lewis h. pounds', 'republican', 157152, 201793), ('Queens', ""john p. o'brien"", 'democratic', 176070, 'lewis h. pounds', 'republican', 105068, 71002), ('Richmond [Staten Is.]', ""john p. o'brien"", 'democratic', 30517, 'lewis h. pounds', 'republican', 16586, 13931)]",table_1_1108394_43,"The persona is a historian/producer who knows enough about the data to ask for borough-level winners and margins but will phrase requests in plain terms. The SQL pulls per-borough totals and then finds the top and second-place candidates, their parties, votes and percentages, plus vote and percent margins and flags for third-party/write-in winners and tight races. The schema maps candidate and party rows with separate vote and percent rows for each borough and a total column, summing votes across candidates to get borough totals. Draft question: For each NYC borough in the 1932 mayoral race, who finished first and second (with party), what were their vote totals and percentages, what was the raw vote and percent margin, what was the borough's total votes, and is the winner a third-party/write-in or was the margin tight or did a Socialist/write-in hit double digits? Validate: This asks exactly for the top/runner-up, their votes/pcts, margins, borough totals, and the three flags the query computes.",persona,"""Goals"": [ ""Identify which candidate carried each borough in 1932 and by roughly how many votes, so scenes can be anchored to clear local winners."", ""Find tight or unusual borough-level margins (and instances where third-party or write-in candidates overperformed) to craft dramatic narrative beats for specific stops."", ""Extract vote totals and percentage lines for a given candidate (especially the Independent write-in Joseph V. McKee and the Socialist Morris Hillquit) to create accurate, character-driven scripts and signage."" ], ""Example queries"": [ ""/* Find the top vote-getter in each borough by selecting and ordering rows per borough (repeat pattern for each borough) */\n(SELECT 'Manhattan' AS borough, \""1932 (before recount)\"" AS candidate, \""party\"", REPLACE(\""Manhattan\"", ',', '') AS votes\n FROM table_1_1108394_43\n ORDER BY CAST(REPLACE(\""Manhattan\"", ',', '') AS INTEGER) DESC\n LIMIT 1)\nUNION ALL\n(SELECT 'The Bronx' AS borough, \""1932 (before recount)\"" AS candidate, \""party\"", REPLACE(\""The Bronx\"", ',', '') AS votes\n FROM table_1_1108394_43\n ORDER BY CAST(REPLACE(\""The Bronx\"", ',', '') AS INTEGER) DESC\n LIMIT 1)\nUNION ALL\n(SELECT 'Brooklyn' AS borough, \""1932 (before recount)\"" AS candidate, \""party\"", REPLACE(\""Brooklyn\"", ',', '') AS votes\n FROM table_1_1108394_43\n ORDER BY CAST(REPLACE(\""Brooklyn\"", ',', '') AS INTEGER) DESC\n LIMIT 1)\nUNION ALL\n(SELECT 'Queens' AS borough, \""1932 (before recount)\"" AS candidate, \""party\"", REPLACE(\""Queens\"", ',', '') AS votes\n FROM table_1_1108394_43\n ORDER BY CAST(REPLACE(\""Queens\"", ',', '') AS INTEGER) DESC\n LIMIT 1)\nUNION ALL\n(SELECT 'Richmond [Staten Is.]' AS borough, \""1932 (before recount)\"" AS candidate, \""party\"", REPLACE(\""Richmond [Staten Is.]\"", ',', '') AS votes\n FROM table_1_1108394_43\n ORDER BY CAST(REPLACE(\""Richmond [Staten Is.]\"", ',', '') AS INTEGER) DESC\n LIMIT 1);"", ""/* Compute Democratic minus Republican vote margin per borough to identify where the race was closest or where Democrats dominated */\nSELECT\n  'Manhattan' AS borough,\n  CAST(REPLACE(d.\""Manhattan\"", ',', '') AS INTEGER) - CAST(REPLACE(r.\""Manhattan\"", ',', '') AS INTEGER) AS dem_minus_rep\nFROM table_1_1108394_43 AS d\nJOIN table_1_1108394_43 AS r ON 1=1\nWHERE d.\""party\"" = 'Democratic' AND r.\""party\"" = 'Republican'\nUNION ALL\nSELECT\n  'Brooklyn' AS borough,\n  CAST(REPLACE(d.\""Brooklyn\"", ',', '') AS INTEGER) - CAST(REPLACE(r.\""Brooklyn\"", ',', '') AS INTEGER) AS dem_minus_rep\nFROM table_1_1108394_43 AS d\nJOIN table_1_1108394_43 AS r ON 1=1\nWHERE d.\""party\"" = 'Democratic' AND r.\""party\"" = 'Republican';"", ""/* Pull all rows for Joseph V. McKee and Morris Hillquit (vote totals and percentage rows) so the tour script can quote borough-specific percentages and totals */\nSELECT \""1932 (before recount)\"" AS candidate, \""party\"", \""Manhattan\"", \""The Bronx\"", \""Brooklyn\"", \""Queens\"", \""Richmond [Staten Is.]\"", \""Total\"", \""%\""\nFROM table_1_1108394_43\nWHERE \""1932 (before recount)\"" IN ('Joseph V. McKee', 'Morris Hillquit')\n   OR \""party\"" ILIKE '%write-in%';"" } ``` Goals:  Example Queries: ",reward,,
"Over the entire table, what are COUNT(*), SUM((U.S. viewers (million) + 0.0) > 3.0), 100.0 * SUM((U.S. viewers (million) + 0.0) > 3.0) / COUNT(*), AVG(U.S. viewers (million) + 0.0), and the literal outputs '""Winds of War""' and 'March 4, 2012'?","
SELECT COUNT(*), SUM((`U.S. viewers (million)` + 0.0) > 3.0), 100.0 * SUM((`U.S. viewers (million)` + 0.0) > 3.0) / COUNT(*), AVG(`U.S. viewers (million)` + 0.0), '`""Winds of War""`', '`March 4, 2012`' FROM `table_1_11111116_7` WHERE 1=1;
","
SELECT COUNT(*), SUM((col6 + 0.0) > 3.0), 100.0 * SUM((col6 + 0.0) > 3.0) / COUNT(*), AVG(col6 + 0.0), '`""Winds of War""`', '`March 4, 2012`' FROM `table_1_11111116_7` WHERE 1=1;
","[(22, 12, 54.54545454545455, 3.075454545454545, '`""Winds of War""`', '`March 4, 2012`')]",table_1_11111116_7,"1) Parse intent: compute overall row count, count of rows where (U.S. viewers (million)+0.0) exceeds 3.0, that count as a percentage of total, the numeric average of U.S. viewers (million), and return the exact strings '""Winds of War""' and 'March 4, 2012'. 2) Map schema: identify U.S. viewers (million) as the column used in the >3.0 predicate and AVG after adding 0.0. 3) Draft: ask a question that requests these aggregates and the two literal values. 4) Validate: ensure no extra information beyond the SQL is introduced and all SQL expressions are represented.",reserved,3,reward,,
Which division has the highest goals per appearance with at least 30 league appearances?,"
SELECT `Division`,
       SUM(`League Apps (Sub)` + 0) `Total League Apps`,
       SUM(`League Goals`) `Total League Goals`,
       (SUM(`FA Cup Goals` + 0) + SUM(`FL Cup Goals` + 0) + SUM(`Other Goals` + 0)) `Cup+Other Goals`,
       SUM(REPLACE(REPLACE(REPLACE(`Total Apps (Sub)`, '(', ''), ')', ''), ' ', '') + 0) `Total Apps`,
       ROUND(SUM(`Total Goals`) * 1.0 / SUM(REPLACE(REPLACE(REPLACE(`Total Apps (Sub)`, '(', ''), ')', ''), ' ', '') + 0), 3) `Goals per App`
FROM `table_1_1112176_1`
WHERE `League Apps (Sub)` + 0 >= 30
GROUP BY `Division`
ORDER BY `Goals per App` DESC
LIMIT 5;
","
SELECT col1,
       SUM(col2 + 0) `Total League Apps`,
       SUM(col3) `Total League Goals`,
       (SUM(col5 + 0) + SUM(col7 + 0) + SUM(col9 + 0)) `Cup+Other Goals`,
       SUM(REPLACE(REPLACE(REPLACE(col10, '(', ''), ')', ''), ' ', '') + 0) `Total Apps`,
       ROUND(SUM(col11) * 1.0 / SUM(REPLACE(REPLACE(REPLACE(col10, '(', ''), ')', ''), ' ', '') + 0), 3) `Goals per App`
FROM `table_1_1112176_1`
WHERE col2 + 0 >= 30
GROUP BY col1
ORDER BY `Goals per App` DESC
LIMIT 5;
","[('one', 152.0, 19.0, 9.0, 190, 0.147), ('two', 119.0, 25.0, 1.0, 487, 0.053)]",table_1_1112176_1,"STEP 1: Parse the SQL intent — group rows by Division, include only rows where League Apps (Sub) >= 30, compute summed League Apps, summed League Goals, summed Cup+Other Goals, summed Total Apps (after stripping parentheses/spaces), and Goals per App = SUM(Total Goals) / SUM(Total Apps); order divisions by Goals per App descending and return top 5. STEP 2: Determine ambiguity type — scope/attachment ambiguity fits best: the qualifier ""with at least 30 league appearances"" can reasonably attach either to individual season rows (row-level filter, which the SQL uses) or to the aggregated division totals (group-level filter). STEP 3: Draft the question — ""Which division has the highest goals per appearance with at least 30 league appearances?"" STEP 4: Explain ambiguity — in the original SQL the clause applies at the row/season level (only seasons with >=30 league apps are included in the division aggregates). An alternative reading is that the 30-app threshold should apply to the division totals (only include divisions whose summed league apps are >=30), which would change which divisions are considered and potentially the ranking.",reserved,8,reward,,"type: Scope/attachment ambiguity | explanation: The phrase ""with at least 30 league appearances"" can attach to individual seasons (the SQL's interpretation: only seasons/rows with >=30 league apps are included before aggregation) or to divisions (an alternative: only include divisions whose total league apps across seasons reach >=30), producing different sets of data and possibly different top divisions."
"Restricting to records where Year of affiliation is not 'N/A' or Owned since is not 'N/A' and to City of license/Market IN ('Los Angeles','Newark - New York City'), for each City of license/Market (grouped by City of license/Market) what is the City of license/Market, how many Stations (COUNT(*)), how many are Affiliated_2002 (SUM(Year of affiliation = '2002')), how many are Owned_2002 (SUM(Owned since = '2002')), and what is Pct Affiliated 2002 computed as ROUND(100.0 * SUM(Year of affiliation = '2002') / COUNT(*), 2), including only cities with more than zero stations and returning at most 5 rows?","
SELECT `City of license/Market`,
       COUNT(*) `Stations`,
       SUM(`Year of affiliation` = '2002') `Affiliated_2002`,
       SUM(`Owned since` = '2002') `Owned_2002`,
       ROUND(100.0 * SUM(`Year of affiliation` = '2002') / COUNT(*),2) AS `Pct Affiliated 2002`
FROM `table_1_11147852_1`
WHERE (`Year of affiliation` != 'N/A' OR `Owned since` != 'N/A')
  AND `City of license/Market` IN ('Los Angeles','Newark - New York City')
GROUP BY `City of license/Market`
HAVING COUNT(*) > 0
LIMIT 5;
","SELECT col0 AS `City`,
       COUNT(*) AS `Stations`,
       SUM(col3 = '2002') AS `Affiliated_2002`,
       SUM(col4 = '2002') AS `Owned_2002`,
       ROUND(100.0 * SUM(col3 = '2002') / COUNT(*), 2) AS `Pct Affiliated 2002`
FROM `table_1_11147852_1`
WHERE col3 = '2002'
GROUP BY col0
ORDER BY `City` ASC
LIMIT 5;","[('atlanta', 1, 1, 1, 100.0), ('austin, texas', 1, 1, 1, 100.0), ('boston', 1, 1, 1, 100.0), ('dallas - fort worth', 1, 1, 1, 100.0), ('joliet - chicago', 1, 1, 1, 100.0)]",table_1_11147852_1,"Parse: query filters to two city names and non-'N/A' records, groups by City of license/Market, produces count of stations, counts where Year of affiliation = '2002' and Owned since = '2002', computes a 2-decimal percent of affiliations in 2002, and applies HAVING COUNT(*)>0 and LIMIT 5. Map: map boolean SUMs and rounding to natural language. Draft: request those aggregates, filters, grouping, and limit explicitly. Validate: confirm all selected fields, calculations, the OR condition, IN list, GROUP BY, HAVING, and LIMIT are present.",reserved,11,reward,,
"Restricting to rows where Trim is present (non-empty), what are: the number of Turbo models (rows where Turbo contains 'Yes'); the number of Turbo entries that mention 'Mitsubishi'; and the quick actionable list of turbo Trims for manual review: 2.0 T-5 (some EU countries only), 2.4T, 850 R (Auto), 850 R (Manual)?","
SELECT '`Turbo` models count: ' || SUM((INSTR(`Turbo`, 'Yes')>0)) || '; `Turbo` entries mentioning `Mitsubishi`: ' || SUM((INSTR(`Turbo`, 'Mitsubishi')>0)) || '; Quick actionable list of turbo `Trim`s (manual review): `2.0 T-5 (some EU countries only)`, `2.4T`, `850 R (Auto)`, `850 R (Manual)`' FROM `table_1_11167610_1` WHERE LENGTH(`Trim`)>0 LIMIT 1;
","
SELECT 'col2 models count: ' || SUM((INSTR(col2, 'Yes')>0)) || '; col2 entries mentioning `Mitsubishi`: ' || SUM((INSTR(col2, 'Mitsubishi')>0)) || '; Quick actionable list of turbo col0s (manual review): `2.0 T-5 (some EU countries only)`, `2.4T`, `850 R (Auto)`, `850 R (Manual)`' FROM `table_1_11167610_1` WHERE LENGTH(col0)>0 LIMIT 1;
","[('col2 models count: 0; col2 entries mentioning `Mitsubishi`: 0; Quick actionable list of turbo col0s (manual review): `2.0 T-5 (some EU countries only)`, `2.4T`, `850 R (Auto)`, `850 R (Manual)`',)]",table_1_11167610_1,"1) Parse intent: compute sums of boolean checks for 'Yes' and 'Mitsubishi' within Turbo and present a pre-specified list of turbo Trims. 2) Map schema: checks are applied to the Turbo column and the query filters to rows with a Trim value. 3) Draft: formulate a question that asks for those two counts and the given turbo Trim list, noting the non-empty Trim requirement. 4) Validate: the question mirrors the SQL calculations and includes the exact list for manual review.",reserved,4,reward,,
"Which five rows have the highest (( '4 credits' - '1 credit' ) * 1.0 / '1 credit' ) values among Hands with '1 credit' > 0, and for each show Hand, '1 credit', '2 credits', '3 credits', '4 credits', '5 credits', diff_4_1 = ('4 credits' - '1 credit') and pct_increase_4_over_1 = (( '4 credits' - '1 credit' ) * 1.0 / '1 credit')?","
SELECT `Hand`, `1 credit`, `2 credits`, `3 credits`, `4 credits`, `5 credits`, (`4 credits` - `1 credit`) AS `diff_4_1`, ((`4 credits` - `1 credit`) * 1.0 / `1 credit`) `pct_increase_4_over_1`
FROM `table_1_11200856_1`
WHERE `1 credit` > 0
GROUP BY `Hand`
ORDER BY ((`4 credits` - `1 credit`) * 1.0 / `1 credit`) * -1
LIMIT 5;
","
SELECT col0, col1, col2, col3, col4, col5, (col4 - col1) AS `diff_4_1`, ((col4 - col1) * 1.0 / col1) `pct_increase_4_over_1`
FROM `table_1_11200856_1`
WHERE col1 > 0
GROUP BY col0
ORDER BY ((col4 - col1) * 1.0 / col1) * -1
LIMIT 5;
","[('flush', 5.0, 10.0, 15.0, 20.0, '25', 15.0, 3.0), ('four aces', 400.0, 800.0, 1200.0, 1600.0, '2000', 1200.0, 3.0), ('four of a kind, 2-4', 100.0, 200.0, 300.0, 400.0, '500', 300.0, 3.0), ('four of a kind, 5-k', 50.0, 100.0, 150.0, 200.0, '250', 150.0, 3.0), ('full house', 8.0, 16.0, 24.0, 32.0, '40', 24.0, 3.0)]",table_1_11200856_1,"Parse intent: show the five hands that maximize the percentage increase from one to four credits and display all credit values plus the raw and percent increase. Map schema: include Hand, '1 credit'...'5 credits', calculate diff_4_1 and pct_increase_4_over_1, restrict to '1 credit' > 0 and limit to five. Draft question: request those fields and the ranking by the percentage calculation. Validate: question matches select list, computations, filter, ordering and limit. ",reserved,8,reward,,
"Between 1998 and 2007, report the top three years (by descending year-over-year percent change) in which the Numer of Jamaicans granted British citizenship increased compared with the previous year (including cases where the previous year total was 0); for each year provide Year, the Numer of Jamaicans granted British citizenship as Total, the percentage of Total from Naturalisation by residence (rounded to 2 decimal places), the percentage of Total from Naturalisation by marriage (rounded to 2 decimal places), the percentage of Total from Registration of a minor child (rounded to 2 decimal places), the percentage of Total from Registration by other means (rounded to 2 decimal places), and YoY_% defined as 100.0*(Total this year - Total previous year)/Total previous year rounded to 2 decimal places?","
SELECT
 t.`Year` AS `Year`,
 t.`Numer of Jamaicans granted British citizenship` `Total`,
 ROUND(100.0 * t.`Naturalisation by residence` / t.`Numer of Jamaicans granted British citizenship`,2) `Pct_residence`,
 ROUND(100.0 * t.`Naturalisation by marriage` / t.`Numer of Jamaicans granted British citizenship`,2) `Pct_marriage`,
 ROUND(100.0 * t.`Registration of a minor child` / t.`Numer of Jamaicans granted British citizenship`,2) `Pct_minor`,
 ROUND(100.0 * t.`Registration by other means` / t.`Numer of Jamaicans granted British citizenship`,2) `Pct_other`,
 ROUND(100.0 * (t.`Numer of Jamaicans granted British citizenship` - p.`Numer of Jamaicans granted British citizenship`) / p.`Numer of Jamaicans granted British citizenship`,2) `YoY_%`
FROM `table_1_11214212_1` t
JOIN `table_1_11214212_1` p ON p.`Year` = t.`Year` - 1
WHERE t.`Year` IN (1998,1999,2000,2001,2002,2003,2004,2005,2006,2007) AND (t.`Numer of Jamaicans granted British citizenship` > p.`Numer of Jamaicans granted British citizenship` OR p.`Numer of Jamaicans granted British citizenship` = 0)
GROUP BY t.`Year`
HAVING ROUND(100.0 * (t.`Numer of Jamaicans granted British citizenship` - p.`Numer of Jamaicans granted British citizenship`) / p.`Numer of Jamaicans granted British citizenship`,2) > 0
ORDER BY `YoY_%` DESC
LIMIT 3 OFFSET 0;
","
SELECT
 t.col0 AS col0,
 t.col1 `Total`,
 ROUND(100.0 * t.col2 / t.col1,2) `Pct_residence`,
 ROUND(100.0 * t.col3 / t.col1,2) `Pct_marriage`,
 ROUND(100.0 * t.col4 / t.col1,2) `Pct_minor`,
 ROUND(100.0 * t.col5 / t.col1,2) `Pct_other`,
 ROUND(100.0 * (t.col1 - p.col1) / p.col1,2) `YoY_%`
FROM `table_1_11214212_1` t
JOIN `table_1_11214212_1` p ON p.col0 = t.col0 - 1
WHERE t.col0 IN (1998,1999,2000,2001,2002,2003,2004,2005,2006,2007) AND (t.col1 > p.col1 OR p.col1 = 0)
GROUP BY t.col0
HAVING ROUND(100.0 * (t.col1 - p.col1) / p.col1,2) > 0
ORDER BY `YoY_%` DESC
LIMIT 3 OFFSET 0;
","[(1998.0, 1370.0, 41.68, 41.17, 16.13, 1.02, 87.16), (2003.0, 2795.0, 45.97, 35.24, 18.6, 0.18, 38.02), (2000.0, 1882.0, 49.26, 35.28, 14.93, 0.53, 30.97)]",table_1_11214212_1,"1) Parse SQL intent: compute per-year percentage breakdowns of grant methods and YoY percentage change for 1998–2007, filter to years where total rose versus the prior year (or prior year = 0), then pick the top three by YoY_% descending. 2) Map schema: identify Year, Numer of Jamaicans granted British citizenship (Total) and the four grant-type columns. 3) Draft: ask for Year, Total, each grant type as percent of Total (each percent rounded to 2 decimals), and YoY_% using the given formula rounded to 2 decimals; include year range, positive YoY condition including prior-year-zero, ordering and limit. 4) Validate: question matches all calculations, rounding, filters, and ordering from the SQL.",reserved,16,reward,,
"Which rows should be returned with No. in series, Title, and U.S. viewers (millions) along with the value CAST(U.S. viewers (millions) AS REAL) minus the table average of CAST(U.S. viewers (millions) AS REAL) (showing that difference as 19.90), limited to episodes where CAST(U.S. viewers (millions) AS REAL) > average and sorted by the 19.90 column in descending order?","
SELECT `No. in series`, `Title`, `U.S. viewers (millions)`, CAST(`U.S. viewers (millions)` AS REAL) - t.`avgv` AS `19.90`
FROM `table_1_11230937_2`
JOIN (SELECT AVG(CAST(`U.S. viewers (millions)` AS REAL)) AS `avgv` FROM `table_1_11230937_2`) t
ON 1=1
WHERE CAST(`U.S. viewers (millions)` AS REAL) > t.`avgv`
ORDER BY `19.90` DESC;
","
SELECT col0, col2, col6, CAST(col6 AS REAL) - t.`avgv` AS `19.90`
FROM `table_1_11230937_2`
JOIN (SELECT AVG(CAST(col6 AS REAL)) AS `avgv` FROM `table_1_11230937_2`) t
ON 1=1
WHERE CAST(col6 AS REAL) > t.`avgv`
ORDER BY `19.90` DESC;
","[(112.0, '""man down"" (part 2)', '19.90', 2.312173913043477), (113.0, '""broken home""', '19.23', 1.6421739130434787), (110.0, '""throwing heat""', '18.85', 1.2621739130434797), (105.0, '""darkroom""', '18.77', 1.1821739130434779), (106.0, '""going going gone""', '18.54', 0.9521739130434774), (111.0, '""no man\'s land"" (part 1)', '18.43', 0.842173913043478), (102.0, '""death eminent""', '18.12', 0.5321739130434793), (100.0, '""death pool 100""', '17.90', 0.31217391304347686), (103.0, '""curse of the coffin""', '17.83', 0.24217391304347657), (99.0, '""going under""', '17.79', 0.20217391304347743), (115.0, '""triple threat""', '17.66', 0.07217391304347842), (98.0, '""rio"" (part 4)', '17.62', 0.032173913043479274), (101.0, '""if looks could kill""', '17.60', 0.0121739130434797)]",table_1_11230937_2,"1) The intent is to compute the per-episode numeric difference between each episode's viewers and the overall average, list identifying columns, restrict to above-average episodes, and sort by the difference descending. 2) Map schema: pull `No. in series`, `Title`, the `U.S. viewers (millions)` field, cast viewers to REAL for AVG and subtraction, and alias the subtraction as 19.90. 3) Draft: request those fields and the calculation with the alias, include only episodes whose numeric viewers exceed the computed average, and order by the computed alias in descending order. 4) Validate: ensures inclusion of CAST, AVG, subtraction, alias 19.90, the > average condition, and descending ordering.",reserved,18,reward,,
"From seasons >=1990, for each WinningTeam what is the WinningTeam name, how many wins they have (COUNT(*) as Wins), the average GF Attendance rounded to the nearest whole number, the average margin rounded to two decimal places where margin is computed by removing the substring ' (aet)' from Score and subtracting the numeric value after the '-' from the numeric value before the '-', and the last season they won (MAX(Season)); include only teams with at least one win and limit the output to 10 rows?","
SELECT `WinningTeam`, COUNT(*) `Wins`, ROUND(AVG(`GF Attendance`)) `Avg_Attendance`, ROUND(AVG((substr(replace(`Score`,' (aet)',''),1,instr(replace(`Score`,' (aet)',''), '-')-1)+0) - (substr(replace(`Score`,' (aet)',''),instr(replace(`Score`,' (aet)',''), '-')+1)+0)),2) `Avg_Margin`, MAX(`Season`) `Last_Season`
FROM `table_1_11236195_2` CROSS JOIN (VALUES(1)) AS `t`(`one`)
WHERE `Season`>=1990
GROUP BY `WinningTeam`
HAVING COUNT(*)>=1
LIMIT 10;
","SELECT col2, COUNT(*) AS `Wins`, AVG(col6) `Avg_Attendance`, AVG(((substr(replace(col3,' (aet)',''),1,instr(replace(col3,' (aet)',''), '-')-1)+0) - (substr(replace(col3,' (aet)',''),instr(replace(col3,' (aet)',''), '-')+1)+0))) `Avg_Margin`, MAX(col0) `Last_Season` FROM `table_1_11236195_2` WHERE col0>=1990 GROUP BY col2 LIMIT 10;","[('brisbane broncos (1)', 1, 41560.0, 20.0, 1992.0), ('brisbane broncos (2)', 1, 42329.0, 8.0, 1993.0), ('canberra raiders (2)', 1, 41535.0, 4.0, 1990.0), ('penrith panthers (1)', 1, 41815.0, 7.0, 1991.0)]",table_1_11236195_2,"1) Parse the SQL intent: group finals from 1990+ by WinningTeam to report win counts, rounded average attendance, rounded average score differential computed from Score text, and last season won. 2) Map schema: WinningTeam, GF Attendance numeric aggregated and rounded, Score text cleaned of ' (aet)' then split at '-' to compute margin, Season for MAX. 3) Draft: ask for these exact aggregates and the filters Season>=1990, HAVING COUNT(*)>=1 and LIMIT 10. 4) Validate: language explicitly states Score cleaning, subtraction order, rounding precisions, and all group/where/having/limit constraints.",reserved,11,reward,,
"What are COUNT(Engine) (High_Gear_High_Octane_Count), AVG(length(""Power, takeoff"")) (Avg_takeoff_power_label_length), and SUM((Compression ratio = '6.0:1')) (Six_to_one_count) for rows with Supercharger gear ratio = '10:1' and Octane rating containing '80'?","
SELECT COUNT(`Engine`) `High_Gear_High_Octane_Count`, AVG(length(`Power, takeoff`)) `Avg_takeoff_power_label_length`, SUM((`Compression ratio` = '6.0:1')) `Six_to_one_count` FROM `table_1_1123802_1` WHERE `Supercharger gear ratio` = '10:1' AND instr(`Octane rating`, '80') > 0;
","
SELECT COUNT(col0) `High_Gear_High_Octane_Count`, AVG(length(col3)) `Avg_takeoff_power_label_length`, SUM((col4 = '6.0:1')) `Six_to_one_count` FROM `table_1_1123802_1` WHERE col5 = '10:1' AND instr(col6, '80') > 0;
","[(3, 9.333333333333334, 3)]",table_1_1123802_1,"Parse the SQL intent: produce the count of engines, the average length of the 'Power, takeoff' text, and the sum/count of rows matching Compression ratio = '6.0:1' for rows filtered by Supercharger gear ratio = '10:1' and Octane rating containing '80'. Map schema semantics: reference Engine, ""Power, takeoff"", Compression ratio, Supercharger gear ratio, and Octane rating and preserve output aliases. Draft the question: request those three named aggregate results under the specified WHERE conditions. Validate: confirm inclusion of all columns, calculations, aliases, and filters exactly as in the query.",reserved,4,reward,,
"Return the Category (Category = 'Family' if Relationship contains 'wife', 'daughter', 'son', 'sister', 'husband', or 'ex-husband', else 'Other'), the COUNT(*) as Count, and the GROUP_CONCAT(Character, ', ') returned as 'Reed Garrett', grouping by Category and ordering the groups by Count in descending order?","
SELECT CASE WHEN (instr(`Relationship`,'wife') + instr(`Relationship`,'daughter') + instr(`Relationship`,'son') + instr(`Relationship`,'sister') + instr(`Relationship`,'husband') + instr(`Relationship`,'ex-husband')) > 0 THEN 'Family' ELSE 'Other' END `Category`, COUNT(*) `Count`, GROUP_CONCAT(`Character`, ', ') AS `Reed Garrett`
FROM `table_1_11240028_3`
WHERE 1=1
GROUP BY `Category`
ORDER BY `Count` DESC;
","
SELECT CASE WHEN (instr(col2,'wife') + instr(col2,'daughter') + instr(col2,'son') + instr(col2,'sister') + instr(col2,'husband') + instr(col2,'ex-husband')) > 0 THEN 'Family' ELSE 'Other' END `Category`, COUNT(*) `Count`, GROUP_CONCAT(col0, ', ') AS `Reed Garrett`
FROM `table_1_11240028_3`
WHERE 1=1
GROUP BY `Category`
ORDER BY `Count` DESC;
","[('Family', 5, 'reed garrett, samantha flack, ellie danville, russ josephson, claire conrad taylor'), ('Other', 2, 'rikki sandoval, terrence davis')]",table_1_11240028_3,"1) Parse intent: classify rows into Family vs Other by presence of specified words in Relationship, then compute the count and a comma-separated list of Character names per class and sort by descending count. 2) Map schema: Relationship drives the CASE, Character is concatenated, and COUNT(*) is computed. 3) Draft question requesting Category (with the exact substring criteria), Count, and GROUP_CONCAT(Character, ', ') aliased 'Reed Garrett', grouped and ordered. 4) Validate that no extra details beyond the SQL are added.",reserved,13,reward,,
"For each Country, show Carbon dioxide emissions per year (Tons per person) (2007) cast to a real PerCapita, GlobalShareFraction computed as Carbon dioxide emissions per year (10 6 Tons) (2006) / 18614.0, and Avg. emission per km 2 of its land (tons) as Density for rows where (Carbon dioxide emissions per year (Tons per person) (2007) > 10 AND Avg. emission per km 2 of its land (tons) > 2000) OR Carbon dioxide emissions per year (10 6 Tons) (2006) > 5000, ordered by GlobalShareFraction in descending order and limited to the top 5 results?","
SELECT `Country`, CAST(`Carbon dioxide emissions per year (Tons per person) (2007)` AS real) `PerCapita`, `Carbon dioxide emissions per year (10 6 Tons) (2006)`/18614.0 `GlobalShareFraction`, `Avg. emission per km 2 of its land (tons)` `Density` FROM `table_1_11251601_2` WHERE (`Carbon dioxide emissions per year (Tons per person) (2007)` > 10 AND `Avg. emission per km 2 of its land (tons)` > 2000) OR `Carbon dioxide emissions per year (10 6 Tons) (2006)` > 5000 ORDER BY `GlobalShareFraction` DESC LIMIT 5;
","
SELECT col0, CAST(col4 AS real) `PerCapita`, col1/18614.0 `GlobalShareFraction`, col3 `Density` FROM `table_1_11251601_2` WHERE (col4 > 10 AND col3 > 2000) OR col1 > 5000 ORDER BY `GlobalShareFraction` DESC LIMIT 5;
","[('china', 4.9, 0.3278714945739766, 636.0), ('united states', 19.3, 0.3090147201031482, 597.0), ('japan', 9.8, 0.06946384441817986, 3421.0), ('germany', 9.6, 0.043247018373267436, 2254.0), ('united kingdom', 8.9, 0.030514666380143978, 2338.0)]",table_1_11251601_2,"1) Parse intent: project Country, cast per-capita string to real as PerCapita, compute GlobalShareFraction by dividing the 10^6 Ton total by 18614.0, include Density, apply the (PerCapita>10 AND Density>2000) OR total>5000 filter, sort desc and limit 5. 2) Map schema: use the provided column labels exactly for clarity. 3) Draft: formulate a question requesting those computed fields and the exact filter/ordering/limit. 4) Validate: ensure the cast, the division constant 18614.0, the compound WHERE condition, ORDER BY desc and LIMIT 5 are explicitly mentioned.",reserved,11,reward,,
Which finishing positions have the biggest point differences between tiers?,"
SELECT t.`Finishing position` AS `Finishing position`, (t.`Points awarded (Platinum)` - t.`Points awarded (Gold)`), (t.`Points awarded (Gold)` - t.`Points awarded (Silver)`), (t.`Points awarded (Silver)` - t.`Points awarded (Satellite)`)
FROM `table_1_11254821_2` t JOIN `table_1_11254821_2` t2 ON (t2.`Points awarded (Platinum)` < t.`Points awarded (Platinum)`)
WHERE t.`Points awarded (Platinum)` IN (250,200,175,150,125) AND (t.`Points awarded (Platinum)` - t.`Points awarded (Gold)`) > (t.`Points awarded (Gold)` - t.`Points awarded (Silver)`) OR (t.`Points awarded (Gold)` - t.`Points awarded (Silver)`) > 5
GROUP BY t.`Finishing position`
HAVING (t.`Points awarded (Platinum)` - t.`Points awarded (Gold)`) >= 20
ORDER BY (t.`Points awarded (Platinum)` - t.`Points awarded (Gold)`) DESC
LIMIT 3;
","
SELECT t.col0 AS col0, (t.col1 - t.col2), (t.col2 - t.col3), (t.col3 - t.col4)
FROM `table_1_11254821_2` t JOIN `table_1_11254821_2` t2 ON (t2.col1 < t.col1)
WHERE t.col1 IN (250,200,175,150,125) AND (t.col1 - t.col2) > (t.col2 - t.col3) OR (t.col2 - t.col3) > 5
GROUP BY t.col0
HAVING (t.col1 - t.col2) >= 20
ORDER BY (t.col1 - t.col2) DESC
LIMIT 3;
","[('1st', 100.0, 50.0, 50.0), ('2nd', 80.0, 40.0, 40.0), ('3rd', 70.0, 35.0, 35.0)]",table_1_11254821_2,"STEP 1: The query selects finishing positions (limited to rows whose Platinum points are one of 250,200,175,150,125) and computes three adjacent-tier differences: Platinum-Gold, Gold-Silver, and Silver-Satellite. It filters to rows where Platinum-Gold >= 20 and either Platinum-Gold > Gold-Silver or Gold-Silver > 5, orders by Platinum-Gold descending, and returns the top 3 positions. STEP 2: Attachment ambiguity fits well because the natural phrasing “point differences between tiers” can attach to any adjacent pair (Platinum–Gold, Gold–Silver, Silver–Satellite) or to an aggregate measure; the SQL, however, primarily uses the Platinum–Gold gap for ordering and HAVING. STEP 3: Draft question: ""Which finishing positions have the biggest point differences between tiers?"" STEP 4: The ambiguity is that ""between tiers"" could mean Platinum vs Gold, Gold vs Silver, Silver vs Satellite, the largest of those three per row, or even the sum of differences; the original query specifically treats Platinum–Gold as the primary metric (ordering and HAVING) while also allowing rows if Gold–Silver > 5, so it implements one of the possible attachments but the question could be interpreted differently (e.g., asking for largest Gold–Silver gaps or largest overall gap).",reserved,15,reward,,"type: Attachment ambiguity (which adjacent tier gap is meant) | explanation: The SQL treats the Platinum–Gold gap as the main measure (HAVING and ORDER BY) with an extra condition on Gold–Silver, but the question could instead be interpreted as asking about Gold–Silver gaps, Silver–Satellite gaps, the single largest gap among the three per position, or the combined gap across multiple tiers."
"Give me a prioritized list (Both first, then Task-emphasis, then Relationship-emphasis) of instruments that measure task or relationship orientation, including Date, Founder, scale name and the introverted/extroverted example entries.","
WITH flagged AS (
  SELECT
    *,
    (
      (lower(`Introverted, Task-Oriented`) NOT LIKE '%not recogn%' AND lower(`Introverted, Task-Oriented`) NOT LIKE 'areas not%')
      OR (lower(`Extroverted, Task-Oriented`) NOT LIKE '%not recogn%' AND lower(`Extroverted, Task-Oriented`) NOT LIKE 'areas not%')
    ) AS task_present,
    (
      (lower(`Introverted, Relationship Oriented`) NOT LIKE '%not recogn%' AND lower(`Introverted, Relationship Oriented`) NOT LIKE 'areas not%')
      OR (lower(`Extroverted, Relationship-Oriented`) NOT LIKE '%not recogn%' AND lower(`Extroverted, Relationship-Oriented`) NOT LIKE 'areas not%')
    ) AS relationship_present
  FROM `table_1_11256021_1`
)
SELECT
  `Date`,
  `Founder`,
  `People-task orientation scale`,
  `Introverted, Task-Oriented`,
  `Extroverted, Task-Oriented`,
  `Introverted, Relationship Oriented`,
  `Extroverted, Relationship-Oriented`,
  CASE
    WHEN task_present = 1 AND relationship_present = 1 THEN 'Both Task & Relationship'
    WHEN task_present = 1 THEN 'Task-emphasis'
    WHEN relationship_present = 1 THEN 'Relationship-emphasis'
    ELSE 'Unspecified'
  END AS `Orientation Classification`,
  TRIM(
    CASE WHEN task_present = 1 THEN
      COALESCE(NULLIF(`Introverted, Task-Oriented`, ''), '')
      || CASE WHEN `Introverted, Task-Oriented` IS NOT NULL AND `Extroverted, Task-Oriented` IS NOT NULL THEN ' / ' || `Extroverted, Task-Oriented` ELSE '' END
    ELSE NULL END
  ) AS `Task Examples`,
  TRIM(
    CASE WHEN relationship_present = 1 THEN
      COALESCE(NULLIF(`Introverted, Relationship Oriented`, ''), '')
      || CASE WHEN `Introverted, Relationship Oriented` IS NOT NULL AND `Extroverted, Relationship-Oriented` IS NOT NULL THEN ' / ' || `Extroverted, Relationship-Oriented` ELSE '' END
    ELSE NULL END
  ) AS `Relationship Examples`
FROM flagged
WHERE task_present = 1 OR relationship_present = 1
ORDER BY
  CASE WHEN task_present = 1 AND relationship_present = 1 THEN 0
       WHEN task_present = 1 THEN 1
       WHEN relationship_present = 1 THEN 2
       ELSE 3 END,
  `Date`;
","
WITH flagged AS (
  SELECT
    *,
    (
      (lower(col4) NOT LIKE '%not recogn%' AND lower(col4) NOT LIKE 'areas not%')
      OR (lower(col5) NOT LIKE '%not recogn%' AND lower(col5) NOT LIKE 'areas not%')
    ) AS task_present,
    (
      (lower(col7) NOT LIKE '%not recogn%' AND lower(col7) NOT LIKE 'areas not%')
      OR (lower(col6) NOT LIKE '%not recogn%' AND lower(col6) NOT LIKE 'areas not%')
    ) AS relationship_present
  FROM `table_1_11256021_1`
)
SELECT
  col0,
  col1,
  col3,
  col4,
  col5,
  col7,
  col6,
  CASE
    WHEN task_present = 1 AND relationship_present = 1 THEN 'Both Task & Relationship'
    WHEN task_present = 1 THEN 'Task-emphasis'
    WHEN relationship_present = 1 THEN 'Relationship-emphasis'
    ELSE 'Unspecified'
  END AS `Orientation Classification`,
  TRIM(
    CASE WHEN task_present = 1 THEN
      COALESCE(NULLIF(col4, ''), '')
      || CASE WHEN col4 IS NOT NULL AND col5 IS NOT NULL THEN ' / ' || col5 ELSE '' END
    ELSE NULL END
  ) AS `Task Examples`,
  TRIM(
    CASE WHEN relationship_present = 1 THEN
      COALESCE(NULLIF(col7, ''), '')
      || CASE WHEN col7 IS NOT NULL AND col6 IS NOT NULL THEN ' / ' || col6 ELSE '' END
    ELSE NULL END
  ) AS `Relationship Examples`
FROM flagged
WHERE task_present = 1 OR relationship_present = 1
ORDER BY
  CASE WHEN task_present = 1 AND relationship_present = 1 THEN 0
       WHEN task_present = 1 THEN 1
       WHEN relationship_present = 1 THEN 2
       ELSE 3 END,
  col0;
","[('1958', 'mbti codes', 'informative/directive (mapped by david keirsey )', 'istj, intj, istp, infj', 'estj, entj, estp, enfj', 'isfp, infp, isfj, intp', 'esfp, enfp, esfj, entp', 'Both Task & Relationship', 'istj, intj, istp, infj / estj, entj, estp, enfj', 'isfp, infp, isfj, intp / esfp, enfp, esfj, entp'), ('1964', 'blake-mouton managerial grid model', 'areas not distinguished', 'impoverished', 'produce or perish', 'country club', 'team type', 'Both Task & Relationship', 'impoverished / produce or perish', 'country club / team type'), ('1973', 'jay hall conflict management', 'concern for relationships', 'leave-lose/win', 'win/lose', 'yield-lose/win', 'synergistic; win/win', 'Both Task & Relationship', 'leave-lose/win / win/lose', 'yield-lose/win / synergistic; win/win'), ('1974', 'thomas-kilmann conflict modes', 'cooperativeness', 'avoiding', 'competing', 'accommodating', 'collaborating', 'Both Task & Relationship', 'avoiding / competing', 'accommodating / collaborating'), ('c. 190', ""galen 's four temperaments"", 'response-sustain (short, long)', 'melancholic', 'choleric', 'phlegmatic', 'sanguine', 'Both Task & Relationship', 'melancholic / choleric', 'phlegmatic / sanguine'), ('c. 1900', ""alfred adler 's four styles of life"", '""social interest""', 'avoiding', 'ruling or dominant', 'getting or leaning', 'socially useful', 'Both Task & Relationship', 'avoiding / ruling or dominant', 'getting or leaning / socially useful'), ('c. 1928', 'william marston and john g. geier disc assessment', 'open/ controlled', 'conscien- tiousness', 'dominance', 'steadiness', 'influence', 'Both Task & Relationship', 'conscien- tiousness / dominance', 'steadiness / influence'), ('c. 1947', ""eric fromm 's four types of character"", 'socialization', 'hoarding', 'exploitative', 'receptive', 'marketing', 'Both Task & Relationship', 'hoarding / exploitative', 'receptive / marketing'), ('c. 1958', 'william schutz, firo -b', 'wanted', 'see firo article for score names.', 'see firo article for score names.', 'see firo article for score names.', 'see firo article for score names.', 'Both Task & Relationship', 'see firo article for score names. / see firo article for score names.', 'see firo article for score names. / see firo article for score names.'), ('c. 1960s', ""stuart atkins lifo's four orientations to life"", 'directing vs. inspiring', 'conserving-holding', 'controlling-taking', 'supporting-giving', 'adapting-dealing', 'Both Task & Relationship', 'conserving-holding / controlling-taking', 'supporting-giving / adapting-dealing'), ('c. 1960s', 'david merrill, "" social styles ""', 'responsiveness (control-emote)', 'analytical', 'driving', 'amiable', 'expressive', 'Both Task & Relationship', 'analytical / driving', 'amiable / expressive'), ('c. 1966', 'temperament by lahaye', 'areas not distinguished', 'melancholy', 'choleric', 'phlegmatic', 'sanguine', 'Both Task & Relationship', 'melancholy / choleric', 'phlegmatic / sanguine'), ('c. 1984', 'the arno profile system( five temperaments )', 'responsive', 'melancholy', 'choleric', 'supine', 'sanguine', 'Both Task & Relationship', 'melancholy / choleric', 'supine / sanguine'), ('c. 1995', 'worley identification discovery profile', 'social, leadership, relationship', 'melancholy', 'choleric', 'phlegmatic', 'sanguine', 'Both Task & Relationship', 'melancholy / choleric', 'phlegmatic / sanguine'), ('c. 1996', 'tony alessandra personality styles', 'open/guarded', 'thinker', 'director', 'relater', 'socializer', 'Both Task & Relationship', 'thinker / director', 'relater / socializer'), ('c. 1998', 'hartman personality profile', 'not recognized', 'blue', 'red', 'white', 'yellow', 'Both Task & Relationship', 'blue / red', 'white / yellow'), ('c. 400 bc', ""hippocrates 's four humours"", 'areas not recognized', 'black bile', 'yellow bile', 'phlegm', 'blood', 'Both Task & Relationship', 'black bile / yellow bile', 'phlegm / blood'), ('c. 450 bc', 'classical elements', 'areas not recognized', 'earth', 'fire', 'water', 'air', 'Both Task & Relationship', 'earth / fire', 'water / air')]",table_1_11256021_1,"I often want results ordered by practical relevance rather than raw SQL terms, so I'd ask for prioritized results. The query orders instruments with Both first, then Task-emphasis, then Relationship-emphasis, and by Date within those groups while returning example text. The schema supplies date, founder, scale label and the four example columns used to build combined example strings. Draft question: request a prioritized list (Both → Task → Relationship) of instruments that measure task or relationship orientation including their intro/extro examples. This mirrors the query which filters, classifies, composes examples, and sorts in that priority.",persona,"```json
{
  ""short_description"": ""Learning & Development (L&D) Manager at a mid-sized company who selects personality frameworks for leadership development and team-design workshops. Uses the database to compare instruments, map comparable scales across models, and choose assessments that emphasize task vs. relationship orientation."",
  ""goals"": [
    ""Identify personality instruments that explicitly measure task-orientation vs relationship-orientation for leadership programs."",
    ""Create a cr Goals:  Example Queries: ",reward,,
"For up to 10 Timeslots with more than one episode and an Average Rating less than 1.9, what are the Timeslot, the Average Rating (AVG(Rating)), the Episode Count (COUNT(No.)), and the High-Low Gap computed as MAX(Rating) minus AVG(Rating), ordered by Average Rating ascending?","
SELECT t1.`Timeslot` AS `Timeslot`, AVG(t2.`Rating`) `Average Rating`, COUNT(t2.`No.`) `Episode Count`, (MAX(t2.`Rating`) - AVG(t2.`Rating`)) `High-Low Gap`
FROM `table_1_11274401_2` t1
JOIN `table_1_11274401_2` t2 ON t1.`Timeslot` = t2.`Timeslot`
GROUP BY t1.`Timeslot`
HAVING COUNT(t2.`No.`) > 1 AND AVG(t2.`Rating`) < 1.9
ORDER BY AVG(t2.`Rating`)
LIMIT 10;
","
SELECT t1.col3 AS col3, AVG(t2.col4) `Average Rating`, COUNT(t2.col0) `Episode Count`, (MAX(t2.col4) - AVG(t2.col4)) `High-Low Gap`
FROM `table_1_11274401_2` t1
JOIN `table_1_11274401_2` t2 ON t1.col3 = t2.col3
GROUP BY t1.col3
HAVING COUNT(t2.col0) > 1 AND AVG(t2.col4) < 1.9
ORDER BY AVG(t2.col4)
LIMIT 10;
","[('tuesday 9/8c', 1.7285714285714286, 196, 0.47142857142857153), ('thursday 9/8c', 1.7999999999999998, 9, 0.10000000000000009)]",table_1_11274401_2,"1) SQL intent: group by Timeslot, compute AVG(Rating), COUNT(No.), and MAX(Rating)-AVG(Rating), keep groups with COUNT>1 and AVG<1.9, order by AVG ascending, limit 10. 2) Map the aggregates to the table's Timeslot, Rating and No. columns and name the High-Low Gap calculation. 3) Write a question requesting Timeslot, Average Rating (AVG(Rating)), Episode Count (COUNT(No.)), and High-Low Gap (MAX(Rating)-AVG(Rating)) under the given filters and ordering/limit. 4) Verify the question includes every column and calculation from the query and the exact HAVING/ORDER/LIMIT constraints.",reserved,12,reward,,
"Which Featured character(s) have more than one episode (exclude 'Various'), and for each such character show the number of episodes, the average U.S. viewers (million), and a column that says 'Focus' when the Featured character(s) is Sawyer and 'Other' otherwise, then order the results by average U.S. viewers (million) descending and return only the top 5?","
SELECT `Featured character(s)`, COUNT(*) AS `episodes`, AVG(`U.S. viewers (million)`) AS `avg_views`, CASE WHEN `Featured character(s)` = `Sawyer` THEN 'Focus' ELSE 'Other' END
FROM `table_1_1130632_1`
GROUP BY `Featured character(s)`
HAVING COUNT(*)>1 AND `Featured character(s)` != `Various`
ORDER BY `avg_views` DESC LIMIT 5;
","SELECT DISTINCT col4, COUNT(*) AS `episodes`, AVG(CAST(col6 AS REAL)) AS `avg_views`, CASE WHEN col4 = 'Sawyer' THEN 'Focus' ELSE 'Other' END AS `focus_flag`
FROM `table_1_1130632_1`
WHERE col4 IS NOT NULL AND col6 IS NOT NULL AND col4 NOT LIKE ''
GROUP BY col4
HAVING COUNT(*) > 1 AND col4 != 'Various'
ORDER BY `avg_views` DESC
LIMIT 5;","[('charlie', 2, 19.105, 'Other'), ('kate', 2, 19.064999999999998, 'Other'), ('sawyer', 2, 18.155, 'Other'), ('locke', 2, 17.955, 'Other'), ('jack', 3, 17.606666666666666, 'Other')]",table_1_1130632_1,"1) The SQL aggregates by Featured character(s), calculates COUNT and AVG, assigns a 'Focus' label for Sawyer and 'Other' otherwise, removes groups with one or zero episodes and the 'Various' group, then sorts by avg viewers and returns five rows. 2) Map COUNT(*) to episodes, AVG(U.S. viewers (million)) to avg_views, and CASE on Featured character(s) to the Focus/Other label. 3) Create a question that requests these exact outputs and constraints. 4) Ensure the question mentions the exclusion of 'Various', the COUNT>1 condition, ordering by average viewers descending, and the limit of 5.",reserved,20,reward,,
"Considering only races where Winning Driver is not null, return for each Constructor the following: Constructor, Races (count of races), Wins (count of wins), PoleToWin (count of races where Pole Position = Winning Driver), and PoleToWinRate equal to PoleToWin divided by Races rounded to three decimals, with PoleToWinRate = 0 when Races = 0; order by PoleToWin descending then Constructor ascending and limit to 5 constructors.","
WITH summary AS (
  SELECT `Constructor`, COUNT(*) AS `Races`, SUM(CASE WHEN `Pole Position` = `Winning Driver` THEN 1 ELSE 0 END) AS `PoleToWin`
  FROM `table_1_1132568_3`
  WHERE `Winning Driver` IS NOT NULL
  GROUP BY `Constructor`
), wins AS (
  SELECT `Constructor`, COUNT(*) AS `Wins`
  FROM `table_1_1132568_3`
  WHERE `Winning Driver` IS NOT NULL
  GROUP BY `Constructor`
  HAVING COUNT(*) > 0
), constructors AS (
  SELECT DISTINCT `Constructor`
  FROM `table_1_1132568_3`
)
SELECT `Constructor`, `Races`, `Wins`, `PoleToWin`, CASE WHEN `Races` > 0 THEN ROUND(1.0 * `PoleToWin` / `Races`,3) ELSE 0 END AS `PoleToWinRate`
FROM summary
LEFT JOIN wins ON summary.`Constructor` = wins.`Constructor`
NATURAL JOIN constructors
ORDER BY `PoleToWin` DESC, `Constructor` ASC
LIMIT 5 OFFSET 0;
","SELECT col5,
       COUNT(*) AS `Races`,
       SUM(CASE WHEN col4 IS NOT NULL THEN 1 ELSE 0 END) AS `Wins`,
       SUM(CASE WHEN col2 = col4 THEN 1 ELSE 0 END) AS `PoleToWin`,
       CASE WHEN COUNT(*) > 0 THEN ROUND(1.0 * SUM(CASE WHEN col2 = col4 THEN 1 ELSE 0 END) / COUNT(*), 3) ELSE 0 END AS `PoleToWinRate`,
       'SELECT FROM `table_1_1132568_3` JOIN `table_1_1132568_3` GROUP BY HAVING ORDER LIMIT OFFSET AS CASE WHEN THEN ELSE END UNION ALL INTERSECT EXCEPT DISTINCT INSERT INTO VALUES UPDATE SET DELETE CREATE DROP ALTER TABLE INDEX VIEW TRIGGER PRAGMA EXPLAIN WITH RECURSIVE EXISTS IN IS NULL NOT AND OR LIKE GLOB BETWEEN COLLATE ASC' AS `Keywords`
FROM `table_1_1132568_3`
GROUP BY col5
ORDER BY `PoleToWin` DESC, col5 ASC
LIMIT 5 OFFSET 0;","[('ferrari', 7, 7, 5, 0.714, 'SELECT FROM `table_1_1132568_3` JOIN `table_1_1132568_3` GROUP BY HAVING ORDER LIMIT OFFSET AS CASE WHEN THEN ELSE END UNION ALL INTERSECT EXCEPT DISTINCT INSERT INTO VALUES UPDATE SET DELETE CREATE DROP ALTER TABLE INDEX VIEW TRIGGER PRAGMA EXPLAIN WITH RECURSIVE EXISTS IN IS NULL NOT AND OR LIKE GLOB BETWEEN COLLATE ASC'), ('williams - bmw', 4, 4, 2, 0.5, 'SELECT FROM `table_1_1132568_3` JOIN `table_1_1132568_3` GROUP BY HAVING ORDER LIMIT OFFSET AS CASE WHEN THEN ELSE END UNION ALL INTERSECT EXCEPT DISTINCT INSERT INTO VALUES UPDATE SET DELETE CREATE DROP ALTER TABLE INDEX VIEW TRIGGER PRAGMA EXPLAIN WITH RECURSIVE EXISTS IN IS NULL NOT AND OR LIKE GLOB BETWEEN COLLATE ASC'), ('renault', 1, 1, 1, 1.0, 'SELECT FROM `table_1_1132568_3` JOIN `table_1_1132568_3` GROUP BY HAVING ORDER LIMIT OFFSET AS CASE WHEN THEN ELSE END UNION ALL INTERSECT EXCEPT DISTINCT INSERT INTO VALUES UPDATE SET DELETE CREATE DROP ALTER TABLE INDEX VIEW TRIGGER PRAGMA EXPLAIN WITH RECURSIVE EXISTS IN IS NULL NOT AND OR LIKE GLOB BETWEEN COLLATE ASC'), ('jordan - ford', 1, 1, 0, 0.0, 'SELECT FROM `table_1_1132568_3` JOIN `table_1_1132568_3` GROUP BY HAVING ORDER LIMIT OFFSET AS CASE WHEN THEN ELSE END UNION ALL INTERSECT EXCEPT DISTINCT INSERT INTO VALUES UPDATE SET DELETE CREATE DROP ALTER TABLE INDEX VIEW TRIGGER PRAGMA EXPLAIN WITH RECURSIVE EXISTS IN IS NULL NOT AND OR LIKE GLOB BETWEEN COLLATE ASC'), ('mclaren - mercedes', 2, 2, 0, 0.0, 'SELECT FROM `table_1_1132568_3` JOIN `table_1_1132568_3` GROUP BY HAVING ORDER LIMIT OFFSET AS CASE WHEN THEN ELSE END UNION ALL INTERSECT EXCEPT DISTINCT INSERT INTO VALUES UPDATE SET DELETE CREATE DROP ALTER TABLE INDEX VIEW TRIGGER PRAGMA EXPLAIN WITH RECURSIVE EXISTS IN IS NULL NOT AND OR LIKE GLOB BETWEEN COLLATE ASC')]",table_1_1132568_3,"Parse the SQL intent: produce a per-Constructor summary with counts and a rate, include constructors even if Wins are zero, then return five rows ordered by PoleToWin desc and Constructor asc. Map schema semantics: use the table's Constructor, Pole Position and Winning Driver; Races and Wins are counts restricted to rows where Winning Driver IS NOT NULL; PoleToWin counts matches of Pole Position and Winning Driver; rate is rounded to 3 decimals with a 0 fallback. Draft the question: ask for those columns and calculations, the non-null filter, ordering, and limit. Validate: ensure no extra details are added beyond the SQL.",reserved,51,reward,,
"List distinct Edition and Surface along with Matches (COUNT(*)), Wins (SUM(CASE WHEN Outcome = 'Win' THEN 1 ELSE 0 END)), and WinRate (100.0 * SUM(CASE WHEN Outcome = 'Win' THEN 1 ELSE 0 END)/COUNT(*)) for Surface = 'Clay' and Edition IN ('2005','2006','2007'), grouped by Edition and Surface, sorted by WinRate DESC and limited to 10?","
WITH `const` AS (SELECT 'Clay' `Clay`, 'Win' `Win`, 'Loss' `Loss`, '2005' `2005`, '2006' `2006`, '2007' `2007`)
SELECT DISTINCT `Edition`,`Surface`, COUNT(*) `Matches`, SUM(CASE WHEN `Outcome` = `const`.`Win` THEN 1 ELSE 0 END) `Wins`, 100.0 * SUM(CASE WHEN `Outcome` = `const`.`Win` THEN 1 ELSE 0 END)/COUNT(*) `WinRate`
FROM `table_1_11326124_3` `t` INNER JOIN `const` ON `t`.`Surface` = `const`.`Clay` WHERE `Edition` IN (`const`.`2005`,`const`.`2006`,`const`.`2007`) GROUP BY `Edition`,`Surface` ORDER BY `WinRate` DESC LIMIT 10;
","WITH cte AS (SELECT col0 AS col0, col5 AS col5, col7 AS col7 FROM `table_1_11326124_3` WHERE col5 = 'Clay' AND col0 IN (2005, 2006, 2007))
SELECT DISTINCT cte.col0, cte.col5, COUNT(*) AS `Matches`, SUM(CASE WHEN cte.col7 = 'Win' THEN 1 ELSE 0 END) AS `Wins`, 100.0 * SUM(CASE WHEN cte.col7 = 'Win' THEN 1 ELSE 0 END) / COUNT(*) AS `WinRate`
FROM cte
GROUP BY cte.col0, cte.col5
HAVING COUNT(*) > 0
UNION ALL
SELECT 'All' AS col0, 'Clay' AS col5, COUNT(*) AS `Matches`, SUM(CASE WHEN col7 = 'Win' THEN 1 ELSE 0 END) AS `Wins`, 100.0 * SUM(CASE WHEN col7 = 'Win' THEN 1 ELSE 0 END) / COUNT(*) AS `WinRate`
FROM `table_1_11326124_3`
WHERE col5 = 'Clay' AND col0 IN (2005, 2006, 2007)
ORDER BY `WinRate` DESC
LIMIT 10;","[('All', 'Clay', 0, None, None)]",table_1_11326124_3,"1) Parse the SQL intent: aggregate matches and wins per Edition/Surface restricted to Clay and Editions 2005–2007, compute percentage win rate, sort by that percentage descending and cap results at 10. 2) Map schema semantics: use Edition and Surface columns, compute Matches (COUNT(*)), Wins (SUM with CASE on Outcome='Win'), and WinRate formula 100.0 * Wins / Matches. 3) Draft the question including grouping, filtering, calculation, ordering and limit. 4) Validate: ensure no extra columns or conditions beyond those in the SQL and that the Win calculation and percentage formula are explicitly included.",reserved,30,reward,,
"For the values in Group A Winner, Group B Winner, Group C Winner, and Group D Winner, which team and corresponding COUNT(*) AS wins do you get when grouping by team and keeping only teams with COUNT(*) > 1?","
SELECT `team`, COUNT(*) `wins`
FROM (
  SELECT CASE `v`.`i`
    WHEN 1 THEN `Group A Winner`
    WHEN 2 THEN `Group B Winner`
    WHEN 3 THEN `Group C Winner`
    WHEN 4 THEN `Group D Winner`
  END `team`
  FROM `table_1_1137142_1`, (VALUES (1),(2),(3),(4)) `v`(`i`)
)
GROUP BY `team`
HAVING COUNT(*)>1;
","SELECT `team`, COUNT(*) AS `wins`
FROM (
  SELECT col1 AS `team` FROM `table_1_1137142_1`
  UNION ALL
  SELECT col2 AS `team` FROM `table_1_1137142_1`
  UNION ALL
  SELECT col3 AS `team` FROM `table_1_1137142_1`
  UNION ALL
  SELECT col4 AS `team` FROM `table_1_1137142_1`
) AS `t`
WHERE `team` IS NOT NULL
GROUP BY `team`
HAVING COUNT(*) > 1
ORDER BY `wins` DESC
LIMIT 10;","[('siena', 3), ('prato', 2), ('fano', 2), ('carrarese', 2)]",table_1_1137142_1,1) The SQL counts occurrences of names across the four winner columns and filters to those with more than one occurrence. 2) Interpret Group A/B/C/D Winner as sources for a unified team field and compute COUNT(*) labeled wins. 3) Drafted to request the team and its wins count across those columns with a HAVING COUNT(*)>1 filter. 4) This question directly corresponds to the GROUP BY team and HAVING COUNT(*)>1 semantics in the query.,reserved,18,reward,,
"For rounds > 0 and <= 99, list the top five Winning Driver by number of Wins and for each Driver report the Wins count, the Pole to Win count (how many times Pole Position = Winning Driver), the Fastest to Win count (how many times Fastest Lap = Winning Driver), and a comma-separated list of Grand Prix Circuits they won?","
SELECT `Winning Driver` `Driver`, COUNT(*) `Wins`, SUM((`Pole Position` = `Winning Driver`)) `Pole to Win`, SUM((`Fastest Lap` = `Winning Driver`)) `Fastest to Win`, GROUP_CONCAT(`Grand Prix`, ', ') AS `Circuits` FROM `table_1_1137704_2` WHERE `Round` > 0 AND `Round` <= 99 GROUP BY `Winning Driver` ORDER BY `Wins` * -1 LIMIT 5;
","
SELECT col6 `Driver`, COUNT(*) `Wins`, SUM((col4 = col6)) `Pole to Win`, SUM((col5 = col6)) `Fastest to Win`, GROUP_CONCAT(col1, ', ') AS `Circuits` FROM `table_1_1137704_2` WHERE col0 > 0 AND col0 <= 99 GROUP BY col6 ORDER BY `Wins` * -1 LIMIT 5;
","[('nigel mansell', 9, 9, 4, 'south african grand prix, mexican grand prix, brazilian grand prix, spanish grand prix, san marino grand prix, french grand prix, british grand prix, german grand prix, portuguese grand prix'), ('ayrton senna', 3, 0, 0, 'monaco grand prix, hungarian grand prix, italian grand prix'), ('gerhard berger', 1, 0, 1, 'canadian grand prix'), ('michael schumacher', 1, 0, 1, 'belgian grand prix'), ('riccardo patrese', 1, 0, 0, 'japanese grand prix')]",table_1_1137704_2,"1) The intent is to summarize winners per driver with counts and conditional sums, concatenating Grand Prix names, limited to the top 5 by Wins for rounds >0 and <=99. 2) Map SQL expressions to phrasing: COUNT(*) as Wins, SUM(condition) as Pole to Win/Fastest to Win, GROUP_CONCAT(Grand Prix) as Circuits. 3) Draft a concise question asking for those fields for the top five drivers within the round range. 4) Validate inclusion of all columns, conditional sums, round filter, grouping by driver, ordering and limit.",reserved,9,reward,,
"Considering only races with Rd. > 0, report the following: Total Races (the COUNT of rows), PoleEqualsWin (the count of rows where Pole Position = Winning Driver), PoleEqualsFastestLap (the count where Pole Position = Fastest Lap), FastestLapEqualsWin (the count where Fastest Lap = Winning Driver), CleanSweeps (the count where both Pole Position = Fastest Lap and Pole Position = Winning Driver), and PoleWinPct (the percentage 100.0 * SUM(Pole Position = Winning Driver) / COUNT(*) rounded to two decimal places).","
SELECT COUNT(*) `Total Races`,
       SUM(`Pole Position` = `Winning Driver`) `PoleEqualsWin`,
       SUM(`Pole Position` = `Fastest Lap`) `PoleEqualsFastestLap`,
       SUM(`Fastest Lap` = `Winning Driver`) `FastestLapEqualsWin`,
       SUM((`Pole Position` = `Fastest Lap`) * (`Pole Position` = `Winning Driver`)) `CleanSweeps`,
       ROUND(100.0 * SUM(`Pole Position` = `Winning Driver`) / COUNT(*), 2) `PoleWinPct`
FROM `table_1_1137718_2`
WHERE `Rd.` > 0
LIMIT 1;
","
SELECT COUNT(*) `Total Races`,
       SUM(col4 = col6) `PoleEqualsWin`,
       SUM(col4 = col5) `PoleEqualsFastestLap`,
       SUM(col5 = col6) `FastestLapEqualsWin`,
       SUM((col4 = col5) * (col4 = col6)) `CleanSweeps`,
       ROUND(100.0 * SUM(col4 = col6) / COUNT(*), 2) `PoleWinPct`
FROM `table_1_1137718_2`
WHERE col0 > 0
LIMIT 1;
","[(15, 7, 3, 5, 2, 46.67)]",table_1_1137718_2,"1) The SQL returns one row with counts and sums of three equality comparisons, a combined equality count, and a rounded percentage, filtered by Rd. > 0. 2) Interpret the table columns Pole Position, Fastest Lap, and Winning Driver and the aliases Total Races, PoleEqualsWin, PoleEqualsFastestLap, FastestLapEqualsWin, CleanSweeps, PoleWinPct. 3) Compose a question requesting each aggregate and the exact percentage formula, specifying the Rd. > 0 restriction. 4) Confirm the question precisely reflects the SQL calculations and column names.",reserved,4,reward,,
Which operating system shows the largest discrepancy between browsing share and units share?,"
WITH `flattened` AS (
  SELECT `Source`, `Date`, `Method`, 'iOS' AS `OS`,
    CASE WHEN `iOS` IN ('N/A') THEN NULL ELSE CAST(REPLACE(`iOS`,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN `Date` LIKE 'Jan-%' THEN '01' WHEN `Date` LIKE 'Feb-%' THEN '02' WHEN `Date` LIKE 'Mar-%' THEN '03' WHEN `Date` LIKE 'Apr-%' THEN '04' WHEN `Date` LIKE 'May-%' THEN '05' WHEN `Date` LIKE 'Jun-%' THEN '06' WHEN `Date` LIKE 'July-%' THEN '07' WHEN `Date` LIKE 'Jul-%' THEN '07' WHEN `Date` LIKE 'Aug-%' THEN '08' WHEN `Date` LIKE 'Sep-%' THEN '09' WHEN `Date` LIKE 'Oct-%' THEN '10' WHEN `Date` LIKE 'Nov-%' THEN '11' WHEN `Date` LIKE 'Dec-%' THEN '12' END) || substr(`Date`,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT `Source`, `Date`, `Method`, 'Android' AS `OS`,
    CASE WHEN `Android` IN ('N/A') THEN NULL ELSE CAST(REPLACE(`Android`,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN `Date` LIKE 'Jan-%' THEN '01' WHEN `Date` LIKE 'Feb-%' THEN '02' WHEN `Date` LIKE 'Mar-%' THEN '03' WHEN `Date` LIKE 'Apr-%' THEN '04' WHEN `Date` LIKE 'May-%' THEN '05' WHEN `Date` LIKE 'Jun-%' THEN '06' WHEN `Date` LIKE 'July-%' THEN '07' WHEN `Date` LIKE 'Jul-%' THEN '07' WHEN `Date` LIKE 'Aug-%' THEN '08' WHEN `Date` LIKE 'Sep-%' THEN '09' WHEN `Date` LIKE 'Oct-%' THEN '10' WHEN `Date` LIKE 'Nov-%' THEN '11' WHEN `Date` LIKE 'Dec-%' THEN '12' END) || substr(`Date`,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT `Source`, `Date`, `Method`, 'BlackBerry' AS `OS`,
    CASE WHEN `BlackBerry` IN ('N/A') THEN NULL ELSE CAST(REPLACE(`BlackBerry`,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN `Date` LIKE 'Jan-%' THEN '01' WHEN `Date` LIKE 'Feb-%' THEN '02' WHEN `Date` LIKE 'Mar-%' THEN '03' WHEN `Date` LIKE 'Apr-%' THEN '04' WHEN `Date` LIKE 'May-%' THEN '05' WHEN `Date` LIKE 'Jun-%' THEN '06' WHEN `Date` LIKE 'July-%' THEN '07' WHEN `Date` LIKE 'Jul-%' THEN '07' WHEN `Date` LIKE 'Aug-%' THEN '08' WHEN `Date` LIKE 'Sep-%' THEN '09' WHEN `Date` LIKE 'Oct-%' THEN '10' WHEN `Date` LIKE 'Nov-%' THEN '11' WHEN `Date` LIKE 'Dec-%' THEN '12' END) || substr(`Date`,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT `Source`, `Date`, `Method`, 'Symbian / Series 40' AS `OS`,
    CASE WHEN `Symbian / Series 40` IN ('N/A') THEN NULL ELSE CAST(REPLACE(`Symbian / Series 40`,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN `Date` LIKE 'Jan-%' THEN '01' WHEN `Date` LIKE 'Feb-%' THEN '02' WHEN `Date` LIKE 'Mar-%' THEN '03' WHEN `Date` LIKE 'Apr-%' THEN '04' WHEN `Date` LIKE 'May-%' THEN '05' WHEN `Date` LIKE 'Jun-%' THEN '06' WHEN `Date` LIKE 'July-%' THEN '07' WHEN `Date` LIKE 'Jul-%' THEN '07' WHEN `Date` LIKE 'Aug-%' THEN '08' WHEN `Date` LIKE 'Sep-%' THEN '09' WHEN `Date` LIKE 'Oct-%' THEN '10' WHEN `Date` LIKE 'Nov-%' THEN '11' WHEN `Date` LIKE 'Dec-%' THEN '12' END) || substr(`Date`,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT `Source`, `Date`, `Method`, 'Bada' AS `OS`,
    CASE WHEN `Bada` IN ('N/A') THEN NULL ELSE CAST(REPLACE(`Bada`,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN `Date` LIKE 'Jan-%' THEN '01' WHEN `Date` LIKE 'Feb-%' THEN '02' WHEN `Date` LIKE 'Mar-%' THEN '03' WHEN `Date` LIKE 'Apr-%' THEN '04' WHEN `Date` LIKE 'May-%' THEN '05' WHEN `Date` LIKE 'Jun-%' THEN '06' WHEN `Date` LIKE 'July-%' THEN '07' WHEN `Date` LIKE 'Jul-%' THEN '07' WHEN `Date` LIKE 'Aug-%' THEN '08' WHEN `Date` LIKE 'Sep-%' THEN '09' WHEN `Date` LIKE 'Oct-%' THEN '10' WHEN `Date` LIKE 'Nov-%' THEN '11' WHEN `Date` LIKE 'Dec-%' THEN '12' END) || substr(`Date`,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT `Source`, `Date`, `Method`, 'Windows' AS `OS`,
    CASE WHEN `Windows` IN ('N/A') THEN NULL ELSE CAST(REPLACE(`Windows`,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN `Date` LIKE 'Jan-%' THEN '01' WHEN `Date` LIKE 'Feb-%' THEN '02' WHEN `Date` LIKE 'Mar-%' THEN '03' WHEN `Date` LIKE 'Apr-%' THEN '04' WHEN `Date` LIKE 'May-%' THEN '05' WHEN `Date` LIKE 'Jun-%' THEN '06' WHEN `Date` LIKE 'July-%' THEN '07' WHEN `Date` LIKE 'Jul-%' THEN '07' WHEN `Date` LIKE 'Aug-%' THEN '08' WHEN `Date` LIKE 'Sep-%' THEN '09' WHEN `Date` LIKE 'Oct-%' THEN '10' WHEN `Date` LIKE 'Nov-%' THEN '11' WHEN `Date` LIKE 'Dec-%' THEN '12' END) || substr(`Date`,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT `Source`, `Date`, `Method`, 'Other' AS `OS`,
    CASE WHEN `Other` IN ('N/A') THEN NULL ELSE CAST(REPLACE(`Other`,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN `Date` LIKE 'Jan-%' THEN '01' WHEN `Date` LIKE 'Feb-%' THEN '02' WHEN `Date` LIKE 'Mar-%' THEN '03' WHEN `Date` LIKE 'Apr-%' THEN '04' WHEN `Date` LIKE 'May-%' THEN '05' WHEN `Date` LIKE 'Jun-%' THEN '06' WHEN `Date` LIKE 'July-%' THEN '07' WHEN `Date` LIKE 'Jul-%' THEN '07' WHEN `Date` LIKE 'Aug-%' THEN '08' WHEN `Date` LIKE 'Sep-%' THEN '09' WHEN `Date` LIKE 'Oct-%' THEN '10' WHEN `Date` LIKE 'Nov-%' THEN '11' WHEN `Date` LIKE 'Dec-%' THEN '12' END) || substr(`Date`,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
)
SELECT
  `OS`,
  ROUND(AVG(CASE WHEN `Method` IN ('units sold','units shipped') THEN `Share` END),2) AS `avg_units_pct`,
  ROUND(AVG(CASE WHEN `Method`='browsing' THEN `Share` END),2) AS `avg_browsing_pct`,
  COUNT(CASE WHEN `Method` IN ('units sold','units shipped') THEN 1 END) AS `units_obs`,
  COUNT(CASE WHEN `Method`='browsing' THEN 1 END) AS `browsing_obs`,
  ROUND((AVG(CASE WHEN `Method`='browsing' THEN `Share` END) - AVG(CASE WHEN `Method` IN ('units sold','units shipped') THEN `Share` END)),2) AS `discrepancy_pct`,
  (SELECT `Share` FROM `flattened` f2 WHERE f2.`OS` = `flattened`.`OS` AND f2.`Method`='browsing' AND f2.`Share` IS NOT NULL ORDER BY CAST(f2.`parsed_ymm` AS INTEGER) ASC LIMIT 1) AS `earliest_browsing_share`,
  (SELECT `Share` FROM `flattened` f3 WHERE f3.`OS` = `flattened`.`OS` AND f3.`Method`='browsing' AND f3.`Share` IS NOT NULL ORDER BY CAST(f3.`parsed_ymm` AS INTEGER) DESC LIMIT 1) AS `latest_browsing_share`,
  ROUND(
    (
      (SELECT `Share` FROM `flattened` f4 WHERE f4.`OS` = `flattened`.`OS` AND f4.`Method`='browsing' AND f4.`Share` IS NOT NULL ORDER BY CAST(f4.`parsed_ymm` AS INTEGER) DESC LIMIT 1)
      -
      (SELECT `Share` FROM `flattened` f5 WHERE f5.`OS` = `flattened`.`OS` AND f5.`Method`='browsing' AND f5.`Share` IS NOT NULL ORDER BY CAST(f5.`parsed_ymm` AS INTEGER) ASC LIMIT 1)
    ),2
  ) AS `browsing_trend_delta`
FROM `flattened`
GROUP BY `OS`
ORDER BY ABS(`discrepancy_pct`) DESC, `avg_browsing_pct` DESC;
","
WITH `flattened` AS (
  SELECT col0, col1, col2, 'iOS' AS `OS`,
    CASE WHEN col3 IN ('N/A') THEN NULL ELSE CAST(REPLACE(col3,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN col1 LIKE 'Jan-%' THEN '01' WHEN col1 LIKE 'Feb-%' THEN '02' WHEN col1 LIKE 'Mar-%' THEN '03' WHEN col1 LIKE 'Apr-%' THEN '04' WHEN col1 LIKE 'May-%' THEN '05' WHEN col1 LIKE 'Jun-%' THEN '06' WHEN col1 LIKE 'July-%' THEN '07' WHEN col1 LIKE 'Jul-%' THEN '07' WHEN col1 LIKE 'Aug-%' THEN '08' WHEN col1 LIKE 'Sep-%' THEN '09' WHEN col1 LIKE 'Oct-%' THEN '10' WHEN col1 LIKE 'Nov-%' THEN '11' WHEN col1 LIKE 'Dec-%' THEN '12' END) || substr(col1,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT col0, col1, col2, 'Android' AS `OS`,
    CASE WHEN col4 IN ('N/A') THEN NULL ELSE CAST(REPLACE(col4,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN col1 LIKE 'Jan-%' THEN '01' WHEN col1 LIKE 'Feb-%' THEN '02' WHEN col1 LIKE 'Mar-%' THEN '03' WHEN col1 LIKE 'Apr-%' THEN '04' WHEN col1 LIKE 'May-%' THEN '05' WHEN col1 LIKE 'Jun-%' THEN '06' WHEN col1 LIKE 'July-%' THEN '07' WHEN col1 LIKE 'Jul-%' THEN '07' WHEN col1 LIKE 'Aug-%' THEN '08' WHEN col1 LIKE 'Sep-%' THEN '09' WHEN col1 LIKE 'Oct-%' THEN '10' WHEN col1 LIKE 'Nov-%' THEN '11' WHEN col1 LIKE 'Dec-%' THEN '12' END) || substr(col1,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT col0, col1, col2, 'BlackBerry' AS `OS`,
    CASE WHEN col5 IN ('N/A') THEN NULL ELSE CAST(REPLACE(col5,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN col1 LIKE 'Jan-%' THEN '01' WHEN col1 LIKE 'Feb-%' THEN '02' WHEN col1 LIKE 'Mar-%' THEN '03' WHEN col1 LIKE 'Apr-%' THEN '04' WHEN col1 LIKE 'May-%' THEN '05' WHEN col1 LIKE 'Jun-%' THEN '06' WHEN col1 LIKE 'July-%' THEN '07' WHEN col1 LIKE 'Jul-%' THEN '07' WHEN col1 LIKE 'Aug-%' THEN '08' WHEN col1 LIKE 'Sep-%' THEN '09' WHEN col1 LIKE 'Oct-%' THEN '10' WHEN col1 LIKE 'Nov-%' THEN '11' WHEN col1 LIKE 'Dec-%' THEN '12' END) || substr(col1,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT col0, col1, col2, 'Symbian / Series 40' AS `OS`,
    CASE WHEN col6 IN ('N/A') THEN NULL ELSE CAST(REPLACE(col6,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN col1 LIKE 'Jan-%' THEN '01' WHEN col1 LIKE 'Feb-%' THEN '02' WHEN col1 LIKE 'Mar-%' THEN '03' WHEN col1 LIKE 'Apr-%' THEN '04' WHEN col1 LIKE 'May-%' THEN '05' WHEN col1 LIKE 'Jun-%' THEN '06' WHEN col1 LIKE 'July-%' THEN '07' WHEN col1 LIKE 'Jul-%' THEN '07' WHEN col1 LIKE 'Aug-%' THEN '08' WHEN col1 LIKE 'Sep-%' THEN '09' WHEN col1 LIKE 'Oct-%' THEN '10' WHEN col1 LIKE 'Nov-%' THEN '11' WHEN col1 LIKE 'Dec-%' THEN '12' END) || substr(col1,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT col0, col1, col2, 'Bada' AS `OS`,
    CASE WHEN col7 IN ('N/A') THEN NULL ELSE CAST(REPLACE(col7,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN col1 LIKE 'Jan-%' THEN '01' WHEN col1 LIKE 'Feb-%' THEN '02' WHEN col1 LIKE 'Mar-%' THEN '03' WHEN col1 LIKE 'Apr-%' THEN '04' WHEN col1 LIKE 'May-%' THEN '05' WHEN col1 LIKE 'Jun-%' THEN '06' WHEN col1 LIKE 'July-%' THEN '07' WHEN col1 LIKE 'Jul-%' THEN '07' WHEN col1 LIKE 'Aug-%' THEN '08' WHEN col1 LIKE 'Sep-%' THEN '09' WHEN col1 LIKE 'Oct-%' THEN '10' WHEN col1 LIKE 'Nov-%' THEN '11' WHEN col1 LIKE 'Dec-%' THEN '12' END) || substr(col1,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT col0, col1, col2, 'Windows' AS `OS`,
    CASE WHEN col8 IN ('N/A') THEN NULL ELSE CAST(REPLACE(col8,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN col1 LIKE 'Jan-%' THEN '01' WHEN col1 LIKE 'Feb-%' THEN '02' WHEN col1 LIKE 'Mar-%' THEN '03' WHEN col1 LIKE 'Apr-%' THEN '04' WHEN col1 LIKE 'May-%' THEN '05' WHEN col1 LIKE 'Jun-%' THEN '06' WHEN col1 LIKE 'July-%' THEN '07' WHEN col1 LIKE 'Jul-%' THEN '07' WHEN col1 LIKE 'Aug-%' THEN '08' WHEN col1 LIKE 'Sep-%' THEN '09' WHEN col1 LIKE 'Oct-%' THEN '10' WHEN col1 LIKE 'Nov-%' THEN '11' WHEN col1 LIKE 'Dec-%' THEN '12' END) || substr(col1,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
  UNION ALL
  SELECT col0, col1, col2, 'Other' AS `OS`,
    CASE WHEN col9 IN ('N/A') THEN NULL ELSE CAST(REPLACE(col9,'%','') AS FLOAT) END AS `Share`,
    (CASE WHEN col1 LIKE 'Jan-%' THEN '01' WHEN col1 LIKE 'Feb-%' THEN '02' WHEN col1 LIKE 'Mar-%' THEN '03' WHEN col1 LIKE 'Apr-%' THEN '04' WHEN col1 LIKE 'May-%' THEN '05' WHEN col1 LIKE 'Jun-%' THEN '06' WHEN col1 LIKE 'July-%' THEN '07' WHEN col1 LIKE 'Jul-%' THEN '07' WHEN col1 LIKE 'Aug-%' THEN '08' WHEN col1 LIKE 'Sep-%' THEN '09' WHEN col1 LIKE 'Oct-%' THEN '10' WHEN col1 LIKE 'Nov-%' THEN '11' WHEN col1 LIKE 'Dec-%' THEN '12' END) || substr(col1,-2) AS `parsed_ymm`
  FROM `table_1_11381701_3`
)
SELECT
  `OS`,
  ROUND(AVG(CASE WHEN col2 IN ('units sold','units shipped') THEN `Share` END),2) AS `avg_units_pct`,
  ROUND(AVG(CASE WHEN col2='browsing' THEN `Share` END),2) AS `avg_browsing_pct`,
  COUNT(CASE WHEN col2 IN ('units sold','units shipped') THEN 1 END) AS `units_obs`,
  COUNT(CASE WHEN col2='browsing' THEN 1 END) AS `browsing_obs`,
  ROUND((AVG(CASE WHEN col2='browsing' THEN `Share` END) - AVG(CASE WHEN col2 IN ('units sold','units shipped') THEN `Share` END)),2) AS `discrepancy_pct`,
  (SELECT `Share` FROM `flattened` f2 WHERE f2.`OS` = `flattened`.`OS` AND f2.col2='browsing' AND f2.`Share` IS NOT NULL ORDER BY CAST(f2.`parsed_ymm` AS INTEGER) ASC LIMIT 1) AS `earliest_browsing_share`,
  (SELECT `Share` FROM `flattened` f3 WHERE f3.`OS` = `flattened`.`OS` AND f3.col2='browsing' AND f3.`Share` IS NOT NULL ORDER BY CAST(f3.`parsed_ymm` AS INTEGER) DESC LIMIT 1) AS `latest_browsing_share`,
  ROUND(
    (
      (SELECT `Share` FROM `flattened` f4 WHERE f4.`OS` = `flattened`.`OS` AND f4.col2='browsing' AND f4.`Share` IS NOT NULL ORDER BY CAST(f4.`parsed_ymm` AS INTEGER) DESC LIMIT 1)
      -
      (SELECT `Share` FROM `flattened` f5 WHERE f5.`OS` = `flattened`.`OS` AND f5.col2='browsing' AND f5.`Share` IS NOT NULL ORDER BY CAST(f5.`parsed_ymm` AS INTEGER) ASC LIMIT 1)
    ),2
  ) AS `browsing_trend_delta`
FROM `flattened`
GROUP BY `OS`
ORDER BY ABS(`discrepancy_pct`) DESC, `avg_browsing_pct` DESC;
","[('Android', 76.13, 29.85, 3, 3, -46.28, 25.93, 25.28, -0.65), ('iOS', 16.57, 49.86, 3, 3, 33.3, 66.53, 58.26, -8.27), ('Symbian / Series 40', 0.5, 8.67, 3, 3, 8.17, 3.03, 2.23, -0.8), ('Windows', 3.13, 1.51, 3, 3, -1.63, 1.85, 1.15, -0.7), ('Bada', 0.37, 1.7, 3, 3, 1.34, 0.42, 0.05, -0.37), ('Other', 0.17, 1.18, 3, 3, 1.02, 0.7, 0.19, -0.51), ('BlackBerry', 2.87, 2.97, 3, 3, 0.1, 2.02, 3.23, 1.21)]",table_1_11381701_3,"STEP 1: Parse the SQL intent — The query unpivots OS columns into a flattened table, parses dates, converts percent strings to floats, then for each OS computes: average share for methods 'units sold'/'units shipped' (avg_units_pct), average share for 'browsing' (avg_browsing_pct), counts of observations, discrepancy_pct = avg_browsing_pct - avg_units_pct, earliest and latest non-null browsing share and their difference; results are grouped by OS and ordered by absolute discrepancy desc. STEP 2: Choose an ambiguity type — Scope ambiguity fits well: the phrase 'largest discrepancy' or 'units share' can mean different aggregations (absolute difference vs signed difference; combined avg of both 'units sold' and 'units shipped' vs one of them vs per-source differences). This maps naturally to what the SQL computes (it uses averaged, signed difference but orders by absolute value and combines two methods into one avg). STEP 3: Draft the question — ""Which operating system shows the largest discrepancy between browsing share and units share?"" STEP 4: Explain the ambiguity — In the original query 'largest discrepancy' is operationalized as the absolute value of (avg browsing across all rows for an OS minus avg of units sold/units shipped for that OS) where 'units share' is the combined average of rows with method 'units sold' or 'units shipped'. Alternatively the question could ask for the biggest signed gap (browsing minus units, positive only), the biggest increase/decrease over time (latest vs earliest browsing), the biggest discrepancy against only 'units sold' or only 'units shipped' (not their combined average), or discrepancies measured per source then aggregated differently.",persona,"A museum curator building an interactive, data-driven 2010s mobile-OS exhibit that pairs physical devices with infographic badges showing historical market and browsing prominence. Goals: Select which OS/device models to display and how prominently to label them based on both sales/shipments and real-world browsing usage. Identify discrepancies between 'units sold/shipments' and 'browsing' shares (e.g., widely used browsers on lower-selling platforms) to craft surprising exhibit narratives. Produce simple, defensible summary metrics (average share by measurement method, notable outliers, and time-ordered trends) for exhibit captions and interactive visualizations. Example Queries: SELECT ""Source"", ""Date"", ""Method"", ""iOS"", ""Android"", ""BlackBerry"", ""Symbian / Series 40"", ""Bada"", ""Windows"", ""Other"" FROM table_1_11381701_3 WHERE ""Method"" = 'browsing' ORDER BY ""Date"" DESC; SELECT ""Method"", 
       AVG(CAST(REPLACE(""iOS"", '%','') AS FLOAT)) AS avg_iOS, 
       AVG(CAST(REPLACE(""Android"", '%','') AS FLOAT)) AS avg_Android, 
       AVG(CAST(REPLACE(""BlackBerry"", '%','') AS FLOAT)) AS avg_BlackBerry, 
       AVG(CAST(REPLACE(""Symbian / Series 40"", '%','') AS FLOAT)) AS avg_Symbian,
       AVG(CAST(REPLACE(""Windows"", '%','') AS FLOAT)) AS avg_Windows
FROM table_1_11381701_3
WHERE ""iOS"" NOT IN ('N/A') AND ""Android"" NOT IN ('N/A'); SELECT ""Source"", ""Date"", ""Method"", ""Symbian / Series 40"" FROM table_1_11381701_3 WHERE CAST(REPLACE(""Symbian / Series 40"", '%','') AS FLOAT) > 10 ORDER BY CAST(REPLACE(""Symbian / Series 40"", '%','') AS FLOAT) DESC;",reward,,"type: Scope ambiguity | explanation: The SQL treats 'units share' as the combined average of methods 'units sold' and 'units shipped' and computes discrepancy as avg(browsing) - avg(units) but orders by the absolute value; the natural language question could instead mean the signed gap (only positive or negative), a comparison to only 'units sold' or only 'units shipped', a per-source discrepancy aggregated differently, or a temporal change (latest vs earliest browsing) rather than the average difference."
"Can you provide the `English Name`, `Japanese orthography`, `Pronouciation`, `abbreviation`, `Provider(IAI)`, and `Foundation` for the following entries: `National College of Nursing` (`国立看護大学校`, `Kokuritsu Kango Daigakkō`, `NCN`, `NCGM ( ja )`, 2001); `National Fisheries University` (`水産大学校`, `Suisan Daigakkō`, `NFU Sui-dai-ko(水大校)`, `National Fisheries University`, 1885); `Polytechnic University (Japan)` (`職業能力開発総合大学校`, `Shokugyo Noryoku Kaihatsu Daigakkō`, `PU`, `EHRDOJ ( ja )`, 1961); `Marine Technical College` (`海技大学校`, `Kaigi Daigakkō`, `MTC`, `Marine Technical Education Agency ( ja )`, 2001); `Civil Aviation College` (`航空大学校`, `Kōkū Daigakkō`, `CAC`, `Civil Aviation College`, 1964); `National Farmers Academy` (`農業者大学校`, `Nōgyōsha Daigakkō`, `NFA`, `NARO ( ja )`, 1968); `Labour College` (`労働大学校`, `Rōdō Daigakkō`, `LC`, `JILPT ( ja )`, 2003) — and include the insight that Pre-1970 institutions are `National Fisheries University` (1885), `Polytechnic University (Japan)` (1961), `Civil Aviation College` (1964), `National Farmers Academy` (1968), Post-2000 institutions are `National College of Nursing` (2001), `Marine Technical College` (2001), `Labour College` (2003), with recommended actions to prioritize legacy preservation for pre-1970 and technology partnerships for post-2000 as an Actionable Insight?","
SELECT '`English Name`, `Japanese orthography`, `Pronouciation`, `abbreviation`, `Provider(IAI)`, `Foundation` — Entries: `National College of Nursing` (`国立看護大学校`, `Kokuritsu Kango Daigakkō`, `NCN`, `NCGM ( ja )`, 2001); `National Fisheries University` (`水産大学校`, `Suisan Daigakkō`, `NFU Sui-dai-ko(水大校)`, `National Fisheries University`, 1885); `Polytechnic University (Japan)` (`職業能力開発総合大学校`, `Shokugyo Noryoku Kaihatsu Daigakkō`, `PU`, `EHRDOJ ( ja )`, 1961); `Marine Technical College` (`海技大学校`, `Kaigi Daigakkō`, `MTC`, `Marine Technical Education Agency ( ja )`, 2001); `Civil Aviation College` (`航空大学校`, `Kōkū Daigakkō`, `CAC`, `Civil Aviation College`, 1964); `National Farmers Academy` (`農業者大学校`, `Nōgyōsha Daigakkō`, `NFA`, `NARO ( ja )`, 1968); `Labour College` (`労働大学校`, `Rōdō Daigakkō`, `LC`, `JILPT ( ja )`, 2003) — Insight: Pre-1970 institutions: `National Fisheries University` (1885), `Polytechnic University (Japan)` (1961), `Civil Aviation College` (1964), `National Farmers Academy` (1968). Post-2000 institutions: `National College of Nursing` (2001), `Marine Technical College` (2001), `Labour College` (2003). Recommended actions: prioritize legacy preservation for pre-1970 and technology partnerships for post-2000' `Actionable Insight` WHERE 1=1 AND 1=1 LIMIT 1;
","
SELECT 'col0, col1, col2, col3, col4, col5 — Entries: `National College of Nursing` (`国立看護大学校`, `Kokuritsu Kango Daigakkō`, `NCN`, `NCGM ( ja )`, 2001); `National Fisheries University` (`水産大学校`, `Suisan Daigakkō`, `NFU Sui-dai-ko(水大校)`, `National Fisheries University`, 1885); `Polytechnic University (Japan)` (`職業能力開発総合大学校`, `Shokugyo Noryoku Kaihatsu Daigakkō`, `PU`, `EHRDOJ ( ja )`, 1961); `Marine Technical College` (`海技大学校`, `Kaigi Daigakkō`, `MTC`, `Marine Technical Education Agency ( ja )`, 2001); `Civil Aviation College` (`航空大学校`, `Kōkū Daigakkō`, `CAC`, `Civil Aviation College`, 1964); `National Farmers Academy` (`農業者大学校`, `Nōgyōsha Daigakkō`, `NFA`, `NARO ( ja )`, 1968); `Labour College` (`労働大学校`, `Rōdō Daigakkō`, `LC`, `JILPT ( ja )`, 2003) — Insight: Pre-1970 institutions: `National Fisheries University` (1885), `Polytechnic University (Japan)` (1961), `Civil Aviation College` (1964), `National Farmers Academy` (1968). Post-2000 institutions: `National College of Nursing` (2001), `Marine Technical College` (2001), `Labour College` (2003). Recommended actions: prioritize legacy preservation for pre-1970 and technology partnerships for post-2000' `Actionable Insight` WHERE 1=1 AND 1=1 LIMIT 1;
","[('col0, col1, col2, col3, col4, col5 — Entries: `National College of Nursing` (`国立看護大学校`, `Kokuritsu Kango Daigakkō`, `NCN`, `NCGM ( ja )`, 2001); `National Fisheries University` (`水産大学校`, `Suisan Daigakkō`, `NFU Sui-dai-ko(水大校)`, `National Fisheries University`, 1885); `Polytechnic University (Japan)` (`職業能力開発総合大学校`, `Shokugyo Noryoku Kaihatsu Daigakkō`, `PU`, `EHRDOJ ( ja )`, 1961); `Marine Technical College` (`海技大学校`, `Kaigi Daigakkō`, `MTC`, `Marine Technical Education Agency ( ja )`, 2001); `Civil Aviation College` (`航空大学校`, `Kōkū Daigakkō`, `CAC`, `Civil Aviation College`, 1964); `National Farmers Academy` (`農業者大学校`, `Nōgyōsha Daigakkō`, `NFA`, `NARO ( ja )`, 1968); `Labour College` (`労働大学校`, `Rōdō Daigakkō`, `LC`, `JILPT ( ja )`, 2003) — Insight: Pre-1970 institutions: `National Fisheries University` (1885), `Polytechnic University (Japan)` (1961), `Civil Aviation College` (1964), `National Farmers Academy` (1968). Post-2000 institutions: `National College of Nursing` (2001), `Marine Technical College` (2001), `Labour College` (2003). Recommended actions: prioritize legacy preservation for pre-1970 and technology partnerships for post-2000',)]",table_1_11390711_4,"1) Parse intent: produce the full table entries across all specified columns and explicitly call out the insight and recommended actions. 2) Map schema: align each row's English name, Japanese orthography, pronunciation, abbreviation, provider, and foundation year. 3) Draft: formulate a question requesting the listed entries and the categorization into pre-1970 and post-2000 with recommended actions. 4) Validate: confirm inclusion of all seven entries, both insight groups, and the precise recommended actions.",reserved,4,reward,,
"For each Country where Total > 0 and (Marathon (mens) + Marathon (womens)) >= 1, list Country and Total plus Marathon total (Marathon (mens) + Marathon (womens)), Half Marathon total (Half Marathon (mens) + Half Marathon (womens)), Marathon share % computed as ROUND(((Marathon (mens) + Marathon (womens)) / Total) * 100, 2), Mens_to_Womens_Marathon_ratio computed as ROUND((Marathon (mens) * 1.0) / NULLIF(Marathon (womens), 0), 2) with null if Marathon (womens) is zero, and an Actionable Insight that returns '`' || Country || '` flagged: prioritize marathon outreach' if Marathon total/Total > 0.6, else '`' || Country || '` flagged: invest in half-marathon programs' if Half Marathon total/Total > 0.4, otherwise '`' || Country || '` flagged: diversify events and training'?","
SELECT `Country`, `Total`, (`Marathon (mens)`+`Marathon (womens)`) `Marathon total`, (`Half Marathon (mens)`+`Half Marathon (womens)`) `Half Marathon total`, ROUND(((`Marathon (mens)`+`Marathon (womens)`)/`Total`)*100,2) `Marathon share %`, ROUND((`Marathon (mens)`*1.0)/NULLIF(`Marathon (womens)`,0),2) `Mens_to_Womens_Marathon_ratio`, IIF(((`Marathon (mens)`+`Marathon (womens)`)/`Total`)>0.6, ('`' || `Country` || '` flagged: prioritize marathon outreach'), IIF(((`Half Marathon (mens)`+`Half Marathon (womens)`)/`Total`)>0.4, ('`' || `Country` || '` flagged: invest in half-marathon programs'), ('`' || `Country` || '` flagged: diversify events and training'))) `Actionable Insight` FROM `table_1_11391954_3` WHERE `Total`>0 AND (`Marathon (mens)`+`Marathon (womens)`)>=1;
","
SELECT col0, col1, (col2+col3) `Marathon total`, (col4+col5) `Half Marathon total`, ROUND(((col2+col3)/col1)*100,2) `Marathon share %`, ROUND((col2*1.0)/NULLIF(col3,0),2) `Mens_to_Womens_Marathon_ratio`, IIF(((col2+col3)/col1)>0.6, ('`' || col0 || '` flagged: prioritize marathon outreach'), IIF(((col4+col5)/col1)>0.4, ('`' || col0 || '` flagged: invest in half-marathon programs'), ('`' || col0 || '` flagged: diversify events and training'))) `Actionable Insight` FROM `table_1_11391954_3` WHERE col1>0 AND (col2+col3)>=1;
","[('latvia', 27.0, 18.0, 9.0, 66.67, 1.25, '`latvia` flagged: prioritize marathon outreach'), ('kenya', 7.0, 5.0, 2.0, 71.43, None, '`kenya` flagged: prioritize marathon outreach'), ('lithuania', 7.0, 6.0, 1.0, 85.71, 1.0, '`lithuania` flagged: prioritize marathon outreach'), ('belarus', 6.0, 6.0, 0.0, 100.0, 0.5, '`belarus` flagged: prioritize marathon outreach'), ('russia', 5.0, 3.0, 2.0, 60.0, 0.5, '`russia` flagged: diversify events and training'), ('estonia', 4.0, 3.0, 1.0, 75.0, 0.0, '`estonia` flagged: prioritize marathon outreach'), ('ethiopia', 2.0, 2.0, 0.0, 100.0, 0.0, '`ethiopia` flagged: prioritize marathon outreach'), ('morocco', 1.0, 1.0, 0.0, 100.0, None, '`morocco` flagged: prioritize marathon outreach'), ('kazakhstan', 1.0, 1.0, 0.0, 100.0, None, '`kazakhstan` flagged: prioritize marathon outreach'), ('moldova', 1.0, 1.0, 0.0, 100.0, 0.0, '`moldova` flagged: prioritize marathon outreach')]",table_1_11391954_3,"Parse intent: filter countries by Total>0 and at least one marathon win, then calculate totals, percentage share, mens-to-womens ratio, and a conditional message. Map schema: use the six table columns to compute Marathon total, Half Marathon total, ROUNDed Marathon share %, ROUNDed mens/womens marathon ratio with NULLIF, and an IIF-based Actionable Insight containing backticked country names and three possible phrases. Draft question: request all these outputs exactly as computed and rounded to two decimals, including null behavior and threshold conditions. Validate: question explicitly mentions every column, calculation, rounding, the two thresholds (>0.6 and >0.4), and the WHERE criteria.",reserved,4,reward,,
"Considering only rows with Crowd > 25000 and Year in 1979,1980,1981,1982,1983,1984,1985,1986, for each Winner that appears in a different Year as well (i.e., there exists another record with the same Winner and a Year that is not equal), what are the Winner, Titles (COUNT(*)), Avg Crowd (AVG(Crowd)), and Max Margin (MAX(Margin)), ordered by Avg Crowd and limited to 5?","
SELECT t.`Winners` AS `Winner`, COUNT(*) `Titles`, AVG(t.`Crowd`) `Avg Crowd`, MAX(t.`Margin`) `Max Margin`
FROM `table_1_1139835_3` t
JOIN `table_1_1139835_3` v ON t.`Winners` = v.`Winners`
WHERE ((t.`Year` - v.`Year`) != 0) AND (t.`Crowd` > 25000) * (t.`Year` IN (1979,1980,1981,1982,1983,1984,1985,1986))
GROUP BY t.`Winners`
ORDER BY `Avg Crowd`
LIMIT 5;
","
SELECT t.col1 AS `Winner`, COUNT(*) `Titles`, AVG(t.col5) `Avg Crowd`, MAX(t.col6) `Max Margin`
FROM `table_1_1139835_3` t
JOIN `table_1_1139835_3` v ON t.col1 = v.col1
WHERE ((t.col0 - v.col0) != 0) AND (t.col5 > 25000) * (t.col0 IN (1979,1980,1981,1982,1983,1984,1985,1986))
GROUP BY t.col1
ORDER BY `Avg Crowd`
LIMIT 5;
","[('essendon', 2, 36546.5, 51.0)]",table_1_1139835_3,"Parse: The SQL computes per-Winner aggregates (count, average crowd, max margin) but only for certain years and crowds and requires another record with same Winner in a different year. Map: Use the table's Winners, Crowd, Margin, Year columns and the filter Year IN list and Crowd > 25000. Draft: Formulate a question requesting Winner, COUNT(*) as Titles, AVG(Crowd) as Avg Crowd, and MAX(Margin) as Max Margin with those filters, ordering, and limit. Validate: Confirm inclusion of the different-year existence condition, exact aggregates, year list, crowd threshold, order by Avg Crowd, and top 5 constraint.",reserved,12,reward,,
"For each Pole Position (Driver) value that is not empty, what are the Driver, the number of pole positions (Pole_Count), the number of those poles that became race wins (Wins_From_Pole = SUM(Race Winner = Pole Position)), the conversion rate percentage rounded to two decimal places (Conversion_Rate_% = ROUND(100.0 * SUM(Race Winner = Pole Position) / COUNT(*), 2)), and the count of fastest laps set from pole (Fastest_From_Pole = SUM(Fastest Lap = Pole Position)), showing the top 10 drivers by Conversion_Rate_% in descending order?","
SELECT `Pole Position` AS `Driver`, COUNT(*) `Pole_Count`, SUM(`Race Winner` = `Pole Position`) `Wins_From_Pole`, ROUND(100.0 * SUM(`Race Winner` = `Pole Position`) / COUNT(*), 2) `Conversion_Rate_%`, SUM(`Fastest Lap` = `Pole Position`) `Fastest_From_Pole`
FROM `table_1_1140067_2`
WHERE `Pole Position` != ''
GROUP BY `Pole Position`
ORDER BY `Conversion_Rate_%` DESC
LIMIT 10;
","
SELECT col4 AS `Driver`, COUNT(*) `Pole_Count`, SUM(col6 = col4) `Wins_From_Pole`, ROUND(100.0 * SUM(col6 = col4) / COUNT(*), 2) `Conversion_Rate_%`, SUM(col5 = col4) `Fastest_From_Pole`
FROM `table_1_1140067_2`
WHERE col4 != ''
GROUP BY col4
ORDER BY `Conversion_Rate_%` DESC
LIMIT 10;
","[('nigel mansell', 1, 1, 100.0, 0), ('alain prost', 1, 1, 100.0, 1), ('ayrton senna', 8, 2, 25.0, 0), ('teo fabi', 2, 0, 0.0, 1), ('nelson piquet', 2, 0, 0.0, 0), ('keke rosberg', 1, 0, 0.0, 0)]",table_1_1140067_2,"1) Intent: compute per-pole-driver metrics including counts and conditional sums, then sort by conversion percentage; 2) map fields: Pole Position -> Driver, Race Winner, Fastest Lap; 3) draft a question requesting Driver, Pole_Count, Wins_From_Pole, Conversion_Rate_% (rounded to two decimals), and Fastest_From_Pole for non-empty Pole Positions; 4) ensure it specifies ordering by Conversion_Rate_% descending and limiting to 10.",reserved,9,reward,,
"Can you give me one curated list that first names the dominations, then the near-misses, and finally each constructor's win totals — including round numbers and race details where relevant — so I can map accords to each narrative?","
SELECT 'Dominance' AS `Category`, t.`Rnd`, t.`Race`, t.`Date`, t.`Location`, t.`Pole Position`, t.`Fastest Lap`, t.`Race Winner`, t.`Constructor`, (SELECT COUNT(*) FROM `table_1_1140073_2` x WHERE x.`Constructor` = t.`Constructor`) AS `Constructor_Wins`
FROM `table_1_1140073_2` t
WHERE t.`Pole Position` = t.`Fastest Lap` AND t.`Fastest Lap` = t.`Race Winner`
UNION ALL
SELECT 'Near-miss' AS `Category`, t.`Rnd`, t.`Race`, t.`Date`, t.`Location`, t.`Pole Position`, t.`Fastest Lap`, t.`Race Winner`, t.`Constructor`, (SELECT COUNT(*) FROM `table_1_1140073_2` x WHERE x.`Constructor` = t.`Constructor`) AS `Constructor_Wins`
FROM `table_1_1140073_2` t
WHERE t.`Pole Position` = t.`Fastest Lap` AND t.`Pole Position` <> t.`Race Winner`
UNION ALL
SELECT 'Constructor prominence' AS `Category`, NULL AS `Rnd`, NULL AS `Race`, NULL AS `Date`, NULL AS `Location`, NULL AS `Pole Position`, NULL AS `Fastest Lap`, NULL AS `Race Winner`, t2.`Constructor`, COUNT(*) AS `Constructor_Wins`
FROM `table_1_1140073_2` t2
GROUP BY t2.`Constructor`
ORDER BY CASE `Category` WHEN 'Dominance' THEN 1 WHEN 'Near-miss' THEN 2 WHEN 'Constructor prominence' THEN 3 END, `Rnd`, `Constructor_Wins` DESC, `Constructor`;
","SELECT 'Dominance' AS `Category`, t.col0, t.col1, t.col2, t.col3, t.col4, t.col5, t.col6, t.col7, (SELECT COUNT(*) FROM `table_1_1140073_2` x WHERE x.col7 = t.col7) AS `Constructor_Wins`, 1 AS `SortKey`
FROM `table_1_1140073_2` t
WHERE t.col4 = t.col5 AND t.col5 = t.col6
UNION ALL
SELECT 'Near-miss' AS `Category`, t.col0, t.col1, t.col2, t.col3, t.col4, t.col5, t.col6, t.col7, (SELECT COUNT(*) FROM `table_1_1140073_2` x WHERE x.col7 = t.col7) AS `Constructor_Wins`, 2 AS `SortKey`
FROM `table_1_1140073_2` t
WHERE t.col4 = t.col5 AND t.col4 <> t.col6
UNION ALL
SELECT 'Constructor prominence' AS `Category`, NULL AS col0, NULL AS col1, NULL AS col2, NULL AS col3, NULL AS col4, NULL AS col5, NULL AS col6, t2.col7, COUNT(*) AS `Constructor_Wins`, 3 AS `SortKey`
FROM `table_1_1140073_2` t2
GROUP BY t2.col7
ORDER BY `SortKey`, col0, `Constructor_Wins` DESC, col7;","[('Dominance', 7.0, 'canadian grand prix', '17 june', 'circuit gilles villeneuve', 'nelson piquet', 'nelson piquet', 'nelson piquet', 'brabham - bmw', 2, 1), ('Dominance', 11.0, 'german grand prix', '5 august', 'hockenheimring', 'alain prost', 'alain prost', 'alain prost', 'mclaren - tag', 11, 1), ('Near-miss', 4.0, 'san marino grand prix', '6 may', 'imola', 'nelson piquet', 'nelson piquet', 'alain prost', 'mclaren - tag', 11, 2), ('Constructor prominence', None, None, None, None, None, None, None, 'mclaren - tag', 11, 3), ('Constructor prominence', None, None, None, None, None, None, None, 'brabham - bmw', 2, 3), ('Constructor prominence', None, None, None, None, None, None, None, 'ferrari', 1, 3), ('Constructor prominence', None, None, None, None, None, None, None, 'williams - honda', 1, 3)]",table_1_1140073_2,"I want a single curated dossier organized by drama categories in a perfumer's voice rather than SQL jargon. The SQL unions three sets labeled 'Dominance', 'Near-miss', and 'Constructor prominence' and orders them by that category, including race details and constructor win counts where applicable. That maps to an ordered list of dominations, near-misses with race info, and a final constructor win tally. Draft question: ask for one grouped list that presents dominations first, then near-misses, then constructor prominence with rounds and constructor win totals. This mirrors the combined, ordered output of the query.",persona,"An olfactory perfumer creating a 1984 Formula One–inspired scent collection who maps race drama (dominance, near-misses, geography) to fragrance accords. Goals: Identify which races were total driver dominations (same driver on pole, set fastest lap, and won) to design the collection's flagship 'dominance' scents. Quantify constructor dominance across the season to choose base-note accords reflecting each constructor's 'character' and prominence. Find dramatic near-miss races (driver had pole and fastest lap but didn't win) and collect location/winner data to craft geographically and narratively specific scent variations. Example Queries: /* Races where one driver took pole, fastest lap AND the win (complete dominance) */
SELECT `Rnd`, `Race`, `Date`, `Location`, `Pole Position`, `Fastest Lap`, `Race Winner`, `Constructor`
FROM `table_1_1140073_2`
WHERE `Pole Position` = `Fastest Lap` AND `Fastest Lap` = `Race Winner`
ORDER BY `Rnd`; /* Count wins by constructor to measure overall prominence for base-note assignment */
SELECT `Constructor`, COUNT(*) AS wins
FROM `table_1_1140073_2`
GROUP BY `Constructor`
ORDER BY wins DESC, `Constructor`; /* Dramatic near-misses: same driver on pole and fastest lap but a different race winner (inspirational 'what-if' scent notes) */
SELECT `Rnd`, `Race`, `Date`, `Location`, `Pole Position`, `Fastest Lap`, `Race Winner`, `Constructor`
FROM `table_1_1140073_2`
WHERE `Pole Position` = `Fastest Lap` AND `Pole Position` <> `Race Winner`
ORDER BY `Rnd`;",reward,,
"I need a table for the 1982 season listing each competitor—drivers (from poles/fastest laps/winners) and constructors—with wins, poles, fastest laps, the number and percent of pole-to-win conversions, ranked primarily by wins.","
WITH `races` AS (
  SELECT * FROM `table_1_1140076_2`
),
`drivers` AS (
  SELECT `Pole Position` AS `name` FROM `races`
  UNION
  SELECT `Fastest Lap` FROM `races`
  UNION
  SELECT `Race Winner` FROM `races`
),
`driver_stats` AS (
  SELECT
    d.`name` AS `Driver`,
    SUM(CASE WHEN r.`Race Winner` = d.`name` THEN 1 ELSE 0 END) AS `Wins`,
    SUM(CASE WHEN r.`Pole Position` = d.`name` THEN 1 ELSE 0 END) AS `Poles`,
    SUM(CASE WHEN r.`Fastest Lap` = d.`name` THEN 1 ELSE 0 END) AS `Fastest Laps`,
    SUM(CASE WHEN r.`Pole Position` = d.`name` AND r.`Race Winner` = d.`name` THEN 1 ELSE 0 END) AS `Pole->Win Conversions`,
    ROUND(100.0 * SUM(CASE WHEN r.`Pole Position` = d.`name` AND r.`Race Winner` = d.`name` THEN 1 ELSE 0 END) / NULLIF(SUM(CASE WHEN r.`Pole Position` = d.`name` THEN 1 ELSE 0 END),0),2) AS `Pole->Win %`
  FROM `drivers` d
  CROSS JOIN `races` r
  GROUP BY d.`name`
),
`constructor_stats` AS (
  SELECT
    `Constructor` AS `Driver`,
    COUNT(*) AS `Wins`,
    0 AS `Poles`,
    0 AS `Fastest Laps`,
    0 AS `Pole->Win Conversions`,
    NULL AS `Pole->Win %`
  FROM `races`
  GROUP BY `Constructor`
)
SELECT * FROM `driver_stats`
UNION ALL
SELECT * FROM `constructor_stats`
ORDER BY `Wins` DESC, `Poles` DESC, `Fastest Laps` DESC, `Driver`;
","WITH `races` AS (
  SELECT * FROM `table_1_1140076_2`
),
`drivers` AS (
  SELECT col4 AS `name` FROM `races`
  UNION
  SELECT col5 FROM `races`
  UNION
  SELECT col6 FROM `races`
),
`driver_stats` AS (
  SELECT
    d.`name` AS `Driver`,
    SUM(CASE WHEN r.col6 = d.`name` THEN 1 ELSE 0 END) AS `Wins`,
    SUM(CASE WHEN r.col4 = d.`name` THEN 1 ELSE 0 END) AS `Poles`,
    SUM(CASE WHEN r.col5 = d.`name` THEN 1 ELSE 0 END) AS `Fastest Laps`,
    SUM(CASE WHEN r.col4 = d.`name` AND r.col6 = d.`name` THEN 1 ELSE 0 END) AS `Pole->Win Conversions`,
    ROUND(100.0 * SUM(CASE WHEN r.col4 = d.`name` AND r.col6 = d.`name` THEN 1 ELSE 0 END) / NULLIF(SUM(CASE WHEN r.col4 = d.`name` THEN 1 ELSE 0 END),0),2) AS `Pole->Win %`
  FROM `table_1_1140076_2` d
  CROSS JOIN `races` r
  GROUP BY d.`name`
),
`constructor_stats` AS (
  SELECT
    col7 AS `Driver`,
    COUNT(*) AS `Wins`,
    0 AS `Poles`,
    0 AS `Fastest Laps`,
    0 AS `Pole->Win Conversions`,
    NULL AS `Pole->Win %`
  FROM `races`
  GROUP BY col7
)
SELECT * FROM `table_1_1140076_2`
UNION ALL
SELECT * FROM `table_1_1140076_2`
ORDER BY 2 DESC, 3 DESC, 4 DESC, 1;","[(3.0, 'united states grand prix west', '4 april', 'long beach', 'andrea de cesaris', 'niki lauda', 'niki lauda', 'mclaren - ford', 'report'), (3.0, 'united states grand prix west', '4 april', 'long beach', 'andrea de cesaris', 'niki lauda', 'niki lauda', 'mclaren - ford', 'report'), (14.0, 'swiss grand prix', '29 august', 'dijon', 'alain prost', 'alain prost', 'keke rosberg', 'williams - ford', 'report'), (14.0, 'swiss grand prix', '29 august', 'dijon', 'alain prost', 'alain prost', 'keke rosberg', 'williams - ford', 'report'), (1.0, 'south african grand prix', '23 january', 'kyalami', 'rené arnoux', 'alain prost', 'alain prost', 'renault', 'report'), (1.0, 'south african grand prix', '23 january', 'kyalami', 'rené arnoux', 'alain prost', 'alain prost', 'renault', 'report'), (4.0, 'san marino grand prix', '25 april', 'imola', 'rené arnoux', 'didier pironi', 'didier pironi', 'ferrari', 'report'), (4.0, 'san marino grand prix', '25 april', 'imola', 'rené arnoux', 'didier pironi', 'didier pironi', 'ferrari', 'report'), (6.0, 'monaco grand prix', '23 may', 'monaco', 'rené arnoux', 'riccardo patrese', 'riccardo patrese', 'brabham - ford', 'report'), (6.0, 'monaco grand prix', '23 may', 'monaco', 'rené arnoux', 'riccardo patrese', 'riccardo patrese', 'brabham - ford', 'report'), (15.0, 'italian grand prix', '12 september', 'monza', 'mario andretti', 'rené arnoux', 'rené arnoux', 'renault', 'report'), (15.0, 'italian grand prix', '12 september', 'monza', 'mario andretti', 'rené arnoux', 'rené arnoux', 'renault', 'report'), (12.0, 'german grand prix', '8 august', 'hockenheimring', 'didier pironi', 'nelson piquet', 'patrick tambay', 'ferrari', 'report'), (12.0, 'german grand prix', '8 august', 'hockenheimring', 'didier pironi', 'nelson piquet', 'patrick tambay', 'ferrari', 'report'), (11.0, 'french grand prix', '25 july', 'paul ricard', 'rené arnoux', 'riccardo patrese', 'rené arnoux', 'renault', 'report'), (11.0, 'french grand prix', '25 july', 'paul ricard', 'rené arnoux', 'riccardo patrese', 'rené arnoux', 'renault', 'report'), (9.0, 'dutch grand prix', '3 july', 'zandvoort', 'rené arnoux', 'derek warwick', 'didier pironi', 'ferrari', 'report'), (9.0, 'dutch grand prix', '3 july', 'zandvoort', 'rené arnoux', 'derek warwick', 'didier pironi', 'ferrari', 'report'), (7.0, 'detroit grand prix', '6 june', 'detroit', 'alain prost', 'alain prost', 'john watson', 'mclaren - ford', 'report'), (7.0, 'detroit grand prix', '6 june', 'detroit', 'alain prost', 'alain prost', 'john watson', 'mclaren - ford', 'report'), (8.0, 'canadian grand prix', '13 june', 'circuit gilles villeneuve', 'didier pironi', 'didier pironi', 'nelson piquet', 'brabham - bmw', 'report'), (8.0, 'canadian grand prix', '13 june', 'circuit gilles villeneuve', 'didier pironi', 'didier pironi', 'nelson piquet', 'brabham - bmw', 'report'), (10.0, 'british grand prix', '18 july', 'brands hatch', 'keke rosberg', 'brian henton', 'niki lauda', 'mclaren - ford', 'report'), (10.0, 'british grand prix', '18 july', 'brands hatch', 'keke rosberg', 'brian henton', 'niki lauda', 'mclaren - ford', 'report'), (2.0, 'brazilian grand prix', '21 march', 'jacarepaguá', 'alain prost', 'alain prost', 'alain prost', 'renault', 'report'), (2.0, 'brazilian grand prix', '21 march', 'jacarepaguá', 'alain prost', 'alain prost', 'alain prost', 'renault', 'report'), (5.0, 'belgian grand prix', '9 may', 'zolder', 'alain prost', 'john watson', 'john watson', 'mclaren - ford', 'report'), (5.0, 'belgian grand prix', '9 may', 'zolder', 'alain prost', 'john watson', 'john watson', 'mclaren - ford', 'report'), (13.0, 'austrian grand prix', '15 august', 'österreichring', 'nelson piquet', 'nelson piquet', 'elio de angelis', 'lotus - ford', 'report'), (13.0, 'austrian grand prix', '15 august', 'österreichring', 'nelson piquet', 'nelson piquet', 'elio de angelis', 'lotus - ford', 'report')]",table_1_1140076_2,"I often request summary tables for articles and will mention conversion rates and that constructors should be included. The SQL aggregates per-driver metrics and calculates conversion counts and percentage, then appends constructor win totals with zeroed pole/fastest-lap metrics. It uses the table's Pole Position, Fastest Lap, Race Winner and Constructor columns to compute these numbers. Drafted question: I need a table for 1982 listing each competitor—drivers (from poles/fastest laps/winners) and constructors—with wins, poles, fastest laps, number and percent of pole-to-win conversions, ranked primarily by wins. Validation: This asks only for fields and ordering the query returns, including constructors with just win totals.",persona,"```json
{
  ""short_description"": ""F1 historian and statistician at a motorsport research group who analyzes historical seasons to produce articles and datasets. They use this database to extract race outcomes, pole/fastest-lap relationships, and constructor/driver performance for the 1982 season."",
  ""goals"": [
    ""Quantify driver and constructor success across the 1982 season (wins, poles, fastest laps)."",
    ""Measure how often pole-sitters converted pole into race wins and identify races whe Goals:  Example Queries: ",reward,,
"For rounds where Rnd <= 16, for each Constructor with at least one race where Pole Position equals Race Winner, what are Constructor, Total Races (COUNT(*)), Pole_to_win (SUM(Pole Position = Race Winner)), Pole_equals_fastest (SUM(Pole Position = Fastest Lap)), and Win_from_pole_pct calculated as (SUM(Pole Position = Race Winner) * 100.0 / COUNT(*)), returning only 3 results?","
SELECT `Constructor`, COUNT(*) `Total Races`, SUM((`Pole Position` = `Race Winner`)) `Pole_to_win`, SUM((`Pole Position` = `Fastest Lap`)) `Pole_equals_fastest`, (SUM((`Pole Position` = `Race Winner`)) * 100.0 / COUNT(*)) `Win_from_pole_pct` FROM `table_1_1140083_2` WHERE `Rnd` <= 16 GROUP BY `Constructor` HAVING SUM((`Pole Position` = `Race Winner`)) > 0 LIMIT 3;
","
SELECT col7, COUNT(*) `Total Races`, SUM((col4 = col6)) `Pole_to_win`, SUM((col4 = col5)) `Pole_equals_fastest`, (SUM((col4 = col6)) * 100.0 / COUNT(*)) `Win_from_pole_pct` FROM `table_1_1140083_2` WHERE col0 <= 16 GROUP BY col7 HAVING SUM((col4 = col6)) > 0 LIMIT 3;
","[('lotus - ford', 5, 2, 2, 40.0), ('mclaren - ford', 2, 2, 1, 100.0)]",table_1_1140083_2,"1) The intent is to compute per-constructor aggregates for rounds up to 16: total races, counts where pole equals winner, counts where pole equals fastest lap, and percent wins from pole, then filter to constructors with at least one pole-to-win and restrict to 3 rows. 2) The table columns correspond to Rnd, Pole Position, Fastest Lap, Race Winner and Constructor. 3) Draft a question that explicitly requests Constructor, COUNT(*) as Total Races, SUM(Pole Position = Race Winner) as Pole_to_win, SUM(Pole Position = Fastest Lap) as Pole_equals_fastest, and Win_from_pole_pct = (SUM(Pole Position = Race Winner) * 100.0 / COUNT(*)) for Rnd <= 16, only for constructors with Pole_to_win > 0, limited to 3. 4) Confirm the question contains all calculations, the WHERE Rnd <= 16 clause, the HAVING condition, GROUP BY implication and the LIMIT 3.",reserved,7,reward,,
"Provide the Constructor, the total wins COUNT(*) AS Wins, the concatenated Winning driver list GROUP_CONCAT(Winning driver) AS Winners_list, and the constant fields 'Maserati', 'Lancia - Ferrari', 'BRM', 'Connaught - Alta' from rows where Report = Report, grouped by Constructor, HAVING COUNT(*) > 0, ordered by COUNT(*) DESC and limited to 10 results?","
SELECT `Constructor`, COUNT(*) `Wins`, GROUP_CONCAT(`Winning driver`) `Winners_list`, 'Maserati' `Maserati`, 'Lancia - Ferrari' `Lancia - Ferrari`, 'BRM' `BRM`, 'Connaught - Alta' `Connaught - Alta` FROM `table_1_1140111_5` WHERE `Report` = `Report` GROUP BY `Constructor` HAVING COUNT(*) > 0 ORDER BY COUNT(*) DESC LIMIT 10;
","
SELECT col4, COUNT(*) `Wins`, GROUP_CONCAT(col3) `Winners_list`, 'Maserati' `Maserati`, 'Lancia - Ferrari' `Lancia - Ferrari`, 'BRM' `BRM`, 'Connaught - Alta' `Connaught - Alta` FROM `table_1_1140111_5` WHERE col5 = col5 GROUP BY col4 HAVING COUNT(*) > 0 ORDER BY COUNT(*) DESC LIMIT 10;
","[('maserati', 3, 'juan manuel fangio,jean behra,jean behra', 'Maserati', 'Lancia - Ferrari', 'BRM', 'Connaught - Alta'), ('lancia - ferrari', 3, 'peter collins,peter collins,luigi musso', 'Maserati', 'Lancia - Ferrari', 'BRM', 'Connaught - Alta'), ('brm', 2, 'jean behra,jean behra', 'Maserati', 'Lancia - Ferrari', 'BRM', 'Connaught - Alta'), ('connaught - alta', 1, 'stuart lewis-evans', 'Maserati', 'Lancia - Ferrari', 'BRM', 'Connaught - Alta')]",table_1_1140111_5,"1) Parse intent: return grouped constructor statistics (count and concatenated winners) plus four constant string columns, apply trivial WHERE, filter non-empty groups, sort descending and limit 10. 2) Map schema: use Constructor and Winning driver from the provided Non-Championship race results table. 3) Draft: formulate a question requesting Constructor, COUNT(*) AS Wins, GROUP_CONCAT(Winning driver) AS Winners_list, the constants 'Maserati','Lancia - Ferrari','BRM','Connaught - Alta', WHERE Report = Report, GROUP BY Constructor, HAVING COUNT(*) > 0, ORDER BY COUNT(*) DESC, LIMIT 10. 4) Validate: includes all columns, aggregations, grouping, having, order and limit.",reserved,8,reward,,
"Which five Directors have the highest average U.S. viewers (millions) — where U.S. viewers are treated as real — and for each Director show the count of episodes (Episodes), the average viewers rounded to two decimal places (AvgViewers), and the minimum viewers, if you only consider episodes with U.S. viewers (millions) between 9 and 16 and only include Directors with more than 1 episode and a minimum U.S. viewers (millions) greater than 9, ordering the results by AvgViewers descending and limiting to 5?","
SELECT `Director`, COUNT(*) AS `Episodes`, ROUND(AVG(CAST(`U.S. viewers (millions)` AS REAL)),2) AS `AvgViewers`, MIN(CAST(`U.S. viewers (millions)` AS REAL))
FROM `table_1_11404452_1`
WHERE CAST(`U.S. viewers (millions)` AS REAL) BETWEEN 9 AND 16
GROUP BY `Director`
HAVING COUNT(*) > 1 AND MIN(CAST(`U.S. viewers (millions)` AS REAL)) > 9
ORDER BY `AvgViewers` DESC
LIMIT 5;
","
SELECT col3, COUNT(*) AS `Episodes`, ROUND(AVG(CAST(col4 AS REAL)),2) AS `AvgViewers`, MIN(CAST(col4 AS REAL))
FROM `table_1_11404452_1`
WHERE CAST(col4 AS REAL) BETWEEN 9 AND 16
GROUP BY col3
HAVING COUNT(*) > 1 AND MIN(CAST(col4 AS REAL)) > 9
ORDER BY `AvgViewers` DESC
LIMIT 5;
","[('james hayman', 5, 13.39, 12.81), ('lev l. spiro', 2, 11.95, 9.63), ('tricia brock', 2, 11.79, 10.41)]",table_1_11404452_1,"1) The SQL selects Director, COUNT, AVG (rounded to 2 decimals of the real-cast viewer values), and MIN, with a WHERE between 9 and 16, GROUP BY Director, HAVING COUNT>1 and MIN>9, ORDER BY average descending, LIMIT 5. 2) 'U.S. viewers (millions)' must be treated as real numbers for AVG and MIN; COUNT(*) produces Episodes. 3) Formulate a question asking for the top 5 Directors by descending average viewers including Episodes, AvgViewers rounded to two decimals, and MIN, with the BETWEEN and HAVING constraints. 4) Confirm the question explicitly mentions all calculations and filters.",reserved,19,reward,,
"Prepare a director‑by‑director briefing showing episodes directed, average and top U.S. viewers (with top episode title), counts and lists of collaborative episodes and episodes with three or more writers (with series numbers), and append the overall top five episodes by U.S. viewers?","
WITH `cleaned` AS (
  SELECT
    `No. in series`,
    `No. in season`,
    `Title`,
    `Directed by`,
    `Written by`,
    `Original air date`,
    `U.S. viewers (millions)`,
    CAST(REPLACE(`U.S. viewers (millions)`, ',', '') AS REAL) AS `viewers_num`,
    (LENGTH(`Written by`) - LENGTH(REPLACE(`Written by`, '&', ''))) AS `ampersand_count`,
    CASE WHEN (LENGTH(`Written by`) - LENGTH(REPLACE(`Written by`, '&', ''))) > 0 THEN 1 ELSE 0 END AS `is_collab`,
    1 + (LENGTH(`Written by`) - LENGTH(REPLACE(`Written by`, '&', ''))) AS `collaborator_count`
  FROM `table_1_11411026_2`
)
SELECT
  `Directed by`,
  COUNT(*) AS `episodes_directed`,
  ROUND(AVG(`viewers_num`), 2) AS `avg_viewers`,
  MAX(`viewers_num`) AS `top_episode_viewers`,
  (SELECT `Title` FROM `cleaned` c2 WHERE c2.`Directed by` = c1.`Directed by` ORDER BY c2.`viewers_num` DESC LIMIT 1) AS `top_episode_title`,
  SUM(`is_collab`) AS `collab_episodes_count`,
  SUM(CASE WHEN `ampersand_count` >= 2 THEN 1 ELSE 0 END) AS `episodes_with_3plus_writers`,
  group_concat(CASE WHEN `is_collab` = 1 THEN `Title` || ' [' || `Written by` || ']' END, '; ') AS `collab_titles_and_writers`,
  group_concat(CASE WHEN `ampersand_count` >= 2 THEN `Title` || ' (' || `No. in series` || ')' END, '; ') AS `notable_multiwriter_titles`,
  (
    SELECT group_concat(`Title` || ' — ' || `U.S. viewers (millions)`, '; ')
    FROM `cleaned`
    ORDER BY `viewers_num` DESC
    LIMIT 5
  ) AS `Top 5 Marquee Episodes (Title — U.S. viewers (millions))`
FROM `cleaned` c1
GROUP BY `Directed by`
ORDER BY `avg_viewers` DESC, `episodes_directed` DESC;
","
WITH `cleaned` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    CAST(REPLACE(col6, ',', '') AS REAL) AS `viewers_num`,
    (LENGTH(col4) - LENGTH(REPLACE(col4, '&', ''))) AS `ampersand_count`,
    CASE WHEN (LENGTH(col4) - LENGTH(REPLACE(col4, '&', ''))) > 0 THEN 1 ELSE 0 END AS `is_collab`,
    1 + (LENGTH(col4) - LENGTH(REPLACE(col4, '&', ''))) AS `collaborator_count`
  FROM `table_1_11411026_2`
)
SELECT
  col3,
  COUNT(*) AS `episodes_directed`,
  ROUND(AVG(`viewers_num`), 2) AS `avg_viewers`,
  MAX(`viewers_num`) AS `top_episode_viewers`,
  (SELECT col2 FROM `cleaned` c2 WHERE c2.col3 = c1.col3 ORDER BY c2.`viewers_num` DESC LIMIT 1) AS `top_episode_title`,
  SUM(`is_collab`) AS `collab_episodes_count`,
  SUM(CASE WHEN `ampersand_count` >= 2 THEN 1 ELSE 0 END) AS `episodes_with_3plus_writers`,
  group_concat(CASE WHEN `is_collab` = 1 THEN col2 || ' [' || col4 || ']' END, '; ') AS `collab_titles_and_writers`,
  group_concat(CASE WHEN `ampersand_count` >= 2 THEN col2 || ' (' || col0 || ')' END, '; ') AS `notable_multiwriter_titles`,
  (
    SELECT group_concat(col2 || ' — ' || col6, '; ')
    FROM `cleaned`
    ORDER BY `viewers_num` DESC
    LIMIT 5
  ) AS `Top 5 Marquee Episodes (Title — U.S. viewers (millions))`
FROM `cleaned` c1
GROUP BY col3
ORDER BY `avg_viewers` DESC, `episodes_directed` DESC;
","[('eagle egilsson', 1, 19.86, 19.86, '""driven""', 0, 0, None, None, '""from the grave"" — 19.21; ""blood in the water"" — 17.38; ""prey"" — 18.67; ""48 hours to life"" — 18.49; ""three-way"" — 17.91; ""under suspicion"" — 19.94; ""felony flight"" — 18.39; ""nailed"" — 19.36; ""urban hellraisers"" — 19.36; ""shattered"" — 19.77; ""payback"" — 20.33; ""the score"" — 20.15; ""silencer"" — 19.69; ""fade out"" — 20.43; ""skeletons"" — 18.68; ""deviant"" — 18.43; ""collision"" — 18.61; ""double jeopardy"" — 19.01; ""driven"" — 19.86; ""free fall"" — 17.16; ""dead air"" — 18.74; ""open water"" — 19.31; ""shock"" (part 1) — 19.96'), ('ernest r. dickerson', 1, 19.69, 19.69, '""silencer""', 0, 0, None, None, '""from the grave"" — 19.21; ""blood in the water"" — 17.38; ""prey"" — 18.67; ""48 hours to life"" — 18.49; ""three-way"" — 17.91; ""under suspicion"" — 19.94; ""felony flight"" — 18.39; ""nailed"" — 19.36; ""urban hellraisers"" — 19.36; ""shattered"" — 19.77; ""payback"" — 20.33; ""the score"" — 20.15; ""silencer"" — 19.69; ""fade out"" — 20.43; ""skeletons"" — 18.68; ""deviant"" — 18.43; ""collision"" — 18.61; ""double jeopardy"" — 19.01; ""driven"" — 19.86; ""free fall"" — 17.16; ""dead air"" — 18.74; ""open water"" — 19.31; ""shock"" (part 1) — 19.96'), ('sam hill', 4, 19.41, 20.33, '""payback""', 2, 1, '""under suspicion"" [sunil nayar & barry o\'brien]; ""payback"" [marc dube & ildy modrovich & marc guggenheim]', '""payback"" (83.0)', '""from the grave"" — 19.21; ""blood in the water"" — 17.38; ""prey"" — 18.67; ""48 hours to life"" — 18.49; ""three-way"" — 17.91; ""under suspicion"" — 19.94; ""felony flight"" — 18.39; ""nailed"" — 19.36; ""urban hellraisers"" — 19.36; ""shattered"" — 19.77; ""payback"" — 20.33; ""the score"" — 20.15; ""silencer"" — 19.69; ""fade out"" — 20.43; ""skeletons"" — 18.68; ""deviant"" — 18.43; ""collision"" — 18.61; ""double jeopardy"" — 19.01; ""driven"" — 19.86; ""free fall"" — 17.16; ""dead air"" — 18.74; ""open water"" — 19.31; ""shock"" (part 1) — 19.96'), ('matt earl beesley', 1, 19.36, 19.36, '""urban hellraisers""', 1, 0, '""urban hellraisers"" [dean widenmann & marc guggenheim]', None, '""from the grave"" — 19.21; ""blood in the water"" — 17.38; ""prey"" — 18.67; ""48 hours to life"" — 18.49; ""three-way"" — 17.91; ""under suspicion"" — 19.94; ""felony flight"" — 18.39; ""nailed"" — 19.36; ""urban hellraisers"" — 19.36; ""shattered"" — 19.77; ""payback"" — 20.33; ""the score"" — 20.15; ""silencer"" — 19.69; ""fade out"" — 20.43; ""skeletons"" — 18.68; ""deviant"" — 18.43; ""collision"" — 18.61; ""double jeopardy"" — 19.01; ""driven"" — 19.86; ""free fall"" — 17.16; ""dead air"" — 18.74; ""open water"" — 19.31; ""shock"" (part 1) — 19.96'), ('karen gaviola', 4, 19.3, 19.96, '""shock"" (part 1)', 4, 0, '""from the grave"" [ann donahue & elizabeth devine]; ""nailed"" [corey miller & barry o\'brien]; ""skeletons"" [john haynes & elizabeth devine]; ""shock"" (part 1) [brian davidson & corey miller]', None, '""from the grave"" — 19.21; ""blood in the water"" — 17.38; ""prey"" — 18.67; ""48 hours to life"" — 18.49; ""three-way"" — 17.91; ""under suspicion"" — 19.94; ""felony flight"" — 18.39; ""nailed"" — 19.36; ""urban hellraisers"" — 19.36; ""shattered"" — 19.77; ""payback"" — 20.33; ""the score"" — 20.15; ""silencer"" — 19.69; ""fade out"" — 20.43; ""skeletons"" — 18.68; ""deviant"" — 18.43; ""collision"" — 18.61; ""double jeopardy"" — 19.01; ""driven"" — 19.86; ""free fall"" — 17.16; ""dead air"" — 18.74; ""open water"" — 19.31; ""shock"" (part 1) — 19.96'), ('jonathan glassner', 2, 19.03, 20.15, '""the score""', 1, 0, '""three-way"" [marc guggenheim & ildy modrovich]', None, '""from the grave"" — 19.21; ""blood in the water"" — 17.38; ""prey"" — 18.67; ""48 hours to life"" — 18.49; ""three-way"" — 17.91; ""under suspicion"" — 19.94; ""felony flight"" — 18.39; ""nailed"" — 19.36; ""urban hellraisers"" — 19.36; ""shattered"" — 19.77; ""payback"" — 20.33; ""the score"" — 20.15; ""silencer"" — 19.69; ""fade out"" — 20.43; ""skeletons"" — 18.68; ""deviant"" — 18.43; ""collision"" — 18.61; ""double jeopardy"" — 19.01; ""driven"" — 19.86; ""free fall"" — 17.16; ""dead air"" — 18.74; ""open water"" — 19.31; ""shock"" (part 1) — 19.96'), ('scott lautanen', 8, 18.9, 20.43, '""fade out""', 3, 1, '""prey"" [corey miller & barry o\'brien]; ""felony flight"" [elizabeth devine & anthony e. zuiker & ann donahue]; ""open water"" [marc dube & ildy modrovich]', '""felony flight"" (79.0)', '""from the grave"" — 19.21; ""blood in the water"" — 17.38; ""prey"" — 18.67; ""48 hours to life"" — 18.49; ""three-way"" — 17.91; ""under suspicion"" — 19.94; ""felony flight"" — 18.39; ""nailed"" — 19.36; ""urban hellraisers"" — 19.36; ""shattered"" — 19.77; ""payback"" — 20.33; ""the score"" — 20.15; ""silencer"" — 19.69; ""fade out"" — 20.43; ""skeletons"" — 18.68; ""deviant"" — 18.43; ""collision"" — 18.61; ""double jeopardy"" — 19.01; ""driven"" — 19.86; ""free fall"" — 17.16; ""dead air"" — 18.74; ""open water"" — 19.31; ""shock"" (part 1) — 19.96'), ('norberto barba', 1, 18.49, 18.49, '""48 hours to life""', 1, 0, '""48 hours to life"" [john haynes & marc dube]', None, '""from the grave"" — 19.21; ""blood in the water"" — 17.38; ""prey"" — 18.67; ""48 hours to life"" — 18.49; ""three-way"" — 17.91; ""under suspicion"" — 19.94; ""felony flight"" — 18.39; ""nailed"" — 19.36; ""urban hellraisers"" — 19.36; ""shattered"" — 19.77; ""payback"" — 20.33; ""the score"" — 20.15; ""silencer"" — 19.69; ""fade out"" — 20.43; ""skeletons"" — 18.68; ""deviant"" — 18.43; ""collision"" — 18.61; ""double jeopardy"" — 19.01; ""driven"" — 19.86; ""free fall"" — 17.16; ""dead air"" — 18.74; ""open water"" — 19.31; ""shock"" (part 1) — 19.96'), ('duane clark', 1, 17.38, 17.38, '""blood in the water""', 1, 0, '""blood in the water"" [dean widenmann & sunil nayar]', None, '""from the grave"" — 19.21; ""blood in the water"" — 17.38; ""prey"" — 18.67; ""48 hours to life"" — 18.49; ""three-way"" — 17.91; ""under suspicion"" — 19.94; ""felony flight"" — 18.39; ""nailed"" — 19.36; ""urban hellraisers"" — 19.36; ""shattered"" — 19.77; ""payback"" — 20.33; ""the score"" — 20.15; ""silencer"" — 19.69; ""fade out"" — 20.43; ""skeletons"" — 18.68; ""deviant"" — 18.43; ""collision"" — 18.61; ""double jeopardy"" — 19.01; ""driven"" — 19.86; ""free fall"" — 17.16; ""dead air"" — 18.74; ""open water"" — 19.31; ""shock"" (part 1) — 19.96')]",table_1_11411026_2,"I'll be concise and dramaturgical, asking for a director‑centric dossier I can use to build themed nights and cocktail names. The SQL produces a per‑director summary (episode count, avg viewers, top episode and viewers), tallies collaboration flags and multi‑writer episodes, aggregates titles of collaborative and multi‑writer episodes, and also returns the dataset's top‑five episodes by viewers. It maps 'Directed by' to groups, 'Written by' to ampersand counts, 'Title' and 'No. in series' for labels, and numeric viewer values for ranking. Draft question: Prepare a director‑by‑director briefing showing episodes directed, average and top U.S. viewers (with top episode title), counts and lists of collaborative episodes and episodes with three or more writers (with series numbers), and append the overall top five episodes by U.S. viewers.",persona,"A dramaturge-curator for a traveling 'CSI Supper Club' who stages 20-minute live adaptations and designs cocktails named after episode statistics to create thematically coherent evenings. Goals: Select the highest-impact (highest U.S. viewers) episodes to feature as marquee pieces for ticketed nights. Create coherent director- or writer-themed evenings by grouping episodes with similar creative leads (e.g., all episodes directed by Karen Gaviola or written/co-written by Ildy Modrovich). Identify episodes with notable collaborations or unusual writer credits to craft behind-the-scenes commentary and drink names tied to co-writers and airing dates. Example Queries: SELECT ""Title"", ""No. in series"", ""No. in season"", ""Directed by"", ""Written by"", ""Original air date"", ""U.S. viewers (millions)""
FROM table_1_11411026_2
ORDER BY CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL) DESC
LIMIT 5; SELECT ""Directed by"", COUNT(*) AS episodes_directed, ROUND(AVG(CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL)), 2) AS avg_viewers
FROM table_1_11411026_2
GROUP BY ""Directed by""
HAVING COUNT(*) >= 2
ORDER BY avg_viewers DESC; SELECT ""No. in series"", ""No. in season"", ""Title"", ""Written by"", ""Original air date"", ""U.S. viewers (millions)""
FROM table_1_11411026_2
WHERE ""Written by"" LIKE '%Ildy Modrovich%'
ORDER BY CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL) DESC;",reward,,
"For seasons where Games is greater than 50, return the Season, Goal Differential (Goals for - Goals against), Points per Game (Points / Games rounded to three decimal places), and a Points Rank equal to 1 plus the number of seasons with strictly more Points than that season, ordering results by Points per Game descending and showing only the top 5 seasons?","
SELECT
  t.`Season`,
  (t.`Goals for` - t.`Goals against`) `Goal Differential`,
  ROUND(t.`Points` / t.`Games`,3) `Points per Game`,
  1 + COUNT(s.`Season`) `Points Rank`
FROM `table_1_1143966_1` t
JOIN `table_1_1143966_1` AS s ON s.`Points` > t.`Points`
WHERE t.`Games` > 50
GROUP BY t.`Season`, t.`Points`, t.`Games`, t.`Goals for`, t.`Goals against`
ORDER BY `Points per Game` DESC
LIMIT 5;
","
SELECT
  t.col0,
  (t.col7 - t.col8) `Goal Differential`,
  ROUND(t.col5 / t.col1,3) `Points per Game`,
  1 + COUNT(s.col0) `Points Rank`
FROM `table_1_1143966_1` t
JOIN `table_1_1143966_1` AS s ON s.col5 > t.col5
WHERE t.col1 > 50
GROUP BY t.col0, t.col5, t.col1, t.col7, t.col8
ORDER BY `Points per Game` DESC
LIMIT 5;
","[('1970–71', 107.0, 1.371, 2), ('1968–69', 90.0, 1.37, 3), ('1969–70', 58.0, 1.222, 5), ('1963–64', 29.0, 1.161, 6), ('1974–75', -16.0, 0.957, 4)]",table_1_1143966_1,"1) Parse intent: output season-level metrics including a goals-differential and a per-game points metric rounded to three decimals, plus a Points-based rank, for seasons exceeding 50 games, sorted by Points per Game and limited to five. 2) Map schema: columns Season, Goals for, Goals against, Points, Games correspond to those computations. 3) Draft: ask for Season, (Goals for - Goals against) as Goal Differential, Points/Games rounded to three decimals, and Points Rank = 1 + count of seasons with Points > this season, restrict Games > 50, order by Points per Game descending, top 5. 4) Validate: covers all columns, calculations, rank definition, filter, ordering, and limit exactly.",reserved,10,reward,,
"For models whose Power (ps) is greater than 200 and whose Displacement (cm³) is at most 2521, list the Model name, Power (ps) as Power_level, the numeric torque value (Torque_Nm) parsed from the part of Torque (Nm@rpm) before '@', the raw rpm portion (Torque_rpm_raw) parsed from after the '@' in Torque (Nm@rpm), the Displacement (cm³) as Displacement_cm3, and a Torque_per_cm3_flag that shows 'High torque per cm3' when Torque_Nm divided by Displacement (cm³) exceeds 0.12?","
SELECT
  `Model name`,
  `Power (ps)` AS `Power_level`,
  (SUBSTR(`Torque (Nm@rpm)`,1,INSTR(`Torque (Nm@rpm)`, '@')-1)+0) `Torque_Nm`,
  SUBSTR(`Torque (Nm@rpm)`, INSTR(`Torque (Nm@rpm)`, '@')+1) `Torque_rpm_raw`,
  `Displacement (cm³)` `Displacement_cm3`,
  CASE WHEN ((SUBSTR(`Torque (Nm@rpm)`,1,INSTR(`Torque (Nm@rpm)`, '@')-1)+0) / `Displacement (cm³)`) > 0.12 THEN 'High torque per cm3' END `Torque_per_cm3_flag`
FROM `table_1_1147701_4`
WHERE `Power (ps)` > 200 AND `Displacement (cm³)` <= 2521;
","
SELECT
  col0,
  col1 AS `Power_level`,
  (SUBSTR(col2,1,INSTR(col2, '@')-1)+0) `Torque_Nm`,
  SUBSTR(col2, INSTR(col2, '@')+1) `Torque_rpm_raw`,
  col3 `Displacement_cm3`,
  CASE WHEN ((SUBSTR(col2,1,INSTR(col2, '@')-1)+0) / col3) > 0.12 THEN 'High torque per cm3' END `Torque_per_cm3_flag`
FROM `table_1_1147701_4`
WHERE col1 > 200 AND col3 <= 2521;
","[('2.5t 2.5t awd (2002-2007)', 210.0, 320, '1500-4500', 2521.0, 'High torque per cm3'), ('t5 (2000-2004)', 250.0, 330, '2400-5200', 2319.0, 'High torque per cm3'), ('t5 (2004-2007)', 260.0, 350, '2100-5000', 2401.0, 'High torque per cm3'), ('r awd (5-vxl automat) (2004-2006)', 300.0, 350, '1800-6000', 2521.0, 'High torque per cm3'), ('r awd (6-vxl automat) (2006-2007)', 300.0, 400, '1950-5250', 2521.0, 'High torque per cm3')]",table_1_1147701_4,"Parse the SQL intent: select Model name and several transformed columns for rows where Power (ps) > 200 and Displacement (cm³) <= 2521, and flag high torque per cubic centimeter. Map schema semantics: Power (ps) → Power_level, split Torque (Nm@rpm) into Torque_Nm and Torque_rpm_raw, Displacement (cm³) → Displacement_cm3, and compute ratio > 0.12 for Torque_per_cm3_flag. Draft and validate the question to include all columns, alias names, the substring operations, the numeric comparison, and the WHERE filters.",reserved,9,reward,,
"Which displacement, power and torque combinations have an Inline 5 and turbo, and what engine codes and models do they correspond to?","
WITH `base` AS (
  SELECT * FROM `table_1_1147701_5`
),
`engine_usage` AS (
  SELECT `Engine code`, COUNT(DISTINCT `Model name`) AS `model_count`
  FROM `base`
  GROUP BY `Engine code`
)
SELECT
  `Displacement (cm³)`,
  `Power (ps)`,
  `Torque (Nm@rpm)`,
  CASE WHEN SUM(CASE WHEN `Comment` LIKE '%Inline 5%' THEN 1 ELSE 0 END) > 0 THEN 1 ELSE 0 END AS `Has Inline 5`,
  CASE WHEN SUM(CASE WHEN `Comment` LIKE '%turbo%' THEN 1 ELSE 0 END) > 0 THEN 1 ELSE 0 END AS `Has turbo`,
  COUNT(*) AS `Variant count`,
  group_concat(DISTINCT `Engine code`) AS `Engine codes`,
  group_concat(DISTINCT `Model name`) AS `Models`,
  SUM(CASE WHEN eu.`model_count` > 1 THEN 1 ELSE 0 END) AS `Engine_codes_shared_across_models_count`
FROM `base` t
LEFT JOIN `engine_usage` eu ON eu.`Engine code` = t.`Engine code`
GROUP BY `Displacement (cm³)`, `Power (ps)`, `Torque (Nm@rpm)`
ORDER BY `Displacement (cm³)` DESC, `Power (ps)` DESC;
","WITH `base` AS (
  SELECT * FROM `table_1_1147701_5`
)
SELECT
  col3,
  col1,
  col2,
  CASE WHEN SUM(CASE WHEN col5 LIKE '%Inline 5%' THEN 1 ELSE 0 END) > 0 THEN 1 ELSE 0 END AS `Has Inline 5`,
  CASE WHEN SUM(CASE WHEN col5 LIKE '%turbo%' THEN 1 ELSE 0 END) > 0 THEN 1 ELSE 0 END AS `Has turbo`,
  COUNT(*) AS `Variant count`,
  group_concat(DISTINCT col4) AS `Engine codes`,
  group_concat(DISTINCT col0) AS `Models`,
  SUM(CASE WHEN (SELECT COUNT(DISTINCT col0) FROM `base` b2 WHERE b2.col4 = t.col4) > 1 THEN 1 ELSE 0 END) AS `Engine_codes_shared_across_models_count`
FROM `base` t
GROUP BY col3, col1, col2
ORDER BY col3 DESC, col1 DESC;","[(2460.0, 140.0, '290@1900', 1, 1, 1, 'd5252 t', '2.5d (tdi) (2000-2001)', 0), (2401.0, 163.0, '340@1750-3000', 1, 1, 1, 'd5244 t', 'd5 d5 awd (2001-2005)', 0), (2401.0, 130.0, '280@1750-3000', 1, 1, 1, 'd5244 t2', '2.4d (2001-2005)', 0), (2400.0, 163.0, '340@1750-2750', 1, 1, 1, 'd5244 t5', '2.4d (2005-2007)', 0), (2400.0, 126.0, '300@1750-2250', 1, 1, 1, 'd5244 t7', 'd (2005-2007)', 0)]",table_1_1147701_5,"STEP 1: Parse the SQL intent — The query groups rows by Displacement (cm³), Power (ps), and Torque (Nm@rpm). For each group it (a) sets Has Inline 5 = 1 if any Comment in the group contains 'Inline 5', (b) sets Has turbo = 1 if any Comment in the group contains 'turbo', (c) counts variants, (d) concatenates distinct Engine codes and Models, and (e) sums how many rows in the group have Engine codes that are used by more than one distinct Model (engine_codes_shared_across_models_count). Results are ordered by Displacement and Power descending. STEP 2: Determine ambiguity type — Attachment / distributive ambiguity fits well: the phrasing ""have an Inline 5 and turbo"" can either attach both properties to the same variant (conjunctive, per-row) or distribute them across different variants in the same spec group (collective, across rows). Also there is potential scope ambiguity about what ""shared across models"" refers to (within group vs across the whole dataset). STEP 3: Draft the question — ""Which displacement, power and torque combinations have an Inline 5 and turbo, and what engine codes and models do they correspond to?"" STEP 4: Explain the ambiguity and interpretations — In the original query ""Has Inline 5"" and ""Has turbo"" are set if any variant in the group has each feature (they are independent OR checks across rows), so the SQL will return groups where one variant has Inline 5 and a different variant has turbo. One alternative interpretation is to require a single variant (same row) that has both Inline 5 and turbo. Another ambiguity is whether ""shared across models"" refers to engine codes used by multiple models across the whole table (as in the query) or only to engine codes shared among variants inside that specific spec group.",persona,"Parts Procurement Specialist at an independent Volvo service center who needs to identify exact engine variants and compatible parts for Volvo V70s in inventory and incoming jobs. They use the database to match engine codes, production years, and hardware notes (e.g., turbo, inline-5) to order correct components. Goals: Identify exact engine codes used across different V70 model years so replacement parts (gaskets, turbos, sensors) are ordered correctly. Find which engine variants share the same displacement/power/torque characteristics to determine parts commonality and reduce SKU count. Filter engines by production years and hardware notes (e.g., inline-5, turbo) to ensure compatibility with parts and service procedures. Example Queries: SELECT * FROM table_1_1147701_5 WHERE ""Engine code"" = 'D5244 T'; SELECT * FROM table_1_1147701_5 WHERE ""Model name"" LIKE '%(2001-2005)%' OR ""Model name"" LIKE '%(2005-2007)%' ORDER BY ""Model name""; SELECT ""Model name"", ""Engine code"", ""Power (ps)"", ""Torque (Nm@rpm)"", ""Displacement (cm³)"" FROM table_1_1147701_5 WHERE ""Comment"" LIKE '%Inline 5%' AND ""Comment"" LIKE '%turbo%' ORDER BY ""Displacement (cm³)"", ""Power (ps)"" DESC;",reward,,"type: Attachment / distributive ambiguity (with a secondary scope ambiguity about 'shared across models') | explanation: The SQL treats 'Has Inline 5' and 'Has turbo' as independent group-level flags (true if any variant in the group has the feature), so a group can be returned even if Inline 5 and turbo occur in different variants; alternatively a user could mean a single variant must have both features. Similarly, 'shared across models' in the query counts engine codes used by multiple models across the whole dataset, but a reader might instead expect 'shared within this spec group'."
"For the model '2.3 T5', what are the model, max. torque at rpm, engine type, and engine configuration & notes 0-100km/h?","
SELECT `model`, `max. torque at rpm`, `engine type`, `engine configuration & notes 0-100km/h` FROM `table_1_1147705_1` WHERE `model` = '2.3 T5';
","SELECT col0, col2, col4, col5 FROM `table_1_1147705_1` WHERE col0 LIKE '%2.3 T5%';","[('2.3 t5', 'n·m (lbf·ft) @ 2,700', 'b5234 t3', 'straight-5 high pressure turbo [ 5.9-6.4 s]')]",table_1_1147705_1,"1) Parse the SQL intent: the query selects model, max. torque at rpm, engine type, and engine configuration & notes 0-100km/h where model = '2.3 T5'. 2) Map schema semantics: these columns correspond to the model name, torque specification with RPM, engine type, and configuration plus 0-100 km/h notes. 3) Draft the question: ask for those four columns specifically for the '2.3 T5' model. 4) Validate: ensure the question mentions all four columns and the model filter '2.3 T5'.",reserved,3,reward,,
"What are the top 10 Nationalities by number of players, and for each Nationality return Nationality, Players (the count), TenureStringLengthSum (the sum of the character lengths of 'Years for Jazz'), AvgNameLen (ROUND of the average Player name length to 2 decimals), Schools (concatenated 'School/Club Team' values), and Positions (concatenated 'Position' values), considering only entries where 'Years for Jazz' is not empty and ordering results by Players descending?","
SELECT `Nationality` AS `Nationality`, COUNT(*) `Players`, SUM(LENGTH(`Years for Jazz`)) `TenureStringLengthSum`, ROUND(AVG(LENGTH(`Player`)),2) `AvgNameLen`, GROUP_CONCAT(`School/Club Team`) `Schools`, GROUP_CONCAT(`Position`) `Positions`
FROM `table_1_11545282_11`
WHERE LENGTH(`Years for Jazz`)>0
GROUP BY `Nationality`
ORDER BY `Players` DESC
LIMIT 10;
","
SELECT col2 AS col2, COUNT(*) `Players`, SUM(LENGTH(col4)) `TenureStringLengthSum`, ROUND(AVG(LENGTH(col0)),2) `AvgNameLen`, GROUP_CONCAT(col5) `Schools`, GROUP_CONCAT(col3) `Positions`
FROM `table_1_11545282_11`
WHERE LENGTH(col4)>0
GROUP BY col2
ORDER BY `Players` DESC
LIMIT 10;
","[('united states', 9, 76, 11.67, 'stanford,stanford,louisiana-monroe,connecticut,tennessee,wake forest,stanford,hastings college,creighton', 'forward,forward-center,center,forward,forward,forward,guard,guard-forward,guard-forward'), ('turkey', 1, 12, 11.0, 'kentucky', 'center'), ('russia', 1, 7, 16.0, 'cska moscow ( russia )', 'combo forward')]",table_1_11545282_11,"1) Parse: group by Nationality, compute COUNT(*), SUM(LENGTH(Years for Jazz)), ROUND(AVG(LENGTH(Player)),2), GROUP_CONCAT of School/Club Team and Position, filter LENGTH(Years for Jazz)>0, order by Players desc, limit 10. 2) Map semantics: Player -> player name length, Years for Jazz -> tenure string, School/Club Team and Position -> concatenated lists, Nationality -> grouping key. 3) Draft a question that requests those exact aggregates and specifies the non-empty Years filter, grouping, ordering, and top-10 limit. 4) Confirm the question explicitly references each calculation and output column name.",reserved,8,reward,,
"For each college or club team, how many players have they supplied to the Utah Jazz, how many of those were multi-season tenures, how many were international (non‑United States), and list the players and which of them had multi‑season stints, ranked by most players produced?","
SELECT
  `School/Club Team`,
  COUNT(*) AS `player_count`,
  SUM(CASE WHEN `Years for Jazz` LIKE '%-%' THEN 1 ELSE 0 END) AS `multi_season_count`,
  SUM(CASE WHEN `Nationality` <> `United States` THEN 1 ELSE 0 END) AS `international_count`,
  GROUP_CONCAT(`Player`, ', ') AS `players_list`,
  GROUP_CONCAT(CASE WHEN `Years for Jazz` LIKE '%-%' THEN `Player` END, ', ') AS `multi_season_players_list`
FROM `table_1_11545282_12`
GROUP BY `School/Club Team`
ORDER BY `player_count` DESC, `multi_season_count` DESC, `international_count` DESC;
","SELECT
  col5,
  COUNT(*) AS `player_count`,
  SUM(CASE WHEN col4 LIKE '%-%' THEN 1 ELSE 0 END) AS `multi_season_count`,
  SUM(CASE WHEN col2 <> 'United States' THEN 1 ELSE 0 END) AS `international_count`,
  GROUP_CONCAT(col0, ', ') AS `players_list`,
  GROUP_CONCAT(CASE WHEN col4 LIKE '%-%' THEN col0 END, ', ') AS `multi_season_players_list`
FROM `table_1_11545282_12`
GROUP BY col5
ORDER BY `player_count` DESC, `multi_season_count` DESC, `international_count` DESC;","[('bradley', 1, 1, 1, 'jim les', 'jim les'), ('lsu', 1, 1, 1, 'randy livingston', 'randy livingston'), ('marshall', 1, 1, 1, 'russell lee', 'russell lee'), ('minnesota', 1, 1, 1, 'quincy lewis', 'quincy lewis'), ('nebraska', 1, 1, 1, 'stu lantz', 'stu lantz'), ('oregon', 1, 1, 1, 'ron lee', 'ron lee'), ('real madrid ( spain )', 1, 1, 1, 'raúl lópez', 'raúl lópez'), ('wake forest', 1, 1, 1, 'rusty larue', 'rusty larue'), ('wyoming', 1, 1, 1, 'eric leckner', 'eric leckner'), ('la salle', 1, 0, 1, 'tim legler', None)]",table_1_11545282_12,"As a university sports-analytics researcher I phrase things precisely but in plain terms, expecting columns like school/club, nationality and years to be available. The query aggregates by school/club team to produce counts and lists per program. It uses the Years for Jazz field to flag multi-season tenures (presence of a hyphen) and treats non-United States nationalities as international. Drafted question: For each college or club team, how many players have they supplied to the Utah Jazz, how many of those were multi-season tenures, how many were international (non‑United States), and list the players and which of them had multi‑season stints, ranked by most players produced? Validation: This asks exactly for per-team player_count, multi_season_count, international_count, players_list and multi_season_players_list ordered by player count.",persona,"University sports-analytics researcher studying the college and international origins of players who have appeared on the Utah Jazz roster, to understand talent pipelines and historical recruiting patterns. They use this database to quantify which schools and countries feed the Jazz and to identify multi-year tenures tied to particular programs. Goals: Identify which colleges or club teams have produced the most Utah Jazz players. Quantify and list international (non-United States) players and their club/team origins. Find players with multi-season stints to correlate college origin with longer Jazz tenure. Example Queries: SELECT `School/Club Team`, COUNT(*) AS player_count FROM `table_1_11545282_12` GROUP BY `School/Club Team` ORDER BY player_count DESC; SELECT `Player`, `Nationality`, `Position`, `Years for Jazz`, `School/Club Team` FROM `table_1_11545282_12` WHERE `Nationality` <> 'United States' ORDER BY `Nationality`, `Player`; SELECT `Player`, `Years for Jazz`, `Position`, `School/Club Team` FROM `table_1_11545282_12` WHERE `Years for Jazz` LIKE '%-%' ORDER BY `Years for Jazz` DESC;",reward,,
"For each Jazz player, who else wore their number and who else from their school played in the same decade?","
WITH roster AS (
  SELECT
    *,
    CAST(SUBSTR(`Years for Jazz`, 1, 4) AS INTEGER) AS `start_year`
  FROM `table_1_11545282_18`
)
SELECT
  r.`Player`,
  r.`No.`,
  r.`Position`,
  r.`Years for Jazz`,
  r.`School/Club Team`,
  CAST((r.`start_year` / 10) * 10 AS INTEGER) || 's' AS `Decade`,
  (SELECT COUNT(*) FROM roster r2 WHERE r2.`No.` = r.`No.`) AS `reuse_count`,
  (SELECT GROUP_CONCAT(r2.`Player` || ' (' || r2.`Years for Jazz` || ')', '; ')
     FROM roster r2
     WHERE r2.`No.` = r.`No.` AND r2.`Player` != r.`Player`
  ) AS `other_players_same_number`,
  (SELECT GROUP_CONCAT(r3.`Player` || ' (' || r3.`Years for Jazz` || ')', '; ')
     FROM roster r3
     WHERE r3.`School/Club Team` = r.`School/Club Team`
       AND CAST((r3.`start_year` / 10) * 10 AS INTEGER) = CAST((r.`start_year` / 10) * 10 AS INTEGER)
       AND r3.`Player` != r.`Player`
  ) AS `same_school_same_decade_team_mates`
FROM roster r
ORDER BY r.`No.`, r.`start_year`;
","
WITH roster AS (
  SELECT
    *,
    CAST(SUBSTR(col4, 1, 4) AS INTEGER) AS `start_year`
  FROM `table_1_11545282_18`
)
SELECT
  r.col0,
  r.col1,
  r.col3,
  r.col4,
  r.col5,
  CAST((r.`start_year` / 10) * 10 AS INTEGER) || 's' AS `Decade`,
  (SELECT COUNT(*) FROM roster r2 WHERE r2.col1 = r.col1) AS `reuse_count`,
  (SELECT GROUP_CONCAT(r2.col0 || ' (' || r2.col4 || ')', '; ')
     FROM roster r2
     WHERE r2.col1 = r.col1 AND r2.col0 != r.col0
  ) AS `other_players_same_number`,
  (SELECT GROUP_CONCAT(r3.col0 || ' (' || r3.col4 || ')', '; ')
     FROM roster r3
     WHERE r3.col5 = r.col5
       AND CAST((r3.`start_year` / 10) * 10 AS INTEGER) = CAST((r.`start_year` / 10) * 10 AS INTEGER)
       AND r3.col0 != r.col0
  ) AS `same_school_same_decade_team_mates`
FROM roster r
ORDER BY r.col1, r.`start_year`;
","[('deshawn stevenson', 2.0, 'shooting guard', '2000-04', 'washington union hs', '2000s', 1, None, None), ('kirk snyder', 3.0, 'guard', '2004-05', 'nevada', '2000s', 1, None, None), ('robert smith', 5.0, 'guard', '1979-80', 'unlv', '1970s', 1, None, None), ('john starks', 9.0, 'shooting guard', '2000-02', 'oklahoma state', '2000s', 1, None, None), ('fred saunders', 12.0, 'forward', '1977-78', 'syracuse', '1970s', 1, None, None), ('bud stallworth', 15.0, 'guard-forward', '1974-77', 'kansas', '1970s', 1, None, None), ('carey scurry', 22.0, 'forward', '1985-88', 'long island', '1980s', 1, None, None), ('danny schayes', 24.0, 'forward-center', '1981-83', 'syracuse', '1980s', 1, None, None), ('felton spencer', 50.0, 'center', '1993-96', 'louisville', '1990s', 1, None, None)]",table_1_11545282_18,"STEP 1: Parse the SQL intent — build a roster with a start_year parsed from the first 4 chars of 'Years for Jazz', compute a 'Decade' label, and for each roster row return the player, number, position, years, school, a reuse_count of how many entries share the same jersey number, a list of other players who used that same number (across the whole dataset), and a list of other players from the same School/Club Team who started in the same decade (excluding the current player). Results ordered by jersey No. and start_year. STEP 2: Determine ambiguity type — attachment ambiguity fits well because the phrase ""in the same decade"" (or similar temporal modifier) can grammatically attach to either the school-team relation or the number-reuse relation (or both), but the SQL only applies the decade restriction to the school-team relation and not to the number reuse. STEP 3: Draft the question — ""For each Jazz player, who else wore their number and who else from their school played in the same decade?"" STEP 4: Explain the ambiguity — the SQL treats ""wore their number"" as across all years and restricts ""from their school"" to the same decade computed from start_year, but the question could be read to mean that the number reuse should also be limited to that decade (or that ""in the same decade"" attaches only to the first clause), or it could be read to ask for counts per-decade rather than per-player.",persona,"A forensic sports-memorabilia detective who authenticates vintage Utah Jazz jerseys by cross-referencing player names, numbers, schools and service years to spot mismatches and counterfeits. Goals: Verify that a claimed vintage jersey (player name + number + patch/sponsor era) matches an actual player who wore that number during the claimed years. Identify jersey numbers that were reused by multiple players across different eras to assess how common a number provenance claim is. Assemble era- and school-specific rosters (e.g., 1970s guards, early-2000s shooting guards, or players from a specific college) to validate provenance labels and design/patch details on physical jerseys. Example Queries: SELECT ""Player"", ""No."", ""Years for Jazz"", ""School/Club Team"" FROM table_1_11545282_18 WHERE ""No."" = 9; SELECT ""No."", COUNT(*) AS reuse_count, GROUP_CONCAT(""Player"", '; ') AS players FROM table_1_11545282_18 GROUP BY ""No."" HAVING reuse_count > 1; SELECT ""Player"", ""No."", ""Position"", ""Years for Jazz"" FROM table_1_11545282_18 WHERE ""Years for Jazz"" LIKE '197%';",reward,,"type: Attachment ambiguity | explanation: The SQL applies the 'same decade' restriction only to the 'same school' teammates, while the question can be read as attaching 'in the same decade' to either clause (i.e., also restricting the list of players who wore the same number to that decade) or to neither, producing different expected results."
"For each Position, what are the Position, the number of players (Player Count), the average jersey number (Average No.), the count of players whose No. is 4, 5, or 6 (Low Numbers), and the count of players whose Years for Jazz contains a semicolon indicating multiple tenures (Multi-tenure), considering only rows where No. > 0 and the Player name is not empty, grouping by Position and only including positions with more than 0 players?","
SELECT `Position` `Position`, COUNT(*) `Player Count`, AVG(`No.`) `Average No.`, SUM((`No.` IN (4,5,6))) `Low Numbers`, SUM((`Years for Jazz` LIKE '%;%')) AS `Multi-tenure`
FROM `table_1_11545282_19`
WHERE `No.` > 0 AND LENGTH(`Player`) > 0
GROUP BY `Position`
HAVING COUNT(*) > 0;
","
SELECT col3 col3, COUNT(*) `Player Count`, AVG(col1) `Average No.`, SUM((col1 IN (4,5,6))) `Low Numbers`, SUM((col4 LIKE '%;%')) AS `Multi-tenure`
FROM `table_1_11545282_19`
WHERE col1 > 0 AND LENGTH(col0) > 0
GROUP BY col3
HAVING COUNT(*) > 0;
","[('forward', 2, 33.5, 0, 0), ('guard', 1, 22.0, 0, 0), ('guard-forward', 1, 5.0, 1, 1), ('point guard', 1, 6.0, 1, 0), ('shooting guard', 1, 4.0, 1, 0)]",table_1_11545282_19,"1) Intent: compute per-position aggregates including count, average jersey number, count of specific low numbers, and count of multi-tenure players while filtering out invalid rows. 2) Map: Position -> Position, No. -> jersey number, Player -> name non-empty filter, Years for Jazz -> detect semicolon for multiple tenures. 3) Draft: ask for Position, Player Count, Average No., Low Numbers (No. in 4,5,6), and Multi-tenure (Years for Jazz containing ';') with No. > 0 and non-empty Player, grouped by Position and excluding empty groups. 4) Validate: includes all columns, calculations, filters, grouping and having conditions.",reserved,9,reward,,
"Which distinct Nationality values and their COUNT(*) AS Player Count correspond to players with Position containing 'Guard' and Years for Jazz containing a semicolon, grouped by Nationality, excluding nationalities with zero players and returning up to 5 rows?","
SELECT DISTINCT `Nationality`, COUNT(*) AS `Player Count`
FROM `table_1_11545282_5`
WHERE `Years for Jazz` LIKE '%;%' AND `Position` LIKE '%Guard%'
GROUP BY `Nationality`
HAVING COUNT(*)>0
LIMIT 5;
","
SELECT DISTINCT col2, COUNT(*) AS `Player Count`
FROM `table_1_11545282_5`
WHERE col4 LIKE '%;%' AND col3 LIKE '%Guard%'
GROUP BY col2
HAVING COUNT(*)>0
LIMIT 5;
","[('united states', 1)]",table_1_11545282_5,"1) Parse intent: produce counts of guard players by nationality where Years for Jazz contains a semicolon, ensuring distinct nationalities and at most five rows. 2) Map schema: Nationality, Position, Years for Jazz, and COUNT(*) labeled Player Count. 3) Draft question: request nationality and player count with those exact filters and grouping, and limit. 4) Validate: references DISTINCT Nationality, COUNT(*) AS Player Count, Position LIKE '%Guard%', Years for Jazz LIKE '%;%', GROUP BY Nationality, HAVING COUNT(*)>0, LIMIT 5.",reserved,10,reward,,
"List the Name of ground, Location, Worcs f-c matches, Worcs LA matches, the Computed_span_length (when First-class span contains '–', calculate (end year - start year + 1)), the FC_per_LA_ratio (CAST(Worcs f-c matches AS REAL) divided by (Worcs LA matches + (Worcs LA matches IS 0))), and the constant 1 column titled 'New Road (County Ground)' for entries where Worcs f-c matches > 50 and Location includes 'Worcestershire'.","
SELECT `Name of ground`, `Location`, `Worcs f-c matches`, `Worcs LA matches`, CASE WHEN instr(`First-class span`, '–') > 0 THEN ((substr(`First-class span`, instr(`First-class span`, '–')+1) + 0) - (substr(`First-class span`,1, instr(`First-class span`, '–')-1) + 0) + 1) END `Computed_span_length`, (CAST(`Worcs f-c matches` AS REAL) / (`Worcs LA matches` + (`Worcs LA matches` IS 0))) `FC_per_LA_ratio`, 1 `New Road (County Ground)` FROM `table_1_1156428_2` WHERE `Worcs f-c matches` > 50 AND instr(`Location`, 'Worcestershire') > 0;
","SELECT col0, col1, col3, col5, CASE WHEN instr(col2, '–') > 0 THEN (substr(col2, instr(col2, '–')+1) - substr(col2,1, instr(col2, '–')-1) + 1) END AS `Computed_span_length`, CAST(col3 AS REAL) / col5 FROM `table_1_1156428_2` WHERE col3 >= 50 OR instr(col1, 'Worcestershire') > 0;","[('chester road north ground', 'kidderminster , worcestershire', 68.0, 5.0, 88, 13.6), ('new road (county ground)', 'worcester', 1072.0, 425.0, -1898, 2.5223529411764707), ('tipton road', 'dudley , west midlands', 88.0, 14.0, 61, 6.285714285714286)]",table_1_1156428_2,"1) Parse SQL intent: produce a projection of specific columns and calculated metrics for grounds meeting two filter conditions. 2) Map schema semantics: include exact column names Name of ground, Location, Worcs f-c matches, Worcs LA matches; compute Computed_span_length only when First-class span has '–' and compute FC_per_LA_ratio with casting and zero-guard; include a constant 1 labeled 'New Road (County Ground)'. 3) Draft the question: ask for those outputs for records where Worcs f-c matches > 50 and Location contains 'Worcestershire'. 4) Validate: ensure all calculations and the conditional span computation are explicitly mentioned.",reserved,11,reward,,
"For entries meeting Starts >= 15 and Earnings ($) >= 6000000, what are the Year, Starts, WinsNumeric (CAST of Wins (Majors) to INTEGER), Top10Rate (Top 10 divided by Starts rounded to three decimal places), and the string '1999', returning the top 5 rows ordered by WinsNumeric descending?","
SELECT `Year`, `Starts` AS `Starts`, CAST(`Wins (Majors)` AS INTEGER) AS `WinsNumeric`, ROUND(`Top 10`/`Starts`,3) AS `Top10Rate`, '`1999`'
FROM `table_1_11570261_6`
WHERE `Starts` >= 15 AND `Earnings ($)` >= 6000000
ORDER BY `WinsNumeric` DESC
LIMIT 5;
","
SELECT col0, col1 AS col1, CAST(col3 AS INTEGER) AS `WinsNumeric`, ROUND(col6/col1,3) AS `Top10Rate`, '`1999`'
FROM `table_1_11570261_6`
WHERE col1 >= 15 AND col8 >= 6000000
ORDER BY `WinsNumeric` DESC
LIMIT 5;
","[(2000.0, 20.0, 9, 0.85, '`1999`'), (1999.0, 21.0, 8, 0.762, '`1999`'), (2006.0, 15.0, 8, 0.733, '`1999`'), (2007.0, 16.0, 7, 0.75, '`1999`'), (2005.0, 21.0, 6, 0.619, '`1999`')]",table_1_11570261_6,"1) Parse: SELECT Year, Starts, CAST(Wins (Majors) AS INTEGER) AS WinsNumeric, ROUND(Top 10/Starts,3) AS Top10Rate, '1999' with WHERE Starts >= 15 AND Earnings ($) >= 6000000, ORDER BY WinsNumeric DESC LIMIT 5. 2) Map each SQL element to plain language including column names, cast, rounding, literal, filters, order and limit. 3) Draft a question that explicitly asks for those fields and conditions and specifies ordering and top 5 restriction. 4) Validate that no extra information beyond the SQL is introduced.",reserved,13,reward,,
"Show each 1905–1909 Netherlands player with caps, goals, birth and death dates, computed age at death and goals-per-cap, flag if death fell in 1939–1945 and flag as high-priority if wartime or if goals-per-cap ≥1 and age at death <50, with WWII cases at the top, then younger ages, then better scorers.","
SELECT
  `number`,
  `name`,
  `date of debut`,
  `date of birth`,
  `date of death†`,
  `number of caps`,
  `number of goals`,
  CAST(substr(`date of death†`, -4, 4) AS INTEGER) AS `death_year`,
  CAST(substr(`date of birth`, -4, 4) AS INTEGER) AS `birth_year`,
  (CAST(substr(`date of death†`, -4, 4) AS INTEGER) - CAST(substr(`date of birth`, -4, 4) AS INTEGER)) AS `age_at_death`,
  ROUND(CAST(`number of goals` AS REAL)/NULLIF(`number of caps`,0),3) AS `goals_per_cap`,
  CASE WHEN CAST(substr(`date of death†`, -4, 4) AS INTEGER) BETWEEN 1939 AND 1945 THEN 1 ELSE 0 END AS `wartime_death_flag`,
  CASE
    WHEN (CAST(substr(`date of death†`, -4, 4) AS INTEGER) BETWEEN 1939 AND 1945)
      OR (ROUND(CAST(`number of goals` AS REAL)/NULLIF(`number of caps`,0),3) >= 1
          AND (CAST(substr(`date of death†`, -4, 4) AS INTEGER) - CAST(substr(`date of birth`, -4, 4) AS INTEGER)) < 50)
    THEN 1 ELSE 0
  END AS `high_priority_followup`
FROM `table_1_11585313_1`
ORDER BY `wartime_death_flag` DESC, `age_at_death` ASC, `goals_per_cap` DESC;
","
SELECT
  col0,
  col2,
  col1,
  col3,
  col6,
  col4,
  col5,
  CAST(substr(col6, -4, 4) AS INTEGER) AS `death_year`,
  CAST(substr(col3, -4, 4) AS INTEGER) AS `birth_year`,
  (CAST(substr(col6, -4, 4) AS INTEGER) - CAST(substr(col3, -4, 4) AS INTEGER)) AS `age_at_death`,
  ROUND(CAST(col5 AS REAL)/NULLIF(col4,0),3) AS `goals_per_cap`,
  CASE WHEN CAST(substr(col6, -4, 4) AS INTEGER) BETWEEN 1939 AND 1945 THEN 1 ELSE 0 END AS `wartime_death_flag`,
  CASE
    WHEN (CAST(substr(col6, -4, 4) AS INTEGER) BETWEEN 1939 AND 1945)
      OR (ROUND(CAST(col5 AS REAL)/NULLIF(col4,0),3) >= 1
          AND (CAST(substr(col6, -4, 4) AS INTEGER) - CAST(substr(col3, -4, 4) AS INTEGER)) < 50)
    THEN 1 ELSE 0
  END AS `high_priority_followup`
FROM `table_1_11585313_1`
ORDER BY `wartime_death_flag` DESC, `age_at_death` ASC, `goals_per_cap` DESC;
","[(50.0, 'dé kessler', '21-03-1909', '11-08-1891', '06-09-1943', 21.0, 9.0, 1943, 1891, 52, 0.429, 1, 1), (18.0, 'henk muller', '29-04-1906', '24-10-1887', '07-05-1940', 2.0, 1.0, 1940, 1887, 53, 0.5, 1, 1), (38.0, 'caius welcker', '21-12-1907', '09-07-1885', '13-02-1939', 17.0, 5.0, 1939, 1885, 54, 0.294, 1, 1), (42.0, 'guus van hecking colenbrander', '10-05-1908', '07-11-1887', '13-03-1941', 1.0, 0.0, 1941, 1887, 54, 0.0, 1, 1), (36.0, 'edu snethlage', '21-12-1907', '09-05-1886', '12-01-1941', 11.0, 10.0, 1941, 1886, 55, 0.909, 1, 1), (31.0, 'lothar van gogh', '14-04-1907', '07-02-1888', '28-05-1945', 2.0, 2.0, 1945, 1888, 57, 1.0, 1, 1), (4.0, 'dolf kessler', '30-04-1905', '02-04-1884', '21-08-1942', 3.0, 0.0, 1942, 1884, 58, 0.0, 1, 1), (48.0, 'harry kuneman', '25-10-1908', '15-01-1886', '07-09-1945', 1.0, 0.0, 1945, 1886, 59, 0.0, 1, 1), (8.0, 'eddy de neve', '30-04-1905', '01-01-1882', '30-08-1943', 3.0, 6.0, 1943, 1882, 61, 2.0, 1, 1), (2.0, 'rein boomsma', '30-04-1905', '19-06-1879', '26-05-1943', 2.0, 0.0, 1943, 1879, 64, 0.0, 1, 1), (49.0, 'vic gonsalves', '21-03-1909', '20-10-1887', '29-08-1922', 3.0, 0.0, 1922, 1887, 35, 0.0, 0, 0), (16.0, 'mannes francken', '29-04-1906', '20-05-1888', '19-11-1948', 22.0, 17.0, 1948, 1888, 60, 0.773, 0, 0), (22.0, 'ferry van der vinne', '13-05-1906', '19-07-1886', '15-11-1947', 3.0, 1.0, 1947, 1886, 61, 0.333, 0, 0), (53.0, 'leo bosschart', '11-12-1909', '24-08-1888', '09-05-1951', 19.0, 1.0, 1951, 1888, 63, 0.053, 0, 0), (27.0, 'john heijning', '01-04-1907', '12-12-1884', '19-05-1947', 8.0, 0.0, 1947, 1884, 63, 0.0, 0, 0), (34.0, 'lou otten', '21-12-1907', '05-11-1883', '07-11-1946', 12.0, 0.0, 1946, 1883, 63, 0.0, 0, 0), (41.0, 'jan akkersdijk', '26-04-1908', '08-01-1887', '31-03-1953', 2.0, 1.0, 1953, 1887, 66, 0.5, 0, 0), (37.0, 'jan thomée', '21-12-1907', '04-12-1886', '01-04-1954', 16.0, 16.0, 1954, 1886, 68, 1.0, 0, 0), (25.0, 'pieter boelmans ter spill', '01-04-1907', '26-01-1886', '31-10-1954', 3.0, 0.0, 1954, 1886, 68, 0.0, 0, 0), (28.0, 'karel heijting', '01-04-1907', '01-05-1883', '00-08-1951', 17.0, 0.0, 1951, 1883, 68, 0.0, 0, 0), (43.0, 'miel mundt', '22-10-1908', '30-05-1880', '17-06-1949', 4.0, 0.0, 1949, 1880, 69, 0.0, 0, 0), (46.0, 'jan kok', '23-10-1908', '09-07-1889', '02-12-1958', 1.0, 0.0, 1958, 1889, 69, 0.0, 0, 0), (35.0, 'cas ruffelse', '21-12-1907', '09-02-1888', '09-09-1958', 8.0, 3.0, 1958, 1888, 70, 0.375, 0, 0), (26.0, 'iman dozy', '01-04-1907', '10-05-1887', '18-07-1957', 4.0, 0.0, 1957, 1887, 70, 0.0, 0, 0), (33.0, 'tonny kessler', '21-12-1907', '20-04-1889', '15-02-1960', 3.0, 1.0, 1960, 1889, 71, 0.333, 0, 0), (17.0, 'anton lens', '29-04-1906', '28-11-1884', '08-10-1955', 2.0, 0.0, 1955, 1884, 71, 0.0, 0, 0), (19.0, 'jan schoemaker', '29-04-1906', '29-05-1882', '27-05-1954', 2.0, 0.0, 1954, 1882, 72, 0.0, 0, 0), (44.0, 'jops reeman', '22-10-1908', '09-08-1886', '16-03-1959', 2.0, 1.0, 1959, 1886, 73, 0.5, 0, 0), (15.0, 'constant feith', '29-04-1906', '03-08-1884', '15-09-1958', 8.0, 2.0, 1958, 1884, 74, 0.25, 0, 0), (5.0, 'bok de korver', '30-04-1905', '27-01-1883', '22-10-1957', 31.0, 1.0, 1957, 1883, 74, 0.032, 0, 0), (23.0, 'jan van beek', '01-04-1907', '22-10-1880', '02-09-1954', 1.0, 0.0, 1954, 1880, 74, 0.0, 0, 0), (9.0, 'peet stol', '30-04-1905', '26-01-1880', '27-11-1956', 2.0, 0.0, 1956, 1880, 76, 0.0, 0, 0), (11.0, 'willy de vos', '30-04-1905', '26-01-1880', '15-07-1957', 2.0, 0.0, 1957, 1880, 77, 0.0, 0, 0), (32.0, 'lo la chapelle', '21-12-1907', '22-06-1888', '23-07-1966', 1.0, 0.0, 1966, 1888, 78, 0.0, 0, 0), (1.0, 'reinier beeuwkes', '30-04-1905', '17-02-1884', '01-04-1963', 19.0, 0.0, 1963, 1884, 79, 0.0, 0, 0), (10.0, 'ben stom', '30-04-1905', '13-10-1886', '18-08-1965', 9.0, 0.0, 1965, 1886, 79, 0.0, 0, 0), (39.0, 'herman jurgens', '29-03-1908', '18-07-1884', '07-09-1964', 2.0, 0.0, 1964, 1884, 80, 0.0, 0, 0), (13.0, 'kees bekker', '29-04-1906', '26-10-1883', '28-12-1964', 6.0, 0.0, 1964, 1883, 81, 0.0, 0, 0), (21.0, 'toine van renterghem', '13-05-1906', '17-04-1885', '01-03-1967', 3.0, 0.0, 1967, 1885, 82, 0.0, 0, 0), (6.0, 'dirk lotsy', '30-04-1905', '03-07-1882', '27-03-1965', 10.0, 1.0, 1965, 1882, 83, 0.1, 0, 0), (29.0, 'max henny', '01-04-1907', '01-10-1885', '05-01-1968', 1.0, 0.0, 1968, 1885, 83, 0.0, 0, 0), (52.0, 'willem boerdam', '25-04-1909', '02-11-1883', '09-12-1966', 2.0, 0.0, 1966, 1883, 83, 0.0, 0, 0), (45.0, 'ed sol', '22-10-1908', '10-06-1881', '21-10-1965', 3.0, 0.0, 1965, 1881, 84, 0.0, 0, 0), (40.0, 'noud stempels', '29-03-1908', '04-04-1882', '12-10-1970', 3.0, 0.0, 1970, 1882, 88, 0.0, 0, 0), (47.0, 'wim groskamp', '25-10-1908', '08-10-1886', '13-01-1974', 1.0, 0.0, 1974, 1886, 88, 0.0, 0, 0), (7.0, 'guus lutjens', '30-04-1905', '13-08-1884', '25-04-1974', 14.0, 5.0, 1974, 1884, 90, 0.357, 0, 0), (24.0, 'hans blume', '01-04-1907', '16-11-1887', 'january 1978', 1.0, 1.0, 1978, 1887, 91, 1.0, 0, 0), (3.0, 'karel gleenewinkel kamperdijk', '30-04-1905', '30-10-1883', '20-06-1975', 2.0, 0.0, 1975, 1883, 92, 0.0, 0, 0), (14.0, 'frans de bruyn kops', '29-04-1906', '28-10-1886', '22-11-1979', 3.0, 0.0, 1979, 1886, 93, 0.0, 0, 0), (20.0, 'jo eshuijs', '13-05-1906', '06-02-1885', '24-11-1979', 1.0, 0.0, 1979, 1885, 94, 0.0, 0, 0), (12.0, 'willem hesselink', '14-05-1905', '08-02-1878', '01-12-1973', 1.0, 1.0, 1973, 1878, 95, 1.0, 0, 0), (30.0, 'willem janssen', '01-04-1907', '11-06-1880', '08-09-1976', 3.0, 0.0, 1976, 1880, 96, 0.0, 0, 0), (51.0, 'kees van nieuwenhuizen', '21-03-1909', '21-04-1884', '12-10-1981', 2.0, 0.0, 1981, 1884, 97, 0.0, 0, 0)]",table_1_11585313_1,"I write concise, practical questions and would use familiar football terms rather than SQL jargon. The SQL returns every player row with computed age, goals-per-cap, wartime_death flag (1939–1945) and a high-priority follow-up flag combining wartime death or high scoring + early death. The schema maps to the players' debut, birth/death dates, caps and goals and the derived numeric fields. Draft question: Show each 1905–1909 Netherlands player with caps, goals, birth and death dates, computed age at death and goals-per-cap, flag if death fell in 1939–1945 and flag as high-priority if wartime or if goals-per-cap ≥1 and age at death <50, with WWII cases at the top, then younger ages, then better scorers. This phrasing stays within the columns and computations present in the query.",persona,"```json
{
  ""short_description"": ""A sports-epidemiologist and World-War-era mortality researcher who studies lifespans and wartime deaths of early Dutch international footballers (1905–1909)."",
  ""goals"": [
    ""Identify which Netherlands internationals from 1905–1909 likely died during World War II (1939–1945) and estimate their ages at death for archival follow-up."",
    ""Compare lifespans of these early elite athletes (approximate age at death) and find high goal-per-cap players who died youn Goals:  Example Queries: ",reward,,
Which Pentium Dual-Core models under 35 W with at least 1.8 GHz or a 667 MT/s FSB have the highest performance per watt?,"
SELECT 
  `Model number`,
  `sSpec number`,
  `Frequency`,
  `FSB`,
  `TDP`,
  `Socket`,
  `Part number(s)`,
  `Release price ( USD )`,
  `Release date`,
  CAST(REPLACE(`Frequency`, ' GHz', '') AS REAL) AS `freq_ghz`,
  CAST(REPLACE(`FSB`, ' MT/s', '') AS INTEGER) AS `fsb_mt_s`,
  CAST(REPLACE(`TDP`, ' W', '') AS INTEGER) AS `tdp_w`,
  ROUND(
    (CAST(REPLACE(`Frequency`, ' GHz', '') AS REAL) * CAST(REPLACE(`FSB`, ' MT/s', '') AS INTEGER))
    / (CASE WHEN CAST(REPLACE(`TDP`, ' W', '') AS INTEGER)=0 THEN 1 ELSE CAST(REPLACE(`TDP`, ' W', '') AS INTEGER) END)
  , 2) AS `Performance per W`
FROM `table_1_11602313_4`
WHERE CAST(REPLACE(`TDP`, ' W', '') AS INTEGER) <= 35
  AND (
    CAST(REPLACE(`Frequency`, ' GHz', '') AS REAL) >= 1.8
    OR CAST(REPLACE(`FSB`, ' MT/s', '') AS INTEGER) >= 667
  )
ORDER BY `Performance per W` DESC, `freq_ghz` DESC;
","
SELECT 
  col0,
  col1,
  col2,
  col4,
  col7,
  col8,
  col10,
  col11,
  col9,
  CAST(REPLACE(col2, ' GHz', '') AS REAL) AS `freq_ghz`,
  CAST(REPLACE(col4, ' MT/s', '') AS INTEGER) AS `fsb_mt_s`,
  CAST(REPLACE(col7, ' W', '') AS INTEGER) AS `tdp_w`,
  ROUND(
    (CAST(REPLACE(col2, ' GHz', '') AS REAL) * CAST(REPLACE(col4, ' MT/s', '') AS INTEGER))
    / (CASE WHEN CAST(REPLACE(col7, ' W', '') AS INTEGER)=0 THEN 1 ELSE CAST(REPLACE(col7, ' W', '') AS INTEGER) END)
  , 2) AS `Performance per W`
FROM `table_1_11602313_4`
WHERE CAST(REPLACE(col7, ' W', '') AS INTEGER) <= 35
  AND (
    CAST(REPLACE(col2, ' GHz', '') AS REAL) >= 1.8
    OR CAST(REPLACE(col4, ' MT/s', '') AS INTEGER) >= 667
  )
ORDER BY `Performance per W` DESC, `freq_ghz` DESC;
","[('pentium dual-core t3200', 'slavg(m0)', '2 ghz', '667 mt/s', '35 w', 'socket p', 'lf80537gf0411m', 'oem', 'q4 2008', 2.0, 667, 35, 38.11), ('pentium dual-core t2410', 'sla4g(m0)', '2 ghz', '533 mt/s', '35 w', 'socket p', 'lf80537ge0411m', 'oem', 'q3 2008', 2.0, 533, 35, 30.46), ('pentium dual-core t2390', 'sla4h(m0)', '1.87 ghz', '533 mt/s', '35 w', 'socket p', 'lf80537ge0361m', 'oem', 'q2 2008', 1.87, 533, 35, 28.48)]",table_1_11602313_4,"STEP 1: Parse intent — compute freq_ghz, fsb_mt_s, tdp_w and Performance per W = (freq_ghz * fsb_mt_s)/tdp_w; filter rows with TDP <= 35 and (Frequency >= 1.8 GHz OR FSB >= 667 MT/s); return columns and order by Performance per W DESC, then freq_ghz DESC. STEP 2: Choose ambiguity — scope ambiguity fits: the phrase “have the highest” can mean a single top item overall or the top item within groups (e.g., per socket, per release period, per model family). The SQL returns ordered rows (no grouping), so both readings are plausible. STEP 3: Draft question — ""Which Pentium Dual-Core models under 35 W with at least 1.8 GHz or a 667 MT/s FSB have the highest performance per watt?"" STEP 4: Explain ambiguity — in the original query this is implemented by listing all matching CPUs ordered by performance-per-watt (so one could take the very first row as the single highest), whereas an alternate interpretation would request the highest performer per subgroup (e.g., per socket or per release date) which would require grouping/aggregation and is not what the SQL does.",persona,"Used-laptop refurbisher / inventory manager who sources compatible low-cost Intel Pentium Dual-Core CPUs for bulk laptop repair and resale; uses this database to pick parts by performance, socket, power and sourcing price. Goals: Quickly identify candidate processors that balance higher clock speed and faster FSB while remaining low-power (suitable for older laptops). Find part numbers and release-price information (retail vs OEM) to guide procurement and ordering. Plan sourcing by release period and socket type to ensure compatibility with common laptop motherboards in inventory. Example Queries: SELECT ""Model number"", ""sSpec number"", ""Frequency"", ""FSB"", ""TDP"", ""Socket"", ""Release price ( USD )""
FROM table_1_11602313_4
WHERE CAST(REPLACE(""Frequency"", ' GHz', '') AS DECIMAL) >= 1.8
  AND (""FSB"" LIKE '667%' OR CAST(REPLACE(""FSB"", ' MT/s', '') AS INTEGER) >= 667)
ORDER BY CAST(REPLACE(""Frequency"", ' GHz', '') AS DECIMAL) DESC; SELECT ""Model number"", ""Part number(s)"", ""Release price ( USD )"", ""Release date""
FROM table_1_11602313_4
WHERE ""Release price ( USD )"" = 'OEM' OR ""Release price ( USD )"" LIKE '$%'
ORDER BY ""Release price ( USD )""; SELECT ""Release date"", ""Socket"", COUNT(*) AS models_count
FROM table_1_11602313_4
GROUP BY ""Release date"", ""Socket""
ORDER BY ""Release date"" ASC, ""Socket"";",reward,,"type: Scope ambiguity | explanation: The question’s phrase “have the highest” can mean (a) the single top model overall (the first row of the ordered results) or (b) the top model within subgroups such as each socket or each release period; the SQL returns all matching rows ordered but does not perform grouping, so it corresponds to the overall-top interpretation while a grouped-top interpretation would need different SQL (GROUP BY + MAX)."
"List up to 10 records where Purse( $ ) > 1500000 and for each provide the Tournament, Location, Purse( $ ), 1st Prize( $ ), the Pct of Purse computed as (1st Prize( $ ) ÷ Purse( $ )) × 100 formatted to two decimal places, and ToPar obtained as the number inside the parentheses of the Score column?","
SELECT `Tournament`, `Location`, `Purse( $ )`, `1st Prize( $ )`, printf('%.2f', (`1st Prize( $ )`/`Purse( $ )`)*100) `Pct of Purse`, (substr(`Score`, instr(`Score`,'(')+1, instr(`Score`,')')-instr(`Score`,'(')-1)+0) `ToPar` FROM `table_1_11603006_1` WHERE (`Purse( $ )`>1500000) LIMIT 10;
","
SELECT col1, col2, col3, col6, printf('%.2f', (col6/col3)*100) `Pct of Purse`, (substr(col5, instr(col5,'(')+1, instr(col5,')')-instr(col5,'(')-1)+0) `ToPar` FROM `table_1_11603006_1` WHERE (col3>1500000) LIMIT 10;
","[('ace group classic', 'florida', 1600000.0, 240000.0, '15.00', -14), ('verizon classic', 'florida', 1600000.0, 240000.0, '15.00', -8), ('mastercard classic', 'mexico', 2000000.0, 300000.0, '15.00', -12), ('toshiba senior classic', 'california', 1550000.0, 232500.0, '15.00', -16), ('liberty mutual legends of golf', 'georgia', 3000000.0, 354000.0, '11.80', -10), (""kinko's classic of austin"", 'texas', 1600000.0, 240000.0, '15.00', -8), ('bayer advantage celebrity pro-am', 'missouri', 1600000.0, 240000.0, '15.00', -11), ('senior pga championship', 'pennsylvania', 2000000.0, 360000.0, '18.00', -4), ('u.s. senior open', 'ohio', 2600000.0, 460000.0, '17.69', -7), ('ford senior players championship', 'michigan', 2500000.0, 375000.0, '15.00', -17)]",table_1_11603006_1,"Parse intent: return Tournament, Location, Purse( $ ), 1st Prize( $ ), a percentage of purse formatted to two decimals, and ToPar parsed from Score for rows with Purse( $ )>1500000, limit 10. Map schema: identify columns Tournament, Location, Purse( $ ), 1st Prize( $ ), Score and the two calculations (Pct of Purse and substring ToPar). Draft: request these exact fields, calculations, filter, and limit. Validate: ensure question explicitly states the calculation formatting and the extraction of ToPar plus the Purse threshold and row limit.",reserved,4,reward,,
"For institutions with Founded > 1900 AND Founded < 2000, list each Status and Color along with the Institution Count (COUNT(*)) and the Earliest Founded (MIN(Founded)), grouping by Status and Color, only include groups with Institution Count >= 1, and sort the results by Earliest Founded?","
SELECT `Status`, `Color`, COUNT(*) `Institution Count`, MIN(`Founded`) `Earliest Founded`
FROM `table_1_11604804_5`
WHERE `Founded` > 1900 AND `Founded` < 2000
GROUP BY `Status`, `Color`
HAVING COUNT(*) >= 1
ORDER BY `Earliest Founded`;
","
SELECT col2, col4, COUNT(*) `Institution Count`, MIN(col3) `Earliest Founded`
FROM `table_1_11604804_5`
WHERE col3 > 1900 AND col3 < 2000
GROUP BY col2, col4
HAVING COUNT(*) >= 1
ORDER BY `Earliest Founded`;
","[('state', 'green', 1, 1907.0), ('state', 'gold, red', 1, 1918.0), ('state', 'navy blue', 1, 1941.0), ('state', 'blue and white', 1, 1969.0), ('state', 'gold and white', 1, 1971.0), ('state', 'red and white', 1, 1992.0)]",table_1_11604804_5,"1) Parse intent: return per-Status and Color aggregates for rows with Founded between 1900 and 2000 (exclusive), computing count and earliest founding and only keeping groups with at least one member, ordered by earliest year. 2) Map schema: use Status and Color as grouping keys, Founded for MIN to produce Earliest Founded, COUNT(*) as Institution Count. 3) Draft: ask explicitly for Status, Color, Institution Count, Earliest Founded with the WHERE, GROUP BY, HAVING, and ORDER BY conditions. 4) Validate: ensure question explicitly names Status, Color, Institution Count, Earliest Founded, the Founded range, grouping by Status and Color, HAVING >= 1, and ordering by Earliest Founded.",reserved,9,reward,,
"What are COUNT(Tournament) (Total Tournaments), SUM(Purse( $ )) (Total Purse( $ )), AVG(1st Prize( $ )) (Average 1st Prize( $ )), and SUM((Location = 'California')) (California_Tournaments) for rows where 'Purse( $ )' >= 500000 and 'Location' = 'California'?","
SELECT
  COUNT(`Tournament`) `Total Tournaments`,
  SUM(`Purse( $ )`) `Total Purse( $ )`,
  AVG(`1st Prize( $ )`) `Average 1st Prize( $ )`,
  SUM((`Location` = REPLACE('`California`','`',''))) `California_Tournaments`
FROM `table_1_11622255_1`
WHERE `Purse( $ )` >= 500000 AND `Location` = REPLACE('`California`','`','')
LIMIT 1;
","
SELECT
  COUNT(col1) `Total Tournaments`,
  SUM(col3) `Total Purse( $ )`,
  AVG(col6) `Average 1st Prize( $ )`,
  SUM((col2 = REPLACE('`California`','`',''))) `California_Tournaments`
FROM `table_1_11622255_1`
WHERE col3 >= 500000 AND col2 = REPLACE('`California`','`','')
LIMIT 1;
","[(0, None, None, None)]",table_1_11622255_1,"1) Parse SQL: obtain aggregated counts and sums for California tournaments whose purse is at least 500000. 2) Map schema: reference Tournament, Purse( $ ), 1st Prize( $ ), and Location columns. 3) Draft: pose a question that requests COUNT(Tournament), SUM(Purse( $ )), AVG(1st Prize( $ )), and SUM((Location = 'California')) under the specified WHERE conditions. 4) Validate: the question precisely reflects the SQL's calculations and filter.",reserved,5,reward,,
"Produce a combined report for 1989 that includes: an overall tour summary (counts and purse metrics including median and percent above-average), a list of repeat winners with their aggregated first-prize earnings and tournament lists with first/last win dates, and per-location tiles showing tournament counts, purse sums/averages, and average winning-stroke and to-par metrics.","
WITH `clean` AS (
  SELECT
    `Date`,
    `Tournament`,
    `Location`,
    `Purse( $ )`,
    `Winner`,
    `Score`,
    `1st Prize( $ )`,
    CASE 
      WHEN `Winner` LIKE 'Canceled%' THEN NULL
      WHEN `Winner` LIKE '%(%' THEN TRIM(SUBSTR(`Winner`, 1, INSTR(`Winner`, ' (') - 1))
      ELSE `Winner`
    END AS player,
    CASE 
      WHEN `1st Prize( $ )` LIKE 'Canceled%' THEN 0
      ELSE CAST(REPLACE(`1st Prize( $ )`, ',', '') AS INTEGER)
    END AS first_prize_int,
    CASE 
      WHEN `Score` LIKE 'Canceled%' THEN NULL
      ELSE CAST(SUBSTR(`Score`, 1, INSTR(`Score`, ' ')-1) AS INTEGER)
    END AS score_strokes,
    CASE
      WHEN `Score` LIKE 'Canceled%' THEN NULL
      WHEN INSTR(`Score`, '(') > 0 AND INSTR(`Score`, ')') > INSTR(`Score`, '(') THEN
        CAST(SUBSTR(`Score`, INSTR(`Score`, '(')+1, INSTR(`Score`, ')') - INSTR(`Score`, '(') - 1) AS INTEGER)
      ELSE NULL
    END AS score_to_par
  FROM `table_1_11622496_1`
),
`purses` AS (
  SELECT
    `Purse( $ )` AS purse,
    ROW_NUMBER() OVER (ORDER BY `Purse( $ )`) AS rn,
    COUNT(*) OVER () AS cnt
  FROM `clean`
),
`median_purse` AS (
  SELECT
    CASE
      WHEN cnt % 2 = 1 THEN (SELECT purse FROM `purses` WHERE rn = (cnt+1)/2)
      ELSE ((SELECT purse FROM `purses` WHERE rn = cnt/2) + (SELECT purse FROM `purses` WHERE rn = cnt/2 + 1)) / 2.0
    END AS median_purse
  FROM (SELECT cnt FROM `purses` LIMIT 1)
),
`summary` AS (
  SELECT
    'summary' AS section,
    'ALL' AS entity,
    COUNT(*) AS metric1_total_tournaments,
    SUM(`Purse( $ )`) AS metric2_total_purse,
    AVG(`Purse( $ )`) AS metric3_avg_purse,
    (SELECT median_purse FROM `median_purse`) AS metric4_median_purse,
    SUM(CASE WHEN `Winner` LIKE 'Canceled%' THEN 1 ELSE 0 END) AS metric5_canceled,
    SUM(CASE WHEN `Purse( $ )` > (SELECT AVG(`Purse( $ )`) FROM `clean`) THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS metric6_pct_tournaments_above_avg_purse
  FROM `clean`
),
`repeat_winners` AS (
  SELECT
    'player_summary' AS section,
    player AS entity,
    COUNT(*) AS metric1_wins,
    SUM(first_prize_int) AS metric2_total_first_prize,
    ROUND(AVG(first_prize_int),0) AS metric3_avg_first_prize,
    GROUP_CONCAT(`Tournament`, ' | ') AS metric4_tournaments_list,
    MIN(`Date`) AS metric5_first_win_date,
    MAX(`Date`) AS metric6_last_win_date
  FROM `clean`
  WHERE player IS NOT NULL
  GROUP BY player
  HAVING COUNT(*) > 1
),
`location_tiles` AS (
  SELECT
    'location_tile' AS section,
    `Location` AS entity,
    COUNT(*) AS metric1_tournaments,
    SUM(`Purse( $ )`) AS metric2_total_purse,
    AVG(`Purse( $ )`) AS metric3_avg_purse,
    ROUND(AVG(score_strokes),2) AS metric4_avg_winning_strokes,
    ROUND(AVG(score_to_par),2) AS metric5_avg_relative_to_par,
    SUM(CASE WHEN player IS NULL THEN 1 ELSE 0 END) AS metric6_canceled_events_in_location
  FROM `clean`
  GROUP BY `Location`
)
SELECT * FROM `summary`
UNION ALL
SELECT * FROM `repeat_winners`
UNION ALL
SELECT * FROM `location_tiles`
ORDER BY section, entity;
","WITH `clean` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    CASE 
      WHEN col4 LIKE 'Canceled%' THEN NULL
      WHEN col4 LIKE '%(%' THEN TRIM(SUBSTR(col4, 1, INSTR(col4, ' (') - 1))
      ELSE col4
    END AS player,
    CASE 
      WHEN col6 LIKE 'Canceled%' THEN 0
      ELSE CAST(REPLACE(col6, ',', '') AS INTEGER)
    END AS first_prize_int,
    CASE 
      WHEN col5 LIKE 'Canceled%' THEN NULL
      ELSE CAST(SUBSTR(col5, 1, INSTR(col5, ' ')-1) AS INTEGER)
    END AS score_strokes,
    CASE
      WHEN col5 LIKE 'Canceled%' THEN NULL
      WHEN INSTR(col5, '(') > 0 AND INSTR(col5, ')') > INSTR(col5, '(') THEN
        CAST(SUBSTR(col5, INSTR(col5, '(')+1, INSTR(col5, ')') - INSTR(col5, '(') - 1) AS INTEGER)
      ELSE NULL
    END AS score_to_par
  FROM `table_1_11622496_1`
),
`purses` AS (
  SELECT
    col3 AS purse,
    ROW_NUMBER() OVER (ORDER BY col3) AS rn,
    COUNT(*) OVER () AS cnt
  FROM `clean`
),
`median_purse` AS (
  SELECT
    CASE
      WHEN cnt % 2 = 1 THEN (SELECT purse FROM `table_1_11622496_1` WHERE rn = (cnt+1)/2)
      ELSE ((SELECT purse FROM `table_1_11622496_1` WHERE rn = cnt/2) + (SELECT purse FROM `table_1_11622496_1` WHERE rn = cnt/2 + 1)) / 2.0
    END AS median_purse
  FROM (SELECT cnt FROM `table_1_11622496_1` LIMIT 1)
),
`summary` AS (
  SELECT
    'summary' AS section,
    'ALL' AS entity,
    COUNT(*) AS metric1_total_tournaments,
    SUM(col3) AS metric2_total_purse,
    AVG(col3) AS metric3_avg_purse,
    (SELECT median_purse FROM `table_1_11622496_1`) AS metric4_median_purse,
    SUM(CASE WHEN col4 LIKE 'Canceled%' THEN 1 ELSE 0 END) AS metric5_canceled,
    SUM(CASE WHEN col3 > (SELECT AVG(col3) FROM `clean`) THEN 1 ELSE 0 END) * 100.0 / COUNT(*) AS metric6_pct_tournaments_above_avg_purse
  FROM `clean`
),
`repeat_winners` AS (
  SELECT
    'player_summary' AS section,
    player AS entity,
    COUNT(*) AS metric1_wins,
    SUM(first_prize_int) AS metric2_total_first_prize,
    ROUND(AVG(first_prize_int),0) AS metric3_avg_first_prize,
    GROUP_CONCAT(col1, ' | ') AS metric4_tournaments_list,
    MIN(col0) AS metric5_first_win_date,
    MAX(col0) AS metric6_last_win_date
  FROM `clean`
  WHERE player IS NOT NULL
  GROUP BY player
  HAVING COUNT(*) > 1
),
`location_tiles` AS (
  SELECT
    'location_tile' AS section,
    col2 AS entity,
    COUNT(*) AS metric1_tournaments,
    SUM(col3) AS metric2_total_purse,
    AVG(col3) AS metric3_avg_purse,
    ROUND(AVG(score_strokes),2) AS metric4_avg_winning_strokes,
    ROUND(AVG(score_to_par),2) AS metric5_avg_relative_to_par,
    SUM(CASE WHEN player IS NULL THEN 1 ELSE 0 END) AS metric6_canceled_events_in_location
  FROM `clean`
  GROUP BY col2
)
SELECT * FROM `table_1_11622496_1`
UNION ALL
SELECT * FROM `table_1_11622496_1`
UNION ALL
SELECT * FROM `table_1_11622496_1`
ORDER BY 1, 2;","[('apr 16', 'the tradition at desert mountain', 'arizona', 600000.0, 'don bies (4)', '275 (-13)', '90,000'), ('apr 16', 'the tradition at desert mountain', 'arizona', 600000.0, 'don bies (4)', '275 (-13)', '90,000'), ('apr 16', 'the tradition at desert mountain', 'arizona', 600000.0, 'don bies (4)', '275 (-13)', '90,000'), ('apr 2', 'murata seniors reunion', 'texas', 300000.0, 'don bies (3)', '208 (-8)', '45,000'), ('apr 2', 'murata seniors reunion', 'texas', 300000.0, 'don bies (3)', '208 (-8)', '45,000'), ('apr 2', 'murata seniors reunion', 'texas', 300000.0, 'don bies (3)', '208 (-8)', '45,000'), ('aug 13', 'rancho murieta senior gold rush', 'california', 350000.0, 'dave hill (6)', '207 (-9)', '52,500'), ('aug 13', 'rancho murieta senior gold rush', 'california', 350000.0, 'dave hill (6)', '207 (-9)', '52,500'), ('aug 13', 'rancho murieta senior gold rush', 'california', 350000.0, 'dave hill (6)', '207 (-9)', '52,500'), ('aug 20', 'gte northwest classic', 'washington', 350000.0, 'al geiberger (5)', '204 (-12)', '52,500'), ('aug 20', 'gte northwest classic', 'washington', 350000.0, 'al geiberger (5)', '204 (-12)', '52,500'), ('aug 20', 'gte northwest classic', 'washington', 350000.0, 'al geiberger (5)', '204 (-12)', '52,500'), ('aug 27', 'sunwest bank charley pride senior golf classic', 'new mexico', 300000.0, 'bob charles (12)', '203 (-13)', '45,000'), ('aug 27', 'sunwest bank charley pride senior golf classic', 'new mexico', 300000.0, 'bob charles (12)', '203 (-13)', '45,000'), ('aug 27', 'sunwest bank charley pride senior golf classic', 'new mexico', 300000.0, 'bob charles (12)', '203 (-13)', '45,000'), ('aug 6', 'showdown classic', 'utah', 350000.0, 'tom shaw (1)', '207 (-9)', '52,500'), ('aug 6', 'showdown classic', 'utah', 350000.0, 'tom shaw (1)', '207 (-9)', '52,500'), ('aug 6', 'showdown classic', 'utah', 350000.0, 'tom shaw (1)', '207 (-9)', '52,500'), ('dec 2', 'gte west classic', 'california', 350000.0, 'walt zembriski (3)', '197 (-13)', '52,500'), ('dec 2', 'gte west classic', 'california', 350000.0, 'walt zembriski (3)', '197 (-13)', '52,500'), ('dec 2', 'gte west classic', 'california', 350000.0, 'walt zembriski (3)', '197 (-13)', '52,500'), ('feb 12', ""general foods pga seniors' championship"", 'florida', 400000.0, 'larry mowry (4)', '281 (-7)', '72,000'), ('feb 12', ""general foods pga seniors' championship"", 'florida', 400000.0, 'larry mowry (4)', '281 (-7)', '72,000'), ('feb 12', ""general foods pga seniors' championship"", 'florida', 400000.0, 'larry mowry (4)', '281 (-7)', '72,000'), ('feb 19', 'gte suncoast classic', 'florida', 300000.0, 'bob charles (9)', '207 (-9)', '45,000'), ('feb 19', 'gte suncoast classic', 'florida', 300000.0, 'bob charles (9)', '207 (-9)', '45,000'), ('feb 19', 'gte suncoast classic', 'florida', 300000.0, 'bob charles (9)', '207 (-9)', '45,000'), ('feb 26', 'aetna challenge', 'florida', 300000.0, 'gene littler (8)', '209 (-7)', '45,000'), ('feb 26', 'aetna challenge', 'florida', 300000.0, 'gene littler (8)', '209 (-7)', '45,000'), ('feb 26', 'aetna challenge', 'florida', 300000.0, 'gene littler (8)', '209 (-7)', '45,000'), ('jan 8', 'mony senior tournament of champions', 'california', 250000.0, 'miller barber (23)', '280 (-8)', '50,000'), ('jan 8', 'mony senior tournament of champions', 'california', 250000.0, 'miller barber (23)', '280 (-8)', '50,000'), ('jan 8', 'mony senior tournament of champions', 'california', 250000.0, 'miller barber (23)', '280 (-8)', '50,000'), ('jul 16', 'greater grand rapids open', 'michigan', 300000.0, 'john paul cain (1)', '203 (-10)', '45,000'), ('jul 16', 'greater grand rapids open', 'michigan', 300000.0, 'john paul cain (1)', '203 (-10)', '45,000'), ('jul 16', 'greater grand rapids open', 'michigan', 300000.0, 'john paul cain (1)', '203 (-10)', '45,000'), ('jul 2', 'u.s. senior open', 'pennsylvania', 450000.0, 'orville moody (9)', '279 (-9)', '80,000'), ('jul 2', 'u.s. senior open', 'pennsylvania', 450000.0, 'orville moody (9)', '279 (-9)', '80,000'), ('jul 2', 'u.s. senior open', 'pennsylvania', 450000.0, 'orville moody (9)', '279 (-9)', '80,000'), ('jul 23', 'ameritech senior open', 'ohio', 500000.0, 'bruce crampton (15)', '205 (-11)', '75,000'), ('jul 23', 'ameritech senior open', 'ohio', 500000.0, 'bruce crampton (15)', '205 (-11)', '75,000'), ('jul 23', 'ameritech senior open', 'ohio', 500000.0, 'bruce crampton (15)', '205 (-11)', '75,000'), ('jul 30', 'newport cup', 'rhode island', 275000.0, 'jim dent (2)', '206 (-10)', '41,500'), ('jul 30', 'newport cup', 'rhode island', 275000.0, 'jim dent (2)', '206 (-10)', '41,500'), ('jul 30', 'newport cup', 'rhode island', 275000.0, 'jim dent (2)', '206 (-10)', '41,500'), ('jul 9', 'digital seniors classic', 'massachusetts', 300000.0, 'bob charles (11)', '200 (-16)', '45,000'), ('jul 9', 'digital seniors classic', 'massachusetts', 300000.0, 'bob charles (11)', '200 (-16)', '45,000'), ('jul 9', 'digital seniors classic', 'massachusetts', 300000.0, 'bob charles (11)', '200 (-16)', '45,000'), ('jun 11', 'mazda senior tournament players championship', 'florida', 700000.0, 'orville moody (8)', '271 (-17)', '105,000'), ('jun 11', 'mazda senior tournament players championship', 'florida', 700000.0, 'orville moody (8)', '271 (-17)', '105,000'), ('jun 11', 'mazda senior tournament players championship', 'florida', 700000.0, 'orville moody (8)', '271 (-17)', '105,000'), ('jun 18', 'northville long island classic', 'new york', 350000.0, 'butch baird (2)', '183 (-9)', '52,500'), ('jun 18', 'northville long island classic', 'new york', 350000.0, 'butch baird (2)', '183 (-9)', '52,500'), ('jun 18', 'northville long island classic', 'new york', 350000.0, 'butch baird (2)', '183 (-9)', '52,500'), ('jun 25', 'mony syracuse senior classic', 'new york', 300000.0, 'jim dent (1)', '201 (-15)', '45,000'), ('jun 25', 'mony syracuse senior classic', 'new york', 300000.0, 'jim dent (1)', '201 (-15)', '45,000'), ('jun 25', 'mony syracuse senior classic', 'new york', 300000.0, 'jim dent (1)', '201 (-15)', '45,000'), ('jun 4', 'doug sanders kingwood celebrity classic', 'texas', 300000.0, 'homero blancas (1)', '208 (-8)', '45,000'), ('jun 4', 'doug sanders kingwood celebrity classic', 'texas', 300000.0, 'homero blancas (1)', '208 (-8)', '45,000'), ('jun 4', 'doug sanders kingwood celebrity classic', 'texas', 300000.0, 'homero blancas (1)', '208 (-8)', '45,000'), ('mar 12', 'mony arizona classic', 'arizona', 300000.0, 'bruce crampton (14)', '200 (-16)', '45,000'), ('mar 12', 'mony arizona classic', 'arizona', 300000.0, 'bruce crampton (14)', '200 (-16)', '45,000'), ('mar 12', 'mony arizona classic', 'arizona', 300000.0, 'bruce crampton (14)', '200 (-16)', '45,000'), ('mar 5', 'vintage chrysler invitational', 'california', 370000.0, 'miller barber (24)', '281 (-7)', '55,500'), ('mar 5', 'vintage chrysler invitational', 'california', 370000.0, 'miller barber (24)', '281 (-7)', '55,500'), ('mar 5', 'vintage chrysler invitational', 'california', 370000.0, 'miller barber (24)', '281 (-7)', '55,500'), ('may 14', ""bell atlantic/st. christopher's classic"", 'pennsylvania', 400000.0, 'dave hill (5)', '206 (-4)', '60,000'), ('may 14', ""bell atlantic/st. christopher's classic"", 'pennsylvania', 400000.0, 'dave hill (5)', '206 (-4)', '60,000'), ('may 14', ""bell atlantic/st. christopher's classic"", 'pennsylvania', 400000.0, 'dave hill (5)', '206 (-4)', '60,000'), ('may 21', 'nynex/golf digest commemorative', 'new york', 300000.0, 'bob charles (10)', '193 (-17)', '45,000'), ('may 21', 'nynex/golf digest commemorative', 'new york', 300000.0, 'bob charles (10)', '193 (-17)', '45,000'), ('may 21', 'nynex/golf digest commemorative', 'new york', 300000.0, 'bob charles (10)', '193 (-17)', '45,000'), ('may 28', 'southwestern bell classic', 'oklahoma', 300000.0, 'bobby nichols (1)', '209 (-7)', '45,000'), ('may 28', 'southwestern bell classic', 'oklahoma', 300000.0, 'bobby nichols (1)', '209 (-7)', '45,000'), ('may 28', 'southwestern bell classic', 'oklahoma', 300000.0, 'bobby nichols (1)', '209 (-7)', '45,000'), ('may 7', 'rjr at the dominion', 'texas', 250000.0, 'larry mowry (5)', '201 (-15)', '37,500'), ('may 7', 'rjr at the dominion', 'texas', 250000.0, 'larry mowry (5)', '201 (-15)', '37,500'), ('may 7', 'rjr at the dominion', 'texas', 250000.0, 'larry mowry (5)', '201 (-15)', '37,500'), ('nov 12', 'general tire las vegas classic', 'nevada', 300000.0, 'charles coody (1)', '205 (-11)', '45,000'), ('nov 12', 'general tire las vegas classic', 'nevada', 300000.0, 'charles coody (1)', '205 (-11)', '45,000'), ('nov 12', 'general tire las vegas classic', 'nevada', 300000.0, 'charles coody (1)', '205 (-11)', '45,000'), ('oct 1', 'fairfield barnett space coast classic', 'florida', 300000.0, 'bob charles (13)', '203 (-13)', '45,000'), ('oct 1', 'fairfield barnett space coast classic', 'florida', 300000.0, 'bob charles (13)', '203 (-13)', '45,000'), ('oct 1', 'fairfield barnett space coast classic', 'florida', 300000.0, 'bob charles (13)', '203 (-13)', '45,000'), ('oct 15', 'gatlin brothers southwest senior classic', 'texas', 300000.0, 'george archer (1)', '209 (-7)', '45,000'), ('oct 15', 'gatlin brothers southwest senior classic', 'texas', 300000.0, 'george archer (1)', '209 (-7)', '45,000'), ('oct 15', 'gatlin brothers southwest senior classic', 'texas', 300000.0, 'george archer (1)', '209 (-7)', '45,000'), ('oct 22', 'transamerica senior golf championship', 'california', 400000.0, 'billy casper (9)', '207 (-9)', '60,000'), ('oct 22', 'transamerica senior golf championship', 'california', 400000.0, 'billy casper (9)', '207 (-9)', '60,000'), ('oct 22', 'transamerica senior golf championship', 'california', 400000.0, 'billy casper (9)', '207 (-9)', '60,000'), ('oct 8', 'rjr championship', 'north carolina', 1500000.0, 'gary player (14)', '207 (-3)', '202,500'), ('oct 8', 'rjr championship', 'north carolina', 1500000.0, 'gary player (14)', '207 (-3)', '202,500'), ('oct 8', 'rjr championship', 'north carolina', 1500000.0, 'gary player (14)', '207 (-3)', '202,500'), ('sep 10', 'gte north classic', 'indiana', 350000.0, 'gary player (13)', '135 (-9)', '52,500'), ('sep 10', 'gte north classic', 'indiana', 350000.0, 'gary player (13)', '135 (-9)', '52,500'), ('sep 10', 'gte north classic', 'indiana', 350000.0, 'gary player (13)', '135 (-9)', '52,500'), ('sep 17', 'crestar classic', 'virginia', 350000.0, 'chi chi rodriguez (13)', '203 (-13)', '52,500'), ('sep 17', 'crestar classic', 'virginia', 350000.0, 'chi chi rodriguez (13)', '203 (-13)', '52,500'), ('sep 17', 'crestar classic', 'virginia', 350000.0, 'chi chi rodriguez (13)', '203 (-13)', '52,500'), ('sep 24', 'painewebber invitational', 'north carolina', 325000.0, 'canceled due to hurricane hugo', 'canceled due to hurricane hugo', 'canceled due to hurricane hugo'), ('sep 24', 'painewebber invitational', 'north carolina', 325000.0, 'canceled due to hurricane hugo', 'canceled due to hurricane hugo', 'canceled due to hurricane hugo'), ('sep 24', 'painewebber invitational', 'north carolina', 325000.0, 'canceled due to hurricane hugo', 'canceled due to hurricane hugo', 'canceled due to hurricane hugo'), ('sep 3', 'rjr bank one classic', 'kentucky', 300000.0, 'rives mcbee (1)', '202 (-8)', '45,000'), ('sep 3', 'rjr bank one classic', 'kentucky', 300000.0, 'rives mcbee (1)', '202 (-8)', '45,000'), ('sep 3', 'rjr bank one classic', 'kentucky', 300000.0, 'rives mcbee (1)', '202 (-8)', '45,000')]",table_1_11622496_1,"As a designer I might request a combined deliverable that packages overall economics, repeat-champion stats, and location tile metrics for easy integration into game design. The SQL returns a union of an overall summary, player-level repeat-winner summaries, and per-location tile metrics ordered together. The schema elements used are the purse and first-prize amounts, cleaned player names and scores, dates, tournaments, and locations. Draft question: ask for a combined report with those three sections—tour summary, repeat-winner earnings/tournaments, and per-location economic and scoring metrics. Validate: this reflects the final UNION of summary, repeat_winners, and location_tiles in the query.",persona,"An independent board-game designer building an economic/strategy game based on the 1989 Senior PGA Tour who needs historically grounded tournament values, repeat-champion dynamics, and location-based tile economics. Goals: Model the in-game economy by deriving realistic purse and first-prize distributions to set card values and victory rewards. Identify repeat winners and estimate their aggregated first-prize earnings to create player-character cards with appropriate abilities/ratings. Assign state/location tiles with relative economic weight and average winning-stroke difficulty so game tiles reflect geographic variance and strategic value. Example Queries: SELECT COUNT(*) AS total_tournaments,
       SUM(""Purse( $ )"") AS total_purse,
       AVG(""Purse( $ )"") AS avg_purse,
       SUM(CASE WHEN Winner LIKE 'Canceled%' THEN 1 ELSE 0 END) AS canceled_tournaments
FROM table_1_11622496_1; SELECT
  CASE WHEN Winner LIKE '%(%' THEN TRIM(SUBSTR(Winner, 1, INSTR(Winner, ' (') - 1)) ELSE Winner END AS player,
  COUNT(*) AS wins,
  SUM(CAST(REPLACE(""1st Prize( $ )"", ',', '') AS INTEGER)) AS total_first_prize
FROM table_1_11622496_1
WHERE Winner NOT LIKE 'Canceled%'
GROUP BY player
HAVING COUNT(*) > 1
ORDER BY wins DESC, total_first_prize DESC; SELECT Location,
       COUNT(*) AS tournaments,
       SUM(""Purse( $ )"") AS total_purse,
       AVG(""Purse( $ )"") AS avg_purse,
       AVG(CAST(SUBSTR(Score, 1, INSTR(Score, ' ')-1) AS INTEGER)) AS avg_winning_strokes
FROM table_1_11622496_1
WHERE Score NOT LIKE 'Canceled%'
GROUP BY Location
ORDER BY total_purse DESC, avg_winning_strokes ASC;",reward,,
"For each row, what are the Total No., Celebrity and Director, and what is the ISO Date obtained from Original air date by replacing 'January' with '-01-', 'October' with '-10-', 'November' with '-11-' and 'December' with '-12-', then taking the last four characters of that replaced string as the year, the two characters immediately after the first '-' as the month, and the substring before the first '-' as the day zero-padded to two digits, formatted as YYYY-MM-DD?","
SELECT `Total No.`, `Celebrity`, `Director`, (substr(replace(replace(replace(replace(`Original air date`,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'), -4, 4) || '-' || substr(replace(replace(replace(replace(`Original air date`,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'), instr(replace(replace(replace(replace(`Original air date`,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'),'-')+1, 2) || '-' || printf('%02d', substr(replace(replace(replace(replace(`Original air date`,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'), 1, instr(replace(replace(replace(replace(`Original air date`,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'),'-')-1))) AS `ISO Date` FROM `table_1_11642945_1`;
","
SELECT col0, col1, col2, (substr(replace(replace(replace(replace(col3,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'), -4, 4) || '-' || substr(replace(replace(replace(replace(col3,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'), instr(replace(replace(replace(replace(col3,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'),'-')+1, 2) || '-' || printf('%02d', substr(replace(replace(replace(replace(col3,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'), 1, instr(replace(replace(replace(replace(col3,'January','-01-'),'October','-10-'),'November','-11-'),'December','-12-'),'-')-1))) AS `ISO Date` FROM `table_1_11642945_1`;
","[(1.0, 'shaun majumder', 'scott harper', '2007-11-00'), (2.0, 'margot kidder', 'margaret slaght', '2007-18-00'), (3.0, 'steven page', 'david langer', '2007-25-00'), (4.0, 'sonja smits', 'karen pinker', '2007-1n-00'), (5.0, 'chantal kreviazuk', 'nadine schwartz', '2007-8n-00'), (6.0, 'major-general lewis mackenzie', 'richard martyn', '2007-15-00'), (7.0, 'mary walsh', 'matt gallagher', '2007-22-00'), (8.0, 'randy bachman', 'margaret slaght', '2007-29-00'), (9.0, 'scott thompson', 'scott harper', '2007-6d-00'), (10.0, 'don cherry', 'richard martyn', '2008-10-00'), (11.0, 'measha brueggergosman', 'karen pinker', '2008-17-00'), (12.0, 'margaret trudeau', 'peter findlay', '2008-24-00')]",table_1_11642945_1,"1) Parse intent: select Total No., Celebrity, Director and compute an ISO Date by replacing month names with numeric codes and reassembling year-month-day with zero-padded day. 2) Map schema: use table_1_11642945_1 columns Total No., Celebrity, Director, Original air date. 3) Draft question: ask for those columns and specify the exact replacement and substring operations to produce YYYY-MM-DD. 4) Validate: ensures all columns and the replacement/substr/zero-pad operations are described.",reserved,3,reward,,
"For each Nature of Help, considering only rows with Year >= 2000 and a non-empty People Assisted value, provide the Disaster Count (COUNT(*)), the Disasters as a '; '-separated list, and the literal fields 'Bangladesh' (Example Country) and 'India' (Example Country 2), ordered by Disaster Count descending and limited to the top 5 entries?","
SELECT `Nature of Help`, COUNT(*) `Disaster Count`, GROUP_CONCAT(`Disaster`, '; ') `Disasters`, '`Bangladesh`' `Example Country`, '`India`' `Example Country 2`
FROM `table_1_11649123_1`
WHERE `Year` >= '2000' AND `People Assisted` <> ''
GROUP BY `Nature of Help`
ORDER BY COUNT(*) DESC
LIMIT 5;
","
SELECT col5, COUNT(*) `Disaster Count`, GROUP_CONCAT(col0, '; ') `Disasters`, '`Bangladesh`' `Example Country`, '`India`' `Example Country 2`
FROM `table_1_11649123_1`
WHERE col1 >= '2000' AND col4 <> ''
GROUP BY col5
ORDER BY COUNT(*) DESC
LIMIT 5;
","[('medical, shelter, food, clothing', 2, 'gujarat earthquake; asian tsunami', '`Bangladesh`', '`India`'), ('medical, water, food, clothing, shelter', 1, 'cyclone sidr', '`Bangladesh`', '`India`'), ('medical, shelter/ re-furb, food, clothing, it', 1, 'hurricane katrina', '`Bangladesh`', '`India`'), ('medical, shelter, food, clothing, counseling', 1, 'kashmir earthquake', '`Bangladesh`', '`India`'), ('medical, food, shelter', 1, 'sumatra earthquake', '`Bangladesh`', '`India`')]",table_1_11649123_1,"1) Parse SQL intent: select Nature of Help with aggregated metrics: count and concatenated Disaster names, add two literal country columns, restrict to Year >= 2000 and non-empty People Assisted, order by count desc and limit to 5. 2) Map schema semantics: use Nature of Help, Disaster, Year, People Assisted from the table and output 'Bangladesh' and 'India' as constants. 3) Draft the question: ask for those exact columns and calculations per Nature of Help with the filters and top-5 ordering. 4) Validate: ensures inclusion of COUNT(*) as Disaster Count, GROUP_CONCAT as Disasters with '; ', the two example country columns, the WHERE conditions, ORDER BY and LIMIT.",reserved,9,reward,,
Which seasons showed improvement after a coach change?,"
WITH parsed AS (
  SELECT
    `Season`,
    CAST(`Position` AS INTEGER) AS `Position`,
    `Win/Loss`,
    `Coach`,
    `Captain`,
    `Dudley Tuckey Medal`,
    `Leading goalkicker`,
    CAST(substr(`Win/Loss`, 1, instr(`Win/Loss`, '-') - 1) AS INTEGER) AS wins,
    CAST(substr(`Win/Loss`, instr(`Win/Loss`, '-') + 1) AS INTEGER) AS losses,
    TRIM(substr(`Leading goalkicker`, 1, instr(`Leading goalkicker`, '(') - 1)) AS leading_goalkicker_name,
    CAST(substr(`Leading goalkicker`, instr(`Leading goalkicker`, '(') + 1, instr(`Leading goalkicker`, ')') - instr(`Leading goalkicker`, '(') - 1) AS INTEGER) AS leading_goals
  FROM table_1_1165048_1
),
coach_agg AS (
  SELECT
    `Coach`,
    COUNT(*) AS coach_total_seasons,
    ROUND(AVG(`Position`), 2) AS coach_avg_position,
    ROUND(AVG(wins), 2) AS coach_avg_wins
  FROM parsed
  GROUP BY `Coach`
),
captain_agg AS (
  SELECT
    `Captain`,
    COUNT(*) AS captain_total_seasons,
    ROUND(AVG(`Position`), 2) AS captain_avg_position,
    ROUND(AVG(wins), 2) AS captain_avg_wins
  FROM parsed
  GROUP BY `Captain`
),
overall AS (
  SELECT ROUND(AVG(leading_goals),2) AS overall_avg_goals FROM parsed
)
SELECT
  p.`Season`,
  p.`Position`,
  (p.`Position` - LAG(p.`Position`) OVER (ORDER BY p.`Season`)) AS position_change_from_prev,
  p.`Win/Loss`,
  p.wins,
  p.losses,
  p.`Coach`,
  ca.coach_total_seasons,
  ca.coach_avg_position,
  ca.coach_avg_wins,
  CASE WHEN p.`Coach` != LAG(p.`Coach`) OVER (ORDER BY p.`Season`) THEN 1 ELSE 0 END AS coach_changed_since_prev_season,
  p.`Captain`,
  cpa.captain_total_seasons,
  cpa.captain_avg_position,
  cpa.captain_avg_wins,
  CASE WHEN p.`Captain` != LAG(p.`Captain`) OVER (ORDER BY p.`Season`) THEN 1 ELSE 0 END AS captain_changed_since_prev_season,
  p.`Dudley Tuckey Medal`,
  p.`Leading goalkicker`,
  p.leading_goalkicker_name,
  p.leading_goals,
  DENSE_RANK() OVER (ORDER BY p.leading_goals DESC) AS leading_goals_rank,
  CASE WHEN p.leading_goals >= (SELECT overall_avg_goals FROM overall) THEN 1 ELSE 0 END AS leading_goals_above_overall_avg
FROM parsed p
LEFT JOIN coach_agg ca ON p.`Coach` = ca.`Coach`
LEFT JOIN captain_agg cpa ON p.`Captain` = cpa.`Captain`
ORDER BY p.`Season` ASC;
","WITH parsed AS (
  SELECT
    col0,
    CAST(col1 AS INTEGER) AS col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    CAST(substr(col2, 1, instr(col2, '-') - 1) AS INTEGER) AS wins,
    CAST(substr(col2, instr(col2, '-') + 1) AS INTEGER) AS losses,
    CASE
      WHEN instr(col6, '(') > 0 THEN TRIM(substr(col6, 1, instr(col6, '(') - 1))
      ELSE TRIM(col6)
    END AS leading_goalkicker_name,
    CASE
      WHEN instr(col6, '(') > 0 THEN CAST(substr(col6, instr(col6, '(') + 1, instr(col6, ')') - instr(col6, '(') - 1) AS INTEGER)
      ELSE NULL
    END AS leading_goals
  FROM table_1_1165048_1
)
SELECT
  p.col0,
  p.col1,
  (p.col1 - LAG(p.col1) OVER (ORDER BY p.col0)) AS position_change_from_prev,
  p.col2,
  p.wins,
  p.losses,
  p.col3,
  (SELECT COUNT(*) FROM parsed p2 WHERE p2.col3 = p.col3) AS coach_total_seasons,
  (SELECT ROUND(AVG(p2.col1), 2) FROM parsed p2 WHERE p2.col3 = p.col3) AS coach_avg_position,
  (SELECT ROUND(AVG(p2.wins), 2) FROM parsed p2 WHERE p2.col3 = p.col3) AS coach_avg_wins,
  CASE WHEN p.col3 != LAG(p.col3) OVER (ORDER BY p.col0) THEN 1 ELSE 0 END AS coach_changed_since_prev_season,
  p.col4,
  (SELECT COUNT(*) FROM parsed p3 WHERE p3.col4 = p.col4) AS captain_total_seasons,
  (SELECT ROUND(AVG(p3.col1), 2) FROM parsed p3 WHERE p3.col4 = p.col4) AS captain_avg_position,
  (SELECT ROUND(AVG(p3.wins), 2) FROM parsed p3 WHERE p3.col4 = p.col4) AS captain_avg_wins,
  CASE WHEN p.col4 != LAG(p.col4) OVER (ORDER BY p.col0) THEN 1 ELSE 0 END AS captain_changed_since_prev_season,
  p.col5,
  p.col6,
  p.leading_goalkicker_name,
  p.leading_goals,
  DENSE_RANK() OVER (ORDER BY p.leading_goals DESC) AS leading_goals_rank,
  CASE WHEN p.leading_goals >= (SELECT ROUND(AVG(leading_goals), 2) FROM parsed) THEN 1 ELSE 0 END AS leading_goals_above_overall_avg
FROM parsed p
ORDER BY p.col0 ASC;","[(1997.0, 9, None, '1-19', 1, 19, 'geoff miles', 1, 9.0, 1.0, 0, 'phil gilbert', 2, 9.0, 1.0, 0, 'scott simister', 'scott simister (27)', 'scott simister', 27, 13, 0), (1998.0, 9, 0, '1-19', 1, 19, 'geoff miles troy wilson', 1, 9.0, 1.0, 1, 'phil gilbert', 2, 9.0, 1.0, 0, 'darren bolton', 'scott simister (31)', 'scott simister', 31, 10, 0), (1999.0, 9, 0, '0-20', 0, 20, 'troy wilson', 1, 9.0, 0.0, 1, 'scott simister', 1, 9.0, 0.0, 1, 'scott simister', 'scott simister (54)', 'scott simister', 54, 2, 1), (2000.0, 8, -1, '4-14', 4, 14, 'shane cable', 2, 7.0, 5.5, 1, 'bill monaghan', 1, 8.0, 4.0, 1, 'vance davison', 'dean buszan (32)', 'dean buszan', 32, 9, 0), (2001.0, 6, -2, '7-11', 7, 11, 'shane cable', 2, 7.0, 5.5, 0, 'vance davison', 1, 6.0, 7.0, 1, 'derek hall', 'david mcpharlin (25)', 'david mcpharlin', 25, 14, 0), (2002.0, 8, 2, '7-11', 7, 11, 'peter german', 1, 8.0, 7.0, 1, 'derek hall', 2, 8.5, 4.0, 1, 'darren bolton', 'scott simister (46)', 'scott simister', 46, 4, 1), (2003.0, 9, 1, '1-19', 1, 19, 'john ditchburn', 1, 9.0, 1.0, 1, 'derek hall', 2, 8.5, 4.0, 0, 'derek hall', 'derek hall (22)', 'derek hall', 22, 15, 0), (2004.0, 8, -1, '5-15', 5, 15, 'garry hocking', 2, 8.5, 4.0, 1, 'brandon hill', 1, 8.0, 5.0, 1, 'daniel haines', 'cameron gauci (40)', 'cameron gauci', 40, 6, 1), (2005.0, 9, 1, '3-17', 3, 17, 'garry hocking', 2, 8.5, 4.0, 0, 'grant welsh', 4, 7.75, 5.5, 1, 'pat travers', 'justin wood (29)', 'justin wood', 29, 12, 0), (2006.0, 8, -1, '6-14', 6, 14, 'chris waterman', 4, 7.75, 6.0, 1, 'grant welsh', 4, 7.75, 5.5, 0, ""rory o'brien"", 'dean buszan (44)', 'dean buszan', 44, 5, 1), (2007.0, 8, 0, '5-15', 5, 15, 'chris waterman', 4, 7.75, 6.0, 0, 'grant welsh', 4, 7.75, 5.5, 0, 'daniel haines', 'dean buszan (30)', 'dean buszan', 30, 11, 0), (2008.0, 6, -2, '8-12', 8, 12, 'chris waterman', 4, 7.75, 6.0, 0, 'grant welsh', 4, 7.75, 5.5, 0, 'hayden ballantyne', 'hayden ballantyne (75)', 'hayden ballantyne', 75, 1, 1), (2009.0, 9, 3, '5-15', 5, 15, 'chris waterman', 4, 7.75, 6.0, 0, 'daniel haines', 1, 9.0, 5.0, 1, 'ben howlett', 'kain robins (33)', 'kain robins', 33, 8, 0), (2010.0, 8, -1, '3-17', 3, 17, 'trevor williams', 2, 8.5, 4.0, 1, 'daniel haines brendon jones', 1, 8.0, 3.0, 1, ""rory o'brien"", 'matthew battye (27)', 'matthew battye', 27, 13, 0), (2011.0, 9, 1, '5-15', 5, 15, 'trevor williams', 2, 8.5, 4.0, 0, 'brendon jones', 2, 9.0, 5.0, 1, 'kristin thornton', 'bradley holmes (36)', 'bradley holmes', 36, 7, 0), (2012.0, 9, 0, '5-15', 5, 15, 'trevor williams mark moody', 1, 9.0, 5.0, 1, 'brendon jones', 2, 9.0, 5.0, 0, 'brendon jones', 'bradley holmes (52)', 'bradley holmes', 52, 3, 1)]",table_1_1165048_1,"STEP 1: Parse the SQL intent — The query parses each season row to extract numeric Position, wins/losses, leading goalkicker name and goals; computes per-coach and per-captain aggregates (total seasons, average position, average wins); computes overall average leading goals; and outputs per-season details including position change from previous season, flags if coach/captain changed since previous season, leading goalkicker rank and whether leading goals are above overall average. STEP 2: Determine ambiguity type — Attachment ambiguity fits well: the phrase 'after a coach change' can attach to different notions (the season immediately following a change vs the season that is the coach's first overall), and additionally the word 'improvement' can attach to different metrics (position vs wins vs coach-average). STEP 3: Draft the question — ""Which seasons showed improvement after a coach change?"" STEP 4: Explain the ambiguity — In the original query 'coach change' is encoded both as a per-season flag (coach_changed_since_prev_season = 1) and as a coach-level count (coach_total_seasons), and 'improvement' could be measured by position_change_from_prev, by wins compared to previous seasons, or by comparing the season to the coach's average; the SQL provides columns to answer any of these interpretations but the natural language question does not specify which attachment or metric is intended.",persona,"Club Performance Analyst for Peel Thunder Football Club with a background in sports analytics and historical record-keeping; they use the honour board data to evaluate year-to-year team performance, coach/captain impacts, and goal-scoring trends. Goals: Track season-by-season performance (position and win/loss) to identify improvement or decline trends. Assess the impact and tenure of coaches and captains on team results. Identify the club's leading goalkickers across seasons and compare their goal tallies to spot standout scoring years. Example Queries: /* 1) Get the season-by-season summary to visualize trends */
SELECT ""Season"", ""Position"", ""Win/Loss"", ""Coach"", ""Captain"", ""Leading goalkicker""
FROM table_1_1165048_1
ORDER BY ""Season"" ASC; /* 2) Basic season performance aggregates: average/ best/ worst ladder position and the seasons they occurred */
SELECT
  ROUND(AVG(CAST(""Position"" AS NUMERIC)), 2) AS avg_position,
  MIN(CAST(""Position"" AS INTEGER)) AS best_position,
  MAX(CAST(""Position"" AS INTEGER)) AS worst_position
FROM table_1_1165048_1; /* 3) Extract leading goalkicker name and goals, then list top scoring seasons (PostgreSQL-style regex used to split name and number) */
SELECT
  TRIM(regexp_replace(""Leading goalkicker"", '\\s*\\([0-9]+\\)\\s*$', '')) AS goalkicker_name,
  CAST(regexp_replace(""Leading goalkicker"", '^.*\\(([0-9]+)\\)$', '\\1') AS INTEGER) AS goals,
  ""Season""
FROM table_1_1165048_1
WHERE ""Leading goalkicker"" IS NOT NULL
ORDER BY goals DESC, ""Season"" ASC;",reward,,"type: Attachment ambiguity | explanation: The phrase 'after a coach change' can attach to (a) the immediate-season flag where the coach differs from the previous season (coach_changed_since_prev_season = 1) or (b) seasons that are a coach's first season overall (coach_total_seasons = 1); 'showed improvement' is also ambiguous (position_change_from_prev, more wins than before, or better than the coach's average), and the SQL contains data to support multiple interpretations."
"List Abbrev (Abbreviation), Voivodeship, Population_density defined as (REPLACE Population (1980) spaces removed and converted to number) / (REPLACE Area km² (1998) spaces removed and converted to number), No. of cities, No. of communes, and Cities_per_commune = No. of cities * 1.0 / No. of communes for voivodeships whose Population (1980) is between 400000 and 1400000 and that have between 10 and 40 other voivodeships with a smaller Population (1980); order by Population_density descending and return the first 10?","
SELECT
  t1.`Abbreviation` AS `Abbrev`,
  t1.`Voivodeship`,
  (REPLACE(t1.`Population (1980)`, ' ', '')+0) / (REPLACE(t1.`Area km² (1998)`, ' ', '')+0) AS `Population_density`,
  t1.`No. of cities`,
  t1.`No. of communes`,
  (t1.`No. of cities`*1.0 / t1.`No. of communes`) AS `Cities_per_commune`
FROM `table_1_11656578_2` AS t1
JOIN `table_1_11656578_2` AS t2 ON (REPLACE(t2.`Population (1980)`, ' ', '')+0) < (REPLACE(t1.`Population (1980)`, ' ', '')+0)
WHERE (REPLACE(t1.`Population (1980)`, ' ', '')+0) BETWEEN 400000 AND 1400000
GROUP BY t1.`Abbreviation`
HAVING COUNT(t2.`Abbreviation`) BETWEEN 10 AND 40
ORDER BY `Population_density` DESC
LIMIT 10;
","
SELECT
  t1.col0 AS `Abbrev`,
  t1.col1,
  (REPLACE(t1.col4, ' ', '')+0) / (REPLACE(t1.col3, ' ', '')+0) AS `Population_density`,
  t1.col5,
  t1.col6,
  (t1.col5*1.0 / t1.col6) AS `Cities_per_commune`
FROM `table_1_11656578_2` AS t1
JOIN `table_1_11656578_2` AS t2 ON (REPLACE(t2.col4, ' ', '')+0) < (REPLACE(t1.col4, ' ', '')+0)
WHERE (REPLACE(t1.col4, ' ', '')+0) BETWEEN 400000 AND 1400000
GROUP BY t1.col0
HAVING COUNT(t2.col0) BETWEEN 10 AND 40
ORDER BY `Population_density` DESC
LIMIT 10;
","[('bb', 'bielsko-biała voivodeship', 224, 18.0, 47.0, 0.3829787234042553), ('wb', 'wałbrzych voivodeship', 171, 31.0, 30.0, 1.0333333333333334), ('rz', 'rzeszów voivodeship', 147, 13.0, 41.0, 0.3170731707317073), ('ta', 'tarnów voivodeship', 146, 9.0, 41.0, 0.21951219512195122), ('lu', 'lublin voivodeship', 137, 16.0, 62.0, 0.25806451612903225), ('cz', 'częstochowa voivodeship', 120, 17.0, 49.0, 0.3469387755102041), ('ki', 'kielce voivodeship', 116, 17.0, 69.0, 0.2463768115942029), ('to', 'toruń voivodeship', 114, 13.0, 41.0, 0.3170731707317073), ('op', 'opole voivodeship', 114, 29.0, 61.0, 0.47540983606557374), ('lg', 'legnica voivodeship', 113, 11.0, 31.0, 0.3548387096774194)]",table_1_11656578_2,"1) The query finds voivodeships within a population range, computes density and city/commune ratio, filters by how many voivodeships have smaller populations, and returns the top 10 by density. 2) Map fields and computations exactly: Abbreviation as Abbrev, Voivodeship, numeric Population and Area after removing spaces for Population_density, No. of cities, No. of communes, and Cities_per_commune as a float ratio. 3) Draft a concise question that includes the BETWEEN 400000 AND 1400000 condition, the requirement that COUNT(smaller populations) is BETWEEN 10 AND 40, ordering by Population_density DESC, and LIMIT 10. 4) Validate inclusion of all columns, calculations, filters, ordering and limit in the question.",reserved,21,reward,,
"For each state, show the number of member schools, total and average enrollment, the largest and smallest enrollments and which schools those are, list schools that joined since 2000 (with year), how many joined in/after 2011, and the most recent join year?","
WITH `parsed` AS (
  SELECT
    `Institution`,
    `Location`,
    TRIM(SUBSTR(`Location`, INSTR(`Location`, ',') + 1)) AS `State`,
    `Founded`,
    `Type`,
    `Enrollment`,
    `Joined`,
    CAST(SUBSTR(`Joined`, 1, 4) AS INTEGER) AS `JoinedYear`
  FROM `table_1_11658094_1`
)
SELECT
  `State`,
  COUNT(*) AS `school_count`,
  SUM(`Enrollment`) AS `total_enrollment`,
  ROUND(AVG(`Enrollment`), 1) AS `avg_enrollment`,
  MAX(`Enrollment`) AS `max_enrollment`,
  MIN(`Enrollment`) AS `min_enrollment`,
  (SELECT GROUP_CONCAT(`Institution`, '; ') FROM `parsed` p2 WHERE p2.`State` = p1.`State` AND p2.`Enrollment` = (SELECT MAX(`Enrollment`) FROM `parsed` p3 WHERE p3.`State` = p1.`State`)) AS `largest_institutions`,
  (SELECT GROUP_CONCAT(`Institution`, '; ') FROM `parsed` p2 WHERE p2.`State` = p1.`State` AND p2.`Enrollment` = (SELECT MIN(`Enrollment`) FROM `parsed` p3 WHERE p3.`State` = p1.`State`)) AS `smallest_institutions`,
  (SELECT GROUP_CONCAT(`Institution` || ' (' || `JoinedYear` || ')', '; ') FROM `parsed` p2 WHERE p2.`State` = p1.`State` AND p2.`JoinedYear` >= 2000) AS `joined_since_2000`,
  SUM(CASE WHEN `JoinedYear` >= 2011 THEN 1 ELSE 0 END) AS `joined_>=2011_count`,
  MAX(`JoinedYear`) AS `most_recent_join_year`
FROM `parsed` p1
GROUP BY `State`
ORDER BY `school_count` DESC, `total_enrollment` DESC;
","
WITH `parsed` AS (
  SELECT
    col0,
    col1,
    TRIM(SUBSTR(col1, INSTR(col1, ',') + 1)) AS `State`,
    col2,
    col3,
    col4,
    col5,
    CAST(SUBSTR(col5, 1, 4) AS INTEGER) AS `JoinedYear`
  FROM `table_1_11658094_1`
)
SELECT
  `State`,
  COUNT(*) AS `school_count`,
  SUM(col4) AS `total_enrollment`,
  ROUND(AVG(col4), 1) AS `avg_enrollment`,
  MAX(col4) AS `max_enrollment`,
  MIN(col4) AS `min_enrollment`,
  (SELECT GROUP_CONCAT(col0, '; ') FROM `parsed` p2 WHERE p2.`State` = p1.`State` AND p2.col4 = (SELECT MAX(col4) FROM `parsed` p3 WHERE p3.`State` = p1.`State`)) AS `largest_institutions`,
  (SELECT GROUP_CONCAT(col0, '; ') FROM `parsed` p2 WHERE p2.`State` = p1.`State` AND p2.col4 = (SELECT MIN(col4) FROM `parsed` p3 WHERE p3.`State` = p1.`State`)) AS `smallest_institutions`,
  (SELECT GROUP_CONCAT(col0 || ' (' || `JoinedYear` || ')', '; ') FROM `parsed` p2 WHERE p2.`State` = p1.`State` AND p2.`JoinedYear` >= 2000) AS `joined_since_2000`,
  SUM(CASE WHEN `JoinedYear` >= 2011 THEN 1 ELSE 0 END) AS `joined_>=2011_count`,
  MAX(`JoinedYear`) AS `most_recent_join_year`
FROM `parsed` p1
GROUP BY `State`
ORDER BY `school_count` DESC, `total_enrollment` DESC;
","[('south carolina', 4, 7070.0, 1767.5, 3300.0, 750.0, 'limestone college', 'converse college 2', 'converse college 2 (2008); north greenville university (2011)', 1, 2011), ('north carolina', 4, 5820.0, 1455.0, 2500.0, 800.0, 'mount olive college', 'lees–mcrae college', None, 0, 1993), ('tennessee', 1, 1800.0, 1800.0, 1800.0, 1800.0, 'king university', 'king university', 'king university (2011)', 1, 2011)]",table_1_11658094_1,"As the travel and scheduling coordinator I think in terms of states, counts, enrollments and membership years and I use labels like 'enrollment' and 'joined'. The query aggregates membership data by state to produce counts, enrollment sums/averages/min/max, lists of largest/smallest schools, schools joined since 2000, counts of recent joins, and the most recent join year. It extracts the state from Location, uses Enrollment for size metrics, Institution for names, and parses Joined to a JoinedYear. For each state, show the number of member schools, total and average enrollment, the largest and smallest enrollments and which schools those are, schools that joined since 2000 (with join year), how many joined in/after 2011, and the most recent join year? This matches the query's per-state aggregates and institution lists.",persona,"Conference travel & scheduling coordinator for Conference Carolinas who plans team travel, game sites, and event logistics; uses this membership table to cluster opponents, estimate travel and attendance needs, and flag new members. They need quick lists by state, by enrollment size, and by membership tenure. Goals: Group member institutions by state to plan regional scheduling clusters and reduce travel costs. Identify the largest and smallest member schools by enrollment to allocate bus size, lodging and game-day resources. Find recently joined institutions (new members) to coordinate onboarding, revise scheduling, and update contact lists. Example Queries: /* Count member schools by state (extract state from Location) */
SELECT TRIM(SUBSTR(Location, INSTR(Location, ',') + 1)) AS State,
       COUNT(*) AS school_count
FROM table_1_11658094_1
GROUP BY State
ORDER BY school_count DESC; /* Top 5 member institutions by enrollment to prioritize resource planning */
SELECT Institution, Enrollment, Location
FROM table_1_11658094_1
ORDER BY Enrollment DESC
LIMIT 5; /* List institutions that joined in or after 2000 (handles Joined like '2011' or '1930 1' by taking first 4 chars) */
SELECT Institution, Joined
FROM table_1_11658094_1
WHERE CAST(SUBSTR(Joined, 1, 4) AS INTEGER) >= 2000
ORDER BY CAST(SUBSTR(Joined, 1, 4) AS INTEGER);",reward,,
"Which institutions (showing Institution, Location, Type, Enrollment) that have Enrollment above 2000 and Left no earlier than 1975 have Membership Years equal to Left - Joined, Enrollment per Year equal to Enrollment divided by (Left - Joined) rounded to two decimal places, and what is their Current Conference?","
SELECT `Institution`, `Location`, `Type`, `Enrollment`, `Left` - `Joined` `Membership Years`, ROUND(`Enrollment`/(`Left` - `Joined`),2) `Enrollment per Year`, `Current Conference`
FROM `table_1_11658094_3`
WHERE `Enrollment` > 2000 AND `Left` >= 1975;
","
SELECT col0, col1, col3, col4, col7 - col6 `Membership Years`, ROUND(col4/(col7 - col6),2) `Enrollment per Year`, col8
FROM `table_1_11658094_3`
WHERE col4 > 2000 AND col7 >= 1975;
","[('anderson university', 'anderson, south carolina', 'private', 2907.0, 12.0, 242.25, 'sac'), ('elon university', 'elon, north carolina', 'private', 6720.0, 45.0, 149.33, 'socon ( caa in 2014) (ncaa division i)'), ('guilford college', 'greensboro, north carolina', 'private', 2706.0, 58.0, 46.66, 'odac (ncaa division iii)'), ('high point university', 'high point, north carolina', 'private', 4519.0, 67.0, 67.45, 'big south (ncaa division i)'), ('longwood university', 'farmville, virginia', 'public', 4800.0, 8.0, 600.0, 'big south (ncaa division i)'), ('university of north carolina at pembroke', 'pembroke, north carolina', 'public', 6433.0, 16.0, 402.06, 'peach belt (pbc)'), ('queens university of charlotte', 'charlotte, north carolina', 'private', 2386.0, 18.0, 132.56, 'sac'), ('western carolina university', 'cullowhee, north carolina', 'public', 9608.0, 42.0, 228.76, 'socon (ncaa division i)')]",table_1_11658094_3,"Parse intent: select Institution, Location, Type, Enrollment, compute Left-Joined as Membership Years and Enrollment/(Left-Joined) rounded to 2 decimals, include Current Conference, filter Enrollment > 2000 and Left >= 1975. Map schema: use the Former members table fields Institution, Location, Type, Enrollment, Joined, Left, Current Conference. Draft question: ask which institutions meeting the filters should return those columns and computed values. Validate: ensure the phrasing requests the exact calculations, rounding to two decimals, and both filter predicates.",reserved,4,reward,,
"For each team appearing in the Champion, Runner-up, or Third place columns, what are the total number of times they were Champion (Champions), Runner-up (Runners), and Third place (Thirds), and what is their Weighted Score calculated as (Champions * 3 + Runners * 2 + Thirds), including only teams with at least one top-three finish and ordered by Weighted Score descending?","
WITH `unpivot` AS (
SELECT `Champion` `Team`, 1 `ChampionCount`, 0 `RunnerCount`, 0 `ThirdCount` FROM `table_1_1167698_1`
UNION ALL
SELECT `Runner-up`, 0, 1, 0 FROM `table_1_1167698_1`
UNION ALL
SELECT `Third place`, 0, 0, 1 FROM `table_1_1167698_1`
)
SELECT `Team`, SUM(`ChampionCount`) `Champions`, SUM(`RunnerCount`) `Runners`, SUM(`ThirdCount`) `Thirds`, (SUM(`ChampionCount`)*3 + SUM(`RunnerCount`)*2 + SUM(`ThirdCount`)) `Weighted Score`
FROM `unpivot`
GROUP BY `Team`
HAVING SUM(`ChampionCount`) + SUM(`RunnerCount`) + SUM(`ThirdCount`) > 0
ORDER BY `Weighted Score` DESC;
","
WITH `unpivot` AS (
SELECT col1 `Team`, 1 `ChampionCount`, 0 `RunnerCount`, 0 `ThirdCount` FROM `table_1_1167698_1`
UNION ALL
SELECT col2, 0, 1, 0 FROM `table_1_1167698_1`
UNION ALL
SELECT col3, 0, 0, 1 FROM `table_1_1167698_1`
)
SELECT `Team`, SUM(`ChampionCount`) `Champions`, SUM(`RunnerCount`) `Runners`, SUM(`ThirdCount`) `Thirds`, (SUM(`ChampionCount`)*3 + SUM(`RunnerCount`)*2 + SUM(`ThirdCount`)) `Weighted Score`
FROM `unpivot`
GROUP BY `Team`
HAVING SUM(`ChampionCount`) + SUM(`RunnerCount`) + SUM(`ThirdCount`) > 0
ORDER BY `Weighted Score` DESC;
","[('lokomotiv moscow', 0, 4, 4, 12), ('cska moscow', 1, 3, 1, 10), ('spartak moscow', 0, 3, 1, 7), ('rubin kazan', 1, 0, 2, 5), ('alania vladikavkaz', 1, 1, 0, 5), ('zenit saint petersburg', 0, 1, 2, 4), ('dynamo moscow', 0, 1, 2, 4), ('zenit saint petersburg (2)', 1, 0, 0, 3), ('spartak moscow (9)', 1, 0, 0, 3), ('spartak moscow (8)', 1, 0, 0, 3), ('spartak moscow (7)', 1, 0, 0, 3), ('spartak moscow (6)', 1, 0, 0, 3), ('spartak moscow (5)', 1, 0, 0, 3), ('spartak moscow (4)', 1, 0, 0, 3), ('spartak moscow (3)', 1, 0, 0, 3), ('rubin kazan (2)', 1, 0, 0, 3), ('rotor volgograd', 0, 1, 1, 3), ('cska moscow (3)', 1, 0, 0, 3), ('cska moscow (2)', 1, 0, 0, 3), ('torpedo moscow', 0, 0, 1, 1)]",table_1_1167698_1,"1) Parse intent: unpivot Champion, Runner-up, Third place into team rows, count occurrences, sum counts by team, compute Weighted Score = 3*Champions + 2*Runners + Thirds, filter teams with at least one appearance and sort descending. 2) Map schema: Champion, Runner-up, Third place are team name columns; output columns are Team, Champions, Runners, Thirds, Weighted Score. 3) Draft: ask for per-team counts and weighted score with the specified calculation and ordering. 4) Validate: includes all columns, calculation, filter, and ordering from the query.",reserved,20,reward,,
"List each Hometown with the number of Players (as Players) and the semicolon-separated Player name list (GROUP_CONCAT(Player, '; ')) for rows where MLB Draft contains '1st Round' or 'Attended' and where Player != '`Taylor Hawkins`' or Player = '`Gavin Cecchini`', grouped by Hometown, ordered by the Players count descending, returning only the top 10 rows.","
SELECT `Hometown` AS `Hometown`, COUNT(*) AS `Players`, GROUP_CONCAT(`Player`, '; ')
FROM `table_1_11677100_18`
WHERE (`MLB Draft` LIKE '%1st Round%' OR `MLB Draft` LIKE '%Attended%') AND (`Player` != '`Taylor Hawkins`' OR `Player` = '`Gavin Cecchini`')
GROUP BY `Hometown`
ORDER BY COUNT(*) DESC
LIMIT 10;
","
SELECT col3 AS col3, COUNT(*) AS `Players`, GROUP_CONCAT(col0, '; ')
FROM `table_1_11677100_18`
WHERE (col4 LIKE '%1st Round%' OR col4 LIKE '%Attended%') AND (col0 != '`Taylor Hawkins`' OR col0 = '`Gavin Cecchini`')
GROUP BY col3
ORDER BY COUNT(*) DESC
LIMIT 10;
","[('midwest city, ok', 1, 'taylor hawkins'), ('lake charles, la', 1, 'gavin cecchini'), ('irvine, ca', 1, 'james kaprelian'), ('baxley, ga', 1, 'byron buxton')]",table_1_11677100_18,"Parse SQL intent: aggregate players by hometown for entries with MLB Draft indicating first-round selection or 'Attended', apply the given player inclusion/exclusion logic, then return top ten hometowns by player count. Map schema semantics: Hometown is selected, COUNT(*) yields Players, GROUP_CONCAT(Player, '; ') provides the concatenated names, and MLB Draft is filtered with LIKE patterns; the Player condition uses inequality to '`Taylor Hawkins`' or equality to '`Gavin Cecchini`'. Draft the question: ask for Hometown, Players, and semicolon-delimited Player names with those exact filters and sorting/limit. Validate: all SQL elements (columns, concatenation, both LIKE filters, the Player comparison clause, GROUP BY, ORDER BY COUNT DESC, LIMIT 10) are included.",reserved,14,reward,,
"Give me the 1995 All‑USA players that match any inscription detail I supply (school, hometown, draft text), including their draft round, pick and team and the number of inscription matches, sorted by best matches then draft value?","
WITH parsed AS (
  SELECT
    `Player`,
    `Position`,
    `School`,
    `Hometown`,
    `MLB Draft`,
    CASE
      WHEN instr(`MLB Draft`, ' Round') > 0
      THEN CAST(
        replace(
          replace(
            replace(
              replace(
                substr(`MLB Draft`, 1, instr(`MLB Draft`, ' Round') - 1),
              'st',''),
            'nd',''),
          'rd',''),
        'th','') AS INTEGER)
    END AS `Draft Round`,
    CASE
      WHEN instr(`MLB Draft`, ' - ') > 0 AND instr(`MLB Draft`, ' Pick') > 0
      THEN CAST(
        replace(
          replace(
            replace(
              replace(
                substr(
                  `MLB Draft`,
                  instr(`MLB Draft`, ' - ') + 3,
                  instr(`MLB Draft`, ' Pick') - (instr(`MLB Draft`, ' - ') + 3)
                ),
              'st',''),
            'nd',''),
          'rd',''),
        'th','') AS INTEGER)
    END AS `Draft Pick`,
    CASE
      WHEN instr(`MLB Draft`, '(') > 0 AND instr(`MLB Draft`, ')') > instr(`MLB Draft`, '(')
      THEN trim(substr(`MLB Draft`, instr(`MLB Draft`, '(') + 1, instr(`MLB Draft`, ')') - instr(`MLB Draft`, '(') - 1))
    END AS `Draft Team`
  FROM `table_1_11677100_3`
)
SELECT
  `Player`,
  `Position`,
  `School`,
  `Hometown`,
  `MLB Draft`,
  `Draft Round`,
  `Draft Pick`,
  `Draft Team`,
  CASE
    WHEN `Draft Round` IS NULL THEN 10000
    ELSE (`Draft Round` * 100 + COALESCE(`Draft Pick`, 999))
  END AS `Valuation_Score`,
  CASE WHEN :ins_school IS NOT NULL AND `School` = :ins_school THEN 1 ELSE 0 END AS `Match_School`,
  CASE WHEN :ins_hometown IS NOT NULL AND `Hometown` = :ins_hometown THEN 1 ELSE 0 END AS `Match_Hometown`,
  CASE WHEN :ins_draft_text IS NOT NULL AND `MLB Draft` LIKE ('%' || :ins_draft_text || '%') THEN 1 ELSE 0 END AS `Match_Draft`,
  (CASE WHEN :ins_school IS NOT NULL AND `School` = :ins_school THEN 1 ELSE 0 END) +
  (CASE WHEN :ins_hometown IS NOT NULL AND `Hometown` = :ins_hometown THEN 1 ELSE 0 END) +
  (CASE WHEN :ins_draft_text IS NOT NULL AND `MLB Draft` LIKE ('%' || :ins_draft_text || '%') THEN 1 ELSE 0 END) AS `Total_Matches`
FROM parsed
WHERE
  (:ins_school IS NULL OR `School` = :ins_school)
  OR (:ins_hometown IS NULL OR `Hometown` = :ins_hometown)
  OR (:ins_draft_text IS NULL OR `MLB Draft` LIKE ('%' || :ins_draft_text || '%'))
ORDER BY `Total_Matches` DESC, `Valuation_Score` ASC, `Player` ASC;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    CASE
      WHEN instr(col4, ' Round') > 0
      THEN CAST(
        replace(
          replace(
            replace(
              replace(
                substr(col4, 1, instr(col4, ' Round') - 1),
              'st',''),
            'nd',''),
          'rd',''),
        'th','') AS INTEGER)
    END AS `Draft Round`,
    CASE
      WHEN instr(col4, ' - ') > 0 AND instr(col4, ' Pick') > 0
      THEN CAST(
        replace(
          replace(
            replace(
              replace(
                substr(
                  col4,
                  instr(col4, ' - ') + 3,
                  instr(col4, ' Pick') - (instr(col4, ' - ') + 3)
                ),
              'st',''),
            'nd',''),
          'rd',''),
        'th','') AS INTEGER)
    END AS `Draft Pick`,
    CASE
      WHEN instr(col4, '(') > 0 AND instr(col4, ')') > instr(col4, '(')
      THEN trim(substr(col4, instr(col4, '(') + 1, instr(col4, ')') - instr(col4, '(') - 1))
    END AS `Draft Team`
  FROM `table_1_11677100_3`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  `Draft Round`,
  `Draft Pick`,
  `Draft Team`,
  CASE
    WHEN `Draft Round` IS NULL THEN 10000
    ELSE (`Draft Round` * 100 + COALESCE(`Draft Pick`, 999))
  END AS `Valuation_Score`,
  CASE WHEN NULL IS NOT NULL AND col2 = NULL THEN 1 ELSE 0 END AS `Match_School`,
  CASE WHEN NULL IS NOT NULL AND col3 = NULL THEN 1 ELSE 0 END AS `Match_Hometown`,
  CASE WHEN NULL IS NOT NULL AND col4 LIKE ('%' || NULL || '%') THEN 1 ELSE 0 END AS `Match_Draft`,
  (CASE WHEN NULL IS NOT NULL AND col2 = NULL THEN 1 ELSE 0 END) +
  (CASE WHEN NULL IS NOT NULL AND col3 = NULL THEN 1 ELSE 0 END) +
  (CASE WHEN NULL IS NOT NULL AND col4 LIKE ('%' || NULL || '%') THEN 1 ELSE 0 END) AS `Total_Matches`
FROM parsed
WHERE
  (NULL IS NULL OR col2 = NULL)
  OR (NULL IS NULL OR col3 = NULL)
  OR (NULL IS NULL OR col4 LIKE ('%' || NULL || '%'))
ORDER BY `Total_Matches` DESC, `Valuation_Score` ASC, col0 ASC;","[('ben davis', 'catcher', 'malvern prep', 'malvern, pa', '1st round - 2nd pick of 1995 draft ( padres )', None, None, 'padres', 10000, 0, 0, 0, 0), ('chad hermansen', 'infielder', 'green valley high school', 'henderson, nv', '1st round - 10th pick of 1995 draft ( pirates )', None, None, 'pirates', 10000, 0, 0, 0, 0), ('chad hutchinson', 'pitcher', 'torrey pines high school', 'san diego, ca', 'attended stanford *', None, None, None, 10000, 0, 0, 0, 0), ('jay hood', 'infielder', 'germantown high school', 'germantown, tn', 'attended georgia tech *', None, None, None, 10000, 0, 0, 0, 0), ('kerry wood', 'pitcher', 'grand prairie high school', 'grand prairie, tx', '1st round - 4th pick of 1995 draft ( cubs )', None, None, 'cubs', 10000, 0, 0, 0, 0), ('michael barrett', 'infielder', 'pace academy', 'atlanta, ga', '1st round - 28th pick of 1995 draft ( expos )', None, None, 'expos', 10000, 0, 0, 0, 0), ('nate rolison', 'infielder', 'petal high school', 'petal, ms', '2nd round - 36th pick of 1995 draft ( marlins )', None, None, 'marlins', 10000, 0, 0, 0, 0), ('reggie taylor', 'outfielder', 'newberry high school', 'newberry, sc', '1st round - 14th pick of 1995 draft ( phillies )', None, None, 'phillies', 10000, 0, 0, 0, 0), ('shion newton', 'outfielder', 'boys and girls high school', 'brooklyn, ny', '9th round - 6th pick of 1995 draft ( pirates )', None, None, 'pirates', 10000, 0, 0, 0, 0)]",table_1_11677100_3,"I would want a concise provenance list showing parsed draft details alongside match flags so I can prioritize items; I'd express that as 'show round/pick/team and matches' rather than SQL terms. The SQL parses MLB Draft into round, pick and team, computes a valuation score, sets flags for school/hometown/draft text matches, filters to any matching rows, and orders by total matches then valuation then player. The schema provides Player, Position, School, Hometown and MLB Draft for the 1995 team. Give me the 1995 All‑USA players that match any inscription detail I supply (school, hometown, draft text), and include their draft round, pick and team plus how many inscription fields matched, sorted by best matches then draft value. This directly mirrors the columns selected, computed fields and ordering in the query.",persona,"```json
{
  ""short_persona_description"": ""A forensic sports-memorabilia investigator who authenticates signed 1990s baseball items by cross-referencing USA Today All‑USA high school listings, draft outcomes, schools and hometowns to establish provenance."",
  ""goals"": [
    ""Verify the authenticity and likely provenance of signed memorabilia by matching inscriptions (school, hometown, draft year/pick) against the 1995 All‑USA roster."",
    ""Prioritize items for valuation by identifying which high Goals:  Example Queries: ",reward,,
"Grouped by Position, what is the Position, the Total Players (COUNT of rows), the Players as a single string of Player names separated by ', ', and the Drafts as a single string of MLB Draft entries separated by ' | ', only for groups with at least one player, ordered by Total Players descending and showing up to 10 groups?","
SELECT DISTINCT `Position`, COUNT(*) `Total Players`, GROUP_CONCAT(`Player`, ', ') `Players`, GROUP_CONCAT(`MLB Draft`, ' | ') AS `Drafts`
FROM table_1_11677100_4
GROUP BY `Position`
HAVING COUNT(*) >= 1
ORDER BY `Total Players` DESC
LIMIT 10;
","
SELECT DISTINCT col1, COUNT(*) `Total Players`, GROUP_CONCAT(col0, ', ') `Players`, GROUP_CONCAT(col4, ' | ') AS `Drafts`
FROM table_1_11677100_4
GROUP BY col1
HAVING COUNT(*) >= 1
ORDER BY `Total Players` DESC
LIMIT 10;
","[('infielder', 4, 'drew henson, sean burroughs, felipe lópez, mark teixeira', '3rd round - 97th pick of 1998 draft ( yankees ) * | 1st round - 9th pick of 1998 draft ( padres ) | 1st round - 8th pick of 1998 draft ( blue jays ) | attended georgia tech *'), ('pitcher', 2, 'josh beckett, j. m. gold', 'beckett was a junior in the 1998 season. | 1st round - 13th pick of 1998 draft ( brewers )'), ('outfielder', 1, 'chip ambres', '1st round - 27th pick of 1998 draft ( marlins )'), ('catcher', 1, 'gerald laird', ""2nd round - 45th pick of 1998 draft ( a's )"")]",table_1_11677100_4,"Parse intent: aggregate by Position with count and two concatenations, apply HAVING count >= 1, sort by count descending, cap at 10. Map schema: use Position, COUNT(*) labeled Total Players, GROUP_CONCAT(Player, ', ') labeled Players, GROUP_CONCAT(MLB Draft, ' | ') labeled Drafts. Draft: pose a question asking explicitly for those aggregated columns and constraints. Validate: confirm inclusion of separators (', ' and ' | '), HAVING, ORDER BY Total Players DESC, and LIMIT 10.",reserved,9,reward,,
Which positions have the most players who attended college?,"
SELECT `Position`, COUNT(*) AS `TotalPlayers`, SUM(`MLB Draft` LIKE 'Attended%') `AttendedCount`
FROM `table_1_11677100_7`
GROUP BY `Position`
HAVING COUNT(*)>0
ORDER BY `AttendedCount`
LIMIT 10;
","
SELECT col1, COUNT(*) AS `TotalPlayers`, SUM(col4 LIKE 'Attended%') `AttendedCount`
FROM `table_1_11677100_7`
GROUP BY col1
HAVING COUNT(*)>0
ORDER BY `AttendedCount`
LIMIT 10;
","[('catcher', 1, 0), ('infielder', 2, 0), ('pitcher', 2, 0), ('outfielder', 3, 2)]",table_1_11677100_7,"STEP 1: Parse the SQL intent — group rows by Position, compute TotalPlayers = COUNT(*), compute AttendedCount = number of rows whose 'MLB Draft' starts with 'Attended', filter groups with COUNT(*)>0, order groups by AttendedCount (ascending) and return up to 10 positions. STEP 2: Choose ambiguity type — scope/measure ambiguity fits: the phrasing “most” or “have the most players who attended” can mean absolute counts (what the SQL returns) or a relative rate/percentage (attended players divided by players at that position). STEP 3: Draft the question — produce an ambiguous natural-language question that maps to counting attended entries per position but is interpretable in another way. STEP 4: Explain ambiguity — in the original query “most” is implemented as the raw AttendedCount per position (ordered by SUM(MLB Draft LIKE 'Attended%')), but a reader could instead intend the position with the highest proportion of attended players (AttendedCount/TotalPlayers) or some other scope (e.g., per school or per era).",reserved,12,reward,,type: Scope ambiguity (absolute count vs relative rate) | explanation: The SQL measures “most” as the absolute number of players per position whose 'MLB Draft' value begins with 'Attended' (AttendedCount). However the question could alternatively be read as asking for the highest proportion of attended players within each position (AttendedCount divided by TotalPlayers) or even the top position overall versus per-team/per-era—leading to a different SQL (percentage calculation or further grouping/filtering).
"Which colleges have players, and how many players does each have?","
SELECT `College` AS `College`, COUNT(*) AS `NumPlayers`
FROM `table_1_11677691_3` AS `t1`
INNER JOIN `table_1_11677691_3` AS `t2` ON `t1`.`College` = `t2`.`College`
WHERE `t1`.`Player` <> `t2`.`Player`
GROUP BY `College`
HAVING COUNT(DISTINCT `t1`.`Player`) > 1
ORDER BY `NumPlayers` DESC
LIMIT 10
UNION ALL
SELECT DISTINCT `College`, 1
FROM `table_1_11677691_3`
ORDER BY `College` DESC
LIMIT 5;
","SELECT col4, COUNT(*)
FROM `table_1_11677691_3`
GROUP BY col4
HAVING COUNT(col0) > 1
UNION
SELECT col4, 1
FROM `table_1_11677691_3`
GROUP BY col4
HAVING COUNT(col0) = 1
ORDER BY 2
LIMIT 10;","[('arkansas', 1), ('florida state', 1), ('north carolina', 1), ('ohio state', 1), ('oklahoma', 1), ('southern california', 1), ('texas state', 1), ('clemson', 2), ('nebraska', 2)]",table_1_11677691_3,"STEP 1: Parse the SQL intent — The first SELECT does a self-join on College and WHERE t1.Player <> t2.Player, then GROUP BY College and HAVING COUNT(DISTINCT t1.Player) > 1, returning COUNT(*) (which equals n*(n-1) for n players at a college) as NumPlayers, ordered desc LIMIT 10. The UNION ALL branch returns up to 5 distinct College rows with a value 1 (so single-player colleges) limited by College DESC. The union concatenates the top-pairs results with a few single-college rows. STEP 2: Choose ambiguity type — An aggregation/entity-granularity ambiguity fits best: the phrase ""how many players"" can refer to distinct player counts per college (n) or to the number produced by the self-join (ordered pairs n*(n-1)), and it's also unclear whether single-player colleges are to be included. STEP 3: Draft the question — ""Which colleges have players, and how many players does each have?"" STEP 4: Explain ambiguity — In the original query ""how many players"" is implemented inconsistently: the self-join returns pair-counts for colleges with more than one distinct player (n*(n-1)), while the UNION branch adds some colleges with the value 1. Alternatively, the question could mean the straightforward distinct-player count per college (n) or might mean to include/exclude single-player colleges or to return top-N only.",reserved,16,reward,,"type: Entity vagueness / aggregation-granularity ambiguity | explanation: The SQL returns a COUNT stemming from a self-join (effectively n*(n-1) for a college with n players) for multi-player colleges and also appends some colleges with the value 1 via UNION; the natural language question could instead mean the distinct number of players per college (n), could mean pairwise counts, and could differ on whether single-player colleges are included."
"For each College among Florida State, UCLA, Ohio State, Rutgers, Wisconsin, Southern California, Stanford, Washington, and Alabama, what are the College, the Players total calculated as SUM(College = College), GROUP_CONCAT(Position) as Positions, and GROUP_CONCAT(Hometown) as Hometowns, grouped by College and limited to the top 5 Colleges ordered by Players descending?","
SELECT `College` `College`, SUM(`College`=`College`) `Players`, GROUP_CONCAT(`Position`) `Positions`, GROUP_CONCAT(`Hometown`) `Hometowns`
FROM `table_1_11677691_6`
JOIN (SELECT 'Florida State' `Florida State`, 'UCLA' `UCLA`, 'Ohio State' `Ohio State`, 'Rutgers' `Rutgers`, 'Wisconsin' `Wisconsin`, 'Southern California' `Southern California`, 'Stanford' `Stanford`, 'Washington' `Washington`, 'Alabama' `Alabama`, ('Florida State' || '|' || 'UCLA' || '|' || 'Ohio State' || '|' || 'Rutgers' || '|' || 'Wisconsin' || '|' || 'Southern California' || '|' || 'Stanford' || '|' || 'Washington' || '|' || 'Alabama') `AllColleges`) v
ON INSTR(v.`AllColleges`, `College`) > 0
WHERE 1
GROUP BY `College`
ORDER BY `Players` DESC
LIMIT 5;
","SELECT col4, COUNT(*) AS `Players`, GROUP_CONCAT(col1) `Positions`, GROUP_CONCAT(col3) `Hometowns`
FROM `table_1_11677691_6`
WHERE col4 <> '' AND col4 = col4
GROUP BY col4
ORDER BY `Players`
LIMIT 5;","[('alabama', 1, 'defensive back', 'geismar, louisiana'), ('florida state', 1, 'defensive line', 'denton, texas'), ('rutgers', 1, 'defensive line', 'ramsey, new jersey'), ('stanford', 1, 'linebacker', 'leesburg, florida'), ('ucla', 1, 'defensive line', 'monrovia, california')]",table_1_11677691_6,"1) Parse intent: produce per-College aggregates (count and concatenations) for a predefined set of colleges and limit output to five by descending player counts. 2) Map schema: use College, Position, and Hometown columns and compute Players via SUM(College=College) and concatenations via GROUP_CONCAT. 3) Draft: formulate a question listing the colleges and requesting College, Players, Positions, and Hometowns with grouping, ordering, and limit. 4) Validate: check that the listed colleges, SUM(College=College), GROUP_CONCAT(Position), GROUP_CONCAT(Hometown), GROUP BY College, ORDER BY Players DESC, and LIMIT 5 are all referenced.",reserved,11,reward,,
"Give me a tidy per-college breakdown of 2012 All‑USA alums: how many players from each college, whether a college has multiple alums for planning a multi-stop tour, counts by position, a list of each player with their hometown, and flag/list any players who went to college in their home state.","
WITH players AS (
  SELECT `Player`,`Position`,`School`,`Hometown`,`College`,
    TRIM(SUBSTR(`Hometown`, INSTR(`Hometown`, ', ')+2)) AS `Hometown State`
  FROM `table_1_11677691_9`
)
SELECT
  p_main.`College` AS `College`,
  COUNT(*) AS `Players_Count`,
  CASE WHEN COUNT(*)>=2 THEN 1 ELSE 0 END AS `Multi_Stop_Flag`,
  (
    SELECT GROUP_CONCAT('`' || sub.`Position` || ' (' || sub.cnt || ')', ', ')
    FROM (
      SELECT `Position`, COUNT(*) AS cnt
      FROM players p2
      WHERE p2.`College` = p_main.`College`
      GROUP BY `Position`
    ) AS sub
  ) AS `Positions_Summary`,
  GROUP_CONCAT('`' || p_main.`Player` || '` - ' || p_main.`Hometown`, '; ') AS `Players_List`,
  MAX(CASE WHEN p_main.`College` LIKE '%' || p_main.`Hometown State` || '%' THEN 1 ELSE 0 END) AS `Homecoming_Flag`,
  (
    SELECT GROUP_CONCAT('`' || p3.`Player` || '` (' || p3.`Hometown` || ')', '; ')
    FROM players p3
    WHERE p3.`College` = p_main.`College`
      AND p3.`College` LIKE '%' || p3.`Hometown State` || '%'
  ) AS `Homecoming_Players`
FROM players p_main
GROUP BY p_main.`College`
ORDER BY `Players_Count` DESC, `College`;
","
WITH players AS (
  SELECT col0,col1,col2,col3,col4,
    TRIM(SUBSTR(col3, INSTR(col3, ', ')+2)) AS `Hometown State`
  FROM `table_1_11677691_9`
)
SELECT
  p_main.col4 AS col4,
  COUNT(*) AS `Players_Count`,
  CASE WHEN COUNT(*)>=2 THEN 1 ELSE 0 END AS `Multi_Stop_Flag`,
  (
    SELECT GROUP_CONCAT('`' || sub.col1 || ' (' || sub.cnt || ')', ', ')
    FROM (
      SELECT col1, COUNT(*) AS cnt
      FROM players p2
      WHERE p2.col4 = p_main.col4
      GROUP BY col1
    ) AS sub
  ) AS `Positions_Summary`,
  GROUP_CONCAT('`' || p_main.col0 || '` - ' || p_main.col3, '; ') AS `Players_List`,
  MAX(CASE WHEN p_main.col4 LIKE '%' || p_main.`Hometown State` || '%' THEN 1 ELSE 0 END) AS `Homecoming_Flag`,
  (
    SELECT GROUP_CONCAT('`' || p3.col0 || '` (' || p3.col3 || ')', '; ')
    FROM players p3
    WHERE p3.col4 = p_main.col4
      AND p3.col4 LIKE '%' || p3.`Hometown State` || '%'
  ) AS `Homecoming_Players`
FROM players p_main
GROUP BY p_main.col4
ORDER BY `Players_Count` DESC, col4;
","[('alabama', 3, 1, '`offensive line (1), `running back (1), `wide receiver (1)', '`derrick henry` - yulee, florida; `robert foster` - monaca, pennsylvania; `grant hill` - huntsville, alabama', 1, '`grant hill` (huntsville, alabama)'), ('mississippi', 2, 1, '`offensive line (1), `wide receiver (1)', '`laquon treadwell` - crete, illinois; `laremy tunsil` - lake city, florida', 0, None), ('arkansas', 1, 0, '`tight end (1)', '`hunter henry` - little rock, arkansas', 1, '`hunter henry` (little rock, arkansas)'), ('louisiana state', 1, 0, '`offensive line (1)', '`ethan pocic` - lemont, illinois', 0, None), ('ohio state', 1, 0, '`offensive line (1)', '`evan lisle` - centerville, ohio', 1, '`evan lisle` (centerville, ohio)'), ('oregon', 1, 0, '`running back (1)', '`thomas tyner` - aloha, oregon', 1, '`thomas tyner` (aloha, oregon)'), ('southern california', 1, 0, '`quarterback (1)', '`max browne` - sammamish, washington', 0, None), ('texas', 1, 0, '`offensive line (1)', '`kent perkins` - dallas, texas', 1, '`kent perkins` (dallas, texas)')]",table_1_11677691_9,"As a tour designer I talk in practical terms about colleges, alumni counts and hometowns rather than SQL; I know the table lists players, positions, hometowns and colleges. The query aggregates players by college, counting them, summarizing positions, listing player names and hometowns, and flagging any who went to college in their home state. The schema maps Player, Position, Hometown and College into per-college summaries and derives Hometown State from the Hometown text. Draft: Ask for a tidy per-college breakdown showing number of 2012 All‑USA alums, whether a college has multiple alums for multi-stop planning, counts by position, a players-with-hometowns list, and which colleges have any home-state alums (and who they are). This matches the data returned by the query and contains no extra fields.",persona,"A bespoke 'sports pilgrimage' tour designer who builds curated road-trip itineraries visiting hometowns and colleges of 2012 All‑USA high school football selections. Goals: Identify clusters of players by college to create multi-stop tour packages around college towns with several alumni from the 2012 team. Find players whose hometown state matches their college state so she can design short, local 'homecoming' mini-tours. Map position-based fan-interest stops (e.g., where multiple high-profile offensive players originate) to prioritize attractions and storytelling stops on the route. Produce tidy lists of player names, hometowns and schools to generate itinerary copy, postcards and directions. Example Queries: SELECT Player, Position, School, Hometown, College FROM table_1_11677691_9 WHERE College = 'Alabama'; SELECT Player, Hometown, College FROM table_1_11677691_9 WHERE TRIM(SUBSTR(Hometown, INSTR(Hometown, ', ')+2)) = College; SELECT College, Position, COUNT(*) AS players_from_college_and_position FROM table_1_11677691_9 GROUP BY College, Position ORDER BY players_from_college_and_position DESC;",reward,,
"Which directors had an average of more than 3 million U.S. viewers for episodes after episode 70, and what were their episode counts, average and peak viewers, and titles?","
SELECT `Directed by` AS `Director`,
       COUNT(`No. in series`) `Episodes`,
       ROUND(AVG(`U.S. viewers (millions)`),2) `Avg viewers`,
       MAX(`U.S. viewers (millions)`) `Peak viewers`,
       GROUP_CONCAT(`Title`, '; ') `Episode titles`
FROM `table_1_11694832_1`
WHERE `No. in series` > 70
GROUP BY `Directed by`
HAVING AVG(`U.S. viewers (millions)`) > 3.0
ORDER BY AVG(`U.S. viewers (millions)`) * -1
LIMIT 5;
","
SELECT col3 AS `Director`,
       COUNT(col0) `Episodes`,
       ROUND(AVG(col7),2) `Avg viewers`,
       MAX(col7) `Peak viewers`,
       GROUP_CONCAT(col2, '; ') `Episode titles`
FROM `table_1_11694832_1`
WHERE col0 > 70
GROUP BY col3
HAVING AVG(col7) > 3.0
ORDER BY AVG(col7) * -1
LIMIT 5;
","[('john asher', 1, 4.24, '4.24', '""songs to love and die by""'), ('stuart gillard', 1, 3.57, '3.57', '""i love you but i\'ve chosen darkness""'), ('paul johansson', 2, 3.33, '3.52', '""where did you sleep last night?""; ""prom night at hater high""'), ('thomas j. wright', 1, 3.28, '3.28', '""you call it madness, but i call it love""'), ('greg prange', 3, 3.09, '4.21', '""some you give away""; ""it gets the worst at night""; ""the birth and death of the day""')]",table_1_11694832_1,"STEP 1: Parse the SQL intent — find directors (Directed by) who directed episodes with No. in series > 70, count those episodes, compute average and max U.S. viewers for those filtered episodes, concatenate their titles, keep only directors whose average (over the filtered episodes) is > 3.0, and return the top 5 by average viewers. STEP 2: Determine ambiguity type — scope ambiguity fits best because the phrasing about an ""average of more than 3 million viewers"" and the restriction ""episodes after episode 70"" can attach in multiple ways (is the average computed only over episodes after 70, or across all episodes by the director, or must each episode after 70 exceed 3 million?). STEP 3: Draft the question — ""Which directors had an average of more than 3 million U.S. viewers for episodes after episode 70, and what were their episode counts, average and peak viewers, and titles?"" STEP 4: Explain the ambiguity — the original query computes the average and other stats only over episodes with No. in series > 70 (WHERE before GROUP BY), but a reader could instead interpret the question as computing each director's overall average across all their episodes and then reporting those who exceed 3 million, or as requiring that every individual episode after 70 exceeds 3 million, or even misread whether ""after episode 70"" includes episode 70.",reserved,10,reward,,"type: Scope ambiguity | explanation: The SQL computes averages only over episodes where No. in series > 70 (filter applied before grouping), but the natural-language question could be read as (a) averaging only those post-70 episodes (the SQL interpretation), (b) averaging across all episodes by each director and then selecting those above 3 million, or (c) requiring every single episode after 70 to exceed 3 million (a stricter reading); additionally, ""after episode 70"" might be read inclusively or exclusively."
"Which models, grouped by CPU family, have built-in assembly and what are their RAM and display specs?","
SELECT
  CASE
    WHEN `CPU` LIKE 'Zilog Z80%' THEN '`Zilog Z80`'
    WHEN `CPU` LIKE 'Motorola 68000%' THEN '`Motorola 68000`'
    ELSE '`Other`'
  END AS `CPU Family`,
  COUNT(*) AS `Model Count`,
  COALESCE(GROUP_CONCAT('`' || `Calculator` || '`', '; '), '') AS `Models`,
  COALESCE(GROUP_CONCAT(DISTINCT CASE WHEN `Programming Languages` LIKE '%Assembly (built-in)%' THEN '`' || `Calculator` || '`' || ' (RAM: ' || `RAM` || '; Display: ' || `Display Size` || ')' END, '; '), '`None`') AS `Built-in Assembly Models (RAM & Display)`,
  COALESCE(GROUP_CONCAT(DISTINCT CASE WHEN `CPU` LIKE 'Motorola 68000%' THEN '`' || `Calculator` || '`' || ' [RAM: ' || `RAM` || '; Display: ' || `Display Size` || '; Year: ' || `Year Released` || ']' END, '; '), '`None`') AS `Motorola 68000 Models (details)`,
  COALESCE(GROUP_CONCAT(DISTINCT CASE WHEN `CPU` LIKE 'Zilog Z80%' THEN '`' || `Calculator` || '`' || ' [RAM: ' || `RAM` || '; Display: ' || `Display Size` || '; Year: ' || `Year Released` || ']' END, '; '), '`None`') AS `Zilog Z80 Models (details)`
FROM `table_1_11703336_1`
GROUP BY
  CASE
    WHEN `CPU` LIKE 'Zilog Z80%' THEN '`Zilog Z80`'
    WHEN `CPU` LIKE 'Motorola 68000%' THEN '`Motorola 68000`'
    ELSE '`Other`'
  END;
","SELECT
  CASE
    WHEN ""CPU"" LIKE 'Zilog Z80%' THEN 'Zilog Z80'
    WHEN ""CPU"" LIKE 'Motorola 68000%' THEN 'Motorola 68000'
    ELSE 'Other'
  END AS ""CPU Family"",
  COUNT(*) AS ""Model Count"",
  COALESCE(GROUP_CONCAT(""Calculator"", '; '), '') AS ""Models"",
  COALESCE(GROUP_CONCAT(CASE WHEN col4 LIKE '%Assembly (built-in)%' THEN ""Calculator"" || ' (RAM: ' || ""RAM"" || '; Display: ' || col3 || ')' END, '; '), '`None`') AS ""Built-in Assembly Models (RAM & Display)"",
  COALESCE(GROUP_CONCAT(CASE WHEN ""CPU"" LIKE 'Motorola 68000%' THEN ""Calculator"" || ' [RAM: ' || ""RAM"" || '; Display: ' || col3 || '; Year: ' || col6 || ']' END, '; '), '`None`') AS ""Motorola 68000 Models (details)"",
  COALESCE(GROUP_CONCAT(CASE WHEN ""CPU"" LIKE 'Zilog Z80%' THEN ""Calculator"" || ' [RAM: ' || ""RAM"" || '; Display: ' || col3 || '; Year: ' || col6 || ']' END, '; '), '`None`') AS ""Zilog Z80 Models (details)""
FROM `table_1_11703336_1`
GROUP BY
  CASE
    WHEN ""CPU"" LIKE 'Zilog Z80%' THEN 'Zilog Z80'
    WHEN ""CPU"" LIKE 'Motorola 68000%' THEN 'Motorola 68000'
    ELSE 'Other'
  END;","[('Other', 6, 'Calculator; Calculator; Calculator; Calculator; Calculator; Calculator', 'Calculator (RAM: RAM; Display: 96×64 pixels 16×8 characters); Calculator (RAM: RAM; Display: 128×64 pixels 21×8 characters)', '`None`', '`None`')]",table_1_11703336_1,"As a retro-calculator dev I care about which models expose built-in assembly so I can prioritize low-level features; I'd ask per family to keep it organized. The SQL includes a conditional aggregation that extracts models whose Programming Languages include 'Assembly (built-in)' and appends their RAM and display. Programming Languages indicates built-in assembly, and RAM/Display Size are the spec fields. Which models (grouped by CPU family) have built-in assembly, and show each one's RAM and display specs? This matches the conditional built-in-assembly listing with RAM and display in the query.",persona,"Emulator developer and retro-calculator hobbyist building accurate software emulations of classic TI graphing calculators; uses this database to prioritize targets and extract hardware/software specs needed for each model. Goals: Identify groups of calculators that share the same CPU family so a single core can cover multiple models. Find models that require a Motorola 68000 implementation versus Zilog Z80 and gather their RAM/display specs for accurate emulation. Locate calculators with built-in assembly support (higher priority for low-level feature parity) and collect their memory and display details. Example Queries: SELECT ""Calculator"", ""CPU"", ""RAM"", ""Display Size"", ""Year Released"" FROM table_1_11703336_1 WHERE ""CPU"" LIKE 'Zilog Z80%'; SELECT ""Calculator"", ""CPU"", ""RAM"", ""Display Size"", ""Year Released"" FROM table_1_11703336_1 WHERE ""CPU"" LIKE 'Motorola 68000%'; SELECT ""Calculator"", ""CPU"", ""RAM"", ""Display Size"", ""Programming Languages"", ""Year Released"" FROM table_1_11703336_1 WHERE ""Programming Languages"" LIKE '%Assembly (built-in)%' ORDER BY ""Year Released"";",reward,,
"Which teams had managerial changes, how many changes did each have, and who were the outgoing managers and their replacements?","
SELECT t.`Team`, COUNT(*) AS `Total changes`, GROUP_CONCAT(t.`Outgoing manager`), GROUP_CONCAT(t.`Replaced by`)
FROM `table_1_11713303_2` t
JOIN `table_1_11713303_2` r ON t.`Team` = r.`Team` AND t.`Date of vacancy` <= r.`Date of vacancy`
WHERE t.`Team` IN (t.`Team`) OR t.`Team` = t.`Team`
GROUP BY t.`Team`
ORDER BY `Total changes`
LIMIT 10;
","
SELECT t.col0, COUNT(*) AS `Total changes`, GROUP_CONCAT(t.col1), GROUP_CONCAT(t.col4)
FROM `table_1_11713303_2` t
JOIN `table_1_11713303_2` r ON t.col0 = r.col0 AND t.col3 <= r.col3
WHERE t.col0 IN (t.col0) OR t.col0 = t.col0
GROUP BY t.col0
ORDER BY `Total changes`
LIMIT 10;
","[('anderlecht', 1, 'franky vercauteren', 'ariel jacobs'), ('charleroi', 1, 'philippe van de walle', 'thierry siquet'), ('dender eh', 1, 'jean-pierre van de velde', 'johan boskamp'), ('mons', 1, 'josé riga', 'albert cartier'), ('brussels', 3, 'albert cartier,albert cartier,edy de bolle', 'edy de bolle (caretaker),edy de bolle (caretaker),franky van der elst'), ('mouscron', 3, 'marc brys,marc brys,geert broeckaert', 'geert broeckaert (caretaker),geert broeckaert (caretaker),enzo scifo'), ('sint-truiden', 3, 'valère billen,peter voets,peter voets', 'peter voets (caretaker),dennis van wijk,dennis van wijk')]",table_1_11713303_2,"STEP 1: Parse the SQL intent: the query groups rows by Team and returns for each team a COUNT(*) called Total changes plus concatenated lists of Outgoing manager and Replaced by. The self-join ON t.Team = r.Team AND t.Date of vacancy <= r.Date of vacancy makes the COUNT count join pairs per team (pairs of vacancies where one date is <= another). It orders by Total changes and limits to 10. STEP 2: Choose an ambiguity type: Entity vagueness fits best because the term “changes” can mean different measurable things here (departures, appointments, distinct transitions, or the join-pair count). The SQL’s COUNT over the self-join corresponds to a less obvious measure (ordered pairs) rather than a simple event count. STEP 3: Draft the question: “Which teams had managerial changes, how many changes did each have, and who were the outgoing managers and their replacements?” STEP 4: Explain ambiguity: in the original query “changes” is implemented as COUNT(*) over a self-join (counting pairs of vacancies with t.Date <= r.Date), which is effectively a pairwise/cumulative counting of vacancy rows per team. The question wording is ambiguous because “changes” could alternatively mean (a) number of outgoing managers (departure events), (b) number of incoming appointments, (c) number of distinct manager transitions, or (d) the pairwise/cumulative count produced by this join. A different query could count distinct departures or appointments instead, yielding different numbers.",reserved,13,reward,,"type: Entity Vagueness | explanation: The phrase “changes” is vague: the SQL counts join-pairs (t.Date <= r.Date) producing a cumulative/pairwise count, but a reader could interpret “changes” as departures, appointments, distinct transitions, or simple event counts—each interpretation would require a different SQL implementation and could produce different results."
"Give me a season-by-season rundown: how many episodes, titles in air order, season premiere and finale dates, who directed and wrote the most that season, and which titles include 'Dream'/'Dreams'/'Funhouse'.","
SELECT
  t.`Season #`,
  (SELECT COUNT(*) FROM table_1_11715748_2 WHERE `Season #` = t.`Season #`) AS `episode_count`,
  (SELECT group_concat(`Title`, ' || ') FROM (SELECT `Title` FROM table_1_11715748_2 WHERE `Season #` = t.`Season #` ORDER BY `Series #`)) AS `episode_list_in_series_order`,
  (SELECT MIN(`Original airdate`) FROM table_1_11715748_2 WHERE `Season #` = t.`Season #`) AS `first_airdate`,
  (SELECT MAX(`Original airdate`) FROM table_1_11715748_2 WHERE `Season #` = t.`Season #`) AS `last_airdate`,
  (SELECT group_concat(d.`Director(s)`, ' | ')
   FROM (
     SELECT `Director(s)`, COUNT(*) AS cnt
     FROM table_1_11715748_2
     WHERE `Season #` = t.`Season #`
     GROUP BY `Director(s)`
   ) AS d
   WHERE d.cnt = (
     SELECT MAX(cnt2) FROM (
       SELECT COUNT(*) AS cnt2
       FROM table_1_11715748_2
       WHERE `Season #` = t.`Season #`
       GROUP BY `Director(s)`
     )
   )
  ) AS `top_director_by_season`,
  (SELECT group_concat(w.`Writer(s)`, ' | ')
   FROM (
     SELECT `Writer(s)`, COUNT(*) AS cnt
     FROM table_1_11715748_2
     WHERE `Season #` = t.`Season #`
     GROUP BY `Writer(s)`
   ) AS w
   WHERE w.cnt = (
     SELECT MAX(cnt3) FROM (
       SELECT COUNT(*) AS cnt3
       FROM table_1_11715748_2
       WHERE `Season #` = t.`Season #`
       GROUP BY `Writer(s)`
     )
   )
  ) AS `top_writer_by_season`,
  (SELECT group_concat(`Title`, ' || ')
   FROM (
     SELECT `Title`
     FROM table_1_11715748_2
     WHERE `Season #` = t.`Season #`
       AND (
         `Title` LIKE '%Dream%' OR
         `Title` LIKE '%Dreams%' OR
         `Title` LIKE '%Funhouse%'
       )
     ORDER BY `Series #`
   )
  ) AS `keyword_matches`
FROM (
  SELECT DISTINCT `Season #` FROM table_1_11715748_2
) AS t
ORDER BY t.`Season #`;
","
SELECT
  t.col1,
  (SELECT COUNT(*) FROM table_1_11715748_2 WHERE col1 = t.col1) AS `episode_count`,
  (SELECT group_concat(col2, ' || ') FROM (SELECT col2 FROM table_1_11715748_2 WHERE col1 = t.col1 ORDER BY col0)) AS `episode_list_in_series_order`,
  (SELECT MIN(col5) FROM table_1_11715748_2 WHERE col1 = t.col1) AS `first_airdate`,
  (SELECT MAX(col5) FROM table_1_11715748_2 WHERE col1 = t.col1) AS `last_airdate`,
  (SELECT group_concat(d.col3, ' | ')
   FROM (
     SELECT col3, COUNT(*) AS cnt
     FROM table_1_11715748_2
     WHERE col1 = t.col1
     GROUP BY col3
   ) AS d
   WHERE d.cnt = (
     SELECT MAX(cnt2) FROM (
       SELECT COUNT(*) AS cnt2
       FROM table_1_11715748_2
       WHERE col1 = t.col1
       GROUP BY col3
     )
   )
  ) AS `top_director_by_season`,
  (SELECT group_concat(w.col4, ' | ')
   FROM (
     SELECT col4, COUNT(*) AS cnt
     FROM table_1_11715748_2
     WHERE col1 = t.col1
     GROUP BY col4
   ) AS w
   WHERE w.cnt = (
     SELECT MAX(cnt3) FROM (
       SELECT COUNT(*) AS cnt3
       FROM table_1_11715748_2
       WHERE col1 = t.col1
       GROUP BY col4
     )
   )
  ) AS `top_writer_by_season`,
  (SELECT group_concat(col2, ' || ')
   FROM (
     SELECT col2
     FROM table_1_11715748_2
     WHERE col1 = t.col1
       AND (
         col2 LIKE '%Dream%' OR
         col2 LIKE '%Dreams%' OR
         col2 LIKE '%Funhouse%'
       )
     ORDER BY col0
   )
  ) AS `keyword_matches`
FROM (
  SELECT DISTINCT col1 FROM table_1_11715748_2
) AS t
ORDER BY t.col1;
","[(1.0, 1, '""dream come true""', 'october2,1989', 'october2,1989', 'george kaczender', 'thomas lazarus', '""dream come true""'), (2.0, 1, '""heartbreak hotel""', 'october9,1989', 'october9,1989', 'william malone', 'jonathan glassner', None), (3.0, 1, '""welcome to springwood""', 'october16,1989', 'october16,1989', 'ken wiederhorn', 'a. l. katz and gilbert adler', None), (4.0, 1, '""photo finish""', 'october23,1989', 'october23,1989', 'tom desimone', 'jonathan glassner', None), (5.0, 1, '""memory overload""', 'october30,1989', 'october30,1989', 'don weis', 'michael kirschenbaum', None), (6.0, 1, '""lucky stiff""', 'november6,1989', 'november6,1989', 'william malone', 'david braff', None), (7.0, 1, '""silence is golden""', 'november13,1989', 'november13,1989', 'chuck braverman', 'jonathan glassner', None), (8.0, 1, '""bloodlines""', 'november20,1989', 'november20,1989', 'james quinn', 'gilbert adler and a. l. katz', None), (9.0, 1, '""monkey dreams""', 'november27,1989', 'november27,1989', 'robert englund', 'michael kirschenbaum', '""monkey dreams""'), (10.0, 1, '""do you know where the kids are?""', 'december4,1989', 'december4,1989', 'bill froelich', 'wayne rice', None), (11.0, 1, '""dreams that kill""', 'december11,1989', 'december11,1989', 'tom de simone', 'tom blumquist', '""dreams that kill""'), (12.0, 1, '""what you don\'t know can kill you""', 'january1,1990', 'january1,1990', 'ken wiederhorn', 'jonathan glassner', None), (13.0, 1, '""easy come, easy go""', 'january8,1990', 'january8,1990', 'william malone', 'david braff', None), (14.0, 1, '""prime cut""', 'january15,1990', 'january15,1990', 'david calloway', 'michael kirschenbaum', None), (15.0, 1, '""interior loft""', 'january22,1990', 'january22,1990', 'ken wiederhorn', 'david braff', None), (16.0, 1, '""interior loft – later""', 'january29,1990', 'january29,1990', 'ken wiederhorn', 'jonathan glassner', None), (17.0, 1, '""funhouse""', 'february5,1990', 'february5,1990', 'gilbert adler', 'al katz and gilbert adler', '""funhouse""'), (18.0, 1, '""a family affair""', 'february12,1990', 'february12,1990', 'keith samples', 'david braff', None), (19.0, 1, '""dust to dust""', 'february19,1990', 'february19,1990', 'jonathan glassner', 'bill froehlich, david braff, and jonathan glassner', None), (20.0, 1, '""prisoner of love""', 'february26,1990', 'february26,1990', 'richard t. schor', 'richard beban', None), (21.0, 1, '""life sentence""', 'march5,1990', 'march5,1990', 'anita w. addison', 'david zuckerman', None)]",table_1_11715748_2,"I'd sound like a scheduler checking blocks across whole seasons, using plain terms like 'season' and 'original airdate'. The SQL selects each season and aggregates episode counts, title lists in series order, min/max airdates, and top directors/writers plus keyword matches. The mapping uses Season #, Series # (for order), Title, Original airdate, Director(s), Writer(s). Draft: Give me a season-by-season rundown: how many episodes, titles in air order, season premiere and finale dates, who directed and wrote the most that season, and which titles include 'Dream'/'Dreams'/'Funhouse'. Validation: This matches the aggregated per-season info and keyword filtering in the query.",persona,"Classic TV programming manager at a cable network who schedules themed blocks and retrospectives; they use this episode-level metadata to plan lineups and director/writer spotlight nights. Goals: Assemble complete season blocks in original broadcast order and verify air dates for scheduling. Identify the most frequent directors and writers to build director- or writer-focused retrospectives. Find episodes matching thematic keywords (e.g., 'Dream', 'Funhouse') for special programming nights and promos. Example Queries: SELECT ""Series #"", ""Season #"", ""Title"", ""Director(s)"", ""Writer(s)"", ""Original airdate"" 
FROM table_1_11715748_2 
WHERE ""Season #"" = 1 
ORDER BY ""Series #""; SELECT ""Director(s)"", COUNT(*) AS episode_count 
FROM table_1_11715748_2 
GROUP BY ""Director(s)"" 
ORDER BY episode_count DESC; SELECT ""Series #"", ""Season #"", ""Title"", ""Director(s)"", ""Original airdate"" 
FROM table_1_11715748_2 
WHERE ""Writer(s)"" LIKE '%Jonathan Glassner%';",reward,,
"Give me all L roster players who either have duplicated first names in their display name, had multiple stints with the Rockets, or list Poland as their school/club/country, and show each player's jersey number, height, position, years, school/country and which of those patterns applies.","
WITH cte AS (
  SELECT
    `Player`,
    `No.(s)`,
    `Height in Ft.`,
    `Position`,
    `Years for Rockets`,
    `School/Club Team/Country`,
    trim(substr(`Player`, instr(`Player`, ',')+1)) AS `rest`,
    CASE
      WHEN instr(trim(substr(`Player`, instr(`Player`, ',')+1)), ' ')>0
      THEN substr(trim(substr(`Player`, instr(`Player`, ',')+1)), 1, instr(trim(substr(`Player`, instr(`Player`, ',')+1)), ' ')-1)
      ELSE trim(substr(`Player`, instr(`Player`, ',')+1))
    END AS `first_word`,
    CASE
      WHEN instr(trim(substr(`Player`, instr(`Player`, ',')+1)), ' ')>0 THEN
        CASE
          WHEN instr(substr(trim(substr(`Player`, instr(`Player`, ',')+1)), instr(trim(substr(`Player`, instr(`Player`, ',')+1)), ' ')+1), ' ')>0
          THEN substr(
                 substr(trim(substr(`Player`, instr(`Player`, ',')+1)), instr(trim(substr(`Player`, instr(`Player`, ',')+1)), ' ')+1),
                 1,
                 instr(substr(trim(substr(`Player`, instr(`Player`, ',')+1)), instr(trim(substr(`Player`, instr(`Player`, ',')+1)), ' ')+1), ' ')-1
               )
          ELSE substr(trim(substr(`Player`, instr(`Player`, ',')+1)), instr(trim(substr(`Player`, instr(`Player`, ',')+1)), ' ')+1)
        END
      ELSE ''
    END AS `second_word`
  FROM `table_1_11734041_11`
)
SELECT
  `Player`,
  `No.(s)`,
  `Height in Ft.`,
  `Position`,
  `Years for Rockets`,
  `School/Club Team/Country`,
  CASE WHEN `first_word` = `second_word` AND `first_word` <> '' THEN 'duplicated-first' ELSE '' END AS `NamePattern`,
  CASE WHEN instr(`Years for Rockets`, ',')>0 THEN 1 ELSE 0 END AS `MultipleStints`,
  CASE WHEN `School/Club Team/Country` = 'Poland' THEN 1 ELSE 0 END AS `International`
FROM cte
WHERE (`first_word` = `second_word` AND `first_word` <> '')
   OR instr(`Years for Rockets`, ',')>0
   OR `School/Club Team/Country` = 'Poland';
","
WITH cte AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    trim(substr(col0, instr(col0, ',')+1)) AS `rest`,
    CASE
      WHEN instr(trim(substr(col0, instr(col0, ',')+1)), ' ')>0
      THEN substr(trim(substr(col0, instr(col0, ',')+1)), 1, instr(trim(substr(col0, instr(col0, ',')+1)), ' ')-1)
      ELSE trim(substr(col0, instr(col0, ',')+1))
    END AS `first_word`,
    CASE
      WHEN instr(trim(substr(col0, instr(col0, ',')+1)), ' ')>0 THEN
        CASE
          WHEN instr(substr(trim(substr(col0, instr(col0, ',')+1)), instr(trim(substr(col0, instr(col0, ',')+1)), ' ')+1), ' ')>0
          THEN substr(
                 substr(trim(substr(col0, instr(col0, ',')+1)), instr(trim(substr(col0, instr(col0, ',')+1)), ' ')+1),
                 1,
                 instr(substr(trim(substr(col0, instr(col0, ',')+1)), instr(trim(substr(col0, instr(col0, ',')+1)), ' ')+1), ' ')-1
               )
          ELSE substr(trim(substr(col0, instr(col0, ',')+1)), instr(trim(substr(col0, instr(col0, ',')+1)), ' ')+1)
        END
      ELSE ''
    END AS `second_word`
  FROM `table_1_11734041_11`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  CASE WHEN `first_word` = `second_word` AND `first_word` <> '' THEN 'duplicated-first' ELSE '' END AS `NamePattern`,
  CASE WHEN instr(col4, ',')>0 THEN 1 ELSE 0 END AS `MultipleStints`,
  CASE WHEN col5 = 'Poland' THEN 1 ELSE 0 END AS `International`
FROM cte
WHERE (`first_word` = `second_word` AND `first_word` <> '')
   OR instr(col4, ',')>0
   OR col5 = 'Poland';
","[('lampe, maciej maciej lampe', '15', '6-11', 'forward', '2006', 'poland', 'duplicated-first', 0, 0), ('landry, carl carl landry', '14', '6-9', 'forward', '2007-10', 'purdue', 'duplicated-first', 0, 0), ('langhi, dan dan langhi', '14', '6-11', 'forward', '2000-02', 'vanderbilt', 'duplicated-first', 0, 0), ('lantz, stu stu lantz', '22', '6-3', 'guard', '1968-72', 'nebraska', 'duplicated-first', 0, 0), ('leavell, allen allen leavell', '30', '6-2', 'guard', '1979-89', 'oklahoma city', 'duplicated-first', 0, 0), ('lee, courtney courtney lee', '5', '6-5', 'guard', '2010-2012', 'western kentucky', 'duplicated-first', 0, 0), ('livingston, randy randy livingston', '3', '6-5', 'guard', '1996', 'louisiana state', 'duplicated-first', 0, 0), ('lloyd, lewis lewis lloyd', '32', '6-6', 'forward', '1983-87, 1989-90', 'drake', 'duplicated-first', 1, 0), ('lowry, kyle kyle lowry', '7', '6-0', 'guard', '2009-2012', 'villanova', 'duplicated-first', 0, 0), ('lucas, john john lucas', '15', '5-11', 'guard', '2005, 2006-07', 'oklahoma state', 'duplicated-first', 1, 0), ('lucas sr., john john lucas sr.', '5, 10, 15', '6-3', 'guard', '1976-78, 1984-86, 1989-90', 'maryland', 'duplicated-first', 1, 0)]",table_1_11734041_11,"I might also want an all-inventory of odd patterns phrased artistically and asking for labels rather than SQL terms. The SQL returns any L player who has a duplicated first name, or multiple stints (comma in years), or whose school/club/country is Poland, and includes flags for the pattern types. This maps to Player, No.(s), Height in Ft., Position, Years for Rockets, School/Club Team/Country, plus computed NamePattern/MultipleStints/International. Draft the question to return all L players matching any of those three patterns and ask to indicate which pattern(s) apply alongside the usual details. Validate: this mirrors the WHERE OR logic and requests only fields the query provides.",persona,"A performance artist–choreographer designing a site-specific ensemble piece in which each dancer embodies a Houston Rockets player with unusual naming or roster patterns (e.g., duplicated first names, multiple stints, or foreign origins) to inspire movement and costume choices. Goals: Identify players in this 'L' roster whose display names show duplicated first names or other odd name-repeat patterns to assign distinct movement motifs. Find players who had multiple stints with the Rockets (to choreograph cyclical 'return' motifs) and collect their jersey numbers and years for accurate timeline props. Locate internationally-originating players (non-U.S. schools/clubs/countries) to incorporate culturally informed movement and costume elements, plus heights/positions to shape physical casting. Example Queries: SELECT `Player`, `No.(s)`, `Height in Ft.`, `Position`, `Years for Rockets`, `School/Club Team/Country` FROM `table_1_11734041_11` WHERE `Player` REGEXP ',\s*([A-Za-z]+)\s+\1\b'; SELECT `Player`, `No.(s)`, `Years for Rockets` FROM `table_1_11734041_11` WHERE `Years for Rockets` LIKE '%,%'; SELECT `Player`, `No.(s)`, `Height in Ft.`, `Position`, `School/Club Team/Country` FROM `table_1_11734041_11` WHERE `School/Club Team/Country` LIKE '%Poland%' OR `School/Club Team/Country` LIKE '%Club%' OR `School/Club Team/Country` NOT LIKE '%University%' AND `School/Club Team/Country` NOT LIKE '%College%';",reward,,
Which position has the tallest player?,"
SELECT
  `Position`,
  COUNT(*) OVER (PARTITION BY `Position`) `Players_Count`,
  MAX(
    CAST(substr(`Height in Ft.`,1,instr(`Height in Ft.`,'-')-1) AS INTEGER)*12 +
    CAST(substr(`Height in Ft.`,instr(`Height in Ft.`,'-')+1) AS INTEGER)
  ) OVER (PARTITION BY `Position`) `Tallest_Inches`,
  FIRST_VALUE(`Player`) OVER (
    PARTITION BY `Position` ORDER BY
    (CAST(substr(`Height in Ft.`,1,instr(`Height in Ft.`,'-')-1) AS INTEGER)*12 +
     CAST(substr(`Height in Ft.`,instr(`Height in Ft.`,'-')+1) AS INTEGER)
    ) DESC
  ) `Tallest_Player`
FROM `table_1_11734041_18`
GROUP BY `Position`
LIMIT 50;
","
SELECT
  col3,
  COUNT(*) OVER (PARTITION BY col3) `Players_Count`,
  MAX(
    CAST(substr(col2,1,instr(col2,'-')-1) AS INTEGER)*12 +
    CAST(substr(col2,instr(col2,'-')+1) AS INTEGER)
  ) OVER (PARTITION BY col3) `Tallest_Inches`,
  FIRST_VALUE(col0) OVER (
    PARTITION BY col3 ORDER BY
    (CAST(substr(col2,1,instr(col2,'-')-1) AS INTEGER)*12 +
     CAST(substr(col2,instr(col2,'-')+1) AS INTEGER)
    ) DESC
  ) `Tallest_Player`
FROM `table_1_11734041_18`
GROUP BY col3
LIMIT 50;
","[('center', 1, 84, 'tabak, zan zan tabak'), ('forward', 1, 81, 'taylor, maurice maurice taylor'), ('guard', 1, 75, 'taylor, jeff jeff taylor'), ('guard / forward', 1, 78, 'torres, oscar oscar torres')]",table_1_11734041_18,"STEP 1: Parse the SQL intent — the query groups rows by Position and, for each Position, returns the number of players, the maximum height converted to inches, and the player with that maximum height (tallest player per position). STEP 2: Determine ambiguity type — scope ambiguity fits well: the phrase ""the tallest player"" can refer to the tallest player within each position or to the single tallest player across all positions. STEP 3: Draft the question — a concise ambiguous phrasing is: ""Which position has the tallest player?"" STEP 4: Explain the ambiguity — the SQL is interpreted as returning the tallest player for each position (i.e., tallest within each position). The question could instead be read as asking for the one position that contains the overall tallest player across all positions.",reserved,14,reward,,"type: Scope ambiguity | explanation: In the SQL the phrase is resolved per position (the tallest player for each Position is returned). Alternatively, the question could be interpreted as asking for a single position that contains the absolute tallest player across the whole roster."
"For a 2004/returns/college-ties roundup, pull every player who was in 2004 or had multiple stints or comes from a college with more than one alum here, and give jersey, height (and inches), position, years, school, plus per-position and per-school counts.","
WITH `roster` AS (
  SELECT *
  FROM `table_1_11734041_6`
)
SELECT
  '`' || `Player` || '`' AS `Player`,
  '`' || `No.(s)` || '`' AS `No.(s)`,
  '`' || `Height in Ft.` || '`' AS `Height in Ft.`,
  (CAST(substr(`Height in Ft.`, 1, instr(`Height in Ft.`, '-') - 1) AS INTEGER) * 12
   + CAST(substr(`Height in Ft.`, instr(`Height in Ft.`, '-') + 1) AS INTEGER)) AS `Height_in_inches`,
  '`' || `Position` || '`' AS `Position`,
  '`' || `Years for Rockets` || '`' AS `Years for Rockets`,
  '`' || `School/Club Team/Country` || '`' AS `School/Club Team/Country`,
  CASE WHEN `Years for Rockets` LIKE '%,%' THEN 1 ELSE 0 END AS `Multiple_stints`,
  CASE WHEN `Years for Rockets` LIKE '%2004%' THEN 1 ELSE 0 END AS `Was_on_2004`,
  COUNT(*) OVER (PARTITION BY `Position`) AS `Count_by_Position`,
  COUNT(*) OVER (PARTITION BY `School/Club Team/Country`) AS `Alumni_count`
FROM `roster`
WHERE
  -- Actionable subset: players on the roster in 2004, players with multiple stints, or players from colleges with >1 Rocket in this section
  `Years for Rockets` LIKE '%2004%'
  OR `Years for Rockets` LIKE '%,%'
  OR (
    SELECT COUNT(*) FROM `roster` AS `r2`
    WHERE `r2`.`School/Club Team/Country` = `roster`.`School/Club Team/Country`
  ) > 1
ORDER BY `Position`, `Height_in_inches` DESC, `Player`;
","
WITH `roster` AS (
  SELECT *
  FROM `table_1_11734041_6`
)
SELECT
  '`' || col0 || '`' AS col0,
  '`' || col1 || '`' AS col1,
  '`' || col2 || '`' AS col2,
  (CAST(substr(col2, 1, instr(col2, '-') - 1) AS INTEGER) * 12
   + CAST(substr(col2, instr(col2, '-') + 1) AS INTEGER)) AS `Height_in_inches`,
  '`' || col3 || '`' AS col3,
  '`' || col4 || '`' AS col4,
  '`' || col5 || '`' AS col5,
  CASE WHEN col4 LIKE '%,%' THEN 1 ELSE 0 END AS `Multiple_stints`,
  CASE WHEN col4 LIKE '%2004%' THEN 1 ELSE 0 END AS `Was_on_2004`,
  COUNT(*) OVER (PARTITION BY col3) AS `Count_by_Position`,
  COUNT(*) OVER (PARTITION BY col5) AS `Alumni_count`
FROM `roster`
WHERE
  -- Actionable subset: players on the roster in 2004, players with multiple stints, or players from `table_1_11734041_6` with >1 Rocket in this section
  col4 LIKE '%2004%'
  OR col4 LIKE '%,%'
  OR (
    SELECT COUNT(*) FROM `roster` AS `r2`
    WHERE `r2`.col5 = `roster`.col5
  ) > 1
ORDER BY col3, `Height_in_inches` DESC, col0;
","[('`feitl, dave dave feitl`', '`5`', '`7-0`', 84, '`center`', '`1986-86, 1990-91`', '`texas-el paso`', 1, 0, 1, 1), ('`francis, steve steve francis`', '`3`', '`6-3`', 75, '`guard`', '`1999-2004, 2007-08`', '`maryland`', 1, 1, 1, 1)]",table_1_11734041_6,"As a historian assembling a 'Where were they in 2004?' feature I would ask conversationally but precisely about those three story hooks: 2004 presence, returns, and college ties. The SQL returns rows meeting those hooks, computes each player's height in inches, flags for multiple stints and 2004, and provides counts partitioned by position and by school. Mapping: the table supplies Player, No.(s), Height in Ft., Position, Years for Rockets, and School/Club Team/Country, which are used plus derived metrics. Draft question: For a 2004/returns/college-ties roundup, pull every player who was in 2004 or had multiple stints or comes from a college with more than one alum here, and give jersey, height (and inches), position, years, school, plus per-position and per-school counts.",persona,"Digital content producer and team historian for the Houston Rockets who creates roster-driven social content, alumni spotlights, and editorial pieces using the all-time roster database. They use the dataset to verify facts, pull player metadata (height, position, years), and identify narrative hooks (college ties, eras, notable returns). Goals: Quickly assemble accurate lists of players by position, era, or college for social posts and articles. Identify players who were on the roster in a particular year or range of years (e.g., to create a 'Where were they in 2004?' feature). Summarize roster composition (counts by position, common colleges) and pull physical attributes (height) for visual content. Verify jersey numbers and seasons for historical accuracy in editorial/caption copy. Example Queries: SELECT ""Player"", ""No.(s)"", ""Height in Ft."", ""Years for Rockets"", ""School/Club Team/Country"" FROM table_1_11734041_6 WHERE ""Position"" = 'Guard' ORDER BY ""Years for Rockets""; SELECT ""Position"", COUNT(*) AS player_count FROM table_1_11734041_6 GROUP BY ""Position"" ORDER BY player_count DESC; SELECT ""Player"", ""Years for Rockets"", ""School/Club Team/Country"" FROM table_1_11734041_6 WHERE ""Years for Rockets"" LIKE '%2004%' OR ""School/Club Team/Country"" ILIKE '%Maryland%' ORDER BY ""Player"";",reward,,
"Show me the candidate suburbs (settled ≤1966) with population 700–3500, mean household size ≥2.5, median age ≥40 and density <900, including suburb, population, area, density, mean household size, median age, date settled and a practicality score, and also give the average area, average density and total population for suburbs settled by 1966?","
SELECT
  `Suburb`,
  `Population (in 2008)`,
  CAST(`Area (km²)` AS REAL) AS `Area (km²)`,
  `Density (/km²)`,
  CAST(REPLACE(`Mean household size (in 2006)`, ' persons', '') AS REAL) AS `Mean household size (in 2006)`,
  CAST(REPLACE(`Median age (in 2006)`, ' years', '') AS INTEGER) AS `Median age (in 2006)`,
  `Date first settled as a suburb`,
  ROUND(
    (
      `Population (in 2008)` 
      * CAST(REPLACE(`Mean household size (in 2006)`, ' persons', '') AS REAL)
      * CAST(REPLACE(`Median age (in 2006)`, ' years', '') AS REAL)
      * CAST(`Area (km²)` AS REAL)
    ) / (1.0 + `Density (/km²)`),
    3
  ) AS practicality_score,
  (SELECT ROUND(AVG(CAST(`Area (km²)` AS REAL)),3) FROM table_1_1174162_1 WHERE `Date first settled as a suburb` <= 1966) AS `avg_area_settled_<=1966`,
  (SELECT ROUND(AVG(`Density (/km²)`),1) FROM table_1_1174162_1 WHERE `Date first settled as a suburb` <= 1966) AS `avg_density_settled_<=1966`,
  (SELECT SUM(`Population (in 2008)`) FROM table_1_1174162_1 WHERE `Date first settled as a suburb` <= 1966) AS `total_population_settled_<=1966`
FROM table_1_1174162_1
WHERE
  CAST(REPLACE(`Mean household size (in 2006)`, ' persons', '') AS REAL) >= 2.5
  AND `Density (/km²)` < 900
  AND `Date first settled as a suburb` <= 1966
  AND CAST(REPLACE(`Median age (in 2006)`, ' years', '') AS INTEGER) >= 40
  AND `Population (in 2008)` BETWEEN 700 AND 3500
ORDER BY practicality_score DESC;
","SELECT
  col0,
  col1,
  CAST(col4 AS REAL) AS col4,
  col5,
  CAST(REPLACE(col3, ' persons', '') AS REAL) AS col3,
  CAST(REPLACE(col2, ' years', '') AS INTEGER) AS col2,
  col6,
  ROUND(
    (
      col1 
      * CAST(REPLACE(col3, ' persons', '') AS REAL)
      * CAST(REPLACE(col2, ' years', '') AS REAL)
      * CAST(col4 AS REAL)
    ) / (1.0 + col5),
    3
  ) AS practicality_score,
  (SELECT ROUND(AVG(CAST(col4 AS REAL)),3) FROM table_1_1174162_1 WHERE col6 <= 1966) AS `avg_area_settled_<=1966`,
  (SELECT ROUND(AVG(col5),1) FROM table_1_1174162_1 WHERE col6 <= 1966) AS `avg_density_settled_<=1966`,
  (SELECT SUM(col1) FROM table_1_1174162_1 WHERE col6 <= 1966) AS `total_population_settled_<=1966`
FROM table_1_1174162_1
WHERE
  CAST(REPLACE(col3, ' persons', '') AS REAL) >= 2.5
  AND col5 < 900
  AND col6 <= 1986
  AND CAST(REPLACE(col2, ' years', '') AS INTEGER) >= 40
  AND col1 BETWEEN 600 AND 3500
ORDER BY practicality_score DESC;","[('isaacs', 2424.0, 3.1, 781.0, 2.6, 45, 1986.0, 1124.277, 2.633, 1183.8, 17885.0), (""o'malley"", 684.0, 2.6, 263.0, 3.1, 47, 1973.0, 981.488, 2.633, 1183.8, 17885.0)]",table_1_1174162_1,"My persona wants a compact set of candidate suburbs combining demographic filters with the summary context of older suburbs; the voice remains practical and community-focused. The SQL filters for household size ≥2.5, density <900, settled ≤1966, median age ≥40 and population between 700 and 3500, while returning per-suburb fields plus the earlier summary aggregates. The schema fields used are Suburb, Population, Area, Density, Mean household size, Median age, Date first settled and the computed practicality_score, plus avg area, avg density and total population for settled ≤1966. I'll ask for the filtered candidate list with those per-suburb fields and include the three summary stats for the settled-by-1966 set. That keeps the question aligned with the exact query outputs and selection criteria.",persona,"A nocturnal urban mycologist who runs pop-up community mushroom cultivation hubs and uses fine-grained suburban demographics and settlement history to site low-impact production and outreach. Goals: Identify low-density suburbs with older establishment dates (more mature trees and larger gardens) suitable for discreet community mushroom huts. Find suburbs with larger mean household sizes and moderate population so neighbors are likely to share produce and host workshops. Target outreach to areas with older median ages for volunteer operators and custodians, and rank candidate suburbs by practicality (population, area, density). Produce simple summary statistics for suburbs settled before a given year to plan logistics and estimate local demand. Example Queries: SELECT ""Suburb"", ""Population (in 2008)"", ""Area (km²)"", ""Density (/km²)"", ""Mean household size (in 2006)""
FROM table_1_1174162_1
WHERE CAST(REPLACE(""Mean household size (in 2006)"", ' persons', '') AS REAL) >= 2.5
  AND ""Density (/km²)"" < 900
  AND ""Date first settled as a suburb"" <= 1967
ORDER BY ""Population (in 2008)"" DESC; SELECT ""Suburb"", CAST(REPLACE(""Median age (in 2006)"", ' years', '') AS INTEGER) AS median_age
FROM table_1_1174162_1
ORDER BY median_age DESC
LIMIT 3; SELECT AVG(CAST(""Area (km²)"" AS REAL)) AS avg_area_km2,
       AVG(""Density (/km²)"") AS avg_density,
       SUM(""Population (in 2008)"") AS total_population
FROM table_1_1174162_1
WHERE ""Date first settled as a suburb"" < 1965;",reward,,
"List the top 3 Series (Series and Presenters Count) where Presenters Count is the number of the following presenters—Emma Willis, Jamie East, Alice Levine, AJ Odudu, Rylan Clark, Iain Lee—found in the concatenation of the Monday, Tuesday, Wednesday, Thursday, Friday, Saturday and Sunday presenter fields for each Series, grouping by Series and ordering by Presenters Count descending, limit 3?","
SELECT `Series`, ((instr(`Monday`||' '||`Tuesday`||' '||`Wednesday`||' '||`Thursday`||' '||`Friday`||' '||`Saturday`||' '||`Sunday`, 'Emma Willis')>0) + (instr(`Monday`||' '||`Tuesday`||' '||`Wednesday`||' '||`Thursday`||' '||`Friday`||' '||`Saturday`||' '||`Sunday`, 'Jamie East')>0) + (instr(`Monday`||' '||`Tuesday`||' '||`Wednesday`||' '||`Thursday`||' '||`Friday`||' '||`Saturday`||' '||`Sunday`, 'Alice Levine')>0) + (instr(`Monday`||' '||`Tuesday`||' '||`Wednesday`||' '||`Thursday`||' '||`Friday`||' '||`Saturday`||' '||`Sunday`, 'AJ Odudu')>0) + (instr(`Monday`||' '||`Tuesday`||' '||`Wednesday`||' '||`Thursday`||' '||`Friday`||' '||`Saturday`||' '||`Sunday`, 'Rylan Clark')>0) + (instr(`Monday`||' '||`Tuesday`||' '||`Wednesday`||' '||`Thursday`||' '||`Friday`||' '||`Saturday`||' '||`Sunday`, 'Iain Lee')>0)) AS `Presenters Count`
FROM (VALUES
 ('Celebrity Big Brother 8','Emma Willis Jamie East','Emma Willis','Emma Willis','Emma Willis','Emma Willis Jamie East','Alice Levine Jamie East','Alice Levine Jamie East'),
 ('Big Brother 12','Emma Willis Jamie East','Emma Willis','Emma Willis','Emma Willis','Emma Willis Jamie East','Alice Levine Jamie East','Alice Levine Jamie East'),
 ('Celebrity Big Brother 9','Emma Willis Jamie East','Emma Willis','Emma Willis','Emma Willis','Emma Willis Jamie East','Alice Levine Jamie East','Alice Levine Jamie East'),
 ('Big Brother 13','Emma Willis Jamie East','Emma Willis','Emma Willis','Emma Willis','Emma Willis Jamie East','Alice Levine Jamie East','Alice Levine Jamie East'),
 ('Celebrity Big Brother 10','Emma Willis Jamie East','Emma Willis','Emma Willis','Emma Willis','Emma Willis Jamie East','Alice Levine Jamie East','Alice Levine Jamie East'),
 ('Celebrity Big Brother 11','Emma Willis Jamie East','Emma Willis','Emma Willis','Emma Willis','Emma Willis Jamie East','Alice Levine Jamie East','Alice Levine Jamie East'),
 ('Big Brother 14','AJ Odudu Rylan Clark','Emma Willis','Emma Willis','Emma Willis','AJ Odudu Rylan Clark','AJ Odudu Iain Lee','Rylan Clark')
) t(`Series`,`Monday`,`Tuesday`,`Wednesday`,`Thursday`,`Friday`,`Saturday`,`Sunday`)
GROUP BY `Series`
ORDER BY -`Presenters Count`
LIMIT 3;
","SELECT col0, ((instr(col1||' '||col2||' '||col3||' '||col4||' '||col5||' '||col6||' '||col7, 'Emma Willis')>0) + (instr(col1||' '||col2||' '||col3||' '||col4||' '||col5||' '||col6||' '||col7, 'Jamie East')>0) + (instr(col1||' '||col2||' '||col3||' '||col4||' '||col5||' '||col6||' '||col7, 'Alice Levine')>0) + (instr(col1||' '||col2||' '||col3||' '||col4||' '||col5||' '||col6||' '||col7, 'AJ Odudu')>0) + (instr(col1||' '||col2||' '||col3||' '||col4||' '||col5||' '||col6||' '||col7, 'Rylan Clark')>0) + (instr(col1||' '||col2||' '||col3||' '||col4||' '||col5||' '||col6||' '||col7, 'Iain Lee')>0)) AS `Presenters Count`
FROM (
  SELECT 'Celebrity Big Brother 8' AS col0, 'Emma Willis Jamie East' AS col1, 'Emma Willis' AS col2, 'Emma Willis' AS col3, 'Emma Willis' AS col4, 'Emma Willis Jamie East' AS col5, 'Alice Levine Jamie East' AS col6, 'Alice Levine Jamie East' AS col7
  UNION ALL
  SELECT 'Big Brother 12', 'Emma Willis Jamie East', 'Emma Willis', 'Emma Willis', 'Emma Willis', 'Emma Willis Jamie East', 'Alice Levine Jamie East', 'Alice Levine Jamie East'
  UNION ALL
  SELECT 'Celebrity Big Brother 9', 'Emma Willis Jamie East', 'Emma Willis', 'Emma Willis', 'Emma Willis', 'Emma Willis Jamie East', 'Alice Levine Jamie East', 'Alice Levine Jamie East'
  UNION ALL
  SELECT 'Big Brother 13', 'Emma Willis Jamie East', 'Emma Willis', 'Emma Willis', 'Emma Willis', 'Emma Willis Jamie East', 'Alice Levine Jamie East', 'Alice Levine Jamie East'
  UNION ALL
  SELECT 'Celebrity Big Brother 10', 'Emma Willis Jamie East', 'Emma Willis', 'Emma Willis', 'Emma Willis', 'Emma Willis Jamie East', 'Alice Levine Jamie East', 'Alice Levine Jamie East'
  UNION ALL
  SELECT 'Celebrity Big Brother 11', 'Emma Willis Jamie East', 'Emma Willis', 'Emma Willis', 'Emma Willis', 'Emma Willis Jamie East', 'Alice Levine Jamie East', 'Alice Levine Jamie East'
  UNION ALL
  SELECT 'Big Brother 14', 'AJ Odudu Rylan Clark', 'Emma Willis', 'Emma Willis', 'Emma Willis', 'AJ Odudu Rylan Clark', 'AJ Odudu Iain Lee', 'Rylan Clark'
) AS t
GROUP BY col0
ORDER BY `Presenters Count` DESC
LIMIT 3;","[('Big Brother 14', 4), ('Celebrity Big Brother 9', 3), ('Celebrity Big Brother 8', 3)]",table_1_11748792_2,"1) The SQL returns Series and a computed Presenters Count that sums presence flags for six names across the seven daily columns, grouped by Series and limited to three highest counts. 2) Map Series and the seven day columns to the show and its daily presenters, and the presenter's list to the six specific names. 3) Pose a question requesting Series and the Presenters Count defined as the number of those six names appearing in the combined Monday–Sunday fields, then ask for the top 3 by that count. 4) This captures all columns, the six name checks, aggregation, ordering and limit.",reserved,9,reward,,
Which countries with below-average GDP per capita should be prioritized — show the top three by population?,"
SELECT '`' || `Country` || '`' AS `Country`,
`Population` AS `Population_raw`,
`Area (km²)`,
(REPLACE(`GDP per capita (nominal)`, '$', '') + 0) AS `GDP_per_capita_num`,
CASE WHEN (REPLACE(`GDP per capita (nominal)`, '$', '') + 0) < (SELECT AVG(REPLACE(`GDP per capita (nominal)`, '$', '') + 0) FROM `table_1_11780179_1`) THEN '`Priority`' ELSE '`Stable`' END AS `Recommendation`
FROM `table_1_11780179_1`
WHERE (REPLACE(`GDP per capita (nominal)`, '$', '') + 0) < (SELECT AVG(REPLACE(`GDP per capita (nominal)`, '$', '') + 0) FROM `table_1_11780179_1`) AND `Area (km²)` IS `Area (km²)`
GROUP BY `Country`
ORDER BY `Population` DESC
LIMIT 3;
","
SELECT '`' || col0 || '`' AS col0,
col1 AS `Population_raw`,
col2,
(REPLACE(col4, '$', '') + 0) AS `GDP_per_capita_num`,
CASE WHEN (REPLACE(col4, '$', '') + 0) < (SELECT AVG(REPLACE(col4, '$', '') + 0) FROM `table_1_11780179_1`) THEN '`Priority`' ELSE '`Stable`' END AS `Recommendation`
FROM `table_1_11780179_1`
WHERE (REPLACE(col4, '$', '') + 0) < (SELECT AVG(REPLACE(col4, '$', '') + 0) FROM `table_1_11780179_1`) AND col2 IS col2
GROUP BY col0
ORDER BY col1 DESC
LIMIT 3;
","[('`uzbekistan`', 29559100.0, 447400.0, 1, '`Priority`'), ('`kazakhstan`', 16967000.0, 2724900.0, 11, '`Priority`'), ('`kyrgyzstan`', 5550239.0, 199900.0, 1, '`Priority`')]",table_1_11780179_1,"STEP 1: Parse the SQL intent — find countries whose GDP per capita (numeric) is below the table-wide average, compute numeric GDP per capita, mark them 'Priority', then order those results by Population descending and return the top 3. STEP 2: Determine ambiguity type — scope ambiguity fits: it's unclear whether the 'top three by population' applies to the entire table first or to the subset of below-average-GDP-per-capita countries. STEP 3: Draft the question — produce a natural-language question that matches one valid reading of the SQL but is ambiguous in that scope. STEP 4: Explain the ambiguity — the SQL interprets the scope as filtering for below-average GDP per capita first, then taking the top three by population; a different interpretation would take the top three most populous countries overall and then ask which of those have below-average GDP per capita (or should be prioritized).",reserved,24,reward,,"type: Scope ambiguity | explanation: The ambiguity is whether 'top three by population' applies after filtering for below-average GDP per capita (the SQL's interpretation: top three among the below-average group) or before filtering (an alternate reading: the top three most populous countries overall, then check which of those are below average and prioritized)."
"List the top 30 hotspot units for targeted survey—include unit, commander, parsed reported strength, killed/wounded/missing, total casualties, casualty density, artillery flag, artifact-priority score, wounded-to-killed ratio, and any anomaly, with anomalous units surfaced first?","
WITH parsed AS (
  SELECT
    `Unit`,
    `Commander`,
    `Complement`,
    -- extract total_strength: number after 'off ' and before next space (usually before 'men')
    CASE 
      WHEN instr(`Complement`, 'off ') > 0 THEN CAST(
        substr(
          substr(`Complement`, instr(`Complement`, 'off ')+4),
          1,
          CASE 
            WHEN instr(substr(`Complement`, instr(`Complement`, 'off ')+4), ' ')>0 
              THEN instr(substr(`Complement`, instr(`Complement`, 'off ')+4), ' ')-1 
            ELSE length(substr(`Complement`, instr(`Complement`, 'off ')+4)) 
          END
        ) AS INTEGER
      )
      ELSE NULL
    END AS total_strength,
    -- extract killed_num: number before ' off'
    CASE 
      WHEN instr(`Killed`, ' off')>0 THEN CAST(trim(substr(`Killed`,1,instr(`Killed`,' off')-1)) AS INTEGER)
      ELSE CAST(trim(`Killed`) AS INTEGER)
    END AS killed_num,
    -- extract wounded_num
    CASE 
      WHEN instr(`Wounded`, ' off')>0 THEN CAST(trim(substr(`Wounded`,1,instr(`Wounded`,' off')-1)) AS INTEGER)
      ELSE CAST(trim(`Wounded`) AS INTEGER)
    END AS wounded_num,
    -- extract missing_num
    CASE 
      WHEN instr(`Missing`, ' off')>0 THEN CAST(trim(substr(`Missing`,1,instr(`Missing`,' off')-1)) AS INTEGER)
      ELSE CAST(trim(`Missing`) AS INTEGER)
    END AS missing_num
  FROM `table_1_11793221_2`
),
scored AS (
  SELECT
    `Unit`,
    `Commander`,
    `Complement`,
    total_strength,
    COALESCE(killed_num,0) AS killed_num,
    COALESCE(wounded_num,0) AS wounded_num,
    COALESCE(missing_num,0) AS missing_num,
    -- total casualties absolute
    (COALESCE(killed_num,0) + COALESCE(wounded_num,0) + COALESCE(missing_num,0)) AS total_casualties,
    -- casualty density relative to reported strength
    CASE WHEN total_strength IS NULL OR total_strength=0 THEN NULL
         ELSE ROUND( (COALESCE(killed_num,0) + COALESCE(wounded_num,0) + COALESCE(missing_num,0)) * 1.0 / total_strength, 4)
    END AS casualty_density,
    -- identify artillery / organic gun detachments from Unit or Complement text
    CASE 
      WHEN `Unit` LIKE '%Battery%' OR `Complement` LIKE '%guns%' OR `Complement` LIKE '%Howitzer%' OR `Complement` LIKE '%gun%' OR `Unit` LIKE '%Battery R.F.A.%' OR `Unit` LIKE '%KGL%' THEN 1
      ELSE 0
    END AS artillery_flag,
    -- wounded-to-killed ratio (NULL when killed=0 to highlight ambulance/evacuation anomalies)
    CASE WHEN COALESCE(killed_num,0)=0 THEN NULL
         ELSE ROUND( CAST(COALESCE(wounded_num,0) AS REAL) / COALESCE(killed_num,1), 2)
    END AS wounded_to_killed_ratio,
    -- simple artifact-priority score: weights casualties, artillery multiplies priority, and increases with casualty density
    ROUND(
      ( (COALESCE(killed_num,0) + COALESCE(wounded_num,0) + COALESCE(missing_num,0)) * (1.0 + 1.5 * CASE WHEN ( `Unit` LIKE '%Battery%' OR `Complement` LIKE '%guns%' OR `Complement` LIKE '%Howitzer%' ) THEN 1 ELSE 0 END) )
      * (1.0 + COALESCE( (COALESCE(killed_num,0) + COALESCE(wounded_num,0) + COALESCE(missing_num,0)) * 1.0 / NULLIF(total_strength,0), 0) ),
    4) AS artifact_score,
    -- anomaly reasons: high wounded-to-killed, any missing, or killed=0 with wounded>0
    CASE 
      WHEN COALESCE(missing_num,0) > 0 THEN 'missing_reported'
      WHEN COALESCE(killed_num,0)=0 AND COALESCE(wounded_num,0)>0 THEN 'zero_killed_nonzero_wounded'
      WHEN COALESCE(killed_num,0)>0 AND CAST(COALESCE(wounded_num,0) AS REAL)/COALESCE(killed_num,1) > 5 THEN 'very_high_wounded_to_killed'
      ELSE NULL
    END AS anomaly_flag
  FROM parsed
)
SELECT
  `Unit`,
  `Commander`,
  total_strength,
  killed_num,
  wounded_num,
  missing_num,
  total_casualties,
  casualty_density,
  artillery_flag,
  artifact_score,
  wounded_to_killed_ratio,
  anomaly_flag
FROM scored
-- Prioritise by artifact score but always surface anomalous casualty-signature units at top
ORDER BY CASE WHEN anomaly_flag IS NOT NULL THEN 1 ELSE 0 END DESC, artifact_score DESC
LIMIT 30;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    CASE 
      WHEN instr(col2, 'off ') > 0 THEN CAST(
        substr(
          substr(col2, instr(col2, 'off ')+4),
          1,
          CASE 
            WHEN instr(substr(col2, instr(col2, 'off ')+4), ' ')>0 
              THEN instr(substr(col2, instr(col2, 'off ')+4), ' ')-1 
            ELSE length(substr(col2, instr(col2, 'off ')+4)) 
          END
        ) AS INTEGER
      )
      ELSE NULL
    END AS total_strength,
    CASE 
      WHEN instr(col3, ' off')>0 THEN CAST(trim(substr(col3,1,instr(col3,' off')-1)) AS INTEGER)
      ELSE CAST(trim(col3) AS INTEGER)
    END AS killed_num,
    CASE 
      WHEN instr(col4, ' off')>0 THEN CAST(trim(substr(col4,1,instr(col4,' off')-1)) AS INTEGER)
      ELSE CAST(trim(col4) AS INTEGER)
    END AS wounded_num,
    CASE 
      WHEN instr(col5, ' off')>0 THEN CAST(trim(substr(col5,1,instr(col5,' off')-1)) AS INTEGER)
      ELSE CAST(trim(col5) AS INTEGER)
    END AS missing_num
  FROM `table_1_11793221_2`
)
SELECT
  col0,
  col1,
  col2,
  total_strength,
  killed_num,
  wounded_num,
  missing_num,
  (COALESCE(killed_num,0) + COALESCE(wounded_num,0) + COALESCE(missing_num,0)) AS total_casualties,
  CASE WHEN total_strength IS NULL OR total_strength=0 THEN NULL
       ELSE ROUND( (COALESCE(killed_num,0) + COALESCE(wounded_num,0) + COALESCE(missing_num,0)) * 1.0 / total_strength, 4)
  END AS casualty_density,
  CASE 
    WHEN col0 LIKE '%Battery%' OR col2 LIKE '%guns%' OR col2 LIKE '%Howitzer%' OR col2 LIKE '%gun%' OR col0 LIKE '%Battery R.F.A.%' OR col0 LIKE '%KGL%' THEN 1
    ELSE 0
  END AS artillery_flag,
  ROUND(
    ( (COALESCE(killed_num,0) + COALESCE(wounded_num,0) + COALESCE(missing_num,0)) * (1.0 + 1.5 * CASE WHEN (col0 LIKE '%Battery%' OR col2 LIKE '%guns%' OR col2 LIKE '%Howitzer%') THEN 1 ELSE 0 END) )
    * (1.0 + CASE WHEN total_strength IS NULL OR total_strength=0 THEN 0 ELSE (COALESCE(killed_num,0) + COALESCE(wounded_num,0) + COALESCE(missing_num,0)) * 1.0 / total_strength END)
  ,4) AS artifact_score,
  CASE WHEN COALESCE(killed_num,0)=0 THEN NULL
       ELSE ROUND(CAST(COALESCE(wounded_num,0) AS REAL) / COALESCE(killed_num,1), 2)
  END AS wounded_to_killed_ratio,
  CASE 
    WHEN COALESCE(missing_num,0) > 0 THEN 'missing_reported'
    WHEN COALESCE(killed_num,0)=0 AND COALESCE(wounded_num,0)>0 THEN 'zero_killed_nonzero_wounded'
    WHEN COALESCE(killed_num,0)>0 AND CAST(COALESCE(wounded_num,0) AS REAL)/COALESCE(killed_num,1) > 5 THEN 'very_high_wounded_to_killed'
    ELSE NULL
  END AS anomaly_flag
FROM parsed
ORDER BY CASE WHEN anomaly_flag IS NOT NULL THEN 1 ELSE 0 END DESC, artifact_score DESC
LIMIT 30;","[('1st hanoverian brigade', 'major-general friedrich, graf von kielmansegge', '127 off 3189 men', 3189, 0, 10, 1, 11, 0.0034, 0, 11.0379, None, 'missing_reported'), ('quarter-master-general', 'major-general jean victor de constant rebecque', '20 off 126 men', 126, 1, 8, 0, 9, 0.0714, 0, 9.6429, 8.0, 'very_high_wounded_to_killed'), ('light battalion lüneburg', 'lieutenant colonel august von klencke', '22 off 595 men', 595, 0, 3, 1, 4, 0.0067, 0, 4.0269, None, 'missing_reported'), ('light battalion grubenhagen', 'lieutenant colonel baron friedrich von wurmb', '22 off 621 men', 621, 0, 4, 0, 4, 0.0064, 0, 4.0258, None, 'zero_killed_nonzero_wounded'), (""field battalion 1st duke of york's osnabrück"", 'friedrich wilhelm freiherr von bülow', '25 off 607 men', 607, 0, 2, 0, 2, 0.0033, 0, 2.0066, None, 'zero_killed_nonzero_wounded'), ('field battalion bremen', 'lieutenant colonel wilhelm von langrehre', '21 off 512 men', 512, 0, 1, 0, 1, 0.002, 0, 1.002, None, 'zero_killed_nonzero_wounded'), ('27th light battalion (bataljon jagers no. 27)', 'luitenant-kolonel johann willem grunebosch', '23 off 739 men', 739, 0, 1, 0, 1, 0.0014, 0, 1.0014, None, 'zero_killed_nonzero_wounded'), ('1st battalion (1e bataljon)', 'kapitein moritz büsgen', '27 off 835 men', 835, 0, 1, 0, 1, 0.0012, 0, 1.0012, None, 'zero_killed_nonzero_wounded'), ('3rd battalion (3e bataljon)', 'majoor gottfried hechmann', '27 off 819 men', 819, 0, 1, 0, 1, 0.0012, 0, 1.0012, None, 'zero_killed_nonzero_wounded'), ('5th brigade', 'major-general sir colin halkett k.c.b.', '173 off 2059 men', 2059, 5, 15, 0, 20, 0.0097, 0, 20.1943, 3.0, None), ('1st brigade', 'major-general peregrine maitland', '78 off 1901 men', 1901, 5, 9, 0, 14, 0.0074, 0, 14.1031, 1.8, None), ('1st division', 'major-general george cooke', '175 off 4155 men', 4155, 5, 9, 0, 14, 0.0034, 0, 14.0472, 1.8, None), ('1st brigade (1e brigade)', 'generaal-majoor willem frederik van bylandt', '121 off 3216 men', 3216, 2, 6, 0, 8, 0.0025, 0, 8.0199, 3.0, None), ('3rd battalion, 1st regiment of foot guards', 'lieutenant colonel the honourable william stewart', '40 off 982 men', 982, 2, 5, 0, 7, 0.0071, 0, 7.0499, 2.5, None), ('2nd battalion, 1st regiment of foot guards', 'lieutenant colonel henry askew', '35 off 919 men', 919, 2, 4, 0, 6, 0.0065, 0, 6.0392, 2.0, None), ('2nd battalion, 73rd regiment of foot', 'lieutenant-colonel william george harris', '39 off 471 men', 471, 1, 3, 0, 4, 0.0085, 0, 4.034, 3.0, None), ('2nd battalion (2e bataljon)', 'majoor philipp von normann', '25 off 819 men', 819, 1, 2, 0, 3, 0.0037, 0, 3.011, 2.0, None), ('2nd brigade', 'major-general sir john byng, 1st earl of strafford', '79 off 1939 men', 1939, 0, 0, 0, 0, 0.0, 0, 0.0, None, None), ('2nd battalion, coldstream regiment of foot guards', 'lieutenant-colonel james macdonnell', '36 off 896 men', 896, 0, 0, 0, 0, 0.0, 0, 0.0, None, None), ('2nd battalion, 3rd regiment of foot guards', 'lieutenant colonel francis hepburn', '40 off 1043 men', 1043, 0, 0, 0, 0, 0.0, 0, 0.0, None, None), ('artillery', 'lieutenant-colonel steven galway adye', '14 off 401 men', 401, 0, 0, 0, 0, 0.0, 0, 0.0, None, None), (""kuhlmann's battery kglha, king's german legion"", 'captain heinrich jacob kuhlmann', '8 off 302 men 5x9lb guns 1x5.5inch howitzer', 302, 0, 0, 0, 0, 0.0, 1, 0.0, None, None), ('field battalion verden', 'major julius von schkopp', '26 off 533 men', 533, 0, 0, 0, 0, 0.0, 0, 0.0, None, None), ('field jaeger battalion (two companies)', 'captain de reden', '10 off 321 men', 321, 0, 0, 0, 0, 0.0, 0, 0.0, None, None), ('3rd division artillery', 'lieutenant colonel john samuel williamson', '13 off 225 men', 225, 0, 0, 0, 0, 0.0, 0, 0.0, None, None), (""lloyd's battery r.f.a."", 'major william lloyd', '5 off 93 men, 5x9lb guns 1x5.5inch howitzer', 93, 0, 0, 0, 0, 0.0, 1, 0.0, None, None), (""cleeves' battery kglfa king's german legion"", 'captain andreas cleeves', '6 off 132 men, 5x9lb guns 1x5.5inch howitzer', 132, 0, 0, 0, 0, 0.0, 1, 0.0, None, None), ('train (trein)', 'luitenant frederik van gahlen', '2 off 126 men', 126, 0, 0, 0, 0, 0.0, 0, 0.0, None, None), ('1st battalion (1e bataljon)', 'luitenant-kolonel wilhelm ferdinand von dressel', '28 off 835 men', 835, 0, 0, 0, 0, 0.0, 0, 0.0, None, None), ('2nd battalion (2e bataljon)', 'majoor christian philipp schleyer', '22 off 637 men', 637, 0, 0, 0, 0, 0.0, 0, 0.0, None, None)]",table_1_11793221_2,"I often need a single ranked list of likely artifact hotspots that blends absolute casualties, casualty density, and artillery presence; my phrasing will mix archaeological priorities with casualty metrics. The SQL computes total casualties, casualty_density relative to parsed strength, flags artillery, computes a weighted artifact_score, wounded-to-killed ratio (null when killed=0), and anomaly flags, then orders anomalies first and by artifact_score. Draft question: request the top 30 hotspot units with unit, commander, parsed strength, casualty breakdown, casualty_density, artillery flag, artifact_score, wounded-to-killed ratio, and any anomaly, anomalies first. Validate: this mirrors the query's metrics, scoring, anomaly logic, ordering and row limit.",persona,"A battlefield archaeologist who models likely artifact-density hotspots from Napoleonic-era unit strengths and casualty patterns to guide targeted metal-detection surveys. Goals: Identify units and map locations (by unit deployment) that likely left high concentrations of material culture (weapons, personal kit, shrapnel) based on absolute casualties and casualty density relative to unit size. Find artillery batteries and units with organic gun detachments to prioritize areas with spent shot, shell fragments, and artillery fittings. Spot anomalous casualty signatures (very high wounded-to-killed ratios or unusually many missing) that indicate likely ambulance/evacuation routes, burial pits, or dispersed battlefield losses for survey planning. Example Queries: /* 1) Extract numeric strengths and casualty counts for units that include guns/howitzers so we can prioritise artillery loci */
SELECT
  Unit,
  Commander,
  Complement,
  CAST(REGEXP_REPLACE(Complement, '.*off (\\d+) men.*', '\\1') AS INTEGER) AS total_strength,
  CAST(REGEXP_REPLACE(Killed, '^(\\d+) off .*', '\\1') AS INTEGER) AS killed_num,
  CAST(REGEXP_REPLACE(Wounded, '^(\\d+) off .*', '\\1') AS INTEGER) AS wounded_num,
  CAST(REGEXP_REPLACE(Missing, '^(\\d+) off .*', '\\1') AS INTEGER) AS missing_num
FROM table_1_11793221_2
WHERE Complement ILIKE '%gun%' OR Complement ILIKE '%Howitzer%' OR Complement ILIKE '%guns%'; /* 2) Rank units by casualty density (total casualties / unit strength) to find likely artifact hotspots */
WITH parsed AS (
  SELECT
    Unit,
    Commander,
    CAST(REGEXP_REPLACE(Complement, '.*off (\\d+) men.*', '\\1') AS INTEGER) AS total_strength,
    COALESCE(CAST(REGEXP_REPLACE(Killed, '^(\\d+) off .*', '\\1') AS INTEGER),0) AS killed_num,
    COALESCE(CAST(REGEXP_REPLACE(Wounded, '^(\\d+) off .*', '\\1') AS INTEGER),0) AS wounded_num,
    COALESCE(CAST(REGEXP_REPLACE(Missing, '^(\\d+) off .*', '\\1') AS INTEGER),0) AS missing_num
  FROM table_1_11793221_2
)
SELECT
  Unit,
  Commander,
  total_strength,
  (killed_num + wounded_num + missing_num) AS total_casualties,
  ROUND( (killed_num + wounded_num + missing_num)::numeric / NULLIF(total_strength,0), 4) AS casualty_density
FROM parsed
ORDER BY casualty_density DESC
LIMIT 10; /* 3) Find units with anomalous wounded-to-killed ratio or any missing reported (possible ambulance routes/temporary burial sites) */
WITH p AS (
  SELECT
    Unit,
    Commander,
    COALESCE(CAST(REGEXP_REPLACE(Killed, '^(\\d+) off .*', '\\1') AS INTEGER),0) AS k,
    COALESCE(CAST(REGEXP_REPLACE(Wounded, '^(\\d+) off .*', '\\1') AS INTEGER),0) AS w,
    COALESCE(CAST(REGEXP_REPLACE(Missing, '^(\\d+) off .*', '\\1') AS INTEGER),0) AS m
  FROM table_1_11793221_2
)
SELECT
  Unit,
  Commander,
  k AS killed,
  w AS wounded,
  m AS missing,
  CASE WHEN k = 0 AND w > 0 THEN NULL ELSE ROUND(CAST(w AS numeric) / NULLIF(k,0), 2) END AS wounded_to_killed_ratio
FROM p
WHERE (k = 0 AND w > 0) OR (k > 0 AND CAST(w AS numeric)/k > 5) OR m > 0
ORDER BY wounded_to_killed_ratio DESC NULLS FIRST;",reward,,
"For each Unit, calculate 100 * (((the number before ' off ' in Killed) + (the number after ' off ' in Killed but before ' men')) + ((the number before ' off ' in Wounded) + (the number after ' off ' in Wounded but before ' men')) + ((the number before ' off ' in Missing) + (the number after ' off ' in Missing but before ' men'))) / (the number after ' off ' in Complement but before ' men'), and list the Unit and that percentage only for Units where that percentage > 5 and the Complement men (the number after ' off ' in Complement but before ' men') > 500?","
SELECT '`' || `Unit` || '`',
(
(
 (substr(`Killed`,1,instr(`Killed`,' off ')-1)+0)
 + (substr(`Killed`,instr(`Killed`,' off ')+5,(instr(`Killed`,' men')+instr(`Killed`,' man'))-(instr(`Killed`,' off ')+5))+0)
 + (substr(`Wounded`,1,instr(`Wounded`,' off ')-1)+0)
 + (substr(`Wounded`,instr(`Wounded`,' off ')+5,(instr(`Wounded`,' men')+instr(`Wounded`,' man'))-(instr(`Wounded`,' off ')+5))+0)
 + (substr(`Missing`,1,instr(`Missing`,' off ')-1)+0)
 + (substr(`Missing`,instr(`Missing`,' off ')+5,(instr(`Missing`,' men')+instr(`Missing`,' man'))-(instr(`Missing`,' off ')+5))+0)
)
/
(
 substr(`Complement`,instr(`Complement`,' off ')+5,(instr(`Complement`,' men')+instr(`Complement`,' man'))-(instr(`Complement`,' off ')+5))+0
)
) * 100
FROM `table_1_11793221_4`
WHERE
(
(
 (substr(`Killed`,1,instr(`Killed`,' off ')-1)+0)
 + (substr(`Killed`,instr(`Killed`,' off ')+5,(instr(`Killed`,' men')+instr(`Killed`,' man'))-(instr(`Killed`,' off ')+5))+0)
 + (substr(`Wounded`,1,instr(`Wounded`,' off ')-1)+0)
 + (substr(`Wounded`,instr(`Wounded`,' off ')+5,(instr(`Wounded`,' men')+instr(`Wounded`,' man'))-(instr(`Wounded`,' off ')+5))+0)
 + (substr(`Missing`,1,instr(`Missing`,' off ')-1)+0)
 + (substr(`Missing`,instr(`Missing`,' off ')+5,(instr(`Missing`,' men')+instr(`Missing`,' man'))-(instr(`Missing`,' off ')+5))+0)
)
/
(
 substr(`Complement`,instr(`Complement`,' off ')+5,(instr(`Complement`,' men')+instr(`Complement`,' man'))-(instr(`Complement`,' off ')+5))+0
)
) > 5
AND
(
 substr(`Complement`,instr(`Complement`,' off ')+5,(instr(`Complement`,' men')+instr(`Complement`,' man'))-(instr(`Complement`,' off ')+5))+0
) > 500;
","SELECT col0, (
(
 (substr(replace(col3,' man',' men'), instr(replace(col3,' man',' men'),' off ')+5, instr(replace(col3,' man',' men'),' men') - (instr(replace(col3,' man',' men'),' off ')+5)) + 0)
 + (substr(replace(col4,' man',' men'), instr(replace(col4,' man',' men'),' off ')+5, instr(replace(col4,' man',' men'),' men') - (instr(replace(col4,' man',' men'),' off ')+5)) + 0)
 + (substr(replace(col5,' man',' men'), instr(replace(col5,' man',' men'),' off ')+5, instr(replace(col5,' man',' men'),' men') - (instr(replace(col5,' man',' men'),' off ')+5)) + 0)
)
* 100.0
/
(
 substr(replace(col2,' man',' men'), instr(replace(col2,' man',' men'),' off ')+5, instr(replace(col2,' man',' men'),' men') - (instr(replace(col2,' man',' men'),' off ')+5)) + 0
)
) AS `Percent`
FROM `table_1_11793221_4`
WHERE
(
 substr(replace(col2,' man',' men'), instr(replace(col2,' man',' men'),' off ')+5, instr(replace(col2,' man',' men'),' men') - (instr(replace(col2,' man',' men'),' off ')+5)) + 0
) > 0;","[('5th division', 13.397328881469114), ('8th brigade', 25.12776831345826), ('1st battalion, 32nd (cornwall) regiment of foot', 28.760330578512395), ('79th regiment of foot (cameron highlanders)', 43.59756097560975), ('9th brigade', 39.943741209563996), ('2nd battalion, 44th (east essex) regiment of foot', 28.337236533957846), ('92nd regiment of foot (gordon highlanders)', 45.95070422535211), ('4th hanoverian brigade', 3.355155482815057), ('landwehr battalion lüneberg', 2.7491408934707904), ('landwehr battalion munden', 5.593220338983051), ('landwehr battalion osterode', 0.644122383252818)]",table_1_11793221_4,"1) Parse intent: compute total casualties by summing officer and men counts from Killed, Wounded and Missing, divide by the Complement's men count and multiply by 100, then filter by >5% and Complement men >500. 2) Map schema: extraction uses the substring before ' off ' and the substring between ' off ' and ' men' (or ' man'). 3) Draft: request Unit and computed percent for units meeting both thresholds. 4) Validate: include explicit mention of Killed, Wounded, Missing, Complement, extraction rules, arithmetic and both WHERE conditions.",reserved,4,reward,,
"For each River Cottage DVD, show how many releases came out in the same year and how many share the same aspect ratio, and tell me whether that release’s runtime is at/above or below the average runtime for its release year?","
SELECT
  `DVD Name`,
  `Released`,
  substr(`Released`, 7, 4) AS `release_year`,
  `Audio`,
  `Aspect Ratio`,
  `Duration`,
  (
    CAST(substr(`Duration`, 1, instr(`Duration`, ' hours') - 1) AS INTEGER) * 60
    + CAST(trim(substr(`Duration`, instr(`Duration`, ' hours') + 7, instr(`Duration`, ' minutes') - (instr(`Duration`, ' hours') + 7))) AS INTEGER)
  ) AS total_minutes,
  `Number of Episodes`,
  `Num of Discs`,
  CASE WHEN `Num of Discs` > 1 THEN 'multi-disc' ELSE 'single-disc' END AS `disc_type`,
  AVG(`Number of Episodes`) OVER (PARTITION BY substr(`Released`, 7, 4)) AS `avg_episodes_per_year`,
  AVG(`Number of Episodes`) OVER (PARTITION BY `Aspect Ratio`) AS `avg_episodes_per_aspect`,
  COUNT(*) OVER (PARTITION BY substr(`Released`, 7, 4)) AS `releases_per_year`,
  COUNT(*) OVER (PARTITION BY `Aspect Ratio`) AS `releases_per_aspect`,
  RANK() OVER (PARTITION BY substr(`Released`, 7, 4) ORDER BY (
    CAST(substr(`Duration`, 1, instr(`Duration`, ' hours') - 1) AS INTEGER) * 60
    + CAST(trim(substr(`Duration`, instr(`Duration`, ' hours') + 7, instr(`Duration`, ' minutes') - (instr(`Duration`, ' hours') + 7))) AS INTEGER)
  ) DESC) AS `runtime_rank_in_year`,
  CASE
    WHEN (
      CAST(substr(`Duration`, 1, instr(`Duration`, ' hours') - 1) AS INTEGER) * 60
      + CAST(trim(substr(`Duration`, instr(`Duration`, ' hours') + 7, instr(`Duration`, ' minutes') - (instr(`Duration`, ' hours') + 7))) AS INTEGER)
    ) >= AVG(
      CAST(substr(`Duration`, 1, instr(`Duration`, ' hours') - 1) AS INTEGER) * 60
      + CAST(trim(substr(`Duration`, instr(`Duration`, ' hours') + 7, instr(`Duration`, ' minutes') - (instr(`Duration`, ' hours') + 7))) AS INTEGER)
    ) OVER (PARTITION BY substr(`Released`, 7, 4))
    THEN '>= year runtime avg' ELSE '< year runtime avg' END AS `runtime_vs_year_avg`
FROM `table_1_1180228_1`
ORDER BY total_minutes DESC, `Num of Discs` DESC, `release_year` ASC;
","
SELECT
  col0,
  col1,
  substr(col1, 7, 4) AS `release_year`,
  col2,
  col3,
  col4,
  (
    CAST(substr(col4, 1, instr(col4, ' hours') - 1) AS INTEGER) * 60
    + CAST(trim(substr(col4, instr(col4, ' hours') + 7, instr(col4, ' minutes') - (instr(col4, ' hours') + 7))) AS INTEGER)
  ) AS total_minutes,
  col5,
  col6,
  CASE WHEN col6 > 1 THEN 'multi-disc' ELSE 'single-disc' END AS `disc_type`,
  AVG(col5) OVER (PARTITION BY substr(col1, 7, 4)) AS `avg_episodes_per_year`,
  AVG(col5) OVER (PARTITION BY col3) AS `avg_episodes_per_aspect`,
  COUNT(*) OVER (PARTITION BY substr(col1, 7, 4)) AS `releases_per_year`,
  COUNT(*) OVER (PARTITION BY col3) AS `releases_per_aspect`,
  RANK() OVER (PARTITION BY substr(col1, 7, 4) ORDER BY (
    CAST(substr(col4, 1, instr(col4, ' hours') - 1) AS INTEGER) * 60
    + CAST(trim(substr(col4, instr(col4, ' hours') + 7, instr(col4, ' minutes') - (instr(col4, ' hours') + 7))) AS INTEGER)
  ) DESC) AS `runtime_rank_in_year`,
  CASE
    WHEN (
      CAST(substr(col4, 1, instr(col4, ' hours') - 1) AS INTEGER) * 60
      + CAST(trim(substr(col4, instr(col4, ' hours') + 7, instr(col4, ' minutes') - (instr(col4, ' hours') + 7))) AS INTEGER)
    ) >= AVG(
      CAST(substr(col4, 1, instr(col4, ' hours') - 1) AS INTEGER) * 60
      + CAST(trim(substr(col4, instr(col4, ' hours') + 7, instr(col4, ' minutes') - (instr(col4, ' hours') + 7))) AS INTEGER)
    ) OVER (PARTITION BY substr(col1, 7, 4))
    THEN '>= year runtime avg' ELSE '< year runtime avg' END AS `runtime_vs_year_avg`
FROM `table_1_1180228_1`
ORDER BY total_minutes DESC, col6 DESC, `release_year` ASC;
","[('beyond river cottage', '17/10/2005', '2005', 'dolby digital 2.0', '16:9 anamorphic', '4 hours 40 minutes', 280, 10.0, 3.0, 'multi-disc', 10.0, 5.125, 1, 8, 1, '>= year runtime avg'), ('river cottage forever', '11/10/2004', '2004', 'dolby digital 2.0', '16:9 anamorphic', '3 hours 42 minutes', 222, 8.0, 2.0, 'multi-disc', 7.0, 5.125, 2, 8, 1, '>= year runtime avg'), ('river cottage - autumn', '12/10/2009', '2009', 'dolby digital 2.0', '16:9 anamorphic', '3 hours 11 minutes', 191, 4.0, 1.0, 'single-disc', 4.0, 5.125, 1, 8, 1, '>= year runtime avg'), ('river cottage - spring', '27/10/2008', '2008', 'dolby digital 2.0', '16:9 anamorphic', '3 hours 7 minutes', 187, 4.0, 1.0, 'single-disc', 4.0, 5.125, 1, 8, 1, '>= year runtime avg'), (""river cottage - summer's here"", '01/08/2011', '2011', 'dolby digital 2.0', '16:9 anamorphic', '3 hours 5 minutes', 185, 4.0, 1.0, 'single-disc', 4.0, 5.125, 1, 8, 1, '>= year runtime avg'), ('escape to river cottage', '08/09/2003', '2003', 'dolby digital 2.0', '4:3 full frame', '2 hours 48 minutes', 168, 6.0, 2.0, 'multi-disc', 6.0, 6.0, 1, 1, 1, '>= year runtime avg'), ('return to river cottage', '19/04/2004', '2004', 'dolby digital 2.0', '16:9 anamorphic', '2 hours 28 minutes', 148, 6.0, 2.0, 'multi-disc', 7.0, 5.125, 2, 8, 2, '< year runtime avg'), ('river cottage - gone fishing!', '03/12/2007', '2007', 'dolby digital 2.0', '16:9 anamorphic', '2 hours 22 minutes', 142, 3.0, 1.0, 'single-disc', 3.0, 5.125, 1, 8, 1, '>= year runtime avg'), ('river cottage road trip', '02/10/2006', '2006', 'dolby digital 2.0', '16:9 anamorphic', '2 hours 5 minutes', 125, 2.0, 1.0, 'single-disc', 2.0, 5.125, 1, 8, 1, '>= year runtime avg')]",table_1_1180228_1,"I need counts to plan bundles and promos but won't use SQL terms; I'll ask for how many releases share a year or format plus runtime comparison to the year average. The query returns counts of releases per year and per aspect ratio, plus a per-year runtime comparison label and a runtime rank. The schema gives Released, Aspect Ratio and Duration parsed to minutes. Draft question: ask for each release the number of releases in the same year and in the same aspect ratio, and whether its runtime is above or below that year’s average. Validate: this stays within the query's computed fields and doesn't request extra data.",persona,"Home entertainment product manager for a DVD retailer responsible for acquiring, pricing and merchandising physical releases; uses this database to evaluate River Cottage DVD catalogue for stocking and promotional decisions. Goals: Identify which River Cottage DVDs are multi-disc or have the longest runtimes to inform pricing and shelf placement. Compare releases by format/aspect ratio and release year to decide which editions to stock for different customer segments. Assess episode counts and average episodes-per-release to plan box-set bundles and promotional copy. Example Queries: SELECT ""DVD Name"", ""Released"", ""Num of Discs"", ""Duration"" 
FROM table_1_1180228_1 
WHERE ""Num of Discs"" > 1 
ORDER BY ""Num of Discs"" DESC, ""Released""; SELECT YEAR(STR_TO_DATE(""Released"", '%d/%m/%Y')) AS release_year, COUNT(*) AS releases, AVG(""Number of Episodes"") AS avg_episodes
FROM table_1_1180228_1
GROUP BY release_year
ORDER BY release_year; SELECT ""DVD Name"", ""Duration"", (
  CAST(SUBSTRING_INDEX(""Duration"", ' hours', 1) AS UNSIGNED) * 60
  + CAST(REPLACE(SUBSTRING_INDEX(""Duration"", ' hours ', -1), ' minutes', '') AS UNSIGNED)
) AS total_minutes
FROM table_1_1180228_1
ORDER BY total_minutes DESC
LIMIT 5;",reward,,
"For each director (`Directed by`) who directed more than one episode (COUNT(Title) > 1) and only considering episodes with `U.S. viewers (millions)` > 2.5 and `No. in season` > 0, what is the director's name, the count of titles they directed, the average `U.S. viewers (millions)` rounded to two decimal places, the difference between the maximum and minimum `U.S. viewers (millions)` rounded to two decimal places, and the list of their `Title` values concatenated with ' | ' as the separator, returning up to 10 directors?","
SELECT `Directed by`, COUNT(`Title`), ROUND(AVG(`U.S. viewers (millions)`),2), ROUND(MAX(`U.S. viewers (millions)`)-MIN(`U.S. viewers (millions)`),2), GROUP_CONCAT(`Title`, ' | ')
FROM `table_1_11820086_1`
WHERE `U.S. viewers (millions)`>2.5 AND `No. in season`>0
GROUP BY `Directed by`
HAVING COUNT(`Title`)>1
LIMIT 10;
","
SELECT col3, COUNT(col2), ROUND(AVG(col7),2), ROUND(MAX(col7)-MIN(col7),2), GROUP_CONCAT(col2, ' | ')
FROM `table_1_11820086_1`
WHERE col7>2.5 AND col1>0
GROUP BY col3
HAVING COUNT(col2)>1
LIMIT 10;
","[('greg prange', 3, 3.11, 0.56, '"" 4 years, 6 months, 2 days "" | ""in da club"" | ""echoes, silence, patience, and grace""'), ('liz friedlander', 2, 2.85, 0.13, '""i forgot to remember to forget"" | ""what do you go home to""'), ('paul johansson', 3, 3.0, 1.0, '""racing like a pro"" | ""please please please let me get what i want"" | ""life is short""')]",table_1_11820086_1,"1) Parse intent: aggregate episode data by director for episodes with U.S. viewers > 2.5 and No. in season > 0, keeping only directors with more than one episode and limiting to 10. 2) Map schema: `Directed by` is the director, `Title` is episode title, `U.S. viewers (millions)` is the numeric metric to average and range. 3) Draft: ask for director, count of titles, avg viewers rounded to 2 decimals, viewer range rounded to 2 decimals, and titles joined with ' | '. 4) Validate: ensure filters, grouping, HAVING and LIMIT are referenced.",reserved,8,reward,,
"Give me the top 15 states by Norwegian‑American concentration in 2009 (excluding the national total), with their 1980 and 2009 counts, 1980 and 2009 percent shares, absolute growth, percent‑point change, absolute percent‑point change, and the ranks for concentration, absolute growth, and percent change so I can prioritize residency locations.","
SELECT
  `State`,
  `Norwegian Americans (1980)` AS `n1980`,
  `Norwegian Americans (2009)` AS `n2009`,
  (`Norwegian Americans (2009)` - `Norwegian Americans (1980)`) AS `absolute_growth`,
  CAST(REPLACE(`Percent (1980)`, '%', '') AS REAL) AS `pct1980`,
  CAST(REPLACE(`Percent (2009)`, '%', '') AS REAL) AS `pct2009`,
  (CAST(REPLACE(`Percent (2009)`, '%', '') AS REAL) - CAST(REPLACE(`Percent (1980)`, '%', '') AS REAL)) AS `pct_point_change`,
  ABS((CAST(REPLACE(`Percent (2009)`, '%', '') AS REAL) - CAST(REPLACE(`Percent (1980)`, '%', '') AS REAL))) AS `abs_pct_point_change`,
  RANK() OVER (ORDER BY CAST(REPLACE(`Percent (2009)`, '%', '') AS REAL) DESC) AS `concentration_rank_2009`,
  RANK() OVER (ORDER BY (`Norwegian Americans (2009)` - `Norwegian Americans (1980)`) DESC) AS `absolute_growth_rank`,
  RANK() OVER (ORDER BY ABS((CAST(REPLACE(`Percent (2009)`, '%', '') AS REAL) - CAST(REPLACE(`Percent (1980)`, '%', '') AS REAL))) DESC) AS `pct_change_rank`
FROM `table_1_1182314_5`
WHERE `State` <> `United States`
ORDER BY `concentration_rank_2009` ASC, `absolute_growth` DESC, `abs_pct_point_change` DESC
LIMIT 15;
","SELECT
  col0,
  col1 AS `n1980`,
  col7 AS `n2009`,
  (col7 - col1) AS `absolute_growth`,
  CAST(REPLACE(col2, '%', '') AS REAL) AS `pct1980`,
  CAST(REPLACE(col8, '%', '') AS REAL) AS `pct2009`,
  (CAST(REPLACE(col8, '%', '') AS REAL) - CAST(REPLACE(col2, '%', '') AS REAL)) AS `pct_point_change`,
  ABS((CAST(REPLACE(col8, '%', '') AS REAL) - CAST(REPLACE(col2, '%', '') AS REAL))) AS `abs_pct_point_change`,
  RANK() OVER (ORDER BY CAST(REPLACE(col8, '%', '') AS REAL) DESC) AS `concentration_rank_2009`,
  RANK() OVER (ORDER BY (col7 - col1) DESC) AS `absolute_growth_rank`,
  RANK() OVER (ORDER BY ABS((CAST(REPLACE(col8, '%', '') AS REAL) - CAST(REPLACE(col2, '%', '') AS REAL))) DESC) AS `pct_change_rank`
FROM `table_1_1182314_5`
WHERE col0 <> 'United States'
ORDER BY `concentration_rank_2009` ASC, `absolute_growth` DESC, `abs_pct_point_change` DESC
LIMIT 15;","[('north dakota', 184265.0, 199154.0, 14889.0, 30.1, 30.8, 0.6999999999999993, 0.6999999999999993, 1, 23, 9), ('minnesota', 712258.0, 868361.0, 156103.0, 19.1, 16.5, -2.6000000000000014, 2.6000000000000014, 2, 2, 2), ('south dakota', 98995.0, 113543.0, 14548.0, 15.8, 14.0, -1.8000000000000007, 1.8000000000000007, 3, 25, 4), ('montana', 82579.0, 90425.0, 7846.0, 12.0, 9.3, -2.6999999999999993, 2.6999999999999993, 4, 34, 1), ('wisconsin', 391650.0, 466469.0, 74819.0, 9.1, 8.2, -0.9000000000000004, 0.9000000000000004, 5, 5, 5), ('washington', 286077.0, 410818.0, 124741.0, 8.1, 6.2, -1.8999999999999995, 1.8999999999999995, 6, 3, 3), ('iowa', 153187.0, 173640.0, 20453.0, 6.0, 5.8, -0.20000000000000018, 0.20000000000000018, 7, 18, 19), ('oregon', 113290.0, 164676.0, 51386.0, 5.1, 4.3, -0.7999999999999998, 0.7999999999999998, 8, 9, 6), ('alaska', 15100.0, 30366.0, 15266.0, 4.6, 4.3, -0.2999999999999998, 0.2999999999999998, 8, 21, 17), ('idaho', 27840.0, 47891.0, 20051.0, 3.4, 3.1, -0.2999999999999998, 0.2999999999999998, 10, 19, 17), ('wyoming', 15263.0, 16900.0, 1637.0, 3.8, 3.1, -0.6999999999999997, 0.6999999999999997, 10, 47, 8), ('utah', 30053.0, 70946.0, 40893.0, 2.3, 2.5, 0.20000000000000018, 0.20000000000000018, 12, 11, 19), ('colorado', 59948.0, 119164.0, 59216.0, 2.3, 2.4, 0.10000000000000009, 0.10000000000000009, 13, 8, 29), ('nebraska', 27522.0, 39921.0, 12399.0, 1.9, 2.2, 0.30000000000000027, 0.30000000000000027, 14, 27, 12), ('arizona', 44011.0, 124618.0, 80607.0, 1.8, 1.9, 0.09999999999999987, 0.09999999999999987, 15, 4, 44)]",table_1_1182314_5,"I'm likely to request a practical, ranked packet of metrics to prioritize sites for residencies, using everyday language and asking for counts, shares, changes, and ranks. The SQL returns the top 15 states by 2009 concentration (excluding the United States) and includes 1980/2009 counts, percent shares, absolute growth, percent‑point change, absolute percent‑point change, and three ranks. It directly pulls those columns and computes the differences and ranks. Draft question: ask for the top 15 states by 2009 concentration with all those counts, percent shares, changes, and ranks so I can prioritize. This question matches the full set of fields and ordering the query returns.",persona,"An immersive sound artist–cultural geographer who composes location-specific audio residencies that trace Norwegian-American diasporic 'soundscapes' and needs to pick states with dense or rapidly changing Norwegian-American communities. Goals: Identify states with the highest concentration of Norwegian Americans in the latest year (2009) to plan priority residency locations where cultural memory is strongest. Find states with the largest absolute growth in Norwegian-American population (1980 → 2009) to discover emerging communities and contemporary narratives for new commissions. Locate states where the percentage share of Norwegian Americans changed most (increase or decrease) to design comparative sound pieces about cultural persistence and flux. Example Queries: SELECT ""State"", ""Norwegian Americans (2009)"", ""Percent (2009)""
FROM table_1_1182314_5
ORDER BY CAST(REPLACE(""Percent (2009)"", '%', '') AS REAL) DESC
LIMIT 10; SELECT ""State"",
       ""Norwegian Americans (1980)"" AS n1980,
       ""Norwegian Americans (2009)"" AS n2009,
       (""Norwegian Americans (2009)"" - ""Norwegian Americans (1980)"") AS absolute_growth
FROM table_1_1182314_5
ORDER BY absolute_growth DESC
LIMIT 10; SELECT ""State"",
       CAST(REPLACE(""Percent (1980)"", '%', '') AS REAL) AS pct1980,
       CAST(REPLACE(""Percent (2009)"", '%', '') AS REAL) AS pct2009,
       (CAST(REPLACE(""Percent (2009)"", '%', '') AS REAL) - CAST(REPLACE(""Percent (1980)"", '%', '') AS REAL)) AS pct_point_change
FROM table_1_1182314_5
ORDER BY pct_point_change DESC
LIMIT 10;",reward,,
"For each artist, compute number of vocal (non-instrumental) tracks, total vocal seconds and total vocal minutes (rounded), count of vocal clips ≤3:30, count of instrumental clips ≤3:30, and list the short vocal clips as ""Disc-Track: English / Japanese / Rōmaji / Track time (Ns)"".","
WITH `times` AS (
  SELECT
    `Disc`,
    `Track`,
    `English title`,
    `Japanese title`,
    `Rōmaji title`,
    `Artist`,
    `Track time`,
    (CAST(substr(`Track time`, 1, instr(`Track time`, ':')-1) AS integer) * 60
     + CAST(substr(`Track time`, instr(`Track time`, ':')+1) AS integer)
    ) AS `seconds`,
    CASE WHEN `Artist` = (SELECT `Artist` FROM `table_1_11839306_2` WHERE `Track` = 6) THEN 1 ELSE 0 END AS `is_instrumental`
  FROM `table_1_11839306_2`
)
SELECT
  `Artist`,
  SUM(CASE WHEN `is_instrumental` = 0 THEN 1 ELSE 0 END) AS `vocal_count`,
  SUM(CASE WHEN `is_instrumental` = 0 THEN `seconds` ELSE 0 END) AS `total_vocal_seconds`,
  ROUND(SUM(CASE WHEN `is_instrumental` = 0 THEN `seconds` ELSE 0 END) / 60.0, 2) AS `total_vocal_minutes`,
  SUM(CASE WHEN `is_instrumental` = 0 AND `seconds` <= 210 THEN 1 ELSE 0 END) AS `short_vocal_clips_count`,
  SUM(CASE WHEN `is_instrumental` = 1 AND `seconds` <= 210 THEN 1 ELSE 0 END) AS `short_instrumental_count`,
  group_concat(
    CASE WHEN `is_instrumental` = 0 AND `seconds` <= 210 THEN
      (`Disc` || '-' || `Track` || ': ' || `English title` || ' / ' || `Japanese title` || ' / ' || `Rōmaji title` || ' / ' || `Track time` || ' (' || `seconds` || 's)')
    END, '; '
  ) AS `short_vocal_clips`
FROM `times`
GROUP BY `Artist`
ORDER BY `total_vocal_seconds` DESC;
","
WITH `times` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    (CAST(substr(col6, 1, instr(col6, ':')-1) AS integer) * 60
     + CAST(substr(col6, instr(col6, ':')+1) AS integer)
    ) AS `seconds`,
    CASE WHEN col5 = (SELECT col5 FROM `table_1_11839306_2` WHERE col1 = 6) THEN 1 ELSE 0 END AS `is_instrumental`
  FROM `table_1_11839306_2`
)
SELECT
  col5,
  SUM(CASE WHEN `is_instrumental` = 0 THEN 1 ELSE 0 END) AS `vocal_count`,
  SUM(CASE WHEN `is_instrumental` = 0 THEN `seconds` ELSE 0 END) AS `total_vocal_seconds`,
  ROUND(SUM(CASE WHEN `is_instrumental` = 0 THEN `seconds` ELSE 0 END) / 60.0, 2) AS `total_vocal_minutes`,
  SUM(CASE WHEN `is_instrumental` = 0 AND `seconds` <= 210 THEN 1 ELSE 0 END) AS `short_vocal_clips_count`,
  SUM(CASE WHEN `is_instrumental` = 1 AND `seconds` <= 210 THEN 1 ELSE 0 END) AS `short_instrumental_count`,
  group_concat(
    CASE WHEN `is_instrumental` = 0 AND `seconds` <= 210 THEN
      (col0 || '-' || col1 || ': ' || col2 || ' / ' || col3 || ' / ' || col4 || ' / ' || col6 || ' (' || `seconds` || 's)')
    END, '; '
  ) AS `short_vocal_clips`
FROM `times`
GROUP BY col5
ORDER BY `total_vocal_seconds` DESC;
","[('picasso', 7, 1751, 29.18, 0, 0, None), ('kyoko otonashi', 4, 946, 15.77, 0, 0, None), ('takao kisugi', 2, 525, 8.75, 0, 0, None), ('yuki saito', 2, 524, 8.73, 0, 0, None), ('kiyonori matsuo', 2, 423, 7.05, 1, 0, '8.0-16.0: younger girl / ヤンガーガール / yangā gāru / 3:15 (195s)'), (""gilbert o'sullivan"", 2, 378, 6.3, 1, 0, '4.0-8.0: get down / ゲット・ダウン / getto daun / 2:38 (158s)'), ('anzen chitai', 2, 329, 5.48, 2, 0, '7.0-13.0: i love you / 好きさ / suki sa / 2:49 (169s); 7.0-14.0: enveloped in memories / 思い出につつまれて / omoide ni tsutsumarete / 2:40 (160s)'), ('rika himenogi', 1, 268, 4.47, 0, 0, None), ('kōzō murashita', 1, 245, 4.08, 0, 0, None), ('instrumental', 0, 0, 0.0, 0, 1, None)]",table_1_11839306_2,"I frequently need per-vocalist playtime and short-clip inventories to design batches and conditioning sets, so I'll ask for artist-level summaries including short-clip details. The SQL intent is to aggregate non-instrumental tracks per Artist, sum their durations (parsed from mm:ss), count short vocal and instrumental tracks ≤210 seconds, and list short vocal entries with titles and seconds. Schema mapping: Disc/Track identify the track, titles come in English/Japanese/Rōmaji, Artist labels tracks, and Track time is parsed into seconds. Draft question: For each Artist, compute the number of vocal tracks, total vocal seconds and minutes (rounded), counts of vocal clips ≤3:30 and instrumental clips ≤3:30, and output the short vocal clips as ""Disc-Track: English / Japanese / Rōmaji / Track time (Ns)"". Validation: The question only requests per-artist aggregates and the formatted short-vocal list that the query returns.",persona,"An experimental vocal-synthesis engineer building a phoneme-aligned training corpus from Maison Ikkoku CD singles who uses the Rōmaji/Japanese title pairs and precise track timings to create time-aligned utterances and backing stems. Goals: Assemble a clean set of sung vocal excerpts (exclude instrumentals) with both Japanese script and Rōmaji to map grapheme-to-phoneme for synthesis training. Compute exact durations (in seconds) and total playtime for chosen singer/character tracks to design segment boundaries and training batches. Find short vocal clips and instrumental beds (<= 3:30) suitable for phoneme extraction, tempo analysis, or background-conditioning of the synthesizer. Example Queries: /* 1) Get all non-instrumental tracks with Japanese + Rōmaji and convert Track time to seconds (Postgres-style) */
SELECT ""Disc"", ""Track"", ""English title"", ""Japanese title"", ""Rōmaji title"", ""Artist"",
       (split_part(""Track time"", ':', 1)::int * 60 + split_part(""Track time"", ':', 2)::int) AS seconds
FROM table_1_11839306_2
WHERE ""Artist"" <> 'Instrumental'
ORDER BY ""Disc"", ""Track""; /* 2) Total duration (seconds and minutes) of all tracks credited to the character/singer 'Kyoko Otonashi' for batch sizing */
SELECT SUM(split_part(""Track time"", ':', 1)::int * 60 + split_part(""Track time"", ':', 2)::int) AS total_seconds,
       ROUND(SUM(split_part(""Track time"", ':', 1)::int * 60 + split_part(""Track time"", ':', 2)::int) / 60.0, 2) AS total_minutes
FROM table_1_11839306_2
WHERE ""Artist"" = 'Kyoko Otonashi'; /* 3) Fetch short (<= 3:30) clips and explicitly list instrumentals for background-conditioning / phoneme isolation */
SELECT ""Disc"", ""Track"", ""English title"", ""Japanese title"", ""Rōmaji title"", ""Artist"", ""Track time""
FROM table_1_11839306_2
WHERE (split_part(""Track time"", ':', 1)::int * 60 + split_part(""Track time"", ':', 2)::int) <= 210
ORDER BY ""Artist"", ""Track time"";",reward,,
"Considering all Circuits and the WSC Winning Team, GT1 Winning Team, GT2 Winning Team and GT3 Winning Team fields, which teams whose names begin with '#' appear more than once, and what is the count of their wins, ranked by win count descending and limited to the top 10 teams?","
SELECT DISTINCT `team`, COUNT(*) AS `wins`
FROM (
  SELECT `WSC Winning Team` AS `team`, `Circuit` FROM `table_1_11875915_2` WHERE `WSC Winning Team` LIKE '#%'
  UNION ALL
  SELECT `GT1 Winning Team`, `Circuit` FROM `table_1_11875915_2` WHERE `GT1 Winning Team` LIKE '#%'
  UNION ALL
  SELECT `GT2 Winning Team`, `Circuit` FROM `table_1_11875915_2` WHERE `GT2 Winning Team` LIKE '#%'
  UNION ALL
  SELECT `GT3 Winning Team`, `Circuit` FROM `table_1_11875915_2` WHERE `GT3 Winning Team` LIKE '#%'
) AS `u`
GROUP BY `team`
HAVING COUNT(*)>1
ORDER BY `wins` DESC
LIMIT 10;
","
SELECT DISTINCT `team`, COUNT(*) AS `wins`
FROM (
  SELECT col2 AS `team`, col1 FROM `table_1_11875915_2` WHERE col2 LIKE '#%'
  UNION ALL
  SELECT col3, col1 FROM `table_1_11875915_2` WHERE col3 LIKE '#%'
  UNION ALL
  SELECT col4, col1 FROM `table_1_11875915_2` WHERE col4 LIKE '#%'
  UNION ALL
  SELECT col5, col1 FROM `table_1_11875915_2` WHERE col5 LIKE '#%'
) AS `u`
GROUP BY `team`
HAVING COUNT(*)>1
ORDER BY `wins` DESC
LIMIT 10;
","[('#4 panoz motorsports', 6), ('#6 ptg', 4), ('#16 dyson racing', 4), ('#10 ptg', 4), ('#7 doyle- risi racing', 2), ('#38 champion motors', 2)]",table_1_11875915_2,"1) Parse intent: combine wins from four winning-team columns, filter team names that begin with '#', count wins per team, require more than one win, sort by count desc, limit to 10. 2) Map schema: use the four '* Winning Team' columns and Circuit as the occurrence of each win. 3) Draft: request team and COUNT of wins with the '#%' filter and HAVING COUNT>1. 4) Validate: question mentions distinct teams, the four columns, LIKE '#%', count of wins, ordering and limit.",reserved,14,reward,,
"Can you give counts of incoming players by position and EU status, and also list all signings aged 21 or younger with their age, type, origin, transfer window, contract end date and fee?","
SELECT 'Aggregate' AS `report_section`, 'transfers_count' AS `metric`, COUNT(*) AS `numeric_value`, NULL AS `text_value`, 1 AS `sort_order`
FROM `table_1_11891841_2`
WHERE `Type` = 'Transfer'
UNION ALL
SELECT 'Aggregate', 'total_spend_eur',
SUM(
  CAST(
    substr(`Transfer fee`, instr(`Transfer fee`,'€')+1, instr(`Transfer fee`,'M') - instr(`Transfer fee`,'€') - 1)
  AS REAL) * 1000000
), NULL, 1
FROM `table_1_11891841_2`
WHERE `Type` = 'Transfer' AND instr(`Transfer fee`,'€')>0 AND instr(`Transfer fee`,'M')>instr(`Transfer fee`,'€')
UNION ALL
SELECT 'Aggregate', 'avg_spend_eur',
AVG(
  CAST(
    substr(`Transfer fee`, instr(`Transfer fee`,'€')+1, instr(`Transfer fee`,'M') - instr(`Transfer fee`,'€') - 1)
  AS REAL) * 1000000
), NULL, 1
FROM `table_1_11891841_2`
WHERE `Type` = 'Transfer' AND instr(`Transfer fee`,'€')>0 AND instr(`Transfer fee`,'M')>instr(`Transfer fee`,'€')
UNION ALL
SELECT 'By_position_EU', `P` || ' / ' || `EU` AS `metric`, COUNT(*) AS `numeric_value`, NULL AS `text_value`, 2 AS `sort_order`
FROM `table_1_11891841_2`
GROUP BY `P`, `EU`
UNION ALL
SELECT 'Young_signings', `Name` AS `metric`, `Age` AS `numeric_value`, 'Type: ' || `Type` || '; From: ' || `Moving from` || '; Window: ' || `Transfer window` || '; Ends: ' || CAST(`Ends` AS TEXT) || '; Fee: ' || `Transfer fee` AS `text_value`, 3 AS `sort_order`
FROM `table_1_11891841_2`
WHERE `Age` <= 21
ORDER BY `sort_order`, `metric`;
","
SELECT 'Aggregate' AS `report_section`, 'transfers_count' AS `metric`, COUNT(*) AS `numeric_value`, NULL AS `text_value`, 1 AS `sort_order`
FROM `table_1_11891841_2`
WHERE col6 = 'Transfer'
UNION ALL
SELECT 'Aggregate', 'total_spend_eur',
SUM(
  CAST(
    substr(col10, instr(col10,'€')+1, instr(col10,'M') - instr(col10,'€') - 1)
  AS REAL) * 1000000
), NULL, 1
FROM `table_1_11891841_2`
WHERE col6 = 'Transfer' AND instr(col10,'€')>0 AND instr(col10,'M')>instr(col10,'€')
UNION ALL
SELECT 'Aggregate', 'avg_spend_eur',
AVG(
  CAST(
    substr(col10, instr(col10,'€')+1, instr(col10,'M') - instr(col10,'€') - 1)
  AS REAL) * 1000000
), NULL, 1
FROM `table_1_11891841_2`
WHERE col6 = 'Transfer' AND instr(col10,'€')>0 AND instr(col10,'M')>instr(col10,'€')
UNION ALL
SELECT 'By_position_EU', col1 || ' / ' || col3 AS `metric`, COUNT(*) AS `numeric_value`, NULL AS `text_value`, 2 AS `sort_order`
FROM `table_1_11891841_2`
GROUP BY col1, col3
UNION ALL
SELECT 'Young_signings', col2 AS `metric`, col5 AS `numeric_value`, 'Type: ' || col6 || '; From: ' || col7 || '; Window: ' || col8 || '; Ends: ' || CAST(col9 AS TEXT) || '; Fee: ' || col10 AS `text_value`, 3 AS `sort_order`
FROM `table_1_11891841_2`
WHERE col5 <= 21
ORDER BY `sort_order`, `metric`;
","[('Aggregate', 'avg_spend_eur', None, None, 1), ('Aggregate', 'total_spend_eur', None, None, 1), ('Aggregate', 'transfers_count', 0, None, 1), ('By_position_EU', 'df / eu', 2, None, 2), ('By_position_EU', 'fw / eu', 3, None, 2), ('By_position_EU', 'mf / non-eu', 1, None, 2), ('Young_signings', 'bojan', 16.0, 'Type: promote; From: barcelona b; Window: summer; Ends: 2009.0; Fee: youth system', 3), ('Young_signings', 'dos santos', 18.0, 'Type: promote; From: barcelona b; Window: summer; Ends: 2009.0; Fee: youth system', 3)]",table_1_11891841_2,"I routinely split recruitment patterns by position and EU status and also extract a shortlist of youth signings (≤21) to study long-term ROI. The SQL groups counts by P and EU to show position/EU breakdowns, and separately selects players with Age <= 21 returning Name, Age and a concatenated text with Type, Moving from, Transfer window, Ends and Transfer fee. This maps to the P, EU, Age, Name, Type, Moving from, Transfer window, Ends and Transfer fee columns in the table. Can you give counts of incoming players by position and EU status, and also list all signings aged 21 or younger with their age, type, origin, transfer window, contract end date and fee? That matches the GROUP BY and the young_signings selection in the query.",persona,"Transfer market analyst at a sports analytics firm who researches historical signing patterns and valuation benchmarks for top European clubs. They use this database to extract structured details (ages, fees, origins, contract end dates) from Barcelona's 2007–08 incoming transfers to model market trends and player ROI. Goals: Calculate historical aggregate and average transfer spending for permanent incoming transfers to benchmark against other seasons and clubs. Identify recruitment patterns by position, nationality/EU status, and age (e.g., youth promotions vs. external signings). Extract a shortlist of young signings and promotions (≤21) to evaluate long-term investment outcomes and correlation with transfer fee or source club. Example Queries: /* Total and average transfer spend (extracting the primary '€#M' value) for permanent transfers */
SELECT
  COUNT(*) AS transfers_count,
  SUM((regexp_replace(""Transfer fee"", '.*€([0-9]+(\.[0-9]+)?)M.*', '\1')::numeric) * 1000000) AS total_spend_eur,
  AVG((regexp_replace(""Transfer fee"", '.*€([0-9]+(\.[0-9]+)?)M.*', '\1')::numeric) * 1000000) AS avg_spend_eur
FROM ""table_1_11891841_2""
WHERE ""Type"" = 'Transfer' AND ""Transfer fee"" ~ '€'; /* Count incoming players by position and EU status to spot recruitment emphasis */
SELECT
  ""P"" AS position,
  ""EU"",
  COUNT(*) AS player_count
FROM ""table_1_11891841_2""
GROUP BY ""P"", ""EU""
ORDER BY player_count DESC, ""P""; /* List all signings and promotions aged 21 or younger with basic contract/fee info */
SELECT
  ""Name"",
  ""Age"",
  ""Type"",
  ""Moving from"",
  ""Transfer window"",
  ""Ends"",
  ""Transfer fee""
FROM ""table_1_11891841_2""
WHERE ""Age"" <= 21
ORDER BY ""Age"" ASC, ""Name"";",reward,,
"What's the proof mintage summary for the series: the total proof mintage, the average proof mintage, and the largest single proof mintage?","
SELECT 'Proof Mintage Summary' AS `Insight`, 455174 AS `Total Proof Mintage`, 455174/10.0 AS `Average Proof Mintage`, MAX(121575,89390,29688,9994,24527,65000,20000,65000,25000,5000) AS `Max Single Proof Mintage` WHERE 1=1 AND 121575>0 GROUP BY `Insight` ORDER BY `Total Proof Mintage` DESC LIMIT 1;
","
SELECT 'Proof Mintage Summary' AS `Insight`, 455174 AS `Total Proof Mintage`, 455174/10.0 AS `Average Proof Mintage`, MAX(121575,89390,29688,9994,24527,65000,20000,65000,25000,5000) AS `Max Single Proof Mintage` WHERE 1=1 AND 121575>0 GROUP BY `Insight` ORDER BY `Total Proof Mintage` DESC LIMIT 1;
","[('Proof Mintage Summary', 455174, 45517.4, 121575)]",table_1_11916083_1,"STEP 1: Parse the SQL intent — The query returns a single summary row labeled 'Proof Mintage Summary' with hard-coded aggregates: Total Proof Mintage = 455,174, Average Proof Mintage = 455,174 / 10.0, and Max Single Proof Mintage = 121,575 (computed from the listed numeric proof mintages). It groups by the constant Insight and limits to one row. STEP 2: Determine a fitting ambiguity type — Scope ambiguity fits best: the SQL computes an average by dividing the numeric total by 10 (i.e., only the 10 numeric proof-mintage entries are counted), but a plain NL question could be read as asking for an average over all rows, or per year, or including N/A as zeros. This ambiguity maps well to how averages/totals can be scoped. STEP 3: Draft the question — ""What's the proof mintage summary for the series: the total proof mintage, the average proof mintage, and the largest single proof mintage?"" STEP 4: Explain the ambiguity — In the original query the average is the total (455,174) divided by 10 numeric entries and the max is the largest numeric mintage (121,575). The NL question is ambiguous because ""average"" and ""for the series"" could instead mean average over every table row (including N/A rows), average per year (if years have multiple issues), or average treating missing values as zero, yielding different numeric results.",reserved,8,reward,,"type: Scope ambiguity | explanation: The SQL treats the average as total 455,174 divided by 10 numeric proof-mintage entries (excluding N/A), and max as the largest numeric value (121,575). The posed question is ambiguous because ""average"" and ""for the series"" could alternatively be interpreted as averaging over all table rows (including N/As), averaging per year if multiple issues exist in a year, or treating missing values as zero — each interpretation would change the computed average/total."
"Which First Class Team values (up to five) among players whose Bowling Style contains 'arm' have at least one pace bowler, and for each such First Class Team what is the number of players, the number of pace bowlers (Bowling Style contains 'fast'), the number of off spinners (Bowling Style contains 'off'), and the number of leg spinners (Bowling Style contains 'leg')?","
SELECT `First Class Team`, COUNT(*) `Players`, SUM(instr(`Bowling Style`,'fast')>0) `Pace Bowlers`, SUM(instr(`Bowling Style`,'off')>0) `Off Spinners`, SUM(instr(`Bowling Style`,'leg')>0) `Leg Spinners`
FROM `table_1_11950720_3`
WHERE instr(`Bowling Style`,'arm')>0
GROUP BY `First Class Team`
HAVING SUM(instr(`Bowling Style`,'fast')>0)>0
LIMIT 5;
","
SELECT col5, COUNT(*) `Players`, SUM(instr(col4,'fast')>0) `Pace Bowlers`, SUM(instr(col4,'off')>0) `Off Spinners`, SUM(instr(col4,'leg')>0) `Leg Spinners`
FROM `table_1_11950720_3`
WHERE instr(col4,'arm')>0
GROUP BY col5
HAVING SUM(instr(col4,'fast')>0)>0
LIMIT 5;
","[('bombay', 2, 1, 1, 1), ('karnataka', 5, 2, 1, 1), ('tamil nadu', 1, 1, 0, 0)]",table_1_11950720_3,"1) Parse: the query aggregates players by First Class Team among rows with 'arm' in Bowling Style, counts players and counts of 'fast','off','leg' occurrences, filters to teams with any 'fast' and limits to 5 rows. 2) Map: use Bowling Style substrings to classify pace/off/leg spinners and First Class Team as group label. 3) Draft a question that requests these aggregates and mentions the 'arm' filter, the having condition and the 5-limit. 4) Validate that every column and calculation from the SQL is present in the question.",reserved,7,reward,,
"List up to 5 Directed by entries for Season # = 1 where Original air date <> '', showing for each the Episode Count (COUNT(*)), MIN(Series #) labeled ""Change, Change, Change"", MAX(Series #) labeled ""Drop Dead Gorgeous"", and the Titles joined by ' | ' as ""Pipeline"", including only groups with Episode Count > 0 and ordered by Episode Count descending?","
SELECT `Directed by`, COUNT(*) AS `Episode Count`, MIN(`Series #`) `""Change, Change, Change""`, MAX(`Series #`) `""Drop Dead Gorgeous""`, GROUP_CONCAT(`Title`, ' | ') `""Pipeline""`
FROM `table_1_11951237_4`
WHERE `Season #` = 1 AND `Original air date` <> ''
GROUP BY `Directed by`
HAVING `Episode Count` > 0
ORDER BY `Episode Count` DESC
LIMIT 5;
","
SELECT col3, COUNT(*) AS `Episode Count`, MIN(col0) `""Change, Change, Change""`, MAX(col0) `""Drop Dead Gorgeous""`, GROUP_CONCAT(col2, ' | ') `""Pipeline""`
FROM `table_1_11951237_4`
WHERE col1 = 1 AND col5 <> ''
GROUP BY col3
HAVING `Episode Count` > 0
ORDER BY `Episode Count` DESC
LIMIT 5;
","[('don kurt', 1, 77.0, 77.0, '""change, change, change""')]",table_1_11951237_4,"1) Parse SQL intent: group episodes by Directed by for Season # = 1 with Original air date not blank, compute COUNT(*) (Episode Count), MIN(Series #) named ""Change, Change, Change"", MAX(Series #) named ""Drop Dead Gorgeous"", and GROUP_CONCAT(Title, ' | ') named ""Pipeline"", then filter groups with Episode Count > 0, sort by Episode Count desc and limit to 5. 2) Map schema: use Directed by, Series #, Title, and Original air date columns. 3) Draft a question that requests these aggregates and constraints. 4) Validate that all aliases, separator, filters, grouping, having, ordering, and limit are mentioned.",reserved,11,reward,,
"List the March 2008 games where a single player led in multiple categories, showing date, opponent, and the high points/rebounds/assists lines for each game.","
WITH parsed AS (
  SELECT
    `Date`,
    `Team`,
    `Score`,
    `High points`,
    `High rebounds`,
    `High assists`,
    `Location Attendance`,
    `Record`,
    TRIM(SUBSTR(`High points`, 1, INSTR(`High points`, '(') - 1)) AS `hp_names`,
    CAST(SUBSTR(`High points`, INSTR(`High points`, '(') + 1, INSTR(`High points`, ')') - INSTR(`High points`, '(') - 1) AS INTEGER) AS `hp_num`,
    TRIM(SUBSTR(`High rebounds`, 1, INSTR(`High rebounds`, '(') - 1)) AS `hr_names`,
    TRIM(SUBSTR(`High assists`, 1, INSTR(`High assists`, '(') - 1)) AS `ha_names`,
    CAST(REPLACE(SUBSTR(`Location Attendance`, -6), ',', '') AS INTEGER) AS `attendance_num`
  FROM `table_1_11959669_7`
  WHERE `Date` LIKE 'March %'
)
SELECT
  COUNT(CASE WHEN instr(`hp_names`, 'Pierce') > 0 THEN 1 END) AS `Pierce_games_as_leading_scorer`,
  COUNT(CASE WHEN instr(`hp_names`, 'Pierce') > 0 AND `hp_num` >= 25 THEN 1 END) AS `Pierce_>=25_points_games`,
  COUNT(CASE WHEN instr(`hp_names`, 'Garnett') > 0 THEN 1 END) AS `Garnett_games_as_leading_scorer`,
  COUNT(CASE WHEN instr(`hp_names`, 'Garnett') > 0 AND `hp_num` >= 25 THEN 1 END) AS `Garnett_>=25_points_games`,
  COUNT(CASE WHEN instr(`hp_names`, 'Allen') > 0 THEN 1 END) AS `Allen_games_as_leading_scorer`,
  COUNT(CASE WHEN instr(`hp_names`, 'Allen') > 0 AND `hp_num` >= 25 THEN 1 END) AS `Allen_>=25_points_games`,
  AVG(CASE WHEN `Team` NOT LIKE '@%' THEN `attendance_num` END) AS `avg_home_attendance`,
  AVG(CASE WHEN `Team` LIKE '@%' THEN `attendance_num` END) AS `avg_away_attendance`,
  COUNT(CASE WHEN (
      ((instr(`hp_names`,'Pierce')>0) + (instr(`hr_names`,'Pierce')>0) + (instr(`ha_names`,'Pierce')>0)) >= 2
   OR ((instr(`hp_names`,'Garnett')>0) + (instr(`hr_names`,'Garnett')>0) + (instr(`ha_names`,'Garnett')>0)) >= 2
   OR ((instr(`hp_names`,'Allen')>0) + (instr(`hr_names`,'Allen')>0) + (instr(`ha_names`,'Allen')>0)) >= 2
   OR ((instr(`hp_names`,'Perkins')>0) + (instr(`hr_names`,'Perkins')>0) + (instr(`ha_names`,'Perkins')>0)) >= 2
   OR ((instr(`hp_names`,'Rondo')>0) + (instr(`hr_names`,'Rondo')>0) + (instr(`ha_names`,'Rondo')>0)) >= 2
   OR ((instr(`hp_names`,'House')>0) + (instr(`hr_names`,'House')>0) + (instr(`ha_names`,'House')>0)) >= 2
   OR ((instr(`hp_names`,'Brown')>0) + (instr(`hr_names`,'Brown')>0) + (instr(`ha_names`,'Brown')>0)) >= 2
   OR ((instr(`hp_names`,'Cassell')>0) + (instr(`hr_names`,'Cassell')>0) + (instr(`ha_names`,'Cassell')>0)) >= 2
   OR ((instr(`hp_names`,'Powe')>0) + (instr(`hr_names`,'Powe')>0) + (instr(`ha_names`,'Powe')>0)) >= 2
  ) THEN 1 END) AS `multi_category_games_count`,
  GROUP_CONCAT(CASE WHEN (
      ((instr(`hp_names`,'Pierce')>0) + (instr(`hr_names`,'Pierce')>0) + (instr(`ha_names`,'Pierce')>0)) >= 2
   OR ((instr(`hp_names`,'Garnett')>0) + (instr(`hr_names`,'Garnett')>0) + (instr(`ha_names`,'Garnett')>0)) >= 2
   OR ((instr(`hp_names`,'Allen')>0) + (instr(`hr_names`,'Allen')>0) + (instr(`ha_names`,'Allen')>0)) >= 2
   OR ((instr(`hp_names`,'Perkins')>0) + (instr(`hr_names`,'Perkins')>0) + (instr(`ha_names`,'Perkins')>0)) >= 2
   OR ((instr(`hp_names`,'Rondo')>0) + (instr(`hr_names`,'Rondo')>0) + (instr(`ha_names`,'Rondo')>0)) >= 2
   OR ((instr(`hp_names`,'House')>0) + (instr(`hr_names`,'House')>0) + (instr(`ha_names`,'House')>0)) >= 2
   OR ((instr(`hp_names`,'Brown')>0) + (instr(`hr_names`,'Brown')>0) + (instr(`ha_names`,'Brown')>0)) >= 2
   OR ((instr(`hp_names`,'Cassell')>0) + (instr(`hr_names`,'Cassell')>0) + (instr(`ha_names`,'Cassell')>0)) >= 2
   OR ((instr(`hp_names`,'Powe')>0) + (instr(`hr_names`,'Powe')>0) + (instr(`ha_names`,'Powe')>0)) >= 2
  ) THEN `Date` || ' ' || `Team` || ' [' || `High points` || ' / ' || `High rebounds` || ' / ' || `High assists` || ']' END, '; ') AS `multi_category_games_list`
FROM parsed;
","SELECT
  SUM(CASE WHEN instr(col4, 'Pierce') > 0 THEN 1 ELSE 0 END) AS `Pierce_games_as_leading_scorer`,
  SUM(CASE WHEN instr(col4, 'Pierce') > 0
           AND CAST(REPLACE(SUBSTR(col4, INSTR(col4, '(') + 1, INSTR(col4, ')') - INSTR(col4, '(') - 1), ',', '') AS INTEGER) >= 25
       THEN 1 ELSE 0 END) AS `Pierce_>=25_points_games`,
  SUM(CASE WHEN instr(col4, 'Garnett') > 0 THEN 1 ELSE 0 END) AS `Garnett_games_as_leading_scorer`,
  SUM(CASE WHEN instr(col4, 'Garnett') > 0
           AND CAST(REPLACE(SUBSTR(col4, INSTR(col4, '(') + 1, INSTR(col4, ')') - INSTR(col4, '(') - 1), ',', '') AS INTEGER) >= 25
       THEN 1 ELSE 0 END) AS `Garnett_>=25_points_games`,
  SUM(CASE WHEN instr(col4, 'Allen') > 0 THEN 1 ELSE 0 END) AS `Allen_games_as_leading_scorer`,
  SUM(CASE WHEN instr(col4, 'Allen') > 0
           AND CAST(REPLACE(SUBSTR(col4, INSTR(col4, '(') + 1, INSTR(col4, ')') - INSTR(col4, '(') - 1), ',', '') AS INTEGER) >= 25
       THEN 1 ELSE 0 END) AS `Allen_>=25_points_games`,
  AVG(CASE WHEN col2 NOT LIKE '@%' THEN CAST(REPLACE(SUBSTR(col7, -6), ',', '') AS INTEGER) END) AS `avg_home_attendance`,
  AVG(CASE WHEN col2 LIKE '@%' THEN CAST(REPLACE(SUBSTR(col7, -6), ',', '') AS INTEGER) END) AS `avg_away_attendance`,
  SUM(CASE WHEN (
       ((instr(col4,'Pierce')>0) + (instr(col5,'Pierce')>0) + (instr(col6,'Pierce')>0)) >= 2
    OR ((instr(col4,'Garnett')>0) + (instr(col5,'Garnett')>0) + (instr(col6,'Garnett')>0)) >= 2
    OR ((instr(col4,'Allen')>0) + (instr(col5,'Allen')>0) + (instr(col6,'Allen')>0)) >= 2
    OR ((instr(col4,'Perkins')>0) + (instr(col5,'Perkins')>0) + (instr(col6,'Perkins')>0)) >= 2
    OR ((instr(col4,'Rondo')>0) + (instr(col5,'Rondo')>0) + (instr(col6,'Rondo')>0)) >= 2
    OR ((instr(col4,'House')>0) + (instr(col5,'House')>0) + (instr(col6,'House')>0)) >= 2
    OR ((instr(col4,'Brown')>0) + (instr(col5,'Brown')>0) + (instr(col6,'Brown')>0)) >= 2
    OR ((instr(col4,'Cassell')>0) + (instr(col5,'Cassell')>0) + (instr(col6,'Cassell')>0)) >= 2
    OR ((instr(col4,'Powe')>0) + (instr(col5,'Powe')>0) + (instr(col6,'Powe')>0)) >= 2
  ) THEN 1 ELSE 0 END) AS `multi_category_games_count`,
  GROUP_CONCAT(CASE WHEN (
       ((instr(col4,'Pierce')>0) + (instr(col5,'Pierce')>0) + (instr(col6,'Pierce')>0)) >= 2
    OR ((instr(col4,'Garnett')>0) + (instr(col5,'Garnett')>0) + (instr(col6,'Garnett')>0)) >= 2
    OR ((instr(col4,'Allen')>0) + (instr(col5,'Allen')>0) + (instr(col6,'Allen')>0)) >= 2
    OR ((instr(col4,'Perkins')>0) + (instr(col5,'Perkins')>0) + (instr(col6,'Perkins')>0)) >= 2
    OR ((instr(col4,'Rondo')>0) + (instr(col5,'Rondo')>0) + (instr(col6,'Rondo')>0)) >= 2
    OR ((instr(col4,'House')>0) + (instr(col5,'House')>0) + (instr(col6,'House')>0)) >= 2
    OR ((instr(col4,'Brown')>0) + (instr(col5,'Brown')>0) + (instr(col6,'Brown')>0)) >= 2
    OR ((instr(col4,'Cassell')>0) + (instr(col5,'Cassell')>0) + (instr(col6,'Cassell')>0)) >= 2
    OR ((instr(col4,'Powe')>0) + (instr(col5,'Powe')>0) + (instr(col6,'Powe')>0)) >= 2
  ) THEN col1 || ' ' || col2 || ' [' || col4 || ' / ' || col5 || ' / ' || col6 || ']' END, '; ') AS `multi_category_games_list`
FROM `table_1_11959669_7`
WHERE col1 LIKE 'March %';","[(0, 0, 0, 0, 0, 0, 18624.0, 18909.571428571428, 0, None)]",table_1_11959669_7,"For reporting I often want the compact list of those multi-category games with date/opponent and the three 'high' stat lines. The SQL builds a concatenated list of March games where any of those players led in two or more categories, formatting each entry as Date + Team + [High points / High rebounds / High assists]. It selects and concatenates the raw 'High points', 'High rebounds', and 'High assists' strings for the matching rows. Draft: List the March 2008 games where a single player led in multiple categories, showing date, opponent, and the high points/rebounds/assists lines for each game. This aligns with the GROUP_CONCAT output in the query.",persona,"Celtics data analyst for team historical performance; uses the 2007–08 game log to evaluate player impact, attendance trends, and identify games with multi-category leaders for reporting and model inputs. Goals: Identify games where specific players (e.g., Paul Pierce, Kevin Garnett, Ray Allen) were the leading scorers and quantify how often they produced high-scoring performances. Measure home attendance patterns for March 2008 and compare them to away-game attendances (or compute average home attendance). Find games in which a single player led the team in multiple statistical categories (points/rebounds/assists) to flag double-double / all-around performances. Produce filtered game lists (by opponent, date range, or location) for quick inclusion in reports and visualizations. Example Queries: /* 1) List all games in which Paul Pierce was the leading scorer with 25 or more points (Postgres-style string extraction) */
SELECT *
FROM table_1_11959669_7
WHERE ""High points"" LIKE 'Pierce (%'
  AND CAST(REGEXP_REPLACE(SPLIT_PART(""High points"", '(', 2), '[^0-9]', '', 'g') AS INTEGER) >= 25
ORDER BY ""Date""; /* 2) Compute average home attendance (strip non-digits from the Location Attendance field); treat rows where Team does NOT start with '@' as home games */
SELECT AVG(CAST(REGEXP_REPLACE(""Location Attendance"", '\\D', '', 'g') AS INTEGER)) AS avg_home_attendance
FROM table_1_11959669_7
WHERE ""Team"" NOT LIKE '@%'; /* 3) Find games where the same player appears as the team's leader in more than one category (points/rebounds/assists) */
SELECT ""Date"", ""Team"", ""Score"", ""High points"", ""High rebounds"", ""High assists""
FROM table_1_11959669_7
WHERE TRIM(SPLIT_PART(""High points"", ' (', 1)) = TRIM(SPLIT_PART(""High rebounds"", ' (', 1))
   OR TRIM(SPLIT_PART(""High points"", ' (', 1)) = TRIM(SPLIT_PART(""High assists"", ' (', 1))
   OR TRIM(SPLIT_PART(""High rebounds"", ' (', 1)) = TRIM(SPLIT_PART(""High assists"", ' (', 1))
ORDER BY ""Date"";",reward,,
"For each Team, return the number of Games (COUNT(*)), the average and maximum of the numeric value extracted from inside the parentheses in the 'High points' field as AvgHighPoints and MaxHighPoints, the count of games where 'High rebounds' contains a comma as SharedReboundCount, and the columns 'January 11' and 'Air Canada Centre 19,800' computed as MAX(0), considering only rows where Game is in (33,34,35,36,37,38,39,40,41,42,43,44) and Date contains 'January' or where the length of High points is greater than 0, grouping results by Team, including only Teams with at least 2 games, and limiting the output to 5 results?","
SELECT ALL `Team`, COUNT(*) `Games`, AVG((substr(`High points`, instr(`High points`,'(')+1, instr(`High points`,')') - instr(`High points`,'(') -1) + 0)) AS `AvgHighPoints`, MAX((substr(`High points`, instr(`High points`,'(')+1, instr(`High points`,')') - instr(`High points`,'(') -1) + 0)) AS `MaxHighPoints`, SUM((instr(`High rebounds`, ',')>0)) `SharedReboundCount`, MAX(0) `January 11`, MAX(0) `Air Canada Centre 19,800` FROM `table_1_11960407_4` WHERE `Game` IN (33,34,35,36,37,38,39,40,41,42,43,44) AND instr(`Date`,'January')>0 OR length(`High points`)>0 GROUP BY `Team` HAVING COUNT(*)>=2 LIMIT 5;
","SELECT ALL col2, COUNT(*) AS `Games`, AVG((substr(col4, instr(col4,'(')+1, instr(col4,')') - instr(col4,'(') -1) + 0)) AS `AvgHighPoints`, MAX((substr(col4, instr(col4,'(')+1, instr(col4,')') - instr(col4,'(') -1) + 0)) AS `MaxHighPoints`, SUM((instr(col5, ',')>0)) AS `SharedReboundCount`, MAX(0) AS `January 11`, MAX(0) AS `Air Canada Centre 19,800` FROM `table_1_11960407_4` WHERE col0 IN (33,34,35,36,37,38,39,40,41,42,43,44) AND (instr(col1,'January')>0 OR length(col4)>0) GROUP BY col2 HAVING COUNT(*)>=1 LIMIT 5;","[('@ boston', 1, 24.0, 24, 1, 0, 0), ('@ detroit', 1, 16.0, 16, 0, 0, 0), ('@ new york', 1, 40.0, 40, 0, 0, 0), ('@ philadelphia', 1, 25.0, 25, 1, 0, 0), ('@ washington', 1, 37.0, 37, 0, 0, 0)]",table_1_11960407_4,"1) Parse the SQL intent: aggregate rows by Team computing Games (COUNT), average and max of the numeric value inside parentheses in High points, count of High rebounds entries containing a comma, and include two constant columns MAX(0). 2) Map schema semantics: Team, High points, High rebounds, Game, Date from the Game log table. 3) Draft the question: ask for those aggregated columns with the WHERE filter Game IN (33..44) and Date contains 'January' OR High points length > 0, GROUP BY Team HAVING COUNT(*)>=2, LIMIT 5. 4) Validate: ensures all columns, calculations, filters, grouping, having and limit are included.",reserved,13,reward,,
"Show games where Billups had at least 10 assists or scored 20+ points, with date, opponent, score, margin, attendance, high points, high assists and record?","
WITH parsed AS (
  SELECT
    `Game`,
    `Date`,
    `Team`,
    `Score`,
    `High points`,
    `High rebounds`,
    `High assists`,
    `Location Attendance`,
    `Record`,
    -- score body without leading 'W ' or 'L '
    substr(`Score`, 3) AS `score_body`,
    -- position of en-dash in score_body
    instr(substr(`Score`,3),'–') AS `dash_pos`,
    -- left and right numeric parts around en-dash
    CAST(substr(substr(`Score`,3),1,instr(substr(`Score`,3),'–')-1) AS INTEGER) AS `left_score`,
    CAST(substr(substr(`Score`,3),instr(substr(`Score`,3),'–')+1) AS INTEGER) AS `right_score`,
    -- Pistons margin (Pistons points minus opponent points; positive = Pistons win margin)
    CASE
      WHEN `Score` LIKE 'W %' THEN
        CAST(substr(substr(`Score`,3),1,instr(substr(`Score`,3),'–')-1) AS INTEGER) - CAST(substr(substr(`Score`,3),instr(substr(`Score`,3),'–')+1) AS INTEGER)
      ELSE
        CAST(substr(substr(`Score`,3),instr(substr(`Score`,3),'–')+1) AS INTEGER) - CAST(substr(substr(`Score`,3),1,instr(substr(`Score`,3),'–')-1) AS INTEGER)
    END AS `margin`,
    -- numeric attendance extracted from last 6 characters (e.g., '22,076')
    CAST(REPLACE(substr(`Location Attendance`,-6), ',', '') AS INTEGER) AS `attendance`,
    -- flags
    CASE WHEN `Team` LIKE '@ %' THEN 1 ELSE 0 END AS `is_away`,
    -- extract assists number inside parentheses for `High assists`
    CAST(substr(`High assists`, instr(`High assists`,'(')+1, instr(`High assists`,')') - instr(`High assists`,'(') - 1) AS INTEGER) AS `assists_num`,
    -- whether Billups is mentioned in High assists
    CASE WHEN `High assists` LIKE '%Billups%' THEN 1 ELSE 0 END AS `billups_in_assists`,
    -- Billups points when mentioned in High points (extract number in parentheses)
    CASE WHEN `High points` LIKE '%Billups%' THEN CAST(substr(`High points`, instr(`High points`,'(')+1, instr(`High points`,')') - instr(`High points`,'(') - 1) AS INTEGER) ELSE NULL END AS `billups_points`
  FROM `table_1_11960944_6`
)
SELECT
  'Home Biggest Crowd' AS `Insight_type`,
  `Date`,
  `Team`,
  `Score`,
  `margin`,
  `attendance`,
  `Location Attendance`,
  `High points`,
  `High assists`,
  `Record`
FROM parsed
WHERE `is_away` = 0
ORDER BY `attendance` DESC
LIMIT 1

UNION ALL

SELECT
  'Home Smallest Crowd' AS `Insight_type`,
  `Date`,
  `Team`,
  `Score`,
  `margin`,
  `attendance`,
  `Location Attendance`,
  `High points`,
  `High assists`,
  `Record`
FROM parsed
WHERE `is_away` = 0
ORDER BY `attendance` ASC
LIMIT 1

UNION ALL

SELECT
  'Billups Signature Moments' AS `Insight_type`,
  `Date`,
  `Team`,
  `Score`,
  `margin`,
  `attendance`,
  `Location Attendance`,
  `High points`,
  `High assists`,
  `Record`
FROM parsed
WHERE (
    -- Billups had double-digit assists
    (`billups_in_assists` = 1 AND `assists_num` >= 10)
    -- OR Billups is listed among high scorers with >=20 points (signature scoring moment)
    OR (`billups_points` IS NOT NULL AND `billups_points` >= 20)
  )
ORDER BY `Date`

UNION ALL

SELECT
  'Away Blowout (|margin|>=15)' AS `Insight_type`,
  `Date`,
  `Team`,
  `Score`,
  `margin`,
  `attendance`,
  `Location Attendance`,
  `High points`,
  `High assists`,
  `Record`
FROM parsed
WHERE `is_away` = 1
  AND ABS(`margin`) >= 15
ORDER BY `attendance` DESC;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    col7,
    col8,
    substr(col3, 3) AS `score_body`,
    instr(substr(col3,3),'–') AS `dash_pos`,
    CAST(substr(substr(col3,3),1,instr(substr(col3,3),'–')-1) AS INTEGER) AS `left_score`,
    CAST(substr(substr(col3,3),instr(substr(col3,3),'–')+1) AS INTEGER) AS `right_score`,
    CASE
      WHEN col3 LIKE 'W %' THEN
        CAST(substr(substr(col3,3),1,instr(substr(col3,3),'–')-1) AS INTEGER) - CAST(substr(substr(col3,3),instr(substr(col3,3),'–')+1) AS INTEGER)
      ELSE
        CAST(substr(substr(col3,3),instr(substr(col3,3),'–')+1) AS INTEGER) - CAST(substr(substr(col3,3),1,instr(substr(col3,3),'–')-1) AS INTEGER)
    END AS `margin`,
    CAST(REPLACE(substr(col7,-6), ',', '') AS INTEGER) AS `attendance`,
    CASE WHEN col2 LIKE '@ %' THEN 1 ELSE 0 END AS `is_away`,
    CAST(substr(col6, instr(col6,'(')+1, instr(col6,')') - instr(col6,'(') - 1) AS INTEGER) AS `assists_num`,
    CASE WHEN col6 LIKE '%Billups%' THEN 1 ELSE 0 END AS `billups_in_assists`,
    CASE WHEN col4 LIKE '%Billups%' THEN CAST(substr(col4, instr(col4,'(')+1, instr(col4,')') - instr(col4,'(') - 1) AS INTEGER) ELSE NULL END AS `billups_points`
  FROM `table_1_11960944_6`
)
SELECT
  'Home Biggest Crowd' AS `Insight_type`,
  col1,
  col2,
  col3,
  `margin`,
  `attendance`,
  col7,
  col4,
  col6,
  col8
FROM (SELECT * FROM parsed WHERE `is_away` = 0 ORDER BY `attendance` DESC LIMIT 1)

UNION ALL

SELECT
  'Home Smallest Crowd' AS `Insight_type`,
  col1,
  col2,
  col3,
  `margin`,
  `attendance`,
  col7,
  col4,
  col6,
  col8
FROM (SELECT * FROM parsed WHERE `is_away` = 0 ORDER BY `attendance` ASC LIMIT 1)

UNION ALL

SELECT
  'Billups Signature Moments' AS `Insight_type`,
  col1,
  col2,
  col3,
  `margin`,
  `attendance`,
  col7,
  col4,
  col6,
  col8
FROM parsed
WHERE (
    (`billups_in_assists` = 1 AND `assists_num` >= 10)
    OR (`billups_points` IS NOT NULL AND `billups_points` >= 20)
  )

UNION ALL

SELECT
  'Away Blowout (|margin|>=15)' AS `Insight_type`,
  col1,
  col2,
  col3,
  `margin`,
  `attendance`,
  col7,
  col4,
  col6,
  col8
FROM parsed
WHERE `is_away` = 1
  AND ABS(`margin`) >= 15
ORDER BY `attendance` DESC;","[('Home Biggest Crowd', 'february 3', 'dallas', 'w 90–67', 23, 22076, 'the palace of auburn hills 22,076', 'wallace (21)', 'hamilton (7)', '34–13'), ('Home Smallest Crowd', 'february 3', 'dallas', 'w 90–67', 23, 22076, 'the palace of auburn hills 22,076', 'wallace (21)', 'hamilton (7)', '34–13'), ('Billups Signature Moments', 'february 6', 'miami', 'w 100–95', 5, 22076, 'the palace of auburn hills 22,076', 'wallace (26)', 'billups (10)', '35–13'), ('Billups Signature Moments', 'february 22', 'milwaukee', 'w 127–100', 27, 22076, 'the palace of auburn hills 22,076', 'billups (21)', 'billups (12)', '40–15'), ('Billups Signature Moments', 'february 24', '@ phoenix', 'w 116–86', 30, 18422, 'us airways center 18,422', 'wallace (22)', 'billups (11)', '41–15'), ('Away Blowout (|margin|>=15)', 'february 24', '@ phoenix', 'w 116–86', 30, 18422, 'us airways center 18,422', 'wallace (22)', 'billups (11)', '41–15'), ('Billups Signature Moments', 'february 25', '@ denver', 'w 98–93', 5, 17901, 'pepsi center 17,901', 'billups , hamilton , prince (20)', 'prince (9)', '42–15'), ('Billups Signature Moments', 'february 20', '@ milwaukee', 'l 103–98', -5, 14211, 'bradley center 14,211', 'billups (34)', 'billups , prince (6)', '39–15')]",table_1_11960944_6,"Persona note: I'm hunting for Billups signature moments to accent with musical cues, so I ask about nights he either dished out double-digit assists or dropped a 20+ scoring outing. SQL intent: return games where Billups appears in the High assists string with the assists number >=10 or where Billups is among the High points with 20+ points. Schema mapping: the query parses numbers from High assists and High points and flags Billups when his name appears, then returns date, opponent, score, margin, attendance, top stats and record. Draft question: Show games where Billups had at least 10 assists or scored 20+ points, with date, opponent, score, margin, attendance, high points, high assists and record. Validation: This matches the filter for billups_in_assists plus assists_num >=10 or billups_points >=20.",persona,"""Goals"": [ ""Identify the home games with the largest and smallest crowd sizes to map expected crowd timbre and intensity for soundtrack layering."", ""Find games where key players (e.g., Billups) posted high assists or scoring outbursts so the soundtrack can accentuate signature player moments."", ""Locate away games and blowouts (big margins) to study how different arena atmospheres and lopsided momentum affect crowd frequency content for sampling."" ], ""Example queries"": [ ""/* 1) Home games with parsed attendance and score margin, ordered by attendance (MySQL-style) */\nSELECT `Date`, `Team`, `Score`, `Location Attendance`, `Record`,\n  -- extract Pistons score and opponent score from 'W 90–67' or 'L 103–85'\n  (CAST(SUBSTRING_INDEX(SUBSTRING(`Score`, 3), '–', 1) AS UNSIGNED) - CAST(SUBSTRING_INDEX(SUBSTRING(`Score`, 3), '–', -1) AS UNSIGNED)) AS margin,\n  -- extract numeric attendance (last token) and remove comma\n  CAST(REPLACE(SUBSTRING_INDEX(`Location Attendance`, ' ', -1), ',', '') AS UNSIGNED) AS attendance\nFROM `table_1_11960944_6`\nWHERE `Team` NOT LIKE '@%'\nORDER BY attendance DESC;"", ""/* 2) Games where a player recorded double-digit assists (extract number from 'Player (n)') */\nSELECT `Date`, `Team`, `Score`, `High points`, `High assists`, `Location Attendance`\nFROM `table_1_11960944_6`\nWHERE CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(`High assists`, '(', -1), ')', 1) AS UNSIGNED) >= 10\nORDER BY `Date`;"", ""/* 3) Away games that were losses with large margins in opponent arenas with >22000 attendance */\nSELECT `Date`, `Team`, `Score`, `High points`, `High rebounds`, `Location Attendance`, `Record`,\n  (CAST(SUBSTRING_INDEX(SUBSTRING(`Score`, 3), '–', 1) AS UNSIGNED) - CAST(SUBSTRING_INDEX(SUBSTRING(`Score`, 3), '–', -1) AS UNSIGNED)) AS margin,\n  CAST(REPLACE(SUBSTRING_INDEX(`Location Attendance`, ' ', -1), ',', '') AS UNSIGNED) AS attendance\nFROM `table_1_11960944_6`\nWHERE `Team` LIKE '@%'\n  AND `Score` LIKE 'L %'\n  AND CAST(REPLACE(SUBSTRING_INDEX(`Location Attendance`, ' ', -1), ',', '') AS UNSIGNED) > 22000\n  AND ABS((CAST(SUBSTRING_INDEX(SUBSTRING(`Score`, 3), '–', 1) AS UNSIGNED) - CAST(SUBSTRING_INDEX(SUBSTRING(`Score`, 3), '–', -1) AS UNSIGNED))) >= 15\nORDER BY attendance DESC;"" } ``` Goals:  Example Queries: ",reward,,
"For games with Game IN (16,17,18,19,20,21,22,23,24,25,26,27), grouped by Location Attendance (Arena), what are the Arena name, the average attendance computed by converting the attendance portion of Location Attendance to a number (remove commas), the total Wins (Score starting with 'W'), the total Losses (Score starting with 'L'), and the maximum high points value obtained by extracting the number inside parentheses in High points; only include arenas where Wins >= 1 and the maximum parsed High points > 20 or where Losses > 0, order the results by the average attendance descending and limit the output to 5 arenas?","
SELECT `Location Attendance` Arena,
AVG(REPLACE(SUBSTR(`Location Attendance`, INSTR(`Location Attendance`,' ')+1), ',', '')+0) AS `AvgAttendance`,
SUM(SUBSTR(`Score`,1,1)='W') Wins,
SUM(SUBSTR(`Score`,1,1)='L') Losses,
MAX(SUBSTR(`High points`, INSTR(`High points`,'(')+1, INSTR(`High points`,')')-INSTR(`High points`,'(')-1)+0) MaxHighPoints
FROM `table_1_11961582_4`
WHERE `Game` IN (16,17,18,19,20,21,22,23,24,25,26,27)
GROUP BY `Location Attendance`
HAVING SUM(SUBSTR(`Score`,1,1)='W')>=1 AND MAX(SUBSTR(`High points`, INSTR(`High points`,'(')+1, INSTR(`High points`,')')-INSTR(`High points`,'(')-1)+0)>20 OR SUM(SUBSTR(`Score`,1,1)='L')>0
ORDER BY `AvgAttendance` DESC
LIMIT 5;
","SELECT col7 AS Arena, AVG(REPLACE(SUBSTR(col7, INSTR(col7,' ')+1), ',', '')+0) AS `AvgAttendance`, SUM(SUBSTR(col3,1,1)='W') AS Wins, SUM(SUBSTR(col3,1,1)='L') AS Losses, MAX(SUBSTR(col4, INSTR(col4,'(')+1, INSTR(col4,')')-INSTR(col4,'(')-1)+0) AS `MaxHighPoints`
FROM `table_1_11961582_4`
WHERE col0 IN (16,17,18,19,20,21,22,23,24,25,26,27)
GROUP BY col7
HAVING MAX(SUBSTR(col4, INSTR(col4,'(')+1, INSTR(col4,')')-INSTR(col4,'(')-1)+0) > 20
ORDER BY `AvgAttendance`
LIMIT 5;","[('amway arena 16,821', 0.0, 0, 0, 25), ('philips arena 12,232', 0.0, 0, 0, 28), ('philips arena 13,173', 0.0, 0, 0, 23), ('philips arena 14,040', 0.0, 0, 0, 31), ('philips arena 15,263', 0.0, 0, 0, 26)]",table_1_11961582_4,"1) Parse the SQL intent: for games 16–27 compute per-arena average parsed attendance, count wins and losses from Score's first char, and find the max numeric value inside High points parentheses, then filter using the HAVING logic and limit to five by highest average attendance. 2) Map schema semantics: Location Attendance holds venue and attendance with commas, Score indicates result by its first letter, High points embeds the number in parentheses. 3) Draft the question to request those aggregated values and to state the precise filters, sorting, and limit. 4) Validate: confirm all SQL elements (Game list, parsing rules, counts, max, HAVING, ORDER BY, LIMIT) are reflected.",reserved,13,reward,,
"For every row with ((trim(substr(Score,1,instr(Score,'–')-1))+0)-(trim(substr(Score,instr(Score,'–')+1))+0)) != 0, list Game, Date, Team, Score, Left Score as (trim(substr(Score,1,instr(Score,'–')-1))+0), Right Score as (trim(substr(Score,instr(Score,'–')+1))+0), Margin equal to (Left Score - Right Score), Attendance equal to (replace(replace(replace(Location Attendance,'New Orleans Arena ',''),'AT&T Center ',''),',','')+0), Is Away equal to instr(Team,'@'), Close Game defined by abs(Margin) <= 5, and the field 'New Orleans Arena 18,040' equal to (trim(substr(Score,1,instr(Score,'–')-1))+0)?","
SELECT `Game`,`Date`,`Team`,`Score`,
(trim(substr(`Score`,1,instr(`Score`,'–')-1))+0) `Left Score`,
(trim(substr(`Score`,instr(`Score`,'–')+1))+0) `Right Score`,
((trim(substr(`Score`,1,instr(`Score`,'–')-1))+0)-(trim(substr(`Score`,instr(`Score`,'–')+1))+0)) `Margin`,
(replace(replace(replace(`Location Attendance`,'New Orleans Arena ',''),'AT&T Center ',''),',','')+0) `Attendance`,
instr(`Team`,'@') `Is Away`,
abs(((trim(substr(`Score`,1,instr(`Score`,'–')-1))+0)-(trim(substr(`Score`,instr(`Score`,'–')+1))+0)))<=5 `Close Game`,
(trim(substr(`Score`,1,instr(`Score`,'–')-1))+0) `New Orleans Arena 18,040`
FROM `table_1_11963536_11`
WHERE ((trim(substr(`Score`,1,instr(`Score`,'–')-1))+0)-(trim(substr(`Score`,instr(`Score`,'–')+1))+0))!=0;
","
SELECT col0,col1,col2,col3,
(trim(substr(col3,1,instr(col3,'–')-1))+0) `Left Score`,
(trim(substr(col3,instr(col3,'–')+1))+0) `Right Score`,
((trim(substr(col3,1,instr(col3,'–')-1))+0)-(trim(substr(col3,instr(col3,'–')+1))+0)) `Margin`,
(replace(replace(replace(col7,'New Orleans Arena ',''),'AT&T Center ',''),',','')+0) `Attendance`,
instr(col2,'@') `Is Away`,
abs(((trim(substr(col3,1,instr(col3,'–')-1))+0)-(trim(substr(col3,instr(col3,'–')+1))+0)))<=5 `Close Game`,
(trim(substr(col3,1,instr(col3,'–')-1))+0) `New Orleans Arena 18,040`
FROM `table_1_11963536_11`
WHERE ((trim(substr(col3,1,instr(col3,'–')-1))+0)-(trim(substr(col3,instr(col3,'–')+1))+0))!=0;
","[(1.0, 'may 3', 'san antonio', '101–82', 101, 82, 19, 0, 0, 0, 101), (2.0, 'may 5', 'san antonio', '102–84', 102, 84, 18, 0, 0, 0, 102), (3.0, 'may 8', '@ san antonio', '99–110', 99, 110, -11, 0, 1, 0, 99), (4.0, 'may 11', '@ san antonio', '80–100', 80, 100, -20, 0, 1, 0, 80), (5.0, 'may 13', 'san antonio', '101–79', 101, 79, 22, 0, 0, 0, 101), (6.0, 'may 15', '@ san antonio', '80–99', 80, 99, -19, 0, 1, 0, 80)]",table_1_11963536_11,"1) Parse SQL intent: extract game identifiers and detailed numeric breakdowns from Score, compute margin and a numeric attendance, flag away games and close games, exclude tied games. 2) Map schema: use Score and Location Attendance string operations and Team to derive values. 3) Draft question: request all listed columns and transformations for rows with nonzero margin. 4) Validate: ensure inclusion of Left Score, Right Score, Margin, Attendance conversion, instr(Team,'@'), Close Game condition, and the duplicated Left Score alias.",reserved,3,reward,,
"List each Team (using the Home column) for which Attendance contains 'Rose Garden', along with Home_Wins calculated as the number of those games whose Score's first character is 'L', Home_Games as the total number of those games, and Avg_Attendance as the average attendance after stripping the substring 'Rose Garden ' and removing commas; include only teams with at least one such game and present the results ordered by Home_Wins.","
SELECT `Home` AS `Team`, SUM(substr(`Score`,1,1)='L') `Home_Wins`, COUNT(*) `Home_Games`, CASE WHEN COUNT(*)>0 THEN AVG(REPLACE(REPLACE(`Attendance`,'Rose Garden ',''),',','')) END `Avg_Attendance` FROM `table_1_11964047_10` WHERE `Attendance` LIKE '%Rose Garden%' GROUP BY `Home` HAVING COUNT(*)>0 ORDER BY `Home_Wins`;
","
SELECT col4 AS `Team`, SUM(substr(col3,1,1)='L') `Home_Wins`, COUNT(*) `Home_Games`, CASE WHEN COUNT(*)>0 THEN AVG(REPLACE(REPLACE(col6,'Rose Garden ',''),',','')) END `Avg_Attendance` FROM `table_1_11964047_10` WHERE col6 LIKE '%Rose Garden%' GROUP BY col4 HAVING COUNT(*)>0 ORDER BY `Home_Wins`;
","[('portland trail blazers', 0, 5, 0.0)]",table_1_11964047_10,"1) The query computes per-Home aggregates only for rows whose Attendance includes 'Rose Garden', counts rows, sums a boolean on the first character of Score, and averages a cleaned Attendance value, then orders by that sum. 2) Map these to natural language: Team from Home, Home_Wins = count where Score begins with 'L', Home_Games = COUNT(*), Avg_Attendance = average of Attendance after removing 'Rose Garden ' and commas. 3) Write a question asking for those exact fields, specifying the Attendance filter, grouping requirement, minimum count, and ordering. 4) Ensure no extra information beyond the SQL is introduced.",reserved,12,reward,,
"For each Home value, can you provide Venue = Home, Games = COUNT(*), Wins = SUM(substr(Score,1,1) = 'W'), Losses = SUM(substr(Score,1,1) = 'L'), and AvgTopPoints = AVG(substr(Leading scorer, instr(Leading scorer, ':')+2)), grouped by Home and ordered by Wins descending, limited to the top 5 rows?","
SELECT `table_1_11964047_8`.`Home` `Venue`, COUNT(*) `Games`, SUM(substr(`Score`,1,1) = 'W') `Wins`, SUM(substr(`Score`,1,1) = 'L') `Losses`, AVG(substr(`Leading scorer`, instr(`Leading scorer`, ':')+2)) `AvgTopPoints`
FROM `table_1_11964047_8` JOIN `table_1_11964047_8` `t2` ON `table_1_11964047_8`.`#` = `t2`.`#` AND `table_1_11964047_8`.`Date` = `t2`.`Date`
WHERE 1=1
GROUP BY `table_1_11964047_8`.`Home`
ORDER BY `Wins` DESC
LIMIT 5;
","SELECT col4 AS `Venue`, COUNT(*) AS `Games`, SUM(substr(col3,1,1) = 'W') AS `Wins`, SUM(substr(col3,1,1) = 'L') AS `Losses`, AVG(CAST(ltrim(substr(col5, instr(col5, ':')+2)) AS INTEGER)) AS `AvgTopPoints`
FROM `table_1_11964047_8`
WHERE 1=1
GROUP BY col4
ORDER BY `Wins` DESC
LIMIT 5;","[('seattle supersonics', 1, 0, 0, 26.0), ('portland trail blazers', 6, 0, 0, 25.833333333333332), ('los angeles lakers', 1, 0, 0, 30.0), ('los angeles clippers', 1, 0, 0, 32.0), ('indiana pacers', 1, 0, 0, 29.0)]",table_1_11964047_8,"1) Parse SQL intent: group games by Home to compute Games, Wins (Score starts 'W'), Losses (Score starts 'L'), and average numeric top-scorer points parsed after ':'; then order by Wins descending and limit to 5. 2) Map schema: Home is venue, Score and Leading scorer supply W/L and points. 3) Draft: request those exact aggregates and sorting/limit. 4) Validate: all expressions and grouping/ordering/limit are present.",reserved,12,reward,,
"How many finals were there, how many different champions have there been, what was the average and highest final attendance, and how many finals went to penalties?","
SELECT COUNT(`Season`) `Total Finals`, COUNT(DISTINCT `WinningTeam`) `Unique Champions`, AVG(`Cup Final Attendance`) `Average Attendance`, MAX(`Cup Final Attendance`) `Max Attendance`, SUM(instr(`Score`,'Penalties')>0) `Penalty Finals` FROM `table_1_12028543_3` WHERE `Cup Final Attendance`>0 LIMIT 1;
","
SELECT COUNT(col0) `Total Finals`, COUNT(DISTINCT col2) `Unique Champions`, AVG(col6) `Average Attendance`, MAX(col6) `Max Attendance`, SUM(instr(col3,'Penalties')>0) `Penalty Finals` FROM `table_1_12028543_3` WHERE col6>0 LIMIT 1;
","[(17, 16, 7190.470588235294, 11187.0, 0)]",table_1_12028543_3,"STEP 1: Parse the SQL intent — The query restricts to rows where Cup Final Attendance > 0 and returns aggregates: COUNT(Season) as Total Finals, COUNT(DISTINCT WinningTeam) as Unique Champions, AVG(Cup Final Attendance) as Average Attendance, MAX(Cup Final Attendance) as Max Attendance, and SUM(instr(Score,'Penalties')>0) as Penalty Finals. STEP 2: Choose an ambiguity type — Entity vagueness fits: the WinningTeam values include parenthetical title counts (e.g. 'Brisbane City (1)'), so ""champions"" could mean club identity or the exact stored strings. STEP 3: Draft the question — ""How many finals were there, how many different champions have there been, what was the average and highest final attendance, and how many finals went to penalties?"" STEP 4: Explain the ambiguity — In the original query Unique Champions is COUNT(DISTINCT WinningTeam) which treats each stored WinningTeam string (including parenthetical annotations) as distinct; alternatively the question could ask for distinct club names ignoring the annotations (grouping 'Brisbane City (1)' and 'Brisbane City (2)' as the same club), yielding a different count.",reserved,5,reward,,"type: Entity Vagueness | explanation: The phrase 'different champions' is ambiguous: the SQL counts distinct WinningTeam strings (so annotated variants like 'Brisbane City (1)' and 'Brisbane City (2)' are treated as separate champions), whereas a natural interpretation might count unique club names ignoring parenthetical title counts, producing a different result."
"Which distinct entries from the 'Directed by' column (returned as 'Director') have a Production code matching the pattern '1ADK-%', when ordered by Director and limited to 3 results?","
SELECT DISTINCT `Directed by` AS `Director` FROM `table_1_12033013_1` WHERE `Production code` LIKE '1ADK-%' AND 1=1 ORDER BY `Director` LIMIT 3;
","
SELECT DISTINCT col2 AS `Director` FROM `table_1_12033013_1` WHERE col5 LIKE '1ADK-%' AND 1=1 ORDER BY `Director` LIMIT 3;
","[('david lee',), ('howard murray',), ('jack kenny',)]",table_1_12033013_1,"1) Parse SQL intent: fetch distinct values from 'Directed by' aliased as Director with a WHERE clause 'Production code' LIKE '1ADK-%', order results by Director and limit to 3. 2) Map schema semantics: use 'Directed by' for names and 'Production code' for filtering by the '1ADK-%' pattern. 3) Draft a concise question that requests those distinct director names with the specified ordering and limit. 4) Validate that the question explicitly mentions DISTINCT, the alias 'Director', the LIKE filter '1ADK-%', ORDER BY Director, and LIMIT 3.",reserved,10,reward,,
"Which episodes have any of these problems — multi-episode numbering (slashes), an original air date missing a space, a production code that doesn't start with '3', or director/writer fields lacking proper delimiters?","
WITH `t` AS (
  SELECT
    `No. in series`,
    `No. in season`,
    `Title`,
    `Directed by`,
    `Written by`,
    `Original air date`,
    `Production code`,
    CASE WHEN instr(`No. in series`, '/') > 0 OR instr(`No. in season`, '/') > 0 THEN 1 ELSE 0 END AS `MultiEpisode`,
    CASE WHEN instr(`Original air date`, ' ') = 0 THEN 1 ELSE 0 END AS `AirDateMissingSpace`,
    CASE WHEN cast(substr(`Production code`, 1, 1) AS integer) != 3 THEN 1 ELSE 0 END AS `ProdSeasonMismatch`,
    CASE WHEN `Directed by` NOT LIKE '%,%' AND `Directed by` NOT LIKE '%&%' AND `Directed by` LIKE '% % %' THEN 1 ELSE 0 END AS `DirectorDelimiterIssue`,
    CASE WHEN `Written by` NOT LIKE '%,%' AND `Written by` NOT LIKE '%&%' AND `Written by` LIKE '% % %' THEN 1 ELSE 0 END AS `WriterDelimiterIssue`,
    cast(
      CASE
        WHEN instr(`No. in season`, '/') > 0 THEN substr(`No. in season`, 1, instr(`No. in season`, '/') - 1)
        ELSE `No. in season`
      END
    AS integer) AS `SeasonFromNoInSeason`,
    substr(`Production code`, 1, 1) AS `ProdSeasonChar`
  FROM `table_1_12033013_3`
)
SELECT
  '`' || `No. in series` || '`' AS `No. in series`,
  '`' || `No. in season` || '`' AS `No. in season`,
  '`' || `Title` || '`' AS `Title`,
  '`' || `Directed by` || '`' AS `Directed by`,
  '`' || `Written by` || '`' AS `Written by`,
  '`' || `Original air date` || '`' AS `Original air date`,
  '`' || `Production code` || '`' AS `Production code`,
  `MultiEpisode`,
  `AirDateMissingSpace`,
  `ProdSeasonMismatch`,
  `DirectorDelimiterIssue`,
  `WriterDelimiterIssue`,
  `SeasonFromNoInSeason`,
  `ProdSeasonChar`
FROM `t`
WHERE `MultiEpisode` = 1
   OR `AirDateMissingSpace` = 1
   OR `ProdSeasonMismatch` = 1
   OR `DirectorDelimiterIssue` = 1
   OR `WriterDelimiterIssue` = 1
;
","
WITH `t` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    CASE WHEN instr(col0, '/') > 0 OR instr(col1, '/') > 0 THEN 1 ELSE 0 END AS `MultiEpisode`,
    CASE WHEN instr(col5, ' ') = 0 THEN 1 ELSE 0 END AS `AirDateMissingSpace`,
    CASE WHEN cast(substr(col6, 1, 1) AS integer) != 3 THEN 1 ELSE 0 END AS `ProdSeasonMismatch`,
    CASE WHEN col3 NOT LIKE '%,%' AND col3 NOT LIKE '%&%' AND col3 LIKE '% % %' THEN 1 ELSE 0 END AS `DirectorDelimiterIssue`,
    CASE WHEN col4 NOT LIKE '%,%' AND col4 NOT LIKE '%&%' AND col4 LIKE '% % %' THEN 1 ELSE 0 END AS `WriterDelimiterIssue`,
    cast(
      CASE
        WHEN instr(col1, '/') > 0 THEN substr(col1, 1, instr(col1, '/') - 1)
        ELSE col1
      END
    AS integer) AS `SeasonFromNoInSeason`,
    substr(col6, 1, 1) AS `ProdSeasonChar`
  FROM `table_1_12033013_3`
)
SELECT
  '`' || col0 || '`' AS col0,
  '`' || col1 || '`' AS col1,
  '`' || col2 || '`' AS col2,
  '`' || col3 || '`' AS col3,
  '`' || col4 || '`' AS col4,
  '`' || col5 || '`' AS col5,
  '`' || col6 || '`' AS col6,
  `MultiEpisode`,
  `AirDateMissingSpace`,
  `ProdSeasonMismatch`,
  `DirectorDelimiterIssue`,
  `WriterDelimiterIssue`,
  `SeasonFromNoInSeason`,
  `ProdSeasonChar`
FROM `t`
WHERE `MultiEpisode` = 1
   OR `AirDateMissingSpace` = 1
   OR `ProdSeasonMismatch` = 1
   OR `DirectorDelimiterIssue` = 1
   OR `WriterDelimiterIssue` = 1
;
","[('`34`', '`1`', '`""racing in the streets""`', '`brian hargrove`', '`chris sheridan`', '`november14,2001`', '`3adk-01`', 0, 1, 0, 0, 0, 1, '3'), ('`35`', '`2`', '`""amy\'s birthday""`', '`gary shimokawa`', '`john r. morey`', '`november21,2001`', '`3adk-03`', 0, 1, 0, 0, 1, 2, '3'), ('`36`', '`3`', '`""tommy\'s not gay""`', '`gary shimokawa`', '`christopher case`', '`november28,2001`', '`3adk-04`', 0, 1, 0, 0, 0, 3, '3'), ('`37`', '`4`', '`""shannon\'s song""`', '`joe regalbuto`', '`sally lapiduss`', '`december5,2001`', '`3adk-08`', 0, 1, 0, 0, 0, 4, '3'), ('`38`', '`5`', '`""grad school""`', '`gary shimokawa`', '`jennifer fisher`', '`december12,2001`', '`3adk-02`', 0, 1, 0, 0, 0, 5, '3'), ('`39`', '`6`', '`""houseboat""`', '`joe regalbuto`', '`jim hope`', '`december19,2001`', '`3adk-06`', 0, 1, 0, 0, 0, 6, '3'), ('`40`', '`7`', '`""the trial""`', '`jack kenny`', '`christopher titus`', '`january2,2002`', '`3adk-05`', 0, 1, 0, 0, 0, 7, '3'), ('`41`', '`8`', '`""grandma titus""`', '`brian hargrove`', '`shawn thomas`', '`january9,2002`', '`2adk-25`', 0, 1, 1, 0, 0, 8, '2'), ('`42`', '`9`', '`""errrr""`', '`jack kenny`', '`chris sheridan`', '`january16,2002`', '`3adk-13`', 0, 1, 0, 0, 0, 9, '3'), ('`43`', '`10`', '`""tommy\'s crush""`', '`kevin rodney sullivan`', '`patrick meighan`', '`january23,2002`', '`3adk-09`', 0, 1, 0, 1, 0, 10, '3'), ('`44`', '`11`', '`""into thin air""`', '`john amodeo`', '`robert hawkins`', '`january30,2002`', '`3adk-11`', 0, 1, 0, 0, 0, 11, '3'), ('`45`', '`12`', '`""too damn good""`', '`gary shimokawa`', '`david l. moses`', '`february6,2002`', '`3adk-16`', 0, 1, 0, 0, 1, 12, '3'), ('`46`', '`13`', '`""bachelor party""`', '`leslie kolins small`', '`jennifer fisher`', '`february13,2002`', '`3adk-15`', 0, 1, 0, 1, 0, 13, '3'), ('`47`', '`14`', '`""hot streak""`', '`joe regalbuto`', '`patrick meighan & john r. morey`', '`february20,2002`', '`3adk-14`', 0, 1, 0, 0, 0, 14, '3'), ('`48`', '`15`', '`""the session""`', '`brian hargrove`', '`matt ember`', '`march6,2002`', '`3adk-10`', 0, 1, 0, 0, 0, 15, '3'), ('`49`', '`16`', '`""same courtesy""`', '`bill shea`', '`christopher case`', '`march20,2002`', '`3adk-12`', 0, 1, 0, 0, 0, 16, '3'), ('`50`', '`17`', '`""after mrs. shafter""`', '`bill shea`', '`shawn thomas`', '`july29,2002`', '`3adk-17`', 0, 1, 0, 0, 0, 17, '3'), ('`51`', '`18`', '`""the visit""`', '`katy garretson`', '`christopher titus`', '`july29,2002`', '`3adk-18`', 0, 1, 0, 0, 0, 18, '3'), ('`52/53`', '`19/20`', '`""insanity genetic""`', '`kevin rodney sullivan gary shimokawa`', '`jim hope nancy steen & matt ember`', '`august5,2002`', '`3adk-19/3adk-20`', 1, 1, 0, 1, 0, 19, '3')]",table_1_12033013_3,"I'm a metadata manager familiar with episode numbering, credits, air dates and production codes and I speak in terms like 'No. in season' and 'production code'. The query flags rows with various formatting/consistency problems. It checks for slashes in numbering (multi-episode), original air dates missing a space, production codes whose first character isn't 3, and credit delimiter issues. Draft question: Which episodes have any of these problems — multi-episode numbering (slashes), an original air date missing a space, a production code that doesn't start with '3', or director/writer fields lacking proper delimiters? This exactly matches the set of rows the query returns.",persona,"```json
{
  ""short_persona_description"": ""Streaming Metadata Manager at a video-on-demand service responsible for importing and normalizing episode metadata for catalogue pages and staff-facing dashboards. They use this database to validate episode order, attribute credits correctly, and detect inconsistent or duplicate metadata before publishing."",
  ""goals"": [
    ""Verify and normalize episode ordering and season numbering for the catalogue."",
    ""Ensure director and writer credits are attrib Goals:  Example Queries: ",reward,,
"For each Hakka initial, which area has a population density closest to the density calculated from its population and area?","
WITH `candidates` AS (
  SELECT
    `English Name`,
    `Hakka`,
    CASE WHEN instr(`Hakka`, '-') > 0 THEN substr(`Hakka`, 1, instr(`Hakka`, '-') - 1) ELSE `Hakka` END AS `Hakka_initial`,
    `Area`,
    `Population`,
    `Density`,
    (`Population` / `Area`) AS `calc_density`,
    ((`Population` / `Area`) - `Density`) AS `density_diff`,
    abs((`Population` / `Area`) - `Density`) AS `abs_density_diff`
  FROM `table_1_1204998_2`
  WHERE `Population` BETWEEN 200000 AND 400000
    AND `Density` BETWEEN 100 AND 170
)
SELECT
  `English Name`,
  `Hakka`,
  `Hakka_initial`,
  `Area`,
  `Population`,
  `Density`,
  `calc_density`,
  `density_diff`,
  `abs_density_diff`
FROM `candidates` AS c
WHERE `abs_density_diff` = (
  SELECT MIN(`abs_density_diff`)
  FROM `candidates` AS c2
  WHERE c2.`Hakka_initial` = c.`Hakka_initial`
)
ORDER BY `Hakka_initial`;
","
WITH `candidates` AS (
  SELECT
    col0,
    col4,
    CASE WHEN instr(col4, '-') > 0 THEN substr(col4, 1, instr(col4, '-') - 1) ELSE col4 END AS `Hakka_initial`,
    col5,
    col6,
    col7,
    (col6 / col5) AS `calc_density`,
    ((col6 / col5) - col7) AS `density_diff`,
    abs((col6 / col5) - col7) AS `abs_density_diff`
  FROM `table_1_1204998_2`
  WHERE col6 BETWEEN 200000 AND 400000
    AND col7 BETWEEN 100 AND 170
)
SELECT
  col0,
  col4,
  `Hakka_initial`,
  col5,
  col6,
  col7,
  `calc_density`,
  `density_diff`,
  `abs_density_diff`
FROM `candidates` AS c
WHERE `abs_density_diff` = (
  SELECT MIN(`abs_density_diff`)
  FROM `candidates` AS c2
  WHERE c2.`Hakka_initial` = c.`Hakka_initial`
)
ORDER BY `Hakka_initial`;
","[('shanghang county', 'sông-hông-yen', 'sông', 2879.0, 374047.0, 130.0, 129.92254254949634, -0.07745745050365827, 0.07745745050365827), ('changting county', 'tshòng-tin-yen', 'tshòng', 3099.0, 393390.0, 127.0, 126.94094869312681, -0.059051306873186604, 0.059051306873186604), ('wuping county', 'vú-phìn-yen', 'vú', 2630.0, 278182.0, 106.0, 105.77262357414449, -0.22737642585551043, 0.22737642585551043), ('yongding county', 'yún-thin-yen', 'yún', 2216.0, 362658.0, 164.0, 163.6543321299639, -0.34566787003609534, 0.34566787003609534)]",table_1_1204998_2,"STEP 1: Parse the SQL intent — select rows with Population between 200,000 and 400,000 and Density between 100 and 170, compute calc_density = Population / Area and the absolute difference from reported Density, then for each Hakka_initial (substring of Hakka before a '-') choose the row(s) with the minimum abs difference and order by Hakka_initial. STEP 2: Determine ambiguity type — scope ambiguity fits well because the SQL finds the minimum per Hakka_initial, but a natural-language phrasing using words like ""each"" or ""for each"" can also be read as asking for a single overall minimum. STEP 3: Draft the question — ""For each Hakka initial, which area has a population density closest to the density calculated from its population and area?"" STEP 4: Explain the ambiguity — the original query interprets ""for each Hakka initial"" as grouping by Hakka_initial and returning the best-matching area within each group; alternatively the question could be read as asking for just one area overall whose density is closest to its calculated density (ignoring Hakka_initial grouping).",persona,"An itinerant Hakka oral‑history podcaster and acoustic archivist who plans tiny live recording sessions across Longyan’s counties and uses local Hakka names to curate authentic, place‑specific episodes. Goals: Identify administrative areas whose Hakka place‑names start with distinct phonemes (to craft episode titles and show intros with authentic local flavor). Choose counties/districts with mid-sized populations and moderate population density suitable for intimate, in‑person listening events (not too crowded, not too sparse). Verify that the published density matches population/area calculations to detect possible data quirks that might affect travel logistics or venue sizing. Example Queries: SELECT ""English Name"", ""Hakka"", ""Pinyin"", ""Population"", ""Density""
FROM table_1_1204998_2
WHERE ""Hakka"" LIKE 'S%'
ORDER BY ""Population"" DESC; SELECT ""English Name"", ""Area"", ""Population"", ""Density""
FROM table_1_1204998_2
WHERE ""Population"" BETWEEN 200000 AND 400000
  AND ""Density"" BETWEEN 100 AND 150
ORDER BY ""Density"" ASC; SELECT ""English Name"", ""Area"", ""Population"", (""Population"" / ""Area"") AS calc_density, ""Density"", ((""Population"" / ""Area"") - ""Density"") AS density_diff
FROM table_1_1204998_2
ORDER BY density_diff DESC;",reward,,"type: Scope ambiguity | explanation: The phrase ""For each Hakka initial"" can be read two ways: (a) as a grouping scope — return the closest area within every Hakka_initial (what the SQL does), or (b) as a loose/prepositional phrase that could mean ""which single area (across all initials) is closest"", producing a single overall answer instead of one per initial."
"For each NetFlow Version and the IPv6_Status computed as 'IPv6 mentioned' when the Comments field contains 'IPv6' (NULL otherwise), provide the COUNT(*) of rows and the MAX of the literal '`Comprehensive support for IPv6 and MPLS`' as Exemplar_Comment for groups with COUNT>0, ordered by NetFlow Version and limited to 100 results?","
SELECT `NetFlow Version`, CASE WHEN instr(`Comments`, 'IPv6')>0 THEN 'IPv6 mentioned' END `IPv6_Status`, COUNT(*) `Count`, MAX('`Comprehensive support for IPv6 and MPLS`') `Exemplar_Comment` FROM `table_1_1206114_2` WHERE 1 GROUP BY `NetFlow Version`, `IPv6_Status` HAVING COUNT(*)>0 ORDER BY `NetFlow Version` LIMIT 100;
","
SELECT col2, CASE WHEN instr(col4, 'IPv6')>0 THEN 'IPv6 mentioned' END `IPv6_Status`, COUNT(*) `Count`, MAX('`Comprehensive support for IPv6 and MPLS`') `Exemplar_Comment` FROM `table_1_1206114_2` WHERE 1 GROUP BY col2, `IPv6_Status` HAVING COUNT(*)>0 ORDER BY col2 LIMIT 100;
","[('v5', None, 1, '`Comprehensive support for IPv6 and MPLS`'), ('v5, v8, v9', None, 1, '`Comprehensive support for IPv6 and MPLS`'), ('v5, v8, v9, ipfix', None, 1, '`Comprehensive support for IPv6 and MPLS`'), ('v5, v9', None, 2, '`Comprehensive support for IPv6 and MPLS`'), ('v5, v9, ipfix', None, 1, '`Comprehensive support for IPv6 and MPLS`')]",table_1_1206114_2,"1) The query groups by NetFlow Version and a CASE expression that detects 'IPv6' in Comments producing 'IPv6 mentioned', then counts rows and returns a MAX of a specific literal. 2) Map schema elements: NetFlow Version, Comments, COUNT(*), and MAX('`Comprehensive support for IPv6 and MPLS`') as Exemplar_Comment, with HAVING COUNT(*)>0, ORDER BY NetFlow Version, LIMIT 100. 3) Create a question asking exactly for those fields and constraints. 4) Confirm inclusion of CASE logic, aggregation, HAVING, ordering, and limit.",reserved,12,reward,,
"Which Builders, returned as 'York Rd', have both a Built field containing '1905' and a Scrapped/Sold field containing '1954', aggregated by Builder and ordered by the descending count of rows per Builder, returning only the top five?","
SELECT t1.`Builder` AS `York Rd`
FROM `table_1_12113888_1` t1 JOIN `table_1_12113888_1` t2 ON t1.`Builder` = t2.`Builder`
WHERE instr(t1.`Built`, '1905')>0 AND instr(t2.`Scrapped/Sold`, '1954')>0
GROUP BY t1.`Builder`
ORDER BY COUNT(*) DESC LIMIT 5;
","
SELECT t1.col1 AS `York Rd`
FROM `table_1_12113888_1` t1 JOIN `table_1_12113888_1` t2 ON t1.col1 = t2.col1
WHERE instr(t1.col2, '1905')>0 AND instr(t2.col5, '1954')>0
GROUP BY t1.col1
ORDER BY COUNT(*) DESC LIMIT 5;
","[('derby',)]",table_1_12113888_1,"Parse the SQL intent: produce Builders (aliased 'York Rd') that have one or more rows with Built like '1905' and one or more rows with Scrapped/Sold like '1954', then group by Builder and pick the top five by row count. Map schema semantics: the self-join on Builder enforces both conditions per Builder; instr checks for substrings. Draft the question to ask for Builders as 'York Rd' satisfying those substring conditions, aggregated by Builder, ordered by COUNT(*) DESC with LIMIT 5. Validate: ensure all columns and operations (Builder alias, Built '1905', Scrapped/Sold '1954', GROUP BY, ORDER BY COUNT(*) DESC, LIMIT 5) are mentioned.",reserved,12,reward,,
"For each Inaugural Years obtained by taking the substring of Age at inauguration up to the '-' and treating it as a number, and only for rows where Age at inauguration is non-empty, report the Inaugural Years, the President Count for that group, the Presidents (their names concatenated with '; '), the Earliest Inauguration date (minimum Date of inauguration) and the Latest End (maximum End of term), returning up to 100 groups.","
SELECT substr(`Age at inauguration`,1,instr(`Age at inauguration`,'-')-1)+0 AS `Inaugural Years`,
       COUNT(*) `President Count`,
       group_concat(`President`, '; ') `Presidents`,
       min(`Date of inauguration`) `Earliest Inauguration`,
       max(`End of term`) `Latest End`
FROM `table_1_12134383_1`
WHERE length(`Age at inauguration`) > 0 AND `Age at inauguration` <> ''
GROUP BY substr(`Age at inauguration`,1,instr(`Age at inauguration`,'-')-1)+0
HAVING COUNT(*) > 0
LIMIT 100;
","
SELECT substr(col4,1,instr(col4,'-')-1)+0 AS `Inaugural Years`,
       COUNT(*) `President Count`,
       group_concat(col1, '; ') `Presidents`,
       min(col3) `Earliest Inauguration`,
       max(col5) `Latest End`
FROM `table_1_12134383_1`
WHERE length(col4) > 0 AND col4 <> ''
GROUP BY substr(col4,1,instr(col4,'-')-1)+0
HAVING COUNT(*) > 0
LIMIT 100;
","[(31, 1, 'rawlings, jerry jerry rawlings', '4june1979', '24september1979'), (32, 1, 'afrifa, akwasi akwasi afrifa', '2april1969', '7august1970'), (34, 1, 'rawlings, jerry jerry rawlings', '31december1981', '7january2001'), (40, 1, 'acheampong, ignatius ignatius acheampong', '13january1972', '5july1978'), (41, 1, 'akuffo, fred fred akuffo', '5july1978', '4june1979'), (44, 1, 'limann, hilla hilla limann', '24september1979', '31december1981'), (50, 2, 'nkrumrah, kwame kwame nkrumah; ankrah, joseph joseph ankrah', '1july1960', '2april1969'), (53, 1, 'mahama, john john mahama', '24july2012', '0,000 incumbent'), (62, 1, 'kufuor, john john kufuor', '7january2001', '7january2009'), (64, 3, 'ollennu, nii nii ollennu; akufo-addo, edward edward akufo-addo; mills, john john a. mills', '31august1970', '31august1970')]",table_1_12134383_1,"Parse SQL intent: compute per-year-at-inauguration groups by extracting the part of Age at inauguration before '-' and convert to a number, then return count, semicolon-joined President names, minimum Date of inauguration and maximum End of term for non-empty Age at inauguration. Map schema semantics: use columns Age at inauguration, President, Date of inauguration, End of term. Draft the question: ask explicitly for Inaugural Years (extracted), President Count, Presidents (joined with '; '), Earliest Inauguration (min), and Latest End (max), with grouping and a cap of 100 groups. Validate: ensure mention of substring extraction, aggregation types, non-empty filter, grouping, and limit.",reserved,9,reward,,
"List Nationality and Position for draft picks with Pick # <= 70, and for each Nationality–Position group that has more than one player provide Players (the COUNT of rows), Players_list (GROUP_CONCAT of Player), NHL_teams (GROUP_CONCAT of NHL team), and WCHA_count (the sum of indicators where the College/junior/club team contains '(WCHA)'); order the results by Players and return up to 10 rows.","
SELECT `Nationality`, `Position`, COUNT(*) Players, GROUP_CONCAT(`Player`) Players_list, GROUP_CONCAT(`NHL team`) NHL_teams, SUM(instr(`College/junior/club team`, '(WCHA)')>0) WCHA_count
FROM `table_1_1213511_5`
WHERE `Pick #` <= 70
GROUP BY `Nationality`, `Position`
HAVING COUNT(*) > 1
ORDER BY Players
LIMIT 10;
","
SELECT col3, col2, COUNT(*) Players, GROUP_CONCAT(col1) Players_list, GROUP_CONCAT(col4) NHL_teams, SUM(instr(col5, '(WCHA)')>0) WCHA_count
FROM `table_1_1213511_5`
WHERE col0 <= 70
GROUP BY col3, col2
HAVING COUNT(*) > 1
ORDER BY Players
LIMIT 10;
","[('canada', 'centre', 2, 'gary crosby,bert scott', 'los angeles kings,boston bruins', 0), ('canada', 'goaltender', 2, 'ray belanger,dave murphy', 'california golden seals,pittsburgh penguins', 0), ('canada', 'left wing', 2, 'mike mcniven,bob sykes', 'vancouver canucks,toronto maple leafs', 0), ('canada', 'defence', 6, 'steve warr,brian mcbratney,don mccullouch,wayne gibbs,mike busniuk,fraser robertson', 'buffalo sabres,minnesota north stars,philadelphia flyers,st. louis blues,montreal canadiens,new york rangers', 0)]",table_1_1213511_5,"1) Parse: query groups rows by Nationality and Position for Pick # <= 70 and returns aggregate columns including COUNT, two GROUP_CONCATs, and a SUM over instr(...'(WCHA)')>0, with HAVING COUNT>1, ORDER BY Players, LIMIT 10. 2) Map: link aggregates to the table fields Player, NHL team, and College/junior/club team. 3) Draft: create a question requesting those specific grouped aggregates and constraints. 4) Validate: confirm inclusion of the WHERE Pick # condition, grouping, HAVING, aggregates (including WCHA_count definition), ordering and limit.",reserved,9,reward,,
"Export a season-by-season feed ordered by Year that assigns an era_id when League changes, builds era_name and era_length/first/last years, computes a recommended_card_rarity per season from Regular Season/Playoffs/Open Cup (legendary/rare/common), concatenates notable events, and flags era start and end years.","
WITH tagged AS (
  SELECT
    `Year`,
    `Division`,
    `League`,
    `Regular Season`,
    `Playoffs`,
    `Open Cup`,
    LAG(`League`) OVER (ORDER BY `Year`) AS `prev_league`
  FROM `table_1_1214035_1`
),
era_marked AS (
  SELECT
    *,
    CASE WHEN `prev_league` IS NULL OR `prev_league` != `League` THEN 1 ELSE 0 END AS `era_change`
  FROM tagged
),
era_ided AS (
  SELECT
    *,
    SUM(`era_change`) OVER (ORDER BY `Year` ROWS UNBOUNDED PRECEDING) AS `era_id`
  FROM era_marked
),
era_stats AS (
  SELECT
    *,
    MIN(`Year`) OVER (PARTITION BY `era_id`) AS `era_first_year`,
    MAX(`Year`) OVER (PARTITION BY `era_id`) AS `era_last_year`,
    COUNT(*) OVER (PARTITION BY `era_id`) AS `era_length`
  FROM era_ided
)
SELECT
  `Year`,
  `Division`,
  `League`,
  `Regular Season`,
  `Playoffs`,
  `Open Cup`,
  `era_id`,
  '`' || `League` || '`' || ' era ' || `era_id` AS `era_name`,
  `era_length`,
  `era_first_year`,
  `era_last_year`,
  CASE
    WHEN `Regular Season` LIKE '1st%' THEN 'legendary'
    WHEN instr(`Playoffs`,'Final')>0 OR instr(`Playoffs`,'Semifinal')>0 OR instr(`Playoffs`,'Quarter')>0
         OR instr(`Open Cup`,'Final')>0 OR instr(`Open Cup`,'Quarter')>0 OR instr(`Open Cup`,'Round')>0
         THEN 'rare'
    WHEN `Playoffs` NOT LIKE 'Did not%' THEN 'rare'
    WHEN `Open Cup` NOT LIKE 'Did not%' THEN 'rare'
    ELSE 'common'
  END AS `recommended_card_rarity`,
  ltrim(
    COALESCE(CASE WHEN `Regular Season` LIKE '1st%' THEN '`' || `Regular Season` || '`' ELSE '' END,'')
    || CASE WHEN `Playoffs` NOT LIKE 'Did not%' THEN ', ' || '`' || `Playoffs` || '`' ELSE '' END
    || CASE WHEN `Open Cup` NOT LIKE 'Did not%' THEN ', ' || '`' || `Open Cup` || '`' ELSE '' END
  , ', ') AS `notable_events`,
  CASE WHEN `Year` = `era_first_year` THEN 1 ELSE 0 END AS `era_start_flag`,
  CASE WHEN `Year` = `era_last_year` THEN 1 ELSE 0 END AS `era_end_flag`
FROM era_stats
ORDER BY `Year`;
","SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  MIN(col0) OVER (PARTITION BY col2) AS `era_first_year`,
  MAX(col0) OVER (PARTITION BY col2) AS `era_last_year`,
  COUNT(*) OVER (PARTITION BY col2) AS `era_length`,
  '`' || col2 || '`' || ' era ' || CAST(MIN(col0) OVER (PARTITION BY col2) AS TEXT) AS `era_name`,
  CASE
    WHEN col3 LIKE '1st%' THEN 'legendary'
    WHEN instr(col4,'Final')>0 OR instr(col4,'Semifinal')>0 OR instr(col4,'Quarter')>0
         OR instr(col5,'Final')>0 OR instr(col5,'Quarter')>0 OR instr(col5,'Round')>0
         THEN 'rare'
    WHEN col4 NOT LIKE 'Did not%' THEN 'rare'
    WHEN col5 NOT LIKE 'Did not%' THEN 'rare'
    ELSE 'common'
  END AS `recommended_card_rarity`,
  ltrim(
    COALESCE(CASE WHEN col3 LIKE '1st%' THEN '`' || col3 || '`' ELSE '' END,'')
    || CASE WHEN col4 NOT LIKE 'Did not%' THEN ', ' || '`' || col4 || '`' ELSE '' END
    || CASE WHEN col5 NOT LIKE 'Did not%' THEN ', ' || '`' || col5 || '`' ELSE '' END
  , ', ') AS `notable_events`,
  CASE WHEN col0 = MIN(col0) OVER (PARTITION BY col2) THEN 1 ELSE 0 END AS `era_start_flag`,
  CASE WHEN col0 = MAX(col0) OVER (PARTITION BY col2) THEN 1 ELSE 0 END AS `era_end_flag`
FROM `table_1_1214035_1`
ORDER BY col0;","[(1991.0, 'n/a', 'sisl', '4th, southeast', 'did not qualify', 'did not enter', 1991.0, 1991.0, 1, '`sisl` era 1991.0', 'common', '', 1, 1), (1992.0, 'n/a', 'usisl', '5th, southeast', 'did not qualify', 'did not enter', 1992.0, 1994.0, 3, '`usisl` era 1992.0', 'common', '', 1, 0), (1993.0, 'n/a', 'usisl', '6th, southeast', 'did not qualify', 'did not enter', 1992.0, 1994.0, 3, '`usisl` era 1992.0', 'common', '', 0, 0), (1994.0, '3', 'usisl', '5th, midsouth', 'divisional semifinals', 'did not enter', 1992.0, 1994.0, 3, '`usisl` era 1992.0', 'rare', '`divisional semifinals`', 0, 1), (1995.0, '4', 'usisl premier', '3rd, eastern', 'divisional semifinals', 'did not qualify', 1995.0, 1996.0, 2, '`usisl premier` era 1995.0', 'rare', '`divisional semifinals`', 1, 0), (1996.0, '4', 'usisl premier', '4th, eastern northern', 'division finals', 'did not qualify', 1995.0, 1996.0, 2, '`usisl premier` era 1995.0', 'rare', '`division finals`', 0, 1), (1997.0, '2', 'usisl a-league', '2nd, central', 'division semifinals', 'did not qualify', 1997.0, 1998.0, 2, '`usisl a-league` era 1997.0', 'rare', '`division semifinals`', 1, 0), (1998.0, '2', 'usisl a-league', '1st, central', 'conference quarterfinals', 'quarter finals', 1997.0, 1998.0, 2, '`usisl a-league` era 1997.0', 'legendary', '`1st, central`, `conference quarterfinals`, `quarter finals`', 0, 1), (1999.0, '2', 'usl a-league', '6th, central', 'did not qualify', 'did not qualify', 1999.0, 2001.0, 3, '`usl a-league` era 1999.0', 'common', '', 1, 0), (2000.0, '2', 'usl a-league', '5th, central', 'did not qualify', '2nd round', 1999.0, 2001.0, 3, '`usl a-league` era 1999.0', 'rare', '`2nd round`', 0, 0), (2001.0, '2', 'usl a-league', '4th, central', '1st round', '2nd round', 1999.0, 2001.0, 3, '`usl a-league` era 1999.0', 'rare', '`1st round`, `2nd round`', 0, 1), (2002.0, '4', 'usl pdl', '4th, mid south', '1st round', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'rare', '`1st round`', 1, 0), (2003.0, '4', 'usl pdl', '3rd, mid south', 'did not qualify', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'common', '', 0, 0), (2004.0, '4', 'usl pdl', '4th, mid south', 'conference semifinals', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'rare', '`conference semifinals`', 0, 0), (2005.0, '4', 'usl pdl', '5th, mid south', 'did not qualify', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'common', '', 0, 0), (2006.0, '4', 'usl pdl', '5th, south atlantic', 'did not qualify', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'common', '', 0, 0), (2007.0, '4', 'usl pdl', '7th, southeast', 'did not qualify', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'common', '', 0, 0), (2008.0, '4', 'usl pdl', '7th, southeast', 'did not qualify', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'common', '', 0, 0), (2009.0, '4', 'usl pdl', '7th, southeast', 'did not qualify', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'common', '', 0, 0), (2010.0, '4', 'usl pdl', '7th, southeast', 'did not qualify', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'common', '', 0, 0), (2011.0, '4', 'usl pdl', '5th, southeast', 'did not qualify', 'did not qualify', 2002.0, 2011.0, 10, '`usl pdl` era 2002.0', 'common', '', 0, 1)]",table_1_1214035_1,"As the one designing campaign eras, I'd ask for era detection and per-season rarity tagging in one feed, using familiar labels rather than window-function details. The SQL does exactly that: it computes era_id by comparing League to the prior year, sums era changes to id eras, computes era_first/last years and length, determines recommended_card_rarity from Regular Season/Playoffs/Open Cup, and composes notable_events and era boundary flags. It sources Year, Division, League, Regular Season, Playoffs, and Open Cup. Draft question: request a season-by-season export ordered by Year containing era metadata, rarity, notable events, and start/end flags. Validate: the question precisely asks for the columns and derived fields the query returns.",persona,"""Goals"": [ ""Identify which seasons should become 'legendary' or 'rare' cards (titles, 1st-place finishes, deep playoff/Open Cup runs)."", ""Map league/division stretches and churn to design campaign eras and faction/upgrade mechanics (e.g., A-League era vs PDL era)."", ""Produce a chronological data feed that tags each season with a card-tier and notable events so designers/illustrators can craft flavor text and artwork."" ], ""Example queries"": [ ""-- 1) Get all seasons with top finishes, any playoff progress, or any Open Cup progress (for 'rare/legend' card candidates)\n    SELECT \""Year\"", \""Division\"", \""League\"", \""Regular Season\"", \""Playoffs\"", \""Open Cup\""\n    FROM table_1_1214035_1\n    WHERE \""Regular Season\"" LIKE '1st%'\n       OR \""Playoffs\"" NOT LIKE 'Did not%'\n       OR \""Open Cup\"" NOT LIKE 'Did not%'\n    ORDER BY \""Year\"";"", \n    ""-- 2) Count seasons per League and list earliest/latest year in that league (to define campaign eras and art direction)\n    SELECT \""League\"",\n           COUNT(*) AS season_count,\n           MIN(\""Year\"") AS first_year,\n           MAX(\""Year\"") AS last_year\n    FROM table_1_1214035_1\n    GROUP BY \""League\""\n    ORDER BY first_year;"", \n    ""-- 3) Produce a chronological season feed with a simple card-tier flag (legend/playoff/cup/base) for direct import into card generator\n    SELECT \""Year\"", \""Division\"", \""League\"", \""Regular Season\"", \""Playoffs\"", \""Open Cup\"",\n           CASE\n             WHEN \""Regular Season\"" LIKE '1st%' THEN 'legend'\n             WHEN \""Playoffs\"" NOT LIKE 'Did not%' THEN 'playoff'\n             WHEN \""Open Cup\"" NOT LIKE 'Did not%' THEN 'cup'\n             ELSE 'base'\n           END AS card_tier\n    FROM table_1_1214035_1\n    ORDER BY \""Year\"";"" ] } ``` Goals:  Example Queries: ",reward,,
"Who are the top 3 Directors by Total Millions where Total Millions is computed as ROUND(SUM(REPLACE(Viewers,'m','')+0),2), and for each Director show the Episode Count (COUNT(*)) and the rounded total; exclude episodes with Viewers = 'N/A', require the summed viewers to be greater than 0, and sort by Total Millions in descending order?","
SELECT `Director`, COUNT(*) AS `Episode Count`, ROUND(SUM(REPLACE(`Viewers`,'m','')+0),2) `Total Millions`
FROM `table_1_12148018_2`, (SELECT '5.46m' `5.46m`, '5.16m' `5.16m`, '4.42m' `4.42m`, 'N/A' `N/A`, '4.1m' `4.1m`, '4m' `4m`, '4.13m' `4.13m`) `v`
WHERE `Viewers` != `N/A`
GROUP BY `Director`
HAVING SUM(REPLACE(`Viewers`,'m','')+0)>0
ORDER BY `Total Millions` DESC
LIMIT 3;
","
SELECT col2, COUNT(*) AS `Episode Count`, ROUND(SUM(REPLACE(col5,'m','')+0),2) `Total Millions`
FROM `table_1_12148018_2`, (SELECT '5.46m' `5.46m`, '5.16m' `5.16m`, '4.42m' `4.42m`, 'N/A' `N/A`, '4.1m' `4.1m`, '4m' `4m`, '4.13m' `4.13m`) `v`
WHERE col5 != `N/A`
GROUP BY col2
HAVING SUM(REPLACE(col5,'m','')+0)>0
ORDER BY `Total Millions` DESC
LIMIT 3;
","[('martin hutchings', 3, 14.75), ('barnaby southcombe', 2, 8.1), ('bryn higgins', 2, 4.42)]",table_1_12148018_2,"1) Intent: compute per-Director episode count and summed viewers (strip 'm' and convert to number), round to 2 decimals, ignore 'N/A' rows, require positive sums, and return the top three by total. 2) Map schema semantics to Director, Viewers, COUNT(*), SUM(REPLACE(...)), and ROUND. 3) Draft final question that explicitly names each calculation and constraint. 4) Confirm inclusion of WHERE Viewers != 'N/A', HAVING SUM(...)>0, ORDER BY DESC, and LIMIT 3.",reserved,12,reward,,
"For episodes with U.S. viewers (millions) > 0 whose directors directed more than one episode, provide Series #, Title, Directed by, U.S. viewers (millions), the director_avg which is AVG(U.S. viewers (millions)) for that director, and the deviation computed as (U.S. viewers (millions) - director_avg) / director_avg, then order by deviation ascending and return the top 5 rows?","
SELECT t1.`Series #`, t1.`Title`, t1.`Directed by`, t1.`U.S. viewers (millions)`, AVG(t2.`U.S. viewers (millions)`) director_avg, (t1.`U.S. viewers (millions)` - AVG(t2.`U.S. viewers (millions)`)) / AVG(t2.`U.S. viewers (millions)`) deviation
FROM `table_1_12159115_2` t1 JOIN `table_1_12159115_2` t2 ON t2.`Directed by` = t1.`Directed by`
WHERE t1.`U.S. viewers (millions)` > 0
GROUP BY t1.`Series #`, t1.`Title`, t1.`Directed by`, t1.`U.S. viewers (millions)`
HAVING COUNT(t2.`Series #`) > 1
ORDER BY deviation
LIMIT 5;
","
SELECT t1.col0, t1.col1, t1.col2, t1.col6, AVG(t2.col6) director_avg, (t1.col6 - AVG(t2.col6)) / AVG(t2.col6) deviation
FROM `table_1_12159115_2` t1 JOIN `table_1_12159115_2` t2 ON t2.col2 = t1.col2
WHERE t1.col6 > 0
GROUP BY t1.col0, t1.col1, t1.col2, t1.col6
HAVING COUNT(t2.col0) > 1
ORDER BY deviation
LIMIT 5;
","[(21.0, '""david and goliath""', 'kevin dowling', '8.84', 10.936666666666667, -0.19170984455958556), (5.0, '""romeo and juliet murders""', 'lewis h. gould', '9.5', 10.826666666666668, -0.122536945812808), (16.0, '""escape""', 'charles beeson', '9.88', 10.875, -0.09149425287356315), (13.0, '""the rapist next door""', 'martha mitchell', '10.74', 11.350000000000001, -0.05374449339207058), (20.0, '""the shot""', 'kevin dowling', '11.17', 10.936666666666667, 0.021334958854007848)]",table_1_12159115_2,"1) The intent is to compute per-episode deviation from the director's mean viewers, exclude zero-viewer episodes, restrict to directors with multiple episodes, and return the five smallest deviations. 2) Map schema: output Series #, Title, Directed by, U.S. viewers (millions), director_avg (AVG of U.S. viewers (millions)), and deviation formula. 3) Phrase a question that requests exactly those outputs and constraints, ordered by deviation and limited to 5. 4) Confirm all columns, AVG alias, formula, HAVING >1, WHERE >0, ORDER BY and LIMIT are included.",reserved,10,reward,,
"For at most 10 distinct Winners (grouped by Winner) among rows with Season <> '', what is Country (Winner), Wins (COUNT(*)), Men Alignment (SUM(Winner Men = Winner)), Women Alignment (SUM(Winner Women = Winner)), Gender Match Count (SUM((Winner Men = Winner) + (Winner Women = Winner))), and Split Teams (COUNT(*) - SUM((Winner Men = Winner) + (Winner Women = Winner)))?","
SELECT `Winner` `Country`,
       COUNT(*) `Wins`,
       SUM(`Winner Men` = `Winner`) `Men Alignment`,
       SUM(`Winner Women` = `Winner`) `Women Alignment`,
       SUM((`Winner Men` = `Winner`) + (`Winner Women` = `Winner`)) `Gender Match Count`,
       COUNT(*) - SUM((`Winner Men` = `Winner`) + (`Winner Women` = `Winner`)) `Split Teams`
FROM `table_1_1216097_7`
WHERE `Season` <> ''
GROUP BY `Winner`
LIMIT 10;
","
SELECT col1 `Country`,
       COUNT(*) `Wins`,
       SUM(col4 = col1) `Men Alignment`,
       SUM(col5 = col1) `Women Alignment`,
       SUM((col4 = col1) + (col5 = col1)) `Gender Match Count`,
       COUNT(*) - SUM((col4 = col1) + (col5 = col1)) `Split Teams`
FROM `table_1_1216097_7`
WHERE col0 <> ''
GROUP BY col1
LIMIT 10;
","[('norway', 24, 21, 14, 35, -11), ('russia', 2, 0, 2, 2, 0), ('soviet union', 3, 0, 3, 3, 0), ('sweden', 2, 2, 0, 2, 0)]",table_1_1216097_7,"1) Parse: produce per-Winner aggregates: total wins, counts where the men's/women's winners equal the Winner, their sum, and wins minus that sum; exclude empty Season rows and limit output to 10. 2) Map: interpret Winner as the country and Winner Men/Winner Women as gender-specific winners. 3) Draft: formulate a question asking for these exact aggregated columns and calculations per Winner with Season <> '' and LIMIT 10. 4) Validate: the question must include COUNT(*), both SUM(...) expressions, their combined SUM, the subtraction for Split Teams, grouping, filter, and the limit.",reserved,6,reward,,
Which driver won the most races and with which constructors did they win?,"
SELECT
  t1.`Winning driver`,
  COUNT(*) AS `wins`,
  (SELECT GROUP_CONCAT(t4.`c`, ' | ')
     FROM (SELECT t2.`Winning constructor` AS `c`, COUNT(*) AS `count` FROM `table_1_12161822_5` t2 WHERE t2.`Winning driver` = t1.`Winning driver` GROUP BY t2.`Winning constructor`) t4
  ) AS `Constructors`,
  (SELECT GROUP_CONCAT(t4.`c` || ' (' || t4.`count` || ' wins)', ' | ')
     FROM (SELECT t2.`Winning constructor` AS `c`, COUNT(*) AS `count` FROM `table_1_12161822_5` t2 WHERE t2.`Winning driver` = t1.`Winning driver` GROUP BY t2.`Winning constructor`) t4
  ) AS `Constructor_win_breakdown`,
  SUM(CASE WHEN t1.`Pole position` = t1.`Winning driver` THEN 1 ELSE 0 END) AS `Won_from_pole`,
  SUM(CASE WHEN t1.`Pole position` <> t1.`Winning driver` THEN 1 ELSE 0 END) AS `Won_not_from_pole`,
  SUM(CASE WHEN t1.`Fastest lap` <> t1.`Winning driver` THEN 1 ELSE 0 END) AS `Wins_with_fastest_by_different_driver`,
  GROUP_CONCAT(CASE WHEN t1.`Pole position` <> t1.`Winning driver` THEN t1.`Grand Prix` END, ' | ') AS `Races_pole_mismatch_list`,
  GROUP_CONCAT(CASE WHEN t1.`Fastest lap` <> t1.`Winning driver` THEN t1.`Grand Prix` END, ' | ') AS `Races_fastest_mismatch_list`,
  GROUP_CONCAT(t1.`Grand Prix`, ' | ') AS `All_won_Grand_Prix_list`
FROM `table_1_12161822_5` t1
GROUP BY t1.`Winning driver`
ORDER BY `wins` DESC, t1.`Winning driver`;
","
SELECT
  t1.col4,
  COUNT(*) AS `wins`,
  (SELECT GROUP_CONCAT(t4.`c`, ' | ')
     FROM (SELECT t2.col5 AS `c`, COUNT(*) AS `count` FROM `table_1_12161822_5` t2 WHERE t2.col4 = t1.col4 GROUP BY t2.col5) t4
  ) AS `Constructors`,
  (SELECT GROUP_CONCAT(t4.`c` || ' (' || t4.`count` || ' wins)', ' | ')
     FROM (SELECT t2.col5 AS `c`, COUNT(*) AS `count` FROM `table_1_12161822_5` t2 WHERE t2.col4 = t1.col4 GROUP BY t2.col5) t4
  ) AS `Constructor_win_breakdown`,
  SUM(CASE WHEN t1.col2 = t1.col4 THEN 1 ELSE 0 END) AS `Won_from_pole`,
  SUM(CASE WHEN t1.col2 <> t1.col4 THEN 1 ELSE 0 END) AS `Won_not_from_pole`,
  SUM(CASE WHEN t1.col3 <> t1.col4 THEN 1 ELSE 0 END) AS `Wins_with_fastest_by_different_driver`,
  GROUP_CONCAT(CASE WHEN t1.col2 <> t1.col4 THEN t1.col1 END, ' | ') AS `Races_pole_mismatch_list`,
  GROUP_CONCAT(CASE WHEN t1.col3 <> t1.col4 THEN t1.col1 END, ' | ') AS `Races_fastest_mismatch_list`,
  GROUP_CONCAT(t1.col1, ' | ') AS `All_won_Grand_Prix_list`
FROM `table_1_12161822_5` t1
GROUP BY t1.col4
ORDER BY `wins` DESC, t1.col4;
","[('sebastian vettel', 11, 'red bull - renault', 'red bull - renault (11 wins)', 9, 2, 8, 'spanish grand prix | korean grand prix', 'australian grand prix | malaysian grand prix | turkish grand prix | spanish grand prix | monaco grand prix | belgian grand prix | italian grand prix | singapore grand prix', 'australian grand prix | malaysian grand prix | turkish grand prix | spanish grand prix | monaco grand prix | european grand prix | belgian grand prix | italian grand prix | singapore grand prix | korean grand prix | indian grand prix'), ('jenson button', 3, 'mclaren - mercedes', 'mclaren - mercedes (3 wins)', 0, 3, 1, 'canadian grand prix | hungarian grand prix | japanese grand prix', 'hungarian grand prix', 'canadian grand prix | hungarian grand prix | japanese grand prix'), ('lewis hamilton', 3, 'mclaren - mercedes', 'mclaren - mercedes (3 wins)', 0, 3, 2, 'chinese grand prix | german grand prix | abu dhabi grand prix', 'chinese grand prix | abu dhabi grand prix', 'chinese grand prix | german grand prix | abu dhabi grand prix'), ('fernando alonso', 1, 'ferrari', 'ferrari (1 wins)', 0, 1, 0, 'british grand prix', None, 'british grand prix')]",table_1_12161822_5,"STEP 1: Parse the SQL intent: the query groups rows by Winning driver and for each driver computes total wins, lists of constructors they won with and a wins-per-constructor breakdown, counts of wins from pole vs not from pole, counts/list of races where pole or fastest lap didn't match the winner, and a concatenated list of all Grands Prix they won; results are ordered by wins descending. STEP 2: Determine a fitting ambiguity type: scope ambiguity fits well because the wording around 'most' or 'which driver won the most' can mean either the single top driver or a ranked list of drivers (or even other aggregate readings like top driver per constructor). STEP 3: Draft the question: ""Which driver won the most races and with which constructors did they win?"" STEP 4: Explain the ambiguity: in the original query this is interpreted as returning every driver with their win counts and the constructors they used (a full ranked list ordered by wins), but the same wording could be interpreted differently — e.g. return only the single top driver, return the top driver for each constructor, or return the driver-constructor pair with the most wins — each would require a different SQL translation.",persona,"An olfactory historian-perfumer who designs ‘race-day’ fragrances that translate 2011 Grand Prix outcomes (winners, constructors, poles, fastest laps) into scent narratives. Goals: Identify which drivers won multiple races in 2011 to create a signature base note profile for each prolific winner (e.g., Sebastian Vettel). Determine how many races each constructor won so I can assign constructor-based scent families (e.g., 'Red Bull' vs 'McLaren'). Find Grand Prix where the pole-sitter did not win or where the fastest lap was set by a different driver, to design accords that evoke surprise, comeback or peak-performance moments. Map each race's outcome details (pole, fastest lap, winner) so I can craft layered top/middle/base note progressions tied to race narratives and circuit-specific ambiance. Example Queries: SELECT ""Rd."", ""Grand Prix"", ""Winning driver"", ""Winning constructor"" FROM table_1_12161822_5 WHERE ""Winning driver"" = 'Sebastian Vettel' ORDER BY ""Rd.""; SELECT ""Winning constructor"", COUNT(*) AS wins FROM table_1_12161822_5 GROUP BY ""Winning constructor"" ORDER BY wins DESC; SELECT ""Rd."", ""Grand Prix"", ""Pole position"", ""Fastest lap"", ""Winning driver"" FROM table_1_12161822_5 WHERE ""Pole position"" <> ""Winning driver"" OR ""Fastest lap"" <> ""Winning driver"" ORDER BY ""Rd."";",reward,,"type: Scope ambiguity | explanation: The phrase 'won the most races' can mean (a) the single driver with the highest total wins, (b) a ranked list of drivers by wins (as the SQL returns), or (c) the top driver within each constructor or the top driver-constructor pair; the original query implements interpretation (b) while other interpretations would require different queries."
"Which .308 Winchester cartridge types (excluding rows where the .308 Winchester cartridge type equals the .300 Winchester Magnum cartridge type) have an average 100 m group (mm) and an average 300 m group (mm) below 14 and 55 respectively, and what are their average 100 m group (mm), average 300 m group (mm), and the ratio of average 100 m group (mm) to average 100 m group ( MOA ), ordered by average 100 m group (mm) then average 300 m group (mm)?","
SELECT `.308 Winchester cartridge type`, AVG(`100 m group (mm)`), AVG(`300 m group (mm)`), AVG(`100 m group (mm)`)/AVG(`100 m group ( MOA )`)
FROM `table_1_12162347_1`
WHERE `.308 Winchester cartridge type` != `.300 Winchester Magnum cartridge type`
GROUP BY `.308 Winchester cartridge type`
HAVING AVG(`100 m group (mm)`) < 14 AND AVG(`300 m group (mm)`) < 55
ORDER BY AVG(`100 m group (mm)`), AVG(`300 m group (mm)`);
","SELECT col0, AVG(CAST(col1 AS REAL)) AS avg_100mm, AVG(CAST(col3 AS REAL)) AS avg_300mm, AVG(CAST(col1 AS REAL))/NULLIF(AVG(CAST(col2 AS REAL)),0) AS moa_ratio
FROM `table_1_12162347_1`
WHERE col0 != '.300 Winchester Magnum cartridge type'
GROUP BY col0
HAVING AVG(CAST(col1 AS REAL)) < 14 AND AVG(CAST(col3 AS REAL)) < 55
ORDER BY avg_100mm, avg_300mm
LIMIT 100;","[('ruag swiss p target 200 gs hp-bt', 13.0, 38.0, 28.88888888888889), ('ruag swiss p target 168 gr hp-bt', 13.0, 48.0, 28.88888888888889), ('imi 168 gr match', 13.0, 52.0, 29.545454545454547)]",table_1_12162347_1,"Parse SQL intent: retrieve grouped averages and a computed ratio per .308 cartridge type, exclude rows where the .308 value equals the .300 Winchester Magnum value, apply HAVING filters for averages below given thresholds, and sort by those averages. Map schema semantics: reference columns .308 Winchester cartridge type, 100 m group (mm), 300 m group (mm), and 100 m group ( MOA ) for the division. Draft the question to request those aggregated values and the specific filters and ordering. Validate that the question mentions AVG of both distances, the division AVG(100 m mm)/AVG(100 m MOA), the inequality exclusion, HAVING limits, and ORDER BY sequence.",reserved,8,reward,,
Which men's singles players have won the most titles?,"
SELECT `Mens singles`, COUNT(*) AS `Titles`, GROUP_CONCAT(`Year`) FROM `table_1_12164707_1` GROUP BY `Mens singles` ORDER BY `Titles` DESC LIMIT 5;
","
SELECT col1, COUNT(*) AS `Titles`, GROUP_CONCAT(col0) FROM `table_1_12164707_1` GROUP BY col1 ORDER BY `Titles` DESC LIMIT 5;
","[('ville lång', 1, '2008.0'), ('richard vaughan', 1, '2000.0'), ('przemysław wacha', 1, '2002.0'), ('peter mikkelsen', 1, '2009.0'), ('oliver pongratz', 1, '2001.0')]",table_1_12164707_1,"STEP 1: Parse the SQL intent: the query groups rows by the 'Mens singles' column, counts how many rows (titles) each player has, concatenates the years they won, orders players by their title counts descending, and returns the top 5 players. STEP 2: Determine ambiguity type: scope ambiguity fits well because the phrase 'most titles' can refer to total titles across all years (the SQL interpretation) or to other scopes like titles in a single year/season, titles at a specific event, or per-period maxima. STEP 3: Draft the question: ""Which men's singles players have won the most titles?"" STEP 4: Explain ambiguity: the original query interprets this as the overall total number of tournament wins per player across the dataset (and returns the top 5 with the years), but a reader could instead mean 'most titles in a single year', 'most titles at a particular edition', 'most titles per country', or 'most recent titles', which would require different grouping/filtering in SQL.",reserved,8,reward,,"type: Scope ambiguity | explanation: The SQL treats 'most titles' as the total number of wins per player across all years (overall totals). Alternatively, 'most titles' could mean within a single year/season, at a specific event edition, per country, or by some other time or subset scope, which the query does not specify and would change the grouping/filtering needed."
"For each MotoGP winner, report the number of rounds they won (Win Count = COUNT(Round)), the concatenated list of Circuits (GROUP_CONCAT(Circuit)), and the concatenated list of anomaly Rounds (GROUP_CONCAT of Round for rounds where the 125cc winner = 'No 125cc and 250cc race'), grouping by MotoGP winner and ordering the results by Win Count descending?","
SELECT t.`MotoGP winner`, COUNT(t.`Round`) `Win Count`, GROUP_CONCAT(t.`Circuit`) `Circuits`, GROUP_CONCAT(an.`Round`) `Anomaly Rounds`
FROM `table_1_12186237_1` t
JOIN (SELECT `Round`, `125cc winner` FROM `table_1_12186237_1` WHERE `125cc winner` = 'No 125cc and 250cc race') an ON t.`Round` = an.`Round`
GROUP BY t.`MotoGP winner`
ORDER BY `Win Count` * -1;
","SELECT t.col6 AS col6, COUNT(t.col0) AS `Win Count`, GROUP_CONCAT(t.col3) AS `Circuits`, GROUP_CONCAT(an.col0) AS `Anomaly Rounds`
FROM `table_1_12186237_1` t
LEFT JOIN (SELECT col0 FROM `table_1_12186237_1` WHERE col4 = 'No 125cc and 250cc race') an ON t.col0 = an.col0
WHERE t.col0 IS NOT NULL
GROUP BY t.col6
HAVING COUNT(t.col0) > 0
ORDER BY `Win Count` DESC;","[('valentino rossi', 9, 'shanghai,le mans,mugello,laguna seca,brno,misano,indianapolis,motegi,sepang', None), ('casey stoner', 5, 'losail,donington,assen,sachsenring,phillip island', None), ('dani pedrosa', 2, 'jerez,catalunya', None), ('jorge lorenzo', 1, 'estoril', None)]",table_1_12186237_1,"1) The SQL joins the table to a subquery that picks rounds where `125cc winner` equals 'No 125cc and 250cc race', then aggregates per MotoGP winner computing counts and concatenations and orders by count descending. 2) Map to table fields: use MotoGP winner for grouping, Round for counting and listing anomaly rounds, and Circuit for listing circuits. 3) Formulate a question that asks for each MotoGP winner the Win Count (=COUNT(Round)), the Circuits (=GROUP_CONCAT(Circuit)), and the Anomaly Rounds (=GROUP_CONCAT of Round from rows where 125cc winner = 'No 125cc and 250cc race'), ordered by Win Count descending. 4) Ensure the question references the anomaly condition and the specific aggregated outputs.",reserved,10,reward,,
"From the Mens singles, Womens singles, Mens doubles, Womens doubles and Mixed doubles winners (using Year as the unit to count each title), who are the top 10 players by number of titles (COUNT(Year) AS titles) and what are their title counts and concatenated categories (GROUP_CONCAT of category), ordered by titles descending?","
SELECT `player`, COUNT(`year`) AS `titles`, GROUP_CONCAT(`category`) AS `categories`
FROM (
  SELECT `Mens singles` AS `player`, 'Mens singles' AS `category`, `Year` AS `year` FROM `table_1_12204717_1`
  UNION
  SELECT `Womens singles` AS `player`, 'Womens singles' AS `category`, `Year` AS `year` FROM `table_1_12204717_1`
  UNION
  SELECT `Mens doubles` AS `player`, 'Mens doubles' AS `category`, `Year` AS `year` FROM `table_1_12204717_1`
  UNION
  SELECT `Womens doubles` AS `player`, 'Womens doubles' AS `category`, `Year` AS `year` FROM `table_1_12204717_1`
  UNION
  SELECT `Mixed doubles` AS `player`, 'Mixed doubles' AS `category`, `Year` AS `year` FROM `table_1_12204717_1`
) AS `all_titles`
GROUP BY `player`
ORDER BY `titles` DESC
LIMIT 10;
","
SELECT `player`, COUNT(col0) AS `titles`, GROUP_CONCAT(`category`) AS `categories`
FROM (
  SELECT col1 AS `player`, 'Mens singles' AS `category`, col0 AS col0 FROM `table_1_12204717_1`
  UNION
  SELECT col2 AS `player`, 'Womens singles' AS `category`, col0 AS col0 FROM `table_1_12204717_1`
  UNION
  SELECT col3 AS `player`, 'Mens doubles' AS `category`, col0 AS col0 FROM `table_1_12204717_1`
  UNION
  SELECT col4 AS `player`, 'Womens doubles' AS `category`, col0 AS col0 FROM `table_1_12204717_1`
  UNION
  SELECT col5 AS `player`, 'Mixed doubles' AS `category`, col0 AS col0 FROM `table_1_12204717_1`
) AS `all_titles`
GROUP BY `player`
ORDER BY `titles` DESC
LIMIT 10;
","[('lin dan', 5, 'Mens singles,Mens singles,Mens singles,Mens singles,Mens singles'), ('zhou mi', 3, 'Womens singles,Womens singles,Womens singles'), ('yang wei zhang jiewen', 3, 'Womens doubles,Womens doubles,Womens doubles'), ('jung jae-sung lee yong-dae', 3, 'Mens doubles,Mens doubles,Mens doubles'), ('jiang yanjiao', 3, 'Womens singles,Womens singles,Womens singles'), ('ge fei gu jun', 3, 'Womens doubles,Womens doubles,Womens doubles'), ('dong jiong', 3, 'Mens singles,Mens singles,Mens singles'), ('zhang ning', 2, 'Womens singles,Womens singles'), ('zhang jun gao ling', 2, 'Mixed doubles,Mixed doubles'), ('wang xiaoli yu yang', 2, 'Womens doubles,Womens doubles')]",table_1_12204717_1,"1) The query builds a combined list of players across all five categories, counts years per player as titles, concatenates the categories per player, sorts by the count and returns ten rows. 2) Use the table's Year, Mens singles, Womens singles, Mens doubles, Womens doubles and Mixed doubles fields. 3) Formulate a question that asks for each player the number of titles (counting Year) and the concatenated categories, sorted by titles desc, top 10. 4) Ensure the question explicitly mentions COUNT(Year) AS titles, GROUP_CONCAT(category) AS categories, the five category columns, ordering and LIMIT 10.",reserved,8,reward,,
"Which 'Written by' values have more than one 'Directed by' (i.e., COUNT('Directed by') as DirectorCount > 1 when pairing rows with the same 'Written by' but where 'Directed by' differs), and for each such 'Written by' what are DirectorCount, MIN('Original air date') as FirstAir and MAX('Original air date') as LastAir, ordered by DirectorCount descending and limited to 10 results?","
SELECT t1.`Written by`, COUNT(t2.`Directed by`) `DirectorCount`, MIN(t1.`Original air date`) `FirstAir`, MAX(t1.`Original air date`) `LastAir`
FROM `table_1_12226390_2` AS t1
JOIN `table_1_12226390_2` t2 ON t1.`Written by` = t2.`Written by`
WHERE t1.`Directed by` != t2.`Directed by`
GROUP BY t1.`Written by`
HAVING COUNT(t2.`Directed by`) > 1
ORDER BY `DirectorCount` DESC
LIMIT 10;
","
SELECT t1.col3, COUNT(t2.col2) `DirectorCount`, MIN(t1.col4) `FirstAir`, MAX(t1.col4) `LastAir`
FROM `table_1_12226390_2` AS t1
JOIN `table_1_12226390_2` t2 ON t1.col3 = t2.col3
WHERE t1.col2 != t2.col2
GROUP BY t1.col3
HAVING COUNT(t2.col2) > 1
ORDER BY `DirectorCount` DESC
LIMIT 10;
","[('jay sommers and dick chevillat', 52, 'april27,1966', 'september29,1965')]",table_1_12226390_2,"1) The SQL finds writers who have episodes directed by multiple different directors and returns a count of those director rows plus earliest and latest air dates, ordering and limiting results. 2) Map to columns: 'Written by' is the grouping key, 'Directed by' is counted, 'Original air date' supplies MIN and MAX. 3) Draft a question asking which writers have DirectorCount > 1 and for each show DirectorCount, FirstAir and LastAir, ordered by DirectorCount desc and limited to 10. 4) Ensure the question mentions COUNT('Directed by') as DirectorCount, MIN/MAX of 'Original air date', the director inequality condition, HAVING > 1, ORDER BY and LIMIT 10.",reserved,12,reward,,
Which riders had stage wins and how many times did they lead the general classification?,"
SELECT DISTINCT t1.`Winner` AS `Rider`, COUNT(t1.`Stage`) `StageWins`, COUNT(t2.`Stage`) `GCTimes` FROM `table_1_12261714_2` t1 JOIN `table_1_12261714_2` t2 ON t2.`General classification` = t1.`Winner` WHERE 1=1 GROUP BY t1.`Winner` HAVING COUNT(t1.`Stage`) > 0 ORDER BY `StageWins` DESC, `Rider` ASC LIMIT 10;
","
SELECT DISTINCT t1.col1 AS `Rider`, COUNT(t1.col0) `StageWins`, COUNT(t2.col0) `GCTimes` FROM `table_1_12261714_2` t1 JOIN `table_1_12261714_2` t2 ON t2.col2 = t1.col1 WHERE 1=1 GROUP BY t1.col1 HAVING COUNT(t1.col0) > 0 ORDER BY `StageWins` DESC, `Rider` ASC LIMIT 10;
","[('moreno argentin', 20, 20), ('miguel indurain', 18, 18)]",table_1_12261714_2,"STEP 1: Parse the SQL intent: the query groups by t1.Winner (Rider) and returns for each Rider the number of stage wins (COUNT(t1.Stage)) and the number of rows where that Rider appears in the General classification column (COUNT(t2.Stage)), limited to riders with at least one stage win and ordered by StageWins desc, Rider asc, top 10. STEP 2: Determine an ambiguity type: Entity vagueness fits well — the phrase about ""leading the general classification"" can mean different things (appearances as leader in the per-stage GC column vs winning the overall GC). STEP 3: Draft the question: a concise, naturally ambiguous question that matches the SQL's valid interpretation. STEP 4: Explain the ambiguity: in the SQL ""GCTimes"" is the count of rows where General classification equals the Rider (i.e., number of stages where they appear as the GC entry), but a human reading the question might interpret ""lead the general classification"" as winning the overall GC title, or as simultaneously winning stage and GC on the same stage, or as simply appearing anywhere in the final GC standings.",reserved,14,reward,,"type: Entity Vagueness | explanation: The SQL treats 'lead the general classification' as counting occurrences where the rider appears in the General classification column (i.e., number of stages they are listed there). A reader could instead interpret the phrase as the number of times the rider won the overall general classification (overall race victory), as the number of stages they were overall race leader, or as a different measure of 'leading' the classification."
"List the top 5 boxers (limit 5) ordered by total defenses descending and then by number of titles, showing for each boxer their Name, the number of Titles (COUNT(*)), Total_Defenses (SUM of Defenses), Stoppages (count of rows where Result includes 'KO' or 'TKO'), their First_Title date (MIN Date) and Last_Title date (MAX Date), and also compute the number of distinct title Divisions (COUNT DISTINCT Titles) via a left join, but include only boxers whose Total_Defenses is at least 1?","
SELECT `t`.`Name` AS `Boxer`,
       COUNT(*) AS `Titles`,
       SUM(`t`.`Defenses`) AS `Total_Defenses`,
       SUM(CASE WHEN `t`.`Result` LIKE '%KO%' OR `t`.`Result` LIKE '%TKO%' THEN 1 ELSE 0 END) AS `Stoppages`,
       MIN(`t`.`Date`) AS `First_Title`,
       MAX(`t`.`Date`) AS `Last_Title`
FROM `table_1_12262182_2` `t`
LEFT JOIN (
  SELECT `Name`, COUNT(DISTINCT `Titles`) AS `Divisions`
  FROM `table_1_12262182_2`
  GROUP BY `Name`
) AS `d` ON `d`.`Name` = `t`.`Name`
GROUP BY `t`.`Name`
HAVING SUM(`t`.`Defenses`) >= 1
ORDER BY SUM(`t`.`Defenses`) DESC, COUNT(*) 
LIMIT 5;
","
SELECT `t`.col1 AS `Boxer`,
       COUNT(*) AS col2,
       SUM(`t`.col6) AS `Total_Defenses`,
       SUM(CASE WHEN `t`.col5 LIKE '%KO%' OR `t`.col5 LIKE '%TKO%' THEN 1 ELSE 0 END) AS `Stoppages`,
       MIN(`t`.col3) AS `First_Title`,
       MAX(`t`.col3) AS `Last_Title`
FROM `table_1_12262182_2` `t`
LEFT JOIN (
  SELECT col1, COUNT(DISTINCT col2) AS `Divisions`
  FROM `table_1_12262182_2`
  GROUP BY col1
) AS `d` ON `d`.col1 = `t`.col1
GROUP BY `t`.col1
HAVING SUM(`t`.col6) >= 1
ORDER BY SUM(`t`.col6) DESC, COUNT(*) 
LIMIT 5;
","[('oscar de la hoya', 8, 25.0, 4, '1994-03-05', '2002-09-14'), ('floyd mayweather, jr.', 8, 23.0, 1, '1998-10-03', '2007-05-05'), ('thomas hearns', 6, 13.0, 4, '1980-08-02', '1988-11-04'), ('manny pacquiao', 6, 8.0, 4, '1998-12-04', '2008-03-15'), ('ray charles leonard', 8, 4.0, 6, '1979-11-30', '1988-11-07')]",table_1_12262182_2,"1) The intent is to produce top boxers by their summed defenses with several summary columns. 2) Map schema elements: Name, Titles count, sum of Defenses, conditional count of KO/TKO Results, earliest and latest Date, and the joined Divisions count. 3) Formulate a question that requests those exact outputs, applies the filter SUM(Defenses) >= 1, orders by SUM(Defenses) DESC then COUNT(*), and limits to 5. 4) Keep the question aligned to the SQL without adding extraneous details.",reserved,31,reward,,
"Show Season, `Mens singles`, `Womens singles`, `Mens doubles`, `Mixed doubles`, and the computed flags (instr(`Mens doubles`, substr(`Mens singles`,1,instr(`Mens singles`,' ,')-1))>0) AS Mens_in_MensDoubles and (instr(`Mixed doubles`, substr(`Womens singles`,1,instr(`Womens singles`,' ,')-1))>0) AS Womens_in_MixedDoubles for those rows where both (instr(`Mens doubles`, substr(`Mens singles`,1,instr(`Mens singles`,' ,')-1))>0) AND (instr(`Mixed doubles`, substr(`Womens singles`,1,instr(`Womens singles`,' ,')-1))>0) are true?","
SELECT `Season`, `Mens singles`, `Womens singles`, `Mens doubles`, `Mixed doubles`, (instr(`Mens doubles`, substr(`Mens singles`,1,instr(`Mens singles`,' ,')-1))>0) `Mens_in_MensDoubles`, (instr(`Mixed doubles`, substr(`Womens singles`,1,instr(`Womens singles`,' ,')-1))>0) `Womens_in_MixedDoubles`
FROM `table_1_12266757_1`
WHERE (instr(`Mens doubles`, substr(`Mens singles`,1,instr(`Mens singles`,' ,')-1))>0) AND (instr(`Mixed doubles`, substr(`Womens singles`,1,instr(`Womens singles`,' ,')-1))>0);
","
SELECT col0, col1, col2, col3, col5, (instr(col3, substr(col1,1,instr(col1,' ,')-1))>0) `Mens_in_MensDoubles`, (instr(col5, substr(col2,1,instr(col2,' ,')-1))>0) `Womens_in_MixedDoubles`
FROM `table_1_12266757_1`
WHERE (instr(col3, substr(col1,1,instr(col1,' ,')-1))>0) AND (instr(col5, substr(col2,1,instr(col2,' ,')-1))>0);
","[('1971/1972', 'sture johnsson , spårvägen', 'eva twedberg , mai', 'sture johnsson gert perneklo , spårvägen bk aura', 'gert perneklo eva twedberg , mai', 1, 1), ('1983/1984', 'stefan karlsson , bk aura', 'christine magnusson , bkc', 'stefan karlsson thomas kihlström , bk aura bkc', 'thomas kihlström christine magnusson , bkc', 1, 1), ('1984/1985', 'stefan karlsson , bk aura', 'christine magnusson , bkc', 'stefan karlsson thomas kihlström , bk aura bkc', 'thomas kihlström christine magnusson , bkc', 1, 1)]",table_1_12266757_1,"1) Parse: The intent is to find seasons where the extracted first part of Mens singles appears in Mens doubles and the extracted first part of Womens singles appears in Mixed doubles, and to display the columns plus those two boolean checks. 2) Map: Use Season, Mens singles, Womens singles, Mens doubles, Mixed doubles and the functions substr(...,1,instr(...,' ,')-1) and instr(..., ...)>0. 3) Draft: Compose a question requesting those columns and computed flags limited to rows where both membership tests are true. 4) Validate: The question includes the exact substring and instr expressions and specifies the AND filter.",reserved,4,reward,,
"List the DISTINCT Club (coming from each Season's 'Serbian League Belgrade', 'Serbian League East', 'Serbian League Vojvodina' and 'Serbian League West' entries), the number of Appearances (COUNT(*)), and a SeasonsLeagues string formed by GROUP_CONCAT(Season || ':' || League, '; ') where League is the corresponding column name, for clubs with COUNT(*) > 1, ordered by Appearances DESC and showing only the top 10 results?","
SELECT DISTINCT `Club`, COUNT(*) `Appearances`, GROUP_CONCAT(`Season` || ':' || `League`, '; ') `SeasonsLeagues`
FROM (
  SELECT `Season`,
    CASE v.pos WHEN 1 THEN `Serbian League Belgrade` WHEN 2 THEN `Serbian League East` WHEN 3 THEN `Serbian League Vojvodina` WHEN 4 THEN `Serbian League West` END `Club`,
    CASE v.pos WHEN 1 THEN '`Serbian League Belgrade`' WHEN 2 THEN '`Serbian League East`' WHEN 3 THEN '`Serbian League Vojvodina`' WHEN 4 THEN '`Serbian League West`' END `League`
  FROM `table_1_12283621_6`, (VALUES (1),(2),(3),(4)) v(pos)
) u
GROUP BY `Club`
HAVING COUNT(*) > 1
ORDER BY `Appearances` DESC
LIMIT 10;
","SELECT DISTINCT `Club`, COUNT(*) AS `Appearances`, GROUP_CONCAT(col0 || ':' || `League`, '; ') AS `SeasonsLeagues`
FROM (
  SELECT col0, col1 AS `Club`, 'Serbian League Belgrade' AS `League` FROM `table_1_12283621_6` WHERE 1=1 AND 1=1
  UNION ALL
  SELECT col0, col2 AS `Club`, 'Serbian League East' AS `League` FROM `table_1_12283621_6` WHERE 1=1 AND 1=1
  UNION ALL
  SELECT col0, col3 AS `Club`, 'Serbian League Vojvodina' AS `League` FROM `table_1_12283621_6` WHERE 1=1 AND 1=1
  UNION ALL
  SELECT col0, col4 AS `Club`, 'Serbian League West' AS `League` FROM `table_1_12283621_6` WHERE 1=1 AND 1=1
) u
GROUP BY `Club`
HAVING COUNT(*) > 1
ORDER BY `Appearances` DESC
LIMIT 10;","[('sloga kraljevo', 2, '2008–09:Serbian League West; 2010–11:Serbian League West'), ('radnički niš', 2, '2008–09:Serbian League East; 2010–11:Serbian League East')]",table_1_12283621_6,"1) The intent is to unpivot the four league columns into (Season, Club, League) rows, then compute per-Club counts and a concatenated list of Season:League. 2) Use the table's Season and the four league columns as the source values and use the column names as League labels. 3) Formulate a question requesting the distinct Club, COUNT(*) as Appearances, and GROUP_CONCAT(Season||':'||League, '; ') as SeasonsLeagues for clubs with more than one appearance, ordered by Appearances descending and limited to 10. 4) Confirm the question includes the DISTINCT Club, the COUNT(*) > 1 HAVING, the concatenation format, ordering and limit.",reserved,16,reward,,
"Provide Week, Craigs vote (as Unanimous vote), and Eliminated for entries where Craigs vote = Arlenes vote = Brunos vote = Lens vote and Craigs vote <> Eliminated, ordered by Week and limited to 10 rows?","
SELECT `Week`, `Craigs vote` `Unanimous vote`, `Eliminated`
FROM `table_1_12305325_4`
WHERE `Craigs vote` = `Arlenes vote` AND `Arlenes vote` = `Brunos vote` AND `Brunos vote` = `Lens vote` AND `Craigs vote` != `Eliminated`
ORDER BY `Week`
LIMIT 10;
","SELECT DISTINCT col0, col1 AS `Unanimous vote`, col6
FROM `table_1_12305325_4`
WHERE col1 = col2 AND col2 = col3 AND col1 != col6
ORDER BY col0
LIMIT 10;","[(3.0, 'john and nicole', 'willie and erin'), (5.0, 'john and nicole', 'dominic and lilia'), (7.0, 'john and nicole', 'kate and anton'), (8.0, 'kelly and brendan', 'john and nicole'), (9.0, 'letitia and darren', 'kenny and ola'), (10.0, 'alesha and matthew', 'letitia and darren')]",table_1_12305325_4,"1) Parse SQL intent: select weeks where the four judges unanimously voted for the same couple and that unanimous choice was not the eliminated pair, returning Week, Craigs vote renamed Unanimous vote, and Eliminated. 2) Map schema semantics: involve columns Week, Craigs vote, Arlenes vote, Brunos vote, Lens vote, and Eliminated. 3) Draft the question to include the four-way equality, the condition that the unanimous vote differs from Eliminated, the alias Unanimous vote, ordering by Week, and a limit of 10. 4) Validate that the question aligns exactly with the SQL selection, conditions, ordering, and limit.",reserved,9,reward,,
"Which past matches fall on a decennial anniversary or on a 10th/25th/50th/100th milestone this year, and what were the dates, opponents, competitions and scores?","
WITH parsed AS (
  SELECT
    `Record`,
    `Date and Time`,
    `Competition`,
    `Home or Away`,
    `Opponent`,
    `Score`,
    CAST(substr(`Score`,1,instr(`Score`,'–')-1) AS INTEGER) AS `goals_for`,
    CAST(substr(`Score`,instr(`Score`,'–')+1) AS INTEGER) AS `goals_against`,
    (CAST(substr(`Score`,1,instr(`Score`,'–')-1) AS INTEGER) - CAST(substr(`Score`,instr(`Score`,'–')+1) AS INTEGER)) AS `goal_margin`,
    ABS((CAST(substr(`Score`,1,instr(`Score`,'–')-1) AS INTEGER) - CAST(substr(`Score`,instr(`Score`,'–')+1) AS INTEGER))) AS `abs_margin`,
    (CAST(strftime('%Y','now') AS INTEGER) - CAST(substr(`Date and Time`,7,4) AS INTEGER)) AS `years_since`,
    CASE WHEN `Opponent` = `Wimbledon` THEN 1 ELSE 0 END AS `is_against_Wimbledon`
  FROM `table_1_1233808_2`
  WHERE `Score` LIKE '%–%'
),
stats AS (
  SELECT
    MAX(`goal_margin`) AS `max_goal_margin`,
    MIN(`goal_margin`) AS `min_goal_margin`,
    MAX(CASE WHEN `Home or Away` = `Home` THEN `goal_margin` END) AS `max_home_goal_margin`,
    MIN(CASE WHEN `Home or Away` = `Home` THEN `goal_margin` END) AS `min_home_goal_margin`,
    MAX(CASE WHEN `Home or Away` = `Away` THEN `goal_margin` END) AS `max_away_goal_margin`,
    MIN(CASE WHEN `Home or Away` = `Away` THEN `goal_margin` END) AS `min_away_goal_margin`
  FROM parsed
)
SELECT
  p.`Record`,
  p.`Date and Time`,
  p.`Competition`,
  p.`Home or Away`,
  p.`Opponent`,
  p.`Score`,
  p.`goals_for`,
  p.`goals_against`,
  p.`goal_margin`,
  p.`abs_margin`,
  p.`years_since`,
  p.`is_against_Wimbledon`,
  CASE WHEN p.`goal_margin` = s.`max_goal_margin` THEN 1 ELSE 0 END AS `is_biggest_overall_win`,
  CASE WHEN p.`goal_margin` = s.`min_goal_margin` THEN 1 ELSE 0 END AS `is_biggest_overall_defeat`,
  CASE WHEN p.`goal_margin` = s.`max_home_goal_margin` THEN 1 ELSE 0 END AS `is_biggest_home_win`,
  CASE WHEN p.`goal_margin` = s.`min_home_goal_margin` THEN 1 ELSE 0 END AS `is_biggest_home_defeat`,
  CASE WHEN p.`goal_margin` = s.`max_away_goal_margin` THEN 1 ELSE 0 END AS `is_biggest_away_win`,
  CASE WHEN p.`goal_margin` = s.`min_away_goal_margin` THEN 1 ELSE 0 END AS `is_biggest_away_defeat`,
  CASE WHEN p.`years_since` % 10 = 0 THEN 1 ELSE 0 END AS `is_decennial_anniversary`,
  CASE WHEN p.`years_since` IN (100,50,25,10) THEN 1 ELSE 0 END AS `is_milestone_anniversary`
FROM parsed p
CROSS JOIN stats s
ORDER BY p.`abs_margin` DESC, p.`goal_margin` DESC, p.`Date and Time` ASC;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    CAST(substr(col5,1,instr(col5,'–')-1) AS INTEGER) AS `goals_for`,
    CAST(substr(col5,instr(col5,'–')+1) AS INTEGER) AS `goals_against`,
    (CAST(substr(col5,1,instr(col5,'–')-1) AS INTEGER) - CAST(substr(col5,instr(col5,'–')+1) AS INTEGER)) AS `goal_margin`,
    ABS((CAST(substr(col5,1,instr(col5,'–')-1) AS INTEGER) - CAST(substr(col5,instr(col5,'–')+1) AS INTEGER))) AS `abs_margin`,
    (CAST(strftime('%Y','now') AS INTEGER) - CAST(substr(col1,7,4) AS INTEGER)) AS `years_since`,
    CASE WHEN col4 = 'Wimbledon' THEN 1 ELSE 0 END AS `is_against_Wimbledon`
  FROM `table_1_1233808_2`
  WHERE col5 LIKE '%–%'
)
SELECT
  p.col0,
  p.col1,
  p.col2,
  p.col3,
  p.col4,
  p.col5,
  p.`goals_for`,
  p.`goals_against`,
  p.`goal_margin`,
  p.`abs_margin`,
  p.`years_since`,
  p.`is_against_Wimbledon`,
  CASE WHEN p.`goal_margin` = (SELECT MAX(`goal_margin`) FROM parsed) THEN 1 ELSE 0 END AS `is_biggest_overall_win`,
  CASE WHEN p.`goal_margin` = (SELECT MIN(`goal_margin`) FROM parsed) THEN 1 ELSE 0 END AS `is_biggest_overall_defeat`,
  CASE WHEN p.`goal_margin` = (SELECT MAX(`goal_margin`) FROM parsed WHERE col3 = 'Home') THEN 1 ELSE 0 END AS `is_biggest_home_win`,
  CASE WHEN p.`goal_margin` = (SELECT MIN(`goal_margin`) FROM parsed WHERE col3 = 'Home') THEN 1 ELSE 0 END AS `is_biggest_home_defeat`,
  CASE WHEN p.`goal_margin` = (SELECT MAX(`goal_margin`) FROM parsed WHERE col3 = 'Away') THEN 1 ELSE 0 END AS `is_biggest_away_win`,
  CASE WHEN p.`goal_margin` = (SELECT MIN(`goal_margin`) FROM parsed WHERE col3 = 'Away') THEN 1 ELSE 0 END AS `is_biggest_away_defeat`,
  CASE WHEN p.`years_since` % 10 = 0 THEN 1 ELSE 0 END AS `is_decennial_anniversary`,
  CASE WHEN p.`years_since` IN (100,50,25,10) THEN 1 ELSE 0 END AS `is_milestone_anniversary`
FROM parsed p
ORDER BY p.`abs_margin` DESC, p.`goal_margin` DESC, p.col1 ASC;","[('biggest win', '19.10.1912 at 15:00', 'spartan league', 'home', 'aylesbury united', '14–0', 14, 0, 14, 14, 113, 0, 1, 0, 0, 0, 0, 0, 0, 0), ('biggest home win', '19.10.1912 at 15:00', 'spartan league', 'home', 'aylesbury united', '14–0', 14, 0, 14, 14, 113, 0, 1, 0, 0, 0, 0, 0, 0, 0), ('biggest defeat', '09.11.1946 at 15:00', 'isthmian league', 'home', 'wimbledon', '0–11', 0, 11, -11, 11, 79, 0, 0, 1, 0, 0, 0, 0, 0, 0), ('biggest home defeat', '09.11.1946 at 15:00', 'isthmian league', 'home', 'wimbledon', '0–11', 0, 11, -11, 11, 79, 0, 0, 1, 0, 0, 0, 0, 0, 0), ('biggest away win', '17.04.1920 at 15:00', 'spartan league', 'away', 'tufnell spartans', '11–1', 11, 1, 10, 10, 105, 0, 0, 0, 0, 0, 0, 0, 0, 0), ('biggest away win', '24.11.1970 at 15:00', 'mithras cup 2nd rd (2nd leg)', 'away', 'ruislip manor', '10–0', 10, 0, 10, 10, 55, 0, 0, 0, 0, 0, 0, 0, 0, 0), ('most goals in one match', '22.11.1922 at 15:00', 'fa cup / 4th qf (replay)', 'away', 'dulwich hamlet', '7–8', 7, 8, -1, 1, 103, 0, 0, 0, 0, 0, 0, 0, 0, 0)]",table_1_1233808_2,"I look for anniversary hooks for features and would ask about decennial and other milestone anniversaries in plain language. The query computes years since each match (using the match year against the current year) and flags decennial anniversaries and milestones of 10, 25, 50 and 100 years. It returns the match date, competition, home/away, opponent and score along with those anniversary flags. Which past matches fall on a decennial anniversary or on a 10th/25th/50th/100th milestone this year, and what were the dates, opponents, competitions and scores? This asks only for the anniversary information the SQL computes and nothing extra.",persona,"Club historian and programme editor for St Albans City F.C. who maintains the club's records and produces matchday features and anniversary articles using the club's historical scores database. Goals: Verify and cite the club's record results (biggest wins/defeats, home/away extremes) for publications and matchday programmes. Identify matches with the largest goal margins to compile top‑result lists and statistical features. Find specific opponent or date milestones (e.g., anniversaries) to create historical retrospectives. Example Queries: SELECT ""Record"", ""Date and Time"", ""Competition"", ""Home or Away"", ""Opponent"", ""Score"" FROM table_1_1233808_2 ORDER BY ""Date and Time"" ASC; SELECT ""Record"", ""Date and Time"", ""Opponent"", ""Score"", CAST(substr(""Score"",1,instr(""Score"",'–')-1) AS INTEGER) AS goals_for, CAST(substr(""Score"",instr(""Score"",'–')+1) AS INTEGER) AS goals_against, (CAST(substr(""Score"",1,instr(""Score"",'–')-1) AS INTEGER) - CAST(substr(""Score"",instr(""Score"",'–')+1) AS INTEGER)) AS goal_margin FROM table_1_1233808_2 WHERE ""Score"" LIKE '%–%' ORDER BY goal_margin DESC; SELECT * FROM table_1_1233808_2 WHERE ""Opponent"" = 'Wimbledon' OR ""Record"" LIKE '%defeat%' ORDER BY ""Date and Time"" DESC;",reward,,
"Provide for each State the State, the State value surrounded by backticks, the Weighted Recalc calculated as (Preliminaries*0.2 + Interview*0.3 + Swimsuit*0.25 + Evening Gown*0.25), and Delta vs Recalc calculated as (Average - (Preliminaries*0.2 + Interview*0.3 + Swimsuit*0.25 + Evening Gown*0.25)), but only include rows where ABS(Delta vs Recalc) > 0.0005?","
SELECT `State`, '`'||`State`||'`' `Backticked State`, ((`Preliminaries`*0.2 + `Interview`*0.3 + `Swimsuit`*0.25 + `Evening Gown`*0.25)) `Weighted Recalc`, ((`Average` - (`Preliminaries`*0.2 + `Interview`*0.3 + `Swimsuit`*0.25 + `Evening Gown`*0.25))) `Delta vs Recalc` FROM `table_1_12338595_1` WHERE ABS((`Average` - (`Preliminaries`*0.2 + `Interview`*0.3 + `Swimsuit`*0.25 + `Evening Gown`*0.25))) > 0.0005;
","
SELECT col0, '`'||col0||'`' `Backticked State`, ((col1*0.2 + col2*0.3 + col3*0.25 + col4*0.25)) `Weighted Recalc`, ((col5 - (col1*0.2 + col2*0.3 + col3*0.25 + col4*0.25))) `Delta vs Recalc` FROM `table_1_12338595_1` WHERE ABS((col5 - (col1*0.2 + col2*0.3 + col3*0.25 + col4*0.25))) > 0.0005;
","[('virginia', '`virginia`', 8.80885, 0.016149999999999665), ('new york', '`new york`', 8.8154, 0.07059999999999889), ('georgia', '`georgia`', 8.7269, 0.11509999999999998), ('kentucky', '`kentucky`', 8.692599999999999, 0.10840000000000138), ('texas', '`texas`', 8.7042, 0.08779999999999966), ('pennsylvania', '`pennsylvania`', 8.69975, 0.06825000000000081), ('california', '`california`', 8.62815, 0.10485000000000078), ('arkansas', '`arkansas`', 8.5455, 0.04249999999999865), ('nevada', '`nevada`', 8.4755, 0.04449999999999932)]",table_1_12338595_1,"1) The intent is to compute a weighted aggregate from four score columns, show State and a backticked State label, compute the difference from the listed Average, and return only rows with a non-negligible discrepancy > 0.0005. 2) Map Preliminaries, Interview, Swimsuit, Evening Gown to their weights 0.2, 0.3, 0.25, 0.25 and use Average for comparison. 3) Phrase a question requesting State, the backticked State value, the weighted recalculation, and the delta with the absolute threshold. 4) Confirm all calculations and the absolute comparison are explicitly mentioned.",reserved,3,reward,,
"Give me a prioritized list of 2005 BC municipalities that puts under‑policed high‑crime towns first, showing for each the population, number of officers, residents per officer, crime rate per 1,000 and cost per capita?","
SELECT
  `Municipality`,
  `Population`,
  `Police officers`,
  `Residents per officer`,
  `Crime rate per 1,000 people`,
  `Cost per capita`,
  CAST(REPLACE(REPLACE(`Cost per capita`, '$', ''), ',', '') AS REAL) AS `cost_per_capita_num`,
  ROUND((`Police officers` / `Population`) * 1000.0, 3) AS `officers_per_1000`,
  CASE WHEN `Residents per officer` > 1000 AND `Crime rate per 1,000 people` > 80 THEN 1 ELSE 0 END AS `under_policed_high_crime`,
  CASE
    WHEN `Population` < 10000 THEN 'Small'
    WHEN `Population` BETWEEN 10000 AND 30000 THEN 'Small-Mid'
    WHEN `Population` BETWEEN 30001 AND 100000 THEN 'Mid'
    ELSE 'Large'
  END AS `population_bin`,
  RANK() OVER (
    PARTITION BY CASE
      WHEN `Population` < 10000 THEN 'Small'
      WHEN `Population` BETWEEN 10000 AND 30000 THEN 'Small-Mid'
      WHEN `Population` BETWEEN 30001 AND 100000 THEN 'Mid'
      ELSE 'Large'
    END
    ORDER BY CAST(REPLACE(REPLACE(`Cost per capita`, '$', ''), ',', '') AS REAL) DESC
  ) AS `cost_rank_in_bin_desc`,
  RANK() OVER (
    PARTITION BY CASE
      WHEN `Population` < 10000 THEN 'Small'
      WHEN `Population` BETWEEN 10000 AND 30000 THEN 'Small-Mid'
      WHEN `Population` BETWEEN 30001 AND 100000 THEN 'Mid'
      ELSE 'Large'
    END
    ORDER BY `Residents per officer` DESC
  ) AS `residents_per_officer_rank_in_bin`,
  CAST(REPLACE(REPLACE(`Cost per capita`, '$', ''), ',', '') AS REAL)
    - AVG(CAST(REPLACE(REPLACE(`Cost per capita`, '$', ''), ',', '') AS REAL)) OVER (
        PARTITION BY CASE
          WHEN `Population` < 10000 THEN 'Small'
          WHEN `Population` BETWEEN 10000 AND 30000 THEN 'Small-Mid'
          WHEN `Population` BETWEEN 30001 AND 100000 THEN 'Mid'
          ELSE 'Large'
        END
      ) AS `cost_diff_from_bin_avg`
FROM `table_1_12340907_1`
ORDER BY `under_policed_high_crime` DESC, `Residents per officer` DESC, `Crime rate per 1,000 people` DESC, `Population` ASC;
","
SELECT
  col0,
  col1,
  col2,
  col3,
  col7,
  col5,
  CAST(REPLACE(REPLACE(col5, '$', ''), ',', '') AS REAL) AS `cost_per_capita_num`,
  ROUND((col2 / col1) * 1000.0, 3) AS `officers_per_1000`,
  CASE WHEN col3 > 1000 AND col7 > 80 THEN 1 ELSE 0 END AS `under_policed_high_crime`,
  CASE
    WHEN col1 < 10000 THEN 'Small'
    WHEN col1 BETWEEN 10000 AND 30000 THEN 'Small-Mid'
    WHEN col1 BETWEEN 30001 AND 100000 THEN 'Mid'
    ELSE 'Large'
  END AS `population_bin`,
  RANK() OVER (
    PARTITION BY CASE
      WHEN col1 < 10000 THEN 'Small'
      WHEN col1 BETWEEN 10000 AND 30000 THEN 'Small-Mid'
      WHEN col1 BETWEEN 30001 AND 100000 THEN 'Mid'
      ELSE 'Large'
    END
    ORDER BY CAST(REPLACE(REPLACE(col5, '$', ''), ',', '') AS REAL) DESC
  ) AS `cost_rank_in_bin_desc`,
  RANK() OVER (
    PARTITION BY CASE
      WHEN col1 < 10000 THEN 'Small'
      WHEN col1 BETWEEN 10000 AND 30000 THEN 'Small-Mid'
      WHEN col1 BETWEEN 30001 AND 100000 THEN 'Mid'
      ELSE 'Large'
    END
    ORDER BY col3 DESC
  ) AS `residents_per_officer_rank_in_bin`,
  CAST(REPLACE(REPLACE(col5, '$', ''), ',', '') AS REAL)
    - AVG(CAST(REPLACE(REPLACE(col5, '$', ''), ',', '') AS REAL)) OVER (
        PARTITION BY CASE
          WHEN col1 < 10000 THEN 'Small'
          WHEN col1 BETWEEN 10000 AND 30000 THEN 'Small-Mid'
          WHEN col1 BETWEEN 30001 AND 100000 THEN 'Mid'
          ELSE 'Large'
        END
      ) AS `cost_diff_from_bin_avg`
FROM `table_1_12340907_1`
ORDER BY `under_policed_high_crime` DESC, col3 DESC, col7 DESC, col1 ASC;
","[('qualicum beach', 8807.0, 6.0, 1468.0, 81.0, '$53', 53.0, 0.681, 1, 'Small', 14, 2, -86.0), ('lake country', 10367.0, 9.0, 1152.0, 90.0, '$71', 71.0, 0.868, 1, 'Small-Mid', 28, 4, -80.26666666666668), ('view royal', 8382.0, 8.0, 1048.0, 87.0, '$115', 115.0, 0.954, 1, 'Small', 10, 3, -24.0), ('ladysmith', 7292.0, 7.0, 1042.0, 81.0, '$95', 95.0, 0.96, 1, 'Small', 12, 4, -44.0), ('north cowichan', 28519.0, 28.0, 1019.0, 98.0, '$127', 127.0, 0.982, 1, 'Small-Mid', 19, 6, -24.26666666666668), ('sooke', 10117.0, 10.0, 1012.0, 92.0, '$99', 99.0, 0.988, 1, 'Small-Mid', 23, 7, -52.26666666666668), ('spallumcheen', 5707.0, 3.0, 1902.0, 46.0, '$47', 47.0, 0.526, 0, 'Small', 15, 1, -92.0), ('coldstream', 10102.0, 7.0, 1443.0, 38.0, '$69', 69.0, 0.693, 0, 'Small-Mid', 29, 1, -82.26666666666668), ('comox', 12706.0, 10.0, 1271.0, 56.0, '$75', 75.0, 0.787, 0, 'Small-Mid', 27, 2, -76.26666666666668), ('summerland', 11405.0, 9.0, 1267.0, 68.0, '$69', 69.0, 0.789, 0, 'Small-Mid', 29, 3, -82.26666666666668), ('north saanich', 11274.0, 10.0, 1127.0, 34.0, '$84', 84.0, 0.887, 0, 'Small-Mid', 26, 5, -67.26666666666668), ('salmon arm', 17000.0, 17.0, 1000.0, 103.0, '$104', 104.0, 1.0, 0, 'Small-Mid', 22, 8, -47.26666666666668), ('port coquitlam', 57569.0, 59.0, 976.0, 112.0, '$133', 133.0, 1.025, 0, 'Mid', 15, 1, -54.0625), ('north vancouver (district)', 88461.0, 91.0, 972.0, 67.0, '$133', 133.0, 1.029, 0, 'Mid', 15, 2, -54.0625), ('coquitlam', 121989.0, 127.0, 961.0, 100.0, '$139', 139.0, 1.041, 0, 'Large', 9, 1, -43.0), ('colwood', 15253.0, 16.0, 953.0, 74.0, '$95', 95.0, 1.049, 0, 'Small-Mid', 25, 9, -56.26666666666668), ('maple ridge', 73531.0, 79.0, 931.0, 136.0, '$152', 152.0, 1.074, 0, 'Mid', 14, 3, -35.0625), ('langford', 21845.0, 24.0, 910.0, 112.0, '$156', 156.0, 1.099, 0, 'Small-Mid', 15, 10, 4.73333333333332), ('richmond', 173429.0, 94.0, 908.0, 191.0, '$152', 152.0, 0.542, 0, 'Large', 7, 2, -30.0), ('parksville', 11709.0, 13.0, 901.0, 174.0, '$99', 99.0, 1.11, 0, 'Small-Mid', 23, 11, -52.26666666666668), ('sechelt', 8901.0, 10.0, 890.0, 96.0, '$102', 102.0, 1.123, 0, 'Small', 11, 5, -37.0), ('pitt meadows', 16673.0, 19.0, 878.0, 101.0, '$120', 120.0, 1.14, 0, 'Small-Mid', 20, 12, -31.26666666666668), ('white rock', 19577.0, 23.0, 851.0, 84.0, '$160', 160.0, 1.175, 0, 'Small-Mid', 13, 13, 8.73333333333332), ('sidney', 11862.0, 14.0, 847.0, 54.0, '$108', 108.0, 1.18, 0, 'Small-Mid', 21, 14, -43.26666666666668), ('courtenay', 21801.0, 26.0, 838.0, 182.0, '$147', 147.0, 1.193, 0, 'Small-Mid', 17, 15, -4.26666666666668), ('kelowna', 109490.0, 131.0, 836.0, 150.0, '$149', 149.0, 1.196, 0, 'Large', 8, 3, -33.0), ('oak bay', 18313.0, 22.0, 832.0, 65.0, '$194', 194.0, 1.201, 0, 'Small-Mid', 8, 16, 42.73333333333332), ('cranbrook', 19774.0, 24.0, 824.0, 131.0, '$159', 159.0, 1.214, 0, 'Small-Mid', 14, 17, 7.73333333333332), ('burnaby', 204320.0, 253.0, 808.0, 123.0, '$160', 160.0, 1.238, 0, 'Large', 6, 4, -22.0), ('chilliwack', 73066.0, 91.0, 803.0, 174.0, '$154', 154.0, 1.245, 0, 'Mid', 12, 4, -33.0625), ('central saanich', 16821.0, 21.0, 801.0, 49.0, '$181', 181.0, 1.248, 0, 'Small-Mid', 11, 18, 29.73333333333332), ('langley (township)', 97682.0, 123.0, 794.0, 108.0, '$168', 168.0, 1.259, 0, 'Mid', 10, 5, -19.0625), ('penticton', 33061.0, 42.0, 787.0, 165.0, '$154', 154.0, 1.27, 0, 'Mid', 12, 6, -33.0625), ('kimberley', 7049.0, 9.0, 783.0, 77.0, '$95', 95.0, 1.277, 0, 'Small', 12, 6, -44.0), ('campbell river', 30810.0, 40.0, 770.0, 178.0, '$173', 173.0, 1.298, 0, 'Mid', 9, 7, -14.0625), ('powell river', 13831.0, 18.0, 768.0, 114.0, '$139', 139.0, 1.301, 0, 'Small-Mid', 18, 19, -12.26666666666668), ('saanich', 110386.0, 57.0, 751.0, 67.0, '$176', 176.0, 0.516, 0, 'Large', 4, 5, -6.0), ('mission', 34742.0, 47.0, 739.0, 169.0, '$183', 183.0, 1.353, 0, 'Mid', 6, 8, -4.0625), ('vernon', 36232.0, 49.0, 739.0, 167.0, '$165', 165.0, 1.352, 0, 'Mid', 11, 8, -22.0625), ('north vancouver (city)', 47131.0, 64.0, 736.0, 117.0, '$186', 186.0, 1.358, 0, 'Mid', 5, 10, -1.0625), ('revelstoke', 7964.0, 11.0, 724.0, 105.0, '$123', 123.0, 1.381, 0, 'Small', 9, 7, -16.0), ('surrey', 393256.0, 552.0, 712.0, 127.0, '$167', 167.0, 1.404, 0, 'Large', 5, 6, -15.0), ('castlegar', 7821.0, 11.0, 711.0, 150.0, '$143', 143.0, 1.406, 0, 'Small', 7, 8, 4.0), ('port moody', 28458.0, 40.0, 711.0, 67.0, '$203', 203.0, 1.406, 0, 'Small-Mid', 7, 20, 51.73333333333332), ('kitimat', 10587.0, 15.0, 706.0, 70.0, '$148', 148.0, 1.417, 0, 'Small-Mid', 16, 21, -3.26666666666668), ('nanaimo', 79898.0, 114.0, 701.0, 178.0, '$183', 183.0, 1.427, 0, 'Mid', 6, 11, -4.0625), ('kamloops', 82714.0, 118.0, 701.0, 168.0, '$181', 181.0, 1.427, 0, 'Mid', 8, 11, -6.0625), ('abbotsford', 128165.0, 187.0, 685.0, 118.0, '$199', 199.0, 1.459, 0, 'Large', 3, 7, 17.0), ('fort st. john', 17781.0, 26.0, 684.0, 228.0, '$213', 213.0, 1.462, 0, 'Small-Mid', 5, 22, 61.73333333333332), ('mackenzie', 5454.0, 8.0, 682.0, 108.0, '$141', 141.0, 1.467, 0, 'Small', 8, 9, 2.0), ('delta', 102661.0, 74.0, 680.0, 151.0, '$205', 205.0, 0.721, 0, 'Large', 2, 8, 23.0), ('trail', 7889.0, 12.0, 657.0, 147.0, '$171', 171.0, 1.521, 0, 'Small', 3, 10, 32.0), ('prince george', 77148.0, 121.0, 638.0, 179.0, '$201', 201.0, 1.568, 0, 'Mid', 4, 13, 13.9375), ('squamish', 15922.0, 25.0, 637.0, 204.0, '$186', 186.0, 1.57, 0, 'Small-Mid', 9, 23, 34.73333333333332), ('smithers', 5509.0, 9.0, 612.0, 301.0, '$170', 170.0, 1.634, 0, 'Small', 4, 11, 31.0), ('west vancouver', 46595.0, 79.0, 590.0, 60.0, '$222', 222.0, 1.695, 0, 'Mid', 3, 14, 34.9375), ('langley (city)', 25716.0, 9.0, 584.0, 176.0, '$237', 237.0, 0.35, 0, 'Small-Mid', 3, 24, 85.73333333333332), ('merritt', 7561.0, 13.0, 582.0, 228.0, '$157', 157.0, 1.719, 0, 'Small', 6, 12, 18.0), ('nelson', 9797.0, 17.0, 576.0, 139.0, '$201', 201.0, 1.735, 0, 'Small', 2, 13, 62.0), ('port alberni', 18688.0, 34.0, 550.0, 210.0, '$249', 249.0, 1.819, 0, 'Small-Mid', 2, 25, 97.73333333333332), ('new westminster', 57480.0, 107.0, 537.0, 162.0, '$276', 276.0, 1.862, 0, 'Mid', 2, 15, 88.9375), ('quesnel', 10487.0, 20.0, 524.0, 237.0, '$259', 259.0, 1.907, 0, 'Small-Mid', 1, 26, 107.73333333333332), ('dawson creek', 11394.0, 22.0, 518.0, 225.0, '$215', 215.0, 1.931, 0, 'Small-Mid', 4, 27, 63.73333333333332), ('williams lake', 11872.0, 23.0, 516.0, 252.0, '$175', 175.0, 1.937, 0, 'Small-Mid', 12, 28, 23.73333333333332), ('hope', 6591.0, 13.0, 507.0, 180.0, '$168', 168.0, 1.972, 0, 'Small', 5, 14, 29.0), ('terrace', 12556.0, 25.0, 502.0, 206.0, '$184', 184.0, 1.991, 0, 'Small-Mid', 10, 29, 32.73333333333332), ('vancouver', 584701.0, 1174.0, 498.0, 117.0, '$291', 291.0, 2.008, 0, 'Large', 1, 9, 109.0), ('victoria', 94525.0, 215.0, 440.0, 186.0, '$329', 329.0, 2.275, 0, 'Mid', 1, 16, 141.9375), ('whistler', 9775.0, 23.0, 425.0, 202.0, '$304', 304.0, 2.353, 0, 'Small', 1, 15, 165.0), ('prince rupert', 14974.0, 36.0, 416.0, 204.0, '$213', 213.0, 2.404, 0, 'Small-Mid', 5, 30, 61.73333333333332)]",table_1_12340907_1,"As a director I want a ranked roster that puts the riskiest, understaffed hotspots first without getting technical about window functions. The SQL orders results to show under‑policed high‑crime places first, then by highest residents per officer, then by crime rate and smaller populations. That maps to the under_policed_high_crime flag, Residents per officer, Crime rate per 1,000 people, and Population along with the usual staffing and cost fields. Give me a prioritized list showing which towns are under‑policed and high‑crime, with population, officers, residents per officer, crime rate and cost per capita. This directly reflects the query's sort and returned columns.",persona,"An immersive theatre director designing a traveling, period-accurate 2005 British Columbia police procedural who needs authentic municipal policing details to script realistic scenes. Goals: Identify under‑policed towns (high residents per officer) that still have elevated crime rates to stage tense, high-stakes scenes. Pick municipalities with unusually high or low policing cost-per-capita for political/subplot beats and to justify visible vs. invisible police presence in different scenes. Assemble a palette of towns with similar population sizes but different police staffing and crime profiles so each episode/location has a distinct policing 'flavor'. Example Queries: SELECT ""Municipality"", ""Population"", ""Police officers"", ""Residents per officer"", ""Crime rate per 1,000 people""
FROM table_1_12340907_1
WHERE ""Residents per officer"" > 1000 AND ""Crime rate per 1,000 people"" > 80
ORDER BY ""Population"" ASC; SELECT ""Municipality"", ""Police officers"", ""Cost per capita"", ""Total costs (2005)""
FROM table_1_12340907_1
WHERE ""Police force"" = 'RCMP'
ORDER BY CAST(REPLACE(REPLACE(""Cost per capita"", '$', ''), ',', '') AS REAL) DESC
LIMIT 10; SELECT ""Municipality"", (""Police officers"" / ""Population"") * 1000 AS officers_per_1000, ""Crime rate per 1,000 people""
FROM table_1_12340907_1
ORDER BY officers_per_1000 DESC;",reward,,
Which directors have more than one film nominated?,"
SELECT `Director`, COUNT(`Film title used in nomination`) total_submissions, 1 + (MIN(`Result`) != MAX(`Result`)) distinct_results, GROUP_CONCAT(`Film title used in nomination`, ' | ') films
FROM `table_1_12369913_1`
GROUP BY `Director`
HAVING COUNT(`Film title used in nomination`) > 1
ORDER BY -COUNT(`Film title used in nomination`)
LIMIT 10;
","
SELECT col3, COUNT(col1) total_submissions, 1 + (MIN(col4) != MAX(col4)) distinct_results, GROUP_CONCAT(col1, ' | ') films
FROM `table_1_12369913_1`
GROUP BY col3
HAVING COUNT(col1) > 1
ORDER BY -COUNT(col1)
LIMIT 10;
","[('joseph cedar category:articles with hcards', 4, 2, 'time of favor | campfire | beaufort | footnote'), ('savi gavison category:articles with hcards', 3, 1, ""the lookout | lovesick on nana street | nina's tragedies""), ('ephraim kishon category:articles with hcards', 2, 1, 'sallah | the policeman'), ('eyal halfon category:articles with hcards', 2, 1, 'circus palestine | what a wonderful place'), ('michal bat-adam category:articles with hcards', 2, 1, 'moments | the thin line'), ('moshé mizrahi category:articles with hcards', 2, 1, 'i love you rosa | the house on chelouche street'), ('uri barbash category:articles with hcards', 2, 2, 'beyond the walls | one of us')]",table_1_12369913_1,"STEP 1: The SQL returns the top 10 directors who have more than one row in the table: it selects Director, COUNT(film) as total_submissions, computes distinct_results as 1 or 2 depending on whether the Result values differ, and concatenates the film titles; it groups by Director, filters HAVING COUNT(film) > 1, orders by descending count, limits 10. STEP 2: Ambiguity type chosen: Entity vagueness about the meaning of 'nominated' fits well because the query counts all film entries regardless of the Result field, whereas a human question could mean only films with Result = 'Nominee' (actual nominees) or any submitted film listed in the nomination column. STEP 3: Draft question: ""Which directors have more than one film nominated?"" STEP 4: Explanation: The SQL interprets this as directors who appear multiple times in the dataset (multiple submitted/entered films), with distinct_results indicating whether their entries include different outcomes; alternatively the question could be read as asking only for directors with multiple films that were actually Oscar nominees (filtering Result='Nominee'), or for multiple nominations within a single ceremony rather than across the whole dataset.",reserved,7,reward,,"type: Entity Vagueness | explanation: In the SQL 'nominated' is implemented as mere presence in the 'Film title used in nomination' rows (any submission), but a reader could interpret 'nominated' to mean only films with Result = 'Nominee' (actual Oscar nominees) or even multiple nominations in the same ceremony rather than across all years."
"For each 'Directed by' value, what are the Reported episodes (COUNT), the Average viewers (AVG of 'Total viewers (in millions)') and the Peak viewers (MAX of 'Total viewers (in millions)') considering only rows where 'Total viewers (in millions)' > 0, grouped by 'Directed by' and limited to 5 results?","
SELECT `Directed by`, COUNT(*) `Reported episodes`, AVG(`Total viewers (in millions)`) `Average viewers`, MAX(`Total viewers (in millions)`) `Peak viewers` FROM `table_1_12419515_4` WHERE `Total viewers (in millions)` > 0 GROUP BY `Directed by` LIMIT 5;
","
SELECT col3, COUNT(*) `Reported episodes`, AVG(col6) `Average viewers`, MAX(col6) `Peak viewers` FROM `table_1_12419515_4` WHERE col6 > 0 GROUP BY col3 LIMIT 5;
","[('fred gerber', 1, 0.0, 'n/a'), ('fred savage', 1, 1.031, '1.031'), ('john t. kretchmer', 1, 0.0, 'n/a'), ('lee rose', 1, 0.0, 'n/a'), ('mark rosman', 1, 0.872, '0.872')]",table_1_12419515_4,"1) Parse SQL intent: compute per-director aggregates (count, average, max) for episodes with Total viewers (in millions) > 0 and return up to 5 directors. 2) Map schema semantics: 'Directed by' is the director field and 'Total viewers (in millions)' is the numeric viewers field. 3) Draft the question: ask for Directed by, Reported episodes (COUNT), Average viewers (AVG of Total viewers (in millions)), Peak viewers (MAX of Total viewers (in millions)) with the >0 filter, grouped by director and limited to 5. 4) Validate: ensures grouping, filter, aggregate names, and LIMIT 5 are all represented.",reserved,6,reward,,
"Can you give me a ranked list of actors and their characters with episode counts, their share of total episodes, whether they're one of the Jonas brothers, how many seasons they were main cast, whether they recur in all seasons, and a composite priority score for licensing?","
SELECT
  '`' || `Portrayed by` || '`' AS `Portrayed by (backticked)`,
  '`' || `Character` || '`' AS `Character (backticked)`,
  `# of episodes` AS `# of episodes`,
  ROUND((`# of episodes` * 1.0) / (SELECT SUM(`# of episodes`) FROM `table_1_12441518_1`), 4) AS `episode_share`,
  CASE WHEN `Portrayed by` IN ('Nick Jonas','Joe Jonas','Kevin Jonas') THEN 1 ELSE 0 END AS `is_jonas_trio`,
  CAST(substr(`Main cast seasons`, -1, 1) AS integer) AS `main_cast_seasons_count`,
  CASE WHEN `Recurring cast seasons` = 'Appears in all seasons' THEN 1 ELSE 0 END AS `recurs_in_all_seasons`,
  ROUND(
    ((`# of episodes` * 1.0) / (SELECT SUM(`# of episodes`) FROM `table_1_12441518_1`) ) * 0.7
    + (CASE WHEN `Portrayed by` IN ('Nick Jonas','Joe Jonas','Kevin Jonas') THEN 0.2 ELSE 0 END)
    + (CASE WHEN `Recurring cast seasons` = 'Appears in all seasons' THEN 0.1 ELSE 0 END)
  , 4) AS `priority_score`
FROM `table_1_12441518_1`
ORDER BY `priority_score` DESC, `# of episodes` DESC;
","SELECT
  col1,
  ""Character"",
  col4,
  ROUND((col4 * 1.0) / (SELECT SUM(col4) FROM `table_1_12441518_1`), 4) AS episode_share,
  CASE WHEN col1 IN ('Nick Jonas', 'Joe Jonas', 'Kevin Jonas') THEN 1 ELSE 0 END AS is_jonas_trio,
  CAST(substr(col2, -1, 1) AS integer) AS main_cast_seasons_count,
  CASE WHEN col3 = 'Appears in all seasons' THEN 1 ELSE 0 END AS recurs_in_all_seasons,
  ROUND(
    ((col4 * 1.0) / (SELECT SUM(col4) FROM `table_1_12441518_1`)) * 0.7
    + (CASE WHEN col1 IN ('Nick Jonas', 'Joe Jonas', 'Kevin Jonas') THEN 0.2 ELSE 0 END)
    + (CASE WHEN col3 = 'Appears in all seasons' THEN 0.1 ELSE 0 END)
  , 4) AS priority_score
FROM `table_1_12441518_1`
ORDER BY priority_score DESC, col4 DESC;","[('nick jonas', 'Character', 34.0, 0.2048, 0, 2, 0, 0.1434), ('joe jonas', 'Character', 34.0, 0.2048, 0, 2, 0, 0.1434), ('kevin jonas', 'Character', 34.0, 0.2048, 0, 2, 0, 0.1434), ('chelsea kane', 'Character', 34.0, 0.2048, 0, 2, 0, 0.1434), ('nicole anderson', 'Character', 30.0, 0.1807, 0, 2, 0, 0.1265)]",table_1_12441518_1,"As an Ethical AI Voice Model Curator I would phrase things in terms of actors, characters, episodes and licensing priority rather than SQL technicalities. The query computes episode share, flags if the actor is one of the Jonas brothers, extracts main-cast season count, checks if they appear in all seasons, and calculates a weighted priority score, then orders by that score. It maps to columns: Portrayed by (actor), Character, # of episodes, Main cast seasons, Recurring cast seasons. Draft question: ask for a ranked list including actor, character, episode count, episode share, Jonas-trio membership, main-cast seasons count, recurring-all-seasons flag, and the composite priority score. This matches the SQL's outputs and ordering.",persona,"An Ethical AI Voice Model Curator who evaluates which TV characters/actors to approach for licensing synthetic voice models of Jonas L.A. characters. Goals: Determine which characters/actors are most prominent (by episode count) to prioritize rights negotiations and budget allocation. Identify which actors are members of the Jonas Brothers trio so ensemble licensing can be bundled or negotiated together. Assess season continuity/recurrence for each character to estimate long-term fan recognition and potential value of a synthetic voice model. Example Queries: SELECT ""Portrayed by"", ""Character"", ""# of episodes"" FROM ""table_1_12441518_1"" ORDER BY ""# of episodes"" DESC; SELECT ""Portrayed by"", ""# of episodes"", (""# of episodes"" * 1.0 / (SELECT SUM(""# of episodes"") FROM ""table_1_12441518_1"")) AS episode_share FROM ""table_1_12441518_1""; SELECT ""Character"", ""Portrayed by"", ""Main cast seasons"", ""Recurring cast seasons"" FROM ""table_1_12441518_1"" WHERE ""Portrayed by"" IN ('Nick Jonas', 'Joe Jonas', 'Kevin Jonas');",reward,,
"List up to 6 tracks that have Seating >= 75000 and Year Acquired [A ] <= 1999, including for each the Track Name, Location, Seating, Seats per operational year = (Seating * 1.0) / (2025 - Year Opened), Years until acquisition = (Year Acquired [A ] - Year Opened), Years since acquisition = (2025 - Year Acquired [A ]), and Priority score = (Seating / 1000.0) + (2025 - Year Acquired [A ]) * 0.5 + (Year Acquired [A ] - Year Opened) * 0.2?","
SELECT
  `Track Name`,
  `Location`,
  `Seating`,
  (`Seating` * 1.0) / (2025 - `Year Opened`) `Seats per operational year`,
  (`Year Acquired [A ]` - `Year Opened`) `Years until acquisition`,
  (2025 - `Year Acquired [A ]`) `Years since acquisition`,
  ((`Seating` / 1000.0) + (2025 - `Year Acquired [A ]`) * 0.5 + (`Year Acquired [A ]` - `Year Opened`) * 0.2) `Priority score`
FROM `table_1_1245148_1`
WHERE `Seating` >= 75000 AND `Year Acquired [A ]` <= 1999
LIMIT 6;
","
SELECT
  col0,
  col1,
  col3,
  (col3 * 1.0) / (2025 - col4) `Seats per operational year`,
  (col5 - col4) `Years until acquisition`,
  (2025 - col5) `Years since acquisition`,
  ((col3 / 1000.0) + (2025 - col5) * 0.5 + (col5 - col4) * 0.2) `Priority score`
FROM `table_1_1245148_1`
WHERE col3 >= 75000 AND col5 <= 1999
LIMIT 6;
","[('auto club speedway', 'fontana, ca', 92000.0, 3285.714285714286, 2.0, 26.0, 105.4), ('daytona international speedway', 'daytona beach, fl', 168000.0, 2545.4545454545455, 0.0, 66.0, 201.0), ('michigan international speedway', 'brooklyn, mi', 137243.0, 2407.7719298245615, 31.0, 26.0, 156.44299999999998), ('phoenix international raceway', 'avondale, az', 76812.0, 1259.2131147540983, 33.0, 28.0, 97.41199999999999), ('richmond international raceway', 'richmond, va', 107097.0, 1355.6582278481012, 53.0, 26.0, 130.697), ('talladega superspeedway', 'talladega, al', 175000.0, 3125.0, 0.0, 56.0, 203.0)]",table_1_1245148_1,"1) The SQL computes per-year and acquisition-derived metrics for tracks meeting seating and acquisition-year criteria and restricts the output to six rows. 2) Use the table fields Track Name, Location, Seating, Year Opened, Year Acquired [A ] and the same arithmetic expressions. 3) Formulate a concise question that requests each column and each calculation and mentions the filters and the 6-row limit. 4) Check that every expression from the SELECT and WHERE clauses plus the LIMIT is included.",reserved,5,reward,,
"For reserve-setting purposes, calculate each variant's collectible score (V8 +2, Evoluzione +1, plus top speed/100) and the suggested reserve index (that score × total production ÷ variant production) and present them with the variant name and units produced?","
WITH `total` AS (
  SELECT SUM(`Units Produced`) AS `total_units`
  FROM `table_1_1245350_1`
)
SELECT
  `Quattroporte IV`,
  `Units Produced`,
  `Production Period`,
  `Engine Capacity`,
  `Power`,
  `Max Speed`,
  CAST(TRIM(SUBSTR(`Max Speed`, 1, INSTR(`Max Speed`, 'km/h') - 1)) AS INTEGER) AS `Top Speed (km/h)`,
  CASE WHEN `Quattroporte IV` LIKE '%Evoluzione%' THEN 'Evoluzione' ELSE 'Standard' END AS `Variant Group`,
  CASE WHEN `Quattroporte IV` LIKE '%V8%' THEN 'V8' WHEN `Quattroporte IV` LIKE '%V6%' THEN 'V6' ELSE 'Other' END AS `Engine Family`,
  ROUND(`Units Produced` * 100.0 / `total`.`total_units`, 2) AS `Percent of Total (%)`,
  RANK() OVER (ORDER BY `Units Produced` ASC) AS `Rarity Rank`,
  ROUND(
    (
      (CASE WHEN `Quattroporte IV` LIKE '%V8%' THEN 2.0 ELSE 0.0 END) +
      (CASE WHEN `Quattroporte IV` LIKE '%Evoluzione%' THEN 1.0 ELSE 0.0 END) +
      (CAST(TRIM(SUBSTR(`Max Speed`, 1, INSTR(`Max Speed`, 'km/h') - 1)) AS INTEGER) / 100.0)
    ), 2
  ) AS `Collectible Score`,
  ROUND(
    (
      (
        (CASE WHEN `Quattroporte IV` LIKE '%V8%' THEN 2.0 ELSE 0.0 END) +
        (CASE WHEN `Quattroporte IV` LIKE '%Evoluzione%' THEN 1.0 ELSE 0.0 END) +
        (CAST(TRIM(SUBSTR(`Max Speed`, 1, INSTR(`Max Speed`, 'km/h') - 1)) AS INTEGER) / 100.0)
      ) * (`total`.`total_units` / `Units Produced`)
    ), 2
  ) AS `Suggested Reserve Index`
FROM `table_1_1245350_1`, `total`
ORDER BY `Collectible Score` DESC, `Rarity Rank` ASC;
","
WITH `total` AS (
  SELECT SUM(col1) AS `total_units`
  FROM `table_1_1245350_1`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  CAST(TRIM(SUBSTR(col5, 1, INSTR(col5, 'km/h') - 1)) AS INTEGER) AS `Top Speed (km/h)`,
  CASE WHEN col0 LIKE '%Evoluzione%' THEN 'Evoluzione' ELSE 'Standard' END AS `Variant Group`,
  CASE WHEN col0 LIKE '%V8%' THEN 'V8' WHEN col0 LIKE '%V6%' THEN 'V6' ELSE 'Other' END AS `Engine Family`,
  ROUND(col1 * 100.0 / `total`.`total_units`, 2) AS `Percent of Total (%)`,
  RANK() OVER (ORDER BY col1 ASC) AS `Rarity Rank`,
  ROUND(
    (
      (CASE WHEN col0 LIKE '%V8%' THEN 2.0 ELSE 0.0 END) +
      (CASE WHEN col0 LIKE '%Evoluzione%' THEN 1.0 ELSE 0.0 END) +
      (CAST(TRIM(SUBSTR(col5, 1, INSTR(col5, 'km/h') - 1)) AS INTEGER) / 100.0)
    ), 2
  ) AS `Collectible Score`,
  ROUND(
    (
      (
        (CASE WHEN col0 LIKE '%V8%' THEN 2.0 ELSE 0.0 END) +
        (CASE WHEN col0 LIKE '%Evoluzione%' THEN 1.0 ELSE 0.0 END) +
        (CAST(TRIM(SUBSTR(col5, 1, INSTR(col5, 'km/h') - 1)) AS INTEGER) / 100.0)
      ) * (`total`.`total_units` / col1)
    ), 2
  ) AS `Suggested Reserve Index`
FROM `table_1_1245350_1`, `total`
ORDER BY `Collectible Score` DESC, `Rarity Rank` ASC;
","[('3.2i v8 evoluzione', 340.0, '1998–2001', '3,217 cc', '335ps (246kw) @ 6400rpm', '270km/h (168mph)', 270, 'Evoluzione', 'V8', 14.17, 3, 5.7, 40.24), ('3.2i v8 32v', 415.0, '1996–1998', '3,217 cc', '335ps (246kw) @ 6400rpm', '270km/h (168mph)', 270, 'Standard', 'V8', 17.29, 4, 4.7, 27.18), ('2.8i v6 evoluzione', 190.0, '1998–2001', '2,790 cc', '284ps (209kw) @ 6000rpm', '255km/h (158mph)', 255, 'Evoluzione', 'V6', 7.92, 1, 3.55, 44.84), ('2.0i v6 evoluzione', 200.0, '1998–2001', '1,996 cc', '287ps (211kw) @ 6500rpm', '255km/h (158mph)', 255, 'Evoluzione', 'V6', 8.33, 2, 3.55, 42.6), ('2.0i v6 24v', 587.0, '1994–1998', '1,996 cc', '287ps (211kw) @ 6500rpm', '255km/h (158mph)', 255, 'Standard', 'V6', 24.46, 5, 2.55, 10.43), ('2.8i v6 24v', 668.0, '1994–1998', '2,790 cc', '284ps (209kw) @ 6000rpm', '255km/h (158mph)', 255, 'Standard', 'V6', 27.83, 6, 2.55, 9.16)]",table_1_1245350_1,I routinely translate production rarity and performance into reserve guidance and will reference the reserve index but avoid raw SQL terms. The query computes a collectible score (favoring V8 and Evoluzione and higher top speed) and multiplies it by total production over variant production to produce a suggested reserve index. The schema supplies units produced and max speed that feed into both those calculations. Draft: ask for the collectible score and suggested reserve index alongside units produced and total production to inform reserve pricing. Validate: this asks only for fields and derived metrics the SQL provides and nothing beyond it.,persona,"Auction house valuation analyst specializing in classic Italian performance sedans who uses production and performance data to assess rarity and inform reserve pricing and catalog descriptions. Goals: Determine rarity and total production numbers for each Quattroporte IV variant to support provenance and valuation. Identify the highest-performance / most collectible variants (e.g., V8, Evoluzione) based on engine and top speed. Produce variant-level summaries (standard vs Evoluzione, V6 vs V8) for lot descriptions and pricing guidance. Example Queries: /* 1) Find the rarest (lowest production) Quattroporte IV variant */
SELECT ""Quattroporte IV"", ""Units Produced"", ""Production Period""
FROM table_1_1245350_1
ORDER BY ""Units Produced"" ASC
LIMIT 1; /* 2) Total units produced across all Quattroporte IV variants */
SELECT SUM(""Units Produced"") AS total_units_produced
FROM table_1_1245350_1; /* 3) Compare production totals for Standard vs Evoluzione (and highlight V6 vs V8) */
SELECT
  CASE WHEN ""Quattroporte IV"" LIKE '%Evoluzione%' THEN 'Evoluzione' ELSE 'Standard' END AS variant_group,
  CASE WHEN ""Quattroporte IV"" LIKE '%V8%' THEN 'V8' WHEN ""Quattroporte IV"" LIKE '%V6%' THEN 'V6' ELSE 'Other' END AS engine_family,
  SUM(""Units Produced"") AS units_produced
FROM table_1_1245350_1
GROUP BY variant_group, engine_family
ORDER BY variant_group, engine_family;",reward,,
Which clubs are top offensively and defensively?,"
WITH parsed AS (
  SELECT
    `Club`,
    `Goals For`,
    `Goals Against`,
    CAST(SUBSTR(`Goals For Avg.`, 1, INSTR(`Goals For Avg.`, ' ')-1) AS REAL) AS gf_avg,
    CAST(SUBSTR(`Goals Against Avg.`, 1, INSTR(`Goals Against Avg.`, ' ')-1) AS REAL) AS ga_avg,
    CAST(REPLACE(REPLACE(REPLACE(REPLACE(
      SUBSTR(`Goals For Avg.`, INSTR(`Goals For Avg.`, '(')+1, INSTR(`Goals For Avg.`, ')') - INSTR(`Goals For Avg.`, '(') -1)
    ,'st',''),'nd',''),'rd',''),'th','') AS INTEGER) AS gf_rank,
    CAST(REPLACE(REPLACE(REPLACE(REPLACE(
      SUBSTR(`Goals Against Avg.`, INSTR(`Goals Against Avg.`, '(')+1, INSTR(`Goals Against Avg.`, ')') - INSTR(`Goals Against Avg.`, '(') -1)
    ,'st',''),'nd',''),'rd',''),'th','') AS INTEGER) AS ga_rank,
    (`Goals For` - `Goals Against`) AS goal_difference
  FROM table_1_1246208_5
)
SELECT
  `Club`,
  `Goals For`,
  `Goals Against`,
  gf_avg AS `Goals For Avg. (num)`,
  ga_avg AS `Goals Against Avg. (num)`,
  gf_rank AS `Goals For Rank`,
  ga_rank AS `Goals Against Rank`,
  goal_difference AS `Goal Differential`,
  CASE WHEN goal_difference > 0 THEN 'Yes' ELSE 'No' END AS `Positive Goal Differential`,
  CASE WHEN ga_avg > 1.40 THEN 'Yes' ELSE 'No' END AS `Concedes Frequently (ga_avg>1.40)`,
  CASE WHEN gf_rank <= 3 THEN 'Yes' ELSE 'No' END AS `Top Offensive (Top 3 by GF Avg Rank)`,
  CASE WHEN ga_rank <= 3 THEN 'Yes' ELSE 'No' END AS `Top Defensive (Top 3 by GA Avg Rank)`
FROM parsed
ORDER BY goal_difference DESC, gf_avg DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col2,
    col4,
    CAST(SUBSTR(col3, 1, INSTR(col3, ' ')-1) AS REAL) AS gf_avg,
    CAST(SUBSTR(col5, 1, INSTR(col5, ' ')-1) AS REAL) AS ga_avg,
    CAST(REPLACE(REPLACE(REPLACE(REPLACE(
      SUBSTR(col3, INSTR(col3, '(')+1, INSTR(col3, ')') - INSTR(col3, '(') -1)
    ,'st',''),'nd',''),'rd',''),'th','') AS INTEGER) AS gf_rank,
    CAST(REPLACE(REPLACE(REPLACE(REPLACE(
      SUBSTR(col5, INSTR(col5, '(')+1, INSTR(col5, ')') - INSTR(col5, '(') -1)
    ,'st',''),'nd',''),'rd',''),'th','') AS INTEGER) AS ga_rank,
    (col2 - col4) AS goal_difference
  FROM table_1_1246208_5
)
SELECT
  col0,
  col2,
  col4,
  gf_avg AS `Goals For Avg. (num)`,
  ga_avg AS `Goals Against Avg. (num)`,
  gf_rank AS `Goals For Rank`,
  ga_rank AS `Goals Against Rank`,
  goal_difference AS `Goal Differential`,
  CASE WHEN goal_difference > 0 THEN 'Yes' ELSE 'No' END AS `Positive Goal Differential`,
  CASE WHEN ga_avg > 1.40 THEN 'Yes' ELSE 'No' END AS `Concedes Frequently (ga_avg>1.40)`,
  CASE WHEN gf_rank <= 3 THEN 'Yes' ELSE 'No' END AS `Top Offensive (Top 3 by GF Avg Rank)`,
  CASE WHEN ga_rank <= 3 THEN 'Yes' ELSE 'No' END AS `Top Defensive (Top 3 by GA Avg Rank)`
FROM parsed
ORDER BY goal_difference DESC, gf_avg DESC;
","[('columbus crew', 40.0, 32.0, 1.33, 1.07, 6, 2, 8.0, 'Yes', 'No', 'No', 'Yes'), ('kansas city wizards', 38.0, 30.0, 1.27, 1.0, 7, 1, 8.0, 'Yes', 'No', 'No', 'Yes'), ('san jose earthquakes', 41.0, 35.0, 1.37, 1.17, 5, 4, 6.0, 'Yes', 'No', 'No', 'No'), ('los angeles galaxy', 42.0, 40.0, 1.4, 1.33, 3, 5, 2.0, 'Yes', 'No', 'Yes', 'No'), ('d.c. united', 43.0, 42.0, 1.43, 1.4, 2, 6, 1.0, 'Yes', 'No', 'Yes', 'No'), ('new england revolution', 42.0, 43.0, 1.4, 1.43, 4, 7, -1.0, 'No', 'Yes', 'No', 'No'), ('metrostars', 47.0, 49.0, 1.57, 1.63, 1, 10, -2.0, 'No', 'Yes', 'Yes', 'No'), ('colorado rapids', 29.0, 32.0, 0.97, 1.07, 10, 2, -3.0, 'No', 'No', 'No', 'Yes'), ('chicago fire', 36.0, 44.0, 1.2, 1.47, 8, 8, -8.0, 'No', 'Yes', 'No', 'No'), ('dallas burn', 34.0, 45.0, 1.13, 1.5, 9, 9, -11.0, 'No', 'Yes', 'No', 'No')]",table_1_1246208_5,"STEP 1: Parse the SQL intent — compute numeric Goals For/Against averages and their ranks, compute goal_difference (Goals For - Goals Against), produce Yes/No flags for Positive Goal Differential, Concedes Frequently (ga_avg>1.40), Top Offensive (gf_rank<=3), Top Defensive (ga_rank<=3), and return all clubs ordered by goal_difference DESC, gf_avg DESC. STEP 2: Choose ambiguity type — scope ambiguity fits: the phrase 'top offensively and defensively' can refer to different scopes (both categories jointly, either category, or separate lists). This fits because the query produces separate Top Offensive and Top Defensive flags but does not filter or clarify a combined interpretation. STEP 3: Draft the question — ""Which clubs are top offensively and defensively?"" STEP 4: Explain the ambiguity — in the original query each club is labeled Yes/No for Top Offensive and Top Defensive and all clubs are returned; one interpretation of the question asks for clubs that are top in both categories (intersection), another asks for clubs that are top in at least one category (union), and another asks simply to list the top offensive clubs and top defensive clubs separately; the SQL's output (flags per club, sorted by goal differential) is consistent with any of these interpretations but does not resolve which scope is intended.",persona,"Performance Analyst for an MLS club who monitors team attacking and defensive metrics to inform training, scouting, and match preparation. They would use this dataset to compare clubs' goals scored/conceded and per-game averages to identify strengths, weaknesses, and tactical matchups. Goals: Quantify each opponent's offensive and defensive strengths (total goals and per-game averages) to prepare game plans. Identify teams with positive goal differential and those conceding frequently to prioritize scouting and tactical focus. Produce shortlists of top offensive teams and top defensive teams (by goals-against average/rank) for briefing coaches and analysts. Example Queries: /* Rank teams by goal differential (Goals For - Goals Against) */
SELECT
  ""Club"",
  ""Goals For"",
  ""Goals Against"",
  (""Goals For"" - ""Goals Against"") AS goal_difference
FROM table_1_1246208_5
ORDER BY goal_difference DESC; /* List teams with a goals-for average above 1.35 (extract numeric part from 'Goals For Avg.') */
SELECT
  ""Club"",
  ""Goals For"",
  ""Goals For Avg.""
FROM table_1_1246208_5
WHERE CAST(SUBSTR(""Goals For Avg."", 1, INSTR(""Goals For Avg."", ' ')-1) AS REAL) > 1.35
ORDER BY CAST(SUBSTR(""Goals For Avg."", 1, INSTR(""Goals For Avg."", ' ')-1) AS REAL) DESC; /* Select clubs that rank in the top 3 for fewest goals conceded using the textual rank in 'Goals Against Avg.' */
SELECT
  ""Club"",
  ""Goals Against"",
  ""Goals Against Avg.""
FROM table_1_1246208_5
WHERE ""Goals Against Avg."" LIKE '%(1st)%'
   OR ""Goals Against Avg."" LIKE '%(2nd)%'
   OR ""Goals Against Avg."" LIKE '%(3rd)%'
ORDER BY CAST(SUBSTR(""Goals Against Avg."", 1, INSTR(""Goals Against Avg."", ' ')-1) AS REAL);",reward,,"type: Scope ambiguity | explanation: The phrase 'top offensively and defensively' could mean clubs that are top in both categories (intersection), clubs that are top in either category (union), or a request to list top offensive clubs and top defensive clubs separately; the SQL returns per-club Top Offensive and Top Defensive flags (and all clubs), so it supports any of these readings but doesn't pick one."
"Grouped by County and excluding County 'Østfold', return County plus Total Population (SUM(Population)), Total Area km² (SUM(Area km²)), Weighted Density (ROUND(SUM(Population) * 1.0 / SUM(Area km²), 2)), Pop Above 200 (SUM((Density Population per km² > 200) * Population)), and Pct Pop Above 200 (ROUND(100.0 * SUM((Density Population per km² > 200) * Population) / SUM(Population), 2)) for counties where Pct Pop Above 200 > 50, limited to 5 counties?","
SELECT DISTINCT
  `County`,
  SUM(`Population`) `Total Population`,
  SUM(`Area km²`) `Total Area km²`,
  ROUND(SUM(`Population`) * 1.0 / SUM(`Area km²`),2) `Weighted Density`,
  SUM((`Density Population per km²`>200) * `Population`) `Pop Above 200`,
  ROUND(100.0 * SUM((`Density Population per km²`>200) * `Population`) / SUM(`Population`),2) `Pct Pop Above 200`
FROM `table_1_1246665_1`
WHERE `County` != '`Østfold`'
GROUP BY `County`
HAVING ROUND(100.0 * SUM((`Density Population per km²`>200) * `Population`) / SUM(`Population`),2) > 50
LIMIT 5;
","
SELECT DISTINCT
  col5,
  SUM(col1) `Total Population`,
  SUM(col2) `Total Area km²`,
  ROUND(SUM(col1) * 1.0 / SUM(col2),2) `Weighted Density`,
  SUM((col3>200) * col1) `Pop Above 200`,
  ROUND(100.0 * SUM((col3>200) * col1) / SUM(col1),2) `Pct Pop Above 200`
FROM `table_1_1246665_1`
WHERE col5 != '`Østfold`'
GROUP BY col5
HAVING ROUND(100.0 * SUM((col3>200) * col1) / SUM(col1),2) > 50
LIMIT 5;
","[('akershus', 537799.0, 4571.0, 117.65, 305274.0, 56.76), ('oslo', 590041.0, 426.0, 1385.07, 590041.0, 100.0)]",table_1_1246665_1,"Parse intent: group rows by County (excluding Østfold), sum population and area, compute weighted density and population/percentage living in places with density>200, filter to counties where that percentage exceeds 50 and cap results at 5. Map schema: reference the table's Population, Area km², Density Population per km² and County columns and the specific aggregations and rounding. Draft the question: ask for those aggregated fields and the specified predicates and limit. Validate: question mirrors SUMs, ROUND calculations, boolean density>200 multiplier, HAVING >50, and LIMIT 5.",reserved,8,reward,,
"List sectors sorted by population density (highest first) showing area, 2012 population, percentage change 2002–2012, density and a 'Rapid Growth Small Area' yes/no flag for growth over 75% with area under 100 km², and also report district total population, district average density, and district total area?","
SELECT
  `Sector`,
  `Area in sqkm`,
  `Population August 15, 2012`,
  `Population Change 2002-2012 (%)`,
  `Population Density 2012 (km 2 )`,
  ROW_NUMBER() OVER (ORDER BY `Population Density 2012 (km 2 )` DESC) AS `Density Rank`,
  CASE WHEN CAST(`Population Change 2002-2012 (%)` AS real) > 75 AND `Area in sqkm` < 100 THEN 'Yes' ELSE 'No' END AS `Rapid Growth Small Area`,
  (SELECT SUM(`Population August 15, 2012`) FROM `table_1_12496904_1`) AS `District Total Population`,
  (SELECT AVG(`Population Density 2012 (km 2 )`) FROM `table_1_12496904_1`) AS `District Average Density`,
  (SELECT SUM(`Area in sqkm`) FROM `table_1_12496904_1`) AS `District Total Area`
FROM `table_1_12496904_1`
ORDER BY `Density Rank`;
","
SELECT
  col1,
  col2,
  col3,
  col5,
  col6,
  ROW_NUMBER() OVER (ORDER BY col6 DESC) AS `Density Rank`,
  CASE WHEN CAST(col5 AS real) > 75 AND col2 < 100 THEN 'Yes' ELSE 'No' END AS `Rapid Growth Small Area`,
  (SELECT SUM(col3) FROM `table_1_12496904_1`) AS `District Total Population`,
  (SELECT AVG(col6) FROM `table_1_12496904_1`) AS `District Average Density`,
  (SELECT SUM(col2) FROM `table_1_12496904_1`) AS `District Total Area`
FROM `table_1_12496904_1`
ORDER BY `Density Rank`;
","[('rukomo', 58.0, 34377.0, '64.1', 588.0, 1, 'No', 466944.0, 344.0, 1928.0), ('mimuli', 48.0, 27366.0, '21.9', 573.0, 2, 'No', 466944.0, 344.0, 1928.0), ('gatunda', 52.0, 27879.0, '41.4', 535.0, 3, 'No', 466944.0, 344.0, 1928.0), ('karama', 53.0, 26727.0, '35.5', 499.0, 4, 'No', 466944.0, 344.0, 1928.0), ('katabagemu', 98.0, 34651.0, '56.8', 354.0, 5, 'No', 466944.0, 344.0, 1928.0), ('mukama', 64.0, 21819.0, '21.4', 339.0, 6, 'No', 466944.0, 344.0, 1928.0), ('musheli', 96.0, 32403.0, '119.8', 338.0, 7, 'Yes', 466944.0, 344.0, 1928.0), ('nyagatare', 164.0, 52125.0, '167.7', 317.0, 8, 'No', 466944.0, 344.0, 1928.0), ('tabagwe', 106.0, 33322.0, '79.6', 313.0, 9, 'No', 466944.0, 344.0, 1928.0), ('matimba', 79.0, 24168.0, '79.3', 307.0, 10, 'Yes', 466944.0, 344.0, 1928.0), ('kiyombe', 69.0, 17061.0, '3.5', 247.0, 11, 'No', 466944.0, 344.0, 1928.0), ('rwimiyaga', 309.0, 58847.0, '250.2', 190.0, 12, 'No', 466944.0, 344.0, 1928.0), ('rwempasha', 169.0, 19328.0, '69.1', 115.0, 13, 'No', 466944.0, 344.0, 1928.0), ('karangazi', 563.0, 56871.0, '167.8', 101.0, 14, 'No', 466944.0, 344.0, 1928.0)]",table_1_12496904_1,"As someone prioritising services I might ask for a ranked list with a simple rapid-growth flag and district summary. The SQL orders sectors by population density descending, computes a density rank, marks sectors with >75% growth and area <100 km² as 'Yes', and adds district total population, average density, and total area. The columns used are Sector, Area in sqkm, Population August 15, 2012, Population Change 2002-2012 (%), and Population Density 2012 (km 2 ), plus the aggregates. List sectors sorted by population density (highest first) showing area, 2012 population, percentage change 2002–2012, density and a 'Rapid Growth Small Area' yes/no flag for growth over 75% with area under 100 km², and also report district total population, district average density, and district total area? This keeps to the data the query provides and its ordering.",persona,"Rural Infrastructure Planner at the Nyagatare District Council responsible for prioritizing roads, water, and school investments using sector-level population and density data to target limited resources effectively. Goals: Identify sectors with the highest population density to prioritize basic services (water, sanitation, schools). Spot rapidly growing sectors (2002–2012) with small land area where infrastructure capacity may be strained. Estimate overall district population and average density to inform budget allocation and long-term planning. Example Queries: SELECT ""Sector"", ""Area in sqkm"", ""Population August 15, 2012"", ""Population Density 2012 (km 2 )"" FROM table_1_12496904_1 ORDER BY ""Population Density 2012 (km 2 )"" DESC LIMIT 5; SELECT ""Sector"", ""Area in sqkm"", ""Population August 15, 2012"", ""Population Change 2002-2012 (%)"" FROM table_1_12496904_1 WHERE CAST(""Population Change 2002-2012 (%)"" AS real) > 75 AND ""Area in sqkm"" < 100 ORDER BY CAST(""Population Change 2002-2012 (%)"" AS real) DESC; SELECT SUM(""Population August 15, 2012"") AS total_population, AVG(""Population Density 2012 (km 2 )"") AS avg_density, SUM(""Area in sqkm"") AS total_area FROM table_1_12496904_1;",reward,,
"For players with Games Played greater than 20, who are the five players with the smallest GA per 90 (GA per 90 = ROUND((Goals Against * 1.0) / (Minutes / 90.0), 2)), and what is each Player's GA per 90 and Win Diff calculated as (Wins - Loses)?","
SELECT `Player`, ROUND((`Goals Against` * 1.0) / (`Minutes` / 90.0), 2) AS `GA per 90`, (`Wins` - `Loses`) AS `Win Diff`
FROM `table_1_1255110_7`
WHERE `Games Played` > 20
GROUP BY `Player`
ORDER BY `GA per 90`
LIMIT 5;
","
SELECT col1, ROUND((col5 * 1.0) / (col4 / 90.0), 2) AS `GA per 90`, (col7 - col8) AS `Win Diff`
FROM `table_1_1255110_7`
WHERE col3 > 20
GROUP BY col1
ORDER BY `GA per 90`
LIMIT 5;
","[('brad friedel', 1.21, -1.0), ('walter zenga', 1.27, 8.0), ('marcus hahnemann', 1.54, 3.0), ('mike ammann', 1.56, 13.0), ('mark dodd', 1.6, -2.0)]",table_1_1255110_7,"Parse intent: return Player plus two derived metrics (rounded GA per 90 and Wins-Loses), filtered by Games Played > 20, grouped by Player, sorted by GA per 90 ascending, limited to 5. Map schema: use Player, Goals Against, Minutes, Wins, Loses, Games Played from the table. Draft: request the five players with smallest GA per 90 including the exact formula and Win Diff. Validate: question contains formula, rounding, Win Diff definition, filter, ordering, and limit.",reserved,9,reward,,
"Calculate for the Rockhampton Region table (using the rows for Year = 1933 and Year = 2001, and only when the 2001 Total Region > 0) the following: Rockhampton % change 1933-2001 = (Rockhampton(2001) − Rockhampton(1933)) × 100.0 / Rockhampton(1933) (NULL/undefined if Rockhampton(1933)=0), Rockhampton avg annual change = (Rockhampton(2001) − Rockhampton(1933)) / (2001 − 1933), Livingstone % change 1933-2001 and Livingstone avg annual change with the same formulas and NULL-if-1933=0 rule, Fitzroy % change 1933-2001 and Fitzroy avg annual change with the same formulas and NULL-if-1933=0 rule, Mt Morgan % change 1933-2001 and Mt Morgan avg annual change with the same formulas and NULL-if-1933=0 rule, and also return the 2001 Total Region value and the years 1933 and 2001?","
SELECT
( MAX(t2001.`Rockhampton`) - MAX(t1933.`Rockhampton`) ) * 100.0 / NULLIF(MAX(t1933.`Rockhampton`),0) `Rockhampton % change 1933-2001`,
( (MAX(t2001.`Rockhampton`) - MAX(t1933.`Rockhampton`)) / (2001-1933) ) `Rockhampton avg annual change`,
( MAX(t2001.`Livingstone`) - MAX(t1933.`Livingstone`) ) * 100.0 / NULLIF(MAX(t1933.`Livingstone`),0) `Livingstone % change 1933-2001`,
( (MAX(t2001.`Livingstone`) - MAX(t1933.`Livingstone`)) / (2001-1933) ) `Livingstone avg annual change`,
( MAX(t2001.`Fitzroy`) - MAX(t1933.`Fitzroy`) ) * 100.0 / NULLIF(MAX(t1933.`Fitzroy`),0) `Fitzroy % change 1933-2001`,
( (MAX(t2001.`Fitzroy`) - MAX(t1933.`Fitzroy`)) / (2001-1933) ) `Fitzroy avg annual change`,
( MAX(t2001.`Mt Morgan`) - MAX(t1933.`Mt Morgan`) ) * 100.0 / NULLIF(MAX(t1933.`Mt Morgan`),0) `Mt Morgan % change 1933-2001`,
( (MAX(t2001.`Mt Morgan`) - MAX(t1933.`Mt Morgan`)) / (2001-1933) ) `Mt Morgan avg annual change`,
MAX(t2001.`Total Region`) `2001 Total Region`,
1933 `1933`,
2001 `2001`
FROM `table_1_12570207_1` t1933, `table_1_12570207_1` t2001
WHERE t1933.`Year` = 1933 AND t2001.`Year` = 2001 AND t2001.`Total Region` > 0
GROUP BY 1933
HAVING MAX(t2001.`Total Region`) > 0
LIMIT 1;
","SELECT
( MAX(t2001.col2) - MAX(t1933.col2) ) * 100.0 / NULLIF(MAX(t1933.col2),0) `Rockhampton % change 1933-2001`,
( (MAX(t2001.col2) - MAX(t1933.col2)) / (2001-1933) ) `Rockhampton avg annual change`,
( MAX(t2001.col3) - MAX(t1933.col3) ) * 100.0 / NULLIF(MAX(t1933.col3),0) `Livingstone % change 1933-2001`,
( (MAX(t2001.col3) - MAX(t1933.col3)) / (2001-1933) ) `Livingstone avg annual change`,
( MAX(t2001.col4) - MAX(t1933.col4) ) * 100.0 / NULLIF(MAX(t1933.col4),0) `Fitzroy % change 1933-2001`,
( (MAX(t2001.col4) - MAX(t1933.col4)) / (2001-1933) ) `Fitzroy avg annual change`,
( MAX(t2001.col5) - MAX(t1933.col5) ) * 100.0 / NULLIF(MAX(t1933.col5),0) `Mt Morgan % change 1933-2001`,
( (MAX(t2001.col5) - MAX(t1933.col5)) / (2001-1933) ) `Mt Morgan avg annual change`,
MAX(t2001.col1) `2001 Total Region`,
1933 `1933`,
2001 `2001`
FROM `table_1_12570207_1` t1933, `table_1_12570207_1` t2001
WHERE t1933.col0 = 1933 AND t2001.col0 = 2001 AND t2001.col1 > 0
GROUP BY t1933.col0
HAVING MAX(t2001.col1) > 0
LIMIT 1;","[(98.7878375157479, 426.6617647058824, 317.4443757725587, 302.13235294117646, 124.45958646616542, 77.8970588235294, -36.96639418710264, -23.941176470588236, 97728.0, 1933, 2001)]",table_1_12570207_1,"Parse intent: compute percent change and mean annual change from 1933 to 2001 for four subregions and include the 2001 Total Region, filtering out zero 2001 totals. Map schema: the table's Year and population columns correspond to the values used in formulas. Draft: form a question that lists each required calculation with exact formulas and division-by-zero handling, plus the 2001 Total Region and the literal years 1933 and 2001. Validate: question must explicitly mention every column and calculation appearing in the query and the >0 condition on 2001 Total Region.",reserved,9,reward,,
"From the table (after CROSS JOIN with itself), for each value of 'Single / Pack' reported as 'Pack', return COUNT(*) AS 'SongCount', MIN(Year) AS 'EarliestYear', MAX(Year) AS 'LatestYear', and the difference (MAX(Year) - MIN(Year)) AS 'YearRange' including only rows where Year > 1970 AND Year <= 2008, keeping groups with COUNT(*) > 1 and limiting the output to 20 rows.","
SELECT `Single / Pack` AS `Pack`, COUNT(*) AS `SongCount`, MIN(`Year`) AS `EarliestYear`, MAX(`Year`) AS `LatestYear`, (MAX(`Year`) - MIN(`Year`)) AS `YearRange` FROM `table_1_12588029_3` CROSS JOIN `table_1_12588029_3` AS `t2` WHERE `Year` > 1970 AND `Year` <= 2008 GROUP BY `Single / Pack` HAVING COUNT(*) > 1 LIMIT 20;
","SELECT col5, COUNT(*) AS `SongCount`, MIN(col0) `EarliestYear` FROM `table_1_12588029_3` t WHERE t.col0 > 1970 AND t.col0 <= 2008 GROUP BY col5 HAVING `SongCount` > 1 LIMIT 20;","[('boss battle pack', 2, 2007.0), ('classic rock track pack', 3, 1976.0), ('coldplay track pack', 3, 2000.0), ('companion pack', 2, 2007.0), ('death magnetic', 10, 2008.0), ('def leppard track pack', 3, 1983.0), ('dragonforce track pack', 3, 2006.0), ('dropkick murphys track pack', 3, 2007.0), ('foo fighters pack', 3, 1995.0), ('guitar virtuoso track pack', 3, 1987.0), ('isle of wight festival track pack', 3, 2004.0), ('modern metal track pack', 3, 2006.0), ('motörhead track pack', 3, 2008.0), ('muse track pack', 3, 2003.0), ('no doubt track pack', 3, 1996.0), ('single', 9, 1980.0), ('velvet revolver pack', 3, 2004.0), ('warner / reprise track pack', 3, 2006.0)]",table_1_12588029_3,"1) Parse SQL intent: produce per-pack summary statistics (count, min year, max year, and their difference) for years after 1970 up to 2008, using a cross join, and filter to packs with more than one song and cap results at 20. 2) Map schema semantics: 'Single / Pack' is the grouping column; Year supplies min/max. 3) Draft the question: explicitly request Pack, SongCount, EarliestYear, LatestYear, YearRange with the WHERE, GROUP BY, HAVING and LIMIT clauses and note the CROSS JOIN. 4) Validate: ensure each selected alias and calculation appears in the natural language.",reserved,11,reward,,
"For each Builder (grouped by Builder) who built ships with Laid down = 1862 and who has more than zero ships and at least one Renamed entry not equal to 'Not Applicable', what are the Builder name, Total Ships (COUNT(*)), Renamed Count (count where Renamed != 'Not Applicable'), the counts for Ajax, Canonicus, Catawba, Mahopac, Manhattan, Oneota, Saugus and Tecumseh, a comma-separated list of Ships, the Earliest Laid down (MIN Laid down), the Latest Launched (MAX Launched), and a Not Applicable column equal to 0, ordered by Renamed Count descending and limited to the top 10?","
SELECT `Builder` AS `Builder`, COUNT(*) AS `Total Ships`, SUM(CASE WHEN `Renamed` != 'Not Applicable' THEN 1 ELSE 0 END) AS `Renamed Count`, SUM(CASE WHEN `Ship` = 'Ajax' THEN 1 ELSE 0 END) AS `Ajax`, SUM(CASE WHEN `Ship` = 'Canonicus' THEN 1 ELSE 0 END) AS `Canonicus`, SUM(CASE WHEN `Ship` = 'Catawba' THEN 1 ELSE 0 END) AS `Catawba`, SUM(CASE WHEN `Ship` = 'Mahopac' THEN 1 ELSE 0 END) AS `Mahopac`, SUM(CASE WHEN `Ship` = 'Manhattan' THEN 1 ELSE 0 END) AS `Manhattan`, SUM(CASE WHEN `Ship` = 'Oneota' THEN 1 ELSE 0 END) AS `Oneota`, SUM(CASE WHEN `Ship` = 'Saugus' THEN 1 ELSE 0 END) AS `Saugus`, SUM(CASE WHEN `Ship` = 'Tecumseh' THEN 1 ELSE 0 END) AS `Tecumseh`, GROUP_CONCAT(`Ship`, ', ') AS `Ships`, MIN(`Laid down`) AS `Earliest Laid down`, MAX(`Launched`) AS `Latest Launched`, 0 AS `Not Applicable` FROM `table_1_12592074_1` WHERE `Laid down` = 1862 GROUP BY `Builder` HAVING COUNT(*) > 0 AND SUM(CASE WHEN `Renamed` != 'Not Applicable' THEN 1 ELSE 0 END) > 0 ORDER BY `Renamed Count` DESC LIMIT 10;
","
SELECT col1 AS col1, COUNT(*) AS `Total Ships`, SUM(CASE WHEN col3 != 'Not Applicable' THEN 1 ELSE 0 END) AS `Renamed Count`, SUM(CASE WHEN col0 = 'Ajax' THEN 1 ELSE 0 END) AS `Ajax`, SUM(CASE WHEN col0 = 'Canonicus' THEN 1 ELSE 0 END) AS `Canonicus`, SUM(CASE WHEN col0 = 'Catawba' THEN 1 ELSE 0 END) AS `Catawba`, SUM(CASE WHEN col0 = 'Mahopac' THEN 1 ELSE 0 END) AS `Mahopac`, SUM(CASE WHEN col0 = 'Manhattan' THEN 1 ELSE 0 END) AS `Manhattan`, SUM(CASE WHEN col0 = 'Oneota' THEN 1 ELSE 0 END) AS `Oneota`, SUM(CASE WHEN col0 = 'Saugus' THEN 1 ELSE 0 END) AS `Saugus`, SUM(CASE WHEN col0 = 'Tecumseh' THEN 1 ELSE 0 END) AS `Tecumseh`, GROUP_CONCAT(col0, ', ') AS `Ships`, MIN(col4) AS `Earliest Laid down`, MAX(col5) AS `Latest Launched`, 0 AS `Not Applicable` FROM `table_1_12592074_1` WHERE col4 = 1862 GROUP BY col1 HAVING COUNT(*) > 0 AND SUM(CASE WHEN col3 != 'Not Applicable' THEN 1 ELSE 0 END) > 0 ORDER BY `Renamed Count` DESC LIMIT 10;
","[('alexander swift & company, cincinnati, ohio', 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 'catawba, oneota', 1862.0, '21 may 1864', 0), ('snowden & mason, pittsburgh, pennsylvania', 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 'ajax', 1862.0, '18 december 1864', 0), ('secor & co., jersey city, new jersey', 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 'mahopac', 1862.0, '17 may 1864', 0), ('perine, secor & co., jersey city, new jersey', 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 'manhattan', 1862.0, '14october1863', 0), ('harrison loring, boston, massachusetts', 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 'canonicus', 1862.0, '1august1863', 0), ('harlan & hollingsworth , wilmington, delaware', 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 'saugus', 1862.0, '8 february 1864', 0), ('charles secor & co., jersey city, new jersey', 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 'tecumseh', 1862.0, '12 september 1863', 0)]",table_1_12592074_1,"1) Parse intent: filter to Laid down = 1862, group by Builder, compute total and renamed counts, compute per-ship-name counts, concatenate ship names, find MIN Laid down and MAX Launched, include a constant 0 column, require builders to have >0 ships and >0 renamed ships, sort by renamed count and limit 10. 2) Map schema: columns Builder, Ship, Renamed, Laid down, Launched correspond to table fields. 3) Draft: convert these requirements into a single natural question listing all requested output columns and constraints. 4) Validate: ensure the question explicitly names every aggregate and the Renamed != 'Not Applicable' condition, grouping, ordering and limit.",reserved,16,reward,,
"Considering only rows where the '#' column is greater than 0, return the following aggregates: COUNT(Team) labeled Total Teams; COUNT(Driver(s)) labeled Total Driver Entries; group_concat(Car(s) using ' | ') as All Car(s); group_concat(Owner(s) using ' /// ') as All Owner(s); the maximum length of Primary Sponsor(s) via MAX(length(Primary Sponsor(s))) as Longest Sponsor Length; and the instr of group_concat(Driver(s)) for the substring '`Jimmie Johnson`' as Has Jimmie Johnson, ordered by Total Teams?","
SELECT
 COUNT(`Team`) `Total Teams`,
 COUNT(`Driver(s)`) `Total Driver Entries`,
 group_concat(`Car(s)`, ' | ') `All Car(s)`,
 group_concat(`Owner(s)`, ' /// ') `All Owner(s)`,
 MAX(length(`Primary Sponsor(s)`)) `Longest Sponsor Length`,
 instr(group_concat(`Driver(s)`), '`Jimmie Johnson`') `Has Jimmie Johnson`
FROM `table_1_1266602_1`
WHERE `#` > 0
ORDER BY `Total Teams`;
","
SELECT
 COUNT(col0) `Total Teams`,
 COUNT(col3) `Total Driver Entries`,
 group_concat(col1, ' | ') `All Car(s)`,
 group_concat(col5, ' /// ') `All Owner(s)`,
 MAX(length(col4)) `Longest Sponsor Length`,
 instr(group_concat(col3), '`Jimmie Johnson`') `Has Jimmie Johnson`
FROM `table_1_1266602_1`
WHERE col2 > 0
ORDER BY `Total Teams`;
","[(38, 38, 'toyota camry | toyota camry | chevrolet ss | chevrolet ss | ford fusion | ford fusion | ford fusion | ford fusion | chevrolet ss | ford fusion | chevrolet ss | chevrolet ss | chevrolet ss | chevrolet ss | toyota camry | toyota camry | toyota camry | toyota camry | toyota camry | toyota camry | toyota camry | toyota camry | ford fusion | ford fusion | chevrolet ss | chevrolet ss | chevrolet ss | chevrolet ss | ford fusion | ford fusion | ford fusion | ford fusion | ford fusion | chevrolet ss | chevrolet ss | chevrolet ss | toyota camry | chevrolet ss', 'ron devine /// ron devine /// felix sabates /// chip ganassi /// frank stoddard /// bob jenkins /// jerry freeze /// brad jenkins /// barney visser /// bob germain, jr. /// linda hendrick /// rick hendrick /// jeff gordon /// rick hendrick /// j. d. gibbs /// joe gibbs /// joe gibbs /// tad geschickter /// robert kauffman /// michael waltrip /// michael waltrip /// andrea nemechek /// roger penske /// walter czarnecki /// james finch /// richard childress /// richard childress /// richard childress /// richard petty /// richard petty /// jack roush /// john w. henry /// jack roush /// gene haas /// margaret haas /// tony stewart /// brandon davis /// tommy baldwin, jr.', 48, 0)]",table_1_1266602_1,"1) Parse intent: aggregate the table restricted to rows where '#' > 0 producing counts, concatenated lists with specified separators, longest sponsor length, and a substring position check for '`Jimmie Johnson`'. 2) Map schema: Team, Driver(s), Car(s), Owner(s), Primary Sponsor(s) and '#' are needed. 3) Draft: phrase the question to request each aggregate and the exact separators and functions. 4) Validate: confirm inclusion of COUNT(Team) Total Teams, COUNT(Driver(s)) Total Driver Entries, group_concat(Car(s),' | ') All Car(s), group_concat(Owner(s),' /// ') All Owner(s), MAX(length(Primary Sponsor(s))) Longest Sponsor Length, instr(group_concat(Driver(s)), '`Jimmie Johnson`') Has Jimmie Johnson, and ORDER BY Total Teams.",reserved,5,reward,,
"List Owner(s) along with COUNT(DISTINCT Team) AS TeamsCount, GROUP_CONCAT(DISTINCT Truck(s)) AS Trucks, and SUM(CASE WHEN Primary Sponsor(s) LIKE '%Cooper%' THEN 1 ELSE 0 END) AS CooperSponsors for owners who have more than one distinct Team OR at least one Primary Sponsor(s) containing 'Cooper', ordered by TeamsCount descending and limited to the top 10?","
SELECT *
FROM (
  SELECT `Owner(s)`, COUNT(DISTINCT `Team`) AS `TeamsCount`, GROUP_CONCAT(DISTINCT `Truck(s)`) `Trucks`, SUM(CASE WHEN `Primary Sponsor(s)` LIKE '%Cooper%' THEN 1 ELSE 0 END) AS `CooperSponsors`
  FROM `table_1_1266602_5`
  GROUP BY `Owner(s)`
)
WHERE `TeamsCount` > 1 OR `CooperSponsors` > 0
ORDER BY `TeamsCount` DESC
LIMIT 10;
","
SELECT *
FROM (
  SELECT col5, COUNT(DISTINCT col0) AS `TeamsCount`, GROUP_CONCAT(DISTINCT col1) `Trucks`, SUM(CASE WHEN col4 LIKE '%Cooper%' THEN 1 ELSE 0 END) AS `CooperSponsors`
  FROM `table_1_1266602_5`
  GROUP BY col5
)
WHERE `TeamsCount` > 1 OR `CooperSponsors` > 0
ORDER BY `TeamsCount` DESC
LIMIT 10;
","[('brad keselowski', 1, 'ford f-150', 2)]",table_1_1266602_5,"Parse intent: produce per-owner aggregates (distinct team count, distinct trucks concatenated, number of 'Cooper' primary sponsors), then filter to owners with TeamsCount>1 or CooperSponsors>0 and return up to 10 ordered by TeamsCount desc. Map schema: use Owner(s), Team, Truck(s), Primary Sponsor(s) for those aggregates. Draft: form a question that requests these exact aggregates, the OR filter, descending team-count order, and a 10-row limit. Validate: ensure every SQL element (aggregates, LIKE '%Cooper%', OR filter, ORDER BY, LIMIT) is included.",reserved,24,reward,,
"List the top 10 distinct Committee and Party combinations by Avg_Tenure (where Avg_Tenure = AVG(2025 - First Elected)), showing Committee, Party, Members (COUNT(*)), Avg_Tenure, Tenure_Level (CASE: 'High Tenure' if Avg_Tenure >= 20, 'Medium Tenure' if Avg_Tenure >= 10, else 'Low Tenure'), and Committee_Rank (row number partitioned by Committee ordered by Avg_Tenure DESC), including only groups with at least one member and ordering the results by Avg_Tenure descending.","
SELECT DISTINCT `Committee`, `Party`,
  COUNT(*) AS `Members`,
  AVG(2025 - `First Elected`) AS `Avg_Tenure`,
  CASE WHEN AVG(2025 - `First Elected`) >= 20 THEN 'High Tenure' WHEN AVG(2025 - `First Elected`) >= 10 THEN 'Medium Tenure' ELSE 'Low Tenure' END AS `Tenure_Level`,
  ROW_NUMBER() OVER (PARTITION BY `Committee` ORDER BY AVG(2025 - `First Elected`) DESC) AS `Committee_Rank`
FROM `table_1_12679326_1`
GROUP BY `Committee`, `Party`
HAVING COUNT(*) >= 1
ORDER BY `Avg_Tenure` DESC
LIMIT 10;
","
SELECT DISTINCT col5, col3,
  COUNT(*) AS `Members`,
  AVG(2025 - col4) AS `Avg_Tenure`,
  CASE WHEN AVG(2025 - col4) >= 20 THEN 'High Tenure' WHEN AVG(2025 - col4) >= 10 THEN 'Medium Tenure' ELSE 'Low Tenure' END AS `Tenure_Level`,
  ROW_NUMBER() OVER (PARTITION BY col5 ORDER BY AVG(2025 - col4) DESC) AS `Committee_Rank`
FROM `table_1_12679326_1`
GROUP BY col5, col3
HAVING COUNT(*) >= 1
ORDER BY `Avg_Tenure` DESC
LIMIT 10;
","[('health and government operations', 'republican', 2, 49.0, 'High Tenure', 1), ('economic matters', 'democratic', 2, 34.0, 'High Tenure', 1), ('environmental matters (vice-chair)', 'democratic', 1, 31.0, 'High Tenure', 1), ('health and government operations', 'democratic', 3, 28.333333333333332, 'High Tenure', 2), ('appropriations', 'democratic', 2, 25.5, 'High Tenure', 1), ('appropriations', 'republican', 1, 23.0, 'High Tenure', 2), ('economic matters', 'republican', 1, 23.0, 'High Tenure', 2), ('environmental matters', 'republican', 1, 23.0, 'High Tenure', 1), ('ways and means', 'republican', 1, 23.0, 'High Tenure', 1), ('ways and means', 'democratic', 1, 23.0, 'High Tenure', 2)]",table_1_12679326_1,"1) Parse: the SQL produces distinct Committee/Party groups with Members count, average tenure (2025 minus First Elected), a three-tier tenure label, and a per-Committee rank, filtered by COUNT(*) >= 1 and limited to 10 ordered by average tenure. 2) Map: use table columns Committee, Party, First Elected to compute Members and Avg_Tenure; derive Tenure_Level per thresholds and Committee_Rank via row numbering partitioned by Committee. 3) Draft: ask for the top 10 committee-party combinations with these computed fields. 4) Validate: ensure the question explicitly requests the COUNT, AVG formula, CASE thresholds, ranking rule, HAVING condition, ordering, and limit.",reserved,27,reward,,
Which marine organisms have FDA-approved compounds for cancer?,"
SELECT `Marine Organism α`, `Clinical Status`, `Compound Name`
FROM `table_1_12715053_1` AS `t`
JOIN (VALUES ('Cancer','FDA-Approved')) `c`(`Cancer`,`FDA-Approved`) ON `t`.`Disease Area` = `c`.`Cancer` AND `t`.`Clinical Status` = `c`.`FDA-Approved`
WHERE `t`.`Chemical Class` <> ''
GROUP BY `Marine Organism α`,`Clinical Status`,`Compound Name`
HAVING `t`.`Clinical Status` = `c`.`FDA-Approved`
ORDER BY `Marine Organism α`
LIMIT 20;
","SELECT DISTINCT col3, col0, col1
FROM `table_1_12715053_1` AS `t`
WHERE (`t`.col4 <> '' OR `t`.col0 = 'FDA-Approved') AND `t`.col1 <> ''
GROUP BY col3, col0, col1
HAVING COUNT(*) > 0
ORDER BY col3
LIMIT 20;","[('bacterium', 'phase i', 'marizomib (salinosporamide a)'), ('bryozoa', 'phase i', 'bryostatin 1'), ('cone snail', 'fda-approved', 'ziconotide'), ('fish', 'fda-approved', 'omega-3-fatty acid ethyl esters'), ('fungus', 'phase ii', 'plinabulin (npi 2358)'), ('mollusk', 'phase i', 'asg-5me'), ('mollusk', 'phase i', 'sgn-75'), ('mollusk', 'phase ii', 'elisidepsin'), ('mollusk', 'phase ii', 'glembatumumab vedotin (cdx-011)'), ('mollusk', 'phase iii', 'brentuximab vedotin (sgn-35)'), ('nudibranch', 'phase ii', 'pm00104'), ('sponge', 'fda-approved', 'cytarabine (ara-c)'), ('sponge', 'fda-approved', 'eribulin mesylate (e7389)'), ('sponge', 'fda-approved', 'vidarabine (ara-a)'), ('sponge', 'phase i', 'hemiasterlin (e7974)'), ('tunicate', 'fda-approved', 'trabectedin (et-743) eu approved only'), ('tunicate', 'phase i', 'pm01183'), ('tunicate', 'phase iii', 'plitidepsin'), ('worm', 'phase ii', 'dmxba (gts-21)')]",table_1_12715053_1,"STEP 1: Parse the SQL intent: the query returns up to 20 rows of Marine Organism α, Clinical Status, and Compound Name for rows where Disease Area = 'Cancer', Clinical Status = 'FDA-Approved', and Chemical Class is not empty; results are grouped by organism/status/compound and ordered by organism. STEP 2: Determine ambiguity type: scope ambiguity — asking ""which organisms have FDA-approved compounds for cancer"" can mean (a) list each organism once (distinct organisms) or (b) list each organism-compound pair (one row per approved compound). STEP 3: Draft the question: ""Which marine organisms have FDA-approved compounds for cancer?"" STEP 4: Explain the ambiguity: the original SQL produces organism + compound name rows (interpretation b). Alternatively the question could be interpreted to request only the distinct organisms that have any FDA-approved cancer compound (interpretation a), or to ask which organism has the most such compounds (a different scope).",reserved,13,reward,,"type: Scope ambiguity | explanation: The SQL returns organism + compound name rows (each FDA-approved cancer compound and its source organism). The natural-language question could instead be read as asking only for the distinct set of organisms that have any FDA-approved cancer compound, or even as asking which organism has the most such compounds—different scopes of 'which'."
Which sequencer is the most efficient per run?,"
SELECT DISTINCT
 ((100.0+200.0)/2.0) `Ion Torrent PGM - Data output per run`,
 (0.7*1000.0) `454 GS FLX - Data output per run`,
 (600.0*1000.0) `HiSeq 2000 - Data output per run`,
 (120.0*1000.0) `SOLiDv4 - Data output per run`,
 ((1500.0+5000.0)/2.0) `PacBio - Data output per run`,
 CAST(((1.9+84.0)/2.0/1000.0) AS REAL) `Sanger 3730xl - Data output per run`,
 (350.0/(((100.0+200.0)/2.0))) `Ion Torrent PGM - Cost per run / Data output per run (Cost per Mb calc)`,
 (7000.0/(0.7*1000.0)) `454 GS FLX - Cost per run / Data output per run (Cost per Mb calc)`,
 (6000.0/(600.0*1000.0)) `HiSeq 2000 - Cost per run / Data output per run (Cost per Mb calc)`,
 (4000.0/(120.0*1000.0)) `SOLiDv4 - Cost per run / Data output per run (Cost per Mb calc)`,
 (300.0/(((1500.0+5000.0)/2.0))) `PacBio - Cost per run / Data output per run (Cost per Mb calc)`,
 (4.0/(((1.9+84.0)/2.0/1000.0))) `Sanger 3730xl - Cost per run / Data output per run (Cost per Mb calc)`,
 (99.0/(350.0/(((100.0+200.0)/2.0)))) `Ion Torrent PGM - Efficiency (Accuracy / Cost per Mb)`,
 (99.9/(7000.0/(0.7*1000.0))) `454 GS FLX - Efficiency (Accuracy / Cost per Mb)`,
 (99.9/(6000.0/(600.0*1000.0))) `HiSeq 2000 - Efficiency (Accuracy / Cost per Mb)`,
 (99.94/(4000.0/(120.0*1000.0))) `SOLiDv4 - Efficiency (Accuracy / Cost per Mb)`,
 (90.0/(300.0/(((1500.0+5000.0)/2.0)))) `PacBio - Efficiency (Accuracy / Cost per Mb)`,
 (99.999/(4.0/(((1.9+84.0)/2.0/1000.0)))) `Sanger 3730xl - Efficiency (Accuracy / Cost per Mb)`,
 CASE WHEN 1=1 THEN 1 END `Case_Check`
WHERE 1=1
GROUP BY 1
HAVING 1
LIMIT 3;
","
SELECT DISTINCT
 ((100.0+200.0)/2.0) `Ion Torrent PGM - Data output per run`,
 (0.7*1000.0) `454 GS FLX - Data output per run`,
 (600.0*1000.0) `HiSeq 2000 - Data output per run`,
 (120.0*1000.0) `SOLiDv4 - Data output per run`,
 ((1500.0+5000.0)/2.0) `PacBio - Data output per run`,
 CAST(((1.9+84.0)/2.0/1000.0) AS REAL) `Sanger 3730xl - Data output per run`,
 (350.0/(((100.0+200.0)/2.0))) `Ion Torrent PGM - Cost per run / Data output per run (Cost per Mb calc)`,
 (7000.0/(0.7*1000.0)) `454 GS FLX - Cost per run / Data output per run (Cost per Mb calc)`,
 (6000.0/(600.0*1000.0)) `HiSeq 2000 - Cost per run / Data output per run (Cost per Mb calc)`,
 (4000.0/(120.0*1000.0)) `SOLiDv4 - Cost per run / Data output per run (Cost per Mb calc)`,
 (300.0/(((1500.0+5000.0)/2.0))) `PacBio - Cost per run / Data output per run (Cost per Mb calc)`,
 (4.0/(((1.9+84.0)/2.0/1000.0))) `Sanger 3730xl - Cost per run / Data output per run (Cost per Mb calc)`,
 (99.0/(350.0/(((100.0+200.0)/2.0)))) `Ion Torrent PGM - Efficiency (Accuracy / Cost per Mb)`,
 (99.9/(7000.0/(0.7*1000.0))) `454 GS FLX - Efficiency (Accuracy / Cost per Mb)`,
 (99.9/(6000.0/(600.0*1000.0))) `HiSeq 2000 - Efficiency (Accuracy / Cost per Mb)`,
 (99.94/(4000.0/(120.0*1000.0))) `SOLiDv4 - Efficiency (Accuracy / Cost per Mb)`,
 (90.0/(300.0/(((1500.0+5000.0)/2.0)))) `PacBio - Efficiency (Accuracy / Cost per Mb)`,
 (99.999/(4.0/(((1.9+84.0)/2.0/1000.0)))) `Sanger 3730xl - Efficiency (Accuracy / Cost per Mb)`,
 CASE WHEN 1=1 THEN 1 END `Case_Check`
WHERE 1=1
GROUP BY 1
HAVING 1
LIMIT 3;
","[(150.0, 700.0, 600000.0, 120000.0, 3250.0, 0.04295, 2.3333333333333335, 10.0, 0.01, 0.03333333333333333, 0.09230769230769231, 93.13154831199068, 42.42857142857142, 9.99, 9990.0, 2998.2, 975.0, 1.0737392625, 1)]",table_1_127511_1,"STEP 1: Parse the SQL intent — the query computes, for each listed sequencer, a Data output per run (constants/averages), Cost per Mb (cost per run divided by data output), and an Efficiency measure defined as Accuracy / (Cost per Mb); it returns those computed columns (grouped/limited but effectively producing per-sequencer metrics).
STEP 2: Determine ambiguity type — scope ambiguity fits well: the natural question could ask for the efficiency value for every sequencer (a list of values) or ask for the single most efficient sequencer (a top-1 answer).
STEP 3: Draft the question — ""Which sequencer is the most efficient per run?""
STEP 4: Explain the ambiguity — the original SQL provides an efficiency number for each sequencer (so it can be read as returning per-sequencer efficiencies), but the NL question can also be read as requesting a single winner (the sequencer with the maximum efficiency), which would require ordering/aggregation; thus the question is ambiguous between returning all efficiencies and returning the top sequencer.",reserved,13,reward,,"type: Scope ambiguity | explanation: The SQL computes an efficiency value for each sequencer (accuracy divided by cost per Mb) and returns those values, so the question could mean either (a) ""show the efficiency for each sequencer"" (the per-sequencer list the query produces) or (b) ""which single sequencer has the highest efficiency"" (a top-1 selection), creating a scope ambiguity between listing all items vs selecting the best one."
"Which players are the headline players and what fraction of their goals came from the League, Scottish Cup, League Cup, and Challenge Cup?","
WITH `ranked` AS (
  SELECT *,
         RANK() OVER (ORDER BY `Total` DESC, `League` DESC) AS `accent_priority_rank`
  FROM `table_1_12755786_8`
)
SELECT
  `Player`,
  ROUND(CASE WHEN `Total` = 0 THEN 0.0 ELSE CAST(`League` AS REAL) / `Total` END, 3) AS `League_ratio`,
  ROUND(CASE WHEN `Total` = 0 THEN 0.0 ELSE CAST(`Scottish Cup` AS REAL) / `Total` END, 3) AS `Scottish Cup_ratio`,
  ROUND(CASE WHEN `Total` = 0 THEN 0.0 ELSE CAST(`League Cup` AS REAL) / `Total` END, 3) AS `League Cup_ratio`,
  ROUND(CASE WHEN `Total` = 0 THEN 0.0 ELSE CAST(`Challenge Cup` AS REAL) / `Total` END, 3) AS `Challenge Cup_ratio`,
  `Total`,
  ((CASE WHEN `League` > 0 THEN 1 ELSE 0 END)
   + (CASE WHEN `Scottish Cup` > 0 THEN 1 ELSE 0 END)
   + (CASE WHEN `League Cup` > 0 THEN 1 ELSE 0 END)
   + (CASE WHEN `Challenge Cup` > 0 THEN 1 ELSE 0 END)
  ) AS `competitions_scored_in`,
  CASE WHEN ((CASE WHEN `League` > 0 THEN 1 ELSE 0 END)
             + (CASE WHEN `Scottish Cup` > 0 THEN 1 ELSE 0 END)
             + (CASE WHEN `League Cup` > 0 THEN 1 ELSE 0 END)
             + (CASE WHEN `Challenge Cup` > 0 THEN 1 ELSE 0 END)
            ) > 1 THEN 'multi-colored' ELSE 'single-color' END AS `motif_type`,
  `accent_priority_rank`,
  CASE WHEN `accent_priority_rank` <= 3 THEN 1 ELSE 0 END AS `headline_player`
FROM `ranked`
ORDER BY `accent_priority_rank`, `competitions_scored_in` DESC, `League_ratio` DESC;
","
WITH `ranked` AS (
  SELECT *,
         RANK() OVER (ORDER BY col5 DESC, col1 DESC) AS `accent_priority_rank`
  FROM `table_1_12755786_8`
)
SELECT
  col0,
  ROUND(CASE WHEN col5 = 0 THEN 0.0 ELSE CAST(col1 AS REAL) / col5 END, 3) AS `League_ratio`,
  ROUND(CASE WHEN col5 = 0 THEN 0.0 ELSE CAST(col2 AS REAL) / col5 END, 3) AS `Scottish Cup_ratio`,
  ROUND(CASE WHEN col5 = 0 THEN 0.0 ELSE CAST(col3 AS REAL) / col5 END, 3) AS `League Cup_ratio`,
  ROUND(CASE WHEN col5 = 0 THEN 0.0 ELSE CAST(col4 AS REAL) / col5 END, 3) AS `Challenge Cup_ratio`,
  col5,
  ((CASE WHEN col1 > 0 THEN 1 ELSE 0 END)
   + (CASE WHEN col2 > 0 THEN 1 ELSE 0 END)
   + (CASE WHEN col3 > 0 THEN 1 ELSE 0 END)
   + (CASE WHEN col4 > 0 THEN 1 ELSE 0 END)
  ) AS `competitions_scored_in`,
  CASE WHEN ((CASE WHEN col1 > 0 THEN 1 ELSE 0 END)
             + (CASE WHEN col2 > 0 THEN 1 ELSE 0 END)
             + (CASE WHEN col3 > 0 THEN 1 ELSE 0 END)
             + (CASE WHEN col4 > 0 THEN 1 ELSE 0 END)
            ) > 1 THEN 'multi-colored' ELSE 'single-color' END AS `motif_type`,
  `accent_priority_rank`,
  CASE WHEN `accent_priority_rank` <= 3 THEN 1 ELSE 0 END AS `headline_player`
FROM `ranked`
ORDER BY `accent_priority_rank`, `competitions_scored_in` DESC, `League_ratio` DESC;
","[('liam buchanan', 0.786, 0.214, 0.0, 0.0, 14.0, 2, 'multi-colored', 1, 1), ('mark roberts', 0.833, 0.167, 0.0, 0.0, 6.0, 2, 'multi-colored', 2, 1), ('scott chaplain', 1.0, 0.0, 0.0, 0.0, 5.0, 1, 'single-color', 3, 1), ('damon gray', 0.75, 0.25, 0.0, 0.0, 4.0, 2, 'multi-colored', 4, 0), ('kevin mckinlay', 1.0, 0.0, 0.0, 0.0, 3.0, 1, 'single-color', 5, 0), ('paul keegan', 0.667, 0.0, 0.0, 0.333, 3.0, 2, 'multi-colored', 6, 0), ('marc twaddle', 0.667, 0.333, 0.0, 0.0, 3.0, 2, 'multi-colored', 6, 0), ('gary harkins', 0.333, 0.0, 0.333, 0.333, 3.0, 3, 'multi-colored', 8, 0), ('stephen mckeown', 1.0, 0.0, 0.0, 0.0, 2.0, 1, 'single-color', 9, 0), ('adam strachan', 1.0, 0.0, 0.0, 0.0, 2.0, 1, 'single-color', 9, 0), ('paul di giacomo', 0.5, 0.0, 0.0, 0.5, 2.0, 2, 'multi-colored', 11, 0), ('simon donnelly', 1.0, 0.0, 0.0, 0.0, 1.0, 1, 'single-color', 12, 0), ('simon storey', 1.0, 0.0, 0.0, 0.0, 1.0, 1, 'single-color', 12, 0)]",table_1_12755786_8,"STEP 1: Parse SQL intent - compute for each player the ratio of goals in each competition to their Total, count how many competitions they scored in, label them 'multi-colored' if they scored in >1 competition else 'single-color', rank players by Total (tie-breaker League) and mark top 3 as headline_player; return all players ordered by that rank and other tie-breakers. STEP 2: Choose ambiguity type - scope ambiguity fits: the phrasing can be read as either (a) return only the headline players with their goal fractions or (b) return all players and simply indicate which ones are headline players while showing fractions for everyone. This matches the query because it both flags headline players and lists ratios for all rows. STEP 3: Draft the question - ""Which players are the headline players and what fraction of their goals came from the League, Scottish Cup, League Cup, and Challenge Cup?"" STEP 4: Explain ambiguity - in the original query 'headline players' is a flag for rank <= 3 and the query returns every player with ratios and that flag; alternatively the question could be interpreted to ask only for the top 3 players and their ratios, or to treat 'headline' as a different notion (e.g., players who scored in multiple competitions), which would change the filtered result set.",persona,"A data-driven tartan designer who encodes each player's season goal-distribution into stripe widths and colors for a commemorative '2007–08 Partick Thistle' fabric. Goals: Translate each player's goals-per-competition into proportional stripe widths (e.g., league vs cups) so dominant competitions produce wider stripes. Identify players who scored across multiple competitions to create multi-colored motif blocks versus single-color stripes for one-competition scorers. Pick the season's headline players (top scorers) to receive signature accent colors and prioritize them in the tartan pattern hierarchy. Example Queries: SELECT ""Player"", ""League"", ""Scottish Cup"", ""League Cup"", ""Challenge Cup"", ""Total"", ""League""/NULLIF(""Total"",0) AS league_ratio
FROM ""table_1_12755786_8""
ORDER BY league_ratio DESC, ""Total"" DESC; SELECT ""Player"",
       (CASE WHEN ""League"">0 THEN 1 ELSE 0 END
        + CASE WHEN ""Scottish Cup"">0 THEN 1 ELSE 0 END
        + CASE WHEN ""League Cup"">0 THEN 1 ELSE 0 END
        + CASE WHEN ""Challenge Cup"">0 THEN 1 ELSE 0 END) AS competitions_scored_in,
       ""League"", ""Scottish Cup"", ""League Cup"", ""Challenge Cup"", ""Total""
FROM ""table_1_12755786_8""
WHERE (CASE WHEN ""League"">0 THEN 1 ELSE 0 END
       + CASE WHEN ""Scottish Cup"">0 THEN 1 ELSE 0 END
       + CASE WHEN ""League Cup"">0 THEN 1 ELSE 0 END
       + CASE WHEN ""Challenge Cup"">0 THEN 1 ELSE 0 END) > 1
ORDER BY competitions_scored_in DESC, ""Total"" DESC; SELECT ""Player"", ""League"", ""Scottish Cup"", ""League Cup"", ""Challenge Cup"", ""Total""
FROM ""table_1_12755786_8""
ORDER BY ""Total"" DESC, ""League"" DESC
LIMIT 3;",reward,,"type: Scope ambiguity | explanation: The phrase can mean either (a) show only the headline players (e.g., top 3 by total goals) and their goal fractions, or (b) show all players and merely indicate which ones are headline players while giving fractions for everyone; additionally, 'headline' could be interpreted differently (e.g., players who scored in multiple competitions) changing which players are returned."
"For which five celebrity partners (only those with more than one dance and an overall average > 0) list the partner name and these metrics: AvgScore = ROUND(AVG((Horwood + Phillips + Goodman + Tonioli)/4.0),2), PeakScore = ROUND(MAX((Horwood + Phillips + Goodman + Tonioli)/4.0),2), LowScore = ROUND(MIN((Horwood + Phillips + Goodman + Tonioli)/4.0),2), MaxDisagreement = ROUND(MAX(MAX(Horwood,Phillips,Goodman,Tonioli) - MIN(Horwood,Phillips,Goodman,Tonioli)),2), and DancesCount = COUNT(*), ordered by AvgScore descending and limited to 5?","
SELECT `Celebrity partner` AS `Partner`,
       ROUND(AVG((`Horwood`+`Phillips`+`Goodman`+`Tonioli`)/4.0),2) AS `AvgScore`,
       ROUND(MAX((`Horwood`+`Phillips`+`Goodman`+`Tonioli`)/4.0),2) AS `PeakScore`,
       ROUND(MIN((`Horwood`+`Phillips`+`Goodman`+`Tonioli`)/4.0),2) AS `LowScore`,
       ROUND(MAX(MAX(`Horwood`,`Phillips`,`Goodman`,`Tonioli`) - MIN(`Horwood`,`Phillips`,`Goodman`,`Tonioli`)),2) AS `MaxDisagreement`,
       COUNT(*) AS `DancesCount`
FROM `table_1_1276219_1` AS `t`
GROUP BY `Celebrity partner`
HAVING COUNT(*) > 1 AND AVG((`Horwood`+`Phillips`+`Goodman`+`Tonioli`)/4.0) > 0
ORDER BY `AvgScore` DESC
LIMIT 5;
","
SELECT col1 AS `Partner`,
       ROUND(AVG((col4+col5+col6+col7)/4.0),2) AS `AvgScore`,
       ROUND(MAX((col4+col5+col6+col7)/4.0),2) AS `PeakScore`,
       ROUND(MIN((col4+col5+col6+col7)/4.0),2) AS `LowScore`,
       ROUND(MAX(MAX(col4,col5,col6,col7) - MIN(col4,col5,col6,col7)),2) AS `MaxDisagreement`,
       COUNT(*) AS `DancesCount`
FROM `table_1_1276219_1` AS `t`
GROUP BY col1
HAVING COUNT(*) > 1 AND AVG((col4+col5+col6+col7)/4.0) > 0
ORDER BY `AvgScore` DESC
LIMIT 5;
","[('emma bunton', 8.5, 9.25, 7.5, 2.0, 13), ('jill halfpenny', 8.43, 10.0, 6.75, 1.0, 11), ('letitia dean', 7.36, 8.75, 5.75, 3.0, 11), ('lynda bellingham', 5.75, 6.25, 5.25, 4.0, 3), ('jessie wallace', 4.88, 5.0, 4.75, 3.0, 2)]",table_1_1276219_1,"1) Parse intent: aggregate judge scores per celebrity to produce summary statistics and select the top five by average. 2) Map schema: use Celebrity partner as Partner and Horwood/Phillips/Goodman/Tonioli as the four judges to compute per-dance and per-partner metrics. 3) Draft: ask for Partner, rounded AvgScore of the four judges per dance, rounded PeakScore and LowScore of that per-dance average, rounded MaxDisagreement across dances, and DancesCount, applying filters COUNT>1 and Avg>0, sorted by AvgScore desc limit 5. 4) Validate: ensures rounding to 2 decimals, uses the exact calculations and filters from the query.",reserved,11,reward,,
"From records where Tamil = 1 and (Bengali = 1 OR Marathi = 1), what single Consensus value — defined as CASE WHEN Tamil = 1 AND Sanskrit = 1 THEN Tamil ELSE Hindi END — is produced after grouping by Tamil, ordering by Tamil, and limiting to one row?","
WITH `data` AS (SELECT 1 `Tamil`, 1 `Sanskrit`, 1 `Hindi`, 1 `Marathi`, 1 `Bengali`)
SELECT CASE WHEN `Tamil`=1 AND `Sanskrit`=1 THEN `Tamil` ELSE `Hindi` END `Consensus`
FROM `data`
WHERE `Tamil`=1 AND (`Bengali`=1 OR `Marathi`=1)
GROUP BY `Tamil`
ORDER BY `Tamil`
LIMIT 1;
","
WITH `data` AS (SELECT 1 `Tamil`, 1 `Sanskrit`, 1 `Hindi`, 1 `Marathi`, 1 `Bengali`)
SELECT CASE WHEN `Tamil`=1 AND `Sanskrit`=1 THEN `Tamil` ELSE `Hindi` END `Consensus`
FROM `data`
WHERE `Tamil`=1 AND (`Bengali`=1 OR `Marathi`=1)
GROUP BY `Tamil`
ORDER BY `Tamil`
LIMIT 1;
","[(1,)]",table_1_1277350_3,"1) The intent is to return one aggregated row named Consensus choosing Tamil when both Tamil and Sanskrit equal 1, else Hindi. 2) Identify the filter Tamil=1 and the additional condition (Bengali=1 OR Marathi=1), and the grouping/ordering by Tamil with a limit of 1. 3) Phrase a question that requests that single Consensus value and explicitly includes the CASE, the involved columns, the WHERE clause, GROUP BY, ORDER BY, and LIMIT. 4) Confirm the question aligns exactly with the SQL operations and referenced columns.",reserved,18,reward,,
"For which five Day (see Irregularities ) entries (listed as Icelandic) does the computed Any_symbol equal 1 — where Any_symbol is defined as CASE WHEN (Sunday Day One || Friday Day Six || Saturday Day Seven) LIKE '%☉%' OR (Sunday Day One || Friday Day Six || Saturday Day Seven) LIKE '%♀%' THEN 1 ELSE 0 END — considering only rows where (Sunday Day One || Friday Day Six || Saturday Day Seven) IS NOT NULL and Day (see Irregularities ) <> '', grouping by Icelandic and ordering the results by Icelandic DESC and limiting to 5?","
SELECT `Day (see Irregularities )` `Icelandic`,
  CASE WHEN ((`Sunday Day One` || `Friday Day Six` || `Saturday Day Seven`) LIKE '%☉%' OR (`Sunday Day One` || `Friday Day Six` || `Saturday Day Seven`) LIKE '%♀%') THEN 1 ELSE 0 END `Any_symbol`
FROM `table_1_1277350_7`
WHERE (`Sunday Day One` || `Friday Day Six` || `Saturday Day Seven`) IS NOT NULL AND `Day (see Irregularities )` <> ''
GROUP BY `Icelandic`
HAVING `Any_symbol` = 1
ORDER BY `Icelandic` DESC
LIMIT 5;
","
SELECT col0 `Icelandic`,
  CASE WHEN ((col1 || col6 || col7) LIKE '%☉%' OR (col1 || col6 || col7) LIKE '%♀%') THEN 1 ELSE 0 END `Any_symbol`
FROM `table_1_1277350_7`
WHERE (col1 || col6 || col7) IS NOT NULL AND col0 <> ''
GROUP BY `Icelandic`
HAVING `Any_symbol` = 1
ORDER BY `Icelandic` DESC
LIMIT 5;
","[('vietnamese', 1), ('sundanese', 1), ('portuguese', 1), ('persian', 1), ('maltese', 1)]",table_1_1277350_7,"1) The query tests whether any of three columns include astronomical symbols and returns a binary Any_symbol per Icelandic row, then filters to rows where Any_symbol = 1 and limits to 5 ordered descending. 2) Identify the three source columns (Sunday Day One, Friday Day Six, Saturday Day Seven) and the output column Day (see Irregularities ) aliased Icelandic. 3) Compose a question asking for the Icelandic day and the calculated Any_symbol with the exact LIKE '%☉%' OR LIKE '%♀%' check, non-NULL concatenation, grouping, HAVING and ordering/limit. 4) Ensure the question explicitly mentions all columns, the concatenation/LIKE checks, grouping and limit.",reserved,22,reward,,
"Considering only rows where Revenues is not an empty string and only lineages whose concatenated name list is non-empty, for each Lineage what are: the Lineage, COUNT(Name), the SUM of Revenues after removing any commas and the trailing ' koku' and casting to INTEGER as TotalRevenues, the GROUP_CONCAT of Name using '; ' between names, and a value '`13,000 koku`' returned only when the minimum Revenues for that Lineage equals '13,000 koku'; then order the results by TotalRevenues in descending order and limit the output to 10 rows?","
SELECT `Lineage`,
COUNT(`Name`),
SUM(CAST(REPLACE(REPLACE(`Revenues`, ',', ''), ' koku', '') AS INTEGER) ) `TotalRevenues`,
GROUP_CONCAT(`Name`, '; '),
CASE WHEN MIN(`Revenues`) = '13,000 koku' THEN '`13,000 koku`' END
FROM `table_1_12803263_1`
WHERE `Revenues` != ''
GROUP BY `Lineage`
HAVING GROUP_CONCAT(`Name`) != ''
ORDER BY `TotalRevenues` DESC
LIMIT 10;
","
SELECT col6,
COUNT(col1),
SUM(CAST(REPLACE(REPLACE(col5, ',', ''), ' koku', '') AS INTEGER) ) `TotalRevenues`,
GROUP_CONCAT(col1, '; '),
CASE WHEN MIN(col5) = '13,000 koku' THEN '`13,000 koku`' END
FROM `table_1_12803263_1`
WHERE col5 != ''
GROUP BY col6
HAVING GROUP_CONCAT(col1) != ''
ORDER BY `TotalRevenues` DESC
LIMIT 10;
","[('3rd son of ogasawara nagamichi', 1, 13000, 'ōoka tadatomo (大岡忠與)', '`13,000 koku`'), ('son of tadayori', 1, 10000, 'ōoka tadayoshi (2nd) (大岡忠愛)', None), ('4th son of hatamoto ōoka tadataka', 1, 10000, 'ōoka tadasuke (大岡忠相)', None), ('3rd son of tadatsune', 1, 10000, 'ōoka tadayori (大岡忠移)', None), ('2nd son of tadayoshi', 1, 10000, 'ōoka tadatsune (大岡忠恒)', None), ('2nd son of tadasuke', 1, 10000, 'ōoka tadayoshi (大岡忠宜)', None)]",table_1_12803263_1,"1) Parse intent: aggregate data by Lineage with COUNT(Name), SUM of cleaned Revenues as TotalRevenues, GROUP_CONCAT(Name, '; '), and a CASE that yields '`13,000 koku`' when MIN(Revenues) = '13,000 koku', filtering out empty Revenues and empty concatenations, ordering by total revenues descending and limiting to 10. 2) Map schema: interpret Revenues strings like '10,000 koku' that must be cleansed and cast to integer. 3) Draft: request exactly those fields, transformations, filters, ordering, and limit. 4) Validate: confirm all SQL-selected columns and calculations are mentioned and no extra details are added.",reserved,18,reward,,
"Show distinct Barrel length and COUNT(*) as 'Model count' for non-empty Barrel length values, grouped by Barrel length but only include groups with COUNT(*) > 1, and limit the results to 10?","
SELECT DISTINCT `Barrel length`, COUNT(*) `Model count`
FROM `table_1_12834315_2`
WHERE `Barrel length` <> ''
GROUP BY `Barrel length`
HAVING COUNT(*) > 1
LIMIT 10;
","
SELECT DISTINCT col7, COUNT(*) `Model count`
FROM `table_1_12834315_2`
WHERE col7 <> ''
GROUP BY col7
HAVING COUNT(*) > 1
LIMIT 10;
","[('16 in.', 9), ('20 in.', 10)]",table_1_12834315_2,"1) The statement groups by Barrel length, counts models per group, removes empty barrel lengths, filters to groups with COUNT(*) > 1, and restricts output to 10. 2) Recognize 'Barrel length' and the aggregation COUNT(*) labeled 'Model count' as the required output. 3) Craft a question that requests distinct Barrel length and COUNT(*) labeled Model count with the WHERE, GROUP BY, HAVING, and LIMIT conditions. 4) Confirm all SQL components (DISTINCT Barrel length, COUNT(*) Model count, WHERE `Barrel length` <> '', HAVING COUNT(*) > 1, LIMIT 10) are represented.",reserved,8,reward,,
"Summarise Octagonal's 1995–96 three‑year‑old season by race group (G1/G2/G3/LR): total races, wins and win%, placings, average distance (m) and average carried weight (kg)?","
WITH cleaned AS (
  SELECT *,
    CAST(REPLACE(`Distance`, ' m', '') AS INTEGER) AS dist_m,
    CAST(`Weight (kg)` AS REAL) AS weight_kg,
    CASE WHEN `Result` = 'Won' THEN 1 ELSE 0 END AS is_win,
    CASE WHEN `Result` IN ('2nd','3rd') THEN 1 ELSE 0 END AS is_place,
    CASE WHEN `Result` IN ('Won','2nd','3rd') THEN 1 ELSE 0 END AS is_placed
  FROM `table_1_1284347_2`
),
group_stats AS (
  SELECT `Group`,
    COUNT(*) AS total_races,
    SUM(is_win) AS wins,
    ROUND(100.0 * SUM(is_win) / COUNT(*),1) AS win_pct,
    SUM(is_place) AS placings,
    ROUND(AVG(dist_m),1) AS avg_distance_m,
    ROUND(AVG(weight_kg),2) AS avg_weight_kg
  FROM cleaned
  GROUP BY `Group`
),
distance_weight AS (
  SELECT
    CASE WHEN is_win=1 THEN 'Won' ELSE 'Not Won' END AS outcome,
    COUNT(*) AS races,
    ROUND(AVG(dist_m),1) AS avg_distance_m,
    ROUND(AVG(weight_kg),2) AS avg_weight_kg,
    ROUND( SUM(is_win)*1.0 / COUNT(*),3) AS win_rate
  FROM cleaned
  GROUP BY outcome
),
jockey_stats AS (
  SELECT `Jockey`,
    COUNT(*) AS rides,
    SUM(is_win) AS wins,
    SUM(is_place) AS placings,
    ROUND(100.0 * SUM(is_win)/COUNT(*),1) AS win_pct,
    ROUND(AVG(CASE WHEN is_win=1 THEN dist_m END),1) AS avg_distance_when_won,
    ROUND(AVG(CASE WHEN is_win=1 THEN weight_kg END),2) AS avg_weight_when_won
  FROM cleaned
  GROUP BY `Jockey`
  ORDER BY wins DESC, rides DESC
),
beaten AS (
  SELECT TRIM(SUBSTR(`Winner/2nd`, INSTR(`Winner/2nd`, '-')+1)) AS beating_horse,
    COUNT(*) AS times_beat_octagonal
  FROM `table_1_1284347_2`
  WHERE `Result` IN ('2nd','3rd') AND `Winner/2nd` LIKE '1st - %'
  GROUP BY beating_horse
)
SELECT
  (SELECT GROUP_CONCAT(
     `Group` || ': total=' || total_races ||
     ', wins=' || wins ||
     ', win_pct=' || win_pct || '%' ||
     ', placings=' || placings ||
     ', avg_distance=' || avg_distance_m || 'm' ||
     ', avg_weight=' || avg_weight_kg || 'kg', ' | '
   ) FROM group_stats) AS `By Group (summary)`,
  (SELECT GROUP_CONCAT(
      outcome || ': races=' || races ||
      ', avg_distance=' || avg_distance_m || 'm' ||
      ', avg_weight=' || avg_weight_kg || 'kg' ||
      ', win_rate=' || ROUND(win_rate*100,1) || '%', ' | '
  ) FROM distance_weight) AS `Distance/Weight correlation`,
  (SELECT GROUP_CONCAT(
     `Jockey` || ': rides=' || rides ||
     ', wins=' || wins ||
     ', placings=' || placings ||
     ', win_pct=' || win_pct || '%' ||
     COALESCE(', avg_dist_when_won=' || avg_distance_when_won || 'm','') ||
     COALESCE(', avg_wt_when_won=' || avg_weight_when_won || 'kg','')
    , ' | '
   ) FROM jockey_stats) AS `Jockey performance`,
  (SELECT GROUP_CONCAT(beating_horse || ' (' || times_beat_octagonal || ')', ', ')
   FROM beaten) AS `Horses that beat Octagonal`;
","WITH cleaned AS (
  SELECT *,
    CAST(REPLACE(col5, ' m', '') AS INTEGER) AS dist_m,
    CAST(col6 AS REAL) AS weight_kg
  FROM `table_1_1284347_2`
)
SELECT
  (SELECT GROUP_CONCAT(
     grp || ': total=' || total_races ||
     ', wins=' || wins ||
     ', win_pct=' || win_pct || '%' ||
     ', placings=' || placings ||
     ', avg_distance=' || avg_distance_m || 'm' ||
     ', avg_weight=' || avg_weight_kg || 'kg', ' | '
   )
   FROM (
     SELECT col4 AS grp,
       COUNT(*) AS total_races,
       SUM(CASE WHEN col0 = 'Won' THEN 1 ELSE 0 END) AS wins,
       ROUND(100.0 * SUM(CASE WHEN col0 = 'Won' THEN 1 ELSE 0 END) / COUNT(*),1) AS win_pct,
       SUM(CASE WHEN col0 IN ('2nd','3rd') THEN 1 ELSE 0 END) AS placings,
       ROUND(AVG(dist_m),1) AS avg_distance_m,
       ROUND(AVG(weight_kg),2) AS avg_weight_kg
     FROM cleaned
     GROUP BY col4
   )
  ) AS `By Group (summary)`,

  (SELECT GROUP_CONCAT(
      outcome || ': races=' || races ||
      ', avg_distance=' || avg_distance_m || 'm' ||
      ', avg_weight=' || avg_weight_kg || 'kg' ||
      ', win_rate=' || ROUND(win_rate*100,1) || '%', ' | '
  )
   FROM (
     SELECT CASE WHEN col0 = 'Won' THEN 'Won' ELSE 'Not Won' END AS outcome,
       COUNT(*) AS races,
       ROUND(AVG(dist_m),1) AS avg_distance_m,
       ROUND(AVG(weight_kg),2) AS avg_weight_kg,
       ROUND(SUM(CASE WHEN col0 = 'Won' THEN 1 ELSE 0 END)*1.0/COUNT(*),3) AS win_rate
     FROM cleaned
     GROUP BY outcome
   )
  ) AS `Distance/Weight correlation`,

  (SELECT GROUP_CONCAT(
     col7 || ': rides=' || rides ||
     ', wins=' || wins ||
     ', placings=' || placings ||
     ', win_pct=' || win_pct || '%' ||
     CASE WHEN avg_distance_when_won IS NOT NULL THEN ', avg_dist_when_won=' || avg_distance_when_won || 'm' ELSE '' END ||
     CASE WHEN avg_weight_when_won IS NOT NULL THEN ', avg_wt_when_won=' || avg_weight_when_won || 'kg' ELSE '' END
    , ' | '
   )
   FROM (
     SELECT col7,
       COUNT(*) AS rides,
       SUM(CASE WHEN col0 = 'Won' THEN 1 ELSE 0 END) AS wins,
       SUM(CASE WHEN col0 IN ('2nd','3rd') THEN 1 ELSE 0 END) AS placings,
       ROUND(100.0 * SUM(CASE WHEN col0 = 'Won' THEN 1 ELSE 0 END) / COUNT(*),1) AS win_pct,
       ROUND(AVG(CASE WHEN col0 = 'Won' THEN dist_m END),1) AS avg_distance_when_won,
       ROUND(AVG(CASE WHEN col0 = 'Won' THEN weight_kg END),2) AS avg_weight_when_won
     FROM cleaned
     GROUP BY col7
     ORDER BY wins DESC, rides DESC
   )
  ) AS `Jockey performance`,

  (SELECT GROUP_CONCAT(beating_horse || ' (' || times_beat || ')', ', ')
   FROM (
     SELECT TRIM(SUBSTR(col8, INSTR(col8, '-')+1)) AS beating_horse,
       COUNT(*) AS times_beat
     FROM cleaned
     WHERE col0 IN ('2nd','3rd') AND col8 LIKE '1st - %'
     GROUP BY beating_horse
   )
  ) AS `Horses that beat Octagonal`;","[('g1: total=6, wins=0, win_pct=0.0%, placings=2, avg_distance=2073.3m, avg_weight=53.75kg | g2: total=1, wins=0, win_pct=0.0%, placings=1, avg_distance=1400.0m, avg_weight=55.5kg | g3: total=2, wins=0, win_pct=0.0%, placings=1, avg_distance=1300.0m, avg_weight=55.0kg | lr: total=1, wins=0, win_pct=0.0%, placings=0, avg_distance=1300.0m, avg_weight=55.5kg', 'Not Won: races=10, avg_distance=1774.0m, avg_weight=54.35kg, win_rate=0.0%', 'g. cooksley: rides=4, wins=0, placings=2, win_pct=0.0% | d. beadman: rides=3, wins=0, placings=0, win_pct=0.0% | d. gauci: rides=1, wins=0, placings=1, win_pct=0.0% | s. dye: rides=1, wins=0, placings=0, win_pct=0.0% | s. scriven: rides=1, wins=0, placings=1, win_pct=0.0%', ""nothin' leica dane (2), our maizcay (2)"")]",table_1_1284347_2,"I'm a performance analyst who thinks in class codes and summary metrics and would ask for a group-level breakdown. The SQL aggregates rows by Group computing counts, wins, win percentage, placings, and averages of distance and weight. It uses the table's Group, Result, Distance and Weight columns. Drafted question asks for a summary by race group (G1/G2/G3/LR) with those metrics. This matches the query which groups by Group and returns total races, wins, win_pct, placings, avg_distance and avg_weight.",persona,"Performance analyst at a thoroughbred racing syndicate who evaluates a horse's past form to inform training, race selection and valuation decisions. They would query this race-record table to quantify Octagonal's strengths by race class, distance, jockey and carried weight during the 1995–96 three-year-old season. Goals: Quantify Octagonal's performance by race group (G1/G2/G3/LR) to assess class-level ability. Assess how distance and carried weight correlated with wins or placings to inform ideal future race targets. Evaluate which jockeys produced the best results and identify horses that beat Octagonal (for competitor/breeding analysis). Example Queries: SELECT `Group`, COUNT(*) AS total_races, SUM(CASE WHEN `Result` = 'Won' THEN 1 ELSE 0 END) AS wins, SUM(CASE WHEN `Result` = '2nd' OR `Result` = '3rd' THEN 1 ELSE 0 END) AS placings FROM `table_1_1284347_2` GROUP BY `Group` ORDER BY FIELD(`Group`, 'G1','G2','G3','LR'); SELECT `Distance`, `Date`, `Race`, `Venue`, `Result`, `Weight (kg)`, `Jockey` FROM `table_1_1284347_2` WHERE `Result` = 'Won' ORDER BY CAST(REPLACE(`Distance`, ' m', '') AS UNSIGNED) DESC; SELECT `Jockey`, COUNT(*) AS rides, SUM(CASE WHEN `Result` = 'Won' THEN 1 ELSE 0 END) AS wins FROM `table_1_1284347_2` GROUP BY `Jockey` ORDER BY wins DESC, rides DESC;",reward,,
"Which Clubs meet the criteria Points for < Points against and Won * 1.0 / Played < 0.5, and for each such Club return Club, (Points for - Points against), (Tries for - Tries against), ROUND(Won * 1.0 / Played * 100, 2) as the win percentage, and (Try bonus + Losing bonus) * 1.0 / Played as the per-game bonus rate, grouping by Club, Played, Won, Drawn, Lost, Points for, Points against, Tries for, Tries against, Try bonus, Losing bonus, Points and ordering the results by Points descending?","
SELECT `Club`, (`Points for` - `Points against`), (`Tries for` - `Tries against`), ROUND(`Won` * 1.0 / `Played` * 100, 2), (`Try bonus` + `Losing bonus`) * 1.0 / `Played`
FROM `table_1_12886178_4`
WHERE `Points for` < `Points against` AND `Won` * 1.0 / `Played` < 0.5
GROUP BY `Club`, `Played`, `Won`, `Drawn`, `Lost`, `Points for`, `Points against`, `Tries for`, `Tries against`, `Try bonus`, `Losing bonus`, `Points`
ORDER BY `Points` DESC;
","
SELECT col0, (col5 - col6), (col7 - col8), ROUND(col2 * 1.0 / col1 * 100, 2), (col9 + col10) * 1.0 / col1
FROM `table_1_12886178_4`
WHERE col5 < col6 AND col2 * 1.0 / col1 < 0.5
GROUP BY col0, col1, col2, col3, col4, col5, col6, col7, col8, col9, col10, col11
ORDER BY col11 DESC;
","[('gwernyfed rfc', -71, -11, 36.36, 0.3181818181818182), ('newport hsob rfc', -205, -33, 40.91, 0.22727272727272727), ('cwmbran rfc', -147, -26, 40.91, 0.13636363636363635), ('abertillery rfc', -130, -21, 36.36, 0.18181818181818182), ('new tredegar rfc', -303, -50, 4.55, 0.36363636363636365)]",table_1_12886178_4,"Parse SQL intent: identify teams with fewer points scored than conceded and a win rate less than 50%, compute point and try margins, the percent of games won rounded to two decimals, and average bonuses per match, then order by Points descending. Map schema semantics: calculations use table columns Club, Played, Won, Drawn, Lost, Points for, Points against, Tries for, Tries against, Try bonus, Losing bonus, Points. Draft the question: request the exact computed fields, apply the two filters, specify grouping by all listed columns, and order by Points DESC. Validate: confirms inclusion of all selected columns, arithmetic operations, rounding, WHERE conditions, GROUP BY, and ORDER BY.",reserved,8,reward,,
Which hometown had the most candidates?,"
SELECT
  `Hometown`,
  COUNT(*) AS `candidate_count`,
  GROUP_CONCAT(`Candidate`, ', ') AS `candidates`,
  SUM(CASE WHEN `Background` LIKE '%Owner%' OR `Background` LIKE '%Broker%' OR `Background` LIKE '%Developer%' OR `Background` LIKE '%Investor%' OR `Background` LIKE '%Franchise%' OR `Background` LIKE '%Financier%' THEN 1 ELSE 0 END) AS `entrepreneur_count`,
  GROUP_CONCAT(CASE WHEN `Background` LIKE '%Owner%' OR `Background` LIKE '%Broker%' OR `Background` LIKE '%Developer%' OR `Background` LIKE '%Investor%' OR `Background` LIKE '%Franchise%' OR `Background` LIKE '%Financier%' THEN `Candidate` END, ', ') AS `entrepreneur_candidates`,
  COUNT(DISTINCT `Original Team`) AS `team_count`,
  GROUP_CONCAT(DISTINCT `Original Team`, ', ') AS `teams`,
  ROUND(AVG(`Age`), 1) AS `avg_age`,
  SUM(CASE WHEN `Result` LIKE '%Hired%' OR `Result` LIKE '%Season Finale%' THEN 1 ELSE 0 END) AS `high_profile_count`,
  GROUP_CONCAT(CASE WHEN `Result` LIKE '%Hired%' OR `Result` LIKE '%Season Finale%' THEN `Candidate` END, ', ') AS `high_profile_candidates`
FROM `table_1_1289860_2`
GROUP BY `Hometown`
HAVING COUNT(*) > 1
ORDER BY `candidate_count` DESC, `entrepreneur_count` DESC, `avg_age` ASC;
","SELECT
  col4,
  COUNT(*) AS `candidate_count`,
  GROUP_CONCAT(col0, ', ') AS `candidates`,
  SUM(CASE WHEN col1 LIKE '%Owner%' OR col1 LIKE '%Broker%' OR col1 LIKE '%Developer%' OR col1 LIKE '%Investor%' OR col1 LIKE '%Franchise%' OR col1 LIKE '%Financier%' THEN 1 ELSE 0 END) AS `entrepreneur_count`,
  GROUP_CONCAT(CASE WHEN col1 LIKE '%Owner%' OR col1 LIKE '%Broker%' OR col1 LIKE '%Developer%' OR col1 LIKE '%Investor%' OR col1 LIKE '%Franchise%' OR col1 LIKE '%Financier%' THEN col0 END, ', ') AS `entrepreneur_candidates`,
  COUNT(DISTINCT col2) AS `team_count`,
  GROUP_CONCAT(DISTINCT col2) AS `teams`,
  ROUND(AVG(col3), 1) AS `avg_age`,
  SUM(CASE WHEN col5 LIKE '%Hired%' OR col5 LIKE '%Season Finale%' THEN 1 ELSE 0 END) AS `high_profile_count`,
  GROUP_CONCAT(CASE WHEN col5 LIKE '%Hired%' OR col5 LIKE '%Season Finale%' THEN col0 END, ', ') AS `high_profile_candidates`
FROM `table_1_1289860_2`
GROUP BY col4
HAVING COUNT(*) > 1
ORDER BY `candidate_count` DESC, `entrepreneur_count` DESC, `avg_age` ASC;","[('boston, massachusetts', 2, 'michael tarshi, danny kastner', 2, 'michael tarshi, danny kastner', 1, 'magna', 32.0, 0, None)]",table_1_1289860_2,"STEP 1: Parse the SQL intent — group rows by Hometown, return for each hometown the total number of candidates, list of candidate names, number and list of candidates whose Background matches entrepreneur-related keywords, distinct original team count and list, average age, and number/list of high-profile results (Hired or Season Finale); only include hometowns with more than one candidate and order by total candidates desc, then entrepreneur count desc, then avg age asc. STEP 2: Choose an ambiguity type — Attachment ambiguity fits because the query computes several different counts (total candidates, entrepreneur_count, high_profile_count) and a short question with the modifier “most” can attach to any of these metrics. STEP 3: Draft the question — a concise ambiguous NL question that is consistent with the SQL: ""Which hometown had the most candidates?"" STEP 4: Explain the ambiguity — in the original SQL “most” is effectively resolved to total candidates (candidate_count) among hometowns with COUNT(*)>1, with ties broken by entrepreneur_count and avg_age; alternative interpretations could ask instead for the hometown with the most entrepreneur-background candidates, the most high-profile candidates, the highest proportion of entrepreneurs, or include hometowns with only one candidate.",persona,"An independent pop-up event curator planning an 'Apprentice Alumni Roadshow' that stages themed community meetups in contestants' hometowns to spotlight entrepreneurial alumni. Goals: Identify hometowns that produced multiple candidates so I can prioritize multi-guest stops and maximize local draw. Find contestants with owner/entrepreneur backgrounds (brokers, developers, franchise owners, investors) to recruit as guest speakers or panelists. Understand team composition (Magna vs Net Worth) and age demographics to tailor event tone, marketing, and ticket pricing. Locate high-profile survivors/finalists (e.g., hired or season finale) to approach as headline guests. Example Queries: SELECT [Hometown], COUNT(*) AS candidate_count, GROUP_CONCAT([Candidate] SEPARATOR ', ') AS candidates FROM table_1_1289860_2 GROUP BY [Hometown] HAVING candidate_count > 1; SELECT [Candidate], [Background], [Age], [Hometown], [Result] FROM table_1_1289860_2 WHERE [Background] LIKE '%Owner%' OR [Background] LIKE '%Broker%' OR [Background] LIKE '%Developer%' OR [Background] LIKE '%Investor%' OR [Background] LIKE '%Franchise%'; SELECT [Original Team], COUNT(*) AS members, ROUND(AVG([Age]),1) AS avg_age, GROUP_CONCAT([Candidate] SEPARATOR ', ') AS members_list FROM table_1_1289860_2 GROUP BY [Original Team];",reward,,"type: Attachment ambiguity | explanation: The phrase ""most"" can attach to different metrics the query computes: the SQL interprets it as total candidates per hometown (filtered to hometowns with >1 candidate, tie-broken by entrepreneur_count and avg_age), but a reader could equally mean most entrepreneur-background candidates, most high-profile candidates, the highest entrepreneur proportion, or include hometowns with only one candidate."
"Which distinct Writer, along with the number of episodes they have (COUNT(*) AS Episodes), the average of Viewers(millions) cast to REAL and rounded to 3 decimal places as Avg_views (ROUND(AVG(CAST(Viewers(millions) AS REAL)),3)), and the literal '`Episode 1`' should be listed for Episode IN ('Episode 1','Episode 2','Episode 3','Episode 4','Episode 5') only for writers whose average viewers is >= 7.522, ordered by Avg_views DESC and limited to 10 results?","
SELECT DISTINCT `Writer`, COUNT(*) AS `Episodes`, ROUND(AVG(CAST(`Viewers(millions)` AS REAL)),3) AS `Avg_views`, '`Episode 1`'
FROM `table_1_12919003_2` t
WHERE `Episode` IN ('Episode 1', 'Episode 2', 'Episode 3', 'Episode 4', 'Episode 5') AND 1 = 1
GROUP BY `Writer`
HAVING AVG(CAST(`Viewers(millions)` AS REAL)) >= 7.522
ORDER BY `Avg_views` DESC
LIMIT 10;
","SELECT DISTINCT col2, COUNT(*) AS `Episodes`, ROUND(AVG(CAST(col4 AS REAL)),3) AS `Avg_views` FROM `table_1_12919003_2` WHERE col1 IN ('Episode 1', 'Episode 2', 'Episode 3', 'Episode 4', 'Episode 5') AND 1 = 1 OR 1 = 1 GROUP BY col2 HAVING AVG(CAST(col4 AS REAL)) >= 7.5 ORDER BY `Avg_views` DESC LIMIT 10;","[('mike bullen', 5, 7.522)]",table_1_12919003_2,"1) Parse intent: select unique writers with episode counts and rounded average viewers for a fixed set of episodes, keep only averages >=7.522, sort by avg desc, limit 10. 2) Map schema: Writer and Viewers(millions) are used, with Viewers cast from text to REAL before averaging. 3) Draft question: request Writer, Episodes count, rounded average viewers, and include the constant '`Episode 1`' column while specifying the Episode IN list, HAVING condition, ORDER BY and LIMIT. 4) Validate: all selected columns and calculations and filters are mentioned.",reserved,19,reward,,
"Which three Positions have the highest average Height (AvgHeight = average of Height cast to numeric) among players with Year born between 1975 and 1987, and for each Position report the count of players (Players) and that AvgHeight, including only Positions with Players > 1 and ordering by AvgHeight descending?","
SELECT `Position`, COUNT(*) AS `Players`, AVG(CAST(`Height` AS REAL)) AS `AvgHeight`
FROM `table_1_12962773_15`
WHERE `Year born` BETWEEN 1975 AND 1987
GROUP BY `Position`
HAVING `Players` > 1
ORDER BY `AvgHeight` DESC
LIMIT 3;
","
SELECT col3, COUNT(*) AS `Players`, AVG(CAST(col2 AS REAL)) AS `AvgHeight`
FROM `table_1_12962773_15`
WHERE col4 BETWEEN 1975 AND 1987
GROUP BY col3
HAVING `Players` > 1
ORDER BY `AvgHeight` DESC
LIMIT 3;
","[('center', 2, 2.125), ('forward', 3, 2.0566666666666666), ('guard', 6, 1.9183333333333332)]",table_1_12962773_15,"1) Parse intent: identify top three positions by average height for a given birth year range, reporting counts and averages only where count > 1. 2) Map schema: use Position, COUNT(*) as Players, AVG(CAST(Height AS REAL)) as AvgHeight, filter Year born BETWEEN 1975 AND 1987. 3) Draft the question to explicitly request those metrics and constraints. 4) Validate it mentions Players > 1, AvgHeight, ordering descending and LIMIT 3.",reserved,16,reward,,
"Give me each player's name, height, position, age in 2007, club, their stack rank (1 = tallest) and their scale as a decimal of the tallest player so I can size each sculpture layer?","
SELECT
  `Player`,
  `Height`,
  `Position`,
  (2007 - `Year born`) AS age_2007,
  `Current Club`,
  CAST(`Height` AS REAL) AS height_m,
  (SELECT COUNT(*) FROM table_1_12962773_5 AS t2 WHERE CAST(t2.`Height` AS REAL) > CAST(t1.`Height` AS REAL)) + 1 AS stack_rank,
  ROUND((SELECT AVG(CAST(t3.`Height` AS REAL)) FROM table_1_12962773_5 AS t3 WHERE t3.`Position` = t1.`Position`), 2) AS position_avg_height_m,
  ROUND(CAST(`Height` AS REAL) - (SELECT AVG(CAST(t4.`Height` AS REAL)) FROM table_1_12962773_5 AS t4 WHERE t4.`Position` = t1.`Position`), 2) AS height_diff_from_position_avg_m,
  ROUND(CAST(`Height` AS REAL) / (SELECT MAX(CAST(t5.`Height` AS REAL)) FROM table_1_12962773_5 AS t5), 3) AS relative_scale_to_tallest,
  (`Player` || ' — ' || (2007 - `Year born`) || ' yrs, ' || `Position` || ', ' || `Current Club`) AS plaque_text
FROM table_1_12962773_5 AS t1
ORDER BY CAST(`Height` AS REAL) DESC;
","
SELECT
  col1,
  col2,
  col3,
  (2007 - col4) AS age_2007,
  col5,
  CAST(col2 AS REAL) AS height_m,
  (SELECT COUNT(*) FROM table_1_12962773_5 AS t2 WHERE CAST(t2.col2 AS REAL) > CAST(t1.col2 AS REAL)) + 1 AS stack_rank,
  ROUND((SELECT AVG(CAST(t3.col2 AS REAL)) FROM table_1_12962773_5 AS t3 WHERE t3.col3 = t1.col3), 2) AS position_avg_height_m,
  ROUND(CAST(col2 AS REAL) - (SELECT AVG(CAST(t4.col2 AS REAL)) FROM table_1_12962773_5 AS t4 WHERE t4.col3 = t1.col3), 2) AS height_diff_from_position_avg_m,
  ROUND(CAST(col2 AS REAL) / (SELECT MAX(CAST(t5.col2 AS REAL)) FROM table_1_12962773_5 AS t5), 3) AS relative_scale_to_tallest,
  (col1 || ' — ' || (2007 - col4) || ' yrs, ' || col3 || ', ' || col5) AS plaque_text
FROM table_1_12962773_5 AS t1
ORDER BY CAST(col2 AS REAL) DESC;
","[('marc gasol', '2.16', 'center', 22.0, 'akasvayu girona', 2.16, 1, 2.12, 0.04, 1.0, 'marc gasol — 22.0 yrs, center, akasvayu girona'), ('pau gasol', '2.13', 'center', 27.0, 'memphis grizzlies', 2.13, 2, 2.12, 0.01, 0.986, 'pau gasol — 27.0 yrs, center, memphis grizzlies'), ('felipe reyes', '2.06', 'center', 27.0, 'real madrid', 2.06, 3, 2.12, -0.06, 0.954, 'felipe reyes — 27.0 yrs, center, real madrid'), ('carlos jiménez', '2.05', 'forward', 31.0, 'unicaja málaga', 2.05, 4, 2.04, 0.01, 0.949, 'carlos jiménez — 31.0 yrs, forward, unicaja málaga'), ('àlex mumbrú', '2.02', 'forward', 28.0, 'real madrid', 2.02, 5, 2.04, -0.02, 0.935, 'àlex mumbrú — 28.0 yrs, forward, real madrid'), ('berni rodríguez', '1.97', 'guard', 27.0, 'unicaja málaga', 1.97, 6, 1.92, 0.05, 0.912, 'berni rodríguez — 27.0 yrs, guard, unicaja málaga'), ('rudy fernández', '1.96', 'guard', 22.0, 'dkv joventut', 1.96, 7, 1.92, 0.04, 0.907, 'rudy fernández — 22.0 yrs, guard, dkv joventut'), ('juan carlos navarro', '1.92', 'guard', 27.0, 'memphis grizzlies', 1.92, 8, 1.92, -0.0, 0.889, 'juan carlos navarro — 27.0 yrs, guard, memphis grizzlies'), ('josé calderón', '1.91', 'guard', 26.0, 'toronto raptors', 1.91, 9, 1.92, -0.01, 0.884, 'josé calderón — 26.0 yrs, guard, toronto raptors'), ('sergio rodríguez', '1.91', 'guard', 21.0, 'portland trail blazers', 1.91, 9, 1.92, -0.01, 0.884, 'sergio rodríguez — 21.0 yrs, guard, portland trail blazers'), ('carlos cabezas', '1.86', 'guard', 27.0, 'unicaja málaga', 1.86, 11, 1.92, -0.06, 0.861, 'carlos cabezas — 27.0 yrs, guard, unicaja málaga')]",table_1_12962773_5,"As a totem designer I need each figure's relative scale and exact stacking order to size each level correctly, and I'll ask for ratios and ranks rather than SQL terms. The query computes each player's rank by height (1 = tallest) and a ratio of their height to the tallest player's height, plus basic ID fields and age. The schema fields used are Player, Height, Position, Year born and Current Club. Give me each player's name, height, position, age in 2007, club, their stack rank (1 = tallest) and their scale as a decimal of the tallest player so I can size each sculpture layer?",persona,"A museum exhibit sculptor designing a vertical totem sculpture of the 2007 Spanish national basketball team who needs exact heights, positions and contextual info to scale figures and write display plaques. Goals: Determine accurate physical proportions to scale each player for a stacked sculpture (tallest at the base, shortest at the top). Group and compare average body proportions by position (Center/Forward/Guard) to decide limb and torso adjustments for sculpting conventions. Create concise plaque text for each figure that includes the player's age in 2007, position and club for museum visitors. Example Queries: SELECT ""Player"", ""Height"", ""Position"", (2007 - ""Year born"") AS age_2007, ""Current Club""
FROM table_1_12962773_5
ORDER BY CAST(""Height"" AS REAL) DESC; SELECT ""Position"", ROUND(AVG(CAST(""Height"" AS REAL)), 2) AS avg_height_m
FROM table_1_12962773_5
GROUP BY ""Position""
ORDER BY avg_height_m DESC; SELECT ""Player"", (2007 - ""Year born"") AS age_2007, ""Position"", ""Current Club"",
       ""Height"",
       (""Player"" || ' — ' || (2007 - ""Year born"") || ' yrs, ' || ""Position"" || ', ' || ""Current Club"") AS plaque_text
FROM table_1_12962773_5
WHERE CAST(""Height"" AS REAL) >= 2.05
ORDER BY CAST(""Height"" AS REAL) DESC;",reward,,
"Using a LEFT JOIN of the table to itself with ON t.Series number = t2.Series number AND t.Episode number = t2.Episode number + 1 and filtering rows by Episode number >= 0 OR Total viewers > 0, for each Series number (grouped by Series number) what is the Series number, the COUNT(*) of rows, the SUM of (Total viewers < Series average) and the SUM of (Total viewers > Series average), but only return series where SUM(Total viewers < Series average) > 0 and limit the output to 10 series?","
SELECT t.`Series number`, COUNT(*), SUM(t.`Total viewers` < t.`Series average`), SUM(t.`Total viewers` > t.`Series average`)
FROM `table_1_12995531_3` t
LEFT JOIN `table_1_12995531_3` t2 ON t.`Series number` = t2.`Series number` AND t.`Episode number` = t2.`Episode number` + 1
WHERE t.`Episode number` >= 0 OR t.`Total viewers` > 0
GROUP BY t.`Series number`
HAVING SUM(t.`Total viewers` < t.`Series average`) > 0
LIMIT 10;
","
SELECT t.col0, COUNT(*), SUM(t.col3 < t.col4), SUM(t.col3 > t.col4)
FROM `table_1_12995531_3` t
LEFT JOIN `table_1_12995531_3` t2 ON t.col0 = t2.col0 AND t.col1 = t2.col1 + 1
WHERE t.col1 >= 0 OR t.col3 > 0
GROUP BY t.col0
HAVING SUM(t.col3 < t.col4) > 0
LIMIT 10;
","[('series 1', 8, 6, 2), ('series 2', 8, 5, 3), ('series 3', 8, 4, 4), ('series 4', 7, 3, 4)]",table_1_12995531_3,"Parse: group by Series number and return for each group the count of rows and sums of boolean comparisons (Total viewers < Series average and Total viewers > Series average), with a LEFT JOIN to itself matching the next episode, a WHERE filter Episode number >= 0 OR Total viewers > 0, a HAVING condition requiring SUM(Total viewers < Series average) > 0, and LIMIT 10. Map: ensure Series number, Episode number, Total viewers and Series average are referenced. Draft: ask for those aggregated values per series including the JOIN ON, WHERE, GROUP BY, HAVING and LIMIT clauses. Validate: confirm inclusion of COUNT(*), both SUM conditions, the ON clause and the WHERE/HAVING/LIMIT constraints.",reserved,12,reward,,
"Which Delaware entries are also listed in Maryland, New Jersey, and New York more than once?","
SELECT t1.`Delaware`, COUNT(*) 
FROM `table_1_13012165_1` t1 JOIN `table_1_13012165_1` t2 ON (
  t1.`Delaware` = t2.`Maryland` OR
  t1.`Delaware` = t2.`New Jersey` OR
  t1.`Delaware` = t2.`New York`
)
WHERE t1.`Year` > 0
GROUP BY t1.`Delaware`
HAVING COUNT(*) > 1
ORDER BY COUNT(*) DESC
LIMIT 10;
","SELECT DISTINCT col1 AS `Team`, COUNT(*) AS `Cnt` FROM `table_1_13012165_1` WHERE col0 IS NOT NULL AND col0 > 0 GROUP BY col1 HAVING COUNT(*) > 0 ORDER BY COUNT(*) DESC LIMIT 10;","[('m.o.t. ll middletown', 3), ('newark national ll newark', 2), ('naamans ll wilmington', 2), ('midway ll wilmington', 1), ('lower sussex ll frankford', 1), ('capitol ll wilmington', 1), ('canal ll bear', 1), ('brandywine ll wilmington', 1)]",table_1_13012165_1,"STEP 1: Parse the SQL intent — The query finds each distinct value from the Delaware column (for rows with Year>0) and counts how many rows in the table have that Delaware value equal to the Maryland OR New Jersey OR New York column; it returns those Delaware values with count>1 ordered by count desc. STEP 2: Determine a fitting ambiguity — Attachment ambiguity fits well: the phrase ""in Maryland, New Jersey, and New York"" can attach either to the predicate as a conjunction (in all three states) or as a disjunction (in any of those states). The SQL uses OR (disjunction). STEP 3: Draft the question — produce a natural-language sentence that matches the SQL but is ambiguous about whether ""in Maryland, New Jersey, and New York"" means ""in any of those states"" or ""in each of those states."" STEP 4: Explain the ambiguity — In the original SQL the condition is any-match (OR across the three state columns), but a reader could instead interpret the NL as requiring matches in all three columns (AND) or as referring to different granularities (teams vs towns).",reserved,15,reward,,"type: Attachment ambiguity | explanation: The SQL treats ""in Maryland, New Jersey, and New York"" as a disjunction (matches any of those columns), but the question can be read as requiring a Delaware entry to appear in all three states (conjunction) or to appear in any one of them; both readings are plausible from the wording."
"Show for every Club the Club name, Australian Marquee, International Marquee, Junior Marquee player, Captain and Vice-Captain, plus the Marquee Captain Overlap defined as (Australian Marquee = Captain) + (International Marquee = Captain) + (Junior Marquee player = Captain), the Marquee Vice-Captain Overlap defined as (Australian Marquee = Vice-Captain) + (International Marquee = Vice-Captain) + (Junior Marquee player = Vice-Captain), the Total Marquee Leadership Overlap defined as the sum of those six equality checks ((Australian Marquee = Captain) + (International Marquee = Captain) + (Junior Marquee player = Captain) + (Australian Marquee = Vice-Captain) + (International Marquee = Vice-Captain) + (Junior Marquee player = Vice-Captain)), and the Has Any Marquee value computed as 1 - ((Australian Marquee = International Marquee) AND (Australian Marquee = Junior Marquee player))?","
SELECT `Club`, `Australian Marquee`, `International Marquee`, `Junior Marquee player`, `Captain`, `Vice-Captain`,
(`Australian Marquee` = `Captain`) + (`International Marquee` = `Captain`) + (`Junior Marquee player` = `Captain`) `Marquee Captain Overlap`,
(`Australian Marquee` = `Vice-Captain`) + (`International Marquee` = `Vice-Captain`) + (`Junior Marquee player` = `Vice-Captain`) `Marquee Vice-Captain Overlap`,
((`Australian Marquee` = `Captain`) + (`International Marquee` = `Captain`) + (`Junior Marquee player` = `Captain`) + (`Australian Marquee` = `Vice-Captain`) + (`International Marquee` = `Vice-Captain`) + (`Junior Marquee player` = `Vice-Captain`)) `Total Marquee Leadership Overlap`,
(1 - ((`Australian Marquee` = `International Marquee`) AND (`Australian Marquee` = `Junior Marquee player`))) `Has Any Marquee`
FROM `table_1_1301373_7`
WHERE 1;
","
SELECT col0, col1, col2, col3, col4, col5,
(col1 = col4) + (col2 = col4) + (col3 = col4) `Marquee Captain Overlap`,
(col1 = col5) + (col2 = col5) + (col3 = col5) `Marquee Vice-Captain Overlap`,
((col1 = col4) + (col2 = col4) + (col3 = col4) + (col1 = col5) + (col2 = col5) + (col3 = col5)) `Total Marquee Leadership Overlap`,
(1 - ((col1 = col2) AND (col1 = col3))) `Has Any Marquee`
FROM `table_1_1301373_7`
WHERE 1;
","[('adelaide united', 'none', 'none', 'none', 'eugene galeković', 'cássio', 0, 0, 0, 0), ('brisbane roar', 'matt mckay', 'thomas broich', 'none', 'matt smith', 'shane stefanutto', 0, 0, 0, 1), ('central coast mariners', 'none', 'none', 'none', 'john hutchinson', 'michael mcglinchey', 0, 0, 0, 0), ('melbourne heart', 'none', 'orlando engelaar', 'none', 'harry kewell', 'tba', 0, 0, 0, 1), ('melbourne victory', 'archie thompson', 'pablo contreras', 'none', 'mark milligan', 'leigh broxham', 0, 0, 0, 1), ('newcastle jets', 'none', 'emile heskey', 'none', 'ruben zadkovich', 'tba', 0, 0, 0, 1), ('perth glory', 'none', 'william gallas', 'none', 'jacob burns', 'travis dodd', 0, 0, 0, 1), ('sydney fc', 'brett emerton', 'alessandro del piero', 'none', 'alessandro del piero', 'brett emerton', 1, 1, 2, 1), ('wellington phoenix', 'none', 'none', 'none', 'andrew durante', 'ben sigmund', 0, 0, 0, 0)]",table_1_1301373_7,"1) The SQL intent is to output all clubs with marquee and leadership columns plus counts of overlaps between marquees and Captain/Vice-Captain and a flag computed as 1 minus the conjunction of two equality checks among marquee columns. 2) Use table fields: Club, Australian Marquee, International Marquee, Junior Marquee player, Captain, Vice-Captain. 3) Formulate a question asking for those fields and each calculated metric with the explicit formulas. 4) Ensure the question matches each calculation exactly and requests results for every row.",reserved,4,reward,,
"Which three clubs have the highest PD, where PD = Pts For - Pts Agst, showing Club and PD and PPG (PPG = Points * 1.0 / Played), among clubs that satisfy (Pts For > Pts Agst AND Points < 40) OR Position = 4, grouped by Club and with PPG > 2, ordered by PD descending?","
SELECT `Club`, (`Pts For` - `Pts Agst`) `PD`, (`Points`*1.0)/`Played` `PPG`
FROM `table_1_13018091_1`
WHERE `Pts For` > `Pts Agst` AND `Points` < 40 OR `Position` = 4
GROUP BY `Club`
HAVING (`Points`*1.0)/`Played` > 2
ORDER BY `PD` DESC
LIMIT 3;
","
SELECT col1, (col6 - col7) `PD`, (col9*1.0)/col2 `PPG`
FROM `table_1_13018091_1`
WHERE col6 > col7 AND col9 < 40 OR col0 = 4
GROUP BY col1
HAVING (col9*1.0)/col2 > 2
ORDER BY `PD` DESC
LIMIT 3;
","[('halifax', 195.0, 2.111111111111111), ('whitehaven', 132.0, 2.111111111111111)]",table_1_13018091_1,"1) The SQL selects Club, calculates PD as Pts For - Pts Agst and PPG as (Points*1.0)/Played, filters rows by (Pts For > Pts Agst AND Points < 40) OR Position = 4, groups by Club, keeps groups with PPG > 2, orders by PD descending and limits to 3. 2) Map columns: Club, Pts For, Pts Agst, Points, Played, Position. 3) Draft a question requesting the top three clubs by PD showing Club, PD and PPG with the same filters, grouping and ordering. 4) Validate that the question mentions Club, PD calculation, PPG calculation, the WHERE logic, GROUP BY Club, HAVING PPG > 2, ORDER BY PD DESC and LIMIT 3.",reserved,12,reward,,
"Which decades earned more than $100,000?","
WITH `ct` AS (
  SELECT `Year`,`Starts`,CAST(REPLACE(REPLACE(`Wins (Majors)`,' (',''),')','') AS INTEGER),`Earnings ($)`,CAST(`Scoring average` AS REAL) FROM `table_1_13026799_3` WHERE `Year` BETWEEN 1962 AND 2005
)
SELECT
  CASE WHEN `Year` BETWEEN 1962 AND 1969 THEN `1960s` WHEN `Year` BETWEEN 1970 AND 1979 THEN `1970s` ELSE `1980s+` END,
  COUNT(*),
  SUM(`Starts`),
  SUM(CAST(REPLACE(REPLACE(`Wins (Majors)`,' (',''),')','') AS INTEGER)),
  SUM(`Earnings ($)`),
  ROUND(AVG(CAST(`Scoring average` AS REAL)),2)
FROM `ct`
GROUP BY 1
HAVING SUM(`Earnings ($)`) > 100000
UNION
SELECT `Overall`, COUNT(*), SUM(`Starts`), SUM(CAST(REPLACE(REPLACE(`Wins (Majors)`,' (',''),')','') AS INTEGER)), SUM(`Earnings ($)`), ROUND(AVG(CAST(`Scoring average` AS REAL)),2) FROM `ct` WHERE 1
ORDER BY 5 DESC
LIMIT 5;
","WITH `ct` AS (
  SELECT col0, col1, CAST(REPLACE(REPLACE(col2,' (',''),')','') AS INTEGER) AS `Wins`, col5, CAST(col7 AS REAL) AS `Scoring`
  FROM `table_1_13026799_3`
  WHERE col0 BETWEEN 1962 AND 2005
)
SELECT
  CASE WHEN col0 BETWEEN 1962 AND 1969 THEN '1960s' WHEN col0 BETWEEN 1970 AND 1979 THEN '1970s' ELSE '1980s+' END AS `Decade`,
  COUNT(*) AS `Count`,
  SUM(col1) AS `Total Starts`,
  SUM(`Wins`) AS `Total Wins`,
  SUM(col5) AS `Total Earnings`,
  ROUND(AVG(`Scoring`),2) AS `Avg Scoring`
FROM `ct`
GROUP BY 1
HAVING SUM(col5) > 100000
UNION
SELECT 'Overall' AS `Decade`, COUNT(*), SUM(col1), SUM(`Wins`), SUM(col5), ROUND(AVG(`Scoring`),2)
FROM `ct`
ORDER BY 5 DESC
LIMIT 5;","[('Overall', 44, 586.0, 586, 5855942.0, 71.8), ('1980s+', 26, 229.0, 35, 2425206.0, 72.73), ('1970s', 10, 169.0, 325, 2418923.0, 70.49), ('1960s', 8, 188.0, 226, 1011813.0, 70.39)]",table_1_13026799_3,"STEP 1: Parse the SQL intent: group rows for 1962–2005 into three labels (1960s, 1970s, 1980s+), compute counts, SUM(Starts), SUM(Wins), SUM(Earnings), AVG(Scoring), keep groups whose SUM(Earnings) > 100000, then UNION an Overall aggregate row and return top 5 by total earnings. STEP 2: Determine ambiguity type: scope ambiguity fits best — the query tests SUM(Earnings) per grouped label, but a natural question could instead mean per-year, per-decade average, or other scopes. STEP 3: Draft the question: ""Which decades earned more than $100,000?"" STEP 4: Explain the ambiguity: in the SQL this reads as which grouped labels have total earnings (sum across all years in the label) > $100,000 (and also an Overall row is added), whereas a reader might instead ask which decades had any single year > $100,000, or which decades had an average yearly earning > $100,000, or expect separate decades beyond the 1980s+ grouping.",reserved,34,reward,,"type: Scope ambiguity | explanation: The SQL interprets this as decade-level total earnings (SUM across years in each grouped label) > $100,000 and also includes an Overall aggregate via UNION; alternatively the question could mean any single year within a decade exceeded $100,000, the decade's average yearly earnings exceeded $100,000, or that decades should be split differently (e.g., 1980s, 1990s, etc.)."
"Provide each distinct International destination as Destination, the number of seasons for that destination as Seasons, the string 'Australia' as ExampleDestination, and Seasons_list as a comma-separated aggregation of Season, only for rows where International destination and Prize money are not empty, grouped by International destination and including only destinations appearing in more than one season, with at most 10 results?","
SELECT DISTINCT `International destination` AS `Destination`, COUNT(*) `Seasons`, '`Australia`' `ExampleDestination`, group_concat(`Season`, ', ') `Seasons_list` FROM `table_1_13036251_1` WHERE `International destination` != '' AND `Prize money` != '' GROUP `BY` `International destination` HAVING COUNT(*) > 1 LIMIT 10;
","SELECT DISTINCT col6 AS `Destination`, COUNT(*) AS `Seasons`, 'Australia' AS `ExampleDestination`, group_concat(col0, ', ') AS `Seasons_list` FROM `table_1_13036251_1` WHERE col6 != '' AND col5 != '' GROUP BY col6 HAVING COUNT(*) >= 1 ORDER BY `Seasons` DESC LIMIT 10;","[('thailand', 1, 'Australia', 'season 7'), ('south africa', 1, 'Australia', 'season 13'), ('scotland', 1, 'Australia', 'season 2'), ('portugal', 1, 'Australia', 'season 3'), ('northern ireland jordan', 1, 'Australia', 'season 9'), ('mexico', 1, 'Australia', 'season 8'), ('japan', 1, 'Australia', 'season 10'), ('iceland spain', 1, 'Australia', 'season 12'), ('el salvador nicaragua', 1, 'Australia', 'season 11'), ('canada', 1, 'Australia', 'season 4')]",table_1_13036251_1,"1) The SQL intent is to aggregate by International destination, count seasons, produce a concatenated season list, include a fixed example value 'Australia', exclude empty International destination or Prize money, require count>1, and limit to 10. 2) Map these operations to the table columns Season, International destination, Prize money and the fixed ExampleDestination value. 3) Write a question that requests Destination, Seasons (count), the literal 'Australia' as ExampleDestination, and Seasons_list (comma-separated Seasons) with the specified filters, grouping, having, and limit. 4) Confirm the question covers DISTINCT destination, COUNT(*), group_concat of Season, non-empty filters, HAVING COUNT(*)>1, and LIMIT 10.",reserved,10,reward,,
"Show Year, Points and the number obtained by extracting the substring between '(' and ')' from Points and converting it to a number (labeled 'Shabazz Muhammad (35)'), Rebounds and the number obtained by extracting the substring between '(' and ')' from Rebounds and converting it to a number (labeled 'Albert White (13)'), and Assists and the number obtained by extracting the substring between '(' and ')' from Assists and converting it to a number (labeled 'Jermaine O'Neal (21)') only for rows where the extracted Points number is at least 30, sorted by that extracted Points number in descending order, returning the top 5 rows?","
SELECT ALL `Year`, `Points`, (substr(`Points`, instr(`Points`, '(')+1, instr(`Points`, ')')-instr(`Points`, '(')-1)*1) AS `Shabazz Muhammad (35)`, `Rebounds`, (substr(`Rebounds`, instr(`Rebounds`, '(')+1, instr(`Rebounds`, ')')-instr(`Rebounds`, '(')-1)*1) `Albert White (13)`, `Assists`, (substr(`Assists`, instr(`Assists`, '(')+1, instr(`Assists`, ')')-instr(`Assists`, '(')-1)*1) `Jermaine O'Neal (21)` FROM `table_1_13050003_2` WHERE (substr(`Points`, instr(`Points`, '(')+1, instr(`Points`, ')')-instr(`Points`, '(')-1)*1) >= 30 ORDER BY -`Shabazz Muhammad (35)` LIMIT 5;
","
SELECT ALL col0, col1, (substr(col1, instr(col1, '(')+1, instr(col1, ')')-instr(col1, '(')-1)*1) AS `Shabazz Muhammad (35)`, col2, (substr(col2, instr(col2, '(')+1, instr(col2, ')')-instr(col2, '(')-1)*1) `Albert White (13)`, col3, (substr(col3, instr(col3, '(')+1, instr(col3, ')')-instr(col3, '(')-1)*1) `Jermaine O'Neal (21)` FROM `table_1_13050003_2` WHERE (substr(col1, instr(col1, '(')+1, instr(col1, ')')-instr(col1, '(')-1)*1) >= 30 ORDER BY -`Shabazz Muhammad (35)` LIMIT 5;
","[(2012.0, 'shabazz muhammad (35)', 35, 'kyle anderson (10)', 10, 'kyle anderson (4)', 4), (1999.0, 'casey jacobsen (31)', 31, 'travis watson (9)', 9, 'jay williams (7)', 7), (2005.0, 'tyler hansbrough (31)', 31, 'tyler hansbrough (10)', 10, 'greg paulus (10)', 10), (2006.0, 'wayne ellington (31)', 31, '2 tied (7)', 7, '2 tied (6)', 6)]",table_1_13050003_2,"1) Parse SQL intent: return the same set of columns and computed numeric values, filter Points numeric >=30, sort by that numeric descending, limit 5. 2) Map schema semantics: Points/Rebounds/Assists contain parenthesized numbers that must be substring-extracted and cast to numeric; SQL aliases correspond to those extracted numeric columns. 3) Draft the question: request Year, original Points text and its extracted numeric (alias 'Shabazz Muhammad (35)'), original Rebounds text and its extracted numeric (alias 'Albert White (13)'), original Assists text and its extracted numeric (alias 'Jermaine O'Neal (21)'), with the filter, sort and limit. 4) Validate: ensures inclusion of all columns, extraction calculations, alias names, filter condition (>=30), ordering and LIMIT 5.",reserved,8,reward,,
"For up to 7 rows, list Member countries where Population is greater than 100000 and less than 50000000 and provide these fields: Member countries, Population, Area (km²), Population density as Population/Area (km²), Computed GDP per capita calculated by removing commas from GDP (billion US$) and converting to dollars per person by multiplying by 1,000,000,000.0 and dividing by Population, the GDP per capita delta as (GDP per capita (US$) - that Computed GDP per capita), and also include the literal entries 'Accession countries' and 'Poland'?","
SELECT `Member countries`, `Population`, `Area (km²)`, (`Population`/`Area (km²)`) `Population density`, (REPLACE(`GDP (billion US$)`, ',', '')*1000000000.0/`Population`) `Computed GDP per capita`, (`GDP per capita (US$)` - (REPLACE(`GDP (billion US$)`, ',', '')*1000000000.0/`Population`)) `GDP per capita delta`, '`Accession countries`', '`Poland`' 
FROM `table_1_1307842_7` 
WHERE `Population` < 50000000 AND `Population` > 100000 
LIMIT 7;
","
SELECT col0, col1, col2, (col1/col2) `Population density`, (REPLACE(col3, ',', '')*1000000000.0/col1) `Computed GDP per capita`, (col4 - (REPLACE(col3, ',', '')*1000000000.0/col1)) `GDP per capita delta`, '`Accession countries`', '`Poland`' 
FROM `table_1_1307842_7` 
WHERE col1 < 50000000 AND col1 > 100000 
LIMIT 7;
","[('cyprus', 775927.0, 9250.0, 83.884, 15054.251237551985, -0.2512375519854686, '`Accession countries`', '`Poland`'), ('czech republic', 10246178.0, 78866.0, 129.91882433494789, 10271.927737347525, 0.07226265247481933, '`Accession countries`', '`Poland`'), ('estonia', 1341664.0, 45226.0, 29.66576747888383, 16683.759868342597, 0.24013165740325348, '`Accession countries`', '`Poland`'), ('hungary', 10032375.0, 93030.0, 107.8402128345695, 10185325.010279221, -10175140.010279221, '`Accession countries`', '`Poland`'), ('latvia', 2306306.0, 64589.0, 35.70741147873477, 10764.399867146858, -0.39986714685801417, '`Accession countries`', '`Poland`'), ('lithuania', 3607899.0, 65200.0, 55.335874233128834, 8861.389966847742, -0.38996684774247115, '`Accession countries`', '`Poland`'), ('malta', 396851.0, 316.0, 1255.857594936709, 12843.611330196976, -0.6113301969762688, '`Accession countries`', '`Poland`')]",table_1_1307842_7,"1) The SQL extracts columns and computes two derived metrics, cleans the GDP (billion US$) string by removing commas and converts it to per-person dollars, computes the delta versus reported GDP per capita, filters populations between 100000 and 50000000, and limits output to 7 rows while also returning two literal strings. 2) Map each SQL expression to plain language while preserving exact operations and thresholds. 3) Compose a question that enumerates each requested column, calculation, the two quoted literals, the Population bounds, and the row limit. 4) Confirm that all calculations, column names and numeric conditions are included.",reserved,5,reward,,
"For each Champion, return the Champion, the number of Titles as COUNT(Season) for seasons >= 2000, MVP_when_champion as the SUM of cases where the Season MVP matches the Champion after removing ' (2)' and ' (3)' via REPLACE and checking instr(...)>0, and AvgTeamsDuringTitles as AVG(Teams) across those seasons, only including champions with COUNT(Season)>0 and ordering the results by Titles?","
SELECT t1.`Champion` `Champion`, COUNT(t1.`Season`) `Titles`, SUM((instr(REPLACE(REPLACE(t1.`Champion`,' (2)',''),' (3)',''), REPLACE(REPLACE(t1.`Season MVP`,' (2)',''),' (3)',''))>0)) `MVP_when_champion`, AVG(t2.`Teams`) `AvgTeamsDuringTitles`
FROM `table_1_13082900_1` `t1` JOIN `table_1_13082900_1` `t2` ON t1.`Season` = t2.`Season`
WHERE t2.`Season`>=2000
GROUP BY t1.`Champion`
HAVING COUNT(t1.`Season`)>0
ORDER BY `Titles`;
","
SELECT t1.col2 col2, COUNT(t1.col0) `Titles`, SUM((instr(REPLACE(REPLACE(t1.col2,' (2)',''),' (3)',''), REPLACE(REPLACE(t1.col3,' (2)',''),' (3)',''))>0)) `MVP_when_champion`, AVG(t2.col1) `AvgTeamsDuringTitles`
FROM `table_1_13082900_1` `t1` JOIN `table_1_13082900_1` `t2` ON t1.col0 = t2.col0
WHERE t2.col0>=2000
GROUP BY t1.col2
HAVING COUNT(t1.col0)>0
ORDER BY `Titles`;
","[('detroit shock', 1, 0, 14.0), ('detroit shock (2)', 1, 0, 14.0), ('detroit shock (3)', 1, 0, 14.0), ('houston comets (4)', 1, 0, 16.0), ('indiana fever', 1, 0, 12.0), ('los angeles sparks', 1, 0, 16.0), ('los angeles sparks (2)', 1, 0, 16.0), ('minnesota lynx', 1, 0, 12.0), ('phoenix mercury', 1, 0, 13.0), ('phoenix mercury (2)', 1, 0, 13.0), ('sacramento monarchs', 1, 0, 13.0), ('seattle storm', 1, 0, 13.0), ('seattle storm (2)', 1, 0, 12.0)]",table_1_13082900_1,"1) Parse the SQL intent: produce per-Champion aggregates for seasons from 2000: total Titles, number of those Titles where the Season MVP string appears in the Champion string after removing ' (2)' and ' (3)', and the average Teams during those title seasons; then group and order by Titles. 2) Map schema semantics: mapping COUNT(Season) to Titles, the REPLACE/INSTR expression to MVP_when_champion, and AVG(Teams) to AvgTeamsDuringTitles, all using columns Champion, Season, Season MVP, Teams. 3) Draft the question: clearly request Champion, Titles, MVP_when_champion (with the replacement and substring check described), and AvgTeamsDuringTitles for seasons >=2000, with groups having COUNT>0 and ordered by Titles. 4) Validate: confirm inclusion of all columns, calculations, the ' (2)'/' (3)' replacements, the season >=2000 filter, grouping, having, and ordering.",reserved,9,reward,,
"Which Contextual Assets (Assets (WHAT)) and Conceptual Assets (Assets (WHAT)) appear together and how many pairs do they form (Pair Count = COUNT(*)) when their Motivation (WHY) values are equal, restricting the Contextual Assets (Assets (WHAT)) to 'The Business', grouping by the Contextual Assets and including only groups with Pair Count > 0, limited to 5 rows with an offset of 0?","
SELECT
  t1.`Assets (WHAT)` `Contextual Assets`,
  t2.`Assets (WHAT)` `Conceptual Assets`,
  COUNT(*) AS `Pair Count`
FROM `table_1_13113344_1` t1
INNER JOIN `table_1_13113344_1` t2 ON t1.`Motivation (WHY)` = t2.`Motivation (WHY)`
WHERE t1.`Assets (WHAT)` = 'The Business'
GROUP BY t1.`Assets (WHAT)` HAVING COUNT(*) > 0
LIMIT 5 OFFSET 0;
","SELECT t1.col1 `Contextual Assets`, t2.col1 AS `Conceptual Assets`
FROM `table_1_13113344_1` t1
INNER JOIN `table_1_13113344_1` t2 ON 1=1
WHERE t1.col1 <> ''
GROUP BY t1.col1, t2.col1
HAVING t1.col1 <> ''
LIMIT 5 OFFSET 0;","[('business attributes profile', 'business attributes profile'), ('business attributes profile', 'business data model'), ('business attributes profile', 'business information model'), ('business attributes profile', 'detailed data structures'), ('business attributes profile', 'the business')]",table_1_13113344_1,"Parse SQL intent: produce paired asset names from two rows joined on `Motivation (WHY)`, count pairs, restrict to t1.`Assets (WHAT)` = 'The Business', group and filter groups with count > 0, limit 5 and offset 0. Map schema semantics: t1 and t2 are the same table producing Contextual and Conceptual Assets via `Assets (WHAT)`, joined by `Motivation (WHY)`. Draft the question: request those two asset columns and the count under the stated join, filter, grouping, having and limit/offset. Validate: confirm inclusion of column names, join key, COUNT(*) alias, WHERE value, GROUP BY/HAVING, LIMIT 5 OFFSET 0.",reserved,12,reward,,
"For each Champion with a Purse ( $ ) of at least 1800000 and a Score less than or equal to 204, what is the Champion name, the count of records, the average Score rounded to 2 decimal places, the minimum Score, and the Years they won as a comma-separated list, showing up to 10 Champions?","
SELECT `Champion`, COUNT(*), ROUND(AVG(`Score`),2) AS `Average Score`, MIN(`Score`), GROUP_CONCAT(`Year`, ', ')
FROM `table_1_13169136_1`
WHERE `Purse ( $ )` >= 1800000 AND `Score` <= 204
GROUP BY `Champion`
LIMIT 10;
","
SELECT col2, COUNT(*), ROUND(AVG(col3),2) AS `Average Score`, MIN(col3), GROUP_CONCAT(col0, ', ')
FROM `table_1_13169136_1`
WHERE col6 >= 1800000 AND col3 <= 204
GROUP BY col2
LIMIT 10;
","[('ai miyazato', 1, 201.0, 201.0, '2012.0'), ('inbee park', 1, 201.0, 201.0, '2013.0'), ('jiyai shin', 1, 204.0, 204.0, '2009.0'), ('yani tseng', 2, 200.5, 200.0, '2011.0, 2010.0')]",table_1_13169136_1,"1) Parse intent: aggregate tournament rows by Champion, filtering Purse ( $ ) >= 1800000 and Score <= 204, compute count, average Score rounded to 2 decimals, minimum Score, and concatenate Years, limit 10. 2) Map schema: use Champion, Score, Year, Purse ( $ ). 3) Draft: ask for those aggregated fields per Champion with the given filters and limit. 4) Validate: ensures all selected columns, calculations, filters, grouping and limit are represented.",reserved,8,reward,,
What are the distinct Title values (limit 25) and their Platform_Count computed as ((length(Windows)>0) + (length(`5th Gen`)>0) + (length(`6th Gen`)>0) + (length(Handheld)>0) + (length(Arcade)>0)) for records where Windows = Windows?,"
SELECT DISTINCT `Title`, ((length(`Windows`)>0) + (length(`5th Gen`)>0) + (length(`6th Gen`)>0) + (length(`Handheld`)>0) + (length(`Arcade`)>0)) `Platform_Count`
FROM `table_1_1322914_1`
WHERE `Windows` = `Windows`
LIMIT 25;
","
SELECT DISTINCT col1, ((length(col2)>0) + (length(col3)>0) + (length(col4)>0) + (length(col5)>0) + (length(col6)>0)) `Platform_Count`
FROM `table_1_1322914_1`
WHERE col2 = col2
LIMIT 25;
","[('south park rally', 5), ('need for speed: porsche unleashed', 5), ('mario party 2', 5), ('resident evil code: veronica', 5), ('the sims', 5), ('vagrant story', 5), ('rayman 2: the great escape', 5), ('pokémon stadium', 5), ('kessen', 5), ('thief ii: the metal age', 5), ('kirby 64: the crystal shards', 5), ('soldier of fortune', 5), (""the legend of zelda: majora's mask"", 5), ('perfect dark', 5), ('ground control', 5), ('dracula: resurrection', 5), ('shogun: total war', 5), ('deus ex', 5), ('diablo ii', 5), ('icewind dale', 5), ('jet set radio', 5), ('marvel vs capcom 2', 5), ('homeworld: cataclysm', 5), ('final fantasy ix', 5), ('threads of fate', 5)]",table_1_1322914_1,"1) Parse: SELECT DISTINCT Title and calculate Platform_Count by summing five boolean expressions length(column)>0; apply WHERE Windows = Windows and LIMIT 25. 2) Map: Title is the release title and the five columns indicate platform text fields. 3) Draft: ask for distinct Titles with the explicit Platform_Count formula for rows meeting Windows = Windows, limited to 25 entries. 4) Validate: confirm inclusion of the exact ((length(...)>0)+...) formula, the WHERE clause, DISTINCT, and the 25-result cap.",reserved,5,reward,,
"For each Game site, what are the Games Played (count of games), Wins (number of rows where Result starts with 'W'), Losses (number of rows where Result starts with 'L'), Avg Attendance, Peak Attendance (maximum Attendance), Low Attendance (minimum Attendance), and Total Attendance, including only Game sites with at least one win, with the results ordered by Avg Attendance descending?","
SELECT
  `Game site`,
  COUNT(*) `Games Played`,
  SUM(substr(`Result`,1,1)='W') `Wins`,
  SUM(substr(`Result`,1,1)='L') `Losses`,
  AVG(`Attendance`) AS `Avg Attendance`,
  MAX(`Attendance`) `Peak Attendance`,
  MIN(`Attendance`) `Low Attendance`,
  SUM(`Attendance`) `Total Attendance`
FROM `table_1_13259009_2`
GROUP BY `Game site`
HAVING SUM(substr(`Result`,1,1)='W')>0
ORDER BY `Avg Attendance` DESC;
","SELECT
  col4,
  COUNT(*) AS `Games Played`,
  SUM(CASE WHEN substr(col3,1,1)='W' THEN 1 ELSE 0 END) AS `Wins`,
  SUM(CASE WHEN substr(col3,1,1)='L' THEN 1 ELSE 0 END) AS `Losses`,
  AVG(col6) AS `Avg Attendance`,
  MAX(col6) AS `Peak Attendance`,
  MIN(col6) AS `Low Attendance`,
  SUM(col6) AS `Total Attendance`
FROM `table_1_13259009_2`
GROUP BY col4
ORDER BY `Avg Attendance` DESC;","[('mile high stadium', 1, 0, 0, 74879.0, 74879.0, 74879.0, 74879.0), ('cleveland stadium', 1, 0, 0, 72440.0, 72440.0, 72440.0, 72440.0), ('kingdome', 8, 0, 0, 61060.125, 62887.0, 59977.0, 488481.0), ('miami orange bowl', 1, 0, 0, 56233.0, 56233.0, 56233.0, 56233.0), ('atlanta-fulton county stadium', 1, 0, 0, 52566.0, 52566.0, 52566.0, 52566.0), ('san diego stadium', 1, 0, 0, 50077.0, 50077.0, 50077.0, 50077.0), ('candlestick park', 1, 0, 0, 44592.0, 44592.0, 44592.0, 44592.0), ('arrowhead stadium', 1, 0, 0, 42160.0, 42160.0, 42160.0, 42160.0)]",table_1_13259009_2,"Parse SQL intent: aggregate rows by Game site to compute count of games, counts of wins/losses based on Result's first character, average/min/max/sum of Attendance, filter to sites with at least one win, and order by average attendance descending. Map schema semantics: Game site is the grouping key, Result's first character indicates win 'W' or loss 'L', Attendance is numeric for AVG/MIN/MAX/SUM. Draft the question to request Games Played (count), Wins, Losses, Avg Attendance, Peak Attendance, Low Attendance, Total Attendance per Game site, include only sites with Wins>0, and order by Avg Attendance DESC. Validate: the question must mention all computed columns, the filter on wins, grouping by Game site, and ordering by average attendance.",reserved,8,reward,,
"I need a compact attendance dashboard: average and peak Kingdome attendance (which week/date/opponent), how many Kingdome games were ≥60k/≥62k/≥50k, total home and away games and avg away attendance (and the avg home−away difference), home wins/home losses and season win/loss totals, overtime game counts and how many at Kingdome, and list Kingdome opponents with attendance ≥60k (with values)?","
WITH `base` AS (
  SELECT * FROM `table_1_13259019_2`
),
`home` AS (
  SELECT * FROM `base` WHERE `Game site` = 'Kingdome'
),
`away` AS (
  SELECT * FROM `base` WHERE `Game site` != 'Kingdome'
),
`home_peak` AS (
  SELECT `Week`, `Date`, `Opponent`, `Attendance`
  FROM `home`
  WHERE `Attendance` = (SELECT MAX(`Attendance`) FROM `home`)
  LIMIT 1
),
`thresholds` AS (
  SELECT
    SUM(CASE WHEN `Attendance` >= 60000 THEN 1 ELSE 0 END) AS `home_>=60000`,
    SUM(CASE WHEN `Attendance` >= 62000 THEN 1 ELSE 0 END) AS `home_>=62000`,
    SUM(CASE WHEN `Attendance` >= 50000 THEN 1 ELSE 0 END) AS `home_>=50000`
  FROM `home`
),
`winloss` AS (
  SELECT
    SUM(CASE WHEN `Result` LIKE 'W %' THEN 1 ELSE 0 END) AS `wins_total`,
    SUM(CASE WHEN `Result` LIKE 'L %' THEN 1 ELSE 0 END) AS `losses_total`,
    SUM(CASE WHEN `Result` LIKE 'W %' AND `Game site` = 'Kingdome' THEN 1 ELSE 0 END) AS `home_wins`,
    SUM(CASE WHEN `Result` LIKE 'L %' AND `Game site` = 'Kingdome' THEN 1 ELSE 0 END) AS `home_losses`
  FROM `base`
),
`ot` AS (
  SELECT
    COUNT(*) AS `ot_total`,
    SUM(CASE WHEN `Game site` = 'Kingdome' THEN 1 ELSE 0 END) AS `ot_home`
  FROM `base`
  WHERE `Result` LIKE '%OT%'
),
`agg` AS (
  SELECT
    (SELECT AVG(`Attendance`) FROM `home`) AS `avg_home_attendance`,
    (SELECT MAX(`Attendance`) FROM `home`) AS `max_home_attendance`,
    (SELECT COUNT(*) FROM `home`) AS `home_games`,
    (SELECT AVG(`Attendance`) FROM `away`) AS `avg_away_attendance`,
    (SELECT COUNT(*) FROM `away`) AS `away_games`
)
SELECT
  `agg`.`avg_home_attendance` AS `avg_home_attendance`,
  `agg`.`max_home_attendance` AS `max_home_attendance`,
  `home_peak`.`Week` AS `peak_home_week`,
  `home_peak`.`Date` AS `peak_home_date`,
  `home_peak`.`Opponent` AS `peak_home_opponent`,
  `home_peak`.`Attendance` AS `peak_home_attendance`,
  `thresholds`.`home_>=60000` AS `home_games_>=60000`,
  `thresholds`.`home_>=62000` AS `home_games_>=62000`,
  `thresholds`.`home_>=50000` AS `home_games_>=50000`,
  `agg`.`home_games` AS `home_games_total`,
  `agg`.`away_games` AS `away_games_total`,
  `agg`.`avg_away_attendance` AS `avg_away_attendance`,
  ROUND((`agg`.`avg_home_attendance` - `agg`.`avg_away_attendance`), 1) AS `avg_home_minus_away`,
  `winloss`.`home_wins` AS `home_wins`,
  `winloss`.`home_losses` AS `home_losses`,
  `winloss`.`wins_total` AS `total_wins`,
  `winloss`.`losses_total` AS `total_losses`,
  `ot`.`ot_total` AS `overtime_games_total`,
  `ot`.`ot_home` AS `overtime_games_at_Kingdome`,
  (SELECT GROUP_CONCAT(`Opponent` || ' (' || `Attendance` || ')', ', ')
   FROM `home`
   WHERE `Attendance` >= 60000
   ORDER BY `Attendance` DESC) AS `kingdome_opponents_>=60000_list`
FROM `agg`, `home_peak`, `thresholds`, `winloss`, `ot`;
","SELECT
  (SELECT AVG(col6) FROM `table_1_13259019_2` WHERE col4 = 'Kingdome') AS `avg_home_attendance`,
  (SELECT MAX(col6) FROM `table_1_13259019_2` WHERE col4 = 'Kingdome') AS `max_home_attendance`,
  (SELECT col0 FROM `table_1_13259019_2` WHERE col4 = 'Kingdome' ORDER BY col6 DESC LIMIT 1) AS `peak_home_week`,
  (SELECT col1 FROM `table_1_13259019_2` WHERE col4 = 'Kingdome' ORDER BY col6 DESC LIMIT 1) AS `peak_home_date`,
  (SELECT col2 FROM `table_1_13259019_2` WHERE col4 = 'Kingdome' ORDER BY col6 DESC LIMIT 1) AS `peak_home_opponent`,
  (SELECT col6 FROM `table_1_13259019_2` WHERE col4 = 'Kingdome' ORDER BY col6 DESC LIMIT 1) AS `peak_home_attendance`,
  (SELECT SUM(CASE WHEN col6 >= 60000 THEN 1 ELSE 0 END) FROM `table_1_13259019_2` WHERE col4 = 'Kingdome') AS `home_games_>=60000`,
  (SELECT SUM(CASE WHEN col6 >= 62000 THEN 1 ELSE 0 END) FROM `table_1_13259019_2` WHERE col4 = 'Kingdome') AS `home_games_>=62000`,
  (SELECT SUM(CASE WHEN col6 >= 50000 THEN 1 ELSE 0 END) FROM `table_1_13259019_2` WHERE col4 = 'Kingdome') AS `home_games_>=50000`,
  (SELECT COUNT(*) FROM `table_1_13259019_2` WHERE col4 = 'Kingdome') AS `home_games_total`,
  (SELECT COUNT(*) FROM `table_1_13259019_2` WHERE col4 != 'Kingdome') AS `away_games_total`,
  (SELECT AVG(col6) FROM `table_1_13259019_2` WHERE col4 != 'Kingdome') AS `avg_away_attendance`,
  ROUND(
    ( (SELECT AVG(col6) FROM `table_1_13259019_2` WHERE col4 = 'Kingdome')
    - (SELECT AVG(col6) FROM `table_1_13259019_2` WHERE col4 != 'Kingdome') )
  , 1) AS `avg_home_minus_away`,
  (SELECT SUM(CASE WHEN col3 LIKE 'W %' AND col4 = 'Kingdome' THEN 1 ELSE 0 END) FROM `table_1_13259019_2`) AS `home_wins`,
  (SELECT SUM(CASE WHEN col3 LIKE 'L %' AND col4 = 'Kingdome' THEN 1 ELSE 0 END) FROM `table_1_13259019_2`) AS `home_losses`,
  (SELECT SUM(CASE WHEN col3 LIKE 'W %' THEN 1 ELSE 0 END) FROM `table_1_13259019_2`) AS `total_wins`,
  (SELECT SUM(CASE WHEN col3 LIKE 'L %' THEN 1 ELSE 0 END) FROM `table_1_13259019_2`) AS `total_losses`,
  (SELECT COUNT(*) FROM `table_1_13259019_2` WHERE col3 LIKE '%OT%') AS `overtime_games_total`,
  (SELECT COUNT(*) FROM `table_1_13259019_2` WHERE col3 LIKE '%OT%' AND col4 = 'Kingdome') AS `overtime_games_at_Kingdome`,
  (SELECT GROUP_CONCAT(col2 || ' (' || col6 || ')', ', ')
   FROM `table_1_13259019_2`
   WHERE col4 = 'Kingdome' AND col6 >= 60000
   ORDER BY col6 DESC) AS `kingdome_opponents_>=60000_list`
;","[(None, None, None, None, None, None, None, None, None, 0, 15, 55952.26666666667, None, 0, 0, 8, 7, 1, 0, None)]",table_1_13259019_2,"I often ask for a compact attendance dashboard in plain language, mentioning Kingdome and thresholds rather than SQL clauses. The query calculates average and maximum Kingdome attendance, identifies the peak home game, counts home games over specific attendance thresholds, compares home and away averages and counts, reports wins/losses overall and at home, counts overtime games and lists high-attendance Kingdome opponents. These map to the table's Week, Date, Opponent, Result, Game site and Attendance fields. Give me a compact summary covering those metrics: avg/max Kingdome attendance with the peak game, threshold counts (≥60k/≥62k/≥50k), home/away counts and avgs with the difference, win/loss totals and OT counts, plus the Kingdome opponents that drew ≥60k with their attendances. This is exactly the output the query produces.",persona,"Ticketing & Revenue Analyst for the Seattle Seahawks (historical data analyst) who examines past seasons to understand attendance drivers and inform pricing/marketing strategies. Uses this 1978 schedule table to benchmark historical demand by opponent, venue, and game timing. Goals: Measure average and peak attendance for home games (Kingdome) to identify high-demand opponents and dates. Compare home vs away attendance and quantify how many games exceeded specific attendance thresholds. Provide simple win/loss counts and identify special-case games (e.g., overtime) that might have influenced attendance spikes. Example Queries: SELECT AVG(""Attendance"") AS avg_home_attendance
FROM table_1_13259019_2
WHERE ""Game site"" = 'Kingdome'; SELECT ""Week"", ""Date"", ""Opponent"", ""Result"", ""Attendance""
FROM table_1_13259019_2
WHERE ""Attendance"" >= 60000
ORDER BY ""Attendance"" DESC; SELECT CASE WHEN ""Game site"" = 'Kingdome' THEN 'Home' ELSE 'Away' END AS location,
       COUNT(*) AS games,
       AVG(""Attendance"") AS avg_attendance
FROM table_1_13259019_2
GROUP BY location;",reward,,
"Considering only games with Attendance greater than 30000 and where Game site is 'Kingdome' or 'Arrowhead Stadium', what are for each Game site the count of games, the SUM(Attendance) as Total Attendance, the AVG(Attendance), and the number of games with Result starting with 'W' (Wins), grouping by Game site, excluding empty groups, ordering by Total Attendance descending and returning up to 10 rows?","
SELECT `Game site`, COUNT(*), SUM(`Attendance`) AS `Total Attendance`, AVG(`Attendance`), SUM(substr(`Result`,1,1)='W') AS `Wins`
FROM `table_1_13259034_2` CROSS JOIN (SELECT 'Kingdome' AS `Kingdome`, 'Arrowhead Stadium' AS `Arrowhead Stadium`) AS v
WHERE `Attendance` > 30000 AND (`Game site` = v.`Kingdome` OR `Game site` = v.`Arrowhead Stadium`)
GROUP BY `Game site`
HAVING COUNT(*) > 0
ORDER BY `Total Attendance` DESC
LIMIT 10;
","SELECT col4, COUNT(*) AS `Games`, SUM(col6) AS `Total Attendance`, AVG(col6) AS `Avg Attendance`, SUM(CASE WHEN substr(col3,1,1) = 'W' THEN 1 ELSE 0 END) AS `Wins`
FROM `table_1_13259034_2`
WHERE col6 > 30000
GROUP BY col4
HAVING COUNT(*) > 0
ORDER BY `Total Attendance` DESC
LIMIT 10;","[('kingdome', 6, 348575.0, 58095.833333333336, 0), ('oakland-alameda county coliseum', 1, 50929.0, 50929.0, 0), ('schaefer stadium', 1, 45927.0, 45927.0, 0), ('riverfront stadium', 1, 45579.0, 45579.0, 0), ('three rivers stadium', 1, 45429.0, 45429.0, 0), ('shea stadium', 1, 42923.0, 42923.0, 0)]",table_1_13259034_2,"1) Parse SQL intent: compute counts and attendance aggregates for two specific stadiums filtering out small crowds, and count wins by checking Result's first character. 2) Map schema semantics: fields involved are `Game site`, `Attendance`, and `Result`; calculations are COUNT, SUM, AVG, and SUM(substr(Result,1,1)='W'). 3) Draft the question: request those exact aggregates for Game site = Kingdome or Arrowhead Stadium where Attendance > 30000, grouped and sorted accordingly. 4) Validate: includes HAVING COUNT(*)>0, ORDER BY Total Attendance DESC, and LIMIT 10.",reserved,18,reward,,
"Which writer‑director pairings have repeatedly successful episodes and could form a signature house scent, and for each pairing give episode count, average and max viewers, the flagship episode title, a list of titles with production codes and original air dates, how many of their episodes are in the season's top three, and the diversity index?","
WITH `top3` AS (
  SELECT `No. in series`
  FROM `table_1_13301516_1`
  ORDER BY CAST(`U.S. viewers (millions)` AS REAL) DESC
  LIMIT 3
)
SELECT
  t1.`Directed by` AS `Directed by`,
  t1.`Written by` AS `Written by`,
  COUNT(*) AS `episode_count`,
  ROUND(AVG(CAST(t1.`U.S. viewers (millions)` AS REAL)),2) AS `avg_viewers`,
  ROUND(MAX(CAST(t1.`U.S. viewers (millions)` AS REAL)),2) AS `max_viewers`,
  (SELECT t2.`Title` 
   FROM `table_1_13301516_1` t2 
   WHERE t2.`Directed by` = t1.`Directed by` AND t2.`Written by` = t1.`Written by`
   ORDER BY CAST(t2.`U.S. viewers (millions)` AS REAL) DESC
   LIMIT 1) AS `flagship_episode`,
  GROUP_CONCAT('`' || t1.`Title` || '`' || ' | ' || '`' || t1.`Production code` || '`' || ' | ' || '`' || t1.`Original air date` || '`', '; ') AS `episodes_detail`,
  MIN(t1.`No. in season`) AS `min_No. in season`,
  MAX(t1.`No. in season`) AS `max_No. in season`,
  COUNT(DISTINCT t1.`Production code`) AS `distinct_production_codes`,
  COUNT(DISTINCT t1.`Original air date`) AS `distinct_air_dates`,
  COUNT(CASE WHEN t1.`No. in series` IN (SELECT `No. in series` FROM `top3`) THEN 1 END) AS `top3_hits`,
  (COUNT(DISTINCT t1.`Production code`) + (MAX(t1.`No. in season`) - MIN(t1.`No. in season`))) AS `diversity_index`
FROM `table_1_13301516_1` t1
GROUP BY t1.`Directed by`, t1.`Written by`
HAVING COUNT(*) >= 1
ORDER BY `top3_hits` DESC, `avg_viewers` DESC, `episode_count` DESC;
","
WITH `top3` AS (
  SELECT col0
  FROM `table_1_13301516_1`
  ORDER BY CAST(col7 AS REAL) DESC
  LIMIT 3
)
SELECT
  t1.col3 AS col3,
  t1.col4 AS col4,
  COUNT(*) AS `episode_count`,
  ROUND(AVG(CAST(t1.col7 AS REAL)),2) AS `avg_viewers`,
  ROUND(MAX(CAST(t1.col7 AS REAL)),2) AS `max_viewers`,
  (SELECT t2.col2 
   FROM `table_1_13301516_1` t2 
   WHERE t2.col3 = t1.col3 AND t2.col4 = t1.col4
   ORDER BY CAST(t2.col7 AS REAL) DESC
   LIMIT 1) AS `flagship_episode`,
  GROUP_CONCAT('`' || t1.col2 || '`' || ' | ' || '`' || t1.col6 || '`' || ' | ' || '`' || t1.col5 || '`', '; ') AS `episodes_detail`,
  MIN(t1.col1) AS `min_No. in season`,
  MAX(t1.col1) AS `max_No. in season`,
  COUNT(DISTINCT t1.col6) AS `distinct_production_codes`,
  COUNT(DISTINCT t1.col5) AS `distinct_air_dates`,
  COUNT(CASE WHEN t1.col0 IN (SELECT col0 FROM `top3`) THEN 1 END) AS `top3_hits`,
  (COUNT(DISTINCT t1.col6) + (MAX(t1.col1) - MIN(t1.col1))) AS `diversity_index`
FROM `table_1_13301516_1` t1
GROUP BY t1.col3, t1.col4
HAVING COUNT(*) >= 1
ORDER BY `top3_hits` DESC, `avg_viewers` DESC, `episode_count` DESC;
","[('arthur w. forney', 'judith mccreary', 1, 15.17, 15.17, '""signature""', '`""signature""` | `9012.0` | `january 8, 2008`', 12.0, 12.0, 1, 1, 1, 1.0), ('david platt', 'mark goffman', 1, 13.27, 13.27, '""undercover""', '`""undercover""` | `9015.0` | `april 15, 2008`', 15.0, 15.0, 1, 1, 1, 1.0), ('chris zalla', 'dawn denoon', 1, 12.97, 12.97, '""inconceivable""', '`""inconceivable""` | `9014.0` | `january 22, 2008`', 14.0, 14.0, 1, 1, 1, 1.0), ('kate woods', 'judith mccreary', 1, 12.54, 12.54, '""savant""', '`""savant""` | `9005.0` | `october 16, 2007`', 4.0, 4.0, 1, 1, 0, 1.0), ('helen shaver', 'paul grellong', 1, 12.35, 12.35, '""streetwise""', '`""streetwise""` | `9011.0` | `january 1, 2008`', 11.0, 11.0, 1, 1, 0, 1.0), ('david platt', 'jonathan greene', 2, 12.34, 12.49, '""blinded""', '`""impulsive""` | `9001.0` | `october 9, 2007`; `""blinded""` | `9009.0` | `november 13, 2007`', 3.0, 7.0, 2, 2, 0, 6.0), ('kate woods', 'amanda green', 1, 12.29, 12.29, '""paternity""', '`""paternity""` | `9010.0` | `november 27, 2007`', 9.0, 9.0, 1, 1, 0, 1.0), ('peter leto', 'josh singer', 1, 12.17, 12.17, '""harm""', '`""harm""` | `9002.0` | `october 23, 2007`', 5.0, 5.0, 1, 1, 0, 1.0), ('david platt', 'josh singer', 1, 12.14, 12.14, '""unorthodox""', '`""unorthodox""` | `9013.0` | `january 15, 2008`', 13.0, 13.0, 1, 1, 0, 1.0), ('david platt', 'neal baer & dawn denoon', 1, 12.1, 12.1, '""alternate""', '`""alternate""` | `9003.0` | `september 25, 2007`', 1.0, 1.0, 1, 1, 0, 1.0), ('david platt', 'neal baer & amanda green', 1, 12.06, 12.06, '""authority""', '`""authority""` | `9017.0` | `april 29, 2008`', 17.0, 17.0, 1, 1, 0, 1.0), ('david platt', 'kam miller', 1, 11.75, 11.75, '""svengali""', '`""svengali""` | `9006.0` | `november 6, 2007`', 6.0, 6.0, 1, 1, 0, 1.0), ('jonathan kaplan', 'mark goffman', 1, 11.72, 11.72, '""snitch""', '`""snitch""` | `9008.0` | `december 4, 2007`', 10.0, 10.0, 1, 1, 0, 1.0), ('juan j. campanella', 'mick betancourt', 1, 11.66, 11.66, '""fight""', '`""fight""` | `9007.0` | `november 20, 2007`', 8.0, 8.0, 1, 1, 0, 1.0), ('peter leto', 'paul grellong', 1, 11.66, 11.66, '""avatar""', '`""avatar""` | `9004.0` | `october 2, 2007`', 2.0, 2.0, 1, 1, 0, 1.0), ('peter leto', 'ken storer', 1, 11.5, 11.5, '""closet""', '`""closet""` | `9016.0` | `april 22, 2008`', 16.0, 16.0, 1, 1, 0, 1.0), ('peter leto', 'jonathan greene', 1, 10.44, 10.44, '""trade""', '`""trade""` | `9018.0` | `may 6, 2008`', 18.0, 18.0, 1, 1, 0, 1.0)]",table_1_13301516_1,"As a perfumer hunting for signature ""house"" teams, I'd casually ask for repeatedly successful director-writer pairings and their key episode metrics without using SQL terms. The query groups by director and writer and returns episode_count, avg and max viewers, a flagship episode, concatenated episode details (title | production code | air date), min/max No. in season, counts of distinct production codes and air dates, top-3 hits, and a diversity index, ordered by top3 hits then avg viewers then episode_count. These items correspond to the table's Directed by, Written by, Title, Production code, Original air date, No. in season, No. in series, and U.S. viewers (millions). Which writer-director pairings have repeated successes and should form a house scent — list for each pairing their episode count, average and max viewers, flagship episode title, the list of episodes with production codes and air dates, how many of their episodes are in the season top three, and the diversity index? This stays strictly within the fields and aggregates computed by the query.",persona,"An olfactory artist/perfumer who designs limited-edition scents that capture the visual and narrative 'smell' of individual TV episodes, using credits and audience data to choose which episodes to interpret. Goals: Identify the most-watched episodes to create flagship, broadly appealing scents. Find episodes by specific directors (visual style) or writers (narrative tone) so the scent matches a consistent creative voice. Ensure a diverse selection across the season (different air dates and production codes) to assemble a balanced fragrance collection. Spot writer-director pairings and repeatedly successful collaborators to create a signature 'house' scent inspired by consistent teams. Example Queries: SELECT ""No. in series"", ""No. in season"", ""Title"", ""Directed by"", ""Written by"", ""Original air date"", ""Production code"", ""U.S. viewers (millions)"" FROM table_1_13301516_1 ORDER BY CAST(""U.S. viewers (millions)"" AS REAL) DESC LIMIT 3; SELECT * FROM table_1_13301516_1 WHERE ""Directed by"" = 'David Platt' ORDER BY CAST(""U.S. viewers (millions)"" AS REAL) DESC; SELECT ""Directed by"", ""Written by"", COUNT(*) AS episode_count, AVG(CAST(""U.S. viewers (millions)"" AS REAL)) AS avg_viewers FROM table_1_13301516_1 GROUP BY ""Directed by"", ""Written by"" HAVING COUNT(*) >= 1 ORDER BY avg_viewers DESC;",reward,,
"Who are the top five NZ ODI bowlers with at least 50 matches when ranked by a composite selection score that balances bowling average, economy rate, experience, number of 4‑ and 5‑wicket hauls and best‑innings wickets?","
WITH computed AS (
  SELECT
    `` AS `Player`,
    `Matches`,
    `Wickets`,
    `Average`,
    `Economy Rate`,
    `Best Bowling`,
    `4WI`,
    `5WI`,
    CAST(substr(`Best Bowling`, 1, instr(`Best Bowling`, '/') - 1) AS INTEGER) AS `Best_Wickets`,
    (CAST(`5WI` AS INTEGER) * 2 + CAST(`4WI` AS INTEGER)) AS `Match_Impact`
  FROM table_1_13322378_10
  WHERE CAST(`Matches` AS INTEGER) >= 50
)
SELECT
  `Player`,
  `Matches`,
  `Wickets`,
  `Average`,
  `Economy Rate`,
  `Best Bowling`,
  `4WI`,
  `5WI`,
  `Best_Wickets`,
  `Match_Impact`,
  (
    ((100.0 / CAST(`Average` AS REAL)) * 0.45) +
    ((50.0 / CAST(`Economy Rate` AS REAL)) * 0.25) +
    (CAST(`Matches` AS REAL) * 0.15) +
    (CAST(`Match_Impact` AS REAL) * 3.0) +
    (CAST(`Best_Wickets` AS REAL) * 0.5)
  ) AS `Selection_Score`
FROM computed
ORDER BY `Selection_Score` DESC, CAST(`Average` AS REAL) ASC
LIMIT 5;
","
WITH computed AS (
  SELECT
    col0 AS `Player`,
    col1,
    col3,
    col4,
    col5,
    col6,
    col7,
    col8,
    CAST(substr(col6, 1, instr(col6, '/') - 1) AS INTEGER) AS `Best_Wickets`,
    (CAST(col8 AS INTEGER) * 2 + CAST(col7 AS INTEGER)) AS `Match_Impact`
  FROM table_1_13322378_10
  WHERE CAST(col1 AS INTEGER) >= 50
)
SELECT
  `Player`,
  col1,
  col3,
  col4,
  col5,
  col6,
  col7,
  col8,
  `Best_Wickets`,
  `Match_Impact`,
  (
    ((100.0 / CAST(col4 AS REAL)) * 0.45) +
    ((50.0 / CAST(col5 AS REAL)) * 0.25) +
    (CAST(col1 AS REAL) * 0.15) +
    (CAST(`Match_Impact` AS REAL) * 3.0) +
    (CAST(`Best_Wickets` AS REAL) * 0.5)
  ) AS `Selection_Score`
FROM computed
ORDER BY `Selection_Score` DESC, CAST(col4 AS REAL) ASC
LIMIT 5;
","[('shane bond', 82.0, 147.0, '20.88', '4.28', '6/19', 7.0, 4.0, 6, 15, 65.37573316145665), ('richard hadlee', 115.0, 158.0, '21.56', '4.20', '5/25', 1.0, 5.0, 5, 11, 57.81338899196042), ('kyle mills', 129.0, 192.0, '26.03', '4.73', '5/25', 7.0, 1.0, 5, 9, 53.22148062205018), ('ewen chatfield', 114.0, 140.0, '25.84', '3.57', '5/34', 3.0, 1.0, 5, 5, 39.84288662833554), ('chris pringle', 64.0, 103.0, '23.87', '4.45', '5/45', 2.0, 1.0, 5, 4, 28.79420032667586)]",table_1_13322378_10,"As the NZ bowling analyst I frame questions around selection and match impact using cricket terms rather than SQL jargon. I'm familiar with fields like matches, average, economy, best bowling and counts of 4‑ and 5‑wicket hauls. The SQL filters to players with at least 50 matches, derives best‑wickets and a match‑impact metric, then computes a composite Selection_Score and returns the top five. The schema maps directly to Matches, Average, Economy Rate, Best Bowling, 4WI and 5WI. Drafted question asks for the top five experienced bowlers by that composite score.",persona,"New Zealand national team bowling analyst responsible for selection and match planning; uses the database to compare historical ODI bowling performances and identify candidates for specific match conditions. Goals: Identify bowlers with the best bowling averages among those with substantial experience (to inform selection decisions). Find the most economical bowlers suitable for containing runs in different phases of an innings. Highlight bowlers with match-winning spells (multiple 4WI/5WI or exceptional best-bowling figures) for strategy and match-up planning. Example Queries: -- Top 3 bowlers by best average, requiring at least 50 matches
SELECT Player, Matches, Wickets, ""Average""
FROM table_1_13322378_10
WHERE Matches >= 50
ORDER BY CAST(""Average"" AS REAL) ASC
LIMIT 3; -- Bowlers with strong economy (<= 4.5 runs per over), ordered by economy then average
SELECT Player, Matches, ""Economy Rate"", ""Average""
FROM table_1_13322378_10
WHERE CAST(""Economy Rate"" AS REAL) <= 4.5
ORDER BY CAST(""Economy Rate"" AS REAL) ASC, CAST(""Average"" AS REAL) ASC; -- Bowlers with at least one five-wicket haul, showing frequency of 4WI and 5WI (best for match-winners)
SELECT Player, Matches, Wickets, ""Best Bowling"", CAST(""4WI"" AS INTEGER) AS four_wicket_inns, CAST(""5WI"" AS INTEGER) AS five_wicket_inns
FROM table_1_13322378_10
WHERE CAST(""5WI"" AS INTEGER) >= 1
ORDER BY five_wicket_inns DESC, four_wicket_inns DESC;",reward,,
"Can you give me, for every country, the population and estimated counts for Native American, Whites, Mestizo, Mulatto, Blacks, Zambo and Asians (derived from the percent columns), plus combined Afro and mixed percentages and counts and flags for Afro ≥25% and Indigenous ≥30%, ordered by population descending?","
WITH per AS (
  SELECT
    `Country`,
    `Population`,
    CAST(REPLACE(`Native American`, '%', '') AS FLOAT) AS `Native_Percent`,
    CAST(REPLACE(`Whites`, '%', '') AS FLOAT) AS `White_Percent`,
    CAST(REPLACE(`s Mestizo`, '%', '') AS FLOAT) AS `Mestizo_Percent`,
    CAST(REPLACE(`es Mulatto`, '%', '') AS FLOAT) AS `Mulatto_Percent`,
    CAST(REPLACE(`Blacks`, '%', '') AS FLOAT) AS `Black_Percent`,
    CAST(REPLACE(`s Zambo`, '%', '') AS FLOAT) AS `Zambo_Percent`,
    CAST(REPLACE(`Asians`, '%', '') AS FLOAT) AS `Asian_Percent`
  FROM `table_1_1333612_1`
)
SELECT
  `Country`,
  `Population`,
  `Native_Percent`,
  (`Native_Percent`/100.0)*`Population` AS `Native_Count`,
  `White_Percent`,
  (`White_Percent`/100.0)*`Population` AS `White_Count`,
  `Mestizo_Percent`,
  (`Mestizo_Percent`/100.0)*`Population` AS `Mestizo_Count`,
  `Mulatto_Percent`,
  (`Mulatto_Percent`/100.0)*`Population` AS `Mulatto_Count`,
  `Black_Percent`,
  (`Black_Percent`/100.0)*`Population` AS `Black_Count`,
  `Zambo_Percent`,
  (`Zambo_Percent`/100.0)*`Population` AS `Zambo_Count`,
  `Asian_Percent`,
  (`Asian_Percent`/100.0)*`Population` AS `Asian_Count`,
  (`Mulatto_Percent` + `Black_Percent` + `Zambo_Percent`) AS `Afro_Percent`,
  ((`Mulatto_Percent` + `Black_Percent` + `Zambo_Percent`)/100.0)*`Population` AS `Afro_Count`,
  (`Mestizo_Percent` + `Mulatto_Percent`) AS `Mixed_Percent`,
  ((`Mestizo_Percent` + `Mulatto_Percent`)/100.0)*`Population` AS `Mixed_Count`,
  CASE WHEN (`Mulatto_Percent` + `Black_Percent` + `Zambo_Percent`) >= 25 THEN 1 ELSE 0 END AS `Prioritize_Afro`,
  CASE WHEN `Native_Percent` >= 30 THEN 1 ELSE 0 END AS `Prioritize_Indigenous`,
  CASE WHEN `Population` > 5000000 AND (`Asian_Percent` >= 1 OR (`Mestizo_Percent` + `Mulatto_Percent`) >= 5) THEN 1 ELSE 0 END AS `Shortlist_Minority`
FROM per
ORDER BY `Population` DESC;
","
WITH per AS (
  SELECT
    col0,
    col1,
    CAST(REPLACE(col2, '%', '') AS FLOAT) AS `Native_Percent`,
    CAST(REPLACE(col3, '%', '') AS FLOAT) AS `White_Percent`,
    CAST(REPLACE(col4, '%', '') AS FLOAT) AS `Mestizo_Percent`,
    CAST(REPLACE(col5, '%', '') AS FLOAT) AS `Mulatto_Percent`,
    CAST(REPLACE(col6, '%', '') AS FLOAT) AS `Black_Percent`,
    CAST(REPLACE(col7, '%', '') AS FLOAT) AS `Zambo_Percent`,
    CAST(REPLACE(col8, '%', '') AS FLOAT) AS `Asian_Percent`
  FROM `table_1_1333612_1`
)
SELECT
  col0,
  col1,
  `Native_Percent`,
  (`Native_Percent`/100.0)*col1 AS `Native_Count`,
  `White_Percent`,
  (`White_Percent`/100.0)*col1 AS `White_Count`,
  `Mestizo_Percent`,
  (`Mestizo_Percent`/100.0)*col1 AS `Mestizo_Count`,
  `Mulatto_Percent`,
  (`Mulatto_Percent`/100.0)*col1 AS `Mulatto_Count`,
  `Black_Percent`,
  (`Black_Percent`/100.0)*col1 AS `Black_Count`,
  `Zambo_Percent`,
  (`Zambo_Percent`/100.0)*col1 AS `Zambo_Count`,
  `Asian_Percent`,
  (`Asian_Percent`/100.0)*col1 AS `Asian_Count`,
  (`Mulatto_Percent` + `Black_Percent` + `Zambo_Percent`) AS `Afro_Percent`,
  ((`Mulatto_Percent` + `Black_Percent` + `Zambo_Percent`)/100.0)*col1 AS `Afro_Count`,
  (`Mestizo_Percent` + `Mulatto_Percent`) AS `Mixed_Percent`,
  ((`Mestizo_Percent` + `Mulatto_Percent`)/100.0)*col1 AS `Mixed_Count`,
  CASE WHEN (`Mulatto_Percent` + `Black_Percent` + `Zambo_Percent`) >= 25 THEN 1 ELSE 0 END AS `Prioritize_Afro`,
  CASE WHEN `Native_Percent` >= 30 THEN 1 ELSE 0 END AS `Prioritize_Indigenous`,
  CASE WHEN col1 > 5000000 AND (`Asian_Percent` >= 1 OR (`Mestizo_Percent` + `Mulatto_Percent`) >= 5) THEN 1 ELSE 0 END AS `Shortlist_Minority`
FROM per
ORDER BY col1 DESC;
","[('brazil', 192272890.0, 0.4, 769091.56, 53.8, 103442814.81999998, 0.0, 0.0, 39.1, 75178699.99000001, 6.2, 11920919.18, 0.0, 0.0, 0.5, 961364.4500000001, 45.300000000000004, 87099619.17000002, 39.1, 75178699.99000001, 1, 0, 1), ('mexico', 112322757.0, 14.0, 15725185.980000002, 15.0, 16848413.55, 70.0, 78625929.89999999, 0.5, 561613.785, 0.0, 0.0, 0.0, 0.0, 0.5, 561613.785, 0.5, 561613.785, 70.5, 79187543.685, 0, 0, 1), ('colombia', 45393050.0, 1.8, 817074.9000000001, 20.0, 9078610.0, 53.2, 24149102.6, 21.0, 9532540.5, 3.9, 1770328.95, 0.1, 45393.05, 0.0, 0.0, 25.0, 11348262.5, 74.2, 33681643.1, 1, 0, 1), ('argentina', 40134425.0, 1.0, 401344.25, 85.0, 34114261.25, 11.1, 4454921.175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9, 1163898.325, 0.0, 0.0, 11.1, 4454921.175, 0, 0, 1), ('peru', 29461933.0, 45.5, 13405179.515, 12.0, 3535431.96, 32.0, 9427818.56, 9.7, 2857807.5009999997, 0.0, 0.0, 0.0, 0.0, 0.8, 235695.464, 9.7, 2857807.5009999997, 41.7, 12285626.061, 0, 1, 1), ('venezuela', 26814843.0, 2.7, 724000.761, 42.2, 11315863.746000001, 42.9, 11503567.647, 0.7, 187703.90099999998, 2.8, 750815.6039999999, 0.0, 0.0, 2.2, 589926.5460000001, 3.5, 938519.5050000001, 43.6, 11691271.548, 0, 0, 1), ('chile', 17063000.0, 3.2, 546016.0, 52.7, 8992201.0, 44.1, 7524783.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 44.1, 7524783.0, 0, 0, 1), ('ecuador', 13625000.0, 39.0, 5313750.0, 9.9, 1348875.0, 41.0, 5586250.0, 5.0, 681250.0, 5.0, 681250.0, 0.0, 0.0, 0.1, 13625.0, 10.0, 1362500.0, 46.0, 6267500.0, 0, 1, 1), ('guatemala', 13276517.0, 53.0, 7036554.010000001, 4.0, 531060.68, 42.0, 5576137.14, 0.0, 0.0, 0.0, 0.0, 0.2, 26553.034, 0.8, 106212.136, 0.2, 26553.034, 42.0, 5576137.14, 0, 1, 1), ('cuba', 11236444.0, 0.0, 0.0, 37.0, 4157484.28, 0.0, 0.0, 51.0, 5730586.44, 11.0, 1236008.84, 0.0, 0.0, 1.0, 112364.44, 62.0, 6966595.28, 51.0, 5730586.44, 1, 0, 1), ('bolivia', 10907778.0, 55.0, 5999277.9, 15.0, 1636166.7, 28.0, 3054177.8400000003, 2.0, 218155.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 218155.56, 30.0, 3272333.4, 0, 1, 1), ('dominican republic', 8562541.0, 0.0, 0.0, 14.6, 1250130.986, 0.0, 0.0, 75.0, 6421905.75, 7.7, 659315.657, 2.3, 196938.443, 0.4, 34250.164000000004, 85.0, 7278159.85, 75.0, 6421905.75, 1, 0, 1), ('honduras', 7810848.0, 7.7, 601435.296, 1.0, 78108.48, 85.6, 6686085.888, 1.7, 132784.416, 0.0, 0.0, 3.3, 257757.98400000003, 0.7, 54675.935999999994, 5.0, 390542.4, 87.3, 6818870.304, 0, 0, 1), ('paraguay', 6349000.0, 1.5, 95235.0, 20.0, 1269800.0, 74.5, 4730005.0, 3.5, 222215.00000000003, 0.0, 0.0, 0.0, 0.0, 0.5, 31745.0, 3.5, 222215.00000000003, 78.0, 4952220.0, 0, 0, 1), ('el salvador', 6134000.0, 1.0, 61340.0, 12.0, 736080.0, 86.0, 5275240.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 86.0, 5275240.0, 0, 0, 1), ('nicaragua', 5891199.0, 6.9, 406492.731, 14.0, 824767.8600000001, 78.3, 4612808.817, 0.0, 0.0, 0.0, 0.0, 0.6, 35347.194, 0.2, 11782.398000000001, 0.6, 35347.194, 78.3, 4612808.817, 0, 0, 1), ('costa rica', 4253897.0, 0.8, 34031.176, 82.0, 3488195.5399999996, 15.0, 638084.5499999999, 0.0, 0.0, 0.0, 0.0, 2.0, 85077.94, 0.2, 8507.794, 2.0, 85077.94, 15.0, 638084.5499999999, 0, 0, 0), ('puerto rico', 3967179.0, 0.0, 0.0, 74.8, 2967449.892, 0.0, 0.0, 10.0, 396717.9, 15.0, 595076.85, 0.0, 0.0, 0.2, 7934.358, 25.0, 991794.75, 10.0, 396717.9, 1, 0, 0), ('uruguay', 3494382.0, 0.0, 0.0, 88.0, 3075056.16, 8.0, 279550.56, 4.0, 139775.28, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 139775.28, 12.0, 419325.83999999997, 0, 0, 0), ('panama', 3322576.0, 8.0, 265806.08, 10.0, 332257.60000000003, 32.0, 1063224.32, 27.0, 897095.52, 5.0, 166128.80000000002, 14.0, 465160.6400000001, 4.0, 132903.04, 46.0, 1528384.96, 59.0, 1960319.8399999999, 1, 0, 0)]",table_1_1333612_1,"As a VR ethnographer I'd ask for per-country avatar counts and I know the ethnic labels (Mestizo, Mulatto, Zambo, etc.) and population are the key fields. The query turns percent strings into numbers, computes per-ethnic-group counts from population, sums Afro and mixed shares, creates flags for prioritization, and orders by population. The schema maps Country and Population to country populations and the percent columns to ethnic shares used to estimate counts. Can you give me, for every country, the population and estimated counts for Native American, Whites, Mestizo, Mulatto, Blacks, Zambo and Asians (derived from the percent columns), plus combined Afro and mixed percentages and counts and flags for Afro ≥25% and Indigenous ≥30%, ordered by population descending? This question matches the query scope since it only requests per-country percentages turned into counts, combined Afro/mixed metrics, prioritization flags, and sorting by population.",persona,"A virtual-reality ethnographer designing demographically accurate avatar populations for immersive Latin American historical and cultural reconstructions. Goals: Generate per-country avatar counts by ethnicity (using 2010 population + 2005 ethnic distribution) so the VR population mixes look authentic. Identify countries with substantial Afro-descendant or Indigenous populations to prioritize culturally specific assets (music, clothing, language voiceover casting). Produce a shortlist of mid-to-large countries where small Asian or mixed categories are non-negligible so minority communities are not omitted from scenes. Example Queries: /* 1) Compute estimated headcounts for each ethnic group per country (percent strings -> numeric) */
SELECT
  Country,
  Population,
  (CAST(REPLACE(""Native American"", '%', '') AS FLOAT)/100.0) * Population AS Native_American_Count,
  (CAST(REPLACE(""Whites"", '%', '') AS FLOAT)/100.0) * Population AS White_Count,
  (CAST(REPLACE(""s Mestizo"", '%', '') AS FLOAT)/100.0) * Population AS Mestizo_Count,
  (CAST(REPLACE(""es Mulatto"", '%', '') AS FLOAT)/100.0) * Population AS Mulatto_Count,
  (CAST(REPLACE(""Blacks"", '%', '') AS FLOAT)/100.0) * Population AS Black_Count,
  (CAST(REPLACE(""s Zambo"", '%', '') AS FLOAT)/100.0) * Population AS Zambo_Count,
  (CAST(REPLACE(""Asians"", '%', '') AS FLOAT)/100.0) * Population AS Asian_Count
FROM table_1_1333612_1
ORDER BY Native_American_Count DESC; /* 2) Find countries where combined Afro-descendant share (Mulatto + Blacks + Zambo) exceeds 25% and return estimated counts */
SELECT
  Country,
  Population,
  (CAST(REPLACE(""es Mulatto"", '%', '') AS FLOAT) + CAST(REPLACE(""Blacks"", '%', '') AS FLOAT) + CAST(REPLACE(""s Zambo"", '%', '') AS FLOAT)) AS Afro_Percent,
  ((CAST(REPLACE(""es Mulatto"", '%', '') AS FLOAT) + CAST(REPLACE(""Blacks"", '%', '') AS FLOAT) + CAST(REPLACE(""s Zambo"", '%', '') AS FLOAT))/100.0) * Population AS Afro_Estimated_Count
FROM table_1_1333612_1
WHERE (CAST(REPLACE(""es Mulatto"", '%', '') AS FLOAT) + CAST(REPLACE(""Blacks"", '%', '') AS FLOAT) + CAST(REPLACE(""s Zambo"", '%', '') AS FLOAT)) > 25
ORDER BY Afro_Estimated_Count DESC; /* 3) Shortlist countries with >5,000,000 population where Native American >= 30% OR Asians >= 1% (to ensure minority representation) */
SELECT
  Country,
  Population,
  CAST(REPLACE(""Native American"", '%', '') AS FLOAT) AS Native_Percent,
  CAST(REPLACE(""Asians"", '%', '') AS FLOAT) AS Asian_Percent
FROM table_1_1333612_1
WHERE Population > 5000000
  AND (CAST(REPLACE(""Native American"", '%', '') AS FLOAT) >= 30
       OR CAST(REPLACE(""Asians"", '%', '') AS FLOAT) >= 1)
ORDER BY Population DESC;",reward,,
Which directors had at least 0.7 million U.S. viewers?,"
SELECT `Directed by`, COUNT(*), AVG(`U.S. viewers (million)`+0), MIN(`U.S. viewers (million)`+0), MAX(`U.S. viewers (million)`+0), GROUP_CONCAT(`Title`, '; ')
FROM `table_1_13336122_6`
WHERE `U.S. viewers (million)` != ''
GROUP BY `Directed by`
HAVING AVG(`U.S. viewers (million)`+0) >= 0.7
ORDER BY AVG(`U.S. viewers (million)`+0);
","
SELECT col3, COUNT(*), AVG(col6+0), MIN(col6+0), MAX(col6+0), GROUP_CONCAT(col2, '; ')
FROM `table_1_13336122_6`
WHERE col6 != ''
GROUP BY col3
HAVING AVG(col6+0) >= 0.7
ORDER BY AVG(col6+0);
","[('michael weaver', 1, 0.71, 0.71, 0.71, '""here i go again""'), ('michael lehmann', 1, 0.73, 0.73, 0.73, '""the party""'), ('millicent shelton', 1, 0.74, 0.74, 0.74, '""the ride-along""'), ('david duchovny', 1, 0.75, 0.75, 0.75, '""the way of the fist""'), ('john dahl', 1, 0.76, 0.76, 0.76, '""jfk to lax""'), ('eric stoltz', 1, 0.83, 0.83, 0.83, '""love song""')]",table_1_13336122_6,"STEP 1: Parse the SQL intent: group rows by `Directed by`, count episodes, compute average/min/max of `U.S. viewers (million)` (excluding blanks), concatenate titles, keep only directors whose average U.S. viewers >= 0.7, order by average. STEP 2: Choose ambiguity type: scope ambiguity — the phrase ""had at least 0.7 million viewers"" can refer to an average across a director's episodes (the SQL's meaning) or to individual episodes reaching that threshold. This fits because the query uses AVG but a natural question can be read both ways. STEP 3: Draft the question: ""Which directors had at least 0.7 million U.S. viewers?"" STEP 4: Explain the ambiguity: in the original query this means directors whose average U.S. viewers across their episodes is >= 0.7; alternatively it could mean directors who had at least one episode with >= 0.7 viewers (or every episode >= 0.7), which would require MAX or MIN conditions instead of AVG.",reserved,7,reward,,"type: Scope ambiguity | explanation: The SQL interprets this as directors whose average U.S. viewers across their episodes is >= 0.7; alternatively the question could mean directors who had any single episode reach >= 0.7 (or conversely every episode >= 0.7), which would change the aggregation (MAX or MIN) or the intended grouping/filtering."
"After joining the table to itself on t.Rank = u.Rank AND t.Building = u.Building and filtering to rows with t.Storeys > 0 OR t.Completed IN (1932,1964,1966,1968,1970,1972,1978,1979,1980,1983,1984), for each decade computed as ((Completed/10)*10) what are the Decade value, the Total count of rows, ROUND(AVG(Storeys),2) as AvgStoreys, SUM(CASE WHEN Storeys >= 20 THEN 1 ELSE 0 END) as TallCount, and the value of (t.Storeys IS u.Storeys) as SameStoreys, ordering decades by AvgStoreys descending and returning only the top 3?","
SELECT ((`Completed`/10)*10) AS `Decade`, COUNT(*) `Total`, ROUND(AVG(`Storeys`),2) `AvgStoreys`, SUM(CASE WHEN `Storeys` >= 20 THEN 1 ELSE 0 END) `TallCount`, (t.`Storeys` IS u.`Storeys`) `SameStoreys`
FROM `table_1_13397394_1` t JOIN `table_1_13397394_1` u ON t.`Rank` = u.`Rank` AND t.`Building` = u.`Building`
WHERE t.`Storeys` > 0 OR t.`Completed` IN (1932,1964,1966,1968,1970,1972,1978,1979,1980,1983,1984)
GROUP BY ((`Completed`/10)*10)
ORDER BY `AvgStoreys` DESC
LIMIT 3;
","SELECT ((t.col5/10)*10) AS `Decade`, COUNT(DISTINCT t.col1) AS `Total`, AVG(t.col4) AS `AvgStoreys`, SUM(CASE WHEN t.col4 >= 20 THEN 1 ELSE 0 END) AS `TallCount`, (t.col4 IS u.col4) AS `SameStoreys`
FROM `table_1_13397394_1` t JOIN `table_1_13397394_1` u ON t.col0 = u.col0 AND t.col1 = u.col1
WHERE t.col4 > 0
GROUP BY ((t.col5/10)*10)
ORDER BY `AvgStoreys`
LIMIT 3;","[(1932.0, 1, 10.0, 0, 1), (1970.0, 1, 12.0, 0, 1), (1964.0, 1, 14.0, 0, 1)]",table_1_13397394_1,"1) Parse SQL intent: produce top 3 decades by average Storeys with aggregates and a self-join, applying a WHERE filter that allows t.Storeys > 0 or specific Completed years. 2) Map schema semantics: Completed -> decade calculation, Storeys -> AVG and conditional SUM, Rank and Building -> join keys. 3) Draft the question: request Decade ((Completed/10)*10), COUNT(*) as Total, ROUND(AVG(Storeys),2) as AvgStoreys, SUM(CASE WHEN Storeys >=20 THEN 1 ELSE 0 END) as TallCount, and (t.Storeys IS u.Storeys) as SameStoreys, and specify grouping, ordering, and limit. 4) Validate: ensure the exact year list, join condition, GROUP BY, ORDER BY DESC, and LIMIT 3 are present.",reserved,21,reward,,
"Give me all Illinois districts ordered by how razor-thin the race was (smallest margin first) and then by earliest first-elected, including district, incumbent, party, first elected, results, candidates, the two percentages, the margin, a long-tenured flag and whether the race was unopposed/retired/contested.","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Results`,
    `Candidates`,
    instr(`Candidates`, '%') AS p1,
    CASE
      WHEN instr(`Candidates`, '%') > 0
      THEN CAST(
        substr(
          `Candidates`,
          CASE WHEN instr(`Candidates`, '%') > 4 THEN instr(`Candidates`, '%') - 3 ELSE 1 END,
          3
        ) AS INTEGER
      )
      ELSE NULL
    END AS pct1,
    CASE
      WHEN instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0
      THEN instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') + instr(`Candidates`, '%')
      ELSE 0
    END AS p2,
    CASE
      WHEN instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0
      THEN CAST(
        substr(
          `Candidates`,
          CASE
            WHEN (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') + instr(`Candidates`, '%')) > 4
            THEN (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') + instr(`Candidates`, '%')) - 3
            ELSE 1
          END,
          3
        ) AS INTEGER
      )
      ELSE NULL
    END AS pct2
  FROM `table_1_1341423_13`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Results`,
  `Candidates`,
  pct1,
  pct2,
  CASE WHEN pct1 IS NOT NULL AND pct2 IS NOT NULL THEN ABS(pct1 - pct2) ELSE NULL END AS `margin`,
  CASE WHEN `First elected` <= 1985 THEN 1 ELSE 0 END AS `long_tenured_flag`,
  CASE
    WHEN LOWER(`Results`) LIKE '%unopposed%' OR LOWER(`Candidates`) LIKE '%unopposed%' THEN 'unopposed'
    WHEN LOWER(`Results`) LIKE '%retired%' THEN 'retired'
    ELSE 'contested'
  END AS `race_type`
FROM parsed
ORDER BY
  CASE WHEN pct1 IS NOT NULL AND pct2 IS NOT NULL THEN ABS(pct1 - pct2) ELSE 999 END ASC,
  `First elected` ASC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    instr(col5, '%') AS p1,
    CASE
      WHEN instr(col5, '%') > 0
      THEN CAST(
        substr(
          col5,
          CASE WHEN instr(col5, '%') > 4 THEN instr(col5, '%') - 3 ELSE 1 END,
          3
        ) AS INTEGER
      )
      ELSE NULL
    END AS pct1,
    CASE
      WHEN instr(substr(col5, instr(col5, '%') + 1), '%') > 0
      THEN instr(substr(col5, instr(col5, '%') + 1), '%') + instr(col5, '%')
      ELSE 0
    END AS p2,
    CASE
      WHEN instr(substr(col5, instr(col5, '%') + 1), '%') > 0
      THEN CAST(
        substr(
          col5,
          CASE
            WHEN (instr(substr(col5, instr(col5, '%') + 1), '%') + instr(col5, '%')) > 4
            THEN (instr(substr(col5, instr(col5, '%') + 1), '%') + instr(col5, '%')) - 3
            ELSE 1
          END,
          3
        ) AS INTEGER
      )
      ELSE NULL
    END AS pct2
  FROM `table_1_1341423_13`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  pct1,
  pct2,
  CASE WHEN pct1 IS NOT NULL AND pct2 IS NOT NULL THEN ABS(pct1 - pct2) ELSE NULL END AS `margin`,
  CASE WHEN col3 <= 1985 THEN 1 ELSE 0 END AS `long_tenured_flag`,
  CASE
    WHEN LOWER(col4) LIKE '%unopposed%' OR LOWER(col5) LIKE '%unopposed%' THEN 'unopposed'
    WHEN LOWER(col4) LIKE '%retired%' THEN 'retired'
    ELSE 'contested'
  END AS `race_type`
FROM parsed
ORDER BY
  CASE WHEN pct1 IS NOT NULL AND pct2 IS NOT NULL THEN ABS(pct1 - pct2) ELSE 999 END ASC,
  col3 ASC;
","[('illinois 10', 'john porter', 'republican', 1980.0, 'retired republican hold', 'mark kirk (r) 51% lauren beth gash (d) 49%', 51, 49, 2, 1, 'retired'), ('illinois 15', 'thomas w. ewing', 'republican', 1998.0, 'retired republican hold', 'timothy v. johnson (r) 53% mike kelleher (d) 47%', 53, 47, 6, 0, 'retired'), ('illinois 17', 'lane evans', 'democratic', 1982.0, 're-elected', 'lane evans (d) 55% mark baker (r) 45%', 55, 45, 10, 1, 'contested'), ('illinois 11', 'jerry weller', 'republican', 1994.0, 're-elected', 'jerry weller (r) 56% james stevenson (d) 44%', 56, 44, 12, 0, 'contested'), ('illinois 6', 'henry hyde', 'republican', 1974.0, 're-elected', 'henry hyde (r) 59% brent christensen (d) 41%', 59, 41, 18, 1, 'contested'), ('illinois 8', 'phil crane', 'republican', 1969.0, 're-elected', 'phil crane (r) 61% lance pressl (d) 39%', 61, 39, 22, 1, 'contested'), ('illinois 19', 'david d. phelps', 'democratic', 1998.0, 're-elected', 'david d. phelps (d) 65% jim eatherly (r) 35%', 65, 35, 30, 0, 'contested'), ('illinois 13', 'judy biggert', 'republican', 1998.0, 're-elected', 'judy biggert (r) 66% thomas mason (d) 34%', 66, 34, 32, 0, 'contested'), ('illinois 18', 'ray lahood', 'republican', 1994.0, 're-elected', 'ray lahood (r) 67% joyce harant (d) 33%', 67, 33, 34, 0, 'contested'), ('illinois 14', 'dennis hastert', 'republican', 1986.0, 're-elected', 'dennis hastert (r) 74% vern deljonson (d) 26%', 74, 26, 48, 0, 'contested'), ('illinois 3', 'bill lipinski', 'democratic', 1982.0, 're-elected', 'bill lipinski (d) 76% karl groth (r) 24%', 76, 24, 52, 1, 'contested'), ('illinois 9', 'jan schakowsky', 'democratic', 1998.0, 're-elected', 'jan schakowsky (d) 76% dennis driscoll (r) 24%', 76, 24, 52, 0, 'contested'), ('illinois 7', 'danny k. davis', 'democratic', 1996.0, 're-elected', 'danny k. davis (d) 86% robert dallas (r) 14%', 86, 14, 72, 0, 'contested'), ('illinois 4', 'luis gutierrez', 'democratic', 1992.0, 're-elected', 'luis gutierrez (d) 89% stephanie sailor (i) 11%', 89, 11, 78, 0, 'contested'), ('illinois 2', 'jesse l. jackson jr.', 'democratic', 1995.0, 're-elected', 'jesse l. jackson jr. (d) 90% robert gordon (r) 10%', 90, 10, 80, 0, 'contested'), ('illinois 12', 'jerry costello', 'democratic', 1988.0, 're-elected', 'jerry costello (d) unopposed', None, None, None, 0, 'unopposed'), ('illinois 5', 'rod blagojevich', 'democratic', 1996.0, 're-elected', 'rod blagojevich (d) 88%', 88, None, None, 0, 'contested')]",table_1_1341423_13,"As a curator planning routes I want a single ordered list prioritizing drama and then continuity, phrased less technically but aware of 'first elected'. The SQL returns all rows with parsed top-two percentages, a margin, a long-tenured flag, and a race type, ordered by smallest margin then by earliest first-elected. The schema maps those computed pct1, pct2, margin, long_tenured_flag and race_type alongside the base fields. Draft question: Give me all Illinois districts ordered by how razor-thin the race was (smallest margin first) and then by earliest first-elected, including district, incumbent, party, first elected, results, candidates, the two percentages, the margin, a long-tenured flag and whether the race was unopposed/retired/contested. Validation: This requests exactly the columns computed and the ordering used by the query.",persona,"A civic heritage tour curator who creates immersive, district-by-district theatrical walking tours of late-1990s Illinois congressional races, casting scenes around tight contests, long-serving incumbents and quirky uncontested elections. Goals: Identify the closest races (smallest vote-margin) to script high-drama reenactment stops where the outcome could have plausibly swung either way. Find long-tenured incumbents (early first-elected dates) to locate archival displays and interview subjects for historical context and continuity themes. Locate unopposed races and 'retired hold' outcomes to build one-person monologues and transitional scenes about political succession. Map party geography across districts to design route pacing (more contested/competitive neighborhoods vs. safely held districts) and tailor narrative tone. Example Queries: -- 1) Find districts where the top two vote shares differ by 5 percentage points or less (PostgreSQL-style regex extraction) WITH pcts AS (   SELECT ""District"", ""Incumbent"", ""Candidates"",     CAST(regexp_matches(""Candidates"", '(\\d+)%')[1] AS INTEGER) AS pct1,     CAST(regexp_matches(""Candidates"", '\\d+%.*?(\\d+)%')[1] AS INTEGER) AS pct2   FROM table_1_1341423_13 ) SELECT ""District"", ""Incumbent"", ""Candidates"", ABS(pct1 - pct2) AS margin FROM pcts WHERE ABS(pct1 - pct2) <= 5 ORDER BY margin ASC;  -- 2) List long-tenured incumbents (first elected in or before 1985) to identify archival stops SELECT ""District"", ""Incumbent"", ""Party"", ""First elected"" FROM table_1_1341423_13 WHERE ""First elected"" <= 1985 ORDER BY ""First elected"" ASC;  -- 3) Find districts with unopposed races or explicit 'retired' results to create single-actor scenes SELECT ""District"", ""Incumbent"", ""Results"", ""Candidates"" FROM table_1_1341423_13 WHERE LOWER(""Results"") LIKE '%unopposed%'    OR LOWER(""Candidates"") LIKE '%unopposed%'    OR LOWER(""Results"") LIKE '%retired%' ORDER BY ""District"";",reward,,
"List the top 10 Parties by count of Results = 'Re-elected' (among rows with First elected < 1990 and non-empty Party), and for each Party also report the count of Results = 'Retired Republican hold'?","
SELECT t.`Party`, SUM(t.`Results` = m.`Re-elected`) `Re-elected count`, SUM(t.`Results` = m.`Retired Republican hold`) `Retired Republican hold count`
FROM `table_1_1341423_35` t
JOIN (VALUES ('Re-elected','Retired Republican hold')) m(`Re-elected`,`Retired Republican hold`) ON 1=1
WHERE t.`First elected` < 1990 AND t.`Party` <> ''
GROUP BY t.`Party`
ORDER BY `Re-elected count` DESC
LIMIT 10;
","SELECT t.col2 col2, COUNT(*) `Total`, SUM(t.col4 = 'Re-elected') `Re-elected count`
FROM `table_1_1341423_35` t
WHERE t.col2 <> ''
GROUP BY t.col2
HAVING COUNT(*) > 0 AND SUM(t.col4 = 'Re-elected') >= 0
ORDER BY `Re-elected count` DESC
LIMIT 10;","[('republican', 8, 0), ('democratic', 8, 0)]",table_1_1341423_35,"Parse intent: aggregate counts per Party for two specific Result labels, apply First elected < 1990 and Party <> '', sort by the re-elected count descending and cap at 10. Map schema: Party groups rows, Results compared to 'Re-elected' and 'Retired Republican hold', First elected is a year threshold. Draft: a concise question requesting those counts per Party with the filters, sort, and limit. Validate: includes all SQL elements: Party, both counts, First elected filter, non-empty Party, grouping, ordering, and limit.",reserved,12,reward,,
"Can you produce a table of all Virginia districts showing district, incumbent, party, first-elected year, results, candidates, an outcome flag (Retired/Gain/Hold/Re-elected/Other), whether the race was unopposed or contested, each incumbent's seniority rank, the total number of open (retired) seats, the total unopposed races, and the current seat count by party?","
WITH `party_counts` AS (
  SELECT `Party`, COUNT(*) AS `Seat_count`
  FROM `table_1_1341423_46`
  GROUP BY `Party`
)
SELECT
  t.`District`,
  t.`Incumbent`,
  t.`Party`,
  t.`First elected`,
  t.`Results`,
  t.`Candidates`,
  CASE
    WHEN t.`Results` LIKE '%Retired%' THEN '`Retired`'
    WHEN LOWER(t.`Results`) LIKE '%gain%' THEN '`Gain`'
    WHEN LOWER(t.`Results`) LIKE '%hold%' THEN '`Hold`'
    WHEN LOWER(t.`Results`) LIKE '%re-elected%' THEN '`Re-elected`'
    ELSE '`Other`'
  END AS `Outcome_flag`,
  CASE
    WHEN LOWER(t.`Candidates`) LIKE '%unopposed%' THEN '`Unopposed`'
    ELSE '`Contested`'
  END AS `Contest_status`,
  RANK() OVER (ORDER BY t.`First elected` ASC) AS `Seniority_rank`,
  (SELECT COUNT(*) FROM `table_1_1341423_46` WHERE `Results` LIKE '%Retired%') AS `Open_seats_total`,
  (SELECT COUNT(*) FROM `table_1_1341423_46` WHERE LOWER(`Candidates`) LIKE '%unopposed%') AS `Unopposed_total`,
  pc.`Seat_count` AS `Party_seat_count`
FROM `table_1_1341423_46` AS t
LEFT JOIN `party_counts` pc ON t.`Party` = pc.`Party`
ORDER BY `Outcome_flag` DESC, `SenioritY_rank` ASC, t.`District`;
","
WITH `party_counts` AS (
  SELECT col2, COUNT(*) AS `Seat_count`
  FROM `table_1_1341423_46`
  GROUP BY col2
)
SELECT
  t.col0,
  t.col1,
  t.col2,
  t.col3,
  t.col4,
  t.col5,
  CASE
    WHEN t.col4 LIKE '%Retired%' THEN '`Retired`'
    WHEN LOWER(t.col4) LIKE '%gain%' THEN '`Gain`'
    WHEN LOWER(t.col4) LIKE '%hold%' THEN '`Hold`'
    WHEN LOWER(t.col4) LIKE '%re-elected%' THEN '`Re-elected`'
    ELSE '`Other`'
  END AS `Outcome_flag`,
  CASE
    WHEN LOWER(t.col5) LIKE '%unopposed%' THEN '`Unopposed`'
    ELSE '`Contested`'
  END AS `Contest_status`,
  RANK() OVER (ORDER BY t.col3 ASC) AS `Seniority_rank`,
  (SELECT COUNT(*) FROM `table_1_1341423_46` WHERE col4 LIKE '%Retired%') AS `Open_seats_total`,
  (SELECT COUNT(*) FROM `table_1_1341423_46` WHERE LOWER(col5) LIKE '%unopposed%') AS `Unopposed_total`,
  pc.`Seat_count` AS `Party_seat_count`
FROM `table_1_1341423_46` AS t
LEFT JOIN `party_counts` pc ON t.col2 = pc.col2
ORDER BY `Outcome_flag` DESC, `SenioritY_rank` ASC, t.col0;
","[('virginia 7', 'thomas j. bliley, jr.', 'republican', 1980.0, 'retired republican hold', 'eric cantor (r) 67% warren stewart (d) 33%', '`Retired`', '`Contested`', 1, 2, 3, 3), ('virginia 2', 'owen b. pickett', 'democratic', 1986.0, 'retired republican gain', 'ed schrock (r) 52% jody wagner (d) 48%', '`Retired`', '`Contested`', 5, 2, 3, 5), ('virginia 10', 'frank wolf', 'republican', 1980.0, 're-elected', 'frank wolf (r) 85%', '`Re-elected`', '`Contested`', 1, 2, 3, 3), ('virginia 4', 'norman sisisky', 'democratic', 1982.0, 're-elected', 'norman sisisky (d) unopposed', '`Re-elected`', '`Unopposed`', 3, 2, 3, 5), ('virginia 9', 'rick boucher', 'democratic', 1982.0, 're-elected', 'rick boucher (d) 70% michael osborne (r) 30%', '`Re-elected`', '`Contested`', 3, 2, 3, 5), ('virginia 8', 'jim moran', 'democratic', 1990.0, 're-elected', 'jim moran (d) 64% demaris h. miller (r) 35%', '`Re-elected`', '`Contested`', 6, 2, 3, 5), ('virginia 3', 'bobby scott', 'democratic', 1992.0, 're-elected', 'bobby scott (d) unopposed', '`Re-elected`', '`Unopposed`', 7, 2, 3, 5), ('virginia 6', 'bob goodlatte', 'republican', 1992.0, 're-elected', 'bob goodlatte (r) unopposed', '`Re-elected`', '`Unopposed`', 7, 2, 3, 3), ('virginia 5', 'virgil goode', 'independent', 1996.0, 're-elected, independent gain', 'virgil goode (i) 68% john boyd (d) 31%', '`Gain`', '`Contested`', 9, 2, 3, 1)]",table_1_1341423_46,"As a nonpartisan state political analyst I use clear terms like open seats, unopposed, and seniority rather than SQL jargon and I know the schema enough to ask for first-elected and incumbent names. The query annotates every district with an outcome flag (Retired/Gain/Hold/Re-elected/Other), contest status, computes a seniority rank, and also returns totals for retired (open) seats and unopposed races plus seat counts by party. The table columns map to District, Incumbent, Party, First elected, Results, and Candidates and the query derives Outcome_flag, Contest_status, Seniority_rank, Open_seats_total, Unopposed_total, and Party_seat_count. Draft question: Can you produce a table of all Virginia districts showing district, incumbent, party, first-elected year, results, candidates, an outcome flag (Retired/Gain/Hold/Re-elected/Other), whether the race was unopposed or contested, each incumbent's seniority rank, the total number of open (retired) seats, the total unopposed races, and the current seat count by party? Validation: This matches the query which returns every row with those derived flags, totals, and per-party counts.",persona,"State political data analyst at a nonpartisan election research institute who compiles and summarizes Virginia House election outcomes to inform media briefings and policy reports. They use this database to track incumbency, open seats, unopposed races, and party shifts across Virginia districts. Goals: Identify open/retiring seats to prioritize follow-up reporting and analysis. Measure incumbency strength by locating unopposed races and long-tenured incumbents. Detect party gains or losses and produce simple seat-count summaries by party for briefings. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Results FROM table_1_1341423_46 WHERE Results LIKE '%Retired%'; SELECT Party, COUNT(*) AS seat_count FROM table_1_1341423_46 GROUP BY Party ORDER BY seat_count DESC; SELECT District, Incumbent, Party, ""First elected"" FROM table_1_1341423_46 WHERE LOWER(Results) LIKE '%unopposed%' OR LOWER(Candidates) LIKE '%unopposed%';",reward,,
"Show District, Incumbent, Party, First elected, Results, and Candidates for Wisconsin and calculate Average margin = CAST(((66 - 34) + (51 - 49) + (64 - 36) + (78 - 22) + (65 - 35) + (63 - 37) + (75 - 25)) / 7.0 AS REAL), and if the smallest margin among (66-34, 51-49, 64-36, 78-22, 65-35, 63-37, 75-25) is <= 5 then report Priority target = 'Wisconsin 2 - Tammy Baldwin' else report NULL?","
SELECT '`District`', '`Incumbent`', '`Party`', '`First elected`', '`Results`', '`Candidates`', CAST(((66 - 34) + (51 - 49) + (64 - 36) + (78 - 22) + (65 - 35) + (63 - 37) + (75 - 25)) / 7.0 AS REAL) `Average margin`, CASE WHEN MIN((66 - 34),(51 - 49),(64 - 36),(78 - 22),(65 - 35),(63 - 37),(75 - 25)) <= 5 THEN '`Wisconsin 2` - `Tammy Baldwin`' ELSE NULL END `Priority target`;
","
SELECT 'col0', 'col1', 'col2', 'col3', 'col4', 'col5', CAST(((66 - 34) + (51 - 49) + (64 - 36) + (78 - 22) + (65 - 35) + (63 - 37) + (75 - 25)) / 7.0 AS REAL) `Average margin`, CASE WHEN MIN((66 - 34),(51 - 49),(64 - 36),(78 - 22),(65 - 35),(63 - 37),(75 - 25)) <= 5 THEN '`Wisconsin 2` - `Tammy Baldwin`' ELSE NULL END `Priority target`;
","[('col0', 'col1', 'col2', 'col3', 'col4', 'col5', 32.0, '`Wisconsin 2` - `Tammy Baldwin`')]",table_1_1341423_49,"1) The SQL intent is to list all table columns, calculate an average of seven vote-margin differences, and conditionally identify a priority target when the smallest margin is <=5. 2) The schema columns are District, Incumbent, Party, First elected, Results, Candidates, and the margins are computed from the percentage pairs in Candidates. 3) Draft a question that explicitly asks for those columns, the exact average formula dividing the sum of the seven differences by 7.0 as a real number, and the conditional Priority target 'Wisconsin 2 - Tammy Baldwin' when the minimum margin is <= 5. 4) Confirm the question mentions every difference term and the conditional outcome.",reserved,9,reward,,
Which Florida districts first elected in or before 1992 were unopposed?,"
SELECT `District`, `Incumbent`, `Party`, `First elected`, `Candidates`, (length(`Candidates`) - length(replace(`Candidates`, '%', ''))) `Percent_sign_count`, ((length(`Candidates`) - length(replace(`Candidates`, '%', ''))) = 0) `Likely_unopposed`, ((length(`Candidates`) - length(replace(`Candidates`, '%', ''))) >= 2) `Clearly_competitive`, 1 `Florida 3`, 1 `Florida 21` FROM `table_1_1341453_11` WHERE `First elected` <= 1992;
","
SELECT col0, col1, col2, col3, col5, (length(col5) - length(replace(col5, '%', ''))) `Percent_sign_count`, ((length(col5) - length(replace(col5, '%', ''))) = 0) `Likely_unopposed`, ((length(col5) - length(replace(col5, '%', ''))) >= 2) `Clearly_competitive`, 1 `Florida 3`, 1 `Florida 21` FROM `table_1_1341453_11` WHERE col3 <= 1992;
","[('florida 3', 'corrine brown', 'democratic', 1992.0, 'corrine brown (d) 56% bill randall (d) 44%', 2, 0, 1, 1, 1), ('florida 4', 'tillie fowler', 'republican', 1992.0, 'tillie fowler (r) unopposed', 0, 1, 0, 1, 1), ('florida 5', 'karen thurman', 'democratic', 1992.0, 'karen thurman (d) 66.3% jack gargan (ref) 33.7%', 2, 0, 1, 1, 1), ('florida 6', 'cliff stearns', 'republican', 1988.0, 'cliff stearns (r) unopposed', 0, 1, 0, 1, 1), ('florida 7', 'john mica', 'republican', 1992.0, 'john mica (r) unopposed', 0, 1, 0, 1, 1), ('florida 8', 'bill mccollum', 'republican', 1980.0, 'bill mccollum (r) 66% al krulick (d) 34%', 2, 0, 1, 1, 1), ('florida 9', 'michael bilirakis', 'republican', 1982.0, 'michael bilirakis (r) unopposed', 0, 1, 0, 1, 1), ('florida 10', 'bill young', 'republican', 1970.0, 'bill young (r) unopposed', 0, 1, 0, 1, 1), ('florida 12', 'charles canady', 'republican', 1992.0, 'charles canady (r) unopposed', 0, 1, 0, 1, 1), ('florida 13', 'dan miller', 'republican', 1992.0, 'dan miller (r) unopposed', 0, 1, 0, 1, 1), ('florida 14', 'porter goss', 'republican', 1988.0, 'porter goss (r) unopposed', 0, 1, 0, 1, 1), ('florida 17', 'carrie meek', 'democratic', 1992.0, 'carrie meek (d) unopposed', 0, 1, 0, 1, 1), ('florida 18', 'ileana ros-lehtinen', 'republican', 1989.0, 'ileana ros-lehtinen (r) unopposed', 0, 1, 0, 1, 1), ('florida 20', 'peter deutsch', 'democratic', 1992.0, 'peter deutsch (d) unopposed', 0, 1, 0, 1, 1), ('florida 21', 'lincoln diaz-balart', 'republican', 1992.0, 'lincoln diaz-balart (r) 75% patrick cusack (d) 25%', 2, 0, 1, 1, 1), ('florida 22', 'clay shaw', 'republican', 1980.0, 'clay shaw (r) unopposed', 0, 1, 0, 1, 1)]",table_1_1341453_11,"STEP 1: Parse the SQL intent: select District, Incumbent, Party, First elected, Candidates; compute Percent_sign_count as number of '%' characters in Candidates; compute Likely_unopposed when Percent_sign_count = 0 and Clearly_competitive when Percent_sign_count >= 2; include constant columns with value 1 for 'Florida 3' and 'Florida 21'; filter rows with First elected <= 1992 (i.e., incumbents first elected in or before 1992). STEP 2: Determine ambiguity type: attachment (modifier) ambiguity fits well because the phrase 'first elected in or before 1992' and the adjective 'unopposed' can attach either to the district or to the incumbent/race; the SQL specifically attaches it to the incumbent's First elected and infers 'unopposed' from the Candidates field lacking '%' characters. STEP 3: Draft the question: ""Which Florida districts first elected in or before 1992 were unopposed?"" STEP 4: Explain ambiguity: in the original query 'first elected in or before 1992' applies to the incumbent's First elected column and 'unopposed' is operationalized as no '%' in the Candidates string (Likely_unopposed); alternatively the question could mean the district itself was created by 1992, or that the race (not necessarily the incumbent) had no opponents in 1998, or that 'unopposed' means an explicit 'unopposed' label rather than absence of percentage figures.",reserved,3,reward,,"type: Attachment ambiguity | explanation: The modifier 'first elected in or before 1992' can attach to the incumbent (as in the query) or to the district's creation/other entity, and 'unopposed' can refer to the incumbent being unopposed, the race being unopposed, or simply absence of percentage figures in the Candidates text—leading to multiple interpretations."
"Which distinct District, Incumbent and Party entries with Results containing 'Retired' have the highest absolute difference between the two vote percentages extracted from the Candidates field (compute Margin as ABS(CAST((first candidate percentage parsed from Candidates - second candidate percentage parsed from Candidates) AS REAL))), and include the constant 1 labeled 'Wisconsin 1', returning the top 3 by Margin in descending order?","
SELECT DISTINCT `District`, `Incumbent`, `Party`,
ABS(CAST(
(
  substr(`Candidates`, instr(`Candidates`, ')')+2, instr(`Candidates`, '%') - instr(`Candidates`, ')') -1)
 -
  substr(
    substr(`Candidates`, instr(`Candidates`, '%')+1),
    instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')')+2,
    instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')') -1
  )
) AS REAL)) `Margin`, 1 `Wisconsin 1`
FROM `table_1_1341453_51`
WHERE `Results` LIKE '%Retired%'
ORDER BY `Margin` DESC
LIMIT 3;
","
SELECT DISTINCT col0, col1, col2,
ABS(CAST(
(
  substr(col5, instr(col5, ')')+2, instr(col5, '%') - instr(col5, ')') -1)
 -
  substr(
    substr(col5, instr(col5, '%')+1),
    instr(substr(col5, instr(col5, '%')+1), ')')+2,
    instr(substr(col5, instr(col5, '%')+1), '%') - instr(substr(col5, instr(col5, '%')+1), ')') -1
  )
) AS REAL)) `Margin`, 1 `Wisconsin 1`
FROM `table_1_1341453_51`
WHERE col4 LIKE '%Retired%'
ORDER BY `Margin` DESC
LIMIT 3;
","[('wisconsin 1', 'mark neumann', 'republican', 14.399999999999999, 1), ('wisconsin 2', 'scott klug', 'republican', 5.100000000000001, 1)]",table_1_1341453_51,"1) Intent: return up to three rows filtered by Results containing 'Retired', with District, Incumbent, Party, a computed Margin equal to the absolute numeric difference between the two Candidates percentages, plus a constant column 'Wisconsin 1', ordered by Margin DESC. 2) Map schema: percentages must be extracted from the Candidates text and converted to REAL for subtraction and ABS. 3) Draft the question to request these exact fields and computation, filtered, ordered and limited per the SQL. 4) Confirm all SQL components (columns, calculation, filter, order, limit, constant) are mentioned.",reserved,11,reward,,
"Provide District, Incumbent, Party, First elected, Result and Candidates for all records where First elected < 1996 or Party = 'Democratic', and if Party = 'Republican' and First elected <= 1988, also provide the Insight '`New York 1`, `New York 6`, `New York 7`, `New York 11`, `New York 22`, `New York 25`, `New York 27`, `New York 29` - Long-serving Republican targets'?","
SELECT `District`, `Incumbent`, `Party`, `First elected`, `Result`, `Candidates`,
CASE WHEN `Party` = 'Republican' AND `First elected` <= 1988 THEN '`New York 1`, `New York 6`, `New York 7`, `New York 11`, `New York 22`, `New York 25`, `New York 27`, `New York 29` - Long-serving Republican targets' END AS `Insight`
FROM `table_1_1341472_34`
WHERE `First elected` < 1996 OR `Party` = 'Democratic';
","
SELECT col0, col1, col2, col3, col4, col5,
CASE WHEN col2 = 'Republican' AND col3 <= 1988 THEN '`New York 1`, `New York 6`, `New York 7`, `New York 11`, `New York 22`, `New York 25`, `New York 27`, `New York 29` - Long-serving Republican targets' END AS `Insight`
FROM `table_1_1341472_34`
WHERE col3 < 1996 OR col2 = 'Democratic';
","[('new york 1', 'michael forbes', 'republican', 1994.0, 're-elected', 'michael forbes (r) 54.72% nora bredes (d) 45.28%', None), ('new york 6', 'floyd flake', 'democratic', 1986.0, 're-elected', 'floyd flake (d) 84.85% jorawar misir (r) 15.14%', None), ('new york 7', 'thomas manton', 'democratic', 1984.0, 're-elected', 'thomas manton (d) 71.07% rose birtley (r) 28.93%', None), ('new york 11', 'major owens', 'democratic', 1982.0, 're-elected', 'major owens (d) 91.95% claudette hayle (r) 8.04%', None), ('new york 22', 'gerald solomon', 'republican', 1978.0, 're-elected', 'gerald solomon (r) 60.48% steve james (d) 39.52%', None), ('new york 25', 'jim walsh', 'republican', 1988.0, 're-elected', 'jim walsh (r) 55.11% marty mack (d) 44.89%', None), ('new york 27', 'bill paxon', 'republican', 1988.0, 're-elected', 'bill paxon (r) 59.88% thomas fricano (d) 40.12%', None), ('new york 29', 'john lafalce', 'democratic', 1974.0, 're-elected', 'john lafalce (d) 61.99% david callard (r) 38.01%', None)]",table_1_1341472_34,"1) Parse SQL intent: produce the six columns and a conditional Insight string for Republicans first elected in or before 1988, restricting rows to First elected < 1996 or Party = Democratic. 2) Map schema: the table provides District, Incumbent, Party, First elected, Result, Candidates. 3) Draft a direct question asking for those columns and the CASE WHEN Insight text. 4) Validate that all selected columns, the WHERE clause, and the exact Insight text are included.",reserved,10,reward,,
"List the 1996 Texas House races that are gains, incumbent defeats, retirements or within 10 points, putting turnovers/upsets first and then the closest races, and show district, incumbent, years served, the two vote percentages, margin and the Tight/Competitive/Safe label?","
WITH RECURSIVE
base AS (
  SELECT rowid AS rid, `District`, `Incumbent`, `Party`, `First elected`, `Result`, `Candidates`
  FROM `table_1_1341472_45`
),
-- reverse each Candidates string
rev AS (
  SELECT rid, `Candidates` AS orig, 1 AS pos, '' AS revstr, length(`Candidates`) AS orig_len FROM base
  UNION ALL
  SELECT rid, orig, pos+1, revstr || substr(orig,pos,1), orig_len FROM rev WHERE pos <= orig_len
),
rev_full AS (
  SELECT rid, orig AS `Candidates`, revstr FROM rev WHERE pos = orig_len+1
),
-- extract reversed-number fragments around '%' in the reversed string
nums AS (
  SELECT
    b.*,
    r.revstr,
    instr(r.revstr, '%') AS rev_pct_pos1,
    instr(substr(r.revstr, instr(r.revstr, '%')+1), '%') AS rev_next_after_pos1,
    -- reversed fragment corresponding to original SECOND percentage (appears first in reversed)
    CASE
      WHEN instr(substr(r.revstr, instr(r.revstr, '%')+1), ' ') > 0
      THEN substr(r.revstr, instr(r.revstr, '%')+1, instr(substr(r.revstr, instr(r.revstr, '%')+1),' ') - 1)
      ELSE substr(r.revstr, instr(r.revstr, '%')+1)
    END AS rev_num_second,
    -- compute position of the second '%' in the reversed string (which corresponds to original FIRST percentage)
    (instr(r.revstr, '%') + IFNULL(instr(substr(r.revstr, instr(r.revstr, '%')+1), '%'),0)) AS rev_pct_pos2,
    -- reversed fragment corresponding to original FIRST percentage (found at rev_pct_pos2)
    CASE
      WHEN (instr(substr(r.revstr, (instr(r.revstr, '%') + IFNULL(instr(substr(r.revstr, instr(r.revstr, '%')+1), '%'),0)) +1), ' ') > 0)
      THEN substr(r.revstr, (instr(r.revstr, '%') + IFNULL(instr(substr(r.revstr, instr(r.revstr, '%')+1), '%'),0)) +1, instr(substr(r.revstr, (instr(r.revstr, '%') + IFNULL(instr(substr(r.revstr, instr(r.revstr, '%')+1), '%'),0)) +1), ' ') -1)
      ELSE substr(r.revstr, (instr(r.revstr, '%') + IFNULL(instr(substr(r.revstr, instr(r.revstr, '%')+1), '%'),0)) +1)
    END AS rev_num_first
  FROM base b JOIN rev_full r USING(rid)
),
-- reverse the small reversed-number strings to obtain normal numeric strings for pct1 and pct2
revnum_first AS (
  SELECT rid, rev_num_first AS orig_s, 1 AS pos, '' AS rev_s, length(rev_num_first) AS len_s FROM nums
  UNION ALL
  SELECT rid, orig_s, pos+1, rev_s || substr(orig_s,pos,1), len_s FROM revnum_first WHERE pos <= len_s
),
revnum_first_full AS (
  SELECT rid, rev_s AS pct1_str FROM revnum_first WHERE pos = len_s+1
),
revnum_second AS (
  SELECT rid, rev_num_second AS orig_s, 1 AS pos, '' AS rev_s, length(rev_num_second) AS len_s FROM nums
  UNION ALL
  SELECT rid, orig_s, pos+1, rev_s || substr(orig_s,pos,1), len_s FROM revnum_second WHERE pos <= len_s
),
revnum_second_full AS (
  SELECT rid, rev_s AS pct2_str FROM revnum_second WHERE pos = len_s+1
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  (1996 - `First elected`) AS years_in_office,
  `Result`,
  -- parsed percentage values (first candidate, second candidate) as reals
  CAST(pf.pct1_str AS REAL) AS pct_first_candidate,
  CAST(ps.pct2_str AS REAL) AS pct_second_candidate,
  ABS(CAST(pf.pct1_str AS REAL) - CAST(ps.pct2_str AS REAL)) AS margin_pct,
  -- competitiveness classification
  CASE
    WHEN ABS(CAST(pf.pct1_str AS REAL) - CAST(ps.pct2_str AS REAL)) < 5 THEN 'Tight (<5%)'
    WHEN ABS(CAST(pf.pct1_str AS REAL) - CAST(ps.pct2_str AS REAL)) < 10 THEN 'Competitive (<10%)'
    ELSE 'Safe (>=10%)'
  END AS competitiveness,
  -- drama flags for alternate-history seeding
  CASE WHEN `Result` LIKE '%gain%' OR `Result` LIKE '%Lost%' THEN 1 ELSE 0 END AS turnover_or_incumbent_defeat_flag,
  CASE WHEN `Result` LIKE '%Retired%' OR `Result` LIKE '%Lost%' THEN 1 ELSE 0 END AS retired_or_defeated_long_tenure_flag,
  `Candidates`
FROM nums n
LEFT JOIN revnum_first_full pf USING(rid)
LEFT JOIN revnum_second_full ps USING(rid)
WHERE
  -- focus output on races that seed drama or are plausibly interesting for Monte Carlo modeling:
  (`Result` LIKE '%gain%' OR `Result` LIKE '%Lost%' OR `Result` LIKE '%Retired%' OR ABS(CAST(pf.pct1_str AS REAL) - CAST(ps.pct2_str AS REAL)) < 10)
ORDER BY turnover_or_incumbent_defeat_flag DESC, margin_pct ASC;
","SELECT
  col0,
  col1,
  col2,
  col3,
  (1996 - col3) AS years_in_office,
  col4,
  CAST(trim(substr(col5, instr(col5, '%') - 6, 6)) AS REAL) AS pct_first_candidate,
  CAST(trim(substr(
    col5,
    (instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%')) - 6,
    6
  )) AS REAL) AS pct_second_candidate,
  ABS(
    CAST(trim(substr(col5, instr(col5, '%') - 6, 6)) AS REAL) -
    CAST(trim(substr(
      col5,
      (instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%')) - 6,
      6
    )) AS REAL)
  ) AS margin_pct,
  CASE
    WHEN ABS(
      CAST(trim(substr(col5, instr(col5, '%') - 6, 6)) AS REAL) -
      CAST(trim(substr(
        col5,
        (instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%')) - 6,
        6
      )) AS REAL)
    ) < 5 THEN 'Tight (<5%)'
    WHEN ABS(
      CAST(trim(substr(col5, instr(col5, '%') - 6, 6)) AS REAL) -
      CAST(trim(substr(
        col5,
        (instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%')) - 6,
        6
      )) AS REAL)
    ) < 10 THEN 'Competitive (<10%)'
    ELSE 'Safe (>=10%)'
  END AS competitiveness,
  CASE WHEN col4 LIKE '%gain%' OR col4 LIKE '%Lost%' THEN 1 ELSE 0 END AS turnover_or_incumbent_defeat_flag,
  CASE WHEN col4 LIKE '%Retired%' OR col4 LIKE '%Lost%' THEN 1 ELSE 0 END AS retired_or_defeated_long_tenure_flag,
  col5
FROM `table_1_1341472_45`
WHERE
  (col4 LIKE '%gain%' OR col4 LIKE '%Lost%' OR col4 LIKE '%Retired%'
   OR ABS(
     CAST(trim(substr(col5, instr(col5, '%') - 6, 6)) AS REAL) -
     CAST(trim(substr(
       col5,
       (instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%')) - 6,
       6
     )) AS REAL)
   ) < 10)
ORDER BY turnover_or_incumbent_defeat_flag DESC, margin_pct ASC;","[('texas 9', 'steve stockman', 'republican', 1994.0, 2.0, 'lost re-election democratic gain', 52.83, 47.16, 5.670000000000002, 'Competitive (<10%)', 1, 1, 'nick lampson (d) 52.83% steve stockman (r) 47.16%'), ('texas 5', 'john bryant', 'democratic', 1982.0, 14.0, 'retired to run for u.s. senate republican gain', 53.07, 46.93, 6.140000000000001, 'Competitive (<10%)', 1, 1, 'pete sessions (r) 53.07% john pouland (d) 46.93%'), ('texas 8', 'jack fields', 'republican', 1980.0, 16.0, 'retired republican hold', 59.11, 40.89, 18.22, 'Safe (>=10%)', 0, 1, 'kevin brady (r) 59.11% gene fontenot (d) 40.89%')]",table_1_1341472_45,"I, the novelist-quant, also need to seed Monte Carlo models so I ask about competitiveness and ordering — I'll request turnovers first and then the closest races. The SQL filters to races that are gains, losses, retirements, or within 10 points, computes absolute margin, classifies as Tight/Competitive/Safe, and orders by turnover flag then smallest margin. District, Incumbent, margin and competitiveness are all derived or present in the table. Draft question: ask for those races, ordering turnovers/upsets first then by narrowest margin, with margins and competitiveness labels. Validate: this explicitly requests the ordering and outputs the query implements and nothing beyond it.",persona,"A counterfactual novelist-quant — an alternative-history author who uses historical election tables to generate statistically plausible 1996 Texas House alternate outcomes and character backstories. Goals: Identify which Texas districts experienced party turnover or incumbent defeat in 1996 to seed pivotal plot events in an alternate-history narrative. Quantify margins of victory to classify races by competitiveness (for realistic tension and scene-setting) and to build simple probabilistic models for Monte Carlo alternate outcomes. Extract long-tenure incumbents who retired or were defeated so the author can craft believable motivations, career arcs, and successor character profiles. Example Queries: -- 1) Find districts that changed party or where the incumbent lost (quick shortlist of dramatic flips/defeats)
    SELECT District, Incumbent, Party, `First elected`, Result, Candidates
    FROM table_1_1341472_45
    WHERE Result LIKE '%gain%' OR Result LIKE '%Lost%'; -- 2) Parse candidate percentage strings to compute margins and list competitive races (margin < 10 percentage points) — MySQL-style string parsing
    SELECT
      District,
      Incumbent,
      Party,
      CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 1), ' ', -1) AS DECIMAL(5,2)) AS pct1,
      CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 2), ' ', -1) AS DECIMAL(5,2)) AS pct2,
      ABS(
        CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 1), ' ', -1) AS DECIMAL(5,2)) -
        CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 2), ' ', -1) AS DECIMAL(5,2))
      ) AS margin
    FROM table_1_1341472_45
    WHERE ABS(
      CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 1), ' ', -1) AS DECIMAL(5,2)) -
      CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 2), ' ', -1) AS DECIMAL(5,2))
    ) < 10
    ORDER BY margin ASC; -- 3) List incumbents who retired (e.g., to run for Senate) with tenure computed (1996 election year) for character background building
    SELECT District, Incumbent, Party, `First elected`, Result, (1996 - `First elected`) AS years_in_office, Candidates
    FROM table_1_1341472_45
    WHERE Result LIKE '%Retired%';",reward,,
"For each Party, restricting to records with Opponent <> '' and Elected >= 1980, what is the Party, how many Opponent strings contain 'unopposed' (Unopposed_Count), and what is the average opponent percentage (Avg_Opponent_Percent) where the percentage is obtained by taking the substring that starts three characters after '(' and ends at '%' and converting it to a number (exclude 'unopposed' rows from the average by treating them as NULL); only include parties whose Unopposed_Count is greater than zero, order by Unopposed_Count descending, and limit to 10 results?","
SELECT DISTINCT `Party`, SUM((instr(`Opponent`,'unopposed')>0)) AS `Unopposed_Count`, AVG(CASE WHEN `Opponent` LIKE '%unopposed%' THEN NULL ELSE (substr(`Opponent`, instr(`Opponent`,'(')+3, instr(`Opponent`,'%')-instr(`Opponent`,'(')-3) + 0.0) END) `Avg_Opponent_Percent` FROM `table_1_1341568_44` WHERE `Opponent` <> '' AND `Elected` >= 1980 GROUP BY `Party` HAVING SUM((instr(`Opponent`,'unopposed')>0)) > 0 ORDER BY `Unopposed_Count` DESC LIMIT 10;
","
SELECT DISTINCT col2, SUM((instr(col5,'unopposed')>0)) AS `Unopposed_Count`, AVG(CASE WHEN col5 LIKE '%unopposed%' THEN NULL ELSE (substr(col5, instr(col5,'(')+3, instr(col5,'%')-instr(col5,'(')-3) + 0.0) END) `Avg_Opponent_Percent` FROM `table_1_1341568_44` WHERE col5 <> '' AND col3 >= 1980 GROUP BY col2 HAVING SUM((instr(col5,'unopposed')>0)) > 0 ORDER BY `Unopposed_Count` DESC LIMIT 10;
","[('republican', 2, 80.39999999999999), ('democratic', 1, 77.16)]",table_1_1341568_44,"Parse intent: produce per-Party aggregates counting 'unopposed' opponents and averaging parsed opponent percentages for elections from 1980 onward, ignoring blank Opponent fields. Map schema: use Party as grouping column, compute Unopposed_Count via searching 'unopposed', compute Avg_Opponent_Percent via substring between '('+3 and '%' and numeric cast, excluding 'unopposed' from average. Draft: question must request those exact metrics, filters, HAVING >0, ordering by count desc and limit 10. Validate: all SQL elements are represented.",reserved,19,reward,,
"Which Massachusetts House districts in 1988 were unopposed, and who were the incumbents, their party, first‑elected year, and tenure?","
WITH details AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    (1988 - `First elected`) AS `Tenure`,
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `IsUnopposed`,
    CASE WHEN `Result` LIKE '%Retired%' THEN 1 ELSE 0 END AS `IsRetired`
  FROM `table_1_1341577_22`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  `Tenure`,
  `IsUnopposed`,
  `IsRetired`,
  SUM(`IsUnopposed`) OVER () AS `Total_Unopposed`,
  SUM(`IsRetired`) OVER () AS `Total_Retired`,
  COUNT(*) OVER (PARTITION BY `Party`) AS `Seats_For_Party`,
  MIN(`First elected`) OVER () AS `Earliest_First_elected`,
  CASE WHEN `First elected` = MIN(`First elected`) OVER () THEN 1 ELSE 0 END AS `Longest_serving_flag`
FROM details
ORDER BY `IsUnopposed` DESC, `First elected` ASC;
","
WITH details AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    (1988 - col3) AS `Tenure`,
    CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `IsUnopposed`,
    CASE WHEN col4 LIKE '%Retired%' THEN 1 ELSE 0 END AS `IsRetired`
  FROM `table_1_1341577_22`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  `Tenure`,
  `IsUnopposed`,
  `IsRetired`,
  SUM(`IsUnopposed`) OVER () AS `Total_Unopposed`,
  SUM(`IsRetired`) OVER () AS `Total_Retired`,
  COUNT(*) OVER (PARTITION BY col2) AS `Seats_For_Party`,
  MIN(col3) OVER () AS `Earliest_First_elected`,
  CASE WHEN col3 = MIN(col3) OVER () THEN 1 ELSE 0 END AS `Longest_serving_flag`
FROM details
ORDER BY `IsUnopposed` DESC, col3 ASC;
","[('massachusetts 9', 'joe moakley', 'democratic', 1972.0, 're-elected', 'joe moakley (d) unopposed', 16.0, 1, 0, 3, 1, 5, 1952.0, 0), ('massachusetts 3', 'joseph d. early', 'democratic', 1974.0, 're-elected', 'joseph d. early (d) unopposed', 14.0, 1, 0, 3, 1, 5, 1952.0, 0), ('massachusetts 7', 'ed markey', 'democratic', 1976.0, 're-elected', 'ed markey (d) unopposed', 12.0, 1, 0, 3, 1, 5, 1952.0, 0), ('massachusetts 2', 'edward boland', 'democratic', 1952.0, 'retired democratic hold', 'richard neal (d) 80.3% louis r. godena (i) 19.7%', 36.0, 0, 1, 3, 1, 5, 1952.0, 1), ('massachusetts 1', 'silvio conte', 'republican', 1958.0, 're-elected', 'silvio conte (r) 82.7% john r. arden (d) 17.3%', 30.0, 0, 0, 3, 1, 1, 1952.0, 0), ('massachusetts 4', 'barney frank', 'democratic', 1980.0, 're-elected', 'barney frank (d) 70.3% debra r. tucker (r) 29.7%', 8.0, 0, 0, 3, 1, 5, 1952.0, 0)]",table_1_1341577_22,"As a political science researcher I phrase requests to get district-level incumbency and competitiveness measures without SQL jargon. The SQL marks rows with 'Unopposed', computes tenure as 1988 minus the first-elected year, and returns those per-row details. The schema provides District, Incumbent, Party, First elected, Result, Candidates and the computed IsUnopposed and Tenure. Which Massachusetts House districts in 1988 were unopposed, and who were the incumbents, their party, first-elected year, and tenure? This question maps directly to the query's unopposed flag and tenure calculation for each district.",persona,"Political science researcher studying incumbency and electoral competitiveness in U.S. House races, using historical election tables to quantify unopposed contests and party dominance. They would use this database to extract district-level outcomes and incumbency tenure for statistical analysis. Goals: Identify which Massachusetts House races in 1988 were unopposed to measure electoral competitiveness. Quantify party seat distribution in Massachusetts for the 1988 House elections. Find long-serving incumbents (earlier first-elected years) and any districts where incumbents retired to study incumbency effects and turnover. Example Queries: SELECT District, Incumbent, Party, [First elected], Result, Candidates
FROM table_1_1341577_22
WHERE Candidates LIKE '%Unopposed%'; SELECT Party, COUNT(*) AS seats
FROM table_1_1341577_22
GROUP BY Party
ORDER BY seats DESC; SELECT District, Incumbent, Party, [First elected], Result
FROM table_1_1341577_22
WHERE [First elected] <= 1976 OR Result LIKE '%Retired%'
ORDER BY [First elected] ASC;",reward,,
Which districts were the most competitive?,"
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  -- Candidate 1 name (text before first "" ("")
  trim(substr(`Candidates`, 1, instr(`Candidates`, '(') - 2)) AS `Candidate1_name`,
  -- Candidate 1 party (between first ""("" and "")"")
  CASE WHEN instr(`Candidates`, '(') > 0 AND instr(`Candidates`, ')') > instr(`Candidates`, '(')
       THEN substr(`Candidates`, instr(`Candidates`, '(') + 1, instr(`Candidates`, ')') - instr(`Candidates`, '(') - 1)
       ELSE NULL END AS `Candidate1_party`,
  -- Candidate 1 percent (number between "") "" and first ""%"", or 100 for Unopposed)
  CASE
    WHEN instr(`Candidates`, '%') = 0 AND `Candidates` LIKE '%Unopposed%' THEN 100.0
    WHEN instr(`Candidates`, '%') > 0 THEN
      CAST(trim(
        substr(
          `Candidates`,
          instr(`Candidates`, ')') + 2,
          instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2)
        )
      ) AS REAL)
    ELSE NULL
  END AS `Candidate1_pct`,
  -- Candidate 2 name (text after first ""%"" up to second "" ("", if present)
  CASE
    WHEN instr(`Candidates`, '%') > 0 AND instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '(') > 0 THEN
      trim(substr(
        `Candidates`,
        instr(`Candidates`, '%') + 1,
        instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '(') - 1
      ))
    ELSE NULL
  END AS `Candidate2_name`,
  -- Candidate 2 party (between second ""("" and "")"" if present)
  CASE
    WHEN instr(`Candidates`, '%') > 0 AND instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '(') > 0 THEN
      substr(
        substr(`Candidates`, instr(`Candidates`, '%') + 1),
        instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '(') + 1,
        instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') - instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '(') - 1
      )
    ELSE NULL
  END AS `Candidate2_party`,
  -- Candidate 2 percent (number before second ""%"", if present)
  CASE
    WHEN instr(`Candidates`, '%') > 0 AND instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0 THEN
      CAST(trim(
        substr(
          substr(`Candidates`, instr(`Candidates`, '%') + 1),
          instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2,
          instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') - (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2)
        )
      ) AS REAL)
    ELSE NULL
  END AS `Candidate2_pct`,
  -- Computed margin (absolute difference between the two top percentages; if only one candidate, margin = 100)
  CASE
    WHEN
      (CASE WHEN instr(`Candidates`, '%') = 0 AND `Candidates` LIKE '%Unopposed%' THEN 100.0
            WHEN instr(`Candidates`, '%') > 0 THEN CAST(trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2))) AS REAL)
            ELSE NULL END) IS NULL
      THEN NULL
    WHEN
      (CASE WHEN instr(`Candidates`, '%') > 0 AND instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0 THEN
             abs(
               (CASE WHEN instr(`Candidates`, '%') = 0 AND `Candidates` LIKE '%Unopposed%' THEN 100.0 ELSE CAST(trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2))) AS REAL END)
               -
               CAST(trim(
                 substr(
                   substr(`Candidates`, instr(`Candidates`, '%') + 1),
                   instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2,
                   instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') - (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2)
                 )
               ) AS REAL)
             )
           WHEN instr(`Candidates`, '%') > 0 AND instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') = 0 THEN
             abs(
               (CASE WHEN instr(`Candidates`, '%') = 0 AND `Candidates` LIKE '%Unopposed%' THEN 100.0 ELSE CAST(trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2))) AS REAL END)
               - 0.0
             )
           WHEN instr(`Candidates`, '%') = 0 AND `Candidates` LIKE '%Unopposed%' THEN 100.0
           ELSE NULL
      END IS NOT NULL
    THEN
      (CASE WHEN instr(`Candidates`, '%') > 0 AND instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0 THEN
             abs(
               (CASE WHEN instr(`Candidates`, '%') = 0 AND `Candidates` LIKE '%Unopposed%' THEN 100.0 ELSE CAST(trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2))) AS REAL END)
               -
               CAST(trim(
                 substr(
                   substr(`Candidates`, instr(`Candidates`, '%') + 1),
                   instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2,
                   instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') - (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2)
                 )
               ) AS REAL)
             )
           WHEN instr(`Candidates`, '%') > 0 AND instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') = 0 THEN
             abs(
               (CASE WHEN instr(`Candidates`, '%') = 0 AND `Candidates` LIKE '%Unopposed%' THEN 100.0 ELSE CAST(trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2))) AS REAL END)
               - 0.0
             )
           WHEN instr(`Candidates`, '%') = 0 AND `Candidates` LIKE '%Unopposed%' THEN 100.0
           ELSE NULL
      END)
    ELSE NULL
  END AS `margin_percent`,
  -- Safety classification: Safe if Unopposed or top pct >= 70 OR margin > 20, Toss-up/Competitive/Lean thresholds otherwise
  CASE
    WHEN `Candidates` LIKE '%Unopposed%' THEN 'Safe'
    WHEN
      (CASE WHEN instr(`Candidates`, '%') = 0 AND `Candidates` LIKE '%Unopposed%' THEN 100.0
            WHEN instr(`Candidates`, '%') > 0 AND (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0) THEN
              (CASE
                WHEN CAST(trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2))) AS REAL) >=
                     CAST(trim(
                       substr(
                         substr(`Candidates`, instr(`Candidates`, '%') + 1),
                         instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2,
                         instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') - (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2)
                       )
                     ) AS REAL)
                THEN CAST(trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2))) AS REAL
                ELSE CAST(trim(
                       substr(
                         substr(`Candidates`, instr(`Candidates`, '%') + 1),
                         instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2,
                         instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') - (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), ')') + 2)
                       )
                     ) AS REAL)
              END)
            WHEN instr(`Candidates`, '%') > 0 AND instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') = 0 THEN
              CAST(trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2))) AS REAL
            ELSE NULL END) >= 70 THEN 'Safe'
    WHEN `margin_percent` IS NOT NULL AND `margin_percent` <= 5 THEN 'Toss-up'
    WHEN `margin_percent` IS NOT NULL AND `margin_percent` <= 10 THEN 'Highly Competitive'
    WHEN `margin_percent` IS NOT NULL AND `margin_percent` <= 20 THEN 'Lean'
    WHEN `margin_percent` IS NOT NULL AND `margin_percent` > 20 THEN 'Safe'
    ELSE 'Unknown'
  END AS `Safety_classification`,
  -- Open/Retiring seat flag
  CASE WHEN `Result` LIKE '%Retired%' THEN 'Yes' ELSE 'No' END AS `Open/Retiring`,
  -- Party hold indicator (Yes if Result mentions ""hold"")
  CASE WHEN lower(`Result`) LIKE '%hold%' THEN 'Yes' ELSE 'No' END AS `Party_hold`
FROM `table_1_1341577_36`
ORDER BY
  -- order by competitiveness (smallest margin first), NULLs last
  CASE WHEN `margin_percent` IS NULL THEN 999 ELSE `margin_percent` END ASC,
  `District` ASC;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    trim(substr(col5, 1, instr(col5, '(') - 2)) AS `Candidate1_name`,
    CASE
      WHEN instr(col5, '(') > 0 AND instr(col5, ')') > instr(col5, '(')
      THEN substr(col5, instr(col5, '(') + 1, instr(col5, ')') - instr(col5, '(') - 1)
      ELSE NULL
    END AS `Candidate1_party`,
    CASE
      WHEN col5 LIKE '%Unopposed%' THEN 100.0
      WHEN instr(col5, '%') > 0 THEN
        CAST(trim(
          substr(
            col5,
            instr(col5, ')') + 2,
            instr(col5, '%') - (instr(col5, ')') + 2)
          )
        ) AS REAL)
      ELSE NULL
    END AS `Candidate1_pct`,
    CASE
      WHEN instr(col5, '%') > 0 AND instr(substr(col5, instr(col5, '%') + 1), '(') > 0
      THEN trim(
        substr(
          col5,
          instr(col5, '%') + 1,
          instr(substr(col5, instr(col5, '%') + 1), '(') - 1
        )
      )
      ELSE NULL
    END AS `Candidate2_name`,
    CASE
      WHEN instr(col5, '%') > 0 AND instr(substr(col5, instr(col5, '%') + 1), '(') > 0
      THEN substr(
        substr(col5, instr(col5, '%') + 1),
        instr(substr(col5, instr(col5, '%') + 1), '(') + 1,
        instr(substr(col5, instr(col5, '%') + 1), ')') - instr(substr(col5, instr(col5, '%') + 1), '(') - 1
      )
      ELSE NULL
    END AS `Candidate2_party`,
    CASE
      WHEN instr(col5, '%') > 0 AND instr(substr(col5, instr(col5, '%') + 1), '%') > 0
      THEN CAST(trim(
        substr(
          substr(col5, instr(col5, '%') + 1),
          instr(substr(col5, instr(col5, '%') + 1), ')') + 2,
          instr(substr(col5, instr(col5, '%') + 1), '%') - (instr(substr(col5, instr(col5, '%') + 1), ')') + 2)
        )
      ) AS REAL)
      ELSE NULL
    END AS `Candidate2_pct`
  FROM `table_1_1341577_36`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  `Candidate1_name`,
  `Candidate1_party`,
  `Candidate1_pct`,
  `Candidate2_name`,
  `Candidate2_party`,
  `Candidate2_pct`,
  -- margin_percent: if there's a second candidate use abs diff, otherwise margin = abs(Candidate1_pct - 0)
  CASE
    WHEN `Candidate1_pct` IS NULL AND `Candidate2_pct` IS NULL THEN NULL
    WHEN `Candidate2_pct` IS NULL THEN abs(`Candidate1_pct` - 0.0)
    ELSE abs(`Candidate1_pct` - `Candidate2_pct`)
  END AS `margin_percent`,
  -- Safety classification
  CASE
    WHEN col5 LIKE '%Unopposed%' THEN 'Safe'
    WHEN
      (CASE WHEN `Candidate2_pct` IS NULL THEN `Candidate1_pct` ELSE (CASE WHEN `Candidate1_pct` >= `Candidate2_pct` THEN `Candidate1_pct` ELSE `Candidate2_pct` END) END) >= 70 THEN 'Safe'
    WHEN (CASE WHEN `Candidate1_pct` IS NULL AND `Candidate2_pct` IS NULL THEN NULL WHEN `Candidate2_pct` IS NULL THEN abs(`Candidate1_pct` - 0.0) ELSE abs(`Candidate1_pct` - `Candidate2_pct`) END) <= 5 THEN 'Toss-up'
    WHEN (CASE WHEN `Candidate1_pct` IS NULL AND `Candidate2_pct` IS NULL THEN NULL WHEN `Candidate2_pct` IS NULL THEN abs(`Candidate1_pct` - 0.0) ELSE abs(`Candidate1_pct` - `Candidate2_pct`) END) <= 10 THEN 'Highly Competitive'
    WHEN (CASE WHEN `Candidate1_pct` IS NULL AND `Candidate2_pct` IS NULL THEN NULL WHEN `Candidate2_pct` IS NULL THEN abs(`Candidate1_pct` - 0.0) ELSE abs(`Candidate1_pct` - `Candidate2_pct`) END) <= 20 THEN 'Lean'
    WHEN (CASE WHEN `Candidate1_pct` IS NULL AND `Candidate2_pct` IS NULL THEN NULL WHEN `Candidate2_pct` IS NULL THEN abs(`Candidate1_pct` - 0.0) ELSE abs(`Candidate1_pct` - `Candidate2_pct`) END) > 20 THEN 'Safe'
    ELSE 'Unknown'
  END AS `Safety_classification`,
  CASE WHEN col4 LIKE '%Retired%' THEN 'Yes' ELSE 'No' END AS `Open/Retiring`,
  CASE WHEN lower(col4) LIKE '%hold%' THEN 'Yes' ELSE 'No' END AS `Party_hold`
FROM parsed
ORDER BY
  CASE WHEN `margin_percent` IS NULL THEN 999 ELSE `margin_percent` END ASC,
  col0 ASC;","[('ohio 1', 'tom luken', 'democratic', 1976.0, 're-elected', 'tom luken (d) 56.5% steve chabot (r) 43.5%', 'tom luken', 'd', 56.5, 'steve chabot', 'r', 43.5, 13.0, 'Lean', 'No', 'No'), ('ohio 5', 'del latta', 'republican', 1958.0, 'retired republican hold', 'paul gillmor (r) 60.6% tom murray (d) 39.4%', 'paul gillmor', 'r', 60.6, 'tom murray', 'd', 39.4, 21.200000000000003, 'Safe', 'Yes', 'Yes'), ('ohio 13', 'don pease', 'democratic', 1976.0, 're-elected', 'don pease (d) 69.8% dwight brown (r) 30.2%', 'don pease', 'd', 69.8, 'dwight brown', 'r', 30.2, 39.599999999999994, 'Safe', 'No', 'No'), ('ohio 19', 'ed feighan', 'democratic', 1982.0, 're-elected', 'ed feighan (d) 70.5% noel f. roberts (r) 29.5%', 'ed feighan', 'd', 70.5, 'noel f. roberts', 'r', 29.5, 41.0, 'Safe', 'No', 'No'), ('ohio 2', 'bill gradison', 'republican', 1974.0, 're-elected', 'bill gradison (r) 72.3% chuck r. stidham (d) 27.7%', 'bill gradison', 'r', 72.3, 'chuck r. stidham', 'd', 27.7, 44.599999999999994, 'Safe', 'No', 'No'), ('ohio 7', 'mike dewine', 'republican', 1982.0, 're-elected', 'mike dewine (r) 73.9% jack schira (d) 26.1%', 'mike dewine', 'r', 73.9, 'jack schira', 'd', 26.1, 47.800000000000004, 'Safe', 'No', 'No'), ('ohio 6', 'bob mcewen', 'republican', 1980.0, 're-elected', 'bob mcewen (r) 74.3% gordon r. roberts (d) 25.7%', 'bob mcewen', 'r', 74.3, 'gordon r. roberts', 'd', 25.7, 48.599999999999994, 'Safe', 'No', 'No'), ('ohio 14', 'thomas c. sawyer', 'democratic', 1986.0, 're-elected', 'thomas c. sawyer (d) 74.7% loretta lang (r) 25.3%', 'thomas c. sawyer', 'd', 74.7, 'loretta lang', 'r', 25.3, 49.400000000000006, 'Safe', 'No', 'No'), ('ohio 8', 'buz lukens', 'republican', 1986.0, 're-elected', 'buz lukens (r) 75.9% john w. griffin (d) 24.1%', 'buz lukens', 'r', 75.9, 'john w. griffin', 'd', 24.1, 51.800000000000004, 'Safe', 'No', 'No'), ('ohio 3', 'tony p. hall', 'democratic', 1978.0, 're-elected', 'tony p. hall (d) 76.9% ron crutcher (r) 23.1%', 'tony p. hall', 'd', 76.9, 'ron crutcher', 'r', 23.1, 53.800000000000004, 'Safe', 'No', 'No'), ('ohio 16', 'ralph regula', 'republican', 1972.0, 're-elected', 'ralph regula (r) 78.6% melvin j. gravely (d) 21.4%', 'ralph regula', 'r', 78.6, 'melvin j. gravely', 'd', 21.4, 57.199999999999996, 'Safe', 'No', 'No'), ('ohio 12', 'john kasich', 'republican', 1982.0, 're-elected', 'john kasich (r) 80.1% mark p. brown (d) 19.9%', 'john kasich', 'r', 80.1, 'mark p. brown', 'd', 19.9, 60.199999999999996, 'Safe', 'No', 'No'), ('ohio 9', 'marcy kaptur', 'democratic', 1982.0, 're-elected', 'marcy kaptur (d) 81.3% al hawkins (r) 18.7%', 'marcy kaptur', 'd', 81.3, 'al hawkins', 'r', 18.7, 62.599999999999994, 'Safe', 'No', 'No'), ('ohio 20', 'mary rose oakar', 'democratic', 1976.0, 're-elected', 'mary rose oakar (d) 82.6% michael sajna (r) 17.4%', 'mary rose oakar', 'd', 82.6, 'michael sajna', 'r', 17.4, 65.19999999999999, 'Safe', 'No', 'No'), ('ohio 4', 'mike oxley', 'republican', 1972.0, 're-elected', 'mike oxley (r) unopposed', 'mike oxley', 'r', 100.0, None, None, None, 100.0, 'Safe', 'No', 'No')]",table_1_1341577_36,"STEP 1: Parse the SQL intent — the query extracts district, incumbent, party, parsed candidate names/parties/percentages, computes the absolute margin between the top two percentages (or 100 for Unopposed), assigns a safety classification (Safe / Toss-up / Highly Competitive / Lean / Unknown) and flags for open/retiring and party hold; it returns all rows ordered by smallest margin first (NULLs last). STEP 2: Choose an ambiguity type — scope ambiguity fits well because the query orders by competitiveness but does not choose how many or which interpretation of “most competitive” to return (single top row vs list vs category-based set). STEP 3: Draft the question — ""Which districts were the most competitive?"" STEP 4: Explain the ambiguity — in the original query ""most competitive"" is operationalized by ordering districts by margin_percent ascending (so the smallest margin comes first) and also by classifying margins into categories (Toss-up, Highly Competitive, Lean). The phrase could instead mean (a) the single district with the smallest margin (LIMIT 1), (b) all districts with a competitive safety_classification (e.g., Toss-up and Highly Competitive), (c) the top N districts by margin, or (d) districts in the 'Lean' category too. The SQL as written returns all districts ordered by margin and provides classification values so it is compatible with multiple interpretations but does not resolve which one is intended.",persona,"""Goals"": [ ""Classify each Ohio district by how 'safe' or 'competitive' it was in 1988 so starting player advantages can mirror historical incumbency strength."", ""Identify open or retiring seats and party holds/changes to create alternate-history scenarios and special event cards."", ""Extract candidate names, vote percentages and tenure (first elected) to generate authentic flavor text, portraits and victory-condition thresholds for each district card."" ], ""Example queries"": [ ""/* 1) Find historically 'safe' seats — unopposed races or incumbents who won by >=70% */\nSELECT District, Incumbent, Party, \""First elected\"", Result, Candidates\nFROM table_1_1341577_36\nWHERE Candidates LIKE '%Unopposed%'\n   OR (REGEXP_REPLACE(REGEXP_SUBSTR(Candidates, '\\\\d+\\\\.?\\\\d*(?=%)'), '%', '')::FLOAT >= 70.0);\n\n/* (Note: REGEXP functions shown generically; adapt to your SQL dialect) */"", ""/* 2) Find open/retired seats (for alternate-history scenarios) */\nSELECT District, Incumbent, Party, \""First elected\"", Result, Candidates\nFROM table_1_1341577_36\nWHERE Result ILIKE '%Retired%'\n   OR Result ILIKE '%vacant%'\n   OR Result ILIKE '%hold%';"", ""/* 3) List districts ordered by closeness of the two top candidates (most competitive first) with computed margin */\nSELECT District, Incumbent, Party, \""First elected\"", Candidates,\n  ABS(\n    (CAST(REGEXP_REPLACE(REGEXP_SUBSTR(Candidates, '\\\\d+\\\\.?\\\\d*(?=%)', 1, 1), '%', '') AS FLOAT))\n    -\n    (CAST(REGEXP_REPLACE(REGEXP_SUBSTR(Candidates, '\\\\d+\\\\.?\\\\d*(?=%)', 1, 2), '%', '') AS FLOAT))\n  ) AS margin_percent\nFROM table_1_1341577_36\nWHERE Candidates ~ '\\\\d+\\\\.?\\\\d*%.*\\\\d+\\\\.?\\\\d*%'\nORDER BY margin_percent ASC;\n\n/* Use the smallest margins to craft tight, competitive district scenarios */"" } ``` Goals:  Example Queries: ",reward,,"type: Scope ambiguity | explanation: The question can mean the single district with the smallest margin, the top N districts by smallest margin, or all districts falling into ""competitive"" classifications (Toss-up/Highly Competitive/Lean). The SQL computes margins and classifies safety and orders by margin, so it supports all these readings but does not specify which scope (one, some, or all) was intended."
"Which districts were close contests within 10 points, listing incumbents, parties, incumbent and runner‑up percentages, margins, scenario tags and stability ratings for my swing cards?","
WITH extracted AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `Result`,
    `Candidates`,
    CASE
      WHEN `Candidates` LIKE '%Unopposed%' THEN 100.0
      ELSE CAST(REGEXP_SUBSTR(`Candidates`, '[0-9]+\.?[0-9]*(?=%)') AS REAL)
    END AS `IncumbentPct`,
    CAST(REGEXP_SUBSTR(`Candidates`, '[0-9]+\.?[0-9]*(?=%)', 1, 2) AS REAL) AS `RunnerUpPct`
  FROM `table_1_1341586_39`
)
SELECT
  '`' || `District` || '`' AS `District`,
  '`' || `Incumbent` || '`' AS `Incumbent`,
  '`' || `Party` || '`' AS `Party`,
  `IncumbentPct`,
  `RunnerUpPct`,
  CASE WHEN `RunnerUpPct` IS NOT NULL THEN ABS(`IncumbentPct` - `RunnerUpPct`) ELSE NULL END AS `Margin`,
  CASE
    WHEN `Candidates` LIKE '%Unopposed%' THEN '`Unopposed`'
    WHEN `IncumbentPct` >= 70.0 THEN '`Safe`'
    WHEN `Result` LIKE '%Retired%' AND `Result` LIKE '%gain%' THEN '`Open_Flip`'
    WHEN `RunnerUpPct` IS NOT NULL AND ABS(`IncumbentPct` - `RunnerUpPct`) < 10.0 THEN '`Close`'
    ELSE '`Contested`'
  END AS `ScenarioTag`,
  CASE
    WHEN `Candidates` LIKE '%Unopposed%' THEN 100
    WHEN `IncumbentPct` >= 70.0 THEN 90
    WHEN `Result` LIKE '%Retired%' AND `Result` LIKE '%gain%' THEN 20
    WHEN `RunnerUpPct` IS NOT NULL AND ABS(`IncumbentPct` - `RunnerUpPct`) < 10.0 THEN 40
    ELSE 60
  END AS `StabilityRating`
FROM extracted
ORDER BY `StabilityRating` DESC, `Margin` ASC;
","WITH extracted AS (
  SELECT
    col0,
    col1,
    col2,
    col4,
    col5,
    CASE
      WHEN col5 LIKE '%Unopposed%' THEN 100.0
      WHEN instr(col5, '%')>0 AND instr(substr(col5, 1, instr(col5, '%')-1), ') ')>0 THEN
        CAST(
          substr(
            substr(col5, 1, instr(col5, '%')-1),
            instr(substr(col5, 1, instr(col5, '%')-1), ') ')+2
          ) AS REAL
        )
      ELSE NULL
    END AS `IncumbentPct`,
    CASE
      WHEN instr(col5, '%')>0 AND instr(substr(col5, instr(col5, '%')+1), '%')>0 AND instr(substr(col5, instr(col5, '%')+1), ') ')>0 THEN
        CAST(
          substr(
            substr(col5, instr(col5, '%')+1),
            instr(substr(col5, instr(col5, '%')+1), ') ')+2,
            instr(substr(col5, instr(col5, '%')+1), '%') - (instr(substr(col5, instr(col5, '%')+1), ') ')+2)
          ) AS REAL
        )
      ELSE NULL
    END AS `RunnerUpPct`
  FROM `table_1_1341586_39`
)
SELECT
  col0,
  col1,
  col2,
  `IncumbentPct`,
  `RunnerUpPct`,
  CASE WHEN `RunnerUpPct` IS NOT NULL THEN ABS(`IncumbentPct` - `RunnerUpPct`) ELSE NULL END AS `Margin`,
  CASE
    WHEN col5 LIKE '%Unopposed%' THEN 'Unopposed'
    WHEN `IncumbentPct` >= 70.0 THEN 'Safe'
    WHEN col4 LIKE '%Retired%' AND col4 LIKE '%gain%' THEN 'Open_Flip'
    WHEN `RunnerUpPct` IS NOT NULL AND ABS(`IncumbentPct` - `RunnerUpPct`) < 10.0 THEN 'Close'
    ELSE 'Contested'
  END AS `ScenarioTag`,
  CASE
    WHEN col5 LIKE '%Unopposed%' THEN 100
    WHEN `IncumbentPct` >= 70.0 THEN 90
    WHEN col4 LIKE '%Retired%' AND col4 LIKE '%gain%' THEN 20
    WHEN `RunnerUpPct` IS NOT NULL AND ABS(`IncumbentPct` - `RunnerUpPct`) < 10.0 THEN 40
    ELSE 60
  END AS `StabilityRating`
FROM extracted
ORDER BY `StabilityRating` DESC, `Margin` ASC;","[('pennsylvania 9', 'bud shuster', 'republican', 100.0, None, None, 'Unopposed', 100), ('pennsylvania 17', 'george gekas', 'republican', 73.6, 26.4, 47.199999999999996, 'Safe', 90), ('pennsylvania 21', 'tom ridge', 'republican', 80.9, 19.1, 61.800000000000004, 'Safe', 90), ('pennsylvania 15', 'donald l. ritter', 'republican', 56.8, 43.2, 13.599999999999994, 'Contested', 60), ('pennsylvania 18', 'doug walgren', 'democratic', 63.0, 37.0, 26.0, 'Contested', 60), ('pennsylvania 12', 'john murtha', 'democratic', 67.4, 32.6, 34.800000000000004, 'Contested', 60), ('pennsylvania 6', 'gus yatron', 'democratic', 69.1, 30.9, 38.199999999999996, 'Contested', 60), ('pennsylvania 7', 'robert w. edgar', 'democratic', 61.3, 38.7, 22.599999999999994, 'Open_Flip', 20)]",table_1_1341586_39,"I need to design tense swing‑card mechanics, so I care about narrowly decided contests; I'm comfortable asking for contests within a points threshold. The query marks contests with an absolute margin under 10 points as Close and provides incumbent/runner‑up percentages, margin, tag and stability rating. It extracts percentages from Candidates, computes the margin and classifies rows accordingly using District, Incumbent, Party, Result and Candidates. Draft question: Which districts were close contests within 10 points, listing incumbents, parties, incumbent and runner‑up percentages, margins, scenario tags and stability ratings for my swing cards? Validate: The question exactly targets the SQL's Close classification and requests only returned fields.",persona,"A retro-political board-game designer crafting a 1986 Pennsylvania expansion pack who needs historically grounded balance metrics for scenario cards. Goals: Identify 'safe' districts and truly uncontested seats to assign high stability ratings in the game. Find open-seat races and party flips from incumbent retirements to create dramatic scenario cards and alternate-history branching paths. Detect competitive/close contests to design tense, swing-card mechanics and set victory point rewards appropriately. Example Queries: -- 1) Mark safe districts (unopposed or incumbent received >= 70%)
SELECT District, Incumbent, Party,
  CASE
    WHEN Candidates LIKE '%Unopposed%' THEN 100.0
    ELSE CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)') AS DECIMAL(5,1))
  END AS IncumbentPct
FROM table_1_1341586_39
WHERE Candidates LIKE '%Unopposed%'
   OR (CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)') AS DECIMAL(5,1)) >= 70.0);

-- 2) Find retirements that produced a party gain (open-seat flips) for dramatic scenario cards
SELECT District, Incumbent AS OutgoingIncumbent, Party AS OutgoingParty, Result, Candidates
FROM table_1_1341586_39
WHERE Result LIKE '%Retired%'
  AND Result LIKE '%gain%';

-- 3) List competitively close races (margin between top two listed percentages < 10%) to model high-stakes encounters
SELECT District, Incumbent, Party,
  CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)') AS DECIMAL(5,1)) AS PctTop,
  CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)', 1, 2) AS DECIMAL(5,1)) AS PctRunnerUp,
  ABS(
    CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)') AS DECIMAL(5,1))
    - CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)', 1, 2) AS DECIMAL(5,1))
  ) AS Margin
FROM table_1_1341586_39
WHERE REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)', 1, 2) IS NOT NULL
HAVING Margin < 10
ORDER BY Margin ASC;",reward,,
"For entries where Party is Democratic or Republican and First elected is between 1950 and 1990 with Candidates not null, what are the Party, the number of seats (TotalSeats = COUNT(*)), and the RaceType defined as 'Unopposed' if Candidates contains 'Unopposed' and 'Contested' otherwise, grouping by Party, keeping only groups with COUNT(*)>0, ordering by TotalSeats and limiting the output to 5 rows?","
SELECT `Party`, COUNT(*) AS `TotalSeats`, CASE WHEN `Candidates` LIKE '%' || `Unopposed` || '%' THEN `Unopposed` ELSE 'Contested' END `RaceType`
FROM `table_1_1341598_39` INNER JOIN (SELECT 'Democratic' AS `Democratic`, 'Republican' AS `Republican`, 'Unopposed' AS `Unopposed`) ON `table_1_1341598_39`.`Party` IN (`Democratic`,`Republican`)
WHERE `First elected` BETWEEN 1950 AND 1990 AND `Candidates` IS NOT NULL
GROUP BY `Party`
HAVING COUNT(*) > 0
ORDER BY `TotalSeats`
LIMIT 5;
","SELECT col2, COUNT(*) AS `TotalSeats`, CASE WHEN col5 LIKE '%Unopposed%' THEN 'Unopposed' ELSE 'Contested' END AS `RaceType`
FROM `table_1_1341598_39`
LEFT JOIN (SELECT 1 AS `k` UNION ALL SELECT 1) AS `aux` ON 1=1
WHERE (col3 BETWEEN 1950 AND 1990) AND (col5 IS NOT NULL) AND (col2 IN ('Democratic','Republican') OR col2 IS NOT NULL)
GROUP BY col2
HAVING COUNT(*) > 0
ORDER BY `TotalSeats` DESC
LIMIT 5;","[('democratic', 6, 'Contested'), ('republican', 4, 'Contested')]",table_1_1341598_39,"Parse intent: aggregate by Party (only Democratic or Republican), count rows meeting First elected BETWEEN 1950 AND 1990 and Candidates IS NOT NULL, classify races using a LIKE '%Unopposed%' test, then apply HAVING COUNT>0, ORDER BY TotalSeats, LIMIT 5. Map schema: Party, First elected, Candidates, computed TotalSeats and RaceType. Draft: phrase a question requesting Party, TotalSeats and the conditional RaceType with all filters, grouping, ordering and limit. Validate: ensures every SQL element is represented including the inline restriction to Democratic and Republican.",reserved,30,reward,,
"For each Party, what is the total number of seats (Total Seats) and how many incumbents were first elected in or before 1976 (Incumbents<=1976), excluding any rows where Party or Result is blank, grouped by Party, only including parties with at least one seat, ordered by Total Seats descending and limited to the top 10 parties?","
SELECT `Party`, COUNT(*) AS `Total Seats`, SUM(CASE WHEN `First elected` <= 1976 THEN 1 END) `Incumbents<=1976`
FROM `table_1_1341604_19`
WHERE `Party` <> '' AND `Result` <> ''
GROUP BY `Party`
HAVING COUNT(*)>0
ORDER BY `Total Seats` DESC
LIMIT 10;
","
SELECT col2, COUNT(*) AS `Total Seats`, SUM(CASE WHEN col3 <= 1976 THEN 1 END) `Incumbents<=1976`
FROM `table_1_1341604_19`
WHERE col2 <> '' AND col4 <> ''
GROUP BY col2
HAVING COUNT(*)>0
ORDER BY `Total Seats` DESC
LIMIT 10;
","[('democratic', 5, 3), ('republican', 2, 1)]",table_1_1341604_19,"1) The query groups rows by Party, counts rows per party, and sums a conditional count of incumbents with First elected <= 1976; it filters out empty Party or Result, requires groups with COUNT(*)>0, orders by count desc, and limits to 10. 2) Map columns: `Party`, `First elected`, and `Result` are used; COUNT(*) becomes Total Seats and the SUM(CASE...) becomes Incumbents<=1976. 3) Draft a question asking for Party, Total Seats, and Incumbents<=1976 with the stated filters, grouping, ordering, and limit. 4) Validate that the question mentions excluding empty Party/Result, grouping by Party, counting total seats, counting incumbents first elected in or before 1976, ordering by total seats descending, and limiting to 10.",reserved,15,reward,,
"Rank Massachusetts districts for targeting with unopposed seats first, then lower incumbent vote shares, then longer-serving incumbents, and include the computed priority score?","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Candidates`,
    (CAST(strftime('%Y','now') AS integer) - `First elected`) AS `Years_in_office`,
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Is_unopposed`,
    CASE
      WHEN `Candidates` LIKE '%Unopposed%' THEN 100.0
      WHEN instr(`Candidates`, `Incumbent` || ' (') > 0 THEN
        CAST(
          trim(
            substr(
              substr(
                `Candidates`,
                instr(`Candidates`, `Incumbent` || ' (') + instr(substr(`Candidates`, instr(`Candidates`, `Incumbent` || ' ('), ), ')'),
                999
              ),
              1,
              instr(
                substr(
                  `Candidates`,
                  instr(`Candidates`, `Incumbent` || ' (') + instr(substr(`Candidates`, instr(`Candidates`, `Incumbent` || ' ('), ), ')'),
                  999
                ),
                '%'
              ) - 1
            )
          ) AS real
        )
      ELSE NULL
    END AS `Incumbent_pct`
  FROM `table_1_1341604_22`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Years_in_office`,
  CASE WHEN `Is_unopposed` = 1 THEN 'Unopposed' ELSE 'Contested' END AS `Contest_status`,
  `Incumbent_pct`,
  CASE
    WHEN `Is_unopposed` = 1 THEN 'Unopposed'
    WHEN `Incumbent_pct` IS NULL THEN 'Unknown'
    WHEN `Incumbent_pct` >= 60 THEN 'Safe'
    WHEN `Incumbent_pct` >= 50 THEN 'Lean'
    ELSE 'Competitive'
  END AS `Competitive_level`,
  -- Priority score: prioritize unopposed, then lower incumbent_pct, then shorter tenure (negative years reduces score)
  (CASE WHEN `Is_unopposed` = 1 THEN 100 ELSE 0 END) - COALESCE(`Incumbent_pct`, 50) - (`Years_in_office` * 0.5) AS `Priority_score`
FROM parsed
ORDER BY `Is_unopposed` DESC, COALESCE(`Incumbent_pct`, 0) ASC, `Years_in_office` DESC;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col5,
    (CAST(strftime('%Y','now') AS integer) - col3) AS `Years_in_office`,
    CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Is_unopposed`,
    CASE
      WHEN col5 LIKE '%Unopposed%' THEN 100.0
      WHEN instr(col5, col1 || ' (') > 0 THEN
        CAST(
          trim(
            substr(
              substr(col5, instr(col5, col1 || ' (')),
              instr(substr(col5, instr(col5, col1 || ' (')), ')') + 1,
              instr(substr(col5, instr(col5, col1 || ' (')), '%') - instr(substr(col5, instr(col5, col1 || ' (')), ')') - 1
            )
          ) AS real
        )
      ELSE NULL
    END AS `Incumbent_pct`
  FROM `table_1_1341604_22`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  `Years_in_office`,
  CASE WHEN `Is_unopposed` = 1 THEN 'Unopposed' ELSE 'Contested' END AS `Contest_status`,
  `Incumbent_pct`,
  CASE
    WHEN `Is_unopposed` = 1 THEN 'Unopposed'
    WHEN `Incumbent_pct` IS NULL THEN 'Unknown'
    WHEN `Incumbent_pct` >= 60 THEN 'Safe'
    WHEN `Incumbent_pct` >= 50 THEN 'Lean'
    ELSE 'Competitive'
  END AS `Competitive_level`,
  (CASE WHEN `Is_unopposed` = 1 THEN 100 ELSE 0 END) - COALESCE(`Incumbent_pct`, 50) - (`Years_in_office` * 0.5) AS `Priority_score`
FROM parsed
ORDER BY `Is_unopposed` DESC, COALESCE(`Incumbent_pct`, 0) ASC, `Years_in_office` DESC;","[('massachusetts 1', 'silvio conte', 'republican', 1958.0, 67.0, 'Unopposed', 100.0, 'Unopposed', -33.5), ('massachusetts 3', 'joseph d. early', 'democratic', 1974.0, 51.0, 'Unopposed', 100.0, 'Unopposed', -25.5), ('massachusetts 4', 'barney frank', 'democratic', 1980.0, 45.0, 'Contested', 59.5, 'Lean', -82.0), ('massachusetts 2', 'edward boland', 'democratic', 1952.0, 73.0, 'Contested', 72.6, 'Safe', -109.1), ('massachusetts 7', 'ed markey', 'democratic', 1976.0, 49.0, 'Contested', 77.8, 'Safe', -102.3)]",table_1_1341604_22,"When triaging targets I might ask for an ordered ranking that puts unopposed seats first and then prioritizes by weak incumbents and tenure. The SQL orders results with unopposed first, then by ascending incumbent percentage (treating missing as low), then by years in office descending, and computes a numeric Priority_score from those factors. It exposes the Priority_score based on unopposed flag, incumbent_pct (or default), and Years_in_office. Rank Massachusetts districts for targeting with unopposed seats first, then lower incumbent vote shares, then longer-serving incumbents, and include the computed priority score? That precisely describes the query's ordering and score output.",persona,"```json
{
  ""short_description"": ""State-level campaign strategist working for a Massachusetts political campaign, looking to assess incumbency strength and competitive opportunities across congressional districts to guide targeted resource allocation."",
  ""goals"": [
    ""Identify which districts had unopposed incumbents or low competition to prioritize challenger recruitment or deprioritize spending."",
    ""Compare incumbency tenure (first elected year) and party distribution to spot long-standi Goals:  Example Queries: ",reward,,
"Provide a prioritized list of Pennsylvania 1980 House races showing District, Incumbent, Party, First elected, Result, Candidates, the vote-margin between the top two listed percentages, a turnover flag for incumbent loss/party gain, a long-tenured flag for first elected before 1976, and tenure years, ordered by closest margin then turnover then tenure.","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    instr(`Candidates`, '%') AS p1_pos,
    CASE
      WHEN instr(`Candidates`, '%') > 0 THEN CAST(substr(`Candidates`, instr(`Candidates`, '%') - 4, 4) AS REAL)
      ELSE NULL
    END AS pct1,
    CASE
      WHEN instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0
      THEN CAST(
        substr(
          `Candidates`,
          instr(`Candidates`, '%') + instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') - 4,
          4
        ) AS REAL
      )
      ELSE NULL
    END AS pct2
  FROM `table_1_1341640_39`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  -- margin between top two listed percentages (heuristic extraction based on table formats)
  CASE
    WHEN pct1 IS NULL AND `Candidates` LIKE '%Unopposed%' THEN 100.0
    WHEN pct1 IS NULL THEN NULL
    WHEN pct2 IS NULL THEN 100.0
    ELSE ABS(pct1 - pct2)
  END AS margin_pct,
  -- flag for incumbent loss or party gain in 1980
  CASE WHEN `Result` LIKE '%Lost%' OR `Result` LIKE '%gain%' THEN 1 ELSE 0 END AS turnover_flag,
  -- long-tenured incumbents first elected before 1976
  CASE WHEN `First elected` < 1976 THEN 1 ELSE 0 END AS long_tenured_flag,
  -- years in office as of 1980
  (1980 - `First elected`) AS tenure_years
FROM parsed
ORDER BY margin_pct ASC, turnover_flag DESC, tenure_years DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    instr(col5, '%') AS p1_pos,
    CASE
      WHEN instr(col5, '%') > 0 THEN CAST(substr(col5, instr(col5, '%') - 4, 4) AS REAL)
      ELSE NULL
    END AS pct1,
    CASE
      WHEN instr(substr(col5, instr(col5, '%') + 1), '%') > 0
      THEN CAST(
        substr(
          col5,
          instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%') - 4,
          4
        ) AS REAL
      )
      ELSE NULL
    END AS pct2
  FROM `table_1_1341640_39`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  -- margin between top two listed percentages (heuristic extraction based on table formats)
  CASE
    WHEN pct1 IS NULL AND col5 LIKE '%Unopposed%' THEN 100.0
    WHEN pct1 IS NULL THEN NULL
    WHEN pct2 IS NULL THEN 100.0
    ELSE ABS(pct1 - pct2)
  END AS margin_pct,
  -- flag for incumbent loss or party gain in 1980
  CASE WHEN col4 LIKE '%Lost%' OR col4 LIKE '%gain%' THEN 1 ELSE 0 END AS turnover_flag,
  -- long-tenured incumbents first elected before 1976
  CASE WHEN col3 < 1976 THEN 1 ELSE 0 END AS long_tenured_flag,
  -- years in office as of 1980
  (1980 - col3) AS tenure_years
FROM parsed
ORDER BY margin_pct ASC, turnover_flag DESC, tenure_years DESC;
","[('pennsylvania 11', 'ray musto', 'democratic', 1980.0, 'lost re-election republican gain', 'james l. nelligan (r) 51.9% ray musto (d) 48.1%', 3.799999999999997, 1, 0, 0.0), ('pennsylvania 12', 'john murtha', 'democratic', 1974.0, 're-elected', 'john murtha (d) 59.4% charles a. getty (r) 40.6%', 18.799999999999997, 0, 1, 6.0), ('pennsylvania 6', 'gus yatron', 'democratic', 1968.0, 're-elected', 'gus yatron (d) 67.1% george hulshart (r) 32.9%', 34.199999999999996, 0, 1, 12.0), ('pennsylvania 21', 'donald a. bailey', 'democratic', 1978.0, 're-elected', 'donald a. bailey (d) 68.4% dirk matson (r) 31.6%', 36.800000000000004, 0, 0, 2.0), ('pennsylvania 18', 'doug walgren', 'democratic', 1976.0, 're-elected', 'doug walgren (d) 68.5% steven r. snyder (r) 31.5%', 37.0, 0, 0, 4.0), ('pennsylvania 9', 'bud shuster', 'republican', 1972.0, 're-elected', 'bud shuster (r) unopposed', 100.0, 0, 1, 8.0)]",table_1_1341640_39,"As an analyst I might ask for a prioritized table for targeting that includes margin, turnover and tenure indicators. The SQL builds those indicators by extracting percentages, checking Result for 'Lost' or 'gain', checking First elected < 1976, and computing tenure years, then orders by margin, turnover, and tenure. The schema provides the base fields used for each derived metric. Draft question: request the full set of fields plus those computed flags and ordering for Pennsylvania 1980 races. Validate: the question maps cleanly to the SQL selection, computations and ordering.",persona,"State-level campaign data analyst working for a political party who studies historical House elections to identify vulnerable seats, turnover patterns, and margins to inform targeting and resource allocation. They use the 1980 House results table to find past upsets, close races, and longevity of incumbents in Pennsylvania. Goals: Identify districts where incumbents lost or where there was a party gain in 1980 to study patterns of turnover. Find historically close races (small vote-margin contests) to flag districts for targeted outreach. Analyze incumbent tenure (first elected year) by party to prioritize long-held vs. recently-won seats. Example Queries: /* 1) Find all districts that resulted in an incumbent loss or a party gain */
SELECT District, Incumbent, Party, ""First elected"", ""Result"", Candidates
FROM table_1_1341640_39
WHERE ""Result"" ILIKE '%Lost%' OR ""Result"" ILIKE '%gain%'; /* 2) Identify close races with margin under 5 percentage points (Postgres regexp to extract two percentages) */
SELECT District, Incumbent, Party, Candidates,
  ABS( (regexp_matches(Candidates, '([0-9]+\.[0-9]+)%')[1])::numeric -
       (regexp_matches(Candidates, '%.* ([0-9]+\.[0-9]+)%')[1])::numeric ) AS margin
FROM table_1_1341640_39
WHERE ABS( (regexp_matches(Candidates, '([0-9]+\.[0-9]+)%')[1])::numeric -
           (regexp_matches(Candidates, '%.* ([0-9]+\.[0-9]+)%')[1])::numeric ) < 5; /* 3) Count incumbents by party who were first elected before 1976 (long-tenured incumbents) and their re-election/result status */
SELECT Party, COUNT(*) AS long_tenured_count,
  SUM(CASE WHEN ""Result"" ILIKE '%Re-elected%' THEN 1 ELSE 0 END) AS re_elected_count,
  SUM(CASE WHEN ""Result"" ILIKE '%Lost%' THEN 1 ELSE 0 END) AS lost_count
FROM table_1_1341640_39
WHERE ""First elected"" < 1976
GROUP BY Party;",reward,,
"For each Georgia House district in 1978, give me the incumbent, how many years they'd served by 1978 (so I can map tempo in bpm), whether they were unopposed, the candidates' vote percentages if present, the margin, a competitiveness label, and whether the result was a party gain to trigger alternate instrumentation?","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    (1978 - `First elected`) AS `Tenure Years`,
    `Result`,
    `Candidates`,
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Is Unopposed`,
    CASE 
      WHEN instr(`Candidates`, '%')>0 AND instr(`Candidates`, ') ')>0
      THEN CAST(trim(substr(`Candidates`, instr(`Candidates`, ') ')+2, instr(`Candidates`, '%') - (instr(`Candidates`, ') ')+2))) AS REAL)
      ELSE NULL
    END AS `Pct1`,
    CASE
      WHEN instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%')>0 AND instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')>0
      THEN CAST(trim(
        substr(
          substr(`Candidates`, instr(`Candidates`, '%')+1),
          instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')+2,
          instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - (instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')+2)
        )
      ) AS REAL)
      ELSE NULL
    END AS `Pct2`
  FROM `table_1_1341663_11`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `Tenure Years`,
  CASE
    WHEN `Tenure Years` >= 24 THEN 60
    WHEN `Tenure Years` >= 12 THEN 80
    WHEN `Tenure Years` >= 6 THEN 100
    ELSE 120
  END AS `Suggested Tempo (bpm)`,
  `Is Unopposed`,
  `Pct1`,
  `Pct2`,
  CASE 
    WHEN `Is Unopposed` = 1 THEN NULL
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL THEN ABS(`Pct1` - `Pct2`)
    ELSE NULL
  END AS `Margin (%)`,
  CASE
    WHEN `Is Unopposed` = 1 THEN 'Drone'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL AND ABS(`Pct1` - `Pct2`) < 10 THEN 'Tight competitive interval'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL AND ABS(`Pct1` - `Pct2`) < 30 THEN 'Moderate competitive interval'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL THEN 'Wide interval (landslide)'
    ELSE 'Unknown'
  END AS `Competitiveness`,
  CASE WHEN `Result` LIKE '%gain%' THEN 1 ELSE 0 END AS `Is Gain`,
  CASE WHEN `Result` LIKE '%gain%' THEN 'Trigger alternate instrumentation' ELSE 'Standard instrumentation' END AS `Instrumentation Trigger`
FROM parsed
ORDER BY `Is Unopposed` DESC, `Margin (%)` ASC, `Tenure Years` DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    (1978 - col3) AS `Tenure Years`,
    col4,
    col5,
    CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Is Unopposed`,
    CASE 
      WHEN instr(col5, '%')>0 AND instr(col5, ') ')>0
      THEN CAST(trim(substr(col5, instr(col5, ') ')+2, instr(col5, '%') - (instr(col5, ') ')+2))) AS REAL)
      ELSE NULL
    END AS `Pct1`,
    CASE
      WHEN instr(substr(col5, instr(col5, '%')+1), '%')>0 AND instr(substr(col5, instr(col5, '%')+1), ') ')>0
      THEN CAST(trim(
        substr(
          substr(col5, instr(col5, '%')+1),
          instr(substr(col5, instr(col5, '%')+1), ') ')+2,
          instr(substr(col5, instr(col5, '%')+1), '%') - (instr(substr(col5, instr(col5, '%')+1), ') ')+2)
        )
      ) AS REAL)
      ELSE NULL
    END AS `Pct2`
  FROM `table_1_1341663_11`
)
SELECT
  col0,
  col1,
  col2,
  `Tenure Years`,
  CASE
    WHEN `Tenure Years` >= 24 THEN 60
    WHEN `Tenure Years` >= 12 THEN 80
    WHEN `Tenure Years` >= 6 THEN 100
    ELSE 120
  END AS `Suggested Tempo (bpm)`,
  `Is Unopposed`,
  `Pct1`,
  `Pct2`,
  CASE 
    WHEN `Is Unopposed` = 1 THEN NULL
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL THEN ABS(`Pct1` - `Pct2`)
    ELSE NULL
  END AS `Margin (%)`,
  CASE
    WHEN `Is Unopposed` = 1 THEN 'Drone'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL AND ABS(`Pct1` - `Pct2`) < 10 THEN 'Tight competitive interval'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL AND ABS(`Pct1` - `Pct2`) < 30 THEN 'Moderate competitive interval'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL THEN 'Wide interval (landslide)'
    ELSE 'Unknown'
  END AS `Competitiveness`,
  CASE WHEN col4 LIKE '%gain%' THEN 1 ELSE 0 END AS `Is Gain`,
  CASE WHEN col4 LIKE '%gain%' THEN 'Trigger alternate instrumentation' ELSE 'Standard instrumentation' END AS `Instrumentation Trigger`
FROM parsed
ORDER BY `Is Unopposed` DESC, `Margin (%)` ASC, `Tenure Years` DESC;
","[('georgia 3', 'jack thomas brinkley', 'democratic', 12.0, 80, 1, None, None, None, 'Drone', 0, 'Standard instrumentation'), ('georgia 2', 'dawson mathis', 'democratic', 8.0, 100, 1, None, None, None, 'Drone', 0, 'Standard instrumentation'), ('georgia 1', 'ronald ""bo"" ginn', 'democratic', 6.0, 100, 1, None, None, None, 'Drone', 0, 'Standard instrumentation'), ('georgia 8', 'billy lee evans', 'democratic', 2.0, 120, 1, None, None, None, 'Drone', 0, 'Standard instrumentation'), ('georgia 6', 'john james flynt, jr.', 'democratic', 24.0, 60, 0, 54.4, 45.6, 8.799999999999997, 'Tight competitive interval', 1, 'Trigger alternate instrumentation'), ('georgia 9', 'ed jenkins', 'democratic', 2.0, 120, 0, 76.9, 23.1, 53.800000000000004, 'Wide interval (landslide)', 0, 'Standard instrumentation')]",table_1_1341663_11,"I'm a sound artist thinking in tempo and texture rather than SQL; I'll use musical terms like tempo, drone, and instrumentation but avoid technical database jargon. The query computes years in office as 1978 minus 'First elected', maps those years to suggested BPM buckets, detects unopposed races, extracts candidate percentages to compute margins and competitiveness labels, and flags party gains. It reads District, Incumbent, Party, First elected, Result, and Candidates to produce Tenure Years, Suggested Tempo, Is Unopposed, Pct1/Pct2, Margin, Competitiveness, and Is Gain. Draft question: 'For each Georgia House district in 1978, give me the incumbent, how many years they'd served by 1978 (so I can map tempo in bpm), whether they were unopposed, the candidates' vote percentages if present, the margin, a competitiveness label, and whether the result was a party gain to trigger alternate instrumentation.' This question matches the fields produced by the query and doesn't ask for anything outside the table.",persona,"A sound artist-composer building a 1978-Georgia 'political symphony' that maps each congressional district's election attributes to musical parameters. Goals: Translate incumbency length into tempo (longer tenure → slower, sustained lines) by computing years in office as of 1978. Identify which districts were unopposed to assign them sustained drones and which were contested (and margins) to create melodic intervals reflecting competitiveness. Detect party changes or 'gains' (e.g., early Republican breakthroughs) to trigger distinct instrumentation or sudden harmonic shifts in the composition. Example Queries: SELECT ""District"", ""Incumbent"", ""Party"", (1978 - ""First elected"") AS tenure_years FROM table_1_1341663_11 ORDER BY tenure_years DESC; SELECT ""District"", ""Incumbent"", ""Party"" FROM table_1_1341663_11 WHERE ""Candidates"" LIKE '%Unopposed%'; SELECT ""District"", ""Incumbent"", ""Party"", ""Result"", ""Candidates"" FROM table_1_1341663_11 WHERE ""Candidates"" NOT LIKE '%Unopposed%' OR ""Result"" LIKE '%gain%';",reward,,
"For each Louisiana district, who is the incumbent, what is the smallest difference in First elected between them and other incumbents from the same party, and how many peers do they have?","
SELECT DISTINCT t1.`District`, t1.`Incumbent`, MIN(ABS(t1.`First elected` - t2.`First elected`)) `Louisiana 1`, COUNT(*) `PeerCount`
FROM `table_1_1341663_19` t1 CROSS JOIN `table_1_1341663_19` t2
WHERE (t1.`Party` = t2.`Party`) * (t1.`District` <> t2.`District`)
GROUP BY t1.`District`
HAVING MIN(ABS(t1.`First elected` - t2.`First elected`)) > 0
ORDER BY t1.`District`;
","
SELECT DISTINCT t1.col0, t1.col1, MIN(ABS(t1.col3 - t2.col3)) `Louisiana 1`, COUNT(*) `PeerCount`
FROM `table_1_1341663_19` t1 CROSS JOIN `table_1_1341663_19` t2
WHERE (t1.col2 = t2.col2) * (t1.col0 <> t2.col0)
GROUP BY t1.col0
HAVING MIN(ABS(t1.col3 - t2.col3)) > 0
ORDER BY t1.col0;
","[('louisiana 1', 'bob livingston', 3.0, 2), ('louisiana 2', 'lindy boggs', 1.0, 2), ('louisiana 3', 'dave treen', 2.0, 2), ('louisiana 5', 'jerry huckaby', 3.0, 2), ('louisiana 6', 'henson moore', 2.0, 2), ('louisiana 7', 'john breaux', 1.0, 2)]",table_1_1341663_19,"STEP 1: Parse the SQL intent — For each District (t1) the query returns the District and Incumbent, computes the minimum absolute difference in 'First elected' years between that district's incumbent and other incumbents of the same Party in different Districts (named 'Louisiana 1'), counts the number of same-party other-district rows as PeerCount, excludes groups where the minimum difference = 0, and orders by District. STEP 2: Determine a fitting ambiguity — Scope ambiguity fits well: the natural-language phrase about “how many peers” can either mean the total number of same-party peers overall or the number of peers that achieve that smallest 'First elected' gap. STEP 3: Draft the question — ""For each Louisiana district, who is the incumbent, what is the smallest difference in First elected between them and other incumbents from the same party, and how many peers do they have?"" STEP 4: Explain the ambiguity and interpretations — In the original SQL, PeerCount = COUNT(*) counts all same-party other districts (total peers) while the MIN(...) gives the smallest year gap; an alternative interpretation of the question is that the final count should be only the number of peers that tie for that minimum gap (which would require a different query).",reserved,11,reward,,"type: Scope ambiguity | explanation: The phrase ""how many peers do they have"" can mean (A) the total number of other same-party incumbents (what the SQL returns via COUNT(*)), or (B) the number of peers who match the smallest 'First elected' difference (a different query that counts only those tied for the minimum)."
"Produce a table of all Missouri 1978 House districts that includes district, incumbent, party, first elected (years in office), incumbent % and opponent %, margin, a 'Competitive'/'Safe' label (competitive if margin <10%), whether the incumbent won, and the number of seats held by that party, ordered by margin ascending.","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    CAST(REGEXP_SUBSTR(`Candidates`, '\\d+\\.\\d+(?=%)', 1, 1) AS REAL) AS incumbent_pct,
    CAST(REGEXP_SUBSTR(`Candidates`, '\\d+\\.\\d+(?=%)', 1, 2) AS REAL) AS opponent_pct,
    ABS(CAST(REGEXP_SUBSTR(`Candidates`, '\\d+\\.\\d+(?=%)', 1, 1) AS REAL) -
        CAST(REGEXP_SUBSTR(`Candidates`, '\\d+\\.\\d+(?=%)', 1, 2) AS REAL)) AS margin,
    (1978 - `First elected`) AS years_in_office,
    CASE WHEN `Result` LIKE '%Re-elected%' THEN 1 ELSE 0 END AS incumbent_won
  FROM `table_1_1341663_26`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  years_in_office,
  incumbent_pct,
  opponent_pct,
  margin,
  CASE WHEN margin < 10 THEN 'Competitive' ELSE 'Safe' END AS competitiveness,
  incumbent_won,
  (SELECT COUNT(*) FROM `table_1_1341663_26` t2 WHERE t2.`Party` = parsed.`Party`) AS seats_by_party
FROM parsed
ORDER BY margin ASC;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    CAST(TRIM(SUBSTR(col5,
                     instr(col5, ')') + 2,
                     instr(col5, '%') - (instr(col5, ')') + 2)
                    )) AS REAL) AS incumbent_pct,
    CAST(TRIM(SUBSTR(
      SUBSTR(col5, instr(col5, '%') + 1),
      instr(SUBSTR(col5, instr(col5, '%') + 1), ')') + 2,
      instr(SUBSTR(col5, instr(col5, '%') + 1), '%') - (instr(SUBSTR(col5, instr(col5, '%') + 1), ')') + 2)
    )) AS REAL) AS opponent_pct,
    ABS(
      CAST(TRIM(SUBSTR(col5,
                       instr(col5, ')') + 2,
                       instr(col5, '%') - (instr(col5, ')') + 2)
                      )) AS REAL)
      - CAST(TRIM(SUBSTR(
          SUBSTR(col5, instr(col5, '%') + 1),
          instr(SUBSTR(col5, instr(col5, '%') + 1), ')') + 2,
          instr(SUBSTR(col5, instr(col5, '%') + 1), '%') - (instr(SUBSTR(col5, instr(col5, '%') + 1), ')') + 2)
        )) AS REAL)
    ) AS margin,
    (1978 - col3) AS years_in_office,
    CASE WHEN col4 LIKE '%Re-elected%' THEN 1 ELSE 0 END AS incumbent_won
  FROM `table_1_1341663_26`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  years_in_office,
  incumbent_pct,
  opponent_pct,
  margin,
  CASE WHEN margin < 10 THEN 'Competitive' ELSE 'Safe' END AS competitiveness,
  incumbent_won,
  (SELECT COUNT(*) FROM `table_1_1341663_26` t2 WHERE t2.col2 = parsed.col2) AS seats_by_party
FROM parsed
ORDER BY margin ASC;","[('missouri 2', 'robert a. young', 'democratic', 1976.0, 2.0, 56.4, 43.6, 12.799999999999997, 'Safe', 1, 4), ('missouri 7', 'gene taylor', 'republican', 1972.0, 6.0, 61.2, 38.8, 22.400000000000006, 'Safe', 1, 1), ('missouri 4', 'ike skelton', 'democratic', 1976.0, 2.0, 72.8, 27.2, 45.599999999999994, 'Safe', 1, 4), ('missouri 9', 'harold volkmer', 'democratic', 1976.0, 2.0, 74.7, 25.3, 49.400000000000006, 'Safe', 1, 4), ('missouri 3', 'dick gephardt', 'democratic', 1976.0, 2.0, 81.9, 18.1, 63.800000000000004, 'Safe', 1, 4)]",table_1_1341663_26,"For report tables I often need party seat totals alongside per‑district results and a competitiveness flag, phrased plainly. The SQL returns per‑district vote shares and margins, a competitiveness label based on margin<10, incumbent win flag, and a count of seats by party via a subquery. It maps District, Incumbent, Party, First elected, computes years_in_office, parses candidate percentages, margin, competitiveness, incumbent_won, and seats_by_party. Drafted question: produce a table of all 1978 Missouri House districts with those metrics and party seat counts, ordered from closest to safest. This reflects exactly the fields and ordering the query produces.",persona,"A Missouri political data analyst at a state think tank who researches historical House election results to understand incumbency strength and voting patterns. They use this database to extract vote shares, margins, and tenure information from the 1978 Missouri U.S. House races to inform reports and visualizations. Goals: Measure incumbency advantage in Missouri's 1978 House races by comparing vote shares and margins for incumbents vs. challengers. Summarize party seat distribution across Missouri districts in 1978 and identify competitive districts. Correlate incumbents' years in office (tenure) with their 1978 victory margins to look for tenure-related trends. Example Queries: SELECT Party, COUNT(*) AS seats
FROM table_1_1341663_26
GROUP BY Party
ORDER BY seats DESC; SELECT District, Incumbent, Party, ""First elected"", Result,
       CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 1) AS REAL) AS pct_1,
       CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 2) AS REAL) AS pct_2,
       ABS(CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 1) AS REAL) -
           CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 2) AS REAL)) AS margin
FROM table_1_1341663_26
WHERE Result LIKE '%Re-elected%'
ORDER BY margin ASC; SELECT years_in_office, ROUND(AVG(margin), 2) AS avg_margin
FROM (
  SELECT (1978 - ""First elected"") AS years_in_office,
         ABS(CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 1) AS REAL) -
             CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 2) AS REAL)) AS margin
  FROM table_1_1341663_26
) AS sub
GROUP BY years_in_office
ORDER BY years_in_office;",reward,,
"Which rows with a '%' in Candidates have District, Incumbent, Party, First elected, Result and Candidates along with the winner percentage (parsed as the trimmed numeric substring immediately after the first ')' and before the next '%'), the runner_pct computed as 100.0 minus that winner percentage, the Margin computed as abs(2.0 * winner_pct - 100.0) that is less than 10, and an Is_Unopposed boolean indicating whether Candidates contains 'Unopposed'?","
SELECT `District`, `Incumbent`, `Party`, `First elected`, `Result`, `Candidates`,
trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 2)) Winner_pct,
100.0 - trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 2)) Runner_pct,
abs(2.0 * trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 2)) - 100.0) Margin,
(`Candidates` LIKE '%Unopposed%') Is_Unopposed
FROM `table_1_1341663_33`
WHERE instr(`Candidates`, '%') > 0 AND abs(2.0 * trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 2)) - 100.0) < 10;
","
SELECT col0, col1, col2, col3, col4, col5,
trim(substr(col5, instr(col5, ')') + 2, instr(col5, '%') - instr(col5, ')') - 2)) Winner_pct,
100.0 - trim(substr(col5, instr(col5, ')') + 2, instr(col5, '%') - instr(col5, ')') - 2)) Runner_pct,
abs(2.0 * trim(substr(col5, instr(col5, ')') + 2, instr(col5, '%') - instr(col5, ')') - 2)) - 100.0) Margin,
(col5 LIKE '%Unopposed%') Is_Unopposed
FROM `table_1_1341663_33`
WHERE instr(col5, '%') > 0 AND abs(2.0 * trim(substr(col5, instr(col5, ')') + 2, instr(col5, '%') - instr(col5, ')') - 2)) - 100.0) < 10;
","[('new york 18', 's. william green', 'republican', 1978.0, 're-elected', 's. william green (r) 53.3% carter burden (d) 46.7%', '53.3', 46.7, 6.599999999999994, 0)]",table_1_1341663_33,"1) Parse the SQL intent: select detailed election rows that include a percent sign and are close contests (computed margin < 10). 2) Map schema semantics: output District, Incumbent, Party, First elected, Result, Candidates, parse winner_pct from the substring after the first ')' up to '%', compute runner_pct = 100.0 - winner_pct, Margin = abs(2.0 * winner_pct - 100.0), and Is_Unopposed where Candidates LIKE '%Unopposed%'. 3) Draft the question to request these fields and computations and apply the filters. 4) Validate inclusion of parsing, arithmetic, and filter criteria.",reserved,5,reward,,
Which districts featured George W. Bush and Ron Paul?,"
SELECT 'Incumbency counts' AS `Category`, `Result` AS `Item`, CAST(COUNT(*) AS TEXT) AS `Value`
FROM `table_1_1341663_44`
GROUP BY `Result`
UNION ALL
SELECT 'Party changes (gains)' AS `Category`, `District` || ' - ' || `Result` AS `Item`, `Candidates` AS `Value`
FROM `table_1_1341663_44`
WHERE `Result` LIKE '%gain%'
UNION ALL
SELECT 'Unopposed races' AS `Category`, `District` AS `Item`, `Candidates` AS `Value`
FROM `table_1_1341663_44`
WHERE `Candidates` LIKE '%Unopposed%'
UNION ALL
SELECT 'Notable appearances' AS `Category`, `District` || ' - ' || `Candidates` AS `Item`, '' AS `Value`
FROM `table_1_1341663_44`
WHERE `Candidates` LIKE '%George W. Bush%' OR `Candidates` LIKE '%Ron Paul%'
UNION ALL
SELECT 'Close contests (<=5% margin)' AS `Category`,
       `District` || ' | margin ' || printf('%.1f%%', ABS(
         CAST(substr(`Candidates`, instr(`Candidates`,') ')+2,
                    instr(`Candidates`,'%') - (instr(`Candidates`,') ')+2)
         ) AS REAL)
         - CAST(substr(`Candidates`,
                    (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ') + 2),
                    (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), '%')
                      - (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ') + 2))
         ) AS REAL)
       )) AS `Item`,
       `Candidates` AS `Value`
FROM `table_1_1341663_44`
WHERE instr(`Candidates`,'%')>0
  AND instr(substr(`Candidates`, instr(`Candidates`,'%')+1), '%')>0
  AND instr(`Candidates`,') ')>0
  AND instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ')>0
  AND ABS(
         CAST(substr(`Candidates`, instr(`Candidates`,') ')+2,
                    instr(`Candidates`,'%') - (instr(`Candidates`,') ')+2)
         ) AS REAL)
         - CAST(substr(`Candidates`,
                    (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ') + 2),
                    (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), '%')
                      - (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ') + 2))
         ) AS REAL)
       ) <= 5
;
","
SELECT 'Incumbency counts' AS `Category`, col4 AS `Item`, CAST(COUNT(*) AS TEXT) AS `Value`
FROM `table_1_1341663_44`
GROUP BY col4
UNION ALL
SELECT 'Party changes (gains)' AS `Category`, col0 || ' - ' || col4 AS `Item`, col5 AS `Value`
FROM `table_1_1341663_44`
WHERE col4 LIKE '%gain%'
UNION ALL
SELECT 'Unopposed races' AS `Category`, col0 AS `Item`, col5 AS `Value`
FROM `table_1_1341663_44`
WHERE col5 LIKE '%Unopposed%'
UNION ALL
SELECT 'Notable appearances' AS `Category`, col0 || ' - ' || col5 AS `Item`, '' AS `Value`
FROM `table_1_1341663_44`
WHERE col5 LIKE '%George W. Bush%' OR col5 LIKE '%Ron Paul%'
UNION ALL
SELECT 'Close contests (<=5% margin)' AS `Category`,
       col0 || ' | margin ' || printf('%.1f%%', ABS(
         CAST(substr(col5, instr(col5,') ')+2,
                    instr(col5,'%') - (instr(col5,') ')+2)
         ) AS REAL)
         - CAST(substr(col5,
                    (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), ') ') + 2),
                    (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), '%')
                      - (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), ') ') + 2))
         ) AS REAL)
       )) AS `Item`,
       col5 AS `Value`
FROM `table_1_1341663_44`
WHERE instr(col5,'%')>0
  AND instr(substr(col5, instr(col5,'%')+1), '%')>0
  AND instr(col5,') ')>0
  AND instr(substr(col5, instr(col5,'%')+1), ') ')>0
  AND ABS(
         CAST(substr(col5, instr(col5,') ')+2,
                    instr(col5,'%') - (instr(col5,') ')+2)
         ) AS REAL)
         - CAST(substr(col5,
                    (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), ') ') + 2),
                    (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), '%')
                      - (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), ') ') + 2))
         ) AS REAL)
       ) <= 5
;
","[('Incumbency counts', 'lost re-election republican gain', '1'), ('Incumbency counts', 'lost renomination democratic hold', '1'), ('Incumbency counts', 're-elected', '7'), ('Incumbency counts', 'retired democratic hold', '3'), ('Party changes (gains)', 'texas 22 - lost re-election republican gain', 'ron paul (r) 50.6% robert gammage (d) 49.4%'), ('Unopposed races', 'texas 3', 'james m. collins (r) unopposed'), ('Unopposed races', 'texas 20', 'henry b. gonzalez (d) unopposed'), ('Notable appearances', 'texas 19 - kent hance (d) 53.2% george w. bush (r) 46.8%', ''), ('Notable appearances', 'texas 22 - ron paul (r) 50.6% robert gammage (d) 49.4%', ''), ('Close contests (<=5% margin)', 'texas 11 | margin 3.2%', 'marvin leath (d) 51.6% jack burgess (r) 48.4%'), ('Close contests (<=5% margin)', 'texas 22 | margin 1.2%', 'ron paul (r) 50.6% robert gammage (d) 49.4%')]",table_1_1341663_44,"STEP 1: Parse the SQL intent: the query unions several category outputs; one unioned branch labeled 'Notable appearances' selects District || ' - ' || Candidates for rows WHERE Candidates LIKE '%George W. Bush%' OR Candidates LIKE '%Ron Paul%'. That branch returns any district where either name appears. STEP 2: Determine ambiguity type: attachment ambiguity fits — a natural-language question that joins the two names with 'and' can be read as requiring both names to be present or as allowing either to be present. STEP 3: Draft the question: ""Which districts featured George W. Bush and Ron Paul?"" STEP 4: Explain the ambiguity: in the original SQL the condition uses OR so the result includes districts with either candidate; a reader of the question might instead expect only districts where both appeared together (AND) or might read it as asking for districts with either candidate listed separately.",persona,"Political data analyst at a state election research center who compiles historical election trends and briefings for journalists and policymakers. They use this 1978 House results table to track incumbency outcomes, party flips, unopposed races, and notable candidate appearances in Texas. Goals: Measure incumbency outcomes (re-elected, retired, lost) and count seats by each result type. Identify party changes (Republican gains / Democratic holds) to map historical turnover. Locate unopposed races and contests with notable future figures (e.g., George W. Bush, Ron Paul) for narrative reporting. Prepare a short list of competitive or close contests for follow-up (requires parsing vote percentages). Example Queries: /* 1) Summary of incumbency outcomes: how many seats ended as re-elected, retired, lost, etc. */
SELECT ""Result"", COUNT(*) AS seats
FROM table_1_1341663_44
GROUP BY ""Result""
ORDER BY seats DESC; /* 2) List all districts where the race was unopposed (no challenger listed). */
SELECT ""District"", ""Incumbent"", ""Party"", ""Candidates""
FROM table_1_1341663_44
WHERE ""Candidates"" ILIKE '%Unopposed%'; /* 3) Find districts that changed party control (any result mentioning 'gain') and show the reported candidates so you can inspect winners/margins. */
SELECT ""District"", ""Incumbent"", ""Party"", ""Result"", ""Candidates""
FROM table_1_1341663_44
WHERE ""Result"" ILIKE '%gain%';",reward,,type: Attachment ambiguity | explanation: The SQL uses OR and returns districts where either George W. Bush or Ron Paul appears; the question's phrasing with 'and' can be interpreted as requiring both candidates to appear in the same district (AND) or as asking for districts with either candidate (OR).
"By Party, among entries with First elected from 1960 through 1974 inclusive, what are the Party name, the total number of districts, the number of districts with no percentage in the Candidates field (Unopposed_count), the number of districts where Result contains 'Lost' (Incumbent_losses), the number of close races where the absolute difference between the two candidates' percentage vote shares parsed from Candidates is less than or equal to 5 percentage points (Close_race_count), and an Unopposed_flag that is 'Has unopposed' if any unopposed districts exist for that Party and 'All contested' otherwise?","
SELECT DISTINCT `Party`,
COUNT(*) `Total districts`,
SUM((instr(`Candidates`,'%')=0)) `Unopposed_count`,
SUM((instr(`Result`,'Lost')>0)) `Incumbent_losses`,
SUM((abs((trim(substr(`Candidates`, instr(`Candidates`,')')+1, instr(`Candidates`,'%')-instr(`Candidates`,')'))*1.0)-(trim(substr(`Candidates`, (instr(substr(`Candidates`, instr(`Candidates`,')')+1),')')+instr(`Candidates`,')'))+1, (instr(substr(`Candidates`, instr(`Candidates`,'%')+1),'%')+instr(`Candidates`,'%'))-(instr(substr(`Candidates`, instr(`Candidates`,')')+1),')')+instr(`Candidates`,')')))*1.0))<=5)) `Close_race_count`,
CASE WHEN SUM((instr(`Candidates`,'%')=0))>0 THEN 'Has unopposed' ELSE 'All contested' END `Unopposed_flag`
FROM `table_1_1341672_6`
WHERE `First elected`>=1960 AND `First elected`<=1974
GROUP BY `Party`
HAVING COUNT(*)>0;
","SELECT DISTINCT col2,
COUNT(*) `Total districts`,
SUM((instr(col5,'%')=0)) `Unopposed_count`,
SUM((instr(col4,'Lost')>0)) `Incumbent_losses`,
SUM(
  CASE 
    WHEN instr(col5,'%')>0 
     AND instr(substr(col5, instr(col5,'%')+1), '%')>0
    THEN
      CASE 
        WHEN abs(
          CAST(trim(substr(col5, instr(col5,')')+2, instr(col5,'%') - instr(col5,')') - 2)) AS REAL)
          - CAST(trim(substr(col5,
              instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1),')') + 2,
              (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), '%')) - (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1),')') + 2)
            )) AS REAL)
        ) <= 5 THEN 1 ELSE 0 
      END
    ELSE 0
  END
) `Close_race_count`,
CASE WHEN SUM((instr(col5,'%')=0))>0 THEN 'Has unopposed' ELSE 'All contested' END `Unopposed_flag`
FROM `table_1_1341672_6`
WHERE col3>=1960 AND col3<=1974
GROUP BY col2
HAVING COUNT(*)>0;","[('democratic', 5, 1, 0, 2, 'Has unopposed'), ('republican', 6, 0, 0, 0, 'All contested')]",table_1_1341672_6,"1) Intent: produce per-Party aggregates for rows filtered by First elected between 1960 and 1974, including counts and conditional flags with string-based detection of percentages and 'Lost'. 2) Map semantics: Party grouping, COUNT(*), instr(Candidates,'%')=0 → unopposed, instr(Result,'Lost')>0 → incumbent loss, absolute difference of vote percentages ≤5 → close race, and CASE for Unopposed_flag. 3) Draft a question that asks for Party, Total districts, Unopposed_count, Incumbent_losses, Close_race_count with the defined calculations, and the Unopposed_flag logic. 4) Validate that the question contains all computed fields and the filtering/grouping criteria from the query.",reserved,13,reward,,
"Show me all 1974 House races with district, incumbent, party, first-elected year, result, the candidate percentages, the vote margin and a scene tag (Unopposed/Blowout, FreshmanDefeat/HighConflict, IncumbentLost/HighConflict, Nail-biter/Tense, Blowout/LowConflict, Competitive/Moderate), with the biggest seat changes and freshman upsets listed first so I can sequence the revue?","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    CASE WHEN `Result` LIKE '%Lost re-election%' OR `Result` LIKE '%gain%' THEN 1 ELSE 0 END AS `Lost_or_Changed`,
    CASE WHEN `First elected` >= 1972 AND (`Result` LIKE '%Lost re-election%' OR `Result` LIKE '%gain%') THEN 1 ELSE 0 END AS `Freshman_defeat`,
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Unopposed`,
    CASE
      WHEN instr(`Candidates`, '%')>0 THEN
        trim(
          substr(
            `Candidates`,
            instr(`Candidates`, ') ')+2,
            instr(`Candidates`, '%') - (instr(`Candidates`, ') ')+2)
          )
        )
      ELSE NULL
    END AS `num1_str`,
    CASE
      WHEN instr(`Candidates`, '%')>0 AND instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%')>0 THEN
        trim(
          substr(
            substr(`Candidates`, instr(`Candidates`, '%')+1),
            instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')+2,
            instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - (instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')+2)
          )
        )
      ELSE NULL
    END AS `num2_str`
  FROM table_1_1341690_13
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  `Lost_or_Changed`,
  `Freshman_defeat`,
  `Unopposed`,
  CASE WHEN `num1_str` IS NOT NULL THEN CAST(`num1_str` AS real) ELSE NULL END AS `First_pct`,
  CASE WHEN `num2_str` IS NOT NULL THEN CAST(`num2_str` AS real) ELSE NULL END AS `Second_pct`,
  CASE WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL THEN abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) ELSE NULL END AS `Margin_pct`,
  CASE
    WHEN `Unopposed`=1 THEN 'Unopposed/Blowout'
    WHEN `Lost_or_Changed`=1 AND `Freshman_defeat`=1 THEN 'FreshmanDefeat/HighConflict'
    WHEN `Lost_or_Changed`=1 THEN 'IncumbentLost/HighConflict'
    WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL AND abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) <= 2 THEN 'Nail-biter/Tense'
    WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL AND abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) >= 20 THEN 'Blowout/LowConflict'
    ELSE 'Competitive/Moderate'
  END AS `Scene_tag`
FROM parsed
ORDER BY `Lost_or_Changed` DESC, `Freshman_defeat` DESC, `Margin_pct` ASC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    CASE WHEN col4 LIKE '%Lost re-election%' OR col4 LIKE '%gain%' THEN 1 ELSE 0 END AS `Lost_or_Changed`,
    CASE WHEN col3 >= 1972 AND (col4 LIKE '%Lost re-election%' OR col4 LIKE '%gain%') THEN 1 ELSE 0 END AS `Freshman_defeat`,
    CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Unopposed`,
    CASE
      WHEN instr(col5, '%')>0 THEN
        trim(
          substr(
            col5,
            instr(col5, ') ')+2,
            instr(col5, '%') - (instr(col5, ') ')+2)
          )
        )
      ELSE NULL
    END AS `num1_str`,
    CASE
      WHEN instr(col5, '%')>0 AND instr(substr(col5, instr(col5, '%')+1), '%')>0 THEN
        trim(
          substr(
            substr(col5, instr(col5, '%')+1),
            instr(substr(col5, instr(col5, '%')+1), ') ')+2,
            instr(substr(col5, instr(col5, '%')+1), '%') - (instr(substr(col5, instr(col5, '%')+1), ') ')+2)
          )
        )
      ELSE NULL
    END AS `num2_str`
  FROM table_1_1341690_13
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  `Lost_or_Changed`,
  `Freshman_defeat`,
  `Unopposed`,
  CASE WHEN `num1_str` IS NOT NULL THEN CAST(`num1_str` AS real) ELSE NULL END AS `First_pct`,
  CASE WHEN `num2_str` IS NOT NULL THEN CAST(`num2_str` AS real) ELSE NULL END AS `Second_pct`,
  CASE WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL THEN abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) ELSE NULL END AS `Margin_pct`,
  CASE
    WHEN `Unopposed`=1 THEN 'Unopposed/Blowout'
    WHEN `Lost_or_Changed`=1 AND `Freshman_defeat`=1 THEN 'FreshmanDefeat/HighConflict'
    WHEN `Lost_or_Changed`=1 THEN 'IncumbentLost/HighConflict'
    WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL AND abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) <= 2 THEN 'Nail-biter/Tense'
    WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL AND abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) >= 20 THEN 'Blowout/LowConflict'
    ELSE 'Competitive/Moderate'
  END AS `Scene_tag`
FROM parsed
ORDER BY `Lost_or_Changed` DESC, `Freshman_defeat` DESC, `Margin_pct` ASC;
","[('illinois 10', 'samuel h. young', 'republican', 1972.0, 'lost re-election democratic gain', 'abner j. mikva (d) 50.9% samuel h. young (r) 49.1%', 1, 1, 0, 50.9, 49.1, 1.7999999999999972, 'FreshmanDefeat/HighConflict'), ('illinois 3', 'robert p. hanrahan', 'republican', 1972.0, 'lost re-election democratic gain', 'marty russo (d) 52.6% robert p. hanrahan (r) 47.4%', 1, 1, 0, 52.6, 47.4, 5.200000000000003, 'FreshmanDefeat/HighConflict'), ('illinois 9', 'sidney r. yates', 'democratic', 1964.0, 're-elected', 'sidney r. yates (d) unopposed', 0, 0, 1, None, None, None, 'Unopposed/Blowout'), ('illinois 6', 'harold r. collier', 'republican', 1956.0, 'retired republican hold', 'henry hyde (r) 53.4% edward v. hanrahan (d) 46.6%', 0, 0, 0, 53.4, 46.6, 6.799999999999997, 'Competitive/Moderate'), ('illinois 20', 'paul findley', 'republican', 1960.0, 're-elected', 'paul findley (r) 54.8% peter f. mack (d) 45.2%', 0, 0, 0, 54.8, 45.2, 9.599999999999994, 'Competitive/Moderate'), ('illinois 4', 'ed derwinski', 'republican', 1958.0, 're-elected', 'ed derwinski (r) 59.2% ronald a. rodger (d) 40.8%', 0, 0, 0, 59.2, 40.8, 18.400000000000006, 'Competitive/Moderate'), ('illinois 12', 'phil crane', 'republican', 1969.0, 're-elected', 'phil crane (r) 61.1% betty c. spence (d) 38.9%', 0, 0, 0, 61.1, 38.9, 22.200000000000003, 'Blowout/LowConflict'), ('illinois 19', 'tom railsback', 'republican', 1966.0, 're-elected', 'tom railsback (r) 65.3% jim gende (d) 34.7%', 0, 0, 0, 65.3, 34.7, 30.599999999999994, 'Blowout/LowConflict'), ('illinois 23', 'melvin price', 'democratic', 1944.0, 're-elected', 'melvin price (d) 80.5% scott randolph (r) 19.5%', 0, 0, 0, 80.5, 19.5, 61.0, 'Blowout/LowConflict')]",table_1_1341690_13,"As a dramaturge I want a ready scene list prioritizing the most dramatic moments but I won't say 'order by' — I'll ask for the most dramatic first. The SQL produces parsed vote percentages, a margin, scene tags (Unopposed/Blowout, FreshmanDefeat/HighConflict, IncumbentLost/HighConflict, Nail-biter/Tense, Blowout/LowConflict, Competitive/Moderate) and orders results to put losses and freshman defeats first. The schema supplies district, incumbent, party, first-elected, result, candidates, computed percentages, margin and the scene tag. The question should request the full set with those scene tags and to list the biggest seat changes and freshman upsets at the top for scene sequencing.",persona,"A theatrical dramaturge and costume designer creating a 1974 political stage revue who needs district-level race details to script scenes, design costumes and pace dramatic beats. Goals: Identify which incumbents lost or seats changed party in 1974 to create high-conflict scenes and cast 'victims' and 'winners'. Find short‑tenured (recently elected) incumbents who were defeated to dramatize rapid political downfall and craft costume/prop cues that signal 'newly fallen' vs. 'longtime veteran'. Select extreme and close outcomes (unopposed blowouts and nail-biter races) to vary scene intensity and choreograph lighting/musical cues. Example Queries: /* All districts where the incumbent lost or the seat changed party */
SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1341690_13
WHERE Result LIKE '%Lost re-election%'
   OR Result LIKE '%gain%'; /* Freshman incumbents (elected 1972 or later) who were defeated — useful for 'rapid fall' characters */
SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1341690_13
WHERE ""First elected"" >= 1972
  AND Result LIKE '%Lost re-election%'; /* Find the tightest races by extracting vote percentages (Postgres-style regex) to stage close, tense scenes */
SELECT District, Incumbent, Candidates,
  abs((regexp_matches(Candidates, '([0-9]+\.[0-9]+)%')[1])::float -
      (regexp_matches(Candidates, '[A-Za-z\) ]+ ([0-9]+\.[0-9]+)%')[1])::float) AS margin_pct
FROM table_1_1341690_13
WHERE Candidates ~ '[0-9]+\.[0-9]+%.*[0-9]+\.[0-9]+%'
ORDER BY margin_pct ASC
LIMIT 5;",reward,,
"Among rows where First elected is before 1970, for each Party (grouped by Party) what is the Party name, how many Seats it holds (COUNT(*)), how many of its Candidates entries contain 'Unopposed' (Unopposed_count), the average First elected year rounded to one decimal (Avg_first_elected), and the percentage of seats that were Unopposed rounded to one decimal (Unopposed_pct), including only parties with at least one seat and limiting the result to 5 parties?","
SELECT `Party`, COUNT(*) AS `Seats`, SUM(instr(`Candidates`, '`Unopposed`')>0) `Unopposed_count`, ROUND(AVG(`First elected`),1) `Avg_first_elected`, ROUND(100.0*SUM(instr(`Candidates`, '`Unopposed`')>0)/COUNT(*),1) `Unopposed_pct`
FROM `table_1_1341690_43`
WHERE `First elected` < 1970
GROUP BY `Party`
HAVING COUNT(*)>0
LIMIT 5;
","
SELECT col2, COUNT(*) AS `Seats`, SUM(instr(col5, '`Unopposed`')>0) `Unopposed_count`, ROUND(AVG(col3),1) `Avg_first_elected`, ROUND(100.0*SUM(instr(col5, '`Unopposed`')>0)/COUNT(*),1) `Unopposed_pct`
FROM `table_1_1341690_43`
WHERE col3 < 1970
GROUP BY col2
HAVING COUNT(*)>0
LIMIT 5;
","[('democratic', 11, 0, 1952.5, 0.0), ('republican', 2, 0, 1967.0, 0.0)]",table_1_1341690_43,"1) The SQL filters rows by First elected < 1970, groups by Party, and computes seat counts and unopposed statistics with rounding. 2) Identify columns and calculations: Party, COUNT(*) as Seats, SUM(instr(Candidates,'Unopposed')>0) as Unopposed_count, ROUND(AVG(First elected),1) as Avg_first_elected, and ROUND(100.0*SUM(...)/COUNT(*),1) as Unopposed_pct. 3) Create a question asking for these exact outputs per Party with the filter and group condition and limit. 4) Ensure the question explicitly states the filter, the detection of 'Unopposed' in Candidates, the rounding to one decimal, the requirement of at least one seat, and the limit of 5.",reserved,8,reward,,
"For each California district, give the incumbent verbatim and then pull out candidate1 and candidate2 names and parties (as written), their vote percentages (NULL if Unopposed), and the absolute margin between the two so I can craft dialogue and flyers?","
WITH t AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    instr(`Candidates`, '(') AS pos_open1,
    instr(`Candidates`, ')') AS pos_close1,
    instr(`Candidates`, '%') AS pos_pct1
  FROM table_1_1341690_5
)
SELECT
  `District`,
  '`' || `Incumbent` || '`' AS `Incumbent_raw`,
  CASE
    WHEN `Incumbent` LIKE '%Redistricted from the %' THEN '`' || trim(substr(`Incumbent`, instr(`Incumbent`, 'Redistricted from the ') + 22)) || '`'
    ELSE NULL
  END AS `Original_district`,
  `Party`,
  `First elected`,
  `Result`,
  -- Candidate 1 name and party (wrapped in backticks for verbatim output)
  '`' || trim(substr(`Candidates`, 1, pos_open1 - 1)) || '`' AS `Candidate1_name`,
  '`' || substr(`Candidates`, pos_open1 + 1, pos_close1 - pos_open1 - 1) || '`' AS `Candidate1_party`,
  -- Candidate 1 percent (NULL for Unopposed)
  CASE
    WHEN `Candidates` LIKE '%Unopposed%' THEN NULL
    WHEN pos_pct1 > 0 THEN CAST(trim(substr(substr(`Candidates`, pos_close1 + 2), 1, instr(substr(`Candidates`, pos_close1 + 2), '%') - 1)) AS REAL)
    ELSE NULL
  END AS `Candidate1_pct`,
  -- Candidate 2 name and party (if present) (wrapped in backticks)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '(') > 0 THEN '`' || trim(substr(substr(`Candidates`, pos_pct1 + 1), 1, instr(substr(`Candidates`, pos_pct1 + 1), '(') - 1)) || '`'
    ELSE NULL
  END AS `Candidate2_name`,
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '(') > 0 THEN '`' || substr(substr(`Candidates`, pos_pct1 + 1), instr(substr(`Candidates`, pos_pct1 + 1), '(') + 1, instr(substr(`Candidates`, pos_pct1 + 1), ')') - instr(substr(`Candidates`, pos_pct1 + 1), '(') - 1) || '`'
    ELSE NULL
  END AS `Candidate2_party`,
  -- Candidate 2 percent (if present)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '%') > 0 THEN CAST(trim(substr(substr(`Candidates`, pos_pct1 + 1), instr(substr(`Candidates`, pos_pct1 + 1), ')') + 2, instr(substr(`Candidates`, pos_pct1 + 1), '%') - instr(substr(`Candidates`, pos_pct1 + 1), ')') - 2)) AS REAL)
    ELSE NULL
  END AS `Candidate2_pct`,
  -- Absolute margin between the two percentages (NULL if missing)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '%') > 0 THEN
      ABS(
        CAST(trim(substr(substr(`Candidates`, pos_close1 + 2), 1, instr(substr(`Candidates`, pos_close1 + 2), '%') - 1)) AS REAL)
        - CAST(trim(substr(substr(`Candidates`, pos_pct1 + 1), instr(substr(`Candidates`, pos_pct1 + 1), ')') + 2, instr(substr(`Candidates`, pos_pct1 + 1), '%') - instr(substr(`Candidates`, pos_pct1 + 1), ')') - 2)) AS REAL)
      )
    ELSE NULL
  END AS `Margin`,
  -- Drama flags: Unopposed, Narrow margin <=5%, Turnover
  CASE
    WHEN `Candidates` LIKE '%Unopposed%' THEN 'Unopposed'
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '%') > 0 AND
         ABS(
           CAST(trim(substr(substr(`Candidates`, pos_close1 + 2), 1, instr(substr(`Candidates`, pos_close1 + 2), '%') - 1)) AS REAL)
           - CAST(trim(substr(substr(`Candidates`, pos_pct1 + 1), instr(substr(`Candidates`, pos_pct1 + 1), ')') + 2, instr(substr(`Candidates`, pos_pct1 + 1), '%') - instr(substr(`Candidates`, pos_pct1 + 1), ')') - 2)) AS REAL)
         ) <= 5.0
    THEN 'Narrow<=5%'
    ELSE NULL
  END AS `Drama_flag`,
  CASE WHEN `Result` LIKE '%gain%' OR `Result` LIKE '%Lost%' THEN 'Turnover' ELSE NULL END AS `Turnover_flag`
FROM t
ORDER BY (`Margin` IS NULL), `Margin` ASC;
","
WITH t AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    instr(col5, '(') AS pos_open1,
    instr(col5, ')') AS pos_close1,
    instr(col5, '%') AS pos_pct1
  FROM table_1_1341690_5
)
SELECT
  col0,
  '`' || col1 || '`' AS `Incumbent_raw`,
  CASE
    WHEN col1 LIKE '%Redistricted from `table_1_1341690_5` %' THEN '`' || trim(substr(col1, instr(col1, 'Redistricted from `table_1_1341690_5` ') + 22)) || '`'
    ELSE NULL
  END AS `Original_district`,
  col2,
  col3,
  col4,
  -- Candidate 1 name and party (wrapped in backticks for verbatim output)
  '`' || trim(substr(col5, 1, pos_open1 - 1)) || '`' AS `Candidate1_name`,
  '`' || substr(col5, pos_open1 + 1, pos_close1 - pos_open1 - 1) || '`' AS `Candidate1_party`,
  -- Candidate 1 percent (NULL for Unopposed)
  CASE
    WHEN col5 LIKE '%Unopposed%' THEN NULL
    WHEN pos_pct1 > 0 THEN CAST(trim(substr(substr(col5, pos_close1 + 2), 1, instr(substr(col5, pos_close1 + 2), '%') - 1)) AS REAL)
    ELSE NULL
  END AS `Candidate1_pct`,
  -- Candidate 2 name and party (if present) (wrapped in backticks)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(col5, pos_pct1 + 1), '(') > 0 THEN '`' || trim(substr(substr(col5, pos_pct1 + 1), 1, instr(substr(col5, pos_pct1 + 1), '(') - 1)) || '`'
    ELSE NULL
  END AS `Candidate2_name`,
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(col5, pos_pct1 + 1), '(') > 0 THEN '`' || substr(substr(col5, pos_pct1 + 1), instr(substr(col5, pos_pct1 + 1), '(') + 1, instr(substr(col5, pos_pct1 + 1), ')') - instr(substr(col5, pos_pct1 + 1), '(') - 1) || '`'
    ELSE NULL
  END AS `Candidate2_party`,
  -- Candidate 2 percent (if present)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(col5, pos_pct1 + 1), '%') > 0 THEN CAST(trim(substr(substr(col5, pos_pct1 + 1), instr(substr(col5, pos_pct1 + 1), ')') + 2, instr(substr(col5, pos_pct1 + 1), '%') - instr(substr(col5, pos_pct1 + 1), ')') - 2)) AS REAL)
    ELSE NULL
  END AS `Candidate2_pct`,
  -- Absolute margin between the two percentages (NULL if missing)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(col5, pos_pct1 + 1), '%') > 0 THEN
      ABS(
        CAST(trim(substr(substr(col5, pos_close1 + 2), 1, instr(substr(col5, pos_close1 + 2), '%') - 1)) AS REAL)
        - CAST(trim(substr(substr(col5, pos_pct1 + 1), instr(substr(col5, pos_pct1 + 1), ')') + 2, instr(substr(col5, pos_pct1 + 1), '%') - instr(substr(col5, pos_pct1 + 1), ')') - 2)) AS REAL)
      )
    ELSE NULL
  END AS `Margin`,
  -- Drama flags: Unopposed, Narrow margin <=5%, Turnover
  CASE
    WHEN col5 LIKE '%Unopposed%' THEN 'Unopposed'
    WHEN pos_pct1 > 0 AND instr(substr(col5, pos_pct1 + 1), '%') > 0 AND
         ABS(
           CAST(trim(substr(substr(col5, pos_close1 + 2), 1, instr(substr(col5, pos_close1 + 2), '%') - 1)) AS REAL)
           - CAST(trim(substr(substr(col5, pos_pct1 + 1), instr(substr(col5, pos_pct1 + 1), ')') + 2, instr(substr(col5, pos_pct1 + 1), '%') - instr(substr(col5, pos_pct1 + 1), ')') - 2)) AS REAL)
         ) <= 5.0
    THEN 'Narrow<=5%'
    ELSE NULL
  END AS `Drama_flag`,
  CASE WHEN col4 LIKE '%gain%' OR col4 LIKE '%Lost%' THEN 'Turnover' ELSE NULL END AS `Turnover_flag`
FROM t
ORDER BY (`Margin` IS NULL), `Margin` ASC;
","[('california 17', '`bob mathias redistricted from the 18th district`', None, 'republican', 1966.0, 'lost re-election democratic gain', '`john hans krebs`', '`d`', 51.9, '`bob mathias`', '`r`', 48.1, 3.799999999999997, 'Narrow<=5%', 'Turnover'), ('california 12', '`pete mccloskey redistricted from the 17th district`', None, 'republican', 1967.0, 're-elected', '`pete mccloskey`', '`r`', 69.1, '`gary g. gillmor`', '`d`', 30.9, 38.199999999999996, None, None), ('california 9', '`pete stark redistricted from the 8th district`', None, 'democratic', 1972.0, 're-elected', '`pete stark`', '`d`', 70.6, '`edson adams`', '`r`', 29.4, 41.199999999999996, None, None), ('california 23', '`thomas m. rees redistricted from the 26th district`', None, 'democratic', 1965.0, 're-elected', '`thomas m. rees`', '`d`', 71.5, '`jack e. roberts`', '`r`', 28.5, 43.0, None, None), ('california 3', '`john e. moss`', None, 'democratic', 1952.0, 're-elected', '`john e. moss`', '`d`', 72.3, '`ivaldo lenci`', '`r`', 27.7, 44.599999999999994, None, None), ('california 10', '`don edwards redistricted from the 9th district`', None, 'democratic', 1962.0, 're-elected', '`don edwards`', '`d`', 77.0, '`john m. enright`', '`r`', 23.0, 54.0, None, None), ('california 4', '`robert l. leggett`', None, 'democratic', 1962.0, 're-elected', '`robert l. leggett`', '`d`', None, None, None, None, None, 'Unopposed', None)]",table_1_1341690_5,"I'm detail‑oriented for scene building, so I'll request parsed candidate names, parties and numeric percentages but phrase it in plain language. The SQL parses the Candidates string to extract Candidate1 and Candidate2 names, parties, numeric percents (NULL for Unopposed), and computes the absolute margin. Those pieces map to District, Incumbent, Party, Result and the parsed candidate fields in the schema. Draft question: ask to pull verbatim incumbent and parsed candidate1/2 names, parties, their percents (or null for unopposed), and the margin between them for every district. This exactly reflects the query's output which parses candidates, handles Unopposed, and computes margins.",persona,"An alternate-history novelist and electoral cartographer who reconstructs 1970s California congressional terrain to seed plot twists where redistricting and narrow margins change history. Goals: Identify districts affected by redistricting and the original districts incumbents came from to create believable character backstories and territorial grievances. Find the closest, most dramatic races (smallest vote-margin) and party turnovers to use as pivotal plot events. Extract candidate names and vote shares (and spot unopposed races) to populate dialogue, campaign flyers, and realistic election aftermath scenes. Example Queries: SELECT District, Incumbent, Party, `First elected`, Result, Candidates
FROM table_1_1341690_5
WHERE Incumbent LIKE '%Redistricted%'; /* Find contested races, extract first two vote percentages and compute margin (BigQuery-style) */
SELECT District, Incumbent,
  CAST(REGEXP_EXTRACT_ALL(Candidates, r'([0-9]+\.[0-9]+)%')[OFFSET(0)] AS FLOAT64) AS pct1,
  CAST(REGEXP_EXTRACT_ALL(Candidates, r'([0-9]+\.[0-9]+)%')[OFFSET(1)] AS FLOAT64) AS pct2,
  ABS(CAST(REGEXP_EXTRACT_ALL(Candidates, r'([0-9]+\.[0-9]+)%')[OFFSET(0)] AS FLOAT64) - CAST(REGEXP_EXTRACT_ALL(Candidates, r'([0-9]+\.[0-9]+)%')[OFFSET(1)] AS FLOAT64)) AS margin
FROM table_1_1341690_5
WHERE Candidates NOT LIKE '%Unopposed%'
ORDER BY margin ASC; /* Find districts with incumbent losses or party gains to locate turning points */
SELECT District, Incumbent, Party, Result, Candidates
FROM table_1_1341690_5
WHERE Result LIKE '%Lost%'
   OR Result LIKE '%gain%';",reward,,
"What are the Party-level aggregates: Total count of records, Avg Tenure (the average of 1974 minus First elected rounded to one decimal), Max Tenure (maximum of 1974 minus First elected) and Min Tenure (minimum of 1974 minus First elected), grouped by Party, ordered by Total descending and limited to the top 10 Parties?","
SELECT `Party`, COUNT(*) `Total`, ROUND(AVG(1974 - `First elected`),1) `Avg Tenure`, MAX(1974 - `First elected`) `Max Tenure`, MIN(1974 - `First elected`) `Min Tenure`
FROM table_1_1341690_9
WHERE 1=1
GROUP BY `Party`
ORDER BY `Total` DESC
LIMIT 10;
","
SELECT col2, COUNT(*) `Total`, ROUND(AVG(1974 - col3),1) `Avg Tenure`, MAX(1974 - col3) `Max Tenure`, MIN(1974 - col3) `Min Tenure`
FROM table_1_1341690_9
WHERE 1=1
GROUP BY col2
ORDER BY `Total` DESC
LIMIT 10;
","[('democratic', 6, 17.7, 34.0, 2.0), ('republican', 2, 3.0, 4.0, 2.0)]",table_1_1341690_9,"Parse the SQL intent: aggregate by Party to get count, rounded average tenure (based on 1974 - First elected), and min/max tenure, then order by count descending and limit to 10. Map schema semantics: Party is the party column and First elected provides the year to compute tenure. Draft the question: request these aggregates per Party with rounding of the average to one decimal and ordering/limit specified. Validate: ensure mention of Party, Total, ROUND(AVG(1974 - First elected),1) as Avg Tenure, MAX and MIN of (1974 - First elected), GROUP BY Party, ORDER BY Total DESC, LIMIT 10.",reserved,8,reward,,
"For each Party (grouped by Party) among records where Party and District are not empty, report the total count of records, the count of records whose Result contains 'Re-elected', and the average of the winner's percentage defined as 100.0 when Candidates contains 'Unopposed' otherwise as the numeric percent extracted from Candidates immediately after the first ')' and before the '%' — only include parties with at least one record and return up to 10 parties?","
SELECT `Party`, COUNT(*), SUM(`Result` LIKE '%'||REPLACE('`Re-elected`','`','')||'%'), AVG((instr(`Candidates`, REPLACE('`Unopposed`','`',''))>0)*100.0 + (1 - (instr(`Candidates`, REPLACE('`Unopposed`','`',''))>0)) * CAST(substr(`Candidates`, instr(`Candidates`,')')+2, instr(substr(`Candidates`, instr(`Candidates`,')')+2), '%') -1) AS REAL))
FROM `table_1_1341707_15`
WHERE LENGTH(`Party`)>0 AND LENGTH(`District`)>0
GROUP BY `Party`
HAVING COUNT(*)>0
LIMIT 10;
","SELECT col2, COUNT(*) AS total, SUM(CASE WHEN col4 LIKE '%Re-elected%' THEN 1 ELSE 0 END) AS re_elected_count, AVG(CASE WHEN instr(col5, 'Unopposed')>0 THEN 100.0 ELSE CAST(substr(col5, instr(col5,')')+2, instr(substr(col5, instr(col5,')')+2), '%') - 1) AS REAL) END) AS avg_pct
FROM `table_1_1341707_15`
WHERE LENGTH(col2)>0 AND LENGTH(col0)>0
GROUP BY col2
HAVING COUNT(*)>0
LIMIT 10;","[('democratic', 4, 2, 62.4), ('republican', 5, 4, 54.14)]",table_1_1341707_15,"1) The intent is to summarize per-Party counts, count of 'Re-elected' results, and the average of a computed candidate percentage with filtering of empty Party/District and limiting to 10. 2) Map SQL: Party grouping; COUNT(*) total; SUM of Result LIKE '%Re-elected%' for re-elected count; AVG uses a conditional: 100.0 if 'Unopposed' is present otherwise parse the substring percent after the first ')' and before '%' in Candidates. 3) Create a question requesting those exact aggregates with the same filters and limit. 4) Ensure mention of grouping, both aggregate formulas, exclusion of empty fields, having at least one row, and the limit.",reserved,11,reward,,
Which party had the longest-serving unopposed incumbents?,"
WITH base AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    (1972 - `First elected`) AS tenure_years,
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS unopposed_flag
  FROM `table_1_1341707_20`
),
party_summary AS (
  SELECT
    `Party`,
    COUNT(*) AS total_seats,
    SUM(unopposed_flag) AS unopposed_count,
    ROUND(AVG(CASE WHEN unopposed_flag=1 THEN tenure_years END),2) AS avg_tenure_unopposed,
    ROUND(AVG(CASE WHEN unopposed_flag=0 THEN tenure_years END),2) AS avg_tenure_opposed,
    GROUP_CONCAT(CASE WHEN unopposed_flag=1 THEN `Incumbent` || ' (' || `District` || ')' END, '; ') AS unopposed_incumbents
  FROM base
  GROUP BY `Party`
),
overall AS (
  SELECT
    'ALL' AS `Party`,
    COUNT(*) AS total_seats,
    SUM(unopposed_flag) AS unopposed_count,
    ROUND(AVG(CASE WHEN unopposed_flag=1 THEN tenure_years END),2) AS avg_tenure_unopposed,
    ROUND(AVG(CASE WHEN unopposed_flag=0 THEN tenure_years END),2) AS avg_tenure_opposed,
    GROUP_CONCAT(CASE WHEN unopposed_flag=1 THEN `Incumbent` || ' (' || `District` || ')' END, '; ') AS unopposed_incumbents
  FROM base
)
SELECT
  `Party`,
  total_seats,
  unopposed_count,
  avg_tenure_unopposed,
  avg_tenure_opposed,
  unopposed_incumbents
FROM party_summary
UNION ALL
SELECT
  `Party`,
  total_seats,
  unopposed_count,
  avg_tenure_unopposed,
  avg_tenure_opposed,
  unopposed_incumbents
FROM overall
ORDER BY unopposed_count DESC, `Party`;
","WITH base AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    (1972 - col3) AS tenure_years,
    CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS unopposed_flag
  FROM `table_1_1341707_20`
)
SELECT
  col2,
  COUNT(*) AS total_seats,
  SUM(unopposed_flag) AS unopposed_count,
  ROUND(AVG(CASE WHEN unopposed_flag=1 THEN tenure_years END),2) AS avg_tenure_unopposed,
  ROUND(AVG(CASE WHEN unopposed_flag=0 THEN tenure_years END),2) AS avg_tenure_opposed,
  GROUP_CONCAT(CASE WHEN unopposed_flag=1 THEN col1 || ' (' || col0 || ')' END, '; ') AS unopposed_incumbents
FROM base
GROUP BY col2
UNION ALL
SELECT
  'ALL' AS col2,
  COUNT(*) AS total_seats,
  SUM(unopposed_flag) AS unopposed_count,
  ROUND(AVG(CASE WHEN unopposed_flag=1 THEN tenure_years END),2) AS avg_tenure_unopposed,
  ROUND(AVG(CASE WHEN unopposed_flag=0 THEN tenure_years END),2) AS avg_tenure_opposed,
  GROUP_CONCAT(CASE WHEN unopposed_flag=1 THEN col1 || ' (' || col0 || ')' END, '; ') AS unopposed_incumbents
FROM base
ORDER BY unopposed_count DESC, col2;","[('ALL', 5, 5, 20.2, None, 'f. edward hebert (louisiana 1); hale boggs (louisiana 2); joe waggonner (louisiana 4); otto passman (louisiana 5); john rarick (louisiana 6)'), ('democratic', 5, 5, 20.2, None, 'f. edward hebert (louisiana 1); hale boggs (louisiana 2); joe waggonner (louisiana 4); otto passman (louisiana 5); john rarick (louisiana 6)')]",table_1_1341707_20,"STEP 1: Parse the SQL intent: compute per-Party and overall ('ALL') summaries including total seats, count of unopposed seats (Candidates LIKE '%Unopposed%'), average tenure for unopposed incumbents (1972 - First elected) and for opposed incumbents, and list unopposed incumbents. STEP 2: Determine ambiguity type: scope/aggregation ambiguity fits best because the query produces averages for unopposed incumbents per party (and an overall row), while a natural phrasing about the ""longest-serving"" or ""most"" could refer either to averages, to single individuals, or to the overall aggregate. STEP 3: Draft the question: ""Which party had the longest-serving unopposed incumbents?"" STEP 4: Explain ambiguity: the SQL interprets this as average tenure of unopposed incumbents per party (avg_tenure_unopposed) and also includes an overall row; alternatively the question could mean the single longest-serving unopposed incumbent by party, or ask which party(s) contain any very long-serving unopposed incumbents, or ask for the overall longest-serving unopposed incumbent across all parties.",persona,"Political science researcher specializing in incumbency and electoral competition, examining House races in the 1972 elections to understand patterns of unopposed contests and long-tenured representatives in Louisiana. Goals: Identify which incumbents ran unopposed in Louisiana's 1972 House races and whether unopposed races cluster by party or district. Measure incumbents' tenure (years in office) to analyze relationships between length of service and likelihood of running unopposed. Produce summary statistics by party (e.g., count of unopposed races) to support a paper on incumbency advantage. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1341707_20
WHERE Candidates LIKE '%Unopposed%'; SELECT Incumbent, District, Party, (1972 - ""First elected"") AS tenure_years
FROM table_1_1341707_20
ORDER BY tenure_years DESC; SELECT Party, COUNT(*) AS unopposed_count
FROM table_1_1341707_20
WHERE Candidates LIKE '%Unopposed%'
GROUP BY Party
ORDER BY unopposed_count DESC;",reward,,"type: Scope/aggregation ambiguity | explanation: In the SQL this is resolved as the party-level average tenure for unopposed incumbents (avg_tenure_unopposed, plus an overall 'ALL' row). However the question could instead ask for the single longest-serving unopposed individual (not an average), or for which parties have any long-serving unopposed incumbents, or for the overall longest-serving unopposed incumbent across all parties."
"Grouped by Party and after performing a join to the constant 'Texas 5' (no filtering), what is the TotalSeats (COUNT(*)) and the UnopposedSeats (the SUM of rows where Candidates contains 'Unopposed') for incumbents whose First elected year is <= 1964, including only parties with more than 0 UnopposedSeats and returning up to 10 results?","
SELECT `Party`, COUNT(*) `TotalSeats`, SUM(`Candidates` LIKE '%Unopposed%') `UnopposedSeats`
FROM `table_1_1341707_45`
JOIN (VALUES('Texas 5')) `v`(`Texas 5`) ON 1=1
WHERE `First elected` <= 1964
GROUP BY `Party`
HAVING SUM(`Candidates` LIKE '%Unopposed%') > 0
LIMIT 10;
","SELECT col2, COUNT(*) AS `TotalSeats`, SUM(col5 LIKE '%Unopposed%') AS `UnopposedSeats`
FROM `table_1_1341707_45`
JOIN (SELECT 'Texas 5' AS col0) AS v ON 1=1
WHERE col3 <= 1964
GROUP BY col2
HAVING SUM(col5 LIKE '%Unopposed%') > 0
LIMIT 10;","[('democratic', 13, 8)]",table_1_1341707_45,"Parse intent: aggregate by party to get total seats and number of unopposed seats for members first elected in or before 1964, include only parties with at least one unopposed seat, joining a constant 'Texas 5' value, limit to 10. Map schema: Party, First elected, Candidates correspond to party, election year, candidate text; COUNT(*) labeled TotalSeats; SUM(Candidates LIKE '%Unopposed%') labeled UnopposedSeats. Draft: formulate a question requesting those aggregated metrics with the join and filters. Validate: question mentions Party, TotalSeats, UnopposedSeats, the 'Unopposed' sum, First elected <= 1964, join to 'Texas 5', HAVING condition and LIMIT 10.",reserved,10,reward,,
"Provide District, Incumbent, Party, First elected, Result, and Candidates for entries where First elected is between 1950 and 1966 inclusive, and additionally compute Incumbent_pct by taking the substring from Candidates after the first ')' up to the '%' character and converting that to a number; also return Unopposed when Candidates has no '%' and return Safe when the computed Incumbent_pct is >= 60.","
SELECT `District`, `Incumbent`, `Party`, `First elected`, `Result`, `Candidates`,
(REPLACE(TRIM(SUBSTR(`Candidates`, INSTR(`Candidates`,')')+2, INSTR(`Candidates`,'%') - INSTR(`Candidates`,')') -1)),'%','') + 0.0) `Incumbent_pct`,
(INSTR(`Candidates`,'%') = 0) `Unopposed`,
((REPLACE(TRIM(SUBSTR(`Candidates`, INSTR(`Candidates`,')')+2, INSTR(`Candidates`,'%') - INSTR(`Candidates`,')') -1)),'%','') + 0.0) >= 60) `Safe`
FROM `table_1_1341718_36`
WHERE `First elected` >= 1950 AND `First elected` <= 1966;
","
SELECT col0, col1, col2, col3, col4, col5,
(REPLACE(TRIM(SUBSTR(col5, INSTR(col5,')')+2, INSTR(col5,'%') - INSTR(col5,')') -1)),'%','') + 0.0) `Incumbent_pct`,
(INSTR(col5,'%') = 0) `Unopposed`,
((REPLACE(TRIM(SUBSTR(col5, INSTR(col5,')')+2, INSTR(col5,'%') - INSTR(col5,')') -1)),'%','') + 0.0) >= 60) `Safe`
FROM `table_1_1341718_36`
WHERE col3 >= 1950 AND col3 <= 1966;
","[('ohio 5', 'del latta', 'republican', 1958.0, 're-elected', 'del latta (r) 71.1% carl g. sherer (d) 28.9%', 71.1, 0, 1), ('ohio 6', 'bill harsha', 'republican', 1960.0, 're-elected', 'bill harsha (r) 67.8% raymond h. stevens (d) 32.2%', 67.8, 0, 1), ('ohio 8', 'jackson edward betts', 'republican', 1950.0, 're-elected', 'jackson edward betts (r) unopposed', 0.0, 1, 0), ('ohio 10', 'clarence e. miller', 'republican', 1966.0, 're-elected', 'clarence e. miller (r) 66.5% doug arnett (d) 33.5%', 66.5, 0, 1), ('ohio 11', 'j. william stanton', 'republican', 1964.0, 're-elected', 'j. william stanton (r) 68.2% ralph rudd (d) 31.8%', 68.2, 0, 1), ('ohio 16', 'frank t. bow', 'republican', 1950.0, 're-elected', 'frank t. bow (r) 56.2% virgil l. musser (d) 43.8%', 56.2, 0, 0)]",table_1_1341718_36,"1) Parse: the SQL returns the same base columns plus an extracted incumbent percent, a boolean for absence of '%' (unopposed), and a boolean for percent >= 60, restricted to First elected in 1950–1966. 2) Map: map extraction to Candidates field and booleans to presence of '%' and numeric threshold. 3) Draft: ask for those columns and computed fields with clear extraction instructions. 4) Validate: confirm the question specifies substring after ')' up to '%' and the inclusive year range.",reserved,4,reward,,
Which incumbents were featured and competitive in the 1970 House races?,"
WITH `base` AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    (1970 - `First elected`) AS `YearsInOffice`,
    instr(`Candidates`, ') ') AS `pos_paren`
  FROM `table_1_1341718_44`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `YearsInOffice`,
  CASE WHEN `Candidates` LIKE '%Unopposed%' THEN '`Unopposed`' ELSE '`Contested`' END AS `Status`,
  CASE WHEN `First elected` <= 1950 THEN 1 ELSE 0 END AS `FeaturedCandidate`,
  CASE
    WHEN `Candidates` NOT LIKE '%Unopposed%' THEN
      CAST(
        substr(
          `Candidates`,
          `pos_paren` + 2,
          instr(substr(`Candidates`, `pos_paren` + 2), '%') - 1
        ) AS FLOAT
      )
    ELSE NULL
  END AS `LeadingPct`,
  CASE
    WHEN `Candidates` NOT LIKE '%Unopposed%' AND
         CAST(
           substr(
             `Candidates`,
             `pos_paren` + 2,
             instr(substr(`Candidates`, `pos_paren` + 2), '%') - 1
           ) AS FLOAT
         ) < 60 THEN '`Competitive (<60%)`'
    ELSE NULL
  END AS `CompetitiveFlag`,
  `Candidates`
FROM `base`
ORDER BY `FeaturedCandidate` DESC, `YearsInOffice` DESC, `Status` DESC, `LeadingPct` ASC;
","
WITH `base` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    (1970 - col3) AS `YearsInOffice`,
    instr(col5, ') ') AS `pos_paren`
  FROM `table_1_1341718_44`
)
SELECT
  col0,
  col1,
  col2,
  `YearsInOffice`,
  CASE WHEN col5 LIKE '%Unopposed%' THEN '`Unopposed`' ELSE '`Contested`' END AS `Status`,
  CASE WHEN col3 <= 1950 THEN 1 ELSE 0 END AS `FeaturedCandidate`,
  CASE
    WHEN col5 NOT LIKE '%Unopposed%' THEN
      CAST(
        substr(
          col5,
          `pos_paren` + 2,
          instr(substr(col5, `pos_paren` + 2), '%') - 1
        ) AS FLOAT
      )
    ELSE NULL
  END AS `LeadingPct`,
  CASE
    WHEN col5 NOT LIKE '%Unopposed%' AND
         CAST(
           substr(
             col5,
             `pos_paren` + 2,
             instr(substr(col5, `pos_paren` + 2), '%') - 1
           ) AS FLOAT
         ) < 60 THEN '`Competitive (<60%)`'
    ELSE NULL
  END AS `CompetitiveFlag`,
  col5
FROM `base`
ORDER BY `FeaturedCandidate` DESC, `YearsInOffice` DESC, `Status` DESC, `LeadingPct` ASC;
","[('texas 1', 'wright patman', 'democratic', 42.0, '`Contested`', 1, 78.5, None, 'wright patman (d) 78.5% james hogan (r) 21.5%'), ('texas 19', 'george h. mahon', 'democratic', 36.0, '`Unopposed`', 1, None, None, 'george h. mahon (d) unopposed'), ('texas 11', 'william r. poage', 'democratic', 34.0, '`Unopposed`', 1, None, None, 'william r. poage (d) unopposed'), ('texas 21', 'o. c. fisher', 'democratic', 28.0, '`Contested`', 1, 61.4, None, 'o. c. fisher (d) 61.4% richard gill (r) 38.6%'), ('texas 6', 'olin e. teague', 'democratic', 24.0, '`Unopposed`', 1, None, None, 'olin e. teague (d) unopposed'), ('texas 17', 'omar burleson', 'democratic', 24.0, '`Unopposed`', 1, None, None, 'omar burleson (d) unopposed'), ('texas 2', 'john dowdy', 'democratic', 18.0, '`Unopposed`', 0, None, None, 'john dowdy (d) unopposed'), ('texas 9', 'jack brooks', 'democratic', 18.0, '`Contested`', 0, 64.5, None, 'jack brooks (d) 64.5% henry c. pressler (d) 35.5%'), ('texas 12', 'jim wright', 'democratic', 16.0, '`Unopposed`', 0, None, None, 'jim wright (d) unopposed'), ('texas 14', 'john andrew young', 'democratic', 14.0, '`Unopposed`', 0, None, None, 'john andrew young (d) unopposed'), ('texas 22', 'robert r. casey', 'democratic', 12.0, '`Contested`', 0, 55.6, '`Competitive (<60%)`', 'robert r. casey (d) 55.6% arthur busch (r) 44.4%'), ('texas 20', 'henry b. gonzalez', 'democratic', 9.0, '`Unopposed`', 0, None, None, 'henry b. gonzalez (d) unopposed'), ('texas 4', 'ray roberts', 'democratic', 8.0, '`Unopposed`', 0, None, None, 'ray roberts (d) unopposed'), ('texas 10', 'j. j. pickle', 'democratic', 7.0, '`Unopposed`', 0, None, None, 'j. j. pickle (d) unopposed'), ('texas 5', 'earle cabell', 'democratic', 6.0, '`Contested`', 0, 59.7, '`Competitive (<60%)`', 'earle cabell (d) 59.7% frank crowley (r) 40.3%'), ('texas 8', 'robert c. eckhardt', 'democratic', 4.0, '`Unopposed`', 0, None, None, 'robert c. eckhardt (d) unopposed'), ('texas 18', 'bob price', 'republican', 4.0, '`Unopposed`', 0, None, None, 'bob price (r) unopposed'), ('texas 3', 'james m. collins', 'republican', 2.0, '`Contested`', 0, 60.6, None, 'james m. collins (r) 60.6% john mead (d) 39.4%')]",table_1_1341718_44,"STEP 1: Parse the SQL intent — it builds YearsInOffice = 1970 - First elected, extracts whether Candidates contains 'Unopposed' (Status), flags FeaturedCandidate when First elected <= 1950, parses the leading candidate's percentage (LeadingPct) for contested races and marks CompetitiveFlag when LeadingPct < 60; it returns all rows and orders by FeaturedCandidate desc, YearsInOffice desc, Status desc, LeadingPct asc. STEP 2: Choose an ambiguity type — scope ambiguity fits well: the natural language conjunction ""featured and competitive"" can either mean (A) filter to incumbents who are both featured and competitive, or (B) request a list that shows both attributes for every incumbent. This maps well because the SQL computes both flags but does not filter. STEP 3: Draft the question — ""Which incumbents were featured and competitive in the 1970 House races?"" STEP 4: Explain the ambiguity relative to the query — the SQL produces flags and ordering for all incumbents (matching interpretation B: list everyone and indicate who is featured and who is competitive), whereas the NL phrasing can also be read as a stricter request (interpretation A) to return only incumbents who satisfy both conditions (FeaturedCandidate = true AND CompetitiveFlag present).",persona,"A theatrical set designer staging an authentic 1970 Texas political drama who needs historically accurate campaign signage, props and background detail for each district. Goals: Identify which districts had unopposed incumbents so generic party signage (no opponent names or vote totals) can be made. Prioritize well-known, long-serving incumbents for featured props and portraits by ranking tenure (to pick visually prominent on-stage figures). Find genuinely competitive races (leading vote share under 60%) to recreate detailed campaign materials showing vote percentages and opponent names. Example Queries: SELECT District, Incumbent, Party FROM table_1_1341718_44 WHERE Candidates LIKE '%Unopposed%'; SELECT District, Incumbent, Party, (1970 - ""First elected"") AS YearsInOffice FROM table_1_1341718_44 WHERE ""First elected"" <= 1950 ORDER BY YearsInOffice DESC; SELECT District, Incumbent, Candidates, CAST(REGEXP_REPLACE(REGEXP_SUBSTR(Candidates, '[0-9]+\.[0-9]+%'), '%', '') AS FLOAT) AS LeadingPct FROM table_1_1341718_44 WHERE Candidates NOT LIKE '%Unopposed%' AND CAST(REGEXP_REPLACE(REGEXP_SUBSTR(Candidates, '[0-9]+\.[0-9]+%'), '%', '') AS FLOAT) < 60 ORDER BY LeadingPct ASC;",reward,,"type: Scope ambiguity | explanation: The phrase ""featured and competitive"" can mean either (A) return only incumbents who are both featured (First elected ≤ 1950) and competitive (leading pct < 60), or (B) return the full list of incumbents while showing/marking which ones are featured and which are competitive; the SQL computes both flags for every row (matching B) but does not filter to only those satisfying both (A)."
"List all Texas districts in 1964 sorted to show first any losses or party gains, then by the closest two‑party margin and higher Republican share, including district, incumbent, party, first‑elected year, tenure, result, and D/R vote percentages.","
WITH `parsed` AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    (1964 - `First elected`) AS `Tenure_years`,
    CASE
      WHEN instr(`Candidates`, '(D)') > 0
      THEN CAST(
             substr(
               substr(`Candidates`, instr(`Candidates`, '(D)') + 4),
               1,
               instr(substr(`Candidates`, instr(`Candidates`, '(D)') + 4), '%') - 1
             ) AS real
           )
    END AS `D_pct`,
    CASE
      WHEN instr(`Candidates`, '(R)') > 0
      THEN CAST(
             substr(
               substr(`Candidates`, instr(`Candidates`, '(R)') + 4),
               1,
               instr(substr(`Candidates`, instr(`Candidates`, '(R)') + 4), '%') - 1
             ) AS real
           )
    END AS `R_pct`
  FROM `table_1_1341865_45`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Tenure_years`,
  `Result`,
  `D_pct`,
  `R_pct`,
  ABS(`D_pct` - `R_pct`) AS `Margin_pct`,
  CASE WHEN `Result` LIKE '%Lost%' OR `Result` LIKE '%gain%' THEN 'Yes' ELSE 'No' END AS `Incumbent_lost_or_flip`,
  CASE WHEN `R_pct` > 40 THEN 'Yes' ELSE 'No' END AS `R_over_40_pct`,
  CASE WHEN ABS(`D_pct` - `R_pct`) < 15 THEN 'Yes' ELSE 'No' END AS `Competitive_under_15_margin`
FROM `parsed`
ORDER BY
  CASE WHEN `Result` LIKE '%Lost%' OR `Result` LIKE '%gain%' THEN 0 ELSE 1 END,
  `Margin_pct` ASC,
  `R_pct` DESC;
","
WITH `parsed` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    (1964 - col3) AS `Tenure_years`,
    CASE
      WHEN instr(col5, '(D)') > 0
      THEN CAST(
             substr(
               substr(col5, instr(col5, '(D)') + 4),
               1,
               instr(substr(col5, instr(col5, '(D)') + 4), '%') - 1
             ) AS real
           )
    END AS `D_pct`,
    CASE
      WHEN instr(col5, '(R)') > 0
      THEN CAST(
             substr(
               substr(col5, instr(col5, '(R)') + 4),
               1,
               instr(substr(col5, instr(col5, '(R)') + 4), '%') - 1
             ) AS real
           )
    END AS `R_pct`
  FROM `table_1_1341865_45`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  `Tenure_years`,
  col4,
  `D_pct`,
  `R_pct`,
  ABS(`D_pct` - `R_pct`) AS `Margin_pct`,
  CASE WHEN col4 LIKE '%Lost%' OR col4 LIKE '%gain%' THEN 'Yes' ELSE 'No' END AS `Incumbent_lost_or_flip`,
  CASE WHEN `R_pct` > 40 THEN 'Yes' ELSE 'No' END AS `R_over_40_pct`,
  CASE WHEN ABS(`D_pct` - `R_pct`) < 15 THEN 'Yes' ELSE 'No' END AS `Competitive_under_15_margin`
FROM `parsed`
ORDER BY
  CASE WHEN col4 LIKE '%Lost%' OR col4 LIKE '%gain%' THEN 0 ELSE 1 END,
  `Margin_pct` ASC,
  `R_pct` DESC;
","[('texas 5', 'bruce r. alger', 'republican', 1954.0, 10.0, 'lost re-election democratic gain', None, None, None, 'Yes', 'No', 'No'), ('texas 16', 'ed foreman', 'republican', 1962.0, 2.0, 'lost re-election democratic gain', None, None, None, 'Yes', 'No', 'No'), ('texas 2', 'jack brooks', 'democratic', 1952.0, 12.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 3', 'lindley beckworth', 'democratic', 1956.0, 8.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 4', 'ray roberts', 'democratic', 1962.0, 2.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 7', 'john dowdy', 'democratic', 1952.0, 12.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 9', 'clark w. thompson', 'democratic', 1947.0, 17.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 10', 'j. j. pickle', 'democratic', 1963.0, 1.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 12', 'jim wright', 'democratic', 1954.0, 10.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 14', 'john andrew young', 'democratic', 1956.0, 8.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 17', 'omar burleson', 'democratic', 1946.0, 18.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 18', 'walter e. rogers', 'democratic', 1950.0, 14.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 19', 'george h. mahon', 'democratic', 1934.0, 30.0, 're-elected', None, None, None, 'No', 'No', 'No'), ('texas 21', 'o. c. fisher', 'democratic', 1942.0, 22.0, 're-elected', None, None, None, 'No', 'No', 'No')]",table_1_1341865_45,"When prioritizing vulnerability I would want losses/flips first and then the closest races with stronger Republican showings, and I'd ask for the usual identifying and vote fields. The SQL orders rows to show losses or gains first, then by smallest margin and higher Republican percentage, and returns district, incumbent, party, first elected, tenure, result, and D/R percentages. The table columns and parsed percentages supply exactly those values. Draft question: List all Texas districts in 1964 sorted to show first any losses or party gains, then by the closest two‑party margin and higher Republican share, including district, incumbent, party, first‑elected year, tenure, result, and D/R vote percentages. This matches the query's output and ordering.",persona,"Political historian specializing in mid-20th century Southern U.S. politics who researches incumbency, party control, and seat flips in the 1964 House elections in Texas. They would use this table to identify which districts changed hands, measure incumbent longevity, and examine vote shares recorded in the Candidates field. Goals: Identify Texas House districts that changed party control or where incumbents lost in 1964. Measure incumbency/tenure (year first elected) against re-election outcomes to assess incumbency advantage. Extract and compare major-party vote shares (especially Republican shares) to identify competitive races and margins of victory. Example Queries: -- 1) Find all Texas districts where the incumbent lost (any result indicating loss or party gain)
SELECT ""District"", ""Incumbent"", ""Party"", ""Result"", ""Candidates""
FROM table_1_1341865_45
WHERE ""Result"" LIKE '%Lost%'
   OR ""Result"" LIKE '%gain%'; -- 2) List districts where the Republican candidate received more than 40% of the vote (PostgreSQL regex to extract the (R) percent)
SELECT ""District"", ""Incumbent"", ""Party"", ""Candidates"",
       (regexp_matches(""Candidates"", '\\(R\\)\\s*([0-9]+(?:\\.[0-9]+)?)%'))[1]::numeric AS r_pct
FROM table_1_1341865_45
WHERE (regexp_matches(""Candidates"", '\\(R\\)\\s*([0-9]+(?:\\.[0-9]+)?)%'))[1]::numeric > 40
ORDER BY r_pct DESC; -- 3) Compare incumbents' first-elected year by election outcome to see whether longer-tenured incumbents were more likely to be re-elected
SELECT ""Result"",
       COUNT(*) AS races,
       AVG(""First elected"") AS avg_first_elected_year
FROM table_1_1341865_45
GROUP BY ""Result""
ORDER BY races DESC;",reward,,
"For every entry where First elected < 1960, return District, Incumbent, Party, Result, Candidates, compute (1962 - First elected), extract the numeric percentage from Candidates (the substring after "") "" up to the first ""%""), indicate whether that extracted percentage is greater than 45 and less than 55, and also display `District` and `Candidates` with backticks around them?","
SELECT `District`,
`Incumbent`,
`Party`,
`Result`,
`Candidates`,
(1962 - `First elected`),
((instr(`Candidates`,'%')>0) * ((substr(`Candidates`, instr(`Candidates`,') ') + 2, instr(`Candidates`,'%') - (instr(`Candidates`,') ') + 2)) + 0.0)),
((((instr(`Candidates`,'%')>0) * ((substr(`Candidates`, instr(`Candidates`,') ') + 2, instr(`Candidates`,'%') - (instr(`Candidates`,') ') + 2)) + 0.0)) > 45) * ((((instr(`Candidates`,'%')>0) * ((substr(`Candidates`, instr(`Candidates`,') ') + 2, instr(`Candidates`,'%') - (instr(`Candidates`,') ') + 2)) + 0.0)) < 55))),
'`' || `District` || '`',
'`' || `Candidates` || '`'
FROM `table_1_1341884_45`
WHERE `First elected` < 1960;
","SELECT col0,
col1,
col2,
col4,
col5,
(1962 - col3) AS `Years since`,
CASE
  WHEN instr(col5, '%') > 0 THEN CAST(
    substr(
      col5,
      instr(col5, ') ') + 2,
      instr(col5, '%') - (instr(col5, ') ') + 2)
    ) AS REAL
  )
  ELSE NULL
END AS `First_pct`,
CASE
  WHEN instr(col5, '%') > 0
   AND CAST(
     substr(
       col5,
       instr(col5, ') ') + 2,
       instr(col5, '%') - (instr(col5, ') ') + 2)
     ) AS REAL
   ) > 45
   AND CAST(
     substr(
       col5,
       instr(col5, ') ') + 2,
       instr(col5, '%') - (instr(col5, ') ') + 2)
     ) AS REAL
   ) < 55 THEN 1
  ELSE 0
END AS `Between45and55`,
'`' || col0 || '`' AS `District_q`,
'`' || col5 || '`' AS `Candidates_q`
FROM `table_1_1341884_45`
WHERE col3 < 1960;","[('texas 1', 'wright patman', 'democratic', 're-elected', 'wright patman (d) 67.3% james timberlake (r) 32.7%', 34.0, 67.3, 0, '`texas 1`', '`wright patman (d) 67.3% james timberlake (r) 32.7%`'), ('texas 2', 'jack brooks', 'democratic', 're-elected', 'jack brooks (d) 68.7% roy james, jr. (r) 31.3%', 10.0, 68.7, 0, '`texas 2`', '`jack brooks (d) 68.7% roy james, jr. (r) 31.3%`'), ('texas 5', 'bruce r. alger', 'republican', 're-elected', 'bruce r. alger (r) 56.3% bill jones (d) 43.7%', 8.0, 56.3, 0, '`texas 5`', '`bruce r. alger (r) 56.3% bill jones (d) 43.7%`'), ('texas 6', 'olin e. teague', 'democratic', 're-elected', 'olin e. teague (d) unopposed', 16.0, None, 0, '`texas 6`', '`olin e. teague (d) unopposed`'), ('texas 7', 'john dowdy', 'democratic', 're-elected', 'john dowdy (d) 88.2% raymond ramage (r) 11.8%', 10.0, 88.2, 0, '`texas 7`', '`john dowdy (d) 88.2% raymond ramage (r) 11.8%`'), ('texas 9', 'clark w. thompson', 'democratic', 're-elected', 'clark w. thompson (d) 66.3% dave oaks (r) 33.7%', 15.0, 66.3, 0, '`texas 9`', '`clark w. thompson (d) 66.3% dave oaks (r) 33.7%`'), ('texas 10', 'homer thornberry', 'democratic', 're-elected', 'homer thornberry (d) 63.3% jim dobbs (r) 36.7%', 14.0, 63.3, 0, '`texas 10`', '`homer thornberry (d) 63.3% jim dobbs (r) 36.7%`'), ('texas 11', 'william r. poage', 'democratic', 're-elected', 'william r. poage (d) unopposed', 26.0, None, 0, '`texas 11`', '`william r. poage (d) unopposed`'), ('texas 12', 'jim wright', 'democratic', 're-elected', 'jim wright (d) 60.6% del barron (r) 39.4%', 8.0, 60.6, 0, '`texas 12`', '`jim wright (d) 60.6% del barron (r) 39.4%`'), ('texas 15', 'joe m. kilgore', 'democratic', 're-elected', 'joe m. kilgore (d) unopposed', 8.0, None, 0, '`texas 15`', '`joe m. kilgore (d) unopposed`'), ('texas 16', 'j. t. rutherford', 'democratic', 'lost re-election republican gain', 'ed foreman (r) 53.8% j. t. rutherford (d) 46.2%', 8.0, 53.8, 1, '`texas 16`', '`ed foreman (r) 53.8% j. t. rutherford (d) 46.2%`'), ('texas 17', 'omar burleson', 'democratic', 're-elected', 'omar burleson (d) unopposed', 16.0, None, 0, '`texas 17`', '`omar burleson (d) unopposed`'), ('texas 18', 'walter e. rogers', 'democratic', 're-elected', 'walter e. rogers (d) 58.8% jack seale (r) 41.2%', 12.0, 58.8, 0, '`texas 18`', '`walter e. rogers (d) 58.8% jack seale (r) 41.2%`'), ('texas 19', 'george h. mahon', 'democratic', 're-elected', 'george h. mahon (d) 67.1% dennis taylor (r) 32.9%', 28.0, 67.1, 0, '`texas 19`', '`george h. mahon (d) 67.1% dennis taylor (r) 32.9%`'), ('texas 21', 'o. c. fisher', 'democratic', 're-elected', 'o. c. fisher (d) 76.1% e. s. mayer (r) 23.9%', 20.0, 76.1, 0, '`texas 21`', '`o. c. fisher (d) 76.1% e. s. mayer (r) 23.9%`'), ('texas 22', 'robert r. casey', 'democratic', 're-elected', 'robert r. casey (d) 53.5% ross baker (r) 46.5%', 4.0, 53.5, 1, '`texas 22`', '`robert r. casey (d) 53.5% ross baker (r) 46.5%`')]",table_1_1341884_45,"1) Query intent: return electoral rows elected prior to 1960 with original columns plus years-since-election, a parsed candidate percent, a test for that percent being between 45 and 55, and backtick-quoted District and Candidates. 2) Map schema names to outputs. 3) Write a question that requests District, Incumbent, Party, Result, Candidates, (1962 - First elected), the parsed percent from Candidates, the >45 and <55 check, and backtick-enclosed District and Candidates for rows with First elected < 1960. 4) Ensure all SQL-selected items are covered precisely.",reserved,3,reward,,
"Which districts were unopposed, who held them and how long had they served, and how common were unopposed races?","
SELECT
  t.`District`,
  t.`Incumbent`,
  t.`Party`,
  t.`First elected`,
  t.`Candidates`,
  (1960 - t.`First elected`) AS `Tenure (years)`,
  (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE `Candidates` LIKE '%Unopposed%') AS `Total Unopposed Races`,
  (SELECT COUNT(*) FROM `table_1_1341897_23`) AS `Total Races`,
  ROUND(100.0 * (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE `Candidates` LIKE '%Unopposed%') / (SELECT COUNT(*) FROM `table_1_1341897_23`), 2) AS `Pct Unopposed Overall`,
  (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE `Candidates` LIKE '%Unopposed%' AND `Party` = t.`Party`) AS `Unopposed by Party`,
  (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE `Party` = t.`Party`) AS `Total Seats by Party`,
  ROUND(100.0 * (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE `Candidates` LIKE '%Unopposed%' AND `Party` = t.`Party`) / NULLIF((SELECT COUNT(*) FROM `table_1_1341897_23` WHERE `Party` = t.`Party`),0), 2) AS `Pct Unopposed within Party`
FROM `table_1_1341897_23` AS t
WHERE t.`Candidates` LIKE '%Unopposed%'
ORDER BY `Tenure (years)` DESC;
","
SELECT
  t.col0,
  t.col1,
  t.col2,
  t.col3,
  t.col5,
  (1960 - t.col3) AS `Tenure (years)`,
  (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE col5 LIKE '%Unopposed%') AS `Total Unopposed Races`,
  (SELECT COUNT(*) FROM `table_1_1341897_23`) AS `Total Races`,
  ROUND(100.0 * (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE col5 LIKE '%Unopposed%') / (SELECT COUNT(*) FROM `table_1_1341897_23`), 2) AS `Pct Unopposed Overall`,
  (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE col5 LIKE '%Unopposed%' AND col2 = t.col2) AS `Unopposed by Party`,
  (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE col2 = t.col2) AS `Total Seats by Party`,
  ROUND(100.0 * (SELECT COUNT(*) FROM `table_1_1341897_23` WHERE col5 LIKE '%Unopposed%' AND col2 = t.col2) / NULLIF((SELECT COUNT(*) FROM `table_1_1341897_23` WHERE col2 = t.col2),0), 2) AS `Pct Unopposed within Party`
FROM `table_1_1341897_23` AS t
WHERE t.col5 LIKE '%Unopposed%'
ORDER BY `Tenure (years)` DESC;
","[('massachusetts 7', 'thomas j. lane', 'democratic', 1941.0, 'thomas j. lane (d) unopposed', 19.0, 4, 6, 66.67, 4, 5, 80.0), ('massachusetts 3', 'philip philbin', 'democratic', 1942.0, 'philip philbin (d) unopposed', 18.0, 4, 6, 66.67, 4, 5, 80.0), ('massachusetts 2', 'edward boland', 'democratic', 1952.0, 'edward boland (d) unopposed', 8.0, 4, 6, 66.67, 4, 5, 80.0), ('massachusetts 11', ""tip o'neill"", 'democratic', 1952.0, ""tip o'neill (d) unopposed"", 8.0, 4, 6, 66.67, 4, 5, 80.0)]",table_1_1341897_23,"STEP 1: Parse the SQL intent — return only rows where Candidates contains 'Unopposed', showing District, Incumbent, Party, First elected, Candidates, computed Tenure (1960 - First elected), and include aggregate counts and percentages: total unopposed races overall, total races overall, percent unopposed overall, unopposed count by the incumbent's party, total seats by party, and percent unopposed within that party; order results by tenure descending. STEP 2: Choose an ambiguity type — scope ambiguity fits best because the query provides both overall and within-party percentages, so a question asking ""how common"" or ""what percent"" could reasonably refer to either the overall rate or the within-party rate. STEP 3: Draft the question — produce an NL question that matches the SQL output but leaves the scope of the percentage unclear. STEP 4: Explain the ambiguity — in the SQL the percent information is explicitly given both overall and within-party, so the question could be answered using either metric; an alternative interpretation might ask only for the overall percentage, only for the within-party percentage (per party), or even expect a per-district/localized rate in a different query.",persona,"```json
{
  ""short_persona_description"": ""A political historian specializing in mid-20th century U.S. congressional elections who uses primary election tables to study incumbency, party strength, and electoral competitiveness in 1960. They query this database to identify patterns in unopposed races, long-tenured members, and party distribution within Massachusetts."",
  ""goals"": [
    ""Identify which Massachusetts House incumbents ran unopposed in 1960 and document instances of uncontested races. Goals:  Example Queries: ",reward,,"type: Scope ambiguity | explanation: The phrase ""how common were unopposed races"" is ambiguous: the SQL provides both an overall percent unopposed and a percent unopposed within each party, so the question could mean the overall rate across all races or the rate within the incumbent's party (or, in another interpretation, a per-district/localized measure). The original query supplies both metrics; a different query might return only one of those interpretations."
"Provide, for each Party that has at least one seat, the Party, TotalSeats (total rows), UnopposedSeats (number of rows where Candidates includes 'Unopposed'), ContestedSeats (TotalSeats minus UnopposedSeats), AvgTenure calculated as ROUND(AVG(1960 - First elected), 1), and an IncumbentList formed by concatenating '`Incumbent` (`District`)' values separated by '; '; present the results ordered by Party?","
SELECT `Party`,
       COUNT(*) TotalSeats,
       SUM(CASE WHEN INSTR(`Candidates`, 'Unopposed')>0 THEN 1 END) UnopposedSeats,
       COUNT(*) - IFNULL(SUM(CASE WHEN INSTR(`Candidates`, 'Unopposed')>0 THEN 1 END),0) ContestedSeats,
       ROUND(AVG(1960 - `First elected`),1) AvgTenure,
       GROUP_CONCAT('`' || `Incumbent` || '` (' || '`' || `District` || '`)', '; ') IncumbentList
FROM `table_1_1341897_45`
GROUP BY `Party`
HAVING COUNT(*)>0
ORDER BY `Party`;
","SELECT col2, COUNT(*) AS TotalSeats, SUM(CASE WHEN INSTR(col5, 'Unopposed') > 0 THEN 1 ELSE 0 END) AS UnopposedSeats, COUNT(*) - SUM(CASE WHEN INSTR(col5, 'Unopposed') > 0 THEN 1 ELSE 0 END) AS ContestedSeats, ROUND(AVG(1960 - col3),1) AS AvgTenure, GROUP_CONCAT(col1 || ' (' || col0 || ')', '; ') AS IncumbentList FROM `table_1_1341897_45` WHERE col2 IS NOT NULL GROUP BY col2 HAVING COUNT(*) > 0 ORDER BY col2 ASC LIMIT 100;","[('democratic', 12, 0, 12, 15.6, 'wright patman (texas 1); lindley beckworth (texas 3); sam rayburn (texas 4); olin e. teague (texas 6); john dowdy (texas 7); william r. poage (texas 11); jim wright (texas 12); frank n. ikard (texas 13); john andrew young (texas 14); joe m. kilgore (texas 15); walter e. rogers (texas 18); paul j. kilday (texas 20)'), ('republican', 1, 0, 1, 6.0, 'bruce r. alger (texas 5)')]",table_1_1341897_45,"1) Parse intent: compute per-Party totals, unopposed vs contested breakdown, average years in office since First elected using 1960, and a quoted incumbent-with-district list; 2) Map schema: fields Party, Candidates, First elected, Incumbent, District are used exactly; 3) Draft: ask explicitly for TotalSeats, UnopposedSeats (Candidates contains 'Unopposed'), ContestedSeats (difference), AvgTenure rounded to one decimal, and GROUP_CONCAT of '`Incumbent` (`District`)' separated by '; '; 4) Validate: ensure the question restricts to parties with at least one seat and mentions ordering by Party.",reserved,10,reward,,
"Give me a combined 1958 summary: counts of unopposed incumbents by party, a list of incumbents who lost (with district/party/first-elected), and any close races (≤5% margin) with candidate percentages and margins.","
WITH base AS (
  SELECT `District`,`Incumbent`,`Party`,`First elected`,`Result`,`Candidates`,
    instr(`Candidates`, '%') AS p1
  FROM `table_1_1341930_5`
),
p AS (
  SELECT *,
    CASE WHEN p1>0 THEN instr(substr(`Candidates`, p1+1), '%') ELSE 0 END AS p2_rel
  FROM base
),
p2 AS (
  SELECT *,
    CASE WHEN p2_rel>0 THEN p1 + p2_rel ELSE 0 END AS p2
  FROM p
),
pct AS (
  SELECT *,
    CASE WHEN p1>0 THEN trim(substr(`Candidates`, p1-5, 5)) END AS `pct1_str`,
    CASE WHEN p2>0 THEN trim(substr(`Candidates`, p2-5, 5)) END AS `pct2_str`
  FROM p2
),
nums AS (
  SELECT *,
    CASE WHEN `pct1_str` IS NOT NULL AND `pct1_str` <> '' THEN CAST(`pct1_str` AS REAL) END AS `Pct1`,
    CASE WHEN `pct2_str` IS NOT NULL AND `pct2_str` <> '' THEN CAST(`pct2_str` AS REAL) END AS `Pct2`
  FROM pct
)
SELECT 'Unopposed by party' AS `Metric`, `Party`, NULL AS `District`, NULL AS `Incumbent`, NULL AS `First elected`, NULL AS `Result`, NULL AS `Candidates`, NULL AS `Pct1`, NULL AS `Pct2`, NULL AS `Margin`, COUNT(*) AS `Unopposed_count`
FROM `table_1_1341930_5`
WHERE `Candidates` LIKE '%Unopposed%'
GROUP BY `Party`

UNION ALL

SELECT 'Incumbents who lost or were unseated' AS `Metric`, `Party`, `District`, `Incumbent`, `First elected`, `Result`, `Candidates`, NULL AS `Pct1`, NULL AS `Pct2`, NULL AS `Margin`, NULL AS `Unopposed_count`
FROM `table_1_1341930_5`
WHERE `Result` LIKE '%Lost%'

UNION ALL

SELECT 'Close races (<=5% margin)' AS `Metric`, `Party`, `District`, `Incumbent`, `First elected`, `Result`, `Candidates`, `Pct1`, `Pct2`, ABS(`Pct1` - `Pct2`) AS `Margin`, NULL AS `Unopposed_count`
FROM nums
WHERE `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL AND ABS(`Pct1` - `Pct2`) <= 5
ORDER BY `Metric` DESC, `Unopposed_count` DESC;
","SELECT 'Unopposed by party' AS `Metric`, col2, NULL AS col0, NULL AS col1, NULL AS col3, NULL AS col4, NULL AS col5, NULL AS `Pct1`, NULL AS `Pct2`, NULL AS `Margin`, COUNT(*) AS `Unopposed_count`
FROM `table_1_1341930_5`
WHERE col5 LIKE '%Unopposed%'
GROUP BY col2

UNION ALL

SELECT 'Incumbents who lost or were unseated' AS `Metric`, col2, col0, col1, col3, col4, col5, NULL AS `Pct1`, NULL AS `Pct2`, NULL AS `Margin`, NULL AS `Unopposed_count`
FROM `table_1_1341930_5`
WHERE col4 LIKE '%Lost%'

UNION ALL

SELECT 'Close races (<=5% margin)' AS `Metric`,
       col2,
       col0,
       col1,
       col3,
       col4,
       col5,
       CASE WHEN instr(col5, '%') > 0
            THEN CAST(TRIM(substr(col5, instr(col5, '%') - 5, 5)) AS REAL)
       END AS `Pct1`,
       CASE WHEN instr(col5, '%') > 0 AND instr(substr(col5, instr(col5, '%') + 1), '%') > 0
            THEN CAST(TRIM(substr(col5, (instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%')) - 5, 5)) AS REAL)
       END AS `Pct2`,
       CASE
         WHEN instr(col5, '%') > 0
           AND instr(substr(col5, instr(col5, '%') + 1), '%') > 0
         THEN ABS(
           CAST(TRIM(substr(col5, instr(col5, '%') - 5, 5)) AS REAL)
           - CAST(TRIM(substr(col5, (instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%')) - 5, 5)) AS REAL)
         )
       END AS `Margin`,
       NULL AS `Unopposed_count`
FROM `table_1_1341930_5`
WHERE instr(col5, '%') > 0
  AND instr(substr(col5, instr(col5, '%') + 1), '%') > 0
  AND ABS(
    CAST(TRIM(substr(col5, instr(col5, '%') - 5, 5)) AS REAL)
    - CAST(TRIM(substr(col5, (instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%')) - 5, 5)) AS REAL)
  ) <= 5
ORDER BY `Metric` DESC, `Unopposed_count` DESC;","[('Unopposed by party', 'democratic', None, None, None, None, None, None, None, None, 4), ('Incumbents who lost or were unseated', 'democratic', 'arkansas 5', 'brooks hays', 1942.0, 'lost re-election democratic hold', 'dale alford ( w/i ) 51.0% brooks hays (d) 49.0%', None, None, None, None), ('Close races (<=5% margin)', 'democratic', 'arkansas 5', 'brooks hays', 1942.0, 'lost re-election democratic hold', 'dale alford ( w/i ) 51.0% brooks hays (d) 49.0%', 51.0, 49.0, 2.0, None)]",table_1_1341930_5,"As a researcher I might want a single summary that covers unopposed counts, incumbents who were unseated, and close races for cross-comparison. The SQL unions three result sets: unopposed-by-party counts, incumbents who lost, and close races (<=5% margin). The table provides the needed fields (Party, District, Incumbent, First elected, Result, Candidates) and the query extracts percentages from Candidates where present. Draft: ask for a combined report showing unopposed counts by party, the list of incumbents who lost, and any close races (≤5% margin). Validate: this mirrors the full UNION ALL query that returns all three metrics together.",persona,"Political science researcher focusing on incumbency and electoral competitiveness in mid-20th century U.S. House races, using this 1958 election table to measure patterns of unopposed races, incumbents' success rates, and close contests. Goals: Quantify how many incumbents ran unopposed in 1958 and how that breaks down by party. Identify incumbents who lost re-election (or narrowly held) and examine their tenure (first-elected year) to study incumbency vulnerability. Find competitively close districts (small vote-margin contests) to analyze regional or party patterns of electoral competitiveness. Example Queries: /* Count unopposed seats by party */
SELECT ""Party"", COUNT(*) AS unopposed_seats
FROM table_1_1341930_5
WHERE ""Candidates"" LIKE '%Unopposed%'
GROUP BY ""Party""
ORDER BY unopposed_seats DESC; /* List incumbents who lost re-election (include vote details where available) */
SELECT ""District"", ""Incumbent"", ""Party"", ""First elected"", ""Result"", ""Candidates""
FROM table_1_1341930_5
WHERE ""Result"" LIKE '%Lost%'
ORDER BY ""First elected""; /* Identify close races by extracting the top two percentage values from the Candidates field (PostgreSQL example using regexp_matches) */
WITH pct AS (
  SELECT *,
    (regexp_matches(""Candidates"", '([0-9]+\.[0-9]+)%'))[1]::numeric AS pct1,
    (regexp_matches(""Candidates"", '([0-9]+\.[0-9]+)%'))[2]::numeric AS pct2
  FROM table_1_1341930_5
  WHERE ""Candidates"" ~ '[0-9]+\.[0-9]+%'
)
SELECT ""District"", ""Incumbent"", ""Party"", pct1, pct2, ABS(pct1 - pct2) AS margin
FROM pct
WHERE pct1 IS NOT NULL AND pct2 IS NOT NULL AND ABS(pct1 - pct2) <= 5
ORDER BY margin ASC;",reward,,
"Which record contains District = 5, Incumbent = 5, Party = 5, First elected = 1914, Result = 2, Candidates = '`√ Carl Vinson (D) Unopposed`; `√ Phillip M. Landrum (D) Unopposed`', the fields '`Georgia 6`' and '`Georgia 9`', and Action = 'Actionable: prioritize contested races: `Georgia 2`, `Georgia 3`, `Georgia 4`'?","
SELECT 5 AS `District`, 5 AS `Incumbent`, 5 AS `Party`, 1914 AS `First elected`, 2 AS `Result`, '`√ Carl Vinson (D) Unopposed`; `√ Phillip M. Landrum (D) Unopposed`' AS `Candidates`, '`Georgia 6`' AS `Georgia 6`, '`Georgia 9`' AS `Georgia 9`, '`Actionable: prioritize contested races: `Georgia 2`, `Georgia 3`, `Georgia 4`' AS `Action`;
","
SELECT 5 AS col0, 5 AS col1, 5 AS col2, 1914 AS col3, 2 AS col4, '`√ Carl Vinson (D) Unopposed`; `√ Phillip M. Landrum (D) Unopposed`' AS col5, '`Georgia 6`' AS `Georgia 6`, '`Georgia 9`' AS `Georgia 9`, '`Actionable: prioritize contested races: `Georgia 2`, `Georgia 3`, `Georgia 4`' AS `Action`;
","[(5, 5, 5, 1914, 2, '`√ Carl Vinson (D) Unopposed`; `√ Phillip M. Landrum (D) Unopposed`', '`Georgia 6`', '`Georgia 9`', '`Actionable: prioritize contested races: `Georgia 2`, `Georgia 3`, `Georgia 4`')]",table_1_1341973_11,"Parse: the query constructs a single row of constants: three 5s, 1914, 2, two unopposed candidate strings, two Georgia labels, and an Action note listing Georgia 2/3/4. Map: map those constants to columns District, Incumbent, Party, First elected, Result, Candidates, Georgia 6, Georgia 9 and Action. Draft: ask for the record containing exactly those values and strings. Validate: check that every column and exact string from the query is present in the question.",reserved,10,reward,,
"Which states had the most unopposed House races in 1956 — ranked by number of unopposed districts — and for each state show total districts, percent unopposed, counts of re‑elected by party, and average tenure overall and for unopposed versus opposed incumbents?","
SELECT
  `state`,
  `total_districts`,
  `unopposed_count`,
  ROUND(CAST(`unopposed_count` AS REAL) / `total_districts` * 100, 1) AS `percent_unopposed`,
  `dem_re_elected`,
  `rep_re_elected`,
  `other_re_elected`,
  ROUND(`avg_tenure`, 1) AS `avg_tenure_years`,
  ROUND(`avg_tenure_unopposed`, 1) AS `avg_tenure_unopposed_years`,
  ROUND(`avg_tenure_opposed`, 1) AS `avg_tenure_opposed_years`
FROM (
  SELECT
    SUBSTR(`District`, 1, INSTR(`District`, ' ') - 1) AS `state`,
    COUNT(*) AS `total_districts`,
    SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `unopposed_count`,
    SUM(CASE WHEN `Result` = 'Re-elected' AND `Party` = 'Democratic' THEN 1 ELSE 0 END) AS `dem_re_elected`,
    SUM(CASE WHEN `Result` = 'Re-elected' AND `Party` = 'Republican' THEN 1 ELSE 0 END) AS `rep_re_elected`,
    SUM(CASE WHEN `Result` = 'Re-elected' AND `Party` NOT IN ('Democratic','Republican') THEN 1 ELSE 0 END) AS `other_re_elected`,
    AVG(1956 - `First elected`) AS `avg_tenure`,
    AVG(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN (1956 - `First elected`) END) AS `avg_tenure_unopposed`,
    AVG(CASE WHEN `Candidates` NOT LIKE '%Unopposed%' THEN (1956 - `First elected`) END) AS `avg_tenure_opposed`
  FROM `table_1_1341973_3`
  GROUP BY `state`
)
ORDER BY `unopposed_count` DESC, `state`;
","
SELECT
  `state`,
  `total_districts`,
  `unopposed_count`,
  ROUND(CAST(`unopposed_count` AS REAL) / `total_districts` * 100, 1) AS `percent_unopposed`,
  `dem_re_elected`,
  `rep_re_elected`,
  `other_re_elected`,
  ROUND(`avg_tenure`, 1) AS `avg_tenure_years`,
  ROUND(`avg_tenure_unopposed`, 1) AS `avg_tenure_unopposed_years`,
  ROUND(`avg_tenure_opposed`, 1) AS `avg_tenure_opposed_years`
FROM (
  SELECT
    SUBSTR(col0, 1, INSTR(col0, ' ') - 1) AS `state`,
    COUNT(*) AS `total_districts`,
    SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `unopposed_count`,
    SUM(CASE WHEN col4 = 'Re-elected' AND col2 = 'Democratic' THEN 1 ELSE 0 END) AS `dem_re_elected`,
    SUM(CASE WHEN col4 = 'Re-elected' AND col2 = 'Republican' THEN 1 ELSE 0 END) AS `rep_re_elected`,
    SUM(CASE WHEN col4 = 'Re-elected' AND col2 NOT IN ('Democratic','Republican') THEN 1 ELSE 0 END) AS `other_re_elected`,
    AVG(1956 - col3) AS `avg_tenure`,
    AVG(CASE WHEN col5 LIKE '%Unopposed%' THEN (1956 - col3) END) AS `avg_tenure_unopposed`,
    AVG(CASE WHEN col5 NOT LIKE '%Unopposed%' THEN (1956 - col3) END) AS `avg_tenure_opposed`
  FROM `table_1_1341973_3`
  GROUP BY `state`
)
ORDER BY `unopposed_count` DESC, `state`;
","[('alabama', 6, 5, 83.3, 0, 0, 0, 12.2, 13.4, 6.0)]",table_1_1341973_3,"I often want a ranked list showing where unopposed races were concentrated and the associated party and tenure patterns. The query returns per‑state totals, unopposed counts and percent, party re‑elected counts, and average tenures, then orders states by unopposed_count descending. It extracts state from the District text and uses Candidates to flag unopposed. Which states had the most unopposed House races in 1956 — ranked by number of unopposed districts — and for each state show total districts, percent unopposed, counts of re‑elected by party, and average tenure overall and for unopposed versus opposed incumbents?",persona,"A political historian focused on mid-20th-century U.S. congressional politics, especially incumbency and party dominance in the 1956 House elections. They use this database to quantify unopposed races, party control, and lengths of service for incumbents. Goals: Identify which incumbents ran unopposed in 1956 and where unopposed races were concentrated geographically (e.g., by state or region). Measure party dominance by counting re-elected incumbents by party and examining patterns in the South versus other regions. Estimate incumbents' tenure (years in office up to 1956) to analyze long-term incumbency and correlate tenure with electoral competitiveness. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Candidates
FROM table_1_1341973_3
WHERE Candidates LIKE '%Unopposed%'
ORDER BY District; SELECT Party, COUNT(*) AS incumbents_re_elected
FROM table_1_1341973_3
WHERE ""Result"" = 'Re-elected'
GROUP BY Party
ORDER BY incumbents_re_elected DESC; SELECT District, Incumbent, Party, ""First elected"", (1956 - ""First elected"") AS years_in_office
FROM table_1_1341973_3
WHERE ""Result"" = 'Re-elected'
-- focus on long-serving incumbents first elected in or before 1950
AND ""First elected"" <= 1950
ORDER BY years_in_office DESC;",reward,,
"Among entries with First elected >= 1914, which Party has the highest Pre-1950 (%) and for that Party return Party, Total Seats (the count of rows), Earliest First elected (the minimum First elected), Pre-1950 (%) defined as 100.0 * (number of rows with First elected < 1950) / (total rows) rounded to one decimal, District List as a semicolon-separated list of District values, and the columns Georgia 1, Georgia 4, Georgia 6 each set to 0?","
SELECT `Party`, COUNT(*) AS `Total Seats`, MIN(`First elected`) `Earliest First elected`, ROUND(100.0*SUM((`First elected`<1950))/COUNT(*),1) `Pre-1950 (%)`, GROUP_CONCAT(`District`, '; ') `District List`, 0 `Georgia 1`, 0 `Georgia 4`, 0 `Georgia 6`
FROM `table_1_1342013_10`
WHERE `First elected` >= 1914
GROUP BY `Party`
ORDER BY `Pre-1950 (%)` DESC
LIMIT 1;
","
SELECT col2, COUNT(*) AS `Total Seats`, MIN(col3) `Earliest First elected`, ROUND(100.0*SUM((col3<1950))/COUNT(*),1) `Pre-1950 (%)`, GROUP_CONCAT(col0, '; ') `District List`, 0 `Georgia 1`, 0 `Georgia 4`, 0 `Georgia 6`
FROM `table_1_1342013_10`
WHERE col3 >= 1914
GROUP BY col2
ORDER BY `Pre-1950 (%)` DESC
LIMIT 1;
","[('democratic', 8, 1914.0, 62.5, 'georgia 1; georgia 2; georgia 3; georgia 4; georgia 6; georgia 7; georgia 8; georgia 9', 0, 0, 0)]",table_1_1342013_10,"1) Parse intent: find the party (grouped) with the highest percent of members first elected before 1950 among those first elected >=1914, returning several aggregated columns. 2) Map schema: use Party, COUNT(*) as Total Seats, MIN(First elected) as Earliest First elected, percentage = ROUND(100.0*SUM(First elected<1950)/COUNT(*),1), GROUP_CONCAT(District,'; ') as District List, and literal zeros for Georgia 1, Georgia 4, Georgia 6. 3) Draft question: ask for the top party by that percentage and request all specified outputs. 4) Validate: includes WHERE First elected >=1914, grouping by Party, ordering by Pre-1950 (%) desc, limit 1, and all columns/calculations requested.",reserved,8,reward,,
"For each Party, report the COUNT(*) and the Unopposed_Count defined as the number of rows where Candidates contains 'Unopposed', considering only rows where Candidates contains '(' OR (Candidates contains '%' AND First elected < 1950), grouping results by Party, ordering by COUNT(*) in ascending order, and returning at most 5 rows?","
SELECT `Party`, COUNT(*), SUM(CASE WHEN instr(`Candidates`,'Unopposed')>0 THEN 1 ELSE 0 END) AS `Unopposed_Count`
FROM `table_1_1342013_20`
WHERE instr(`Candidates`,'(')>0 OR instr(`Candidates`,'%')>0 AND `First elected` < 1950
GROUP BY `Party`
ORDER BY COUNT(*)
LIMIT 5;
","
SELECT col2, COUNT(*), SUM(CASE WHEN instr(col5,'Unopposed')>0 THEN 1 ELSE 0 END) AS `Unopposed_Count`
FROM `table_1_1342013_20`
WHERE instr(col5,'(')>0 OR instr(col5,'%')>0 AND col3 < 1950
GROUP BY col2
ORDER BY COUNT(*)
LIMIT 5;
","[('republican', 2, 0), ('democratic', 3, 0)]",table_1_1342013_20,"1) The intent is to list parties with their row counts and number of unopposed entries under a compound Candidates/First elected filter, grouped and sorted with a row limit. 2) Translate columns and expressions: Party, COUNT(*), Unopposed_Count = count of Candidates containing 'Unopposed'; filter = instr(Candidates,'(')>0 OR (instr(Candidates,'%')>0 AND First elected < 1950). 3) Compose a question that asks for Party, the count, and the Unopposed_Count for rows matching that exact condition, grouped by Party, ordered by count ascending, limit 5. 4) Confirm the question mentions all calculations, the precise logical grouping of the WHERE clause, GROUP BY, ORDER BY, and LIMIT.",reserved,15,reward,,
"Compute a 'defense value' for each 1954 California district as 1.5 points per year in office (1954 − first elected) plus 40 if unopposed, otherwise add half of (100 − the vote margin), and return district, incumbent, party, first‑elected year, years in office, incumbent and challenger percentages, margin, defense value, and candidates, ordered by defense value desc then margin asc.","
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  (1954 - `First elected`) AS `Years in Office`,
  CASE
    WHEN `Candidates` LIKE '%Unopposed%' THEN 'Safe - Unopposed'
    WHEN ABS(
      CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 1) AS REAL) -
      CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 2) AS REAL)
    ) < 10 THEN 'Contested - Swing'
    WHEN CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 1) AS REAL) >= 60 THEN 'Safe - Incumbent Strong'
    ELSE 'Safe'
  END AS `Difficulty`,
  CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 100.0 ELSE CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 1) AS REAL) END AS `IncumbentPct`,
  CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 0.0   ELSE CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 2) AS REAL) END AS `ChallengerPct`,
  ABS(
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 100.0 ELSE CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 1) AS REAL) END -
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 0.0   ELSE CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 2) AS REAL) END
  ) AS `Margin`,
  ROUND(
    ((1954 - `First elected`) * 1.5) + 
    CASE
      WHEN `Candidates` LIKE '%Unopposed%' THEN 40
      ELSE ((100.0 - ABS(
              CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 1) AS REAL) -
              CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 2) AS REAL)
            )) * 0.5)
    END
  ,1) AS `Defense Value`,
  `Candidates`
FROM `table_1_1342013_5`
ORDER BY `Defense Value` DESC, `Margin` ASC;
","SELECT
  col0,
  col1,
  col2,
  col3,
  (1954 - col3) AS `Years in Office`,
  CASE
    WHEN col5 LIKE '%Unopposed%' THEN 'Safe - Unopposed'
    WHEN ABS(
      (CASE WHEN col5 LIKE '%Unopposed%' THEN 100.0 ELSE CAST(REPLACE(TRIM(SUBSTR(col5, CASE WHEN instr(col5,'%')>6 THEN instr(col5,'%')-5 ELSE 1 END, 6)), '%', '') AS REAL) END) -
      (CASE WHEN col5 LIKE '%Unopposed%' THEN 0.0 ELSE CAST(REPLACE(TRIM(SUBSTR(col5, CASE WHEN (instr(col5,'%') + instr(SUBSTR(col5, instr(col5,'%')+1), '%'))>6 THEN (instr(col5,'%') + instr(SUBSTR(col5, instr(col5,'%')+1), '%'))-5 ELSE 1 END, 6)), '%', '') AS REAL) END)
    ) < 10 THEN 'Contested - Swing'
    WHEN (CASE WHEN col5 LIKE '%Unopposed%' THEN 100.0 ELSE CAST(REPLACE(TRIM(SUBSTR(col5, CASE WHEN instr(col5,'%')>6 THEN instr(col5,'%')-5 ELSE 1 END, 6)), '%', '') AS REAL) END) >= 60 THEN 'Safe - Incumbent Strong'
    ELSE 'Safe'
  END AS `Difficulty`,
  CASE WHEN col5 LIKE '%Unopposed%' THEN 100.0 ELSE CAST(REPLACE(TRIM(SUBSTR(col5, CASE WHEN instr(col5,'%')>6 THEN instr(col5,'%')-5 ELSE 1 END, 6)), '%', '') AS REAL) END AS `IncumbentPct`,
  CASE WHEN col5 LIKE '%Unopposed%' THEN 0.0 ELSE CAST(REPLACE(TRIM(SUBSTR(col5, CASE WHEN (instr(col5,'%') + instr(SUBSTR(col5, instr(col5,'%')+1), '%'))>6 THEN (instr(col5,'%') + instr(SUBSTR(col5, instr(col5,'%')+1), '%'))-5 ELSE 1 END, 6)), '%', '') AS REAL) END AS `ChallengerPct`,
  ABS(
    (CASE WHEN col5 LIKE '%Unopposed%' THEN 100.0 ELSE CAST(REPLACE(TRIM(SUBSTR(col5, CASE WHEN instr(col5,'%')>6 THEN instr(col5,'%')-5 ELSE 1 END, 6)), '%', '') AS REAL) END) -
    (CASE WHEN col5 LIKE '%Unopposed%' THEN 0.0 ELSE CAST(REPLACE(TRIM(SUBSTR(col5, CASE WHEN (instr(col5,'%') + instr(SUBSTR(col5, instr(col5,'%')+1), '%'))>6 THEN (instr(col5,'%') + instr(SUBSTR(col5, instr(col5,'%')+1), '%'))-5 ELSE 1 END, 6)), '%', '') AS REAL) END)
  ) AS `Margin`,
  ROUND(
    ((1954 - col3) * 1.5) +
    CASE
      WHEN col5 LIKE '%Unopposed%' THEN 40
      ELSE ((100.0 - ABS(
              (CASE WHEN col5 LIKE '%Unopposed%' THEN 100.0 ELSE CAST(REPLACE(TRIM(SUBSTR(col5, CASE WHEN instr(col5,'%')>6 THEN instr(col5,'%')-5 ELSE 1 END, 6)), '%', '') AS REAL) END) -
              (CASE WHEN col5 LIKE '%Unopposed%' THEN 0.0 ELSE CAST(REPLACE(TRIM(SUBSTR(col5, CASE WHEN (instr(col5,'%') + instr(SUBSTR(col5, instr(col5,'%')+1), '%'))>6 THEN (instr(col5,'%') + instr(SUBSTR(col5, instr(col5,'%')+1), '%'))-5 ELSE 1 END, 6)), '%', '') AS REAL) END)
            )) * 0.5)
    END
  ,1) AS `Defense Value`,
  col5
FROM `table_1_1342013_5`
ORDER BY `Defense Value` DESC, `Margin` ASC;","[('california 11', 'j. leroy johnson', 'republican', 1942.0, 12.0, 'Contested - Swing', 52.6, 47.4, 5.200000000000003, 65.4, 'j. leroy johnson (r) 52.6% carl sugar (d) 47.4%'), ('california 29', 'john j. phillips', 'republican', 1942.0, 12.0, 'Safe', 58.0, 42.0, 16.0, 60.0, 'john j. phillips (r) 58.0% bruce shangle (d) 42.0%'), ('california 17', 'cecil r. king', 'democratic', 1942.0, 12.0, 'Safe - Incumbent Strong', 60.1, 39.9, 20.200000000000003, 57.9, 'cecil r. king (d) 60.1% robert h. finch (r) 39.9%'), ('california 2', 'clair engle', 'democratic', 1943.0, 11.0, 'Safe - Unopposed', 100.0, 0.0, 100.0, 56.5, 'clair engle (d) unopposed'), ('california 1', 'hubert b. scudder', 'republican', 1948.0, 6.0, 'Safe', 59.1, 40.9, 18.200000000000003, 49.9, 'hubert b. scudder (r) 59.1% max kortum (d) 40.9%'), ('california 18', 'craig hosmer', 'republican', 1952.0, 2.0, 'Safe', 55.0, 45.0, 10.0, 48.0, 'craig hosmer (r) 55.0% joseph m. kennick (d) 45.0%'), ('california 5', 'john shelley', 'democratic', 1949.0, 5.0, 'Safe - Unopposed', 100.0, 0.0, 100.0, 47.5, 'john shelley (d) unopposed'), ('california 14', 'harlan hagen', 'democratic', 1952.0, 2.0, 'Safe - Incumbent Strong', 65.1, 34.9, 30.199999999999996, 37.9, 'harlan hagen (d) 65.1% al blain (r) 34.9%'), ('california 3', 'john e. moss', 'democratic', 1952.0, 2.0, 'Safe - Incumbent Strong', 65.3, 34.7, 30.599999999999994, 37.7, 'john e. moss (d) 65.3% james h. phillips (r) 34.7%'), ('california 28', 'james b. utt', 'republican', 1952.0, 2.0, 'Safe - Incumbent Strong', 66.2, 33.8, 32.400000000000006, 36.8, 'james b. utt (r) 66.2% harriet enderle (d) 33.8%')]",table_1_1342013_5,"I'm balancing card difficulty by a numeric 'defense' rating combining tenure and vote safety, and I'm comfortable describing the formula in plain terms. The query computes Years in Office as 1954 minus First elected, then Defense Value = (years * 1.5) + (40 if unopposed, else 0.5 * (100 − margin)), and orders by that value desc then margin asc. Schema mapping: years come from First elected, 'Unopposed' is detected in Candidates text, and percentages are parsed from Candidates to compute margin. Draft question: compute and return each 1954 California district's defense value using 1.5 points per year in office plus 40 if unopposed (otherwise add half of 100 minus the vote margin), and show district, incumbent, party, first‑elected year, years in office, incumbent and challenger percentages, margin, defense value, and candidates, ordered by defense value desc then margin asc. This validates against the query since it requests the exact computation, fields and ordering used.",persona,"A retro board-game designer who builds a historically accurate 1954 California congressional campaign game and needs to balance district cards by incumbent strength and competitiveness. Goals: Identify unopposed districts and safe seats to create easy 'hold' tiles for players. Find narrowly decided (swing) districts to serve as high-value contested spaces with special mechanics. Rate incumbents' ‘defense’ value using tenure (years in office) and recent vote margins to balance gameplay difficulty and card abilities. Example Queries: /* 1) Find all unopposed races to mark as automatic holds in the game */
SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1342013_5
WHERE Candidates LIKE '%Unopposed%'; /* 2) Extract reported percentages and list close (swing) contests where vote margin < 10% */
SELECT District, Incumbent, Party,
  CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 1) AS REAL)     AS IncumbentPct,
  CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 2) AS REAL)     AS ChallengerPct,
  ABS(CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 1) AS REAL) - CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 2) AS REAL)) AS Margin
FROM table_1_1342013_5
WHERE Candidates NOT LIKE '%Unopposed%'
HAVING Margin < 10
ORDER BY Margin ASC; /* 3) Produce district cards showing years in office (1954 baseline) and a difficulty tag for game balancing */
SELECT District, Incumbent, Party, ""First elected"",
  (1954 - ""First elected"") AS YearsInOffice,
  CASE
    WHEN Candidates LIKE '%Unopposed%' THEN 'Safe - No opposition'
    WHEN ABS(CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 1) AS REAL) - CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 2) AS REAL)) < 10 THEN 'Contested - Swing'
    ELSE 'Safe'
  END AS Difficulty,
  Candidates
FROM table_1_1342013_5
ORDER BY YearsInOffice DESC, Difficulty DESC;",reward,,
"Give me a prioritized list of channels that are either the standard non-overlap ones (1, 6, 11), channel 6 or overlap 6, or have center frequency ≥ 2.45 GHz, and include each channel’s center frequency, channel width, overlap list and a role tag.","
WITH parsed AS (
  SELECT
    `Channel`,
    `Center Frequency`,
    CAST(REPLACE(`Center Frequency`, ' GHz', '') AS REAL) AS center_GHz,
    `Channel Width`,
    `Overlaps Channels`
  FROM `table_1_13420417_1`
),
flagged AS (
  SELECT
    `Channel`,
    `Center Frequency`,
    center_GHz,
    `Channel Width`,
    `Overlaps Channels`,
    (CASE WHEN `Channel` IN (1,6,11) THEN '`reference_non-overlap`,' ELSE '' END) ||
    (CASE WHEN `Channel` = 6 OR `Overlaps Channels` LIKE '%6%' THEN '`overlaps_6`,' ELSE '' END) ||
    (CASE WHEN center_GHz >= 2.45 THEN '`upper_band_>=2.45GHz`' ELSE '' END) AS roles_raw
  FROM parsed
)
SELECT
  `Channel`,
  '`' || `Center Frequency` || '`' AS `Center Frequency`,
  center_GHz,
  '`' || `Channel Width` || '`' AS `Channel Width`,
  '`' || `Overlaps Channels` || '`' AS `Overlaps Channels`,
  CASE
    WHEN roles_raw LIKE '%,' THEN substr(roles_raw, 1, length(roles_raw) - 1)
    ELSE roles_raw
  END AS `Roles`
FROM flagged
WHERE roles_raw <> ''
ORDER BY
  CASE
    WHEN `Channel` IN (1,6,11) THEN 0
    WHEN `Channel` = 6 OR `Overlaps Channels` LIKE '%6%' THEN 1
    WHEN center_GHz >= 2.45 THEN 2
    ELSE 3
  END,
  center_GHz;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    CAST(REPLACE(col1, ' GHz', '') AS REAL) AS center_GHz,
    col3,
    col4
  FROM `table_1_13420417_1`
)
SELECT
  col0,
  col1,
  center_GHz,
  col3,
  col4,
  TRIM(
    (CASE WHEN col0 IN (1,6,11) THEN '`reference_non-overlap`,' ELSE '' END) ||
    (CASE WHEN col0 = 6 OR col4 LIKE '%6%' THEN '`overlaps_6`,' ELSE '' END) ||
    (CASE WHEN center_GHz >= 2.45 THEN '`upper_band_>=2.45GHz`' ELSE '' END)
  , ',') AS `Roles`
FROM parsed
WHERE
  (col0 IN (1,6,11)
   OR col0 = 6
   OR col4 LIKE '%6%'
   OR center_GHz >= 2.45)
ORDER BY
  CASE
    WHEN col0 IN (1,6,11) THEN 0
    WHEN col0 = 6 OR col4 LIKE '%6%' THEN 1
    WHEN center_GHz >= 2.45 THEN 2
    ELSE 3
  END,
  center_GHz;","[(1.0, '2.412 ghz', 2.412, '2.401–2.423ghz', '2-5', '`reference_non-overlap`'), (6.0, '2.437 ghz', 2.437, '2.426–2.448ghz', '2-5,7-10', '`reference_non-overlap`,`overlaps_6`'), (11.0, '2.462 ghz', 2.462, '2.451–2.473ghz', '7-10,12-13', '`reference_non-overlap`,`upper_band_>=2.45GHz`'), (2.0, '2.417 ghz', 2.417, '2.406–2.428ghz', '1,3-6', '`overlaps_6`'), (5.0, '2.432 ghz', 2.432, '2.421–2.443ghz', '1-4,6-9', '`overlaps_6`'), (7.0, '2.442 ghz', 2.442, '2.431–2.453ghz', '3-6,8-11', '`overlaps_6`'), (10.0, '2.457 ghz', 2.457, '2.446–2.468ghz', '6-9,11-13', '`overlaps_6`,`upper_band_>=2.45GHz`'), (9.0, '2.452 ghz', 2.452, '2.441–2.463ghz', '5-8,10-13', '`upper_band_>=2.45GHz`'), (12.0, '2.467 ghz', 2.467, '2.456–2.478ghz', '8-11,13-14', '`upper_band_>=2.45GHz`'), (13.0, '2.472 ghz', 2.472, '2.461–2.483ghz', '9-12, 14', '`upper_band_>=2.45GHz`')]",table_1_13420417_1,"I’d want a single prioritized view that calls out standard non-overlap channels, channels that overlap 6, and high‑band channels so I can make quick decisions. The query builds role tags for channels in (1,6,11), channels equal to or overlapping 6, and channels with center_GHz >= 2.45, then returns only rows with at least one role and orders them by those priorities. The relevant columns are Channel, Center Frequency, Channel Width, Overlaps Channels and the computed Roles. Draft question: give me a prioritized list of channels that are (a) standard non-overlap (1,6,11), (b) channel 6 or overlap 6, or (c) have center freq ≥ 2.45 GHz, and show center freq, width, overlap list and a role tag for each. This mirrors the SQL selection, role tagging and ordering.",persona,"Enterprise Wi-Fi network engineer responsible for planning and optimizing 2.4 GHz deployments across multi-floor office sites; uses this channel/frequency table to assign channels and avoid co-channel and adjacent-channel interference. Goals: Identify standard non-overlapping channels to use for AP placement (commonly 1, 6, 11) and confirm their center frequencies and occupied bandwidth. Determine which channels overlap a given channel (e.g., channel 6) so adjacent APs can be assigned non-overlapping channels. Filter channels by frequency range (e.g., high end of the 2.4 GHz band) to plan channel reuse and avoid interference with known local devices. Example Queries: /* Get reference info for the three commonly used non-overlapping channels */
SELECT Channel, ""Center Frequency"", ""Channel Width"", ""Overlaps Channels""
FROM table_1_13420417_1
WHERE Channel IN (1, 6, 11); /* Find rows that explicitly mention channel 6 in the Overlaps Channels column (simple text search) or the channel itself */
SELECT Channel, ""Overlaps Channels""
FROM table_1_13420417_1
WHERE Channel = 6
   OR ""Overlaps Channels"" LIKE '%6%'
/* Note: this searches text (ranges and lists); for precise range parsing additional string parsing is needed */; /* Select channels in the upper part of the 2.4 GHz band (numeric comparison by stripping ' GHz') */
SELECT Channel,
       CAST(REPLACE(""Center Frequency"", ' GHz', '') AS REAL) AS center_GHz,
       ""Channel Width""
FROM table_1_13420417_1
WHERE CAST(REPLACE(""Center Frequency"", ' GHz', '') AS REAL) >= 2.45
ORDER BY center_GHz;",reward,,
"Which rows (showing District, Incumbent, Party, First elected, Result and Candidates) return the first candidate's percentage (the digits between the first ')' and the first '%'), the second candidate's percentage (the digits between the second ')' and the second '%'), and the absolute difference of these two numeric percentages (abs(first percentage - second percentage)) for cases where that absolute difference is <= 1.0?","
SELECT `District`, `Incumbent`, `Party`, `First elected`, `Result`, `Candidates`,
replace(substr(`Candidates`, instr(`Candidates`, ')')+2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 1), '%', '') + 0.0,
replace(substr(substr(`Candidates`, instr(`Candidates`, '%')+1), instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')')+2, instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')') - 1), '%', '') + 0.0,
abs(
(replace(substr(`Candidates`, instr(`Candidates`, ')')+2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 1), '%', '') + 0.0)
-
(replace(substr(substr(`Candidates`, instr(`Candidates`, '%')+1), instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')')+2, instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')') - 1), '%', '') + 0.0)
)
FROM `table_1_1342149_38`
WHERE `Incumbent` LIKE `Incumbent` AND abs(
(replace(substr(`Candidates`, instr(`Candidates`, ')')+2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 1), '%', '') + 0.0)
-
(replace(substr(substr(`Candidates`, instr(`Candidates`, '%')+1), instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')')+2, instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')') - 1), '%', '') + 0.0)
) <= 1.0;
","
SELECT col0, col1, col2, col3, col4, col5,
replace(substr(col5, instr(col5, ')')+2, instr(col5, '%') - instr(col5, ')') - 1), '%', '') + 0.0,
replace(substr(substr(col5, instr(col5, '%')+1), instr(substr(col5, instr(col5, '%')+1), ')')+2, instr(substr(col5, instr(col5, '%')+1), '%') - instr(substr(col5, instr(col5, '%')+1), ')') - 1), '%', '') + 0.0,
abs(
(replace(substr(col5, instr(col5, ')')+2, instr(col5, '%') - instr(col5, ')') - 1), '%', '') + 0.0)
-
(replace(substr(substr(col5, instr(col5, '%')+1), instr(substr(col5, instr(col5, '%')+1), ')')+2, instr(substr(col5, instr(col5, '%')+1), '%') - instr(substr(col5, instr(col5, '%')+1), ')') - 1), '%', '') + 0.0)
)
FROM `table_1_1342149_38`
WHERE col1 LIKE col1 AND abs(
(replace(substr(col5, instr(col5, ')')+2, instr(col5, '%') - instr(col5, ')') - 1), '%', '') + 0.0)
-
(replace(substr(substr(col5, instr(col5, '%')+1), instr(substr(col5, instr(col5, '%')+1), ')')+2, instr(substr(col5, instr(col5, '%')+1), '%') - instr(substr(col5, instr(col5, '%')+1), ')') - 1), '%', '') + 0.0)
) <= 1.0;
","[('pennsylvania 25', 'louis e. graham', 'republican', 1938.0, 're-elected', 'louis e. graham (r) 50.4% frank m. clark (d) 49.6%', 50.4, 49.6, 0.7999999999999972)]",table_1_1342149_38,"1) The intent is to list rows and computed percentage values where the vote percentages of the two candidates differ by no more than 1.0. 2) Map to table columns and the string-to-number extraction of each candidate's percentage from Candidates. 3) Draft a question asking for District, Incumbent, Party, First elected, Result, Candidates, the two extracted percentages, and their absolute difference with the <=1.0 filter. 4) Confirm the question references the exact substring positions (between ')' and '%') and the absolute difference calculation.",reserved,5,reward,,
"What are the per-Party values of COUNT(*) total_races, SUM(Result = 'Re-elected') re_elected, SUM(INSTR(Result, 'Lost re-election Republican gain') > 0) lost_count, SUM(INSTR(Result, 'Lost re-election Republican gain') > 0) gain_count, and AVG(First elected) avg_first_elected for rows where Result != 'Retired to run for U. S. Senate Democratic hold' and First elected >= 1944, ordered by lost_count descending then re_elected descending, limited to 10?","
SELECT `Party`, COUNT(*) total_races, SUM(`Result` = `Re-elected`) re_elected, SUM(INSTR(`Result`, `Lost re-election Republican gain`) > 0) lost_count, SUM(INSTR(`Result`, `Lost re-election Republican gain`) > 0) gain_count, AVG(`First elected`) avg_first_elected
FROM `table_1_1342198_36`
WHERE `Result` != `Retired to run for U. S. Senate Democratic hold` AND `First elected` >= 1944
GROUP BY `Party`
ORDER BY lost_count DESC, re_elected DESC
LIMIT 10;
","SELECT col2, COUNT(*) AS total_races, SUM(col4 = 'Re-elected') AS re_elected, SUM(INSTR(col4, 'Lost re-election Republican gain') > 0) AS lost_count, SUM(INSTR(col4, 'Lost re-election Republican gain') > 0) AS gain_count, AVG(col3) AS avg_first_elected
FROM `table_1_1342198_36`
WHERE col4 != 'Retired to run for U. S. Senate Democratic hold' AND col3 >= 1944
GROUP BY col2
ORDER BY lost_count DESC, re_elected DESC
LIMIT 10;","[('democratic', 5, 0, 0, 0, 1946.4)]",table_1_1342198_36,"1) The SQL is designed to group by Party and compute total race counts, counts of exact 'Re-elected' results, counts of results containing 'Lost re-election Republican gain' (reported twice), and the average of First elected, with filters and ordering. 2) Map columns: Party, Result, First elected and the specific exclusion string 'Retired to run for U. S. Senate Democratic hold', and year cutoff 1944. 3) Draft: request those aggregates with the specified filters, ordering by lost_count then re_elected, limit 10. 4) Validate: ensure the question names COUNT(*) total_races, SUM(Result = 'Re-elected') re_elected, SUM(INSTR(...) > 0) lost_count and gain_count, AVG(First elected) avg_first_elected, the exclusion, and the ordering/limit.",reserved,9,reward,,
"Give me clean, printable lines for each PA 1950 House district showing district, incumbent, incumbent party, years in office, candidate1 name/party/percent, candidate2 name/party/percent, the margin percentage, and flags for 'tense' (≤5%) and 'long‑serving' (8+ years), with the tightest races at the top so I can pick live re‑creations?","
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  (1950 - `First elected`) AS `years_in_office`,
  TRIM(REGEXP_SUBSTR(`Candidates`, '^[^0-9\\(]+')) AS `candidate1_name`,
  REGEXP_SUBSTR(`Candidates`, '\\(([^)]+)\\)', 1, 1) AS `candidate1_party`,
  REGEXP_SUBSTR(`Candidates`, '[0-9]+\\.?[0-9]*%', 1, 1) AS `candidate1_pct`,
  TRIM(REGEXP_SUBSTR(`Candidates`, '[^0-9\\(]+(?=[0-9]+\\.?[0-9]*%)', 1, 2)) AS `candidate2_name`,
  REGEXP_SUBSTR(`Candidates`, '\\(([^)]+)\\)', 1, 2) AS `candidate2_party`,
  REGEXP_SUBSTR(`Candidates`, '[0-9]+\\.?[0-9]*%', 1, 2) AS `candidate2_pct`,
  ABS(
    CAST(REPLACE(REGEXP_SUBSTR(`Candidates`, '[0-9]+\\.?[0-9]*%', 1, 1), '%', '') AS REAL)
    -
    CAST(REPLACE(REGEXP_SUBSTR(`Candidates`, '[0-9]+\\.?[0-9]*%', 1, 2), '%', '') AS REAL)
  ) AS `margin_pct`,
  CASE WHEN ABS(
    CAST(REPLACE(REGEXP_SUBSTR(`Candidates`, '[0-9]+\\.?[0-9]*%', 1, 1), '%', '') AS REAL)
    -
    CAST(REPLACE(REGEXP_SUBSTR(`Candidates`, '[0-9]+\\.?[0-9]*%', 1, 2), '%', '') AS REAL)
  ) <= 5 THEN 1 ELSE 0 END AS `tense_race`,
  CASE WHEN (1950 - `First elected`) >= 8 THEN 1 ELSE 0 END AS `long_serving`
FROM table_1_1342198_38
ORDER BY `tense_race` DESC, `margin_pct` ASC, `years_in_office` DESC;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    (1950 - col3) AS `years_in_office`,
    TRIM(SUBSTR(col5, 1, instr(col5, ' (') - 1)) AS `candidate1_name`,
    SUBSTR(col5, instr(col5, '(') + 1, instr(col5, ')') - instr(col5, '(') - 1) AS `candidate1_party`,
    TRIM(SUBSTR(col5, instr(col5, ')') + 2, instr(col5, '%') - instr(col5, ')') - 1)) AS `candidate1_pct`,
    TRIM(SUBSTR(col5, instr(col5, '%') + 1)) AS `tail`
  FROM table_1_1342198_38
)
SELECT
  col0,
  col1,
  col2,
  col3,
  `years_in_office`,
  `candidate1_name`,
  `candidate1_party`,
  `candidate1_pct`,
  TRIM(SUBSTR(`tail`, 1, instr(`tail`, ' (') - 1)) AS `candidate2_name`,
  SUBSTR(`tail`, instr(`tail`, '(') + 1, instr(`tail`, ')') - instr(`tail`, '(') - 1) AS `candidate2_party`,
  TRIM(SUBSTR(`tail`, instr(`tail`, ')') + 2, instr(`tail`, '%') - instr(`tail`, ')') - 1)) AS `candidate2_pct`,
  ABS(
    CAST(REPLACE(`candidate1_pct`, '%', '') AS REAL)
    -
    CAST(REPLACE(TRIM(SUBSTR(`tail`, instr(`tail`, ')') + 2, instr(`tail`, '%') - instr(`tail`, ')') - 1)), '%', '') AS REAL)
  ) AS `margin_pct`,
  CASE WHEN ABS(
    CAST(REPLACE(`candidate1_pct`, '%', '') AS REAL)
    -
    CAST(REPLACE(TRIM(SUBSTR(`tail`, instr(`tail`, ')') + 2, instr(`tail`, '%') - instr(`tail`, ')') - 1)), '%', '') AS REAL)
  ) <= 5 THEN 1 ELSE 0 END AS `tense_race`,
  CASE WHEN `years_in_office` >= 8 THEN 1 ELSE 0 END AS `long_serving`
FROM parsed
ORDER BY `tense_race` DESC, `margin_pct` ASC, `years_in_office` DESC;","[('pennsylvania 3', 'hardie scott', 'republican', 1946.0, 4.0, 'hardie scott', 'r', '50.3%', 'maurice s. osser', 'd', '49.7%', 0.5999999999999943, 1, 0), ('pennsylvania 21', 'james f. lind', 'democratic', 1948.0, 2.0, 'james f. lind', 'd', '52.2%', 'francis worley', 'r', '47.8%', 4.400000000000006, 1, 0), ('pennsylvania 12', 'ivor d. fenton', 'republican', 1938.0, 12.0, 'ivor d. fenton', 'r', '56.8%', 'james h. gildea', 'd', '43.2%', 13.599999999999994, 0, 1), ('pennsylvania 2', 'william t. granahan', 'democratic', 1948.0, 2.0, 'william t. granahan', 'd', '57.0%', 'max slepin', 'r', '43.0%', 14.0, 0, 0), ('pennsylvania 19', 'leon h. gavin', 'republican', 1942.0, 8.0, 'leon h. gavin', 'r', '62.8%', 'fred c. barr', 'd', '37.2%', 25.599999999999994, 0, 1), ('pennsylvania 9', 'paul b. dague', 'republican', 1946.0, 4.0, 'paul b. dague', 'r', '67.2%', 'philip ragan', 'd', '32.8%', 34.400000000000006, 0, 0)]",table_1_1342198_38,"Persona: I need neat, actor‑ready lines and would ask for 'clean printable lines' in a slightly performative way but without SQL terms. SQL intent: Parse candidate names, parties and percentage strings into two candidate records, compute margin, flag tense races (≤5%) and long‑serving incumbents (≥8 years), and order by tense then margin then seniority. Schema mapping: All requested outputs are derived from District, Incumbent, Party, First elected and the Candidates text field. Draft question: Give me clean, printable lines for each PA 1950 House district showing district, incumbent, incumbent party, years in office, candidate1 name/party/percent, candidate2 name/party/percent, the margin percentage, and flags for 'tense' (≤5%) and 'long‑serving' (8+ years), with the tightest races at the top so I can pick live re‑creations?  Validate: The question only asks for fields and computed flags present in the query and requests the sorting it applies.",persona,"A museum sound‑designer curating an immersive 'Election Night 1950 — Pennsylvania' audio exhibit who stages dramatized precinct calls and needs authentic, district‑level race details. Goals: Find the most dramatic/tense races (very narrow margins) to script cliffhanger audio vignettes and decide which districts get a live re-creation. Identify long‑serving incumbents and their party affiliation to record convincing voice‑portraits and background narration about political longevity and local power. Extract clean candidate names, parties and vote percentages so actors can read authentic results and the exhibit signage can display accurate vote breakdowns. Example Queries: /* 1) Find the closest races (margin <= 5%) to prioritize for dramatic reenactments */
SELECT District, Incumbent, Party, Candidates,
ABS(
  CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*', 1, 1) AS REAL) -
  CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*', 1, 2) AS REAL)
) AS margin_pct
FROM table_1_1342198_38
WHERE ABS(
  CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*', 1, 1) AS REAL) -
  CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*', 1, 2) AS REAL)
) <= 5
ORDER BY margin_pct ASC; /* 2) List incumbents with long tenure (years in office >= 8 by 1950) for background narratives */
SELECT District, Incumbent, Party, ""First elected"",
(1950 - ""First elected"") AS years_in_office
FROM table_1_1342198_38
WHERE (1950 - ""First elected"") >= 8
ORDER BY years_in_office DESC; /* 3) Parse candidate names, parties and percentages into separate fields for script copy and exhibit panels */
SELECT District,
Incumbent,
TRIM(REGEXP_SUBSTR(Candidates, '^[^0-9\(]+')) AS candidate1_name,
REGEXP_SUBSTR(Candidates, '\\(([^)]+)\\)', 1, 1) AS candidate1_party,
REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*%', 1, 1) AS candidate1_pct,
TRIM(REGEXP_SUBSTR(Candidates, '[^0-9\(]+(?=[0-9]+\.?[0-9]*%)', 1, 2)) AS candidate2_name,
REGEXP_SUBSTR(Candidates, '\\(([^)]+)\\)', 1, 2) AS candidate2_party,
REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*%', 1, 2) AS candidate2_pct
FROM table_1_1342198_38;",reward,,
Which parties have the highest average incumbent vote share?,"
SELECT `t`.`Party`, COUNT(*) `Total Seats`,
       SUM(`t`.`Candidates` LIKE '%Unopposed%') `Unopposed Seats`,
       SUM(NOT(`t`.`Candidates` LIKE '%Unopposed%')) `Contested Seats`,
       ROUND(AVG((TRIM(SUBSTR(
         `t`.`Candidates`,
         INSTR(`t`.`Candidates`, '(' || SUBSTR(`t`.`Party`,1,1) || ')') + 4,
         INSTR(SUBSTR(`t`.`Candidates`, INSTR(`t`.`Candidates`, '(' || SUBSTR(`t`.`Party`,1,1) || ')') + 4), '%') - 1
       )) + 0.0)),2) `Avg Incumbent %`
FROM `table_1_1342198_6` `t`
WHERE `t`.`Party` IS NOT NULL AND `t`.`Party` <> ''
GROUP BY `t`.`Party`
HAVING `Contested Seats`>0 AND `Unopposed Seats`>=0
ORDER BY `Avg Incumbent %` DESC
LIMIT 10;
","
SELECT `t`.col2, COUNT(*) `Total Seats`,
       SUM(`t`.col5 LIKE '%Unopposed%') `Unopposed Seats`,
       SUM(NOT(`t`.col5 LIKE '%Unopposed%')) `Contested Seats`,
       ROUND(AVG((TRIM(SUBSTR(
         `t`.col5,
         INSTR(`t`.col5, '(' || SUBSTR(`t`.col2,1,1) || ')') + 4,
         INSTR(SUBSTR(`t`.col5, INSTR(`t`.col5, '(' || SUBSTR(`t`.col2,1,1) || ')') + 4), '%') - 1
       )) + 0.0)),2) `Avg Incumbent %`
FROM `table_1_1342198_6` `t`
WHERE `t`.col2 IS NOT NULL AND `t`.col2 <> ''
GROUP BY `t`.col2
HAVING `Contested Seats`>0 AND `Unopposed Seats`>=0
ORDER BY `Avg Incumbent %` DESC
LIMIT 10;
","[('republican', 2, 1, 1, 27.0), ('democratic', 6, 4, 2, 16.42)]",table_1_1342198_6,"STEP 1: Parse the SQL intent: the query groups rows by Party, counts total seats, counts Unopposed Seats via Candidates LIKE '%Unopposed%', counts Contested Seats as NOT LIKE '%Unopposed%', extracts the incumbent's percentage from the Candidates text (looking for the party initial like '(R)') and computes the average of those percentages per party, filters out empty parties and requires Contested Seats>0, then orders parties by that average descending and returns the top 10. STEP 2: Determine ambiguity type: Scope ambiguity fits well because the phrase “average incumbent percentage” can be read as an average over different scopes (e.g., only contested seats vs. all seats vs. seats with incumbents), and the SQL specifically averages parsed percentages (effectively only where a percent exists) and excludes parties with no contested seats. STEP 3: Draft the question: ""Which parties have the highest average incumbent vote share?"" STEP 4: Explain the ambiguity: the original query interprets this as the mean of incumbents' reported vote percentages parsed from the Candidates text for each party (effectively averaging over contested races and excluding parties with zero contested seats), whereas a reader might instead mean the average across all that party's seats (counting unopposed seats somehow), the average including or excluding certain years/incumbents, or even the single party with the top incumbent rather than a per-party average ranking.",reserved,14,reward,,"type: Scope ambiguity | explanation: The SQL treats the average as the mean of parsed incumbent percentages (effectively only where percent values appear — i.e., contested races — and excludes parties with zero contested seats), but the phrase could also mean averaging across all seats including unopposed ones (or treating unopposed seats differently), or could be interpreted as asking for the single top party rather than a per-party average ranking."
"For each Party, what is the total number of seats (count of rows), the number of contested seats (count of rows where the Candidates field does not contain the text 'Unopposed'), and the average winner percentage across those contested races computed by extracting the 6-character substring starting two characters after the first ')' in Candidates, removing the '%' and treating it as a numeric value, then averaging those numbers and rounding to one decimal, considering only entries with First elected between 1900 and 1948 inclusive; group the results by Party, order them by the contested-seat count descending, and return the top 10 parties?","
SELECT `Party`, count(*) `total_seats`, sum(instr(`Candidates`,'Unopposed')=0) `contested_count`, round( sum(replace(substr(`Candidates`, instr(`Candidates`,')')+2, 6), '%','')+0) / NULLIF(sum(instr(`Candidates`,'Unopposed')=0),0) ,1) `avg_winner_pct`
FROM `table_1_1342218_43`
WHERE `First elected` >= 1900 AND `First elected` <= 1948
GROUP BY `Party`
ORDER BY `contested_count` DESC
LIMIT 10;
","
SELECT col2, count(*) `total_seats`, sum(instr(col5,'Unopposed')=0) `contested_count`, round( sum(replace(substr(col5, instr(col5,')')+2, 6), '%','')+0) / NULLIF(sum(instr(col5,'Unopposed')=0),0) ,1) `avg_winner_pct`
FROM `table_1_1342218_43`
WHERE col3 >= 1900 AND col3 <= 1948
GROUP BY col2
ORDER BY `contested_count` DESC
LIMIT 10;
","[('democratic', 11, 11, 23.4)]",table_1_1342218_43,"1) Parse intent: compute per-party aggregates: total seats, number of contested seats, and average winner percentage parsed from the Candidates text; 2) Map schema: use Party, Candidates, and First elected columns and consider 'Unopposed' presence and percentage substring after the first ')'; 3) Draft: ask for Party, total count, contested count (Candidates does not contain 'Unopposed'), and average of extracted winner percentages rounded to 1 decimal for rows with First elected between 1900 and 1948; 4) Validate: group by Party, order by contested count descending, limit to top 10.",reserved,9,reward,,
"Provide a tidy list of Arkansas districts showing District, Incumbent, Party, First elected, Result, and Candidates, include an Uncontested flag for rows with ""Unopposed"", compute incumbent tenure as 1948 minus First elected, label continuity as Re-elected / Retired hold / Hold, and include per-party and total counts of unopposed and retired seats.","
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Uncontested_flag`,
  (1948 - `First elected`) AS `Incumbent_tenure_years`,
  CASE
    WHEN `Result` LIKE '%Re-elected%' THEN 'Re-elected'
    WHEN `Result` LIKE '%Retired%' AND `Result` LIKE '%hold%' THEN 'Retired hold'
    WHEN `Result` LIKE '%hold%' THEN 'Hold (continuity)'
    ELSE `Result`
  END AS `Continuity_category`,
  SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END) OVER (PARTITION BY `Party`) AS `Unopposed_by_party`,
  SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END) OVER () AS `Total_unopposed`,
  SUM(CASE WHEN `Result` LIKE '%Retired%' THEN 1 ELSE 0 END) OVER (PARTITION BY `Party`) AS `Retired_by_party`,
  SUM(CASE WHEN `Result` LIKE '%Retired%' THEN 1 ELSE 0 END) OVER () AS `Total_retired`
FROM `table_1_1342218_5`
WHERE `District` LIKE 'Arkansas %'
ORDER BY `Uncontested_flag` DESC, `Party`, `First elected`;
","
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Uncontested_flag`,
  (1948 - col3) AS `Incumbent_tenure_years`,
  CASE
    WHEN col4 LIKE '%Re-elected%' THEN 'Re-elected'
    WHEN col4 LIKE '%Retired%' AND col4 LIKE '%hold%' THEN 'Retired hold'
    WHEN col4 LIKE '%hold%' THEN 'Hold (continuity)'
    ELSE col4
  END AS `Continuity_category`,
  SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END) OVER (PARTITION BY col2) AS `Unopposed_by_party`,
  SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END) OVER () AS `Total_unopposed`,
  SUM(CASE WHEN col4 LIKE '%Retired%' THEN 1 ELSE 0 END) OVER (PARTITION BY col2) AS `Retired_by_party`,
  SUM(CASE WHEN col4 LIKE '%Retired%' THEN 1 ELSE 0 END) OVER () AS `Total_retired`
FROM `table_1_1342218_5`
WHERE col0 LIKE 'Arkansas %'
ORDER BY `Uncontested_flag` DESC, col2, col3;
","[('arkansas 1', 'ezekiel c. gathings', 'democratic', 1938.0, 're-elected', 'ezekiel c. gathings (d) unopposed', 1, 10.0, 'Re-elected', 6, 6, 1, 1), ('arkansas 2', 'wilbur mills', 'democratic', 1938.0, 're-elected', 'wilbur mills (d) unopposed', 1, 10.0, 'Re-elected', 6, 6, 1, 1), ('arkansas 6', 'william f. norrell', 'democratic', 1938.0, 're-elected', 'william f. norrell (d) unopposed', 1, 10.0, 'Re-elected', 6, 6, 1, 1), ('arkansas 4', 'william fadjo cravens', 'democratic', 1939.0, 'retired democratic hold', 'boyd anderson tackett (d) unopposed', 1, 9.0, 'Retired hold', 6, 6, 1, 1), ('arkansas 5', 'brooks hays', 'democratic', 1942.0, 're-elected', 'brooks hays (d) unopposed', 1, 6.0, 'Re-elected', 6, 6, 1, 1), ('arkansas 3', 'james william trimble', 'democratic', 1944.0, 're-elected', 'james william trimble (d) unopposed', 1, 4.0, 'Re-elected', 6, 6, 1, 1)]",table_1_1342218_5,"As a mapmaker I prefer concise ledgers, so my phrasing will be tidy and craft-like but nontechnical. The SQL builds per-row flags and derived labels and also computes windowed sums partitioned by party and overall. It uses the 'Candidates' text to detect 'Unopposed', 'Result' to determine continuity, and 'First elected' to compute tenure against 1948. Draft question: Provide a tidy list of Arkansas districts with those columns, an Uncontested flag, tenure in years, a continuity label, and per-party and total unopposed and retired counts. Validate: The question mirrors the exact columns and derived metrics the query produces without adding extra requirements.",persona,"A political textile cartographer — an artisan who designs historically-accurate quilted maps that encode 1948 House election outcomes into stitch patterns and color blocks. Goals: Identify which Arkansas congressional districts in 1948 were uncontested so I can use a single-color block (no border) for those panels. Map incumbent longevity and party continuity (e.g., first-elected year and whether they were re-elected or seats changed) to decide stitch complexity and pattern repetition. Quantify and compare uncontested seats by party and flag any non-standard results (e.g., 'Retired Democratic hold') to add special embellishments. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Candidates FROM table_1_1342218_5 WHERE Candidates LIKE '%Unopposed%'; SELECT District, Incumbent, Party, ""First elected"", Result FROM table_1_1342218_5 WHERE ""First elected"" < 1940 AND (Result LIKE '%Re-elected%' OR Candidates LIKE '%Unopposed%'); SELECT Party, COUNT(*) AS unopposed_count, SUM(CASE WHEN Result LIKE '%Retired%' THEN 1 ELSE 0 END) AS retired_seats FROM table_1_1342218_5 WHERE Candidates LIKE '%Unopposed%' GROUP BY Party;",reward,,
"For each Party among entries with District starting with 'California' and First elected prior to 1950, report the Party, the total count of entries (COUNT(*)), and the Contested Seats value defined as COUNT(*) minus the number of entries whose Candidates include 'Unopposed'; include only parties with COUNT(*) > 0, sort by Contested Seats ascending and return up to 5 rows?","
SELECT DISTINCT `Party`, COUNT(*) , COUNT(*) - SUM(`Candidates` LIKE '%Unopposed%') AS `Contested Seats`
FROM `table_1_1342218_6`
WHERE SUBSTR(`District`,1,9) = 'California' AND `First elected` < 1950
GROUP BY `Party`
HAVING COUNT(*) > 0
ORDER BY `Contested Seats`
LIMIT 5;
","SELECT DISTINCT col2, COUNT(*) AS `Total`, COUNT(*) - SUM(col5 LIKE '%Unopposed%') AS `Contested Seats`
FROM `table_1_1342218_6`
WHERE col0 LIKE 'California %' AND col3 < 1950
GROUP BY col2
HAVING COUNT(*) > 0
ORDER BY `Contested Seats`
LIMIT 5;","[('democratic', 3, 0), ('republican', 2, 1)]",table_1_1342218_6,"1) Parse the SQL intent: group by Party for California districts elected before 1950, count rows per party and calculate contested seats by subtracting unopposed races, then sort and limit. 2) Map schema semantics: District prefix 'California', numeric First elected < 1950, Candidates text contains 'Unopposed' indicates unopposed; output Party, COUNT(*), and Contested Seats. 3) Draft the question. 4) Validate that all SQL elements—filters, aggregation, calculation, having, ordering, and LIMIT—are represented.",reserved,12,reward,,
"By party, can you summarize how many Texas districts are in the dataset, how many were unopposed vs contested (and list those districts), how many contested races look potentially competitive (i.e., a recorded opponent % and the winner ≤90%), the average first‑elected year, and which incumbents were first elected before 1940 with their year?","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    CASE WHEN instr(`Candidates`, 'Unopposed') > 0 THEN 1 ELSE 0 END AS `is_unopposed`,
    CASE WHEN instr(`Candidates`, '%') > 0
         THEN trim(
                substr(
                  `Candidates`,
                  instr(`Candidates`, ')') + 2,
                  instr(`Candidates`, '%') - (instr(`Candidates`, ')') + 2)
                )
              )
         ELSE NULL
    END AS `first_pct_text`,
    CASE WHEN instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0 THEN 1 ELSE 0 END AS `has_second_pct`
  FROM `table_1_1342233_43`
),
parsed_num AS (
  SELECT
    *,
    CASE WHEN `first_pct_text` IS NOT NULL THEN CAST(`first_pct_text` AS REAL) ELSE NULL END AS `first_pct`
  FROM parsed
)
SELECT
  `Party`,
  COUNT(*) AS `district_count`,
  SUM(`is_unopposed`) AS `unopposed_districts`,
  COUNT(CASE WHEN `is_unopposed` = 0 THEN 1 END) AS `contested_districts`,
  SUM(CASE WHEN `is_unopposed` = 0 AND `has_second_pct` = 1 AND `first_pct` IS NOT NULL AND `first_pct` <= 90 THEN 1 ELSE 0 END) AS `potentially_competitive_districts`,
  ROUND(AVG(`First elected`),2) AS `avg_first_elected`,
  group_concat(CASE WHEN `First elected` < 1940 THEN '`' || `Incumbent` || '` (`' || `First elected` || '`)' END, '; ') AS `long_serving_incumbents`,
  group_concat(CASE WHEN `is_unopposed` = 0 THEN '`' || `District` || '`' END, '; ') AS `contested_district_list`,
  group_concat(CASE WHEN `is_unopposed` = 1 THEN '`' || `District` || '`' END, '; ') AS `unopposed_district_list`
FROM parsed_num
GROUP BY `Party`
ORDER BY `district_count` DESC;
","WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    CASE WHEN instr(col5, '%') > 0
         THEN trim(
                substr(
                  col5,
                  instr(col5, ')') + 2,
                  instr(col5, '%') - (instr(col5, ')') + 2)
                )
              )
         ELSE NULL
    END AS `first_pct_text`,
    CASE WHEN instr(substr(col5, instr(col5, '%') + 1), '%') > 0 THEN 1 ELSE 0 END AS `has_second_pct`
  FROM `table_1_1342233_43`
)
SELECT
  col2,
  COUNT(*) AS `district_count`,
  SUM(CASE WHEN instr(col5, 'Unopposed') > 0 THEN 1 ELSE 0 END) AS `unopposed_districts`,
  SUM(CASE WHEN instr(col5, 'Unopposed') = 0 THEN 1 ELSE 0 END) AS `contested_districts`,
  SUM(
    CASE
      WHEN instr(col5, 'Unopposed') = 0
       AND `has_second_pct` = 1
       AND `first_pct_text` IS NOT NULL
       AND CAST(`first_pct_text` AS REAL) <= 90
      THEN 1 ELSE 0 END
  ) AS `potentially_competitive_districts`,
  ROUND(AVG(col3),2) AS `avg_first_elected`,
  group_concat(CASE WHEN col3 < 1940 THEN '`' || col1 || '` (`' || col3 || '`)' END, '; ') AS `long_serving_incumbents`,
  group_concat(CASE WHEN instr(col5, 'Unopposed') = 0 THEN '`' || col0 || '`' END, '; ') AS `contested_district_list`,
  group_concat(CASE WHEN instr(col5, 'Unopposed') > 0 THEN '`' || col0 || '`' END, '; ') AS `unopposed_district_list`
FROM parsed
GROUP BY col2
ORDER BY `district_count` DESC;","[('democratic', 15, 0, 15, 1, 1934.53, '`wright patman` (`1928.0`); `lindley beckworth` (`1938.0`); `sam rayburn` (`1912.0`); `joseph j. mansfield` (`1916.0`); `lyndon b. johnson` (`1937.0`); `william r. poage` (`1936.0`); `ed gossett` (`1938.0`); `milton h. west` (`1933.0`); `r. ewing thomason` (`1930.0`); `paul j. kilday` (`1938.0`)', '`texas 1`; `texas 2`; `texas 3`; `texas 4`; `texas 7`; `texas 9`; `texas 10`; `texas 11`; `texas 13`; `texas 14`; `texas 15`; `texas 16`; `texas 17`; `texas 18`; `texas 20`', None)]",table_1_1342233_43,"The researcher knows mid‑20th Texas politics and will refer to party, incumbents and election years but won't use raw SQL syntax. They likely recognize columns like District, Incumbent, Party, First elected and Candidates. The query groups rows by Party and computes totals, unopposed vs contested counts, flags potentially competitive contests, averages first‑elected year, and gathers lists of long‑serving incumbents and contested/unopposed districts. Map: District/Incumbent/Party/First elected/Candidates are used to derive those aggregates and lists. Draft question: For each party, what are the number of districts, how many were unopposed versus contested, which districts were contested or unopposed, how many contests are potentially competitive (contested with an opponent % and the winner ≤90%), what is the average first‑elected year, and which incumbents were first elected before 1940 (with year)? Validate: This asks exactly for the per‑party counts, competitive flags, averages and lists that the query returns.",persona,"A historical political researcher specializing in mid-20th century Southern politics, using the dataset to study Texas congressional outcomes and party dominance during that period. Goals: Assess party composition and dominance across Texas congressional districts in the dataset. Identify long-serving incumbents and patterns of incumbency (e.g., first-elected year, re-elections, retirements). Detect which districts were unopposed versus contested and flag potentially competitive races for deeper qualitative follow-up. Example Queries: SELECT Party, COUNT(*) AS district_count FROM table_1_1342233_43 GROUP BY Party; SELECT District, Incumbent, `First elected`, Result FROM table_1_1342233_43 WHERE `First elected` < 1940 ORDER BY `First elected` ASC; SELECT District, Incumbent, Party, Candidates FROM table_1_1342233_43 WHERE Candidates LIKE '%Unopposed%' ORDER BY District;",reward,,
"For each Party, compute Outcome from Result ('Lost re-election Democratic gain' => 'Flip', 'Re-elected' => 'Hold', otherwise 'Other') and report Party, Outcome, the COUNT(*) as Count, and AVG(First elected) as AvgFirstElected, grouping by Party and Outcome, ordered by Count descending and limited to 10 rows.","
SELECT DISTINCT `Party` `Party`,
  CASE WHEN `Result` = v.`Lost re-election Democratic gain` THEN 'Flip' WHEN `Result` = v.`Re-elected` THEN 'Hold' ELSE 'Other' END AS `Outcome`,
  COUNT(*) AS `Count`,
  AVG(`First elected`) AS `AvgFirstElected`
FROM `table_1_1342249_13`,
     (VALUES ('Re-elected', 'Lost re-election Democratic gain')) v(`Re-elected`, `Lost re-election Democratic gain`)
GROUP BY `Party`, `Outcome`
ORDER BY `Count` DESC
LIMIT 10;
","SELECT col2,
  CASE col4 WHEN 'Re-elected' THEN 'Hold' WHEN 'Lost re-election Democratic gain' THEN 'Flip' ELSE 'Other' END AS `Outcome`,
  COUNT(*) AS `Count`
FROM `table_1_1342249_13`
GROUP BY col2, `Outcome`
ORDER BY `Count` DESC
LIMIT 10;","[('republican', 'Other', 7), ('democratic', 'Other', 2)]",table_1_1342249_13,"1) The intent is to produce aggregated stats per Party and a CASE-derived Outcome based on Result, count rows and average First elected, then sort and limit. 2) Use Party, Result, and First elected columns to form the outputs and aggregations. 3) Write a question requesting Party, the Outcome mapping ('Lost re-election Democratic gain' -> 'Flip', 'Re-elected' -> 'Hold', else 'Other'), COUNT(*) as Count, and AVG(First elected) as AvgFirstElected, grouped by Party and Outcome. 4) Confirm inclusion of ORDER BY Count DESC and LIMIT 10.",reserved,18,reward,,
"Give me every 1944 Louisiana House district with its incumbent and party, the year they were first elected, years in office as of 1944, whether they were unopposed, the defensive strength score (2.5×years in office plus 15 if unopposed), and the party-level counts and percent of unopposed seats.","
WITH `metrics` AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    (1944 - `First elected`) AS `years_in_office`,
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `uncontested`,
    ROUND((1944 - `First elected`) * 2.5 + CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 15 ELSE 0 END, 1) AS `defensive_strength`
  FROM `table_1_1342249_18`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `years_in_office`,
  `uncontested`,
  `defensive_strength`,
  SUM(`uncontested`) OVER (PARTITION BY `Party`) AS `party_unopposed_seats`,
  COUNT(*) OVER (PARTITION BY `Party`) AS `party_total_seats`,
  ROUND(100.0 * SUM(`uncontested`) OVER (PARTITION BY `Party`) / COUNT(*) OVER (PARTITION BY `Party`), 1) AS `party_unopposed_pct`
FROM `metrics`
ORDER BY `uncontested` DESC, `years_in_office` DESC;
","
WITH `metrics` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    (1944 - col3) AS `years_in_office`,
    CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `uncontested`,
    ROUND((1944 - col3) * 2.5 + CASE WHEN col5 LIKE '%Unopposed%' THEN 15 ELSE 0 END, 1) AS `defensive_strength`
  FROM `table_1_1342249_18`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  `years_in_office`,
  `uncontested`,
  `defensive_strength`,
  SUM(`uncontested`) OVER (PARTITION BY col2) AS `party_unopposed_seats`,
  COUNT(*) OVER (PARTITION BY col2) AS `party_total_seats`,
  ROUND(100.0 * SUM(`uncontested`) OVER (PARTITION BY col2) / COUNT(*) OVER (PARTITION BY col2), 1) AS `party_unopposed_pct`
FROM `metrics`
ORDER BY `uncontested` DESC, `years_in_office` DESC;
","[('louisiana 4', 'overton brooks', 'democratic', 1936.0, 8.0, 1, 35.0, 7, 7, 100.0), ('louisiana 1', 'f. edward hebert', 'democratic', 1940.0, 4.0, 1, 25.0, 7, 7, 100.0), ('louisiana 3', 'james r. domengeaux', 'democratic', 1940.0, 4.0, 1, 25.0, 7, 7, 100.0), ('louisiana 2', 'paul h. maloney', 'democratic', 1942.0, 2.0, 1, 20.0, 7, 7, 100.0), ('louisiana 5', 'charles e. mckenzie', 'democratic', 1942.0, 2.0, 1, 20.0, 7, 7, 100.0), ('louisiana 6', 'james h. morrison', 'democratic', 1942.0, 2.0, 1, 20.0, 7, 7, 100.0), ('louisiana 7', 'henry d. larcade, jr.', 'democratic', 1942.0, 2.0, 1, 20.0, 7, 7, 100.0)]",table_1_1342249_18,"I'm a boardgame designer so I'd talk about 'safe seats' and defensive scores rather than raw SQL, using incumbent, party and unopposed language; I won't assume exact column names. The SQL computes years in office, flags unopposed races, computes a defensive strength, and adds party-level unopposed counts and percentages. It reads District, Incumbent, Party, First elected and Candidates and derives years_in_office, uncontested and defensive_strength, plus SUM/COUNT per Party. Draft the question to request each 1944 Louisiana district with incumbent, party, first-elected year, years in office (to 1944), whether unopposed, the defensive strength (2.5×years +15 if unopposed), and party totals and percent unopposed. This stays within what the query returns and doesn't invent extra fields.",persona,"An alternate-history boardgame designer who models 1944 Louisiana House races to build balanced wartime political scenarios by quantifying 'safe' seats and incumbency strength. Goals: Identify which Louisiana congressional districts in 1944 were uncontested to classify them as 'safe' seats for gameplay. Measure incumbency tenure as of the 1944 election (years since first elected) to assign defensive strength values to each incumbent. Summarize party dominance and the number of unopposed seats by party to calibrate starting conditions and victory point allocation. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1342249_18
WHERE Candidates LIKE '%Unopposed%'; SELECT Incumbent, District, ""First elected"", (1944 - ""First elected"") AS years_in_office
FROM table_1_1342249_18
ORDER BY years_in_office DESC; SELECT Party,
       COUNT(*) AS total_seats,
       SUM(CASE WHEN Candidates LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS unopposed_seats
FROM table_1_1342249_18
GROUP BY Party;",reward,,
"For each distinct Party (with the filter Party = 'Democratic' OR Party = 'Democratic') among records whose First elected value is 1936 or 1940, what are the Party name, the Total Seats (COUNT(*) for that Party), and the Unopposed Seats (SUM of 1 when Candidates LIKE '%Unopposed%' else 0), grouped by Party, only including groups with COUNT(*) > 0 and limited to 10 rows?","
SELECT DISTINCT `Party`,
       COUNT(*) AS `Total Seats`,
       SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END) `Unopposed Seats`
FROM `table_1_1342256_18`
WHERE `First elected` IN (1936,1940) AND (`Party` = 'Democratic' OR `Party` = 'Democratic')
GROUP BY `Party`
HAVING COUNT(*)>0
LIMIT 10;
","SELECT col2, COUNT(*) AS `Total Seats`, SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END) `Unopposed Seats`
FROM `table_1_1342256_18`
GROUP BY col2
HAVING COUNT(*)>0
ORDER BY `Total Seats`
LIMIT 10;","[('democratic', 7, 7)]",table_1_1342256_18,"1) Parse intent: retrieve per-party totals and count unopposed races for entries first elected in 1936 or 1940, limited to the Democratic party condition. 2) Map schema: Party, First elected, Candidates; compute Total Seats via COUNT(*) and Unopposed Seats via SUM of a LIKE '%Unopposed%' case. 3) Draft question including DISTINCT Party, grouping, HAVING COUNT(*)>0 and LIMIT 10. 4) Validate inclusion of all calculations and filters.",reserved,18,reward,,
"For Parties other than 'None (District created)', among rows with Result = 'Re-elected', what is each Party's name, the total seats (COUNT(*) as Total Seats), how many of those seats have Candidates containing the string 'Unopposed' (reported as 'Harry Lane Englebright (R) Unopposed'), and how many Contested Seats there are computed as Total Seats minus that Unopposed count, limited to 10 Parties?","
SELECT DISTINCT `Party`, COUNT(*) `Total Seats`, SUM(INSTR(`Candidates`, 'Unopposed')>0) AS `Harry Lane Englebright (R) Unopposed`, COUNT(*) - SUM(INSTR(`Candidates`, 'Unopposed')>0) `Contested Seats` FROM `table_1_1342256_6` WHERE `Party` != 'None (District created)' AND `Result` = 'Re-elected' GROUP BY `Party` LIMIT 10;
","SELECT DISTINCT col2, COUNT(*) AS `Total Seats` FROM `table_1_1342256_6` WHERE col2 != 'None (District created)' GROUP BY col2 LIMIT 10;","[('democratic', 3), ('none (district created)', 1), ('republican', 3)]",table_1_1342256_6,"1) Parse intent: calculate per-Party totals and split unopposed vs contested for re-elected incumbents while excluding created-district placeholder Party. 2) Map schema: use Party and Result filters, detect 'Unopposed' via Candidates text search, compute totals and difference. 3) Draft: request Party, Total Seats, number of 'Unopposed' seats with the given alias, and Contested Seats = Total - Unopposed. 4) Validate: confirm exclusion of Party = 'None (District created)', filter Result = 'Re-elected', group by Party and limit to 10.",reserved,9,reward,,
"List the top 5 Result categories (ordered by descending Count) for rows where First elected < 1930, and for each Result provide: the Count of records, the COUNT(DISTINCT District) as DistinctDistricts, the District names concatenated with '; ' as Districts, and the average First elected rounded to one decimal (AvgFirstElected); include only groups with at least one record.","
SELECT `Result`, COUNT(*) `Count`, COUNT(DISTINCT `District`) `DistinctDistricts`, GROUP_CONCAT(`District`, '; ') `Districts`, ROUND(AVG(`First elected`),1) `AvgFirstElected`
FROM `table_1_1342270_43`
WHERE `First elected` < 1930
GROUP BY `Result`
HAVING COUNT(*)>0
ORDER BY `Count` DESC
LIMIT 5;
","
SELECT col4, COUNT(*) `Count`, COUNT(DISTINCT col0) `DistinctDistricts`, GROUP_CONCAT(col0, '; ') `Districts`, ROUND(AVG(col3),1) `AvgFirstElected`
FROM `table_1_1342270_43`
WHERE col3 < 1930
GROUP BY col4
HAVING COUNT(*)>0
ORDER BY `Count` DESC
LIMIT 5;
","[('re-elected', 5, 5, 'texas 1; texas 4; texas 6; texas 9; texas 12', 1919.4)]",table_1_1342270_43,"1) Parse: filter rows by First elected < 1930, group by Result, compute count, distinct district count, concatenated district names with '; ', and rounded average first elected, then sort by count desc and limit 5. 2) Map: use table columns Result, District and First elected for these calculations. 3) Draft: phrase a question requesting the top 5 Result groups by record count with those specific aggregates. 4) Validate: confirm the question mentions the COUNT>0 HAVING clause, ordering and rounding.",reserved,10,reward,,
Which party had the most unopposed seats?,"
SELECT
  `Party`,
  COUNT(*) AS `total_seats`,
  SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `unopposed_seats`,
  AVG(`First elected`) AS `avg_first_elected_year`,
  GROUP_CONCAT(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN `District` END, '; ') AS `safe_seats_list`,
  GROUP_CONCAT(
    CASE
      WHEN (length(`Candidates`) - length(replace(`Candidates`, '%', ''))) >= 2
        AND ABS(
          CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 1) AS REAL) -
          CAST(REGEXP_SUBSTR(`Candidates`, '([0-9]+\\.[0-9]+)%', 1, 2) AS REAL)
        ) < 10
      THEN `District`
    END, '; '
  ) AS `close_seats_list`,
  GROUP_CONCAT(CASE WHEN `First elected` <= 1920 THEN `Incumbent` || ' (' || `First elected` || ')' END, '; ') AS `entrenched_incumbents`
FROM `table_1_1342292_2`
GROUP BY `Party`
ORDER BY `unopposed_seats` DESC, `total_seats` DESC;
","SELECT
  col2,
  COUNT(*) AS `total_seats`,
  SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `unopposed_seats`,
  AVG(col3) AS `avg_first_elected_year`,
  GROUP_CONCAT(CASE WHEN col5 LIKE '%Unopposed%' THEN col0 END, '; ') AS `safe_seats_list`,
  GROUP_CONCAT(CASE WHEN col3 <= 1920 THEN col1 || ' (' || col3 || ')' END, '; ') AS `entrenched_incumbents`
FROM `table_1_1342292_2`
GROUP BY col2
ORDER BY `unopposed_seats` DESC, `total_seats` DESC;","[('democratic', 8, 5, 1930.375, 'alabama 1; alabama 2; alabama 3; alabama 6; alabama 8', 'henry b. steagall (1914.0); william b. bankhead (1916.0)')]",table_1_1342292_2,"STEP 1: Parse the SQL intent: group rows by Party and for each party compute total seats (COUNT), number of unopposed seats (COUNT via LIKE '%Unopposed%'), average first-elected year, lists of districts that are unopposed (safe_seats_list), lists of close contests (close_seats_list), and entrenched incumbents (first elected <= 1920); results are ordered by unopposed_seats desc then total_seats desc. STEP 2: Choose an ambiguity type: scope ambiguity fits well because the SQL returns a per-party summary for all parties sorted by unopposed seats, so a short NL question asking ‘which party had the most unopposed seats’ can be read as either requesting the single top party or requesting the per-party counts/ranking shown by the query. STEP 3: Draft the question: ""Which party had the most unopposed seats?"" STEP 4: Explain the ambiguity: in the original query the output is a list of parties with unopposed counts (so it supports the interpretation of listing/ranking every party), but the NL question can also be interpreted as asking only for the single party with the maximum unopposed seats (which would require selecting the top row only).",persona,"An alternate-history board-game designer who builds plausible 1938 U.S. House scenarios and needs real-district vulnerabilities and stable strongholds to design balanced plays. Goals: Identify districts that were uncontested in 1938 to create 'safe-seat' cards and rare-event tokens. Find narrowly decided or low-margin races to design high-tension battleground scenarios and upset mechanics. Profile long-serving incumbents and party strongholds to seed entrenched power mechanics and bonus rules for legacy politicians. Produce party-level summaries (seat counts, number of unopposed seats, average seniority) to balance starting conditions for different factions in the game. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Candidates
FROM table_1_1342292_2
WHERE Candidates LIKE '%Unopposed%'
ORDER BY ""First elected"" ASC; SELECT District, Incumbent, Party, Candidates,
       ABS(
         CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 1) AS REAL) -
         CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 2) AS REAL)
       ) AS margin
FROM table_1_1342292_2
WHERE Candidates REGEXP '[0-9]+\.[0-9]+%'
-- return districts where the vote-margin between top two listed percentages is under 10%
HAVING margin < 10
ORDER BY margin ASC; SELECT Party,
       COUNT(*) AS total_seats,
       SUM(CASE WHEN Candidates LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS unopposed_seats,
       AVG(""First elected"") AS avg_first_elected_year
FROM table_1_1342292_2
GROUP BY Party
ORDER BY unopposed_seats DESC, total_seats DESC;",reward,,"type: Scope ambiguity | explanation: The question can mean (a) return the single party that had the highest number of unopposed seats, or (b) return the counts (or a ranking) of unopposed seats for every party; the provided SQL produces a per-party ranking (interpretation b) but could be rephrased/rewritten to return only the top party (interpretation a)."
"Which three Parties (ordered by Total) have the following metrics for rows with First elected >= 1928: Total (COUNT(*) per Party), Re-elected (number of rows where Result contains 'Re-elected'), and Unopposed (number of rows where Candidates contains 'Unopposed'), grouping results by Party and limiting to 3 rows?","
SELECT `Party`, COUNT(*) AS `Total`, SUM(INSTR(`Result`, 'Re-elected')>0) `Re-elected`, SUM(INSTR(`Candidates`, 'Unopposed')>0) `Unopposed` FROM `table_1_1342292_4` WHERE `First elected` >= 1928 GROUP BY `Party` ORDER BY `Total` LIMIT 3;
","
SELECT col2, COUNT(*) AS `Total`, SUM(INSTR(col4, 'Re-elected')>0) `Re-elected`, SUM(INSTR(col5, 'Unopposed')>0) `Unopposed` FROM `table_1_1342292_4` WHERE col3 >= 1928 GROUP BY col2 ORDER BY `Total` LIMIT 3;
","[('democratic', 4, 0, 0)]",table_1_1342292_4,"1) The SQL selects Party and three aggregates with a First elected >= 1928 filter, groups by Party, orders by the aggregate Total, and limits output to 3. 2) Translate SQL terms to plain language: Total = COUNT(*), Re-elected = SUM of Result containing 'Re-elected', Unopposed = SUM of Candidates containing 'Unopposed'. 3) Pose a question that requests these exact metrics per Party with the specified filter, grouping, ordering, and limit. 4) Confirm that the question contains all columns, calculations, filter, grouping, order, and limit from the query and nothing extra.",reserved,8,reward,,
"For each non-empty Party, list Party; the Total seats (COUNT of rows for that Party); the Average tenure calculated as ROUND(AVG(1938 - `First elected`), 2); the Re-elected count (SUM where `Result` = 'Re-elected'); and the Unopposed count (SUM where `Candidates` contains 'Unopposed' using INSTR), only for parties with COUNT(*) > 0 and with SUM(INSTR(`Candidates`, 'Unopposed') > 0) >= 0, and order the output by Average tenure in descending order?","
SELECT `Party`,
COUNT(*) AS `Total seats`,
ROUND(AVG(1938 - `First elected`),2) `Average tenure`,
SUM(`Result` = TRIM('`Re-elected`','`')) `Re-elected count`,
SUM((INSTR(`Candidates`, TRIM('`Unopposed`','`')) > 0)) `Unopposed count`
FROM `table_1_1342292_45`
WHERE `Party` <> ''
GROUP BY `Party`
HAVING COUNT(*) > 0 AND SUM((INSTR(`Candidates`, TRIM('`Unopposed`','`')) > 0)) >= 0
ORDER BY `Average tenure` DESC;
","
SELECT col2,
COUNT(*) AS `Total seats`,
ROUND(AVG(1938 - col3),2) `Average tenure`,
SUM(col4 = TRIM('`Re-elected`','`')) `Re-elected count`,
SUM((INSTR(col5, TRIM('`Unopposed`','`')) > 0)) `Unopposed count`
FROM `table_1_1342292_45`
WHERE col2 <> ''
GROUP BY col2
HAVING COUNT(*) > 0 AND SUM((INSTR(col5, TRIM('`Unopposed`','`')) > 0)) >= 0
ORDER BY `Average tenure` DESC;
","[('democratic', 5, 9.8, 0, 0)]",table_1_1342292_45,"1) Parse: The SQL returns Party-level aggregates: total seats, rounded average of (1938 - First elected), count of Result equal to 'Re-elected', and count of Candidates containing 'Unopposed', with Party non-empty, grouped by Party, having COUNT>0 and SUM(unopposed) >=0, ordered by average tenure desc. 2) Map: Use exact column names and calculations in plain language. 3) Draft: Ask for those metrics per Party with the same filters and ordering. 4) Validate: All computations, filters, grouping, HAVING, and ORDER BY are explicitly mentioned.",reserved,10,reward,,
"Give me a roster of the 1936 Georgia House districts showing district, incumbent, party, year first elected, years in office, whether they were unopposed, the candidates text and any winner/runner vote shares and margin, with unopposed long‑timers listed first?","
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  (1936 - `First elected`) AS `Years in office`,
  CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Uncontested`,
  `Candidates`,
  -- Winner_share: extract the first percentage that appears after the first ') ' (pattern in the contested row)
  CASE
    WHEN `Candidates` NOT LIKE '%Unopposed%' AND instr(`Candidates`, '%') > 0 AND instr(`Candidates`, ') ') > 0
    THEN CAST(replace(
           substr(
             `Candidates`,
             instr(`Candidates`, ') ') + 2,
             instr(`Candidates`, '%') - (instr(`Candidates`, ') ') + 2) + 1
           ),
         '%','') AS REAL)
    ELSE NULL
  END AS `Winner_share`,
  -- Runner_share: extract the second percentage by locating the second '%' after the first '%'
  CASE
    WHEN `Candidates` NOT LIKE '%Unopposed%' AND instr(`Candidates`, '%') > 0 AND instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') > 0
    THEN CAST(replace(
           substr(
             `Candidates`,
             instr(`Candidates`, '%') + instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ') + 2,
             (instr(`Candidates`, '%') + instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%'))
               - (instr(`Candidates`, '%') + instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ') + 2) + 1
           ),
         '%','') AS REAL)
    ELSE NULL
  END AS `Runner_share`,
  -- Margin (Winner_share - Runner_share) where both percents exist
  CASE
    WHEN
      `Candidates` NOT LIKE '%Unopposed%'
      AND instr(`Candidates`, '%') > 0
      AND instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') > 0
    THEN
      ( CAST(replace(
          substr(
            `Candidates`,
            instr(`Candidates`, ') ') + 2,
            instr(`Candidates`, '%') - (instr(`Candidates`, ') ') + 2) + 1
          ), '%','') AS REAL)
      -
        CAST(replace(
          substr(
            `Candidates`,
            instr(`Candidates`, '%') + instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ') + 2,
            (instr(`Candidates`, '%') + instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%'))
              - (instr(`Candidates`, '%') + instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ') + 2) + 1
          ), '%','') AS REAL)
      )
    ELSE NULL
  END AS `Margin`
FROM `table_1_1342315_10`
ORDER BY `Uncontested` DESC, `Years in office` DESC;
","
SELECT
  col0,
  col1,
  col2,
  col3,
  (1936 - col3) AS `Years in office`,
  CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Uncontested`,
  col5,
  -- Winner_share: extract the first percentage that appears after the first ') ' (pattern in the contested row)
  CASE
    WHEN col5 NOT LIKE '%Unopposed%' AND instr(col5, '%') > 0 AND instr(col5, ') ') > 0
    THEN CAST(replace(
           substr(
             col5,
             instr(col5, ') ') + 2,
             instr(col5, '%') - (instr(col5, ') ') + 2) + 1
           ),
         '%','') AS REAL)
    ELSE NULL
  END AS `Winner_share`,
  -- Runner_share: extract the second percentage by locating the second '%' after the first '%'
  CASE
    WHEN col5 NOT LIKE '%Unopposed%' AND instr(col5, '%') > 0 AND instr(substr(col5, instr(col5, '%')+1), '%') > 0
    THEN CAST(replace(
           substr(
             col5,
             instr(col5, '%') + instr(substr(col5, instr(col5, '%')+1), ') ') + 2,
             (instr(col5, '%') + instr(substr(col5, instr(col5, '%')+1), '%'))
               - (instr(col5, '%') + instr(substr(col5, instr(col5, '%')+1), ') ') + 2) + 1
           ),
         '%','') AS REAL)
    ELSE NULL
  END AS `Runner_share`,
  -- Margin (Winner_share - Runner_share) where both percents exist
  CASE
    WHEN
      col5 NOT LIKE '%Unopposed%'
      AND instr(col5, '%') > 0
      AND instr(substr(col5, instr(col5, '%')+1), '%') > 0
    THEN
      ( CAST(replace(
          substr(
            col5,
            instr(col5, ') ') + 2,
            instr(col5, '%') - (instr(col5, ') ') + 2) + 1
          ), '%','') AS REAL)
      -
        CAST(replace(
          substr(
            col5,
            instr(col5, '%') + instr(substr(col5, instr(col5, '%')+1), ') ') + 2,
            (instr(col5, '%') + instr(substr(col5, instr(col5, '%')+1), '%'))
              - (instr(col5, '%') + instr(substr(col5, instr(col5, '%')+1), ') ') + 2) + 1
          ), '%','') AS REAL)
      )
    ELSE NULL
  END AS `Margin`
FROM `table_1_1342315_10`
ORDER BY `Uncontested` DESC, `Years in office` DESC;
","[('georgia 6', 'carl vinson', 'democratic', 1914.0, 22.0, 1, 'carl vinson (d) unopposed', None, None, None), ('georgia 2', 'edward e. cox', 'democratic', 1924.0, 12.0, 1, 'edward e. cox (d) unopposed', None, None, None), ('georgia 3', 'bryant t. castellow', 'democratic', 1932.0, 4.0, 1, 'stephen pace (d) unopposed', None, None, None), ('georgia 4', 'emmett marshall owen', 'democratic', 1932.0, 4.0, 1, 'emmett marshall owen (d) unopposed', None, None, None), ('georgia 1', 'hugh peterson', 'democratic', 1934.0, 2.0, 1, 'hugh peterson (d) unopposed', None, None, None), ('georgia 8', 'braswell deen', 'democratic', 1932.0, 4.0, 0, 'braswell deen (d) 94.5% ben j. ford (r) 5.5%', 94.5, 5.5, 89.0)]",table_1_1342315_10,"I might also want a full roster ordered to highlight unopposed long‑timers first so I can choreograph scenes of one‑party dominance. The query selects district, incumbent, party, first elected, computed years in office, an Uncontested flag, the raw Candidates text, and extracted winner/runner shares and margin, then orders Uncontested first and by years in office. The table fields map directly to those items: District, Incumbent, Party, First elected and Candidates. Drafted question: request the full 1936 Georgia House roster with those fields and ordering to emphasize unopposed long‑time bosses first. Validation: the SQL returns all those columns and applies the stated ordering.",persona,"A living-history theater director who stages immersive 1936 Georgia political town-hall reenactments and needs historically accurate character briefs and scene beats. Goals: Identify which Georgia House races in 1936 were uncontested so scenes can portray one-party dominance or empty opposition. Find long-serving incumbents to build convincing character backstories, accents and mannerisms for recurring power figures. Locate the few contested races and extract vote shares/margins to script dramatic debate scenes and post-election press reactions. Example Queries: -- 1) List all districts that were unopposed and the incumbents to plan one-party-dominant scenes
    SELECT ""District"", ""Incumbent"", ""Party"", ""First elected""
    FROM ""table_1_1342315_10""
    WHERE ""Candidates"" LIKE '%Unopposed%'; -- 2) Find long-serving incumbents (elected in or before 1920) with their years in office (as of 1936) for casting/character age notes
    SELECT ""District"", ""Incumbent"", ""Party"", ""First elected"", (1936 - ""First elected"") AS ""Years_in_office""
    FROM ""table_1_1342315_10""
    WHERE ""First elected"" <= 1920
    ORDER BY ""First elected"" ASC; -- 3) Extract contested races and attempt to parse the leading candidate's reported percentage (Postgres regex example) to measure contest intensity
    SELECT ""District"",
           ""Incumbent"",
           ""Candidates"",
           -- extract the first percentage number that appears in the Candidates text as the winner_share
           (regexp_replace((regexp_matches(""Candidates"", '([0-9]+\.?[0-9]*)%'))[1], '%', ''))::numeric AS winner_share
    FROM ""table_1_1342315_10""
    WHERE ""Candidates"" NOT LIKE '%Unopposed%';",reward,,
How many 'Hugh Peterson (D) Unopposed' were there in each party by 1930?,"
SELECT `Party`, COUNT(*) AS `Hugh Peterson (D) Unopposed`
FROM `table_1_1342331_11`
WHERE `First elected` <= 1930
GROUP BY `Party`
HAVING COUNT(*) > 0
LIMIT 10;
","
SELECT col2, COUNT(*) AS `Hugh Peterson (D) Unopposed`
FROM `table_1_1342331_11`
WHERE col3 <= 1930
GROUP BY col2
HAVING COUNT(*) > 0
LIMIT 10;
","[('democratic', 5)]",table_1_1342331_11,"STEP 1: Parse the SQL intent: The query returns Party and a count of rows per Party for rows with `First elected` <= 1930 (GROUP BY Party, HAVING COUNT(*)>0). The COUNT(*) is aliased as 'Hugh Peterson (D) Unopposed'. STEP 2: Determine ambiguity type: Entity vagueness (the alias is a person/label, which can be read as referring to a specific candidate or merely as a column header summarizing counts). This fits because the SQL filter is about first-elected date but the alias/name suggests a specific candidate/status. STEP 3: Draft the question: ""How many 'Hugh Peterson (D) Unopposed' were there in each party by 1930?"" STEP 4: Explain the ambiguity: In the original query the phrase 'Hugh Peterson (D) Unopposed' is only a column label for the count of members first elected by 1930 grouped by party. Alternatively, a reader could interpret the question as asking about occurrences of the specific candidate label 'Hugh Peterson (D) Unopposed' (or whether Hugh Peterson was unopposed in particular parties), which would require filtering by the Candidates column or by the specific name/status in a different query.",reserved,8,reward,,type: Entity vagueness | explanation: The phrase 'Hugh Peterson (D) Unopposed' can be read as a literal candidate/status (asking how many times that specific label appears or in which parties that candidate was unopposed) or simply as a column header labeling counts of members first elected by 1930 by party; the SQL uses it only as an alias while a different query could filter for that candidate/status explicitly.
"For Louisiana's 1930 House elections, by party, what were each party's total seats, how many seats were unopposed versus contested, the percent unopposed, the average years in office of incumbents, and which districts (if any) saw incumbents lose renomination or be defeated?","
SELECT
  `Party`,
  COUNT(*) AS `seats_total`,
  SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `unopposed_seats`,
  SUM(CASE WHEN `Candidates` NOT LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `contested_seats`,
  ROUND(100.0 * SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1.0 ELSE 0.0 END) / COUNT(*), 1) AS `pct_unopposed`,
  ROUND(AVG(1930 - `First elected`), 1) AS `avg_years_in_office`,
  SUM(CASE WHEN `Result` LIKE '%Lost%' OR `Result` LIKE '%defeat%' THEN 1 ELSE 0 END) AS `turnover_count`,
  GROUP_CONCAT(CASE WHEN `Result` LIKE '%Lost%' OR `Result` LIKE '%defeat%' THEN `District` END, '; ') AS `turnover_districts`
FROM `table_1_1342359_17`
GROUP BY `Party`
ORDER BY `seats_total` DESC;
","
SELECT
  col2,
  COUNT(*) AS `seats_total`,
  SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `unopposed_seats`,
  SUM(CASE WHEN col5 NOT LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `contested_seats`,
  ROUND(100.0 * SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1.0 ELSE 0.0 END) / COUNT(*), 1) AS `pct_unopposed`,
  ROUND(AVG(1930 - col3), 1) AS `avg_years_in_office`,
  SUM(CASE WHEN col4 LIKE '%Lost%' OR col4 LIKE '%defeat%' THEN 1 ELSE 0 END) AS `turnover_count`,
  GROUP_CONCAT(CASE WHEN col4 LIKE '%Lost%' OR col4 LIKE '%defeat%' THEN col0 END, '; ') AS `turnover_districts`
FROM `table_1_1342359_17`
GROUP BY col2
ORDER BY `seats_total` DESC;
","[('democratic', 6, 5, 1, 83.3, 7.0, 1, 'louisiana 2')]",table_1_1342359_17,"As a political historian, I phrase questions in terms of party control and incumbency but avoid SQL jargon. The query aggregates by party to report totals, unopposed vs contested counts, percent unopposed, average tenure (using 1930 minus First elected), and turnover districts. It maps Party, Candidates (to detect 'Unopposed'), First elected (to compute years in office), Result (to detect 'Lost' or 'defeat'), and District (for listing turnovers). Draft question: For Louisiana's 1930 House elections, by party, what were each party's total seats, how many seats were unopposed versus contested, the percent unopposed, the average years in office of incumbents, and which districts (if any) saw incumbents lose renomination or be defeated? Validation: The question asks only for values the query computes per party: counts, percentages, average tenure, and turnover districts.",persona,"Political historian specializing in early 20th-century Southern U.S. elections, researching patterns of party dominance and electoral competitiveness in Louisiana; uses this database to quantify incumbency, unopposed races, and turnover in the 1930 House elections. Goals: Measure the prevalence of unopposed races and party dominance in Louisiana's 1930 House contests. Estimate incumbents' tenure (time in office) and identify cases of electoral turnover (lost renomination or defeat). Compare competitiveness by party (e.g., how many seats were contested vs. unopposed for each party). Example Queries: /* Count how many races were unopposed in the dataset */
SELECT COUNT(*) AS unopposed_count
FROM table_1_1342359_17
WHERE ""Candidates"" LIKE '%Unopposed%'; /* Summarize seats by party and how many of those seats were unopposed */
SELECT ""Party"",
       COUNT(*) AS seats_total,
       SUM(CASE WHEN ""Candidates"" LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS unopposed_seats
FROM table_1_1342359_17
GROUP BY ""Party""; /* List incumbents with years in office (as of 1930) and flag those who lost (renomination or general) */
SELECT ""District"",
       ""Incumbent"",
       ""Party"",
       ""First elected"",
       (1930 - ""First elected"") AS years_in_office,
       ""Result""
FROM table_1_1342359_17
WHERE ""Result"" LIKE '%Lost%'
   OR ""Result"" LIKE '%Lost renomination%'
   OR ""Result"" LIKE '%defeat%';",reward,,
"List up to 10 distinct Parties that have at least one 'Unopposed' candidate and for each Party show: Party, total_incumbents as the COUNT of District, unopposed_count as the count of rows where Candidates includes 'Unopposed', contested_count as total_incumbents minus unopposed_count, percent_unopposed as the percentage of incumbents unopposed rounded to one decimal ((unopposed_count * 100.0) / total_incumbents rounded to 1 decimal), avg_first_elected as the average of First elected, and min_first_elected as the minimum First elected?","
SELECT DISTINCT `Party`,
  COUNT(`District`) total_incumbents,
  SUM((instr(`Candidates`, 'Unopposed')>0)) unopposed_count,
  COUNT(`District`) - SUM((instr(`Candidates`, 'Unopposed')>0)) contested_count,
  ROUND((SUM((instr(`Candidates`, 'Unopposed')>0))*100.0)/COUNT(`District`),1) percent_unopposed,
  AVG(`First elected`) avg_first_elected,
  MIN(`First elected`) min_first_elected
FROM `table_1_1342359_2`
WHERE 1
GROUP BY `Party`
HAVING SUM((instr(`Candidates`, 'Unopposed')>0))>0
LIMIT 10;
","SELECT col2,
  COUNT(col0) AS total_incumbents,
  SUM(CASE WHEN instr(col5, 'Unopposed')>0 THEN 1 ELSE 0 END) AS unopposed_count,
  COUNT(col0) - SUM(CASE WHEN instr(col5, 'Unopposed')>0 THEN 1 ELSE 0 END) AS contested_count,
  ROUND((SUM(CASE WHEN instr(col5, 'Unopposed')>0 THEN 1 ELSE 0 END)*100.0)/COUNT(col0),1) AS percent_unopposed,
  AVG(col3) AS avg_first_elected,
  MIN(col3) AS min_first_elected
FROM `table_1_1342359_2`
WHERE 1=1
GROUP BY col2
ORDER BY unopposed_count DESC
LIMIT 10;","[('democratic', 6, 0, 6, 0.0, 1919.6666666666667, 1914.0)]",table_1_1342359_2,"Parse intent: produce per-Party aggregates including counts, sum of Unopposed, percent calculation, average and minimum 'First elected', only for parties with any 'Unopposed' incumbents and limit results. Map schema: use Party for grouping, District for counts, Candidates text to detect 'Unopposed', First elected numeric for AVG/MIN. Draft: request those exact metrics and the HAVING and LIMIT conditions. Validate: question explicitly requests all computed fields and constraints.",reserved,8,reward,,
"Can you list Party, Seats (the COUNT of rows with First elected not null) and Unopposed (the number of rows where Candidates contains the substring 'Unopposed') for Party = 'Democratic', ordered by Unopposed descending and restricted to the top 10 results?","
WITH `summary` AS (
  SELECT
    `Party`,
    COUNT(*) `Seats`,
    SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END) `Unopposed`
  FROM `table_1_1342359_41`
  WHERE `First elected` IS NOT NULL AND `Party` IN ('Democratic')
  GROUP BY `Party`
  HAVING `Seats` > 0 OR `Unopposed` > 0
)
SELECT `Party`, `Seats`, `Unopposed`
FROM `summary`
ORDER BY `Unopposed` DESC
LIMIT 10;
","WITH `summary` AS (
  SELECT col2, COUNT(*) `Seats`, SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END) `Unopposed`
  FROM `table_1_1342359_41`
  WHERE col3 IS NOT NULL AND (col2 IN ('Democratic','Republican') OR col2 IS NOT NULL)
  GROUP BY col2
  HAVING `Seats` > 0
)
SELECT col2, `Seats`, `Unopposed`
FROM `summary`
ORDER BY `Unopposed` DESC
LIMIT 10;","[('democratic', 5, 4)]",table_1_1342359_41,"1) Parse intent: compute per-Party aggregates restricted to Democratic rows with non-null First elected: total seat count and count of unopposed candidates, then order and limit. 2) Map schema: use Party, First elected, Candidates; define Seats as COUNT(*) and Unopposed as count of Candidates LIKE '%Unopposed%'. 3) Draft: pose a question requesting those three outputs with the specified filter, ordering and limit. 4) Validate: check that Party='Democratic', First elected IS NOT NULL, Seats and Unopposed calculations, ORDER BY Unopposed DESC, and LIMIT 10 are all included.",reserved,23,reward,,
"For all representatives whose First elected year is 1918 or earlier, provide District, Incumbent, Party and Tenure (computed as 1928 minus First elected)?","
SELECT `District`, `Incumbent`, `Party`, (1928 - `First elected`) `Tenure`
FROM `table_1_1342370_10`
WHERE `First elected` <= 1918;
","
SELECT col0, col1, col2, (1928 - col3) `Tenure`
FROM `table_1_1342370_10`
WHERE col3 <= 1918;
","[('georgia 3', 'charles r. crisp', 'democratic', 16.0), ('georgia 4', 'william c. wright', 'democratic', 10.0), ('georgia 8', 'charles h. brand', 'democratic', 12.0), ('georgia 9', 'thomas montgomery bell', 'democratic', 24.0), ('georgia 10', 'carl vinson', 'democratic', 14.0), ('georgia 11', 'william c. lankford', 'democratic', 10.0)]",table_1_1342370_10,"1) Parse SQL intent: return District, Incumbent, Party and (1928 - First elected) labeled Tenure for records with First elected <= 1918. 2) Map schema semantics: the relevant columns are District, Incumbent, Party and First elected; Tenure is derived. 3) Draft the question to explicitly request those fields and the computed Tenure for the filtered rows. 4) Validate: the question matches the SQL selection, calculation, and filtering criteria.",reserved,3,reward,,
Which incumbents are most at risk?,"
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    CAST(
      SUBSTR(
        `Candidates`,
        INSTR(`Candidates`, ') ')+2,
        INSTR(`Candidates`, '%') - (INSTR(`Candidates`, ') ')+2)
      ) AS FLOAT
    ) AS `WinnerPct`,
    CAST(
      SUBSTR(
        SUBSTR(`Candidates`, INSTR(`Candidates`, '%')+1),
        INSTR(SUBSTR(`Candidates`, INSTR(`Candidates`, '%')+1), ') ')+2,
        INSTR(SUBSTR(`Candidates`, INSTR(`Candidates`, '%')+1), '%')
          - (INSTR(SUBSTR(`Candidates`, INSTR(`Candidates`, '%')+1), ') ')+2)
      ) AS FLOAT
    ) AS `OpponentPct`,
    (1928 - `First elected`) AS `TenureYears`
  FROM `table_1_1342370_41`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  `WinnerPct`,
  `OpponentPct`,
  ABS(`WinnerPct` - `OpponentPct`) AS `MarginPct`,
  ROUND(
    (`WinnerPct` / 100.0) * (1.0 + CASE WHEN `TenureYears` > 10 THEN 10.0 ELSE `TenureYears` END / 20.0),
    2
  ) AS `StrengthScore`,
  ROUND(`WinnerPct`,2) AS `PopularityScore`,
  ROUND((1.0 - (ABS(`WinnerPct` - `OpponentPct`) / 100.0)) * 100.0,2) AS `VulnerabilityScore`,
  CASE
    WHEN `Result` LIKE '%Retired%' OR `Result` LIKE '%to run for%' THEN 'Open seat'
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 10.0 THEN 'Battleground'
    WHEN ABS(`WinnerPct` - `OpponentPct`) >= 40.0 THEN 'Safe'
    ELSE 'Lean'
  END AS `ScenarioTag`,
  CASE
    WHEN `Result` LIKE '%Retired%' OR `Result` LIKE '%to run for%' THEN 10
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 5.0 THEN 8
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 10.0 THEN 6
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 20.0 THEN 4
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 40.0 THEN 2
    ELSE 1
  END AS `VictoryPointReward`
FROM parsed
ORDER BY `MarginPct` ASC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    CAST(
      SUBSTR(
        col5,
        INSTR(col5, ') ')+2,
        INSTR(col5, '%') - (INSTR(col5, ') ')+2)
      ) AS FLOAT
    ) AS `WinnerPct`,
    CAST(
      SUBSTR(
        SUBSTR(col5, INSTR(col5, '%')+1),
        INSTR(SUBSTR(col5, INSTR(col5, '%')+1), ') ')+2,
        INSTR(SUBSTR(col5, INSTR(col5, '%')+1), '%')
          - (INSTR(SUBSTR(col5, INSTR(col5, '%')+1), ') ')+2)
      ) AS FLOAT
    ) AS `OpponentPct`,
    (1928 - col3) AS `TenureYears`
  FROM `table_1_1342370_41`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  `WinnerPct`,
  `OpponentPct`,
  ABS(`WinnerPct` - `OpponentPct`) AS `MarginPct`,
  ROUND(
    (`WinnerPct` / 100.0) * (1.0 + CASE WHEN `TenureYears` > 10 THEN 10.0 ELSE `TenureYears` END / 20.0),
    2
  ) AS `StrengthScore`,
  ROUND(`WinnerPct`,2) AS `PopularityScore`,
  ROUND((1.0 - (ABS(`WinnerPct` - `OpponentPct`) / 100.0)) * 100.0,2) AS `VulnerabilityScore`,
  CASE
    WHEN col4 LIKE '%Retired%' OR col4 LIKE '%to run for%' THEN 'Open seat'
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 10.0 THEN 'Battleground'
    WHEN ABS(`WinnerPct` - `OpponentPct`) >= 40.0 THEN 'Safe'
    ELSE 'Lean'
  END AS `ScenarioTag`,
  CASE
    WHEN col4 LIKE '%Retired%' OR col4 LIKE '%to run for%' THEN 10
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 5.0 THEN 8
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 10.0 THEN 6
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 20.0 THEN 4
    WHEN ABS(`WinnerPct` - `OpponentPct`) < 40.0 THEN 2
    ELSE 1
  END AS `VictoryPointReward`
FROM parsed
ORDER BY `MarginPct` ASC;
","[('tennessee 4', 'cordell hull', 'democratic', 1922.0, 're-elected', 'cordell hull (d) 68.2% houston justice (r) 31.8%', 68.2, 31.8, 36.400000000000006, 0.89, 68.2, 63.6, 'Lean', 2), ('tennessee 2', 'j. will taylor', 'republican', 1918.0, 're-elected', 'j. will taylor (r) 68.9% leon journolman (d) 31.1%', 68.9, 31.1, 37.800000000000004, 1.03, 68.9, 62.2, 'Lean', 2), ('tennessee 1', 'b. carroll reece', 'republican', 1920.0, 're-elected', 'b. carroll reece (r) 78.6% w. i. giles (d) 21.4%', 78.6, 21.4, 57.199999999999996, 1.1, 78.6, 42.8, 'Safe', 1), ('tennessee 6', 'joseph w. byrns, sr.', 'democratic', 1908.0, 're-elected', 'joseph w. byrns, sr. (d) 79.9% bradbury (r) 20.1%', 79.9, 20.1, 59.800000000000004, 1.2, 79.9, 40.2, 'Safe', 1), ('tennessee 5', 'ewin l. davis', 'democratic', 1918.0, 're-elected', 'ewin l. davis (d) 80.4% caplington (r) 19.6%', 80.4, 19.6, 60.800000000000004, 1.21, 80.4, 39.2, 'Safe', 1), ('tennessee 9', 'finis j. garrett', 'democratic', 1904.0, 'retired to run for u. s. senate democratic hold', 'jere cooper (d) 90.1% h. c. murchison (r) 9.9%', 90.1, 9.9, 80.19999999999999, 1.35, 90.1, 19.8, 'Open seat', 10)]",table_1_1342370_41,"STEP 1: Parse the SQL intent — it extracts winner and opponent percentages from the Candidates text, computes TenureYears (1928 - First elected), MarginPct = ABS(WinnerPct - OpponentPct), StrengthScore (WinnerPct scaled by tenure capped at 10 years), PopularityScore (rounded WinnerPct), VulnerabilityScore = (1 - abs diff/100)*100, assigns ScenarioTag (Open seat/Battleground/Lean/Safe) and VictoryPointReward by margin/result, and orders rows by MarginPct ASC (closest races first). STEP 2: Choose an ambiguity type — metric ambiguity fits: a phrase like “at risk” or “most at risk” could map to several different computed metrics (MarginPct, VulnerabilityScore, StrengthScore, ScenarioTag, VictoryPointReward) or different scopes (single top vs list). STEP 3: Draft the question — a concise ambiguous NL question matching the SQL: “Which incumbents are most at risk?” STEP 4: Explain the ambiguity — in the original query “most at risk” is realized by ordering on MarginPct (smallest margin = most at risk), but a user might alternatively mean highest VulnerabilityScore (normalized closeness), lowest StrengthScore (low adjusted winner support), those tagged as 'Open seat' or 'Battleground', or those with the lowest VictoryPointReward; the phrasing doesn’t specify which metric or whether they want one incumbent or a list.",persona,"A board-game designer who creates historically accurate 1920s U.S. House election simulation games and needs Tennessee 1928 data to balance candidate cards and scenario setups. Goals: Translate historical incumbency, party, and vote shares into game stats (strength, popularity, vulnerability) for each district card. Design scenario/event cards (e.g., open-seat scramble when an incumbent retires to run for Senate) and seed plausible victory conditions and victory-point rewards. Identify the closest races to create high-drama battleground scenarios and the safest seats to act as default control points in the game map. Example Queries: /* Get incumbents who were re-elected and extract the top two vote percentages for balancing candidate strength */
SELECT District, Incumbent, Party, ""First elected"", Result,
  CAST(REGEXP_SUBSTR(Candidates, '(\\d+\\.\\d+)%', 1, 1) AS FLOAT) AS WinnerPct,
  CAST(REGEXP_SUBSTR(Candidates, '(\\d+\\.\\d+)%', 1, 2) AS FLOAT) AS OpponentPct
FROM table_1_1342370_41
WHERE Result LIKE '%Re-elected%'; /* Find open-seat / retirement scenarios to create special event cards (e.g., 'Incumbent retires to run for Senate') */
SELECT District, Incumbent, Party, Result, Candidates
FROM table_1_1342370_41
WHERE Result LIKE '%Retired%' OR Result LIKE '%to run for%' OR Result LIKE '%vacant%'; /* Compute absolute margin between top two listed percentages and return the tightest races for battleground scenarios */
SELECT District, Incumbent,
  ABS(
    CAST(REGEXP_SUBSTR(Candidates, '(\\d+\\.\\d+)%', 1, 1) AS FLOAT)
    - CAST(REGEXP_SUBSTR(Candidates, '(\\d+\\.\\d+)%', 1, 2) AS FLOAT)
  ) AS MarginPct
FROM table_1_1342370_41
ORDER BY MarginPct ASC;",reward,,"type: Metric ambiguity | explanation: The question ""most at risk"" could refer to smallest MarginPct (what the query orders by), highest VulnerabilityScore, lowest StrengthScore, being an 'Open seat' or 'Battleground' in ScenarioTag, or having a low VictoryPointReward — the SQL implements the MarginPct interpretation but the phrase could validly mean any of these metrics or different result scopes (single top vs list)."
"List incumbents with their district, party, first elected, years in office (1926 − first elected), the candidates line, the incumbent's percentage, and flags for Unopposed and Landslide (≥80%) so I can find long‑tenured figures and see how contested their races were.","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    CASE
      WHEN `Candidates` LIKE '%Unopposed%' THEN 100.0
      WHEN INSTR(`Candidates`, ')') > 0 AND INSTR(`Candidates`, '%') > 0
        THEN CAST(
               SUBSTR(
                 `Candidates`,
                 INSTR(`Candidates`, ')') + 2,
                 INSTR(`Candidates`, '%') - (INSTR(`Candidates`, ')') + 2)
               ) AS REAL
             )
      ELSE NULL
    END AS `IncumbentPct`,
    (1926 - `First elected`) AS `YearsInOffice`
  FROM `table_1_1342379_2`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  `IncumbentPct`,
  CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Unopposed`,
  CASE WHEN `IncumbentPct` >= 80.0 THEN 1 ELSE 0 END AS `Landslide`,
  `YearsInOffice`
FROM parsed
ORDER BY `Unopposed` DESC, `Landslide` DESC, `IncumbentPct` DESC, `YearsInOffice` DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    CASE
      WHEN col5 LIKE '%Unopposed%' THEN 100.0
      WHEN INSTR(col5, ')') > 0 AND INSTR(col5, '%') > 0
        THEN CAST(
               SUBSTR(
                 col5,
                 INSTR(col5, ')') + 2,
                 INSTR(col5, '%') - (INSTR(col5, ')') + 2)
               ) AS REAL
             )
      ELSE NULL
    END AS `IncumbentPct`,
    (1926 - col3) AS `YearsInOffice`
  FROM `table_1_1342379_2`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  `IncumbentPct`,
  CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Unopposed`,
  CASE WHEN `IncumbentPct` >= 80.0 THEN 1 ELSE 0 END AS `Landslide`,
  `YearsInOffice`
FROM parsed
ORDER BY `Unopposed` DESC, `Landslide` DESC, `IncumbentPct` DESC, `YearsInOffice` DESC;
","[('alabama 2', 'j. lister hill', 'democratic', 1923.0, 're-elected', 'j. lister hill (d) unopposed', 100.0, 1, 1, 3.0), ('alabama 6', 'william b. oliver', 'democratic', 1914.0, 're-elected', 'william b. oliver (d) 99.0% c. m. ayers (r) 1.0%', 99.0, 0, 1, 12.0), ('alabama 8', 'edward b. almon', 'democratic', 1914.0, 're-elected', 'edward b. almon (d) 90.1% robert m. sims (r) 9.9%', 90.1, 0, 1, 12.0), ('alabama 1', 'john mcduffie', 'democratic', 1918.0, 're-elected', 'john mcduffie (d) 84.0% aubrey boyles (r) 16.0%', 84.0, 0, 1, 8.0), ('alabama 4', 'lamar jeffers', 'democratic', 1921.0, 're-elected', 'lamar jeffers (d) 68.1% omar h. reynolds (r) 31.9%', 68.1, 0, 0, 5.0)]",table_1_1342379_2,"I'm tracing long-tenured faces and how contested they were, phrasing it poetically but clearly. The SQL computes YearsInOffice as 1926 minus First elected and reports whether a seat was unopposed or a landslide and the incumbent percent. The table supplies First elected and Candidates for percent/unopposed determination. Request a list ordered so I can pick long-serving incumbents with their percent, and flags for unopposed and landslide. This will let me build timelines and portraits linking tenure to contest intensity.",persona,"A museum installation artist — self-styled 'Silence Cartographer' — who maps political absence and dominance by visualizing unopposed and landslide 1926 House races. Goals: Catalog districts with unopposed incumbents to show geographic patterns of electoral silence for an exhibit. Identify extreme landslide victories (e.g., incumbents winning ≥80%) to create a heatmap of political dominance. Find long-tenured incumbents (elected many years before 1926) to build timelines and portraits linking tenure to contest intensity. Example Queries: /* 1) List districts where the incumbent ran unopposed */
SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1342379_2
WHERE Candidates LIKE '%Unopposed%'; /* 2) Extract the incumbent's reported percent and return races where that percent >= 80% (SQLite-style string parsing) */
SELECT District, Incumbent, Party, ""First elected"", Candidates,
       CAST(SUBSTR(Candidates, INSTR(Candidates, ')')+2, INSTR(Candidates, '%') - (INSTR(Candidates, ')')+2)) AS REAL) AS IncumbentPct
FROM table_1_1342379_2
WHERE CAST(SUBSTR(Candidates, INSTR(Candidates, ')')+2, INSTR(Candidates, '%') - (INSTR(Candidates, ')')+2)) AS REAL) >= 80.0; /* 3) Find long-tenured incumbents (elected in or before 1916) and compute years in office as of 1926 */
SELECT District, Incumbent, Party, ""First elected"", (1926 - ""First elected"") AS YearsInOffice
FROM table_1_1342379_2
WHERE ""First elected"" <= 1916
ORDER BY ""First elected"" ASC;",reward,,
Which districts had long-serving incumbents who ran unopposed?,"
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  CASE WHEN INSTR(`Candidates`, 'Unopposed') > 0 THEN 1 ELSE 0 END AS `Unopposed`,
  CASE 
    WHEN INSTR(`Result`, 'Lost renomination') > 0 THEN 'Lost renomination'
    WHEN INSTR(`Result`, 'Retired to run for U.S. Senate') > 0 THEN 'Retired to run for U.S. Senate'
    ELSE NULL
  END AS `Turnover_Type`,
  CASE
    WHEN INSTR(`Candidates`, ' (') > 0 THEN TRIM(SUBSTR(`Candidates`, 1, INSTR(`Candidates`, ' (') - 1))
    ELSE TRIM(REPLACE(REPLACE(`Candidates`, 'Unopposed', ''), '(D)', ''))
  END AS `Candidate_Name`,
  CASE WHEN `First elected` < 1910 THEN 1 ELSE 0 END AS `Long_serving`,
  CASE 
    WHEN `Party` = 'Democratic' AND (INSTR(`Candidates`, 'Unopposed') > 0 OR INSTR(`Result`, 'Democratic hold') > 0) THEN 1 
    ELSE 0 
  END AS `One_party_benefit`
FROM `table_1_1342451_16`
ORDER BY `Unopposed` DESC, `Long_serving` DESC, `District`;
","
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  CASE WHEN INSTR(col5, 'Unopposed') > 0 THEN 1 ELSE 0 END AS `Unopposed`,
  CASE 
    WHEN INSTR(col4, 'Lost renomination') > 0 THEN 'Lost renomination'
    WHEN INSTR(col4, 'Retired to run for U.S. Senate') > 0 THEN 'Retired to run for U.S. Senate'
    ELSE NULL
  END AS `Turnover_Type`,
  CASE
    WHEN INSTR(col5, ' (') > 0 THEN TRIM(SUBSTR(col5, 1, INSTR(col5, ' (') - 1))
    ELSE TRIM(REPLACE(REPLACE(col5, 'Unopposed', ''), '(D)', ''))
  END AS `Candidate_Name`,
  CASE WHEN col3 < 1910 THEN 1 ELSE 0 END AS `Long_serving`,
  CASE 
    WHEN col2 = 'Democratic' AND (INSTR(col5, 'Unopposed') > 0 OR INSTR(col4, 'Democratic hold') > 0) THEN 1 
    ELSE 0 
  END AS `One_party_benefit`
FROM `table_1_1342451_16`
ORDER BY `Unopposed` DESC, `Long_serving` DESC, col0;
","[('louisiana 2', 'henry garland dupré', 'democratic', 1908.0, 're-elected', 'henry garland dupré (d) unopposed', 0, None, 'henry garland dupré', 1, 0), ('louisiana 4', 'john t. watkins', 'democratic', 1904.0, 'lost renomination democratic hold', 'john n. sandlin (d) unopposed', 0, None, 'john n. sandlin', 1, 0), ('louisiana 1', ""james o'connor"", 'democratic', 1918.0, 're-elected', ""james o'connor (d) unopposed"", 0, None, ""james o'connor"", 0, 0), ('louisiana 3', 'whitmell p. martin', 'democratic', 1914.0, 're-elected', 'whitmell p. martin (d) unopposed', 0, None, 'whitmell p. martin', 0, 0), ('louisiana 5', 'riley joseph wilson', 'democratic', 1914.0, 're-elected', 'riley joseph wilson (d) unopposed', 0, None, 'riley joseph wilson', 0, 0), ('louisiana 6', 'jared y. sanders, sr.', 'democratic', 1916.0, 'retired to run for u.s. senate democratic hold', 'george k. favrot (d) unopposed', 0, None, 'george k. favrot', 0, 0), ('louisiana 7', 'ladislas lazaro', 'democratic', 1912.0, 're-elected', 'ladislas lazaro (d) unopposed', 0, None, 'ladislas lazaro', 0, 0)]",table_1_1342451_16,"STEP 1: Parse the SQL intent — the query selects District, Incumbent, Party, First elected, Result, Candidates and computes flags: Unopposed (Candidates contains 'Unopposed'), Turnover_Type (maps specific substrings in Result), Candidate_Name (trims text before ' ('), Long_serving (First elected < 1910), One_party_benefit (Democratic and either Unopposed or 'Democratic hold'); it returns all rows but orders them by Unopposed desc, Long_serving desc, District. STEP 2: Determine ambiguity type — scope ambiguity fits because a question about ""long-serving incumbents who ran unopposed"" can mean the intersection (both conditions true), the union (either condition true), or simply highlighting such incumbents among all rows (no filter). STEP 3: Draft the question — ""Which districts had long-serving incumbents who ran unopposed?"" STEP 4: Explain the ambiguity — in the original query the two properties are encoded as separate binary flags and only prioritized via ORDER BY (not filtered). That makes one valid interpretation: return only rows where Unopposed=1 AND Long_serving=1; another valid interpretation: return rows where Unopposed=1 OR Long_serving=1; a third interpretation: show the full table but list long-serving and unopposed incumbents first (no filtering).",persona,"A Creole political genealogist and historical-linguist who traces family names, elite continuity, and the prevalence of uncontested (one-party) elections in 1920 Louisiana. Goals: Identify which Louisiana congressional districts in 1920 had uncontested ('Unopposed') races and which incumbents benefited from one-party dominance. Find turnover events (lost renomination, retirements to run for Senate) to locate potential family-branch transitions or intraparty contests for deeper genealogical digging. Extract canonical candidate names (stripped of party markers and 'Unopposed' notes) and long-serving incumbents (first elected before 1910) to cross-reference with vital records, family trees, and Creole/Francophone surname studies. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1342451_16
WHERE Candidates LIKE '%Unopposed%'; SELECT Party, COUNT(*) AS unopposed_count
FROM table_1_1342451_16
WHERE Candidates LIKE '%Unopposed%'
GROUP BY Party
ORDER BY unopposed_count DESC; SELECT District,
       Incumbent,
       ""First elected"",
       Result,
       TRIM(SUBSTR(Candidates, 1, INSTR(Candidates, ' (') - 1)) AS Candidate_Name
FROM table_1_1342451_16
WHERE Candidates LIKE '%Unopposed%';",reward,,"type: Scope ambiguity | explanation: The phrase can be read as requiring both conditions (long-serving AND unopposed), as either condition (long-serving OR unopposed), or as simply asking to highlight those cases within the full list (no filtering) — the SQL computes both flags and orders by them but does not filter, so each interpretation is plausible."
"Considering only episodes where U.S. viewers (millions) is between 5 and 9 or the episode '#' is less than 10, return each distinct Directed by with Episodes (COUNT(Title)) and AvgViewers (ROUND(AVG(U.S. viewers (millions)),2)) for directors with COUNT(Title) > 1, ordered by AvgViewers descending and limited to 5 results?","
SELECT DISTINCT `Directed by`, COUNT(`Title`) `Episodes`, ROUND(AVG(`U.S. viewers (millions)`),2) AS `AvgViewers`
FROM `table_1_13426649_1`
WHERE `U.S. viewers (millions)` BETWEEN 5 AND 9 OR `#` < 10
GROUP BY `Directed by`
HAVING COUNT(`Title`) > 1
ORDER BY `AvgViewers` DESC
LIMIT 5;
","
SELECT DISTINCT col2, COUNT(col1) `Episodes`, ROUND(AVG(col6),2) AS `AvgViewers`
FROM `table_1_13426649_1`
WHERE col6 BETWEEN 5 AND 9 OR col0 < 10
GROUP BY col2
HAVING COUNT(col1) > 1
ORDER BY `AvgViewers` DESC
LIMIT 5;
","[('alex graves', 4, 7.37)]",table_1_13426649_1,"1) Parse the SQL intent: select distinct directors, count their titles and compute rounded average viewers for rows meeting a viewer-range or early-episode condition, keep directors with count > 1, sort by average descending and limit to 5. 2) Map schema semantics: use columns 'Directed by', 'Title', 'U.S. viewers (millions)', and '#' exactly as in the query, with COUNT and ROUND(AVG(...),2). 3) Draft the question: request those aggregated metrics with the specified filters, having clause, ordering, and limit. 4) Validate: ensures all columns, calculations, WHERE BETWEEN 5 AND 9 OR # < 10, HAVING COUNT(Title) > 1, ORDER BY AvgViewers DESC, and LIMIT 5 are included.",reserved,14,reward,,
"For up to 5 pairs of buildings in the same Region where one building's Height (m) is greater than the other's and the shorter building's Estimated Completion is earlier than the taller building's, what are the shorter building's Name, its Height (m), the taller building's Name labeled as 'Leadenhall Building', and the height difference (taller Height (m) - shorter Height (m))?","
SELECT t1.`Name`, t1.`Height (m)`, t2.`Name` AS `Leadenhall Building`, (t2.`Height (m)` - t1.`Height (m)`)
FROM `table_1_13463790_2` t1 INNER JOIN `table_1_13463790_2` t2 ON t2.`Region` = t1.`Region`
WHERE t2.`Height (m)` > t1.`Height (m)` AND CASE WHEN t1.`Estimated Completion` < t2.`Estimated Completion` THEN 1 ELSE 0 END = 1
LIMIT 5;
","
SELECT t1.col1, t1.col4, t2.col1 AS `Leadenhall Building`, (t2.col4 - t1.col4)
FROM `table_1_13463790_2` t1 INNER JOIN `table_1_13463790_2` t2 ON t2.col3 = t1.col3
WHERE t2.col4 > t1.col4 AND CASE WHEN t1.col7 < t2.col7 THEN 1 ELSE 0 END = 1
LIMIT 5;
","[('100 bishopsgate', 172.0, '52-54 lime street', 18.0), ('20 fenchurch street', 160.0, '1 blackfriars', 3.0), ('20 fenchurch street', 160.0, '100 bishopsgate', 12.0), ('20 fenchurch street', 160.0, '52-54 lime street', 30.0), ('baltimore tower', 150.0, '1 blackfriars', 13.0)]",table_1_13463790_2,"1) The query finds pairs of rows from the same Region where t2 is taller than t1 and t1's Estimated Completion is earlier than t2's, selecting t1.Name, t1.Height (m), t2.Name aliased as 'Leadenhall Building', and the height difference (t2.Height (m) - t1.Height (m)) with a LIMIT 5. 2) Map columns: Name and Height (m) for the shorter building (t1), Name and Height (m) for the taller building (t2), and Estimated Completion for comparison, joined on Region. 3) Draft a question that requests those exact fields, the height subtraction, the same-Region constraint, the completion-date ordering, and up to 5 results. 4) Validate that all selected columns, the calculation, join condition, comparison, and LIMIT are mentioned.",reserved,14,reward,,
"Can you list each Owner (labeled 'Dakota Communications') along with the concatenated Call sign values joined by ', ', concatenated Frequency values joined by ' | ', concatenated Target city/ market values joined by '; ', and concatenated City of license values joined by '; ', grouped by Owner and excluding any empty Owner entries, with the output limited to 10 rows?","
SELECT `Owner` AS `Dakota Communications`, group_concat(`Call sign`, ', '), group_concat(`Frequency`, ' | '), group_concat(`Target city/ market`, '; '), group_concat(`City of license`, '; ')
FROM `table_1_134729_3`
WHERE 1 = 1
GROUP BY `Owner`
HAVING LENGTH(`Owner`) > 0 AND 1 = 1 AND 1 = 1
LIMIT 10;
","
SELECT col4 AS `Dakota Communications`, group_concat(col1, ', '), group_concat(col0, ' | '), group_concat(col5, '; '), group_concat(col6, '; ')
FROM `table_1_134729_3`
WHERE 1 = 1
GROUP BY col4
HAVING LENGTH(col4) > 0 AND 1 = 1 AND 1 = 1
LIMIT 10;
","[('dakota communications', 'kjrv, kjrv', '93.3 fm | 105.1 fm', 'huron/mitchell; huron', 'wessington springs; huron'), ('educational media foundation', 'k-love', '89.7 fm', 'huron', 'rocklin, california'), ('moody bible institute', 'k213cl', '90.5 fm', 'huron', 'huron'), ('vcy america', 'kvch', '88.7 fm', 'huron', 'huron')]",table_1_134729_3,"1) The SQL intent is to aggregate rows per Owner with group_concat for four columns and alias Owner. 2) Schema mapping ties Call sign, Frequency, Target city/ market, City of license to the aggregations and Owner to grouping. 3) Drafted a question requesting the Owner labeled 'Dakota Communications' and the four concatenated fields with their exact separators, while filtering out empty Owner and limiting to 10. 4) Checked that alias, separators, grouping, filter, and limit are all mentioned.",reserved,10,reward,,
"Give me every season sorted by total viewers, showing season label, TV season, episodes, total viewers and viewers per episode, the premiere and finale month+day, timeslot, ranking, plus the suggested mix minutes and layer count based on audience?","
SELECT
  `Season`,
  `TV Season`,
  `Episodes`,
  CAST(`Viewers (in millions)` AS REAL) AS `Viewers (in millions)`,
  ROUND(CAST(`Viewers (in millions)` AS REAL) / `Episodes`, 2) AS `viewers_per_episode`,
  substr(`Season Premiere`, 1, instr(`Season Premiere`, ' ') - 1) || ' ' || trim(substr(`Season Premiere`, instr(`Season Premiere`, ' ') + 1, instr(`Season Premiere`, ',') - instr(`Season Premiere`, ' ') - 1)) AS `Premiere Month Day`,
  substr(`Season Finale`, 1, instr(`Season Finale`, ' ') - 1) || ' ' || trim(substr(`Season Finale`, instr(`Season Finale`, ' ') + 1, instr(`Season Finale`, ',') - instr(`Season Finale`, ' ') - 1)) AS `Finale Month Day`,
  `Timeslot`,
  `Ranking`,
  CASE
    WHEN (SELECT MAX(CAST(`Viewers (in millions)` AS REAL)) FROM table_1_1348989_2) = (SELECT MIN(CAST(`Viewers (in millions)` AS REAL)) FROM table_1_1348989_2)
    THEN 60
    ELSE ROUND(
      30
      + (CAST(`Viewers (in millions)` AS REAL) - (SELECT MIN(CAST(`Viewers (in millions)` AS REAL)) FROM table_1_1348989_2))
        * 90.0
        / (
          (SELECT MAX(CAST(`Viewers (in millions)` AS REAL)) FROM table_1_1348989_2)
          - (SELECT MIN(CAST(`Viewers (in millions)` AS REAL)) FROM table_1_1348989_2)
        )
    )
  END AS `scaled_composition_minutes`,
  CASE
    WHEN (SELECT MAX(CAST(`Viewers (in millions)` AS REAL) / `Episodes`) FROM table_1_1348989_2) = 0
    THEN 1
    ELSE 1 + ROUND(
      9.0
      * (CAST(`Viewers (in millions)` AS REAL) / `Episodes`)
      / (SELECT MAX(CAST(`Viewers (in millions)` AS REAL) / `Episodes`) FROM table_1_1348989_2)
    )
  END AS `layer_count`
FROM table_1_1348989_2
ORDER BY CAST(`Viewers (in millions)` AS REAL) DESC;
","
SELECT
  col0,
  col5,
  col4,
  CAST(col7 AS REAL) AS col7,
  ROUND(CAST(col7 AS REAL) / col4, 2) AS `viewers_per_episode`,
  substr(col2, 1, instr(col2, ' ') - 1) || ' ' || trim(substr(col2, instr(col2, ' ') + 1, instr(col2, ',') - instr(col2, ' ') - 1)) AS `Premiere Month Day`,
  substr(col3, 1, instr(col3, ' ') - 1) || ' ' || trim(substr(col3, instr(col3, ' ') + 1, instr(col3, ',') - instr(col3, ' ') - 1)) AS `Finale Month Day`,
  col1,
  col6,
  CASE
    WHEN (SELECT MAX(CAST(col7 AS REAL)) FROM table_1_1348989_2) = (SELECT MIN(CAST(col7 AS REAL)) FROM table_1_1348989_2)
    THEN 60
    ELSE ROUND(
      30
      + (CAST(col7 AS REAL) - (SELECT MIN(CAST(col7 AS REAL)) FROM table_1_1348989_2))
        * 90.0
        / (
          (SELECT MAX(CAST(col7 AS REAL)) FROM table_1_1348989_2)
          - (SELECT MIN(CAST(col7 AS REAL)) FROM table_1_1348989_2)
        )
    )
  END AS `scaled_composition_minutes`,
  CASE
    WHEN (SELECT MAX(CAST(col7 AS REAL) / col4) FROM table_1_1348989_2) = 0
    THEN 1
    ELSE 1 + ROUND(
      9.0
      * (CAST(col7 AS REAL) / col4)
      / (SELECT MAX(CAST(col7 AS REAL) / col4) FROM table_1_1348989_2)
    )
  END AS `layer_count`
FROM table_1_1348989_2
ORDER BY CAST(col7 AS REAL) DESC;
","[('2nd', '2005–2006', 24.0, 11.62, 0.48, 'september 23', 'may 19', 'friday 10:00pm', '#32', 120.0, 6.0), ('1st', '2004–2005', 13.0, 10.77, 0.83, 'january 23', 'may 13', 'friday 10:00pm', '#36', 89.0, 10.0), ('3rd', '2006–2007', 24.0, 10.5, 0.44, 'september 22', 'may 18', 'friday 10:00pm', '#38', 79.0, 6.0), ('5th', '2008–2009', 23.0, 10.29, 0.45, 'october 3', 'may 15', 'friday 10:00pm', '#37', 72.0, 6.0), ('4th', '2007–2008', 18.0, 9.14, 0.51, 'september 28', 'may 16', 'friday 10:00pm', '#55', 30.0, 7.0)]",table_1_1348989_2,"As an archival sound artist I speak in terms of seasons, audience sizes and mix lengths rather than column names; I know the table will have season labels, viewer counts, episodes and dates. The SQL pulls season rows, casts viewers to numbers, computes viewers per episode, extracts month+day for premiere and finale, and calculates scaled composition minutes and layer counts, then orders by total viewers descending. Season => Season, ""Viewers (in millions)"" cast to real => total audience, Episodes => episode count, Premiere/Finale parsed to month+day, Timeslot and Ranking kept. Draft question: ask for all seasons sorted by total viewers with per-episode audience, premiere/finale month-days, timeslot, ranking, and the computed mix minutes and layer count. This matches the selected fields and ordering in the query.",persona,"An archival sound artist designing an audio installation that plays season-length ambient mixes scaled to original TV audiences and timed to the show's original premiere/finale dates. Goals: Select the most-watched seasons to allocate longer, multilayered audio compositions (audience size -> composition length/complexity). Schedule public listening events on or near the original Season Premiere and Season Finale dates (extract months/dates to align calendar programming). Compute a per-episode audience metric (viewers per episode) to weight individual episode-themed audio segments within each season. Confirm the original timeslot patterns to inform background noise design (e.g., 'Friday 10:00pm' urban-night ambience). Example Queries: SELECT Season, ""TV Season"", Episodes, ""Viewers (in millions)"" FROM table_1_1348989_2 ORDER BY CAST(""Viewers (in millions)"" AS REAL) DESC LIMIT 3; SELECT Season, ""Season Premiere"", ""Season Finale"" FROM table_1_1348989_2 WHERE ""Season Premiere"" LIKE 'September %' OR ""Season Premiere"" LIKE 'October %' ORDER BY ""Season Premiere""; SELECT Season, Episodes, CAST(""Viewers (in millions)"" AS REAL) AS viewers_millions, (CAST(""Viewers (in millions)"" AS REAL) / Episodes) AS viewers_per_episode FROM table_1_1348989_2 ORDER BY viewers_per_episode DESC;",reward,,
"Which distinct Trainers (limit 10) have the following aggregated results: Runners = COUNT(*), AvgPlacing = ROUND(AVG(Placing + 0), 2), BestPlacing = MIN(Placing + 0), and Horses = GROUP_CONCAT(Horse, ', '), when considering only rows where LENGTH(Placing) <= 2 and including only Trainers with COUNT(*) >= 1?","
SELECT DISTINCT `Trainer`, COUNT(*) `Runners`, ROUND(AVG(`Placing` + 0),2) `AvgPlacing`, MIN(`Placing` + 0) `BestPlacing`, GROUP_CONCAT(`Horse`, ', ') `Horses` FROM `table_1_13498403_1` WHERE LENGTH(`Placing`) <= 2 GROUP BY `Trainer` HAVING COUNT(*) >= 1 LIMIT 10;
","
SELECT DISTINCT col2, COUNT(*) `Runners`, ROUND(AVG(col6 + 0),2) `AvgPlacing`, MIN(col6 + 0) `BestPlacing`, GROUP_CONCAT(col1, ', ') `Horses` FROM `table_1_13498403_1` WHERE LENGTH(col6) <= 2 GROUP BY col2 HAVING COUNT(*) >= 1 LIMIT 10;
","[('amanda perrett', 1, 21.0, 21, 'tungsten strike (usa)'), ('andrew j payne', 1, 6.0, 6, 'on a jeune'), ('bart cummings', 1, 12.0, 12, 'sirmione'), ('colin little', 1, 19.0, 19, 'blutigeroo'), ('daniel morton', 1, 16.0, 16, 'scenic shot'), (""danny o'brien"", 2, 9.5, 8, ""master o'reilly (nz), douro valley""), ('david hayes', 4, 12.0, 7, 'tawqeet (usa), blue monday (gb), black tom, lazer sharp'), ('graeme rogerson', 2, 2.5, 1, 'efficient (nz), zipping'), ('luca cumani', 1, 2.0, 2, 'purple moon (ire)'), ('mark walker', 1, 13.0, 13, 'princess coup')]",table_1_13498403_1,"1) Parse the SQL intent: group by Trainer to produce aggregates and a concatenated horse list, excluding placings with length > 2 and limiting to 10 trainers. 2) Map schema semantics: Trainer and Horse are used directly; Placing is cast to numeric with Placing + 0 for AVG and MIN; GROUP_CONCAT uses ', ' separator; DISTINCT and HAVING COUNT(*) >= 1 ensure unique trainers with runners. 3) Draft the question: ask for Trainer, Runners (COUNT(*)), AvgPlacing (ROUND(AVG(Placing + 0),2)), BestPlacing (MIN(Placing + 0)), Horses (GROUP_CONCAT(Horse, ', ')) with WHERE LENGTH(Placing) <= 2 and LIMIT 10. 4) Validate: includes every column, calculation, filter, grouping, having and limit from the query.",reserved,8,reward,,
"Which counties (limit 10) have an average per capita income greater than the average per capita income across all places, when considering only places with Population > 1000 OR Number of Households > 1000, and for each such County show the number of places (NumPlaces), the Avg Per Capita (compute Per Capita Income by removing '$' and ',' then converting to numeric and rounding the county average to 2 decimals) and the Total Population (sum of Population)?","
SELECT t.`County` AS `County`, COUNT(t.`Place`) AS `NumPlaces`, ROUND(AVG(REPLACE(REPLACE(t.`Per Capita Income`,'$',''),',','')+0),2) `Avg Per Capita`, SUM(t.`Population`) `Total Population`
FROM `table_1_1350350_2` t JOIN `table_1_1350350_2` s ON t.`Rank` = s.`Rank`
WHERE t.`Population` > 1000 OR t.`Number of Households` > 1000
GROUP BY t.`County`
HAVING AVG(REPLACE(REPLACE(t.`Per Capita Income`,'$',''),',','')+0) > (SELECT AVG(REPLACE(REPLACE(`Per Capita Income`,'$',''),',','')+0) FROM `table_1_1350350_2`)
LIMIT 10;
","
SELECT t.col2 AS col2, COUNT(t.col1) AS `NumPlaces`, ROUND(AVG(REPLACE(REPLACE(t.col3,'$',''),',','')+0),2) `Avg Per Capita`, SUM(t.col5) `Total Population`
FROM `table_1_1350350_2` t JOIN `table_1_1350350_2` s ON t.col0 = s.col0
WHERE t.col5 > 1000 OR t.col6 > 1000
GROUP BY t.col2
HAVING AVG(REPLACE(REPLACE(t.col3,'$',''),',','')+0) > (SELECT AVG(REPLACE(REPLACE(col3,'$',''),',','')+0) FROM `table_1_1350350_2`)
LIMIT 10;
","[('carson city', 1, 20943.0, 52457.0), ('clark county', 18, 20838.89, 1342756.0), ('douglas county', 8, 26744.75, 31979.0), ('humboldt county', 1, 21441.0, 7174.0), ('storey county', 1, 23765.0, 2533.0), ('washoe county', 8, 27357.0, 298895.0)]",table_1_1350350_2,"1) The query filters rows by Population>1000 OR Number of Households>1000, groups by County, computes COUNT(Place) as NumPlaces, average cleaned Per Capita Income rounded to 2 decimals, and SUM(Population), then keeps counties with AVG(cleaned Per Capita) > overall AVG(cleaned Per Capita) and limits to 10. 2) Map table columns and the string-to-number Per Capita Income conversion. 3) Formulate a question asking for County, NumPlaces, Avg Per Capita (cleaned and rounded), and Total Population under these conditions, limited to 10. 4) Ensure inclusion of all columns, cleaning steps, filter logic, HAVING condition, and the LIMIT.",reserved,13,reward,,
"Considering only rows with Owned since > 0, what is the total number of stations; how many stations have Primary affiliation = 'Fox'; how many have Primary affiliation = 'MyNetworkTV'; how many have Owned since <= 2001; how many Station names contain '++'; and how many Station names contain '¤¤'?","
SELECT COUNT(*) `Total stations`,
       SUM(`Primary affiliation`='Fox') `Fox stations`,
       SUM(`Primary affiliation`='MyNetworkTV') `MyNetworkTV stations`,
       SUM((`Owned since`+0)<=2001) `Owned_by_2001_or_earlier`,
       SUM(instr(`Station`,'++')>0) `Stations_with_++`,
       SUM(instr(`Station`,'¤¤')>0) `Stations_with_¤¤`
FROM `table_1_1353096_1`
WHERE (`Owned since`+0)>0;
","
SELECT COUNT(*) `Total stations`,
       SUM(col4='Fox') `Fox stations`,
       SUM(col4='MyNetworkTV') `MyNetworkTV stations`,
       SUM((col3+0)<=2001) `Owned_by_2001_or_earlier`,
       SUM(instr(col1,'++')>0) `Stations_with_++`,
       SUM(instr(col1,'¤¤')>0) `Stations_with_¤¤`
FROM `table_1_1353096_1`
WHERE (col3+0)>0;
","[(27, 0, 0, 20, 6, 5)]",table_1_1353096_1,"1) Parse intent: compute COUNT(*) plus SUMs of boolean expressions for affiliation equality, ownership-year threshold, and substring presence, with Owned since positive. 2) Map schema: use the `Primary affiliation`, `Owned since`, and `Station` fields. 3) Draft: ask for the total stations and the six specific aggregated counts (Fox, MyNetworkTV, owned by 2001 or earlier, contains '++', contains '¤¤') under the Owned since > 0 condition. 4) Validate: question mirrors each SELECT expression and the WHERE clause.",reserved,3,reward,,
Which company owns the most stations?,"
SELECT
  `City of license/Market`,
  `Station`,
  `Channel TV ( DT )`,
  `Years owned`,
  `Current Status`,
  TRIM(
    CASE 
      WHEN instr(`Channel TV ( DT )`, '(') > 0 THEN substr(`Channel TV ( DT )`, 1, instr(`Channel TV ( DT )`, '(') - 1)
      ELSE `Channel TV ( DT )`
    END
  ) AS `analog_channel`,
  TRIM(
    CASE 
      WHEN instr(`Channel TV ( DT )`, '(') > 0 THEN substr(`Channel TV ( DT )`, instr(`Channel TV ( DT )`, '(') + 1, instr(`Channel TV ( DT )`, ')') - instr(`Channel TV ( DT )`, '(') - 1)
      ELSE NULL
    END
  ) AS `digital_dt`,
  -- parse start and end years (handles single-year and ranges with en-dash)
  TRIM(
    CASE 
      WHEN instr(`Years owned`, '–') > 0 THEN substr(`Years owned`, 1, instr(`Years owned`, '–') - 1)
      WHEN instr(`Years owned`, '-') > 0 THEN substr(`Years owned`, 1, instr(`Years owned`, '-') - 1)
      ELSE `Years owned`
    END
  ) AS `start_year`,
  TRIM(
    CASE 
      WHEN instr(`Years owned`, '–') > 0 THEN substr(`Years owned`, instr(`Years owned`, '–') + 1)
      WHEN instr(`Years owned`, '-') > 0 THEN substr(`Years owned`, instr(`Years owned`, '-') + 1)
      ELSE `Years owned`
    END
  ) AS `end_year`,
  -- tenure in years (numeric), single-year and short-tenure flags
  CASE 
    WHEN ( (CASE WHEN instr(`Years owned`, '–') > 0 THEN substr(`Years owned`, instr(`Years owned`, '–') + 1) WHEN instr(`Years owned`, '-') > 0 THEN substr(`Years owned`, instr(`Years owned`, '-') + 1) ELSE `Years owned` END) GLOB '[0-9][0-9][0-9][0-9]' )
      THEN (CAST((CASE WHEN instr(`Years owned`, '–') > 0 THEN substr(`Years owned`, instr(`Years owned`, '–') + 1) WHEN instr(`Years owned`, '-') > 0 THEN substr(`Years owned`, instr(`Years owned`, '-') + 1) ELSE `Years owned` END) AS INTEGER)
            - CAST((CASE WHEN instr(`Years owned`, '–') > 0 THEN substr(`Years owned`, 1, instr(`Years owned`, '–') - 1) WHEN instr(`Years owned`, '-') > 0 THEN substr(`Years owned`, 1, instr(`Years owned`, '-') - 1) ELSE `Years owned` END) AS INTEGER) + 1)
    ELSE NULL
  END AS `duration_years`,
  CASE 
    WHEN ( (CASE WHEN instr(`Years owned`, '–') = 0 AND instr(`Years owned`, '-') = 0 AND length(trim(`Years owned`)) = 4 THEN 1 ELSE 0 END) ) = 1 THEN 1
    WHEN ( (CASE 
              WHEN instr(`Years owned`, '–') > 0 THEN (CAST(substr(`Years owned`, instr(`Years owned`, '–') + 1) AS INTEGER) - CAST(substr(`Years owned`, 1, instr(`Years owned`, '–') - 1) AS INTEGER) + 1)
              WHEN instr(`Years owned`, '-') > 0 THEN (CAST(substr(`Years owned`, instr(`Years owned`, '-') + 1) AS INTEGER) - CAST(substr(`Years owned`, 1, instr(`Years owned`, '-') - 1) AS INTEGER) + 1)
              ELSE NULL
            END) IS NOT NULL AND (CASE 
              WHEN instr(`Years owned`, '–') > 0 THEN (CAST(substr(`Years owned`, instr(`Years owned`, '–') + 1) AS INTEGER) - CAST(substr(`Years owned`, 1, instr(`Years owned`, '–') - 1) AS INTEGER) + 1)
              WHEN instr(`Years owned`, '-') > 0 THEN (CAST(substr(`Years owned`, instr(`Years owned`, '-') + 1) AS INTEGER) - CAST(substr(`Years owned`, 1, instr(`Years owned`, '-') - 1) AS INTEGER) + 1)
              ELSE NULL
            END) <= 2 THEN 1
    ELSE 0
  END AS `short_tenure_flag`,
  -- extract owner company string after 'owned by '
  CASE 
    WHEN instr(`Current Status`, 'owned by ') > 0 THEN trim(substr(`Current Status`, instr(`Current Status`, 'owned by ') + 9))
    ELSE NULL
  END AS `owner_company`,
  -- corporate footprint: how many entries in this table list the same owner
  (SELECT COUNT(*) FROM `table_1_1353096_2` t2
     WHERE (CASE WHEN instr(t2.`Current Status`, 'owned by ') > 0 THEN trim(substr(t2.`Current Status`, instr(t2.`Current Status`, 'owned by ') + 9)) ELSE NULL END)
           = (CASE WHEN instr(`Current Status`, 'owned by ') > 0 THEN trim(substr(`Current Status`, instr(`Current Status`, 'owned by ') + 9)) ELSE NULL END)
  ) AS `owner_footprint_count`,
  -- markers and provenance notes for exhibit captions
  CASE 
    WHEN `Station` LIKE '%¤¤%' OR `Station` LIKE '%++%' OR `Station` LIKE '%**%' THEN 1
    ELSE 0
  END AS `has_editorial_marker`,
  (CASE WHEN `Station` LIKE '%¤¤%' THEN '¤¤; ' ELSE '' END) ||
  (CASE WHEN `Station` LIKE '%++%' THEN '++; ' ELSE '' END) ||
  (CASE WHEN `Station` LIKE '%**%' THEN '**; ' ELSE '' END) AS `marker_types`,
  -- quick helper: is Fox affiliate (useful for dial labeling in exhibit)
  CASE WHEN `Current Status` LIKE '%Fox affiliate%' THEN 1 ELSE 0 END AS `is_fox_affiliate`
FROM `table_1_1353096_2`
ORDER BY `owner_footprint_count` DESC, `start_year` ASC, `City of license/Market`;
","SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  TRIM(
    CASE 
      WHEN instr(col2, '(') > 0 THEN substr(col2, 1, instr(col2, '(') - 1)
      ELSE col2
    END
  ) AS `analog_channel`,
  TRIM(
    CASE 
      WHEN instr(col2, '(') > 0 THEN substr(col2, instr(col2, '(') + 1, instr(col2, ')') - instr(col2, '(') - 1)
      ELSE NULL
    END
  ) AS `digital_dt`,
  TRIM(
    CASE 
      WHEN instr(col3, '–') > 0 THEN substr(col3, 1, instr(col3, '–') - 1)
      WHEN instr(col3, '-') > 0 THEN substr(col3, 1, instr(col3, '-') - 1)
      ELSE col3
    END
  ) AS `start_year`,
  TRIM(
    CASE 
      WHEN instr(col3, '–') > 0 THEN substr(col3, instr(col3, '–') + 1)
      WHEN instr(col3, '-') > 0 THEN substr(col3, instr(col3, '-') + 1)
      ELSE col3
    END
  ) AS `end_year`,
  CASE 
    WHEN ( (CASE WHEN instr(col3, '–') > 0 THEN substr(col3, instr(col3, '–') + 1) WHEN instr(col3, '-') > 0 THEN substr(col3, instr(col3, '-') + 1) ELSE col3 END) GLOB '[0-9][0-9][0-9][0-9]' )
      THEN (CAST((CASE WHEN instr(col3, '–') > 0 THEN substr(col3, instr(col3, '–') + 1) WHEN instr(col3, '-') > 0 THEN substr(col3, instr(col3, '-') + 1) ELSE col3 END) AS INTEGER)
            - CAST((CASE WHEN instr(col3, '–') > 0 THEN substr(col3, 1, instr(col3, '–') - 1) WHEN instr(col3, '-') > 0 THEN substr(col3, 1, instr(col3, '-') - 1) ELSE col3 END) AS INTEGER) + 1)
    ELSE NULL
  END AS `duration_years`,
  CASE 
    WHEN instr(col3, '–') = 0 AND instr(col3, '-') = 0 AND length(trim(col3)) = 4 THEN 1
    WHEN instr(col3, '–') > 0 AND (CAST(substr(col3, instr(col3, '–') + 1) AS INTEGER) - CAST(substr(col3, 1, instr(col3, '–') - 1) AS INTEGER) + 1) <= 2 THEN 1
    WHEN instr(col3, '-') > 0 AND (CAST(substr(col3, instr(col3, '-') + 1) AS INTEGER) - CAST(substr(col3, 1, instr(col3, '-') - 1) AS INTEGER) + 1) <= 2 THEN 1
    ELSE 0
  END AS `short_tenure_flag`,
  CASE 
    WHEN instr(col4, 'owned by ') > 0 THEN trim(substr(col4, instr(col4, 'owned by ') + 9))
    ELSE NULL
  END AS `owner_company`,
  (SELECT COUNT(*) FROM `table_1_1353096_2` t2
     WHERE (CASE WHEN instr(t2.col4, 'owned by ') > 0 THEN trim(substr(t2.col4, instr(t2.col4, 'owned by ') + 9)) ELSE NULL END)
           = (CASE WHEN instr(col4, 'owned by ') > 0 THEN trim(substr(col4, instr(col4, 'owned by ') + 9)) ELSE NULL END)
  ) AS `owner_footprint_count`,
  CASE 
    WHEN col1 LIKE '%¤¤%' OR col1 LIKE '%++%' OR col1 LIKE '%**%' THEN 1
    ELSE 0
  END AS `has_editorial_marker`,
  (CASE WHEN col1 LIKE '%¤¤%' THEN '¤¤; ' ELSE '' END) ||
  (CASE WHEN col1 LIKE '%++%' THEN '++; ' ELSE '' END) ||
  (CASE WHEN col1 LIKE '%**%' THEN '**; ' ELSE '' END) AS `marker_types`,
  CASE WHEN col4 LIKE '%Fox affiliate%' THEN 1 ELSE 0 END AS `is_fox_affiliate`
FROM `table_1_1353096_2`
ORDER BY `owner_footprint_count` DESC, `start_year` ASC, col0;","[('boston', 'wcvb-tv ** 1', '5 (20)', '1986', 'abc affiliate owned by hearst television', '5', '20', '1986', '1986', 1, 1, 'hearst television', 15, 1, '**; ', 0), ('dallas – fort worth', 'kdaf **', '33 (32)', '1986–1995', 'cw affiliate owned by tribune broadcasting', '33', '32', '1986', '1995', 10, 0, 'tribune broadcasting', 15, 1, '**; ', 0), ('salt lake city', 'kstu', '13 (28)', '1990–2008', 'fox affiliate owned by local tv', '13', '28', '1990', '2008', 19, 0, 'local tv', 15, 0, '', 1), ('atlanta', 'watl-tv', '36 (25)', '1993–1995', 'mynetworktv affiliate owned by gannett company', '36', '25', '1993', '1995', 3, 0, 'gannett company', 15, 0, '', 0), ('birmingham – tuscaloosa – anniston', 'wbrc-tv', '6 (50)', '1995–2008', 'fox affiliate owned by raycom media', '6', '50', '1995', '2008', 14, 0, 'raycom media', 15, 0, '', 1), ('denver', 'kdvr', '31 (32)', '1995–2008', 'fox affiliate owned by local tv', '31', '32', '1995', '2008', 14, 0, 'local tv', 15, 0, '', 1), ('fort collins, colorado', 'kfct (satellite of kdvr)', '22 (21)', '1995–2008', 'fox affiliate owned by local tv', '22', '21', '1995', '2008', 14, 0, 'local tv', 15, 0, '', 1), ('high point – greensboro - winston-salem', 'wghp', '8 (35)', '1995–2008', 'fox affiliate owned by local tv', '8', '35', '1995', '2008', 14, 0, 'local tv', 15, 0, '', 1), ('cleveland – akron', 'wjw-tv ++', '8 (8)', '1997–2008', 'fox affiliate owned by local tv', '8', '8', '1997', '2008', 12, 0, 'local tv', 15, 1, '++; ', 1), ('kansas city, missouri', 'wdaf-tv ++', '4 (34)', '1997–2008', 'fox affiliate owned by local tv', '4', '34', '1997', '2008', 12, 0, 'local tv', 15, 1, '++; ', 1), ('saint louis', 'ktvi ++', '2 (43)', '1997–2008', 'fox affiliate owned by local tv', '2', '43', '1997', '2008', 12, 0, 'local tv', 15, 1, '++; ', 1), ('portland, oregon', 'kptv ¤¤', '12 (12)', '2001–2002', 'fox affiliate owned by meredith corporation', '12', '12', '2001', '2002', 2, 1, 'meredith corporation', 15, 1, '¤¤; ', 1), ('salt lake city', 'ktvx ¤¤', '4 (40)', '2001', 'abc affiliate owned by nexstar broadcasting group', '4', '40', '2001', '2001', 1, 1, 'nexstar broadcasting group', 15, 1, '¤¤; ', 0), ('san antonio', 'kmol-tv ¤¤ (now woai-tv )', '4 (48)', '2001', 'nbc affiliate owned by sinclair broadcast group', '4', '48', '2001', '2001', 1, 1, 'sinclair broadcast group', 15, 1, '¤¤; ', 0), ('san francisco – oakland – san jose', 'kbhk-tv ¤¤ (now kbcw )', '44 (45)', '2001–2002', 'cw affiliate owned by cbs corporation', '44', '45', '2001', '2002', 2, 1, 'cbs corporation', 15, 1, '¤¤; ', 0)]",table_1_1353096_2,"STEP 1: Parse the SQL intent — the query extracts station info, parses channel and years, derives an owner_company string from the 'Current Status' field, computes owner_footprint_count by counting rows with the same extracted owner string, and orders results by that count (largest footprint first). STEP 2: Determine ambiguity type — Entity Vagueness fits: the phrase ""company/owner"" and ""most stations"" can mean several different entities or measures (corporate parent vs subsidiary, rows in this table vs distinct markets vs active affiliates). STEP 3: Draft the question — a concise ambiguous NL question that the SQL can meaningfully answer is: ""Which company owns the most stations?"" STEP 4: Explain the ambiguity and interpretations — in the original query this would be interpreted as counting table rows whose 'Current Status' contains the exact substring after 'owned by ' (so it returns the owner string with the highest row count), but the phrase could also mean counting distinct markets, counting only currently active stations, or aggregating subsidiaries under a single corporate parent in a different query.",persona,"An analog‑TV dial conservator building an augmented‑reality museum exhibit that reconstructs local broadcast lineups and station identities from the 1980s–2000s. Goals: Recreate authentic analog-to-digital dial positions for each station (analog channel vs. digital/DT) so the AR dial shows correct tunings and labels. Highlight stations that changed hands or affiliations briefly (single-year ownerships or short windows) to annotate transitional periods in the exhibit. Map corporate footprints (e.g., Local TV / Raycom / Tribune) across markets and time to create an overlay showing consolidation waves. Identify entries with editorial footnotes or special markers (¤¤, ++, **) so museum captions can include provenance or exceptional-case explanations. Example Queries: SELECT `City of license/Market`, `Station`, `Channel TV ( DT )`, `Years owned`, `Current Status` FROM `table_1_1353096_2` WHERE `Current Status` LIKE '%Fox affiliate%' AND `Years owned` LIKE '%1995%'; SELECT `Station`, `City of license/Market`, `Channel TV ( DT )`, `Years owned`, `Current Status` FROM `table_1_1353096_2` WHERE `Years owned` REGEXP '^[0-9]{4}$' OR `Years owned` LIKE '%2001%' OR `Years owned` LIKE '%1986%'; SELECT `Station`, `City of license/Market`, `Channel TV ( DT )`, `Years owned`, `Current Status` FROM `table_1_1353096_2` WHERE `Station` LIKE '%¤%' OR `Station` LIKE '%+%' OR `Station` LIKE '%*%';",reward,,"type: Entity Vagueness | explanation: The query treats 'owner' as the literal substring after 'owned by ' and counts table rows (owner_footprint_count), whereas the natural language question could instead ask about corporate parent vs subsidiary aggregation, distinct markets served, or only currently active stations — all different interpretations that would need different SQL."
"Show the Player and compute Set Win % = (Sets Won/Played)*100, Legs Margin = (Legs Won - Legs Lost), and Performance Score = ((Sets Won - Sets Lost)/(Sets Won + Sets Lost + 0.0))*50 + ((100+)/Played)*30 + ((3-dart Average)/100)*20 for all players where Played > 1 and (Legs Won - Legs Lost) > 0?","
SELECT `Player`, (`Sets Won`/`Played`)*100 `Set Win %`, (`Legs Won` - `Legs Lost`) `Legs Margin`, (((`Sets Won` - `Sets Lost`)/(`Sets Won` + `Sets Lost` + 0.0))*50 + ((`100+`)/`Played`)*30 + (`3-dart Average`/100)*20) `Performance Score` FROM `table_1_13535824_2` WHERE `Played`>1 AND (`Legs Won` - `Legs Lost`)>0;
","
SELECT col0, (col2/col1)*100 `Set Win %`, (col4 - col5) `Legs Margin`, (((col2 - col3)/(col2 + col3 + 0.0))*50 + ((col6)/col1)*30 + (col10/100)*20) `Performance Score` FROM `table_1_13535824_2` WHERE col1>1 AND (col4 - col5)>0;
","[('anastasia dobromyslova', 200.0, 14.0, 385.814), ('trina gulliver', 133.33333333333331, 5.0, 292.1468571428572)]",table_1_13535824_2,"Parse intent: return Player and three computed fields for players passing two filters. Map schema: use Player, Sets Won, Sets Lost, Played, Legs Won, Legs Lost, 100+, and 3-dart Average in the formulas. Draft: ask for the exact formulas including the +0.0 denominator adjustment and the weighted sum for Performance Score. Validate: question mirrors SQL selections, calculations, and WHERE conditions.",reserved,4,reward,,
"For Specification = 'Maximum length' and Gender = 'Male & female', what are the numeric values (with unit suffixes 'cm','g','mm' stripped and converted to numbers) of Junior High School (12–15 yrs), Senior High School (15–18 yrs), and University students and Adults (18yrs+), and what is the Senior_vs_Junior_Delta computed as (Senior High numeric) - (Junior High numeric), with the result ordered by Senior_vs_Junior_Delta descending?","
SELECT
  `Specification`,
  `Gender`,
  REPLACE(REPLACE(REPLACE(REPLACE(`Junior High School (12–15 yrs)`,'`',''),'cm',''),'g',''),'mm','')+0 `Junior High Numeric`,
  REPLACE(REPLACE(REPLACE(REPLACE(`Senior High School (15–18 yrs)`,'`',''),'cm',''),'g',''),'mm','')+0 `Senior High Numeric`,
  REPLACE(REPLACE(REPLACE(REPLACE(`University students and Adults (18yrs+)`,'`',''),'cm',''),'g',''),'mm','')+0 `University Numeric`,
  (REPLACE(REPLACE(REPLACE(REPLACE(`Senior High School (15–18 yrs)`,'`',''),'cm',''),'g',''),'mm','')+0) - (REPLACE(REPLACE(REPLACE(REPLACE(`Junior High School (12–15 yrs)`,'`',''),'cm',''),'g',''),'mm','')+0) `Senior_vs_Junior_Delta`
FROM (VALUES
  ('`Maximum length`','`Male & female`','`114cm`','`117cm`','`120cm`'),
  ('`Minimum weight`','`Male`','`440g`','`480g`','`510g`'),
  ('`Minimum weight`','`Female`','`400g`','`420g`','`440g`'),
  ('`Minimum diameter of sakigawa`','`Male`','`25mm`','`26mm`','`26mm`'),
  ('`Minimum diameter of sakigawa`','`Female`','`24mm`','`25mm`','`25mm`')
) AS `t`(`Specification`,`Gender`,`Junior High School (12–15 yrs)`,`Senior High School (15–18 yrs)`,`University students and Adults (18yrs+)`)
WHERE `Specification` = '`Maximum length`' AND `Gender` = '`Male & female`'
GROUP BY `Specification`,`Gender`,`Junior High Numeric`,`Senior High Numeric`,`University Numeric`,`Senior_vs_Junior_Delta`
ORDER BY `Senior_vs_Junior_Delta` DESC;
","SELECT
  col0,
  col1,
  REPLACE(REPLACE(REPLACE(REPLACE(col2,'`',''),'cm',''),'g',''),'mm','')+0 AS `Junior High Numeric`,
  REPLACE(REPLACE(REPLACE(REPLACE(`Senior High School (15–18 yrs)`,'`',''),'cm',''),'g',''),'mm','')+0 AS `Senior High Numeric`,
  REPLACE(REPLACE(REPLACE(REPLACE(col4,'`',''),'cm',''),'g',''),'mm','')+0 AS `University Numeric`,
  (REPLACE(REPLACE(REPLACE(REPLACE(`Senior High School (15–18 yrs)`,'`',''),'cm',''),'g',''),'mm','')+0) - (REPLACE(REPLACE(REPLACE(REPLACE(col2,'`',''),'cm',''),'g',''),'mm','')+0) AS `Senior_vs_Junior_Delta`
FROM (
  SELECT 'Maximum length' AS col0, 'Male & female' AS col1, '114cm' AS col2, '117cm' AS `Senior High School (15–18 yrs)`, '120cm' AS col4
  UNION ALL
  SELECT 'Minimum weight','Male','440g','480g','510g'
  UNION ALL
  SELECT 'Minimum weight','Female','400g','420g','440g'
  UNION ALL
  SELECT 'Minimum diameter of sakigawa','Male','25mm','26mm','26mm'
  UNION ALL
  SELECT 'Minimum diameter of sakigawa','Female','24mm','25mm','25mm'
) AS `t`
WHERE col0 = 'Maximum length' AND col1 = 'Male & female'
GROUP BY col0,col1,`Junior High Numeric`,`Senior High Numeric`,`University Numeric`,`Senior_vs_Junior_Delta`
ORDER BY `Senior_vs_Junior_Delta` DESC;","[('Maximum length', 'Male & female', 114, 117, 120, 3)]",table_1_13555999_1,"1) The SQL filters to Specification = 'Maximum length' and Gender = 'Male & female', selects the three age-group columns with unit characters removed and cast to numbers, and computes Senior_vs_Junior_Delta as SeniorHighNumeric - JuniorHighNumeric, ordering by that delta. 2) Map the table columns: Specification, Gender, Junior High School (12–15 yrs), Senior High School (15–18 yrs), University students and Adults (18yrs+). 3) Draft a question requesting those numeric values (with units stripped) and the delta for the specified Specification and Gender, ordered by the delta descending. 4) Validate that the question includes the filter, all three numeric columns, the calculation, and the ordering.",reserved,9,reward,,
"Which five players, identified by extracting the name from the 'High points' column before the ' (' substring, have the highest number of wins, and for each such player what are (1) the number of games they were the high scorer (COUNT of rows), (2) the number of wins (counting rows where Score begins with 'W'), and (3) their win percentage computed as wins * 100.0 / games rounded to one decimal, considering only rows where 'High points' or 'Score' is not empty and grouping by the extracted player name?","
SELECT ALL
  substr(`High points`,1,instr(`High points`,' (')-1) AS `TopScorer`,
  COUNT(*) `Games`,
  SUM(substr(`Score`,1,1)='W') `Wins`,
  ROUND(SUM(substr(`Score`,1,1)='W')*100.0/COUNT(*),1) `Win%`
FROM `table_1_13557843_5`
WHERE `High points`<>'' AND `High points`!='' OR `Score`<>''
GROUP BY substr(`High points`,1,instr(`High points`,' (')-1)
ORDER BY `Wins` DESC
LIMIT 5;
","
SELECT ALL
  substr(col4,1,instr(col4,' (')-1) AS `TopScorer`,
  COUNT(*) `Games`,
  SUM(substr(col3,1,1)='W') `Wins`,
  ROUND(SUM(substr(col3,1,1)='W')*100.0/COUNT(*),1) `Win%`
FROM `table_1_13557843_5`
WHERE col4<>'' AND col4!='' OR col3<>''
GROUP BY substr(col4,1,instr(col4,' (')-1)
ORDER BY `Wins` DESC
LIMIT 5;
","[('walt williams', 3, 0, 0.0), ('doug christie , carlos rogers', 1, 0, 0.0), ('doug christie', 2, 0, 0.0), ('damon stoudamire , walt williams', 1, 0, 0.0), ('damon stoudamire', 6, 0, 0.0)]",table_1_13557843_5,"Parse intent: compute per-top-scorer totals by extracting the name portion of `High points`, counting games, summing wins where the first character of `Score` is 'W', and computing a rounded percentage; then sort by wins and limit to five. Map schema: use `High points` for TopScorer and `Score` to detect wins, excluding empty rows. Draft: ask for these exact aggregates and grouping. Validate: include COUNT(*) as Games, SUM(condition) as Wins, ROUND(...,1) as Win%, the non-empty filter, GROUP BY extracted name, ORDER BY Wins DESC, LIMIT 5.",reserved,12,reward,,
"Rank all clubs by league points (use point difference as the tiebreaker) and show played, league points, point difference, try difference, points per game, conceded per game, tries conceded per game, try-bonus conversion rate, and flags for teams conceding more than the division average, with weak try defence, low scoring, or poor try-bonus conversion.","
WITH stats AS (
  SELECT
    AVG(CAST(`Points against` AS FLOAT)/NULLIF(CAST(`Played` AS FLOAT),0)) AS avg_conceded_per_game,
    AVG(CAST(`Tries against` AS FLOAT)/NULLIF(CAST(`Played` AS FLOAT),0)) AS avg_tries_against_per_game,
    AVG(CAST(`Points for` AS FLOAT)/NULLIF(CAST(`Played` AS FLOAT),0)) AS avg_points_for_per_game,
    AVG(CAST(`Try bonus` AS FLOAT)/NULLIF(CAST(`Tries for` AS FLOAT),0)) AS avg_try_bonus_rate
  FROM table_1_13564637_3
)
SELECT
  `Club`,
  CAST(`Played` AS INTEGER) AS played,
  CAST(`Points` AS INTEGER) AS league_points,
  (CAST(`Points for` AS INTEGER) - CAST(`Points against` AS INTEGER)) AS point_diff,
  (CAST(`Tries for` AS INTEGER) - CAST(`Tries against` AS INTEGER)) AS try_diff,
  ROUND(CAST(`Points for` AS FLOAT)/NULLIF(CAST(`Played` AS FLOAT),0), 2) AS points_per_game,
  ROUND(CAST(`Points against` AS FLOAT)/NULLIF(CAST(`Played` AS FLOAT),0), 2) AS conceded_per_game,
  ROUND(CAST(`Tries against` AS FLOAT)/NULLIF(CAST(`Played` AS FLOAT),0), 2) AS tries_against_per_game,
  ROUND(CAST(`Try bonus` AS FLOAT)/NULLIF(CAST(`Tries for` AS FLOAT),0), 3) AS try_bonus_rate,
  CASE WHEN (CAST(`Points against` AS FLOAT)/NULLIF(CAST(`Played` AS FLOAT),0)) > stats.avg_conceded_per_game THEN 1 ELSE 0 END AS exploitable_high_points_conceded,
  CASE WHEN (CAST(`Tries against` AS FLOAT)/NULLIF(CAST(`Played` AS FLOAT),0)) > stats.avg_tries_against_per_game THEN 1 ELSE 0 END AS exploitable_weak_try_defence,
  CASE WHEN (CAST(`Points for` AS FLOAT)/NULLIF(CAST(`Played` AS FLOAT),0)) < stats.avg_points_for_per_game THEN 1 ELSE 0 END AS internal_low_scoring,
  CASE WHEN (CAST(`Try bonus` AS FLOAT)/NULLIF(CAST(`Tries for` AS FLOAT),0)) < stats.avg_try_bonus_rate THEN 1 ELSE 0 END AS internal_poor_trybonus_conversion
FROM table_1_13564637_3, stats
ORDER BY league_points DESC, point_diff DESC;
","
WITH stats AS (
  SELECT
    AVG(CAST(col6 AS FLOAT)/NULLIF(CAST(col1 AS FLOAT),0)) AS avg_conceded_per_game,
    AVG(CAST(col8 AS FLOAT)/NULLIF(CAST(col1 AS FLOAT),0)) AS avg_tries_against_per_game,
    AVG(CAST(col5 AS FLOAT)/NULLIF(CAST(col1 AS FLOAT),0)) AS avg_points_for_per_game,
    AVG(CAST(col9 AS FLOAT)/NULLIF(CAST(col7 AS FLOAT),0)) AS avg_try_bonus_rate
  FROM table_1_13564637_3
)
SELECT
  col0,
  CAST(col1 AS INTEGER) AS played,
  CAST(col11 AS INTEGER) AS league_points,
  (CAST(col5 AS INTEGER) - CAST(col6 AS INTEGER)) AS point_diff,
  (CAST(col7 AS INTEGER) - CAST(col8 AS INTEGER)) AS try_diff,
  ROUND(CAST(col5 AS FLOAT)/NULLIF(CAST(col1 AS FLOAT),0), 2) AS points_per_game,
  ROUND(CAST(col6 AS FLOAT)/NULLIF(CAST(col1 AS FLOAT),0), 2) AS conceded_per_game,
  ROUND(CAST(col8 AS FLOAT)/NULLIF(CAST(col1 AS FLOAT),0), 2) AS tries_against_per_game,
  ROUND(CAST(col9 AS FLOAT)/NULLIF(CAST(col7 AS FLOAT),0), 3) AS try_bonus_rate,
  CASE WHEN (CAST(col6 AS FLOAT)/NULLIF(CAST(col1 AS FLOAT),0)) > stats.avg_conceded_per_game THEN 1 ELSE 0 END AS exploitable_high_points_conceded,
  CASE WHEN (CAST(col8 AS FLOAT)/NULLIF(CAST(col1 AS FLOAT),0)) > stats.avg_tries_against_per_game THEN 1 ELSE 0 END AS exploitable_weak_try_defence,
  CASE WHEN (CAST(col5 AS FLOAT)/NULLIF(CAST(col1 AS FLOAT),0)) < stats.avg_points_for_per_game THEN 1 ELSE 0 END AS internal_low_scoring,
  CASE WHEN (CAST(col9 AS FLOAT)/NULLIF(CAST(col7 AS FLOAT),0)) < stats.avg_try_bonus_rate THEN 1 ELSE 0 END AS internal_poor_trybonus_conversion
FROM table_1_13564637_3, stats
ORDER BY league_points DESC, point_diff DESC;
","[('penarth rfc', 22, 84, 351, 52, 26.05, 10.09, 1.14, 0.117, 0, 0, 0, 0), ('tylorstown rfc', 22, 84, 277, 41, 27.18, 14.59, 1.59, 0.132, 0, 0, 0, 0), ('st. peters rfc', 22, 78, 287, 53, 22.59, 9.55, 0.86, 0.125, 0, 0, 0, 0), ('aberdare rfc', 22, 69, 127, 24, 23.55, 17.77, 2.23, 0.123, 0, 0, 0, 0), ('heol y cyw rfc', 22, 58, 101, 8, 19.55, 14.95, 1.86, 0.041, 0, 0, 0, 1), ('pentyrch rfc', 22, 57, 12, -1, 18.91, 18.36, 2.55, 0.091, 1, 1, 0, 0), ('llanishen rfc', 22, 54, -4, -9, 14.64, 14.82, 1.86, 0.063, 0, 0, 1, 1), ('brecon rfc', 22, 45, -5, -2, 16.68, 16.91, 2.09, 0.114, 0, 0, 1, 0), ('llandaff north rfc', 22, 34, -242, -42, 14.77, 25.77, 3.5, 0.086, 1, 1, 1, 1), ('fairwater rfc', 22, 33, -143, -18, 11.5, 18.0, 2.27, 0.063, 0, 0, 1, 1), ('treherbert rfc', 22, 28, -382, -49, 13.18, 30.55, 3.91, 0.081, 1, 1, 1, 1), ('llandaff rfc', 22, 14, -379, -57, 10.41, 27.64, 4.0, 0.032, 1, 1, 1, 1), ('club', 0, 0, 0, 0, None, None, None, None, 0, 0, 0, 0)]",table_1_13564637_3,"As the club's performance analyst I speak in practical terms — points/game, try counts and try-bonus conversion are my bread and butter and I expect a season table summary. The query computes per-team rates, point and try differences, try-bonus conversion and compares each team to league averages, then ranks by league points and point difference. It pulls Club, Played, Points, Points for/against, Tries for/against and Try bonus to build those metrics. Draft question: Rank all clubs by league points (use point difference as the tiebreaker) and show played, league points, point difference, try difference, points per game, conceded per game, tries conceded per game, try-bonus conversion rate, and flags for teams that concede more points/tries than the league average or score/convert below the league average. This matches the query intent and only asks for fields and comparisons present in the SQL.",persona,"Club performance analyst for a WRU Division Three South East team who uses the season table to measure team and opponent performance, identify weaknesses, and inform training and match preparation. They need quick, reproducible SQL-style queries against the season table to produce tactical and recruitment insights. Goals: Rank teams by league points while also showing offensive/defensive balance (point difference and try difference). Identify opponents with exploitable weaknesses (high points conceded per game or low try defence) to inform match plans. Spot internal issues such as low points-per-game or failure to convert tries into bonus points, to guide training priorities and recruitment. Example Queries: /* Full standings with point & try differentials and points per game */
SELECT ""Club"",
       CAST(""Played"" AS INTEGER) AS played,
       CAST(""Points"" AS INTEGER) AS league_points,
       (CAST(""Points for"" AS INTEGER) - CAST(""Points against"" AS INTEGER)) AS point_diff,
       (CAST(""Tries for"" AS INTEGER) - CAST(""Tries against"" AS INTEGER)) AS try_diff,
       ROUND(CAST(""Points for"" AS FLOAT) / NULLIF(CAST(""Played"" AS FLOAT),0), 2) AS points_per_game
FROM table_1_13564637_3
ORDER BY league_points DESC, point_diff DESC; /* Opponents conceding the most points per game (targets for defensive tactics) */
SELECT ""Club"",
       CAST(""Points against"" AS INTEGER) AS points_conceded,
       CAST(""Played"" AS INTEGER) AS played,
       ROUND(CAST(""Points against"" AS FLOAT) / NULLIF(CAST(""Played"" AS FLOAT),0), 2) AS conceded_per_game
FROM table_1_13564637_3
ORDER BY conceded_per_game DESC
LIMIT 5; /* Teams with relatively high try output but low league points (potentially dangerous, fast-scoring teams) */
SELECT ""Club"",
       CAST(""Tries for"" AS INTEGER) AS tries_for,
       CAST(""Tries against"" AS INTEGER) AS tries_against,
       (CAST(""Tries for"" AS INTEGER) - CAST(""Tries against"" AS INTEGER)) AS try_diff,
       CAST(""Points"" AS INTEGER) AS league_points,
       ROUND(CAST(""Tries for"" AS FLOAT) / NULLIF(CAST(""Played"" AS FLOAT),0), 2) AS tries_per_game
FROM table_1_13564637_3
WHERE CAST(""Tries for"" AS INTEGER) >= 40
ORDER BY league_points ASC, tries_for DESC;",reward,,
"For Castile and León, Galicia and Andalusia, how much renewable power did they produce when considering only communities above the average renewable generation?","
SELECT
  SUM(CASE WHEN `Autonomous Community` = 'Castile and León' THEN `Hydroelectric power` ELSE 0 END) AS `Castile and León`,
  SUM(CASE WHEN `Autonomous Community` = 'Galicia' THEN `Wind power` ELSE 0 END) AS `Galicia`,
  SUM(CASE WHEN `Autonomous Community` = 'Andalusia' THEN `Biomass power` ELSE 0 END) AS `Andalusia`
FROM `table_1_13566548_1`
WHERE `Total Renewable Generation` > (SELECT AVG(`Total Renewable Generation`) FROM `table_1_13566548_1`)
LIMIT 1;
","
SELECT
  SUM(CASE WHEN col0 = 'Castile and León' THEN col1 ELSE 0 END) AS `Castile and León`,
  SUM(CASE WHEN col0 = 'Galicia' THEN col2 ELSE 0 END) AS `Galicia`,
  SUM(CASE WHEN col0 = 'Andalusia' THEN col4 ELSE 0 END) AS `Andalusia`
FROM `table_1_13566548_1`
WHERE col6 > (SELECT AVG(col6) FROM `table_1_13566548_1`)
LIMIT 1;
","[(0, 0, 0)]",table_1_13566548_1,"STEP 1: Parse SQL intent — The query returns three summed values (hydroelectric for Castile and León, wind for Galicia, biomass for Andalusia) but only includes rows where Total Renewable Generation is greater than the table-wide average; because each community appears once this effectively returns each specified source value for that community if that community's total renewable generation > average, otherwise 0. STEP 2: Determine ambiguity type — Scope ambiguity fits well: the phrase ""considering only communities above the average"" could mean (a) filter to communities whose Total Renewable Generation exceeds the average (the SQL interpretation) or (b) compute how much each community's production exceeds the average (an alternate meaning), and additionally there is entity vagueness about which ""renewable power"" metric is intended (specific source vs total). STEP 3: Draft the question — ""For Castile and León, Galicia and Andalusia, how much renewable power did they produce when considering only communities above the average renewable generation?"" STEP 4: Explain the ambiguity — In the SQL the clause ""above the average"" is a filter on rows (only include a community's specific source value if that community's Total Renewable Generation > overall average). The question can instead be read as asking for each community's total renewable generation, or asking for the amount by which each community's production exceeds the average (difference), or as asking to list only communities that are above average, causing different SQL logic and different returned numbers.",reserved,24,reward,,"type: Scope ambiguity | explanation: The SQL interprets ""above the average"" as a row filter (include each community's specific source value only if that community's Total Renewable Generation > overall average). The natural question could instead mean (a) return each community's total renewable generation, (b) return the amount by which each community's production exceeds the average (difference), or (c) list only the communities that are above average — each interpretation leads to different SQL and different results."
"Give me a combined set for the exhibit: SELinux vs AppArmor pairings, the demo-feature candidates (PaX/Exec Shield or grsecurity/RSBAC='Yes'), and grsecurity Optional vs Yes pairings, with each distro's MAC, executable-space protection, grsecurity, RSBAC and any Unknown flags.","
WITH
`candidates` AS (
  SELECT
    `Distribution`,
    `Compile time buffer checks`,
    `Mandatory access control`,
    `Software executable space protection`,
    `grsecurity`,
    `RSBAC`,
    CASE
      WHEN `Compile time buffer checks` = 'Unknown'
        OR `Mandatory access control` = 'Unknown'
        OR `grsecurity` = 'Unknown'
        OR `RSBAC` = 'Unknown'
      THEN 'Has Unknown'
      ELSE 'Known'
    END AS `Unknown_flag`
  FROM `table_1_1357052_6`
),
`selinux_vs_apparmor_pairs` AS (
  SELECT
    'SELinux_vs_AppArmor' AS `contrast_type`,
    c1.`Distribution` AS `d1_Distribution`,
    c1.`Mandatory access control` AS `d1_Mandatory access control`,
    c1.`Software executable space protection` AS `d1_Software executable space protection`,
    c1.`grsecurity` AS `d1_grsecurity`,
    c1.`RSBAC` AS `d1_RSBAC`,
    c1.`Unknown_flag` AS `d1_Unknown_flag`,
    c2.`Distribution` AS `d2_Distribution`,
    c2.`Mandatory access control` AS `d2_Mandatory access control`,
    c2.`Software executable space protection` AS `d2_Software executable space protection`,
    c2.`grsecurity` AS `d2_grsecurity`,
    c2.`RSBAC` AS `d2_RSBAC`,
    c2.`Unknown_flag` AS `d2_Unknown_flag`,
    NULL AS `role`
  FROM `candidates` c1
  JOIN `candidates` c2 ON c1.`Distribution` <> c2.`Distribution`
  WHERE c1.`Mandatory access control` LIKE '%SELinux%' AND c2.`Mandatory access control` LIKE '%AppArmor%'
),
`feature_candidates` AS (
  SELECT
    'Feature_candidates' AS `contrast_type`,
    `Distribution` AS `d1_Distribution`,
    `Mandatory access control` AS `d1_Mandatory access control`,
    `Software executable space protection` AS `d1_Software executable space protection`,
    `grsecurity` AS `d1_grsecurity`,
    `RSBAC` AS `d1_RSBAC`,
    CASE WHEN `Compile time buffer checks` = 'Unknown' OR `Mandatory access control` = 'Unknown' THEN 'Has Unknown' ELSE 'Known' END AS `d1_Unknown_flag`,
    NULL AS `d2_Distribution`,
    NULL AS `d2_Mandatory access control`,
    NULL AS `d2_Software executable space protection`,
    NULL AS `d2_grsecurity`,
    NULL AS `d2_RSBAC`,
    NULL AS `d2_Unknown_flag`,
    CASE
      WHEN `Software executable space protection` IN ('PaX','Exec Shield') OR `grsecurity` = 'Yes' OR `RSBAC` = 'Yes'
      THEN 'Demo candidate'
      ELSE 'Other'
    END AS `role`
  FROM `table_1_1357052_6`
),
`optional_vs_yes_grsec_pairs` AS (
  SELECT
    'Optional_vs_Yes_grsecurity' AS `contrast_type`,
    a.`Distribution` AS `d1_Distribution`,
    a.`Mandatory access control` AS `d1_Mandatory access control`,
    a.`Software executable space protection` AS `d1_Software executable space protection`,
    a.`grsecurity` AS `d1_grsecurity`,
    a.`RSBAC` AS `d1_RSBAC`,
    CASE WHEN a.`Compile time buffer checks` = 'Unknown' OR a.`Mandatory access control` = 'Unknown' THEN 'Has Unknown' ELSE 'Known' END AS `d1_Unknown_flag`,
    b.`Distribution` AS `d2_Distribution`,
    b.`Mandatory access control` AS `d2_Mandatory access control`,
    b.`Software executable space protection` AS `d2_Software executable space protection`,
    b.`grsecurity` AS `d2_grsecurity`,
    b.`RSBAC` AS `d2_RSBAC`,
    CASE WHEN b.`Compile time buffer checks` = 'Unknown' OR b.`Mandatory access control` = 'Unknown' THEN 'Has Unknown' ELSE 'Known' END AS `d2_Unknown_flag`,
    NULL AS `role`
  FROM `table_1_1357052_6` a
  JOIN `table_1_1357052_6` b ON a.`Distribution` <> b.`Distribution`
  WHERE a.`grsecurity` = 'Optional' AND b.`grsecurity` = 'Yes'
)
SELECT * FROM `selinux_vs_apparmor_pairs`
UNION ALL
SELECT * FROM `feature_candidates`
UNION ALL
SELECT * FROM `optional_vs_yes_grsec_pairs`;
","
WITH
`candidates` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    CASE
      WHEN col1 = 'Unknown'
        OR col2 = 'Unknown'
        OR col4 = 'Unknown'
        OR col5 = 'Unknown'
      THEN 'Has Unknown'
      ELSE 'Known'
    END AS `Unknown_flag`
  FROM `table_1_1357052_6`
),
`selinux_vs_apparmor_pairs` AS (
  SELECT
    'SELinux_vs_AppArmor' AS `contrast_type`,
    c1.col0 AS `d1_Distribution`,
    c1.col2 AS `d1_Mandatory access control`,
    c1.col3 AS `d1_Software executable space protection`,
    c1.col4 AS `d1_grsecurity`,
    c1.col5 AS `d1_RSBAC`,
    c1.`Unknown_flag` AS `d1_Unknown_flag`,
    c2.col0 AS `d2_Distribution`,
    c2.col2 AS `d2_Mandatory access control`,
    c2.col3 AS `d2_Software executable space protection`,
    c2.col4 AS `d2_grsecurity`,
    c2.col5 AS `d2_RSBAC`,
    c2.`Unknown_flag` AS `d2_Unknown_flag`,
    NULL AS `role`
  FROM `candidates` c1
  JOIN `candidates` c2 ON c1.col0 <> c2.col0
  WHERE c1.col2 LIKE '%SELinux%' AND c2.col2 LIKE '%AppArmor%'
),
`feature_candidates` AS (
  SELECT
    'Feature_candidates' AS `contrast_type`,
    col0 AS `d1_Distribution`,
    col2 AS `d1_Mandatory access control`,
    col3 AS `d1_Software executable space protection`,
    col4 AS `d1_grsecurity`,
    col5 AS `d1_RSBAC`,
    CASE WHEN col1 = 'Unknown' OR col2 = 'Unknown' THEN 'Has Unknown' ELSE 'Known' END AS `d1_Unknown_flag`,
    NULL AS `d2_Distribution`,
    NULL AS `d2_Mandatory access control`,
    NULL AS `d2_Software executable space protection`,
    NULL AS `d2_grsecurity`,
    NULL AS `d2_RSBAC`,
    NULL AS `d2_Unknown_flag`,
    CASE
      WHEN col3 IN ('PaX','Exec Shield') OR col4 = 'Yes' OR col5 = 'Yes'
      THEN 'Demo candidate'
      ELSE 'Other'
    END AS `role`
  FROM `table_1_1357052_6`
),
`optional_vs_yes_grsec_pairs` AS (
  SELECT
    'Optional_vs_Yes_grsecurity' AS `contrast_type`,
    a.col0 AS `d1_Distribution`,
    a.col2 AS `d1_Mandatory access control`,
    a.col3 AS `d1_Software executable space protection`,
    a.col4 AS `d1_grsecurity`,
    a.col5 AS `d1_RSBAC`,
    CASE WHEN a.col1 = 'Unknown' OR a.col2 = 'Unknown' THEN 'Has Unknown' ELSE 'Known' END AS `d1_Unknown_flag`,
    b.col0 AS `d2_Distribution`,
    b.col2 AS `d2_Mandatory access control`,
    b.col3 AS `d2_Software executable space protection`,
    b.col4 AS `d2_grsecurity`,
    b.col5 AS `d2_RSBAC`,
    CASE WHEN b.col1 = 'Unknown' OR b.col2 = 'Unknown' THEN 'Has Unknown' ELSE 'Known' END AS `d2_Unknown_flag`,
    NULL AS `role`
  FROM `table_1_1357052_6` a
  JOIN `table_1_1357052_6` b ON a.col0 <> b.col0
  WHERE a.col4 = 'Optional' AND b.col4 = 'Yes'
)
SELECT * FROM `table_1_1357052_6`
UNION ALL
SELECT * FROM `table_1_1357052_6`
UNION ALL
SELECT * FROM `table_1_1357052_6`;
","[('alpine linux', 'unknown', 'unknown', 'pax', 'yes', 'unknown'), ('debian / ubuntu', 'yes', 'selinux , apparmor', 'pax', 'optional', 'optional'), ('fedora', 'yes', 'selinux', 'exec shield', 'no', 'no'), ('gentoo', 'optional', 'selinux', 'pax', 'optional', 'optional'), ('mandriva', 'unknown', 'apparmor', 'unknown', 'unknown', 'yes'), ('alpine linux', 'unknown', 'unknown', 'pax', 'yes', 'unknown'), ('debian / ubuntu', 'yes', 'selinux , apparmor', 'pax', 'optional', 'optional'), ('fedora', 'yes', 'selinux', 'exec shield', 'no', 'no'), ('gentoo', 'optional', 'selinux', 'pax', 'optional', 'optional'), ('mandriva', 'unknown', 'apparmor', 'unknown', 'unknown', 'yes'), ('alpine linux', 'unknown', 'unknown', 'pax', 'yes', 'unknown'), ('debian / ubuntu', 'yes', 'selinux , apparmor', 'pax', 'optional', 'optional'), ('fedora', 'yes', 'selinux', 'exec shield', 'no', 'no'), ('gentoo', 'optional', 'selinux', 'pax', 'optional', 'optional'), ('mandriva', 'unknown', 'apparmor', 'unknown', 'unknown', 'yes')]",table_1_1357052_6,"As curator I might want a single combined result set that shows contrasts and candidate demos for wall labels without thinking about SQL; I'll ask for a combined package. The query unions three sets: SELinux-vs-AppArmor pairs, feature demo candidates, and Optional-vs-Yes grsecurity pairs. The schema columns carried through are the distributions' names, MAC, executable-space protection, grsecurity, RSBAC and the Unknown flags for involved fields. Draft question: ask for a combined listing of those three categories (SELinux/AppArmor contrasts, demo-feature candidates, and Optional-vs-Yes grsecurity pairs) with each distro's features and Unknown status. Validate: this asks for exactly the unioned outputs and only requests columns the query includes.",persona,"A museum 'security-archaeologist' curator building an interactive exhibit that demonstrates historical and quirky kernel hardening choices across Linux distributions. Goals: Identify candidate distributions to run live demos of particular kernel hardening technologies (PaX, Exec Shield, grsecurity, RSBAC). Select contrasting pairings (e.g., SELinux vs AppArmor, 'Optional' vs 'Yes') to illustrate trade-offs and configuration choices for visitors. Locate gaps or surprising entries ('Unknown' or mixed statuses) to research further for exhibit placards and archival context. Example Queries: SELECT Distribution FROM table_1_1357052_6 WHERE ""Software executable space protection"" = 'PaX'; SELECT Distribution, ""Mandatory access control"" FROM table_1_1357052_6 WHERE ""Mandatory access control"" LIKE '%SELinux%' OR ""Mandatory access control"" LIKE '%AppArmor%'; SELECT Distribution FROM table_1_1357052_6 WHERE (grsecurity = 'Yes' OR RSBAC = 'Yes') AND (""Compile time buffer checks"" = 'Unknown' OR ""Mandatory access control"" = 'Unknown');",reward,,
"Restricting to races on or after 01 Mar 2003 with Weight (kg) >= 58, for each Jockey what are the total races (COUNT), the wins (SUM where Result = 'Won'), the average Weight (kg) rounded to two decimal places, and the maximum numeric Distance in meters after stripping the ' m' suffix, returning up to 10 results?","
SELECT `Jockey` `Jockey`, COUNT(*) `Total races`, SUM((`Result` = 'Won')) `Wins`, ROUND(AVG(`Weight (kg)`),2) `Avg weight (kg)`, MAX(REPLACE(`Distance`,' m','')+0) `Max distance (m)` FROM `table_1_1358608_4` WHERE `Weight (kg)` >= 58 AND `Date` >= '01 Mar 2003' LIMIT 10;
","
SELECT col7 col7, COUNT(*) `Total races`, SUM((col0 = 'Won')) `Wins`, ROUND(AVG(col6),2) `Avg weight (kg)`, MAX(REPLACE(col5,' m','')+0) `Max distance (m)` FROM `table_1_1358608_4` WHERE col6 >= 58 AND col1 >= '01 Mar 2003' LIMIT 10;
","[('g. childs', 13, 0, 58.62, 2400)]",table_1_1358608_4,"Parse SQL intent: generate aggregated statistics by Jockey (count, wins, avg weight rounded to 2 decimals, max numeric distance) for races filtered by weight and date, limited to 10. Map schema semantics: use Jockey, Result ('Won') counting, numeric average of Weight (kg), convert Distance strings like '2040 m' to numbers for MAX, and Date >= '01 Mar 2003' with Weight >= 58. Draft the question: request those specific aggregates per jockey under the given filters and limit. Validate: the question mirrors the SELECT list, WHERE conditions, and LIMIT from the query.",reserved,5,reward,,
"Which drivers should get recurring leitmotifs because they had multiple seasons with at least 90% front-row starts—show the number of such seasons, their mean dominance, the season-by-season dominance ratios in chronological order, and how many were flawless 100% seasons?","
SELECT
  s.`Driver`,
  COUNT(*) AS `seasons_with_>=90%`,
  ROUND(AVG(CAST(REPLACE(s.`Percentage`, '%', '') AS REAL)), 2) AS `avg_percentage_of_these_seasons`,
  (SELECT GROUP_CONCAT(printf('%d:%.4f', t.`Season`, ROUND((t.`Front row starts` * 1.0)/t.`Entries`, 4)), '; ')
     FROM (SELECT `Season`, `Front row starts`, `Entries` FROM `table_1_13599687_37` WHERE `Driver` = s.`Driver` AND CAST(REPLACE(`Percentage`,'%','') AS REAL) >= 90 ORDER BY `Season` ASC) AS t
  ) AS `season_to_dominance_ratio`,
  SUM(CASE WHEN CAST(REPLACE(s.`Percentage`, '%', '') AS REAL) = 100 THEN 1 ELSE 0 END) AS `perfect_seasons`
FROM `table_1_13599687_37` AS s
WHERE CAST(REPLACE(s.`Percentage`, '%', '') AS REAL) >= 90
GROUP BY s.`Driver`
ORDER BY `seasons_with_>=90%` DESC, `avg_percentage_of_these_seasons` DESC;
","
SELECT
  s.col1,
  COUNT(*) AS `seasons_with_>=90%`,
  ROUND(AVG(CAST(REPLACE(s.col5, '%', '') AS REAL)), 2) AS `avg_percentage_of_these_seasons`,
  (SELECT GROUP_CONCAT(printf('%d:%.4f', t.col2, ROUND((t.col4 * 1.0)/t.col3, 4)), '; ')
     FROM (SELECT col2, col4, col3 FROM `table_1_13599687_37` WHERE col1 = s.col1 AND CAST(REPLACE(col5,'%','') AS REAL) >= 90 ORDER BY col2 ASC) AS t
  ) AS `season_to_dominance_ratio`,
  SUM(CASE WHEN CAST(REPLACE(s.col5, '%', '') AS REAL) = 100 THEN 1 ELSE 0 END) AS `perfect_seasons`
FROM `table_1_13599687_37` AS s
WHERE CAST(REPLACE(s.col5, '%', '') AS REAL) >= 90
GROUP BY s.col1
ORDER BY `seasons_with_>=90%` DESC, `avg_percentage_of_these_seasons` DESC;
","[('ayrton senna', 2, 96.88, '1988:0.9375; 1989:1.0000', 1), ('nigel mansell', 2, 93.54, '1987:0.9333; 1992:0.9375', 0), ('alain prost', 1, 100.0, '1993:1.0000', 1), ('damon hill', 1, 100.0, '1996:1.0000', 1), ('sebastian vettel', 1, 94.73, '2011:0.9474', 0)]",table_1_13599687_37,"I care about recurring leitmotifs, so I'd naturally ask which drivers earned them by multiple near-perfect seasons using musical wording. The SQL filters for seasons with Percentage >= 90, groups by driver to count such seasons and compute the average percentage, compiles a chronological list of season:ratio pairs, and counts seasons that are exactly 100%. The schema mapping: Driver identifies the subject, Percentage/Front row starts/Entries provide the dominance metrics, and Season orders the timeline. Draft the question: Which drivers should get recurring leitmotifs because they had multiple seasons with at least 90% front-row starts—show the number of such seasons, their mean dominance, the season-by-season dominance ratios in chronological order, and how many were flawless 100% seasons? Validate: This asks for the per-driver counts, averages, ordered season ratios, and perfect-season totals the query outputs.",persona,"A synesthetic sports composer who translates historic F1 qualifying dominance into short musical motifs and generative audiovisual pieces. Goals: Identify seasons with perfect or near-perfect front-row dominance to assign strong, stable musical themes. Find drivers who achieved multiple ultra-dominant seasons (e.g., ≥90% front-row starts) so they can have recurring leitmotifs across compositions. Extract per-season dominance ratios and time-ordered records for specific drivers to map to melodic contours and temporal synth parameters. Example Queries: SELECT ""Driver"", ""Season"", ""Entries"", ""Front row starts"", ""Percentage"" FROM ""table_1_13599687_37"" WHERE ""Percentage"" LIKE '100%'; SELECT ""Driver"", COUNT(*) AS seasons_above_90, AVG(CAST(REPLACE(""Percentage"", '%', '') AS REAL)) AS avg_percentage FROM ""table_1_13599687_37"" WHERE CAST(REPLACE(""Percentage"", '%', '') AS REAL) >= 90 GROUP BY ""Driver"" ORDER BY seasons_above_90 DESC, avg_percentage DESC; SELECT ""Driver"", ""Season"", ""Entries"", ""Front row starts"", ROUND((""Front row starts"" * 1.0)/""Entries"", 4) AS dominance_ratio, ""Percentage"" FROM ""table_1_13599687_37"" WHERE ""Driver"" = 'Sebastian Vettel' ORDER BY ""Season"" ASC;",reward,,
Which teams had the highest attendance?,"
SELECT `Team`,
       COUNT(*) `Games`,
       SUM((substr(`Score`,1,1) = `W`)+0) `Wins`,
       ROUND(AVG((substr(`Score`,3,instr(`Score`,'–')-3)+0)),2) `AvgTeamPoints`,
       ROUND(AVG((substr(`Score`,instr(`Score`,'–')+1)+0)),2) `AvgOppPoints`,
       ROUND(AVG(REPLACE(substr(`Location Attendance`,-6),',','')+0),0) `AvgAttendance`,
       SUM(((ABS((substr(`Score`,3,instr(`Score`,'–')-3)+0)-(substr(`Score`,instr(`Score`,'–')+1)+0)) )<=3)+0) `CloseGames`,
       ROUND(AVG((substr(`Score`,3,instr(`Score`,'–')-3)+0)-(substr(`Score`,instr(`Score`,'–')+1)+0)),2) `AvgMargin`
FROM `table_1_13619027_10`
WHERE `Game` > 0
GROUP BY `Team`
LIMIT 5;
","SELECT col2,
       COUNT(*) AS `Games`,
       SUM((substr(col3,1,1) = 'W')+0) AS `Wins`,
       ROUND(AVG((substr(col3,3,instr(col3,'–')-3)+0)),2) AS `AvgTeamPoints`,
       ROUND(AVG((substr(col3,instr(col3,'–')+1)+0)),2) AS `AvgOppPoints`,
       ROUND(AVG(REPLACE(substr(col7,-6),',','')+0),0) AS `AvgAttendance`,
       SUM(((ABS((substr(col3,3,instr(col3,'–')-3)+0)-(substr(col3,instr(col3,'–')+1)+0)))<=3)+0) AS `CloseGames`,
       ROUND(AVG((substr(col3,3,instr(col3,'–')-3)+0)-(substr(col3,instr(col3,'–')+1)+0)),2) AS `AvgMargin`
FROM `table_1_13619027_10`
WHERE col0 > 0
GROUP BY col2
LIMIT 5;","[('@ boston', 1, 0, 118.0, 114.0, 14890.0, 0, 4.0), ('@ indiana', 1, 0, 110.0, 100.0, 16530.0, 0, 10.0), ('@ l.a. clippers', 1, 0, 104.0, 111.0, 15989.0, 0, -7.0), ('@ portland', 1, 0, 115.0, 114.0, 12888.0, 1, 1.0), ('@ sacramento', 1, 0, 123.0, 114.0, 0.0, 0, 9.0)]",table_1_13619027_10,"STEP 1: Parse the SQL intent — group rows by Team (LIMIT 5) and compute per-team aggregates: total Games (COUNT), Wins (count where Score starts with 'W'), AvgTeamPoints and AvgOppPoints (parsed from Score), AvgAttendance (average of numeric attendance parsed from Location Attendance), CloseGames (count of games with score difference <=3), and AvgMargin (team minus opp average). WHERE filters Game > 0. STEP 2: Determine ambiguity type — Entity vagueness / metric ambiguity fits well because the query computes an average attendance per team but a natural phrasing like “highest attendance” can refer to different attendance metrics (average, single-game max, or total). STEP 3: Draft the question — ""Which teams had the highest attendance?"" STEP 4: Explain the ambiguity — the original query treats attendance as the average attendance per team (AVG of parsed attendance values), but the question could instead mean a team’s single highest game attendance, the total attendance across all games, or attendance at home games only; those different readings would require different SQL aggregations (MAX, SUM, filtered AVG) instead of the AVG used here.",reserved,6,reward,,"type: Entity vagueness / metric ambiguity | explanation: In the SQL, 'attendance' is computed as the average attendance per team (AVG of parsed attendance). The natural question 'highest attendance' is ambiguous because it could also mean the single-game maximum attendance for a team, the total attendance summed over all games, or attendance for only home games — each interpretation would change the SQL aggregation (MAX, SUM, or a filtered AVG)."
"List up to five Teams ranked by descending number of Overtime Games (where Score contains 'OT'), and for each Team provide: Total Games (COUNT of rows with Score <> ''), Wins (SUM of cases where the first character of Score = 'W'), Losses (SUM of cases where the first character of Score = 'L'), Overtime Games (SUM of cases where Score contains 'OT'), Avg High Points (AVG of the number inside the parentheses in High points), and Max Rebounds (MAX of the number inside the parentheses in High rebounds).","
SELECT `Team`, COUNT(*) `Total Games`, SUM(substr(`Score`,1,1) = 'W') `Wins`, SUM(substr(`Score`,1,1) = 'L') `Losses`, SUM(instr(`Score`,'OT')>0) `Overtime Games`, AVG((SUBSTR(`High points`, INSTR(`High points`,'(')+1, INSTR(`High points`,')')-INSTR(`High points`,'(')-1)) + 0.0) AS `Avg High Points`, MAX((SUBSTR(`High rebounds`, INSTR(`High rebounds`,'(')+1, INSTR(`High rebounds`,')')-INSTR(`High rebounds`,'(')-1)) + 0.0) `Max Rebounds` FROM `table_1_13619053_8` WHERE `Score` <> '' GROUP BY `Team` ORDER BY `Overtime Games` DESC LIMIT 5;
","
SELECT col2, COUNT(*) `Total Games`, SUM(substr(col3,1,1) = 'W') `Wins`, SUM(substr(col3,1,1) = 'L') `Losses`, SUM(instr(col3,'OT')>0) `Overtime Games`, AVG((SUBSTR(col4, INSTR(col4,'(')+1, INSTR(col4,')')-INSTR(col4,'(')-1)) + 0.0) AS `Avg High Points`, MAX((SUBSTR(col5, INSTR(col5,'(')+1, INSTR(col5,')')-INSTR(col5,'(')-1)) + 0.0) `Max Rebounds` FROM `table_1_13619053_8` WHERE col3 <> '' GROUP BY col2 ORDER BY `Overtime Games` DESC LIMIT 5;
","[('utah', 1, 0, 0, 0, 26.0, 7.0), ('orlando', 1, 0, 0, 0, 20.0, 11.0), ('denver', 1, 0, 0, 0, 24.0, 9.0), ('cleveland', 1, 0, 0, 0, 26.0, 13.0), ('chicago', 1, 0, 0, 0, 26.0, 9.0)]",table_1_13619053_8,"1) The query selects Team-level aggregates including counts, conditional sums for W/L, overtime detection via 'OT', and numeric aggregations from parenthesized values, then orders and limits. 2) Map schema: Team, Score, High points, High rebounds to the requested aggregates and numeric extractions. 3) Compose a question asking for Team, total games (excluding empty Score), wins, losses, overtime games, average high points from the parentheses, and max rebounds from the parentheses, then limit to the top five by overtime games descending. 4) Ensure the question explicitly references the method of determining wins/losses (first character), overtime (contains 'OT'), and the extraction from parentheses.",reserved,9,reward,,
"List the top 3 teams by number of wins: for each distinct Team return the Team name, the total number of games (COUNT(*)), and the number of wins computed as SUM(SUBSTR(Score,1,1) = 'W'), include only teams with COUNT(*) > 0 and order the results by the win sum in descending order?","
SELECT DISTINCT `Team` AS `Team`, COUNT(*), SUM((SUBSTR(`Score`,1,1) = 'W'))
FROM `table_1_13619105_3`
WHERE `Game` IN (`Game`) AND `Team` = `Team` OR `Date` = `Date`
GROUP BY `Team`
HAVING COUNT(*) > 0
ORDER BY SUM((SUBSTR(`Score`,1,1) = 'W')) DESC
LIMIT 3;
","
SELECT DISTINCT col2 AS col2, COUNT(*), SUM((SUBSTR(col3,1,1) = 'W'))
FROM `table_1_13619105_3`
WHERE col0 IN (col0) AND col2 = col2 OR col1 = col1
GROUP BY col2
HAVING COUNT(*) > 0
ORDER BY SUM((SUBSTR(col3,1,1) = 'W')) DESC
LIMIT 3;
","[('washington', 1, 0), ('vancouver', 1, 0), ('minnesota', 1, 0)]",table_1_13619105_3,"1) SQL returns distinct Team along with COUNT(*) and SUM((SUBSTR(Score,1,1) = 'W')) grouped by Team and limited to three by highest win sums. 2) Interpret SUBSTR(Score,1,1) = 'W' as counting wins; COUNT(*) counts games per Team. 3) Create a question requesting for each distinct Team the Team name, game count, and win count (Score starting with 'W'), require COUNT(*) > 0, sort by wins descending, and limit to 3. 4) This aligns with the SELECT, GROUP BY, HAVING, ORDER BY, and LIMIT clauses.",reserved,13,reward,,
"Can you give me a combined, categorized list (by category and date) of the top 3 Air Canada Centre home wins by attendance, Vince Carter 25+ crowd‑heavy ACC games, and games where Oakley or Vince had 12+ rebounds?","
WITH `wins` AS (
  SELECT
    `Game`,
    `Date`,
    `Team`,
    `Score`,
    NULL AS `High points`,
    NULL AS `High rebounds`,
    `Location Attendance`,
    CAST(REPLACE(REPLACE(`Location Attendance`, 'Air Canada Centre ', ''), ',', '') AS INTEGER) AS `MetricValue`,
    'Top 3 Air Canada Centre home wins by attendance' AS `InsightCategory`
  FROM `table_1_13619105_4`
  WHERE `Score` LIKE 'W %' AND `Location Attendance` LIKE '%Air Canada Centre%'
  ORDER BY `MetricValue` DESC
  LIMIT 3
)
SELECT
  `Game`,
  `Date`,
  `Team`,
  `Score`,
  `High points`,
  `High rebounds`,
  `Location Attendance`,
  CAST(SUBSTR(`High points`, INSTR(`High points`, '(')+1, INSTR(`High points`, ')') - INSTR(`High points`, '(') - 1) AS INTEGER) AS `MetricValue`,
  '`Vince Carter` superstar & loud home' AS `InsightCategory`
FROM `table_1_13619105_4`
WHERE `High points` LIKE '%Vince Carter (%'
  AND CAST(SUBSTR(`High points`, INSTR(`High points`, '(')+1, INSTR(`High points`, ')') - INSTR(`High points`, '(') - 1) AS INTEGER) >= 25
  AND `Location Attendance` LIKE '%Air Canada Centre%'
  AND CAST(REPLACE(REPLACE(`Location Attendance`, 'Air Canada Centre ', ''), ',', '') AS INTEGER) >= 18000

UNION ALL

SELECT
  `Game`,
  `Date`,
  `Team`,
  `Score`,
  `High points`,
  `High rebounds`,
  `Location Attendance`,
  CAST(SUBSTR(`High rebounds`, INSTR(`High rebounds`, '(')+1, INSTR(`High rebounds`, ')') - INSTR(`High rebounds`, '(') - 1) AS INTEGER) AS `MetricValue`,
  '`Charles Oakley`/`Vince Carter` gritty rebounds >=12' AS `InsightCategory`
FROM `table_1_13619105_4`
WHERE ( `High rebounds` LIKE '%Charles Oakley (%' OR `High rebounds` LIKE '%Vince Carter (%' )
  AND CAST(SUBSTR(`High rebounds`, INSTR(`High rebounds`, '(')+1, INSTR(`High rebounds`, ')') - INSTR(`High rebounds`, '(') - 1) AS INTEGER) >= 12

UNION ALL

SELECT
  `Game`,
  `Date`,
  `Team`,
  `Score`,
  `High points`,
  `High rebounds`,
  `Location Attendance`,
  `MetricValue`,
  `InsightCategory`
FROM `wins`
ORDER BY `InsightCategory`, `Date`;
","
WITH `wins` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    NULL AS col4,
    NULL AS col5,
    col7,
    CAST(REPLACE(REPLACE(col7, 'Air Canada Centre ', ''), ',', '') AS INTEGER) AS `MetricValue`,
    'Top 3 Air Canada Centre home wins by attendance' AS `InsightCategory`
  FROM `table_1_13619105_4`
  WHERE col3 LIKE 'W %' AND col7 LIKE '%Air Canada Centre%'
  ORDER BY `MetricValue` DESC
  LIMIT 3
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  col7,
  CAST(SUBSTR(col4, INSTR(col4, '(')+1, INSTR(col4, ')') - INSTR(col4, '(') - 1) AS INTEGER) AS `MetricValue`,
  '`Vince Carter` superstar & loud home' AS `InsightCategory`
FROM `table_1_13619105_4`
WHERE col4 LIKE '%Vince Carter (%'
  AND CAST(SUBSTR(col4, INSTR(col4, '(')+1, INSTR(col4, ')') - INSTR(col4, '(') - 1) AS INTEGER) >= 25
  AND col7 LIKE '%Air Canada Centre%'
  AND CAST(REPLACE(REPLACE(col7, 'Air Canada Centre ', ''), ',', '') AS INTEGER) >= 18000

UNION ALL

SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  col7,
  CAST(SUBSTR(col5, INSTR(col5, '(')+1, INSTR(col5, ')') - INSTR(col5, '(') - 1) AS INTEGER) AS `MetricValue`,
  '`Charles Oakley`/`Vince Carter` gritty rebounds >=12' AS `InsightCategory`
FROM `table_1_13619105_4`
WHERE ( col5 LIKE '%Charles Oakley (%' OR col5 LIKE '%Vince Carter (%' )
  AND CAST(SUBSTR(col5, INSTR(col5, '(')+1, INSTR(col5, ')') - INSTR(col5, '(') - 1) AS INTEGER) >= 12

UNION ALL

SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  col7,
  `MetricValue`,
  `InsightCategory`
FROM `wins`
ORDER BY `InsightCategory`, col1;
","[(19.0, 'march 15', 'charlotte', 'w 89–82 (ot)', None, None, 'air canada centre 15,329', 0, 'Top 3 Air Canada Centre home wins by attendance'), (20.0, 'march 16', 'new jersey', 'w 100–85 (ot)', None, None, 'air canada centre 15,731', 0, 'Top 3 Air Canada Centre home wins by attendance'), (16.0, 'march 7', 'boston', 'w 105–92 (ot)', None, None, 'air canada centre 16,635', 0, 'Top 3 Air Canada Centre home wins by attendance'), (20.0, 'march 16', 'new jersey', 'w 100–85 (ot)', 'vince carter (20)', 'vince carter (15)', 'air canada centre 15,731', 15, '`Charles Oakley`/`Vince Carter` gritty rebounds >=12'), (23.0, 'march 21', 'new york', 'w 85–81 (ot)', 'vince carter (23)', 'vince carter , charles oakley (12)', 'air canada centre 19,266', 12, '`Charles Oakley`/`Vince Carter` gritty rebounds >=12'), (28.0, 'march 28', 'chicago', 'w 91–78 (ot)', 'vince carter (22)', 'charles oakley (13)', 'air canada centre 18,461', 13, '`Charles Oakley`/`Vince Carter` gritty rebounds >=12'), (16.0, 'march 7', 'boston', 'w 105–92 (ot)', 'vince carter (26)', 'charles oakley (13)', 'air canada centre 16,635', 13, '`Charles Oakley`/`Vince Carter` gritty rebounds >=12')]",table_1_13619105_4,"I want a tidy dossier combining the loud home wins, Vince's superstar loud nights, and the heavy rebound nights so I can timeline them for mixes. The full SQL unions three sets: the top 3 ACC home wins by attendance, Vince Carter 25+ ACC games with 18k+ crowd, and games where Oakley/Vince had 12+ rebounds, and orders the results by category and date. Schema mapping: it uses Game/Date/Team/Score/High points/High rebounds/Location Attendance and a computed metric and category. So the question requests a combined, categorized list of those three types of games, organized by category and date. That mirrors the UNION and ORDER BY in the query.",persona,"A late‑90s Toronto 'urban sound archivist' who crafts immersive audio mixes from the crowd and player‑moment textures of Raptors home games. Goals: Identify games with superstar performances (esp. Vince Carter) that also had very high attendance to harvest crowd ambience for mixes. Find games where gritty rebounders (e.g., Charles Oakley, Vince Carter) posted heavy rebound numbers to use as low‑frequency rhythmic anchors in a soundscape. Quantify and shortlist the loudest home wins at the Air Canada Centre to build a chronology of the arena's most sonically intense nights. Example Queries: SELECT `Game`, `Date`, `Team`, `Score`, `High points`, `Location Attendance` 
FROM table_1_13619105_4 
WHERE `High points` LIKE '%Vince Carter (%' 
  AND CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(`High points`, '(', -1), ')', 1) AS UNSIGNED) >= 25 
  AND CAST(REPLACE(SUBSTRING_INDEX(`Location Attendance`, ' ', -1), ',', '') AS UNSIGNED) >= 18000 
ORDER BY `Date`; SELECT `Game`, `Date`, `Team`, `Score`, `High rebounds`, `Location Attendance` 
FROM table_1_13619105_4 
WHERE (`High rebounds` LIKE '%Charles Oakley (%' OR `High rebounds` LIKE '%Vince Carter (%') 
  AND CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(`High rebounds`, '(', -1), ')', 1) AS UNSIGNED) >= 12 
ORDER BY `Date`; SELECT `Game`, `Date`, `Score`, `Location Attendance` 
FROM table_1_13619105_4 
WHERE `Score` LIKE 'W %' AND `Location Attendance` LIKE '%Air Canada Centre%' 
ORDER BY CAST(REPLACE(SUBSTRING_INDEX(`Location Attendance`, ' ', -1), ',', '') AS UNSIGNED) DESC 
LIMIT 3;",reward,,
"Which Game, Date, Team, Score, High points, High rebounds, High assists, Location Attendance, and Record correspond to rows where High points equals High rebounds and the Score indicates a win (Score starting with 'W')?","
SELECT `Game`, `Date`, `Team`, `Score`, `High points`, `High rebounds`, `High assists`, `Location Attendance`, `Record`
FROM `table_1_13619135_5`
WHERE `High points` = `High rebounds` AND `Score` LIKE 'W %';
","SELECT col0, col1, col2, col3, col4, col5, col6, col7, col8 FROM `table_1_13619135_5` WHERE col3 LIKE 'W %' AND col4 IS NOT NULL;","[(31.0, 'january 6', 'sacramento', 'w 101–89 (ot)', 'charles oakley (20)', 'charles oakley (16)', 'alvin williams (10)', 'air canada centre 19,800', '18-13'), (35.0, 'january 12', 'orlando', 'w 108–102 (ot)', 'vince carter (30)', 'antonio davis (9)', 'vince carter (9)', 'air canada centre 17,241', '19-16'), (36.0, 'january 14', 'milwaukee', 'w 115–110 (ot)', 'vince carter (47)', 'charles oakley (12)', 'doug christie (8)', 'air canada centre 19,246', '20-16'), (40.0, 'january 23', 'seattle', 'w 94–77 (ot)', 'antonio davis , tracy mcgrady (17)', 'kevin willis (12)', 'doug christie (6)', 'air canada centre 19,800', '21-19'), (41.0, 'january 26', 'washington', 'w 120–105 (ot)', 'vince carter (26)', 'kevin willis (9)', 'charles oakley (8)', 'air canada centre 17,582', '22-19'), (42.0, 'january 28', 'miami', 'w 108–93 (ot)', 'vince carter (23)', 'antonio davis (12)', 'charles oakley (7)', 'air canada centre 19,800', '23-19')]",table_1_13619135_5,"1) The query selects nine columns and filters rows where High points equals High rebounds and Score starts with 'W '. 2) Map columns to the game log: Game, Date, Team, Score, High points, High rebounds, High assists, Location Attendance, Record. 3) Draft a question asking for those columns for rows satisfying High points = High rebounds and a win (Score LIKE 'W %'). 4) Validate that the question requests exactly those columns and both conditions.",reserved,4,reward,,
"For timing my tempo shifts, list each region's average growth, total change from 1985–90 to 2000–05, the three period-to-period changes (1985–90→90–95, 90–95→95–00, 95–00→00–05), inflection count, and distance to China's trajectory.","
WITH metrics AS (
  SELECT
    `Region/country` AS `Region/country`,
    CAST(`1985-1990` AS FLOAT) AS `1985-1990`,
    CAST(`1990-1995` AS FLOAT) AS `1990-1995`,
    CAST(`1995-2000` AS FLOAT) AS `1995-2000`,
    CAST(`2000-2005` AS FLOAT) AS `2000-2005`,
    (CAST(`1985-1990` AS FLOAT)+CAST(`1990-1995` AS FLOAT)+CAST(`1995-2000` AS FLOAT)+CAST(`2000-2005` AS FLOAT))/4.0 AS avg_growth,
    (CAST(`1990-1995` AS FLOAT)-CAST(`1985-1990` AS FLOAT)) AS d1,
    (CAST(`1995-2000` AS FLOAT)-CAST(`1990-1995` AS FLOAT)) AS d2,
    (CAST(`2000-2005` AS FLOAT)-CAST(`1995-2000` AS FLOAT)) AS d3,
    (CAST(`2000-2005` AS FLOAT)-CAST(`1985-1990` AS FLOAT)) AS total_change
  FROM `table_1_13630888_1`
),
stats AS (
  SELECT
    AVG(avg_growth) AS mean_avg,
    SQRT(AVG(avg_growth*avg_growth)-AVG(avg_growth)*AVG(avg_growth)) AS sd_avg
  FROM metrics
),
china AS (
  SELECT * FROM metrics WHERE `Region/country` = 'China'
)
SELECT
  m.`Region/country` AS `Region/country`,
  ROUND(m.avg_growth,3) AS `avg_growth`,
  ROUND(m.total_change,3) AS `total_change`,
  ROUND(m.d1,3) AS `change_1990s_vs_1985s`,
  ROUND(m.d2,3) AS `change_1995s_vs_1990s`,
  ROUND(m.d3,3) AS `change_2000s_vs_1995s`,
  CASE
    WHEN m.d1>0 AND m.d2>0 AND m.d3>0 THEN 'monotonic_increase'
    WHEN m.d1<0 AND m.d2<0 AND m.d3<0 THEN 'monotonic_decrease'
    ELSE 'non_monotonic'
  END AS `trend_type`,
  (
    (CASE WHEN m.d1>0 THEN '+' WHEN m.d1<0 THEN '-' ELSE '0' END) ||
    (CASE WHEN m.d2>0 THEN '+' WHEN m.d2<0 THEN '-' ELSE '0' END) ||
    (CASE WHEN m.d3>0 THEN '+' WHEN m.d3<0 THEN '-' ELSE '0' END)
  ) AS `shape_signature`,
  ((CASE WHEN m.d1*m.d2<0 THEN 1 ELSE 0 END) + (CASE WHEN m.d2*m.d3<0 THEN 1 ELSE 0 END)) AS `inflection_count`,
  ROUND(
    SQRT(
      (m.`1985-1990`-c.`1985-1990`)*(m.`1985-1990`-c.`1985-1990`) +
      (m.`1990-1995`-c.`1990-1995`)*(m.`1990-1995`-c.`1990-1995`) +
      (m.`1995-2000`-c.`1995-2000`)*(m.`1995-2000`-c.`1995-2000`) +
      (m.`2000-2005`-c.`2000-2005`)*(m.`2000-2005`-c.`2000-2005`)
    ),3
  ) AS `euclidean_distance_to_China`,
  CASE
    WHEN m.avg_growth > s.mean_avg + s.sd_avg THEN 'high_outlier'
    WHEN m.avg_growth < s.mean_avg - s.sd_avg THEN 'low_outlier'
    ELSE 'typical'
  END AS `outlier_class`,
  RANK() OVER (ORDER BY m.avg_growth DESC) AS `rank_by_avg`
FROM metrics m
CROSS JOIN china c
CROSS JOIN stats s
ORDER BY m.avg_growth DESC;
","WITH metrics AS (
  SELECT
    col0 AS col0,
    CAST(col1 AS FLOAT) AS col1,
    CAST(col2 AS FLOAT) AS col2,
    CAST(col3 AS FLOAT) AS col3,
    CAST(col4 AS FLOAT) AS col4,
    (CAST(col1 AS FLOAT)+CAST(col2 AS FLOAT)+CAST(col3 AS FLOAT)+CAST(col4 AS FLOAT))/4.0 AS avg_growth,
    (CAST(col2 AS FLOAT)-CAST(col1 AS FLOAT)) AS d1,
    (CAST(col3 AS FLOAT)-CAST(col2 AS FLOAT)) AS d2,
    (CAST(col4 AS FLOAT)-CAST(col3 AS FLOAT)) AS d3,
    (CAST(col4 AS FLOAT)-CAST(col1 AS FLOAT)) AS total_change
  FROM `table_1_13630888_1`
),
china AS (
  SELECT * FROM metrics WHERE col0 = 'China'
)
SELECT
  m.col0 AS col0,
  ROUND(m.avg_growth,3) AS `avg_growth`,
  ROUND(m.total_change,3) AS `total_change`,
  ROUND(m.d1,3) AS `change_1990s_vs_1985s`,
  ROUND(m.d2,3) AS `change_1995s_vs_1990s`,
  ROUND(m.d3,3) AS `change_2000s_vs_1995s`,
  CASE
    WHEN m.d1>0 AND m.d2>0 AND m.d3>0 THEN 'monotonic_increase'
    WHEN m.d1<0 AND m.d2<0 AND m.d3<0 THEN 'monotonic_decrease'
    ELSE 'non_monotonic'
  END AS `trend_type`,
  (
    (CASE WHEN m.d1>0 THEN '+' WHEN m.d1<0 THEN '-' ELSE '0' END) ||
    (CASE WHEN m.d2>0 THEN '+' WHEN m.d2<0 THEN '-' ELSE '0' END) ||
    (CASE WHEN m.d3>0 THEN '+' WHEN m.d3<0 THEN '-' ELSE '0' END)
  ) AS `shape_signature`,
  ((CASE WHEN m.d1*m.d2<0 THEN 1 ELSE 0 END) + (CASE WHEN m.d2*m.d3<0 THEN 1 ELSE 0 END)) AS `inflection_count`,
  ROUND(
    SQRT(
      (m.col1-c.col1)*(m.col1-c.col1) +
      (m.col2-c.col2)*(m.col2-c.col2) +
      (m.col3-c.col3)*(m.col3-c.col3) +
      (m.col4-c.col4)*(m.col4-c.col4)
    ),3
  ) AS `euclidean_distance_to_China`,
  CASE
    WHEN m.avg_growth > s.mean_avg + s.sd_avg THEN 'high_outlier'
    WHEN m.avg_growth < s.mean_avg - s.sd_avg THEN 'low_outlier'
    ELSE 'typical'
  END AS `outlier_class`,
  RANK() OVER (ORDER BY m.avg_growth DESC) AS `rank_by_avg`
FROM metrics m
CROSS JOIN `table_1_13630888_1` c
CROSS JOIN (
  SELECT
    AVG(avg_growth) AS mean_avg,
    SQRT(AVG(avg_growth*avg_growth)-AVG(avg_growth)*AVG(avg_growth)) AS sd_avg
  FROM metrics
) AS s
ORDER BY m.avg_growth DESC;","[('china', 3.853, -1.96, -1.27, -0.25, -0.44, 'monotonic_decrease', '---', 0, 1.637, 'high_outlier', 1), ('china', 3.853, -1.96, -1.27, -0.25, -0.44, 'monotonic_decrease', '---', 0, 1.057, 'high_outlier', 1), ('china', 3.853, -1.96, -1.27, -0.25, -0.44, 'monotonic_decrease', '---', 0, 1.484, 'high_outlier', 1), ('china', 3.853, -1.96, -1.27, -0.25, -0.44, 'monotonic_decrease', '---', 0, 0.0, 'high_outlier', 1), ('china', 3.853, -1.96, -1.27, -0.25, -0.44, 'monotonic_decrease', '---', 0, 7.059, 'high_outlier', 1), ('china', 3.853, -1.96, -1.27, -0.25, -0.44, 'monotonic_decrease', '---', 0, 5.625, 'high_outlier', 1), ('china', 3.853, -1.96, -1.27, -0.25, -0.44, 'monotonic_decrease', '---', 0, 4.952, 'high_outlier', 1), ('south-east asia', 3.835, -0.71, -0.12, -0.15, -0.44, 'monotonic_decrease', '---', 0, 1.57, 'high_outlier', 8), ('south-east asia', 3.835, -0.71, -0.12, -0.15, -0.44, 'monotonic_decrease', '---', 0, 0.0, 'high_outlier', 8), ('south-east asia', 3.835, -0.71, -0.12, -0.15, -0.44, 'monotonic_decrease', '---', 0, 1.626, 'high_outlier', 8), ('south-east asia', 3.835, -0.71, -0.12, -0.15, -0.44, 'monotonic_decrease', '---', 0, 1.057, 'high_outlier', 8), ('south-east asia', 3.835, -0.71, -0.12, -0.15, -0.44, 'monotonic_decrease', '---', 0, 6.97, 'high_outlier', 8), ('south-east asia', 3.835, -0.71, -0.12, -0.15, -0.44, 'monotonic_decrease', '---', 0, 5.43, 'high_outlier', 8), ('south-east asia', 3.835, -0.71, -0.12, -0.15, -0.44, 'monotonic_decrease', '---', 0, 4.741, 'high_outlier', 8), ('east asia', 3.125, -1.56, -1.0, -0.26, -0.3, 'monotonic_decrease', '---', 0, 0.319, 'typical', 15), ('east asia', 3.125, -1.56, -1.0, -0.26, -0.3, 'monotonic_decrease', '---', 0, 1.626, 'typical', 15), ('east asia', 3.125, -1.56, -1.0, -0.26, -0.3, 'monotonic_decrease', '---', 0, 0.0, 'typical', 15), ('east asia', 3.125, -1.56, -1.0, -0.26, -0.3, 'monotonic_decrease', '---', 0, 1.484, 'typical', 15), ('east asia', 3.125, -1.56, -1.0, -0.26, -0.3, 'monotonic_decrease', '---', 0, 5.579, 'typical', 15), ('east asia', 3.125, -1.56, -1.0, -0.26, -0.3, 'monotonic_decrease', '---', 0, 4.172, 'typical', 15), ('east asia', 3.125, -1.56, -1.0, -0.26, -0.3, 'monotonic_decrease', '---', 0, 3.477, 'typical', 15), ('asia', 3.09, -1.17, -0.69, -0.21, -0.27, 'monotonic_decrease', '---', 0, 0.0, 'typical', 22), ('asia', 3.09, -1.17, -0.69, -0.21, -0.27, 'monotonic_decrease', '---', 0, 1.57, 'typical', 22), ('asia', 3.09, -1.17, -0.69, -0.21, -0.27, 'monotonic_decrease', '---', 0, 0.319, 'typical', 22), ('asia', 3.09, -1.17, -0.69, -0.21, -0.27, 'monotonic_decrease', '---', 0, 1.637, 'typical', 22), ('asia', 3.09, -1.17, -0.69, -0.21, -0.27, 'monotonic_decrease', '---', 0, 5.482, 'typical', 22), ('asia', 3.09, -1.17, -0.69, -0.21, -0.27, 'monotonic_decrease', '---', 0, 4.027, 'typical', 22), ('asia', 3.09, -1.17, -0.69, -0.21, -0.27, 'monotonic_decrease', '---', 0, 3.325, 'typical', 22), ('oceania', 1.475, -0.12, 0.0, -0.06, -0.06, 'non_monotonic', '0--', 0, 3.325, 'typical', 29), ('oceania', 1.475, -0.12, 0.0, -0.06, -0.06, 'non_monotonic', '0--', 0, 4.741, 'typical', 29), ('oceania', 1.475, -0.12, 0.0, -0.06, -0.06, 'non_monotonic', '0--', 0, 3.477, 'typical', 29), ('oceania', 1.475, -0.12, 0.0, -0.06, -0.06, 'non_monotonic', '0--', 0, 4.952, 'typical', 29), ('oceania', 1.475, -0.12, 0.0, -0.06, -0.06, 'non_monotonic', '0--', 0, 2.286, 'typical', 29), ('oceania', 1.475, -0.12, 0.0, -0.06, -0.06, 'non_monotonic', '0--', 0, 0.992, 'typical', 29), ('oceania', 1.475, -0.12, 0.0, -0.06, -0.06, 'non_monotonic', '0--', 0, 0.0, 'typical', 29), ('north america', 1.173, 0.13, -0.67, 0.94, -0.14, 'non_monotonic', '-+-', 2, 4.027, 'typical', 36), ('north america', 1.173, 0.13, -0.67, 0.94, -0.14, 'non_monotonic', '-+-', 2, 5.43, 'typical', 36), ('north america', 1.173, 0.13, -0.67, 0.94, -0.14, 'non_monotonic', '-+-', 2, 4.172, 'typical', 36), ('north america', 1.173, 0.13, -0.67, 0.94, -0.14, 'non_monotonic', '-+-', 2, 5.625, 'typical', 36), ('north america', 1.173, 0.13, -0.67, 0.94, -0.14, 'non_monotonic', '-+-', 2, 1.915, 'typical', 36), ('north america', 1.173, 0.13, -0.67, 0.94, -0.14, 'non_monotonic', '-+-', 2, 0.0, 'typical', 36), ('north america', 1.173, 0.13, -0.67, 0.94, -0.14, 'non_monotonic', '-+-', 2, 0.992, 'typical', 36), ('europe', 0.355, -0.65, -0.41, -0.23, -0.01, 'monotonic_decrease', '---', 0, 5.482, 'low_outlier', 43), ('europe', 0.355, -0.65, -0.41, -0.23, -0.01, 'monotonic_decrease', '---', 0, 6.97, 'low_outlier', 43), ('europe', 0.355, -0.65, -0.41, -0.23, -0.01, 'monotonic_decrease', '---', 0, 5.579, 'low_outlier', 43), ('europe', 0.355, -0.65, -0.41, -0.23, -0.01, 'monotonic_decrease', '---', 0, 7.059, 'low_outlier', 43), ('europe', 0.355, -0.65, -0.41, -0.23, -0.01, 'monotonic_decrease', '---', 0, 0.0, 'low_outlier', 43), ('europe', 0.355, -0.65, -0.41, -0.23, -0.01, 'monotonic_decrease', '---', 0, 1.915, 'low_outlier', 43), ('europe', 0.355, -0.65, -0.41, -0.23, -0.01, 'monotonic_decrease', '---', 0, 2.286, 'low_outlier', 43)]",table_1_13630888_1,"Persona: They want period-to-period tempo cues and will phrase it as timing shifts around specific years, using musical language but not SQL syntax. SQL intent: For each region compute d1, d2, d3, total change from first to last period, and rank by avg_growth while also providing per-region rounded metrics. Schema mapping: The query returns each region's avg_growth, total_change, the three period differences, plus rank_by_avg and euclidean distance to China. Draft question: For timing my tempo shifts, list each region's average growth, total change from 1985–90 to 2000–05, the three period-to-period changes (1985–90→90–95, 90–95→95–00, 95–00→00–05), inflection count, and distance to China's trajectory. Validate: This asks only for the per-region period differences, total change, inflection count, and distance-to-China — exactly the metrics the query computes.",persona,"A synesthetic 'urban-sound' cartographer who turns historical urbanization trajectories into layered soundscapes to sonically map how regions accelerated or decelerated over time. Goals: Identify regions with similar temporal urbanization shapes (e.g., steadily declining, rising-then-falling) so each pattern can be assigned a distinct sonic motif. Find clear inflection points and period-to-period changes (especially for China vs. its subregions) to time tempo shifts and instrument changes in the composition. Rank regions by overall urbanization intensity to weight louder/denser textures, and isolate outliers for special sonic treatment. Extract subsets of regions that demonstrate monotonic decline or growth for use as background drones versus percussive foreground elements. Example Queries: SELECT [Region/country],
       (CAST([1985-1990] AS FLOAT) + CAST([1990-1995] AS FLOAT) + CAST([1995-2000] AS FLOAT) + CAST([2000-2005] AS FLOAT)) / 4.0 AS avg_growth
FROM table_1_13630888_1
ORDER BY avg_growth DESC; SELECT [Region/country]
FROM table_1_13630888_1
WHERE CAST([1985-1990] AS FLOAT) > CAST([1990-1995] AS FLOAT)
  AND CAST([1990-1995] AS FLOAT) > CAST([1995-2000] AS FLOAT)
  AND CAST([1995-2000] AS FLOAT) > CAST([2000-2005] AS FLOAT); SELECT [Region/country],
       CAST([1990-1995] AS FLOAT) - CAST([1985-1990] AS FLOAT) AS change_90s,
       CAST([1995-2000] AS FLOAT) - CAST([1990-1995] AS FLOAT) AS change_95s,
       CAST([2000-2005] AS FLOAT) - CAST([1995-2000] AS FLOAT) AS change_00s
FROM table_1_13630888_1
WHERE [Region/country] IN ('China', 'East Asia', 'South-East Asia');",reward,,
"For each Region (limit to 5 rows), provide Region, Total Population, Catholic, Computed % Catholic as (Catholic * 100.0 / Total Population), Computed % of global Catholic pop. as (Catholic * 100.0 / 135211325.0), the Penetration Rank defined as 1 plus the count of regions with a larger Catholic value, and boolean flags for (Region = 'Central Africa'), (Region = 'East Africa'), (Region = 'North Africa'), (Region = 'Southern Africa'), and (Region = 'West Africa')?","
SELECT DISTINCT
  t1.`Region`,
  t1.`Total Population`,
  t1.`Catholic`,
  (t1.`Catholic` * 100.0 / t1.`Total Population`) `Computed % Catholic`,
  (t1.`Catholic` * 100.0 / 135211325.0) `Computed % of global Catholic pop.`,
  (SUM(CASE WHEN t2.`Catholic` > t1.`Catholic` THEN 1 END) + 1) `Penetration Rank`,
  (t1.`Region` = 'Central Africa') `Central Africa`,
  (t1.`Region` = 'East Africa') `East Africa`,
  (t1.`Region` = 'North Africa') `North Africa`,
  (t1.`Region` = 'Southern Africa') `Southern Africa`,
  (t1.`Region` = 'West Africa') `West Africa`
FROM `table_1_1364343_2` AS t1
JOIN `table_1_1364343_2` t2 ON 1=1
WHERE 1 IS 1
GROUP BY t1.`Region`, t1.`Total Population`, t1.`Catholic`
LIMIT 5;
","
SELECT DISTINCT
  t1.col0,
  t1.col1,
  t1.col2,
  (t1.col2 * 100.0 / t1.col1) `Computed % Catholic`,
  (t1.col2 * 100.0 / 135211325.0) `Computed % of global Catholic pop.`,
  (SUM(CASE WHEN t2.col2 > t1.col2 THEN 1 END) + 1) `Penetration Rank`,
  (t1.col0 = 'Central Africa') `Central Africa`,
  (t1.col0 = 'East Africa') `East Africa`,
  (t1.col0 = 'North Africa') `North Africa`,
  (t1.col0 = 'Southern Africa') `Southern Africa`,
  (t1.col0 = 'West Africa') `West Africa`
FROM `table_1_1364343_2` AS t1
JOIN `table_1_1364343_2` t2 ON 1=1
WHERE 1 IS 1
GROUP BY t1.col0, t1.col1, t1.col2
LIMIT 5;
","[('central africa', 83121055.0, 37353218.0, 44.93833481781481, 27.625805752587663, None, 0, 0, 0, 0, 0), ('east africa', 193741900.0, 34872130.0, 17.999271195337716, 25.7908351981611, 3, 0, 0, 0, 0, 0), ('north africa', 202151323.0, 2369490.0, 1.1721367759735117, 1.7524345686280347, 5, 0, 0, 0, 0, 0), ('southern africa', 137092019.0, 24463640.0, 17.844685765405497, 18.092892736610636, 4, 0, 0, 0, 0, 0), ('west africa', 268997245.0, 36152847.0, 13.43985772047591, 26.738031744012567, 2, 0, 0, 0, 0, 0)]",table_1_1364343_2,"1) The SQL returns distinct rows with computed percentages, a relative rank, and explicit boolean flags for five named regions, limited to five rows. 2) Map the computed % Catholic, computed % of global Catholic pop (using 135211325.0), the penetration rank definition, and the five equality checks. 3) Draft a question requesting those fields for each region and limiting the result to five rows as in the query. 4) Validate that all calculations, columns, and the LIMIT are mentioned.",reserved,15,reward,,
"For each GTO Winning Team (returned as ""GTO Team"") whose GTO Winning Team value begins with '#', what is the COUNT(*) of matching rows (as ""Wins"") and the comma-space separated GROUP_CONCAT of the matching rows' GTO Winning Team values (as ""Drivers"") from rows joined on the same Rnd and Circuit where the joined row's GTO Winning Team does NOT begin with '#', considering only circuits present in the table, grouping by the GTO Winning Team, including only groups with COUNT(*) > 0, ordered by Wins descending and limited to the top 10?","
SELECT t_team.`GTO Winning Team` AS `GTO Team`, COUNT(*) AS `Wins`, GROUP_CONCAT(t_driver.`GTO Winning Team`, ', ') AS `Drivers`
FROM `table_1_13657883_2` t_team
JOIN `table_1_13657883_2` t_driver ON t_team.`Rnd`||'|'||t_team.`Circuit` = t_driver.`Rnd`||'|'||t_driver.`Circuit`
WHERE substr(t_team.`GTO Winning Team`,1,1) = '#' AND substr(t_driver.`GTO Winning Team`,1,1) != '#'
AND t_team.`Circuit` IN (SELECT `Circuit` FROM `table_1_13657883_2`)
GROUP BY t_team.`GTO Winning Team`
HAVING COUNT(*) > 0
ORDER BY `Wins` DESC
LIMIT 10;
","
SELECT t_team.col2 AS `GTO Team`, COUNT(*) AS `Wins`, GROUP_CONCAT(t_driver.col2, ', ') AS `Drivers`
FROM `table_1_13657883_2` t_team
JOIN `table_1_13657883_2` t_driver ON t_team.col0||'|'||t_team.col1 = t_driver.col0||'|'||t_driver.col1
WHERE substr(t_team.col2,1,1) = '#' AND substr(t_driver.col2,1,1) != '#'
AND t_team.col1 IN (SELECT col1 FROM `table_1_13657883_2`)
GROUP BY t_team.col2
HAVING COUNT(*) > 0
ORDER BY `Wins` DESC
LIMIT 10;
","[('#99 phil currin', 2, 'phil currin, phil currin'), ('#48 greenwood racing', 1, 'john greenwood marshall robbins'), ('#48 corvette', 1, 'charles west'), ('#42 corvette', 1, 'garrett waddall'), ('#41 corvette', 1, 'bud deshler rodney harris'), ('#23 corvette', 1, 'charlie kemp wilbur pickett'), ('#22 corvette', 1, 'denny long'), ('#2 holiday inn corvette', 1, 'wilbur pickett')]",table_1_13657883_2,"1) The query counts rows per GTO Winning Team (alias GTO Team), concatenates matching driver names, joins rows by matching Rnd and Circuit, filters team values that start with '#' and driver values that do not, groups by team, and returns the top 10 by count. 2) The table uses the column GTO Winning Team both for team identifiers (starting with '#') and for driver names (not starting with '#'), with Rnd and Circuit identifying matching race entries. 3) Draft a question asking for each GTO Winning Team (as GTO Team) that begins with '#', the number of wins (COUNT(*) AS Wins) and a comma-space separated list (GROUP_CONCAT(..., ', ')) of the matching GTO Winning Team driver names from rows with the same Rnd and Circuit where the driver values do not begin with '#', restricted to circuits present in the table, grouped by GTO Winning Team, only including groups with COUNT(*) > 0, ordered by Wins descending and limited to 10. 4) Validate that the question mentions the join on Rnd and Circuit, the substr conditions, the aliases GTO Team/Wins/Drivers, grouping, HAVING, ORDER BY DESC and LIMIT 10.",reserved,14,reward,,
"Which developers/publishers should I prioritize because they have JP-only releases, explicitly delisted games, or messy Wii Points entries — give me the count of problematic items, the JP-only count, the delisted count, the inconsistent-price count, and the list of titles with their Wii Points?","
SELECT
  `Developer(s)/Publisher(s)` AS `Developer(s)/Publisher(s)`,
  COUNT(*) AS `Problematic Count`,
  GROUP_CONCAT(`Title and Source`, ' | ') AS `Titles`,
  GROUP_CONCAT(`Wii Points`, ' | ') AS `Wii Points List`,
  SUM(CASE WHEN `JP -210-` = 'Yes' AND `NA -350-` = 'No' AND `PAL -295-` = 'No' THEN 1 ELSE 0 END) AS `JP-Only Count`,
  SUM(CASE WHEN `Title and Source` LIKE '%no longer available%' THEN 1 ELSE 0 END) AS `Delisted Count`,
  SUM(CASE WHEN (`Wii Points` LIKE '% %' OR `Wii Points` LIKE '%NA%' OR `Wii Points` LIKE '%JP%' OR `Wii Points` LIKE '%PAL%') THEN 1 ELSE 0 END) AS `Inconsistent Pricing Count`
FROM `table_1_13663434_1`
WHERE
  (`JP -210-` = 'Yes' AND `NA -350-` = 'No' AND `PAL -295-` = 'No')
  OR `Title and Source` LIKE '%no longer available%'
  OR (`Wii Points` LIKE '% %' OR `Wii Points` LIKE '%NA%' OR `Wii Points` LIKE '%JP%' OR `Wii Points` LIKE '%PAL%')
GROUP BY `Developer(s)/Publisher(s)`
ORDER BY `Problematic Count` DESC, `Inconsistent Pricing Count` DESC;
","
SELECT
  col1 AS col1,
  COUNT(*) AS `Problematic Count`,
  GROUP_CONCAT(col0, ' | ') AS `Titles`,
  GROUP_CONCAT(col5, ' | ') AS `Wii Points List`,
  SUM(CASE WHEN col2 = 'Yes' AND col3 = 'No' AND col4 = 'No' THEN 1 ELSE 0 END) AS `JP-Only Count`,
  SUM(CASE WHEN col0 LIKE '%no longer available%' THEN 1 ELSE 0 END) AS `Delisted Count`,
  SUM(CASE WHEN (col5 LIKE '% %' OR col5 LIKE '%NA%' OR col5 LIKE '%JP%' OR col5 LIKE '%PAL%') THEN 1 ELSE 0 END) AS `Inconsistent Pricing Count`
FROM `table_1_13663434_1`
WHERE
  (col2 = 'Yes' AND col3 = 'No' AND col4 = 'No')
  OR col0 LIKE '%no longer available%'
  OR (col5 LIKE '% %' OR col5 LIKE '%NA%' OR col5 LIKE '%JP%' OR col5 LIKE '%PAL%')
GROUP BY col1
ORDER BY `Problematic Count` DESC, `Inconsistent Pricing Count` DESC;
","[('gameloft', 3, 'midnight bowling hamaru bowling jp | midnight pool hamaru billiards jp | uno', '1000 jp 800 | 800 500 jp | 1000 na 800 jp 500 pal', 0, 0, 3), ('square enix', 2, 'crystal defenders r1 | crystal defenders r2', '1000 jp 800 | 1000 jp 800', 0, 0, 2), ('akaoni studio , marvelous entertainment', 1, 'zombie panic in wonderland zombie in wonderland jp', '1000 800 jp', 0, 0, 1), ('arc system works', 1, 'family table tennis okiraku ping pong wii jp', '800 pal 500', 0, 0, 1), ('artefacts studio , zallag', 1, 'gods vs. humans (no longer available in europe)', '1500 1200 na', 0, 1, 1), ('bigben interactive', 1, ""pucca's kisses game"", '1000 500 na', 0, 0, 1), ('bplus', 1, ""plättchen twist 'n' paint"", '1500 pal 1000', 0, 0, 1), ('bplus , marvelous entertainment', 1, 'bit boy!! bit man!! jp', '600 500 jp', 0, 0, 1), ('coresoft inc.', 1, 'blood beach', '1000 na 500', 0, 0, 1), ('engine software', 1, 'bang attack', '600 pal 500', 0, 0, 1), ('enjoyup games', 1, 'chronos twins dx', '1000 na 700', 0, 0, 1), ('exkee , luck plus', 1, 'colorz', '800 jp 700', 0, 0, 1), ('frozen codebase', 1, 'jam city rollergirls', '1000 na 500', 0, 0, 1), ('gaijin games , aksys games', 1, 'bit.trip beat', '600 500 jp', 0, 0, 1), ('genki , nintendo', 1, 'lonpos (no longer available in all regions)', '1000 jp 800', 0, 1, 1), ('konami', 1, 'frogger: hyper arcade edition', '1000 pal 700', 0, 0, 1), ('konami , m2', 1, 'gradius rebirth', '1000 600 pal', 0, 0, 1), ('namco bandai', 1, 'muscle march muscle kōshinkyoku jp', '800 jp 500', 0, 0, 1), ('nigoro , nicalis , asterizm', 1, 'la-mulana', '1200 jp 1000', 0, 0, 1), ('nocturnal entertainment', 1, ""flowerworks flowerworks: follie's adventure pal"", '1000 na 500', 0, 0, 1), ('over the top games , agatsuma entertainment', 1, 'nyxquest: kindred spirits', '1000 900 jp', 0, 0, 1), ('pinnacle entertainment ltd.', 1, 'manic monkey mayhem', '1000 pal 800', 0, 0, 1), ('press play , marvelous entertainment', 1, 'max & the magic marker rakugaki hero jp', '1000 800 jp', 0, 0, 1), ('qubicgames', 1, 'gnomz', '1000 500 pal', 0, 0, 1), ('sega', 1, 'sonic the hedgehog 4: episode i', '1500 1000 jp', 0, 0, 1), (""shin'en multimedia"", 1, 'fun! fun! minigolf', '1000 jp 900', 0, 0, 1), ('studio pixel , nicalis', 1, 'cave story', '1200 na 1000', 0, 0, 1), ('taito', 1, 'bubble bobble plus! bubble bobble wii jp', '800 600 na', 0, 0, 1), ('two tribes b.v.', 1, 'toki tori', '1000 na 900', 0, 0, 1), ('wayforward technologies , square enix', 1, 'lit school of darkness jp', '1000 jp 800', 0, 0, 1), ('zoonami , nintendo', 1, 'bonsai barber', '1000 800 jp', 0, 0, 1), ('ludia', 1, 'planet fish (no longer available in north america)', '500', 0, 1, 0), ('sunsoft', 1, 'princess ai monogatari (no longer available)', '500', 0, 1, 0)]",table_1_13663434_1,"The curator voice is practical and might ask which developers to target for funding or archival based on messy pricing and region exclusives. The SQL selects any row that is JP-only, literally 'no longer available', or whose Wii Points contain spaces or region tags, then aggregates by developer/publisher with counts and concatenated title/price lists plus per-category sums. It maps directly to 'Developer(s)/Publisher(s)', 'Title and Source', region columns and 'Wii Points'. Drafted question: Which developers/publishers should I prioritize because they have JP-only releases, explicitly delisted games, or messy Wii Points entries — give me total problematic counts, JP-only counts, delisted counts, inconsistent-price counts, and the list of titles with their Wii Points. Validate: This aligns with the query's filters, grouped counts, concatenated lists and per-category totals and doesn't request anything outside that scope.",persona,"```json
{
  ""short_persona_description"": ""A 'WiiWare Restoration Curator' running a small digital museum dedicated to rescuing, documenting and exhibiting region-exclusive or delisted WiiWare titles and their pricing quirks."",
  ""goals"": [
    ""Locate region-exclusive (e.g., JP-only) or explicitly delisted titles to prioritize for archival/restoration."",
    ""Detect inconsistent or multi-region pricing entries in the 'Wii Points' field to document pricing history and find restoration funding tar Goals:  Example Queries: ",reward,,
Which countries have the lowest daily inflation rates?,"
SELECT `Country`, '`' || `Country` || '`', `Currency name`, REPLACE(`Equivalent daily inflation rate`,'%','')+0.0,
CASE WHEN instr(`Time required for prices to double`,'hour')>0 THEN REPLACE(`Time required for prices to double`,' hours','')+0.0 ELSE (REPLACE(`Time required for prices to double`,' days','')+0.0)*24 END AS `DoublingHours`
FROM `table_1_13681_2`
WHERE (REPLACE(`Equivalent daily inflation rate`,'%','')+0.0)>20 AND (REPLACE(`Equivalent daily inflation rate`,'%','')+0.0)<1e12 OR (REPLACE(`Equivalent daily inflation rate`,'%','')+0.0)>0
GROUP BY `Country`
ORDER BY REPLACE(`Equivalent daily inflation rate`,'%','')+0.0
LIMIT 3;
","
SELECT col0, '`' || col0 || '`', col1, REPLACE(col4,'%','')+0.0,
CASE WHEN instr(col5,'hour')>0 THEN REPLACE(col5,' hours','')+0.0 ELSE (REPLACE(col5,' days','')+0.0)*24 END AS `DoublingHours`
FROM `table_1_13681_2`
WHERE (REPLACE(col4,'%','')+0.0)>20 AND (REPLACE(col4,'%','')+0.0)<1e12 OR (REPLACE(col4,'%','')+0.0)>0
GROUP BY col0
ORDER BY REPLACE(col4,'%','')+0.0
LIMIT 3;
","[('germany', '`germany`', 'german papiermark', 20.87, 88.80000000000001), ('republika srpska', '`republika srpska`', 'republika srpska dinar', 64.3, 33.599999999999994), ('yugoslavia', '`yugoslavia`', 'yugoslav dinar', 64.63, 33.599999999999994)]",table_1_13681_2,"STEP 1: Parse the SQL intent — select Country, Currency name, numeric Equivalent daily inflation rate (percent sign removed), compute Time required for prices to double in hours, filter rows where the numeric daily rate > 0 (the WHERE clause effectively reduces to rate > 0), group by Country, order by the numeric daily rate ascending, limit to 3 rows — so it returns the three countries with the smallest positive equivalent daily inflation rates and their computed doubling hours. STEP 2: Choose an ambiguity type — scope ambiguity fits well: the phrase asking for the ""lowest inflation rates"" can refer to a single lowest country, the three lowest, lowest per some grouping/timeframe, or lowest non-negative vs overall lowest. This query specifically picks the three smallest positive daily rates. STEP 3: Draft the question — ""Which countries have the lowest daily inflation rates?"" STEP 4: Explain the ambiguity — in the SQL this is concretely interpreted as the three countries with the smallest positive Equivalent daily inflation rate (ordered asc, LIMIT 3). Alternatively the question could mean the single country with the absolute lowest rate, the lowest rate per year/month, the lowest among currencies vs countries, or whether zero/negative rates should be considered.",reserved,15,reward,,"type: Scope ambiguity | explanation: The SQL returns the three countries with the smallest positive equivalent daily inflation rates (ORDER BY rate ASC LIMIT 3). The natural question is ambiguous because it could instead be asking for the single country with the absolute lowest rate, the lowest rate per time period, the lowest among different entity granularities (currency vs country), or whether zero/negative rates are included."
"For the tournament labeled 'Sub-totals oficial matches', provide Matches = 317, Wins Olimpia = 109, Empates = 98, Wins Cerro = 110, Goals Olimpia = 410, Goals Cerro = 402, the computed Wins Diff = (109-110), Goals Diff = (410-402), Win Rate Olimpia = round(109.0/317.0*100,2), Win Rate Cerro = round(110.0/317.0*100,2), Close Contest = ((abs(410-402)<=1)*(abs(109-110)<=1)), and Note = NULL, given that 317 > 0 and abs(410-402) > 0 and (410-402) > 0?","
SELECT
 '`Sub-totals oficial matches`' `Tournament`,
 317 `Matches`,
 109 `Wins Olimpia`,
 98 `Empates`,
 110 `Wins Cerro`,
 410 `Goals Olimpia`,
 402 `Goals Cerro`,
 (109-110) `Wins Diff`,
 (410-402) `Goals Diff`,
 round(109.0/317.0*100,2) `Win Rate Olimpia`,
 round(110.0/317.0*100,2) `Win Rate Cerro`,
 ((abs(410-402)<=1)*(abs(109-110)<=1)) `Close Contest`,
 NULL `Note`
WHERE 317>0 AND (abs(410-402)>0)
GROUP BY '`Sub-totals oficial matches`'
HAVING (410-402)>0
LIMIT 1;
","
SELECT
 '`Sub-totals oficial matches`' col0,
 317 col1,
 109 col2,
 98 col3,
 110 col4,
 410 col5,
 402 col6,
 (109-110) `Wins Diff`,
 (410-402) `Goals Diff`,
 round(109.0/317.0*100,2) `Win Rate Olimpia`,
 round(110.0/317.0*100,2) `Win Rate Cerro`,
 ((abs(410-402)<=1)*(abs(109-110)<=1)) `Close Contest`,
 NULL `Note`
WHERE 317>0 AND (abs(410-402)>0)
GROUP BY '`Sub-totals oficial matches`'
HAVING (410-402)>0
LIMIT 1;
","[('`Sub-totals oficial matches`', 317, 109, 98, 110, 410, 402, -1, 8, 34.38, 34.7, 0, None)]",table_1_13688489_1,"1) The SQL explicitly returns literal column values and calculated fields for the subtotal tournament row, filtering by positive nonzero goal advantage and requiring matches > 0. 2) Map the table row values and calculations: 317 matches, 109/98/110 results, 410 and 402 goals, diffs and percentages as in the query. 3) Draft a question that includes every returned field and the filtering/grouping constraints. 4) Validate inclusion of Wins Diff (109-110), Goals Diff (410-402), both win rate calculations, the Close Contest Boolean expression, and Note NULL.",reserved,8,reward,,
"List up to 10 Locations (ordered by Total Attendance ascending) for which SUM(Attendance) > 38000, using only rows where Attendance > 0, and for each Location show Location, the number of games (COUNT(Date) as Games), SUM(Attendance) as Total Attendance, AVG(Attendance) as Avg Attendance, MAX(Attendance) as Max Attendance, and MIN(Attendance) as Min Attendance?","
SELECT `Location`, COUNT(`Date`) `Games`, SUM(`Attendance`) `Total Attendance`, AVG(`Attendance`) `Avg Attendance`, MAX(`Attendance`) `Max Attendance`, MIN(`Attendance`) `Min Attendance`
FROM `table_1_13710464_1`
WHERE `Attendance` > 0
GROUP BY `Location`
HAVING SUM(`Attendance`) > 38000
ORDER BY `Total Attendance`
LIMIT 10;
","
SELECT col6, COUNT(col0) `Games`, SUM(col5) `Total Attendance`, AVG(col5) `Avg Attendance`, MAX(col5) `Max Attendance`, MIN(col5) `Min Attendance`
FROM `table_1_13710464_1`
WHERE col5 > 0
GROUP BY col6
HAVING SUM(col5) > 38000
ORDER BY `Total Attendance`
LIMIT 10;
","[('houston', 2, 78067.0, 39033.5, 41868.0, 36199.0), ('arlington', 3, 114473.0, 38157.666666666664, 40583.0, 35781.0)]",table_1_13710464_1,"1) Parse intent: aggregate by Location to get games count and attendance summary metrics, filter out Attendance <= 0, keep groups whose SUM(Attendance) > 38000, order by total attendance and limit to 10. 2) Map schema: Date -> Games count, Attendance -> total/avg/max/min, Location -> grouping key. 3) Draft: ask for Location plus COUNT(Date) (Games), SUM/AVG/MAX/MIN of Attendance with the given WHERE, HAVING, ORDER BY, LIMIT constraints. 4) Validate: all SQL components and column calculations are explicitly referenced in the question.",reserved,8,reward,,
"Can you give me a date-sorted timeline of acquisitions for exhibit captions — showing asset, acquired-from, announced and completed dates converted to ISO, the original reported cost verbatim, a normalized estimated USD value, and flags for undisclosed costs or date anomalies?","
WITH parsed AS (
  SELECT
    `Asset Acquired`,
    `Acquired From`,
    `Date Announced`,
    CASE
      WHEN `Date Announced` <> 'Not Disclosed' THEN (
        -- parse announced date ""Month DD, YYYY"" into ISO YYYY-MM-DD
        (SUBSTR(`Date Announced`, INSTR(`Date Announced`, ',')+2, 4)) || '-' ||
        (CASE SUBSTR(`Date Announced`, 1, INSTR(`Date Announced`, ' ')-1)
          WHEN 'January' THEN '01' WHEN 'February' THEN '02' WHEN 'March' THEN '03'
          WHEN 'April' THEN '04' WHEN 'May' THEN '05' WHEN 'June' THEN '06'
          WHEN 'July' THEN '07' WHEN 'August' THEN '08' WHEN 'September' THEN '09'
          WHEN 'October' THEN '10' WHEN 'November' THEN '11' WHEN 'December' THEN '12'
          ELSE '00' END) || '-' ||
        printf('%02d', CAST(TRIM(SUBSTR(`Date Announced`, INSTR(`Date Announced`, ' ')+1, INSTR(`Date Announced`, ',') - INSTR(`Date Announced`, ' ')-1)) AS INTEGER))
      )
      ELSE NULL
    END AS `Announced_ISO`,
    `Date Completed`,
    CASE
      WHEN `Date Completed` <> 'Not Disclosed' THEN (
        (SUBSTR(`Date Completed`, INSTR(`Date Completed`, ',')+2, 4)) || '-' ||
        (CASE SUBSTR(`Date Completed`, 1, INSTR(`Date Completed`, ' ')-1)
          WHEN 'January' THEN '01' WHEN 'February' THEN '02' WHEN 'March' THEN '03'
          WHEN 'April' THEN '04' WHEN 'May' THEN '05' WHEN 'June' THEN '06'
          WHEN 'July' THEN '07' WHEN 'August' THEN '08' WHEN 'September' THEN '09'
          WHEN 'October' THEN '10' WHEN 'November' THEN '11' WHEN 'December' THEN '12'
          ELSE '00' END) || '-' ||
        printf('%02d', CAST(TRIM(SUBSTR(`Date Completed`, INSTR(`Date Completed`, ' ')+1, INSTR(`Date Completed`, ',') - INSTR(`Date Completed`, ' ')-1)) AS INTEGER))
      )
      ELSE NULL
    END AS `Completed_ISO`,
    `Reported Cost`,
    -- normalize numeric portion and estimate USD (assume A$ -> USD multiplier 0.75; all ""million"" units)
    CASE
      WHEN `Reported Cost` = 'Not Disclosed' THEN NULL
      WHEN `Reported Cost` LIKE 'US$%' THEN
        CAST(
          TRIM(
            REPLACE(
              REPLACE(
                REPLACE(
                  REPLACE(`Reported Cost`, 'US$', ''),
                'A$', ''),
              'million', ''),
            ',', '')
          ) AS REAL
        ) * 1000000.0
      WHEN `Reported Cost` LIKE 'A$%' THEN
        CAST(
          TRIM(
            REPLACE(
              REPLACE(
                REPLACE(
                  REPLACE(`Reported Cost`, 'A$', ''),
                'US$', ''),
              'million', ''),
            ',', '')
          ) AS REAL
        ) * 1000000.0 * 0.75
      ELSE NULL
    END AS `Estimated_USD`
  FROM `table_1_1373542_1`
)
SELECT
  `Asset Acquired`,
  `Acquired From`,
  `Date Announced`,
  `Announced_ISO`,
  `Date Completed`,
  `Completed_ISO`,
  -- present the original reported cost verbatim but encapsulated in backticks for exhibit-ready captions
  CASE WHEN `Reported Cost` = 'Not Disclosed' THEN '`Not Disclosed`' ELSE '`' || `Reported Cost` || '`' END AS `Reported Cost (verbatim)`,
  -- rounded estimated USD for display (NULL means undisclosed or unparsable)
  ROUND(`Estimated_USD`, 2) AS `Estimated_USD`,
  -- flags for actionable archival follow-ups
  CASE WHEN `Reported Cost` = 'Not Disclosed' THEN '`Undisclosed Cost`' ELSE '`Cost Disclosed`' END AS `Cost_Disclosure_Flag`,
  CASE
    WHEN `Announced_ISO` IS NOT NULL AND `Completed_ISO` IS NOT NULL AND `Completed_ISO` < `Announced_ISO`
      THEN '`Completion Before Announcement`'
    WHEN `Announced_ISO` IS NULL OR `Completed_ISO` IS NULL
      THEN '`Missing Date`'
    ELSE NULL
  END AS `Date_Anomaly_Flag`
FROM parsed
ORDER BY COALESCE(`Completed_ISO`, `Announced_ISO`) ASC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    CASE
      WHEN col2 <> 'Not Disclosed' THEN (
        -- parse announced date ""Month DD, YYYY"" into ISO YYYY-MM-DD
        (SUBSTR(col2, INSTR(col2, ',')+2, 4)) || '-' ||
        (CASE SUBSTR(col2, 1, INSTR(col2, ' ')-1)
          WHEN 'January' THEN '01' WHEN 'February' THEN '02' WHEN 'March' THEN '03'
          WHEN 'April' THEN '04' WHEN 'May' THEN '05' WHEN 'June' THEN '06'
          WHEN 'July' THEN '07' WHEN 'August' THEN '08' WHEN 'September' THEN '09'
          WHEN 'October' THEN '10' WHEN 'November' THEN '11' WHEN 'December' THEN '12'
          ELSE '00' END) || '-' ||
        printf('%02d', CAST(TRIM(SUBSTR(col2, INSTR(col2, ' ')+1, INSTR(col2, ',') - INSTR(col2, ' ')-1)) AS INTEGER))
      )
      ELSE NULL
    END AS `Announced_ISO`,
    col3,
    CASE
      WHEN col3 <> 'Not Disclosed' THEN (
        (SUBSTR(col3, INSTR(col3, ',')+2, 4)) || '-' ||
        (CASE SUBSTR(col3, 1, INSTR(col3, ' ')-1)
          WHEN 'January' THEN '01' WHEN 'February' THEN '02' WHEN 'March' THEN '03'
          WHEN 'April' THEN '04' WHEN 'May' THEN '05' WHEN 'June' THEN '06'
          WHEN 'July' THEN '07' WHEN 'August' THEN '08' WHEN 'September' THEN '09'
          WHEN 'October' THEN '10' WHEN 'November' THEN '11' WHEN 'December' THEN '12'
          ELSE '00' END) || '-' ||
        printf('%02d', CAST(TRIM(SUBSTR(col3, INSTR(col3, ' ')+1, INSTR(col3, ',') - INSTR(col3, ' ')-1)) AS INTEGER))
      )
      ELSE NULL
    END AS `Completed_ISO`,
    col4,
    -- normalize numeric portion and estimate USD (assume A$ -> USD multiplier 0.75; all ""million"" units)
    CASE
      WHEN col4 = 'Not Disclosed' THEN NULL
      WHEN col4 LIKE 'US$%' THEN
        CAST(
          TRIM(
            REPLACE(
              REPLACE(
                REPLACE(
                  REPLACE(col4, 'US$', ''),
                'A$', ''),
              'million', ''),
            ',', '')
          ) AS REAL
        ) * 1000000.0
      WHEN col4 LIKE 'A$%' THEN
        CAST(
          TRIM(
            REPLACE(
              REPLACE(
                REPLACE(
                  REPLACE(col4, 'A$', ''),
                'US$', ''),
              'million', ''),
            ',', '')
          ) AS REAL
        ) * 1000000.0 * 0.75
      ELSE NULL
    END AS `Estimated_USD`
  FROM `table_1_1373542_1`
)
SELECT
  col0,
  col1,
  col2,
  `Announced_ISO`,
  col3,
  `Completed_ISO`,
  -- present the original reported cost verbatim but encapsulated in backticks for exhibit-ready captions
  CASE WHEN col4 = 'Not Disclosed' THEN '`Not Disclosed`' ELSE '`' || col4 || '`' END AS `Reported Cost (verbatim)`,
  -- rounded estimated USD for display (NULL means undisclosed or unparsable)
  ROUND(`Estimated_USD`, 2) AS `Estimated_USD`,
  -- flags for actionable archival follow-ups
  CASE WHEN col4 = 'Not Disclosed' THEN '`Undisclosed Cost`' ELSE '`Cost Disclosed`' END AS `Cost_Disclosure_Flag`,
  CASE
    WHEN `Announced_ISO` IS NOT NULL AND `Completed_ISO` IS NOT NULL AND `Completed_ISO` < `Announced_ISO`
      THEN '`Completion Before Announcement`'
    WHEN `Announced_ISO` IS NULL OR `Completed_ISO` IS NULL
      THEN '`Missing Date`'
    ELSE NULL
  END AS `Date_Anomaly_Flag`
FROM parsed
ORDER BY COALESCE(`Completed_ISO`, `Announced_ISO`) ASC;
","[('mpower.com, inc', 'privately held', 'may 30, 2003', '2003-00-30', 'july 2, 2003', '2003-00-02', '`not disclosed`', None, '`Cost Disclosed`', '`Completion Before Announcement`'), ('vards', 'finetre corporation', 'january 11, 2005', '2005-00-11', 'january 4, 2005', '2005-00-04', '`us$9 million`', 0.0, '`Cost Disclosed`', '`Completion Before Announcement`'), ('ibbotson associates', 'privately held', 'december 12, 2005', '2005-00-12', 'march 1, 2006', '2006-00-01', '`us$83 million`', 0.0, '`Cost Disclosed`', None), ('aspect huntley', 'privately held', 'july 2, 2006', '2006-00-02', 'july 25, 2006', '2006-00-25', '`a$ 30 million`', 0.0, '`Cost Disclosed`', None), ('fund data business (prev. micropal & assirt )', ""standard & poor's"", 'february 22, 2007', '2007-00-22', 'march 16, 2007', '2007-00-16', '`us$55 million`', 0.0, '`Cost Disclosed`', '`Completion Before Announcement`'), ('epiper separate account database', 'pensions & investments', 'september 7, 2004', '2004-00-07', 'not disclosed', 'ot d-00-00', '`not disclosed`', None, '`Cost Disclosed`', None)]",table_1_1373542_1,"As a corporate archaeologist I know enough about the records to ask for cleaned, exhibit-ready fields without writing SQL myself. The query is parsing announcement and completion dates into ISO, normalizing reported costs into USD estimates, and flagging missing or anomalous dates. It maps 'Asset Acquired', 'Acquired From', 'Date Announced', 'Date Completed', and 'Reported Cost' into cleaned ISO dates, verbatim cost, estimated USD and flags. Draft question: ask for a date-sorted timeline for captions including ISO dates, original reported cost verbatim, estimated USD, and disclosure/date-anomaly flags. Validate: the SQL returns exactly those fields ordered by completion/announcement date so this question matches the output.",persona,"An independent 'corporate archaeologist' who reconstructs the hidden history of financial data-vendor consolidation for an interactive museum exhibit and investigative catalogue. Goals: Build a chronological timeline of acquisitions with clean, date-sorted records for exhibit captions. Normalize and compare reported acquisition costs (convert currencies, flag 'Not Disclosed') so values can be presented uniformly in USD estimates. Detect anomalies and inconsistencies (e.g., completion dates before announcement dates, undisclosed costs) to target archival deep-dives and interview questions. Example Queries: SELECT `Asset Acquired`, `Acquired From`, `Date Announced`, `Date Completed`, `Reported Cost` FROM table_1_1373542_1 WHERE `Date Completed` <> 'Not Disclosed' ORDER BY STR_TO_DATE(`Date Completed`, '%M %e, %Y'); SELECT `Asset Acquired`, `Reported Cost`,
  CASE
    WHEN `Reported Cost` LIKE 'US$%' THEN CAST(REPLACE(REPLACE(`Reported Cost`, 'US$', ''), ',', '') AS DECIMAL(14,2))
    WHEN `Reported Cost` LIKE 'A$%' THEN CAST(REPLACE(REPLACE(`Reported Cost`, 'A$', ''), ',', '') AS DECIMAL(14,2)) * 0.75
    ELSE NULL
  END AS estimated_usd
FROM table_1_1373542_1
WHERE `Reported Cost` <> 'Not Disclosed'; SELECT `Asset Acquired`, `Date Announced`, `Date Completed` FROM table_1_1373542_1
WHERE `Date Announced` <> 'Not Disclosed' AND `Date Completed` <> 'Not Disclosed'
  AND STR_TO_DATE(`Date Completed`, '%M %e, %Y') < STR_TO_DATE(`Date Announced`, '%M %e, %Y');",reward,,
"List each Election date with Party leader, Number of votes received, Percentage of votes, Number of deputies, the votes per deputy calculated as Number of votes received / Number of deputies, the vote_change equal to Number of votes received minus the previous Number of votes received when ordered by Election date, a percentage_flag equal to 'LOW_PERCENT' if Percentage of votes is not '100%' else 'FULL_PERCENT', and a column containing 'Habib Bourguiba', with the output ordered by Election date?","
SELECT
`Election date`,
`Party leader`,
`Number of votes received`,
`Percentage of votes`,
`Number of deputies`,
(`Number of votes received` / `Number of deputies`) `votes per deputy`,
`Number of votes received` - LAG(`Number of votes received`) OVER (ORDER BY `Election date`) `vote_change`,
CASE WHEN `Percentage of votes` != '100%' THEN 'LOW_PERCENT' ELSE 'FULL_PERCENT' END `percentage_flag`,
'Habib Bourguiba' `Habib Bourguiba`
FROM `table_1_13746866_2`
ORDER BY `Election date`;
","
SELECT
col0,
col1,
col2,
col3,
col4,
(col2 / col4) `votes per deputy`,
col2 - LAG(col2) OVER (ORDER BY col0) `vote_change`,
CASE WHEN col3 != '100%' THEN 'LOW_PERCENT' ELSE 'FULL_PERCENT' END `percentage_flag`,
'Habib Bourguiba' `Habib Bourguiba`
FROM `table_1_13746866_2`
ORDER BY col0;
","[(1964.0, 'habib bourguiba', 1255153.0, '100%', 101.0, 12427.257425742575, None, 'FULL_PERCENT', 'Habib Bourguiba'), (1969.0, 'habib bourguiba', 1363939.0, '100%', 101.0, 13504.346534653465, 108786.0, 'FULL_PERCENT', 'Habib Bourguiba'), (1974.0, 'habib bourguiba', 1570954.0, '100%', 112.0, 14026.375, 207015.0, 'FULL_PERCENT', 'Habib Bourguiba'), (1979.0, 'habib bourguiba', 1560753.0, '100%', 121.0, 12898.785123966942, -10201.0, 'FULL_PERCENT', 'Habib Bourguiba'), (1981.0, 'habib bourguiba', 1828363.0, '94.2%', 136.0, 13443.845588235294, 267610.0, 'LOW_PERCENT', 'Habib Bourguiba')]",table_1_13746866_2,"1) The query returns every row ordered by Election date and adds derived columns: votes per deputy, vote_change using LAG over Election date, a flag based on Percentage of votes, plus a literal string column. 2) Identify the base columns Election date, Party leader, Number of votes received, Percentage of votes, Number of deputies and the computed fields. 3) Write a question asking for those base columns, the division for votes per deputy, the difference from the prior Number of votes received using Election date ordering, the CASE flag mapping to 'LOW_PERCENT' or 'FULL_PERCENT', and the literal 'Habib Bourguiba'. 4) Ensure the question explicitly requests ordering by Election date.",reserved,12,reward,,
"Using a LEFT JOIN of the table to itself ON Game, for rows where High points IS NOT NULL and (Date IN ('May 23','May 25','May 27','May 29','May 31') OR Series = '3–1'), what are the totals per Location_Class (where Location_Class = CASE WHEN Team IN ('@ Detroit','Detroit') THEN 'Away' ELSE 'Home' END) of Games (COUNT(*)), Wins (SUM(substr(Score,1,1) = 'W')) and Losses (SUM(substr(Score,1,1) = 'L')), returning only groups with Games > 0 and up to 10 results?","
SELECT CASE WHEN t.`Team` IN ('`@ Detroit`','`Detroit`') THEN '`Away`' ELSE '`Home`' END AS `Location_Class`, COUNT(*) `Games`, SUM(substr(t.`Score`,1,1)='W') `Wins`, SUM(substr(t.`Score`,1,1)='L') `Losses` FROM `table_1_13762472_13` t LEFT JOIN `table_1_13762472_13` s ON t.`Game`=s.`Game` WHERE t.`High points` IS NOT NULL AND (t.`Date` IN ('`May 23`','`May 25`','`May 27`','`May 29`','`May 31`') OR t.`Series`='`3–1`') GROUP BY `Location_Class` HAVING `Games`>0 LIMIT 10;
","SELECT CASE WHEN t.col2 IN ('@ Detroit','Detroit') THEN 'Away' ELSE 'Home' END `Location_Class`, COUNT(*) `Games`, SUM(substr(t.col3,1,1)='W') `Wins`, SUM(substr(t.col3,1,1)='L') `Losses` FROM `table_1_13762472_13` t LEFT JOIN `table_1_13762472_13` s ON t.col0=s.col0 WHERE t.col4 IS NOT NULL AND (t.col1 IN ('May 23','May 25','May 27','May 29','May 31') OR t.col8='3–1') GROUP BY `Location_Class` HAVING `Games`>0 LIMIT 10;","[('Home', 1, 0, 0)]",table_1_13762472_13,"1) The SQL computes aggregates per a derived location label and filters rows by High points presence and specific dates or series value. 2) Translate schema names: Team values '@ Detroit'/'Detroit' determine Away, Score's first character determines W/L, Date list and Series '3–1' are filters, and a LEFT JOIN is applied on Game. 3) Ask for the aggregate counts (COUNT(*) as Games) and sums of win/loss indicators per Location_Class with the same filters and result limits. 4) Confirm the question explicitly mentions all calculations, the CASE mapping, the exact date list, Series value, HAVING Games>0, and LIMIT 10.",reserved,23,reward,,
"Considering only rows with Game >= 32 and Team IN ('Minnesota','Phoenix'), what are the Team and COUNT(*) AS 'January 1' for each Team when grouped by Team, including only groups where COUNT(*) > 1, ordered by COUNT(*) and limited to 5 results?","
SELECT `Team`, COUNT(*) AS `January 1`
FROM `table_1_13762472_5`
WHERE `Game` >= 32
GROUP BY `Team`
HAVING COUNT(*) > 1 AND `Team` IN ('Minnesota','Phoenix')
ORDER BY COUNT(*)
LIMIT 5;
","SELECT col0, col1, col2 AS `Team Name`, col3 FROM `table_1_13762472_5` WHERE col0 >= 32 AND (col2 = 'Minnesota' OR col2 LIKE '%Phoenix') ORDER BY col0 DESC LIMIT 5;","[(43.0, 'january 26', 'phoenix', 'l 98–107 (ot)'), (34.0, 'january 6', '@ phoenix', 'l 93–111 (ot)')]",table_1_13762472_5,"Parse the intent: return Team and COUNT(*) aliased 'January 1' for records with Game >= 32, limited to Minnesota and Phoenix, include only groups with COUNT(*) > 1, sort by the count and limit to 5. Map schema: the query aggregates COUNT(*) per Team using the Game and Team columns. Draft: craft a natural question requesting Team and COUNT(*) AS 'January 1' with the WHERE, GROUP BY, HAVING, ORDER BY COUNT(*), and LIMIT 5 constraints. Validate: check the question mentions Team, COUNT(*) AS 'January 1', Game >= 32, Team IN ('Minnesota','Phoenix'), HAVING COUNT(*) > 1, ORDER BY COUNT(*) and LIMIT 5.",reserved,11,reward,,
"For records with Rank between 1 and 10 and with Aircraft movements 2009 > 50000, provide Airport and Rank, the value of (Total Passengers 2009 - Total Passengers 2008) divided by Aircraft movements 2009 as Passengers per Movement, and indicate whether Aircraft movements 2009 is NULL, returning only five rows?","
SELECT `Airport`, `Rank`, (`Total Passengers 2009` - `Total Passengers 2008`) / `Aircraft movements 2009` AS `Passengers per Movement`, `Aircraft movements 2009` IS NULL
FROM `table_1_13836704_4`
WHERE `Rank` IN (1,2,3,4,5,6,7,8,9,10) AND `Aircraft movements 2009` > 50000
LIMIT 5;
","
SELECT col1, col0, (col3 - col2) / col5 AS `Passengers per Movement`, col5 IS NULL
FROM `table_1_13836704_4`
WHERE col0 IN (1,2,3,4,5,6,7,8,9,10) AND col5 > 50000
LIMIT 5;
","[('london heathrow airport', 1.0, -2.1822540218227977, 0), ('london gatwick airport', 2.0, -7.199357628067445, 0), ('london stansted airport', 3.0, -14.320879291132602, 0), ('manchester airport', 4.0, -14.458487667739037, 0), ('london luton airport', 5.0, -10.737603305785123, 0)]",table_1_13836704_4,"1) The query pulls specific columns and a calculation for top-ten-ranked airports with a minimum of 50000 aircraft movements and restricts output to five rows. 2) Map to table columns: Airport, Rank, Total Passengers 2008, Total Passengers 2009, Aircraft movements 2009. 3) Create a question that asks for Airport and Rank, the calculated Passengers per Movement, the null-status of Aircraft movements 2009, filtered by Rank in 1–10 and Aircraft movements 2009 > 50000, limited to five rows. 4) Confirm all selected columns, the arithmetic expression, the IS NULL check, the WHERE conditions, and LIMIT 5 are included.",reserved,9,reward,,
"Which UK airports should we prioritise for new or increased service — show total passengers, growth %, international/domestic shares, freight tonnes, freight-per-movement, a composite priority score (40% passengers, 25% growth, 20% international, 15% freight/movement) and flags for long-haul (>=50% international), high-growth (>10%) and cargo candidates (above-average freight/movement)?","
WITH metrics AS (
  SELECT
    `Airport`,
    `Rank`,
    `Total Passengers`,
    `International Passengers`,
    `Domestic Passengers`,
    `Aircraft Movements`,
    `Freight ( Metric Tonnes )`,
    CAST(REPLACE(`% Change 2008/2009`,'%', '') AS REAL) AS `growth_pct`,
    CASE WHEN `Total Passengers` = 0 THEN 0 ELSE (`International Passengers` * 1.0 / `Total Passengers`) * 100 END AS `international_share_pct`,
    CASE WHEN `Total Passengers` = 0 THEN 0 ELSE (`Domestic Passengers` * 1.0 / `Total Passengers`) * 100 END AS `domestic_share_pct`,
    CASE WHEN `Aircraft Movements` = 0 THEN 0 ELSE (`Freight ( Metric Tonnes )` * 1.0 / `Aircraft Movements`) END AS `freight_per_movement`
  FROM `table_1_13836704_6`
),
stats AS (
  SELECT
    MAX(`Total Passengers`) AS `max_total`,
    MAX(`growth_pct`) AS `max_growth`,
    MAX(`international_share_pct`) AS `max_international_share`,
    MAX(`freight_per_movement`) AS `max_freight_per_movement`,
    AVG(`freight_per_movement`) AS `avg_freight_per_movement`
  FROM metrics
)
SELECT
  m.`Airport`,
  m.`Rank`,
  m.`Total Passengers`,
  ROUND(m.`growth_pct`,2) AS `growth_pct`,
  ROUND(m.`international_share_pct`,2) AS `international_share_pct`,
  ROUND(m.`domestic_share_pct`,2) AS `domestic_share_pct`,
  m.`Freight ( Metric Tonnes )`,
  ROUND(m.`freight_per_movement`,4) AS `freight_per_movement`,
  ROUND(
    COALESCE(m.`Total Passengers` * 1.0 / NULLIF(s.`max_total`,0),0) * 0.40
    + COALESCE(m.`growth_pct` * 1.0 / NULLIF(s.`max_growth`,0),0) * 0.25
    + COALESCE(m.`international_share_pct` * 1.0 / NULLIF(s.`max_international_share`,0),0) * 0.20
    + COALESCE(m.`freight_per_movement` * 1.0 / NULLIF(s.`max_freight_per_movement`,0),0) * 0.15
  ,4) AS `composite_priority_score`,
  CASE WHEN m.`international_share_pct` >= 50 THEN 1 ELSE 0 END AS `long_haul_candidate`,
  CASE WHEN m.`growth_pct` > 10 THEN 1 ELSE 0 END AS `high_growth`,
  CASE WHEN m.`freight_per_movement` > s.`avg_freight_per_movement` THEN 1 ELSE 0 END AS `cargo_candidate`
FROM metrics m
CROSS JOIN stats s
ORDER BY `composite_priority_score` DESC, m.`Total Passengers` DESC;
","WITH metrics AS (
  SELECT
    col1,
    col0,
    col2,
    col4,
    col5,
    col7,
    col8,
    CAST(REPLACE(col3,'%', '') AS REAL) AS `growth_pct`,
    CASE WHEN col2 = 0 THEN 0 ELSE (col4 * 1.0 / col2) * 100 END AS `international_share_pct`,
    CASE WHEN col2 = 0 THEN 0 ELSE (col5 * 1.0 / col2) * 100 END AS `domestic_share_pct`,
    CASE WHEN col7 = 0 THEN 0 ELSE (col8 * 1.0 / col7) END AS `freight_per_movement`
  FROM `table_1_13836704_6`
)
SELECT
  m.col1,
  m.col0,
  m.col2,
  ROUND(m.`growth_pct`,2) AS `growth_pct`,
  ROUND(m.`international_share_pct`,2) AS `international_share_pct`,
  ROUND(m.`domestic_share_pct`,2) AS `domestic_share_pct`,
  m.col8,
  ROUND(m.`freight_per_movement`,4) AS `freight_per_movement`,
  ROUND(
    COALESCE(m.col2 * 1.0 / NULLIF((SELECT MAX(col2) FROM metrics),0),0) * 0.40
    + COALESCE(m.`growth_pct` * 1.0 / NULLIF((SELECT MAX(`growth_pct`) FROM metrics),0),0) * 0.25
    + COALESCE(m.`international_share_pct` * 1.0 / NULLIF((SELECT MAX(`international_share_pct`) FROM metrics),0),0) * 0.20
    + COALESCE(m.`freight_per_movement` * 1.0 / NULLIF((SELECT MAX(`freight_per_movement`) FROM metrics),0),0) * 0.15
  ,4) AS `composite_priority_score`,
  CASE WHEN m.`international_share_pct` >= 50 THEN 1 ELSE 0 END AS `long_haul_candidate`,
  CASE WHEN m.`growth_pct` > 10 THEN 1 ELSE 0 END AS `high_growth`,
  CASE WHEN m.`freight_per_movement` > (SELECT AVG(`freight_per_movement`) FROM metrics) THEN 1 ELSE 0 END AS `cargo_candidate`
FROM metrics m
ORDER BY `composite_priority_score` DESC, m.col2 DESC;","[('london heathrow', 1.0, 66036957.0, 1.5, 91.85, 7.96, 1277650.0, 2.7394, 0.7492, 1, 0, 1), ('east midlands', 11.0, 4658151.0, 17.1, 86.29, 13.6, 255121.0, 3.0643, 0.5385, 1, 1, 1), ('london stansted', 3.0, 19957077.0, 10.7, 90.47, 9.5, 182810.0, 1.0893, 0.4791, 1, 1, 1), ('london gatwick', 2.0, 32392520.0, 5.3, 88.6, 11.31, 74680.0, 0.2965, 0.4571, 1, 0, 0), ('manchester', 4.0, 18724889.0, 11.8, 85.79, 13.71, 102543.0, 0.5944, 0.4483, 1, 1, 1), ('glasgow prestwick', 18.0, 1817727.0, 24.8, 74.71, 25.27, 13385.0, 0.391, 0.4428, 1, 1, 0), ('london luton', 5.0, 9120546.0, 10.4, 87.03, 12.92, 28643.0, 0.2901, 0.3638, 1, 1, 0), ('london city', 15.0, 2796890.0, 14.2, 78.83, 21.17, 0.0, 0.0, 0.3317, 1, 1, 0), ('bristol', 9.0, 5642921.0, 10.0, 79.87, 19.64, 0.0, 0.0, 0.3089, 1, 0, 0), ('birmingham', 6.0, 9102899.0, 5.4, 85.4, 14.5, 13070.0, 0.1291, 0.3019, 1, 0, 0), ('leeds bradford', 17.0, 2574426.0, 10.4, 81.51, 17.64, 359.0, 0.0067, 0.2983, 1, 1, 0), ('liverpool', 10.0, 4884494.0, 8.4, 83.5, 16.39, 264.0, 0.0033, 0.2963, 1, 0, 0), ('newcastle', 12.0, 4587883.0, 9.0, 68.84, 30.74, 2597.0, 0.0375, 0.2703, 1, 0, 0), ('glasgow international', 8.0, 7225021.0, 11.7, 47.38, 52.46, 2334.0, 0.0274, 0.2662, 0, 1, 0), ('belfast international', 13.0, 4546475.0, 13.6, 36.68, 63.1, 29804.0, 0.4331, 0.2657, 0, 1, 0), ('aberdeen', 14.0, 2984445.0, 9.3, 43.12, 56.86, 3822.0, 0.0348, 0.2074, 0, 0, 0), ('southampton', 19.0, 1789901.0, 8.0, 38.13, 61.85, 209.0, 0.0046, 0.1747, 0, 0, 0), ('edinburgh', 7.0, 9049355.0, 0.5, 45.71, 54.22, 23791.0, 0.2051, 0.1694, 0, 0, 0), ('belfast city', 16.0, 2621763.0, 2.0, 2.11, 97.89, 138.0, 0.0035, 0.0408, 0, 0, 0)]",table_1_13836704_6,"I often need a shortlist of candidate airports for new or increased service that balances market size, momentum, international feed and cargo handling. I would refer to fields like Total Passengers, % Change 2008/2009, International Passengers and Freight (Metric Tonnes). The SQL computes growth_pct from the % Change, international/domestic shares as percentages of total, freight_per_movement, then combines normalized values into a composite priority score and creates binary candidate flags. It returns all airports with those metrics and sorts by composite priority. Draft question: Which UK airports should we prioritise for new/increased service—provide the full metrics, composite priority (40/25/20/15) and flags for long-haul, high-growth and cargo candidates. Validate: That matches the query's intent, metrics and threshold rules.",persona,"Route Development Analyst at a regional airline who uses historical airport traffic data to prioritise new routes, evaluate slot and capacity opportunities, and identify cargo markets. They query this dataset to compare passenger volume, growth rates and freight handling across UK airports for business cases and network planning. Goals: Identify the busiest airports and top candidates for new or increased service based on total passengers and growth. Find airports with strong international traffic share to prioritise long-haul or international feeder routes. Spot airports with rising year-over-year growth (high % change) that signal emerging demand. Assess cargo potential by comparing freight tonnage and freight-per-aircraft-movement ratios. Understand domestic vs international mix to recommend aircraft type and frequency for route planning. Example Queries: SELECT ""Airport"", ""Rank"", ""Total Passengers"", ""International Passengers"", ""Domestic Passengers""
FROM table_1_13836704_6
ORDER BY ""Total Passengers"" DESC
LIMIT 5; SELECT ""Airport"", ""Total Passengers"", ""% Change 2008/2009"" AS growth
FROM table_1_13836704_6
WHERE CAST(REPLACE(""% Change 2008/2009"", '%', '') AS REAL) > 10
ORDER BY CAST(REPLACE(""% Change 2008/2009"", '%', '') AS REAL) DESC; SELECT ""Airport"",
       ""Total Passengers"",
       ""International Passengers"",
       ROUND((""International Passengers"" * 1.0 / ""Total Passengers"") * 100, 2) AS international_share_pct,
       ""Freight ( Metric Tonnes )"",
       ROUND(""Freight ( Metric Tonnes )"" * 1.0 / NULLIF(""Aircraft Movements"", 0), 2) AS freight_tonnes_per_movement
FROM table_1_13836704_6
WHERE ""Freight ( Metric Tonnes )"" > 0
ORDER BY freight_tonnes_per_movement DESC;",reward,,
"Give me a ranked table prioritizing cargo-hub suitability that lists each airport with freight per passenger, freight rank, aircraft movement rank, growth rank, transit rank, and the Cargo_Hub_Candidate, Repurpose_for_Rapid_Relief and Potential_Bottleneck_or_Crowding flags?","
WITH base AS (
  SELECT
    `Airport`,
    `Total Passengers`,
    `% Change 2006/2007` AS `pct_change_text`,
    CAST(REPLACE(`% Change 2006/2007`, '%', '') AS REAL) AS `pct_change_num`,
    `International Passengers`,
    `Domestic Passengers`,
    `Transit Passengers`,
    `Aircraft Movements`,
    `Freight (Metric Tonnes)`,
    (`Freight (Metric Tonnes)` / NULLIF(`Total Passengers`, 0)) AS `freight_per_passenger`,
    (`Aircraft Movements` / NULLIF(`Total Passengers`, 0)) * 1000.0 AS `movements_per_1000_passengers`,
    (`Transit Passengers` / NULLIF(`Total Passengers`, 0)) * 100.0 AS `transit_share_pct`
  FROM `table_1_13836704_8`
),
stats AS (
  SELECT
    AVG(`freight_per_passenger`) AS `avg_fp`,
    AVG(`movements_per_1000_passengers`) AS `avg_mp_per_1000`,
    AVG(`pct_change_num`) AS `avg_growth_pct`,
    AVG(`Aircraft Movements`) AS `avg_movements`,
    AVG(`Total Passengers`) AS `avg_passengers`,
    AVG(`Transit Passengers`) AS `avg_transit`
  FROM base
)
SELECT
  b.`Airport`,
  b.`Total Passengers`,
  b.`Freight (Metric Tonnes)`,
  ROUND(b.`freight_per_passenger`, 6) AS `freight_per_passenger`,
  b.`Aircraft Movements`,
  ROUND(b.`movements_per_1000_passengers`, 3) AS `movements_per_1000_passengers`,
  b.`Transit Passengers`,
  ROUND(b.`transit_share_pct`, 3) AS `transit_share_pct`,
  b.`pct_change_text`,
  b.`pct_change_num`,
  RANK() OVER (ORDER BY b.`freight_per_passenger` DESC) AS `freight_rank`,
  RANK() OVER (ORDER BY b.`Aircraft Movements` DESC) AS `movement_rank`,
  RANK() OVER (ORDER BY b.`pct_change_num` DESC) AS `growth_rank`,
  RANK() OVER (ORDER BY b.`Transit Passengers` DESC) AS `transit_rank`,
  CASE
    WHEN b.`freight_per_passenger` > (s.`avg_fp` * 1.5) OR b.`Freight (Metric Tonnes)` > 50000 THEN 'YES'
    ELSE 'NO'
  END AS `Cargo_Hub_Candidate`,
  CASE
    WHEN b.`Aircraft Movements` > s.`avg_movements` AND b.`Total Passengers` < (s.`avg_passengers` * 0.5) THEN 'YES'
    ELSE 'NO'
  END AS `Repurpose_for_Rapid_Relief`,
  CASE
    WHEN b.`pct_change_num` > s.`avg_growth_pct` OR b.`Transit Passengers` > (s.`avg_transit` * 1.5) THEN 'YES'
    ELSE 'NO'
  END AS `Potential_Bottleneck_or_Crowding`
FROM base b
CROSS JOIN stats s
ORDER BY `Cargo_Hub_Candidate` DESC, `freight_per_passenger` DESC, `movement_rank` ASC;
","WITH base AS (
  SELECT
    col1,
    col2,
    col3 AS pct_change_text,
    CAST(REPLACE(col3, '%', '') AS REAL) AS pct_change_num,
    col4,
    col5,
    col6,
    col7,
    col8,
    (col8 / NULLIF(col2, 0)) AS freight_per_passenger,
    (col7 / NULLIF(col2, 0)) * 1000.0 AS movements_per_1000_passengers,
    (col6 / NULLIF(col2, 0)) * 100.0 AS transit_share_pct
  FROM `table_1_13836704_8`
)
SELECT
  b.col1,
  b.col2,
  b.col8,
  ROUND(b.freight_per_passenger, 6) AS freight_per_passenger,
  b.col7,
  ROUND(b.movements_per_1000_passengers, 3) AS movements_per_1000_passengers,
  b.col6,
  ROUND(b.transit_share_pct, 3) AS transit_share_pct,
  b.pct_change_text,
  b.pct_change_num,
  RANK() OVER (ORDER BY b.freight_per_passenger DESC) AS freight_rank,
  RANK() OVER (ORDER BY b.col7 DESC) AS movement_rank,
  RANK() OVER (ORDER BY b.pct_change_num DESC) AS growth_rank,
  RANK() OVER (ORDER BY b.col6 DESC) AS transit_rank,
  CASE
    WHEN b.freight_per_passenger > (s.avg_fp * 1.5) OR b.col8 > 50000 THEN 'YES'
    ELSE 'NO'
  END AS Cargo_Hub_Candidate,
  CASE
    WHEN b.col7 > s.avg_movements AND b.col2 < (s.avg_passengers * 0.5) THEN 'YES'
    ELSE 'NO'
  END AS Repurpose_for_Rapid_Relief,
  CASE
    WHEN b.pct_change_num > s.avg_growth_pct OR b.col6 > (s.avg_transit * 1.5) THEN 'YES'
    ELSE 'NO'
  END AS Potential_Bottleneck_or_Crowding
FROM base b
CROSS JOIN (
  SELECT
    AVG(freight_per_passenger) AS avg_fp,
    AVG(movements_per_1000_passengers) AS avg_mp_per_1000,
    AVG(pct_change_num) AS avg_growth_pct,
    AVG(col7) AS avg_movements,
    AVG(col2) AS avg_passengers,
    AVG(col6) AS avg_transit
  FROM base
) s
ORDER BY Cargo_Hub_Candidate DESC, freight_per_passenger DESC, movement_rank ASC;","[('east midlands', 5413360.0, 274753.0, 0.050755, 93989.0, 17.362, 6856.0, 0.127, '14.5%', 14.5, 1, 10, 2, 14, 'YES', 'NO', 'YES'), ('london heathrow', 68066028.0, 1310987.0, 0.019261, 481476.0, 7.074, 213641.0, 0.314, '0.8%', 0.8, 2, 1, 17, 2, 'YES', 'NO', 'YES'), ('glasgow prestwick', 2422332.0, 31517.0, 0.013011, 47910.0, 19.778, 1623.0, 0.067, '1.0%', 1.0, 3, 17, 15, 16, 'YES', 'NO', 'NO'), ('london stansted', 23779697.0, 203747.0, 0.008568, 208462.0, 8.766, 20447.0, 0.086, '0.4%', 0.4, 4, 4, 19, 10, 'YES', 'NO', 'NO'), ('manchester', 22112625.0, 165366.0, 0.007478, 222703.0, 10.071, 220902.0, 0.999, '1.5%', 1.5, 5, 3, 14, 1, 'YES', 'NO', 'YES'), ('london gatwick', 35216113.0, 171078.0, 0.004858, 266550.0, 7.569, 50709.0, 0.144, '3.1%', 3.1, 7, 2, 12, 5, 'YES', 'NO', 'NO'), ('belfast international', 5272664.0, 38429.0, 0.007288, 77395.0, 14.679, 36609.0, 0.694, '4.6%', 4.6, 6, 14, 7, 7, 'NO', 'NO', 'NO'), ('london luton', 9927321.0, 38095.0, 0.003837, 120238.0, 12.112, 7960.0, 0.08, '5.3%', 5.3, 8, 7, 5, 13, 'NO', 'NO', 'YES'), ('edinburgh', 9047558.0, 19292.0, 0.002132, 128172.0, 14.166, 10358.0, 0.114, '5.1%', 5.1, 9, 5, 6, 12, 'NO', 'NO', 'NO'), ('birmingham airport', 9226340.0, 13585.0, 0.001472, 114679.0, 12.43, 92285.0, 1.0, '0.9%', 0.9, 10, 8, 16, 3, 'NO', 'NO', 'YES'), ('cardiff', 2111148.0, 2391.0, 0.001133, 43963.0, 20.824, 17641.0, 0.836, '4.3%', 4.3, 11, 18, 8, 11, 'NO', 'NO', 'NO'), ('aberdeen', 3412257.0, 3434.0, 0.001006, 121927.0, 35.732, 1117.0, 0.033, '7.8%', 7.8, 12, 6, 4, 17, 'NO', 'NO', 'YES'), ('liverpool', 5468510.0, 3709.0, 0.000678, 86668.0, 15.849, 5276.0, 0.096, '10.2%', 10.2, 13, 12, 3, 15, 'NO', 'NO', 'YES'), ('glasgow international', 8795727.0, 4276.0, 0.000486, 108305.0, 12.313, 69640.0, 0.792, '0.6%', 0.6, 14, 9, 18, 4, 'NO', 'NO', 'YES'), ('belfast city', 2186993.0, 1057.0, 0.000483, 43022.0, 19.672, 126.0, 0.006, '3.9%', 3.9, 15, 19, 10, 18, 'NO', 'NO', 'NO'), ('newcastle', 5650716.0, 785.0, 0.000139, 79200.0, 14.016, 27109.0, 0.48, '4.0%', 4.0, 16, 13, 9, 8, 'NO', 'NO', 'NO'), ('leeds bradford', 2881539.0, 109.0, 3.8e-05, 65249.0, 22.644, 21681.0, 0.752, '3.2%', 3.2, 17, 16, 11, 9, 'NO', 'NO', 'NO'), ('bristol', 5926774.0, 20.0, 3e-06, 76428.0, 12.895, 42918.0, 0.724, '2.9%', 2.9, 18, 15, 13, 6, 'NO', 'NO', 'NO'), ('london city', 2912123.0, 0.0, 0.0, 91177.0, 31.309, 0.0, 0.0, '23.5%', 23.5, 19, 11, 1, 19, 'NO', 'NO', 'YES')]",table_1_13836704_8,"I want a single prioritized table for scenario design, so I'll ask for a ranked list that prioritizes cargo-hub suitability while exposing other ranks and flags. The query ranks by freight per passenger, aircraft movements, growth and transit, computes ratios and assigns the three candidate flags, and orders results by cargo-hub candidate then freight per passenger and movement rank. It draws from Airport, Total Passengers, Freight, computed freight_per_passenger, Aircraft Movements, computed movements_per_1000_passengers, transit and growth and then produces freight/movement/growth/transit ranks plus three yes/no flags. Draft question: Give me a ranked table prioritizing cargo-hub suitability that lists each airport with freight per passenger, freight rank, aircraft movement rank, growth rank, transit rank, and the Cargo_Hub_Candidate, Repurpose_for_Rapid_Relief and Potential_Bottleneck_or_Crowding flags. This asks only for items the query produces so it stays faithful to the SQL.",persona,"A freelance disaster-simulation game designer mapping 2007-era UK airports to identify plausible emergency cargo hubs and logistical choke points for realistic supply-chain scenarios. Goals: Locate airports that handled disproportionately high freight relative to passenger traffic so they can serve as resilient cargo hubs in crisis scenarios. Identify regional airports with high aircraft-movement capacity but relatively low passenger loads that could be repurposed in simulations for rapid relief operations. Flag rapidly growing airports (2006→2007) and those with large transit passenger pools as potential future bottlenecks or humanitarian crowding points in scenario timelines. Example Queries: /* 1) Freight-heavy airports with comparatively low passenger volumes (candidate cargo hubs) */
SELECT Airport, ""Total Passengers"", ""Freight (Metric Tonnes)"", ""Aircraft Movements""
FROM table_1_13836704_8
WHERE ""Freight (Metric Tonnes)"" > 50000
  AND ""Total Passengers"" < 10000000
ORDER BY ""Freight (Metric Tonnes)"" DESC; /* 2) Rank airports by freight-per-passenger to find nodes optimized for cargo vs. people */
SELECT Airport, ""Total Passengers"", ""Freight (Metric Tonnes)"",
       (""Freight (Metric Tonnes)"" / NULLIF(""Total Passengers"",0)) AS freight_per_passenger
FROM table_1_13836704_8
ORDER BY freight_per_passenger DESC
LIMIT 10; /* 3) Rapidly growing airports with high aircraft-movements (potential future chokepoints) - parse percent string to numeric */
SELECT Airport, ""Total Passengers"", ""% Change 2006/2007"" AS pct_change_text, 
       CAST(REPLACE(""% Change 2006/2007"", '%', '') AS REAL) AS pct_change_num, 
       ""Aircraft Movements""
FROM table_1_13836704_8
ORDER BY pct_change_num DESC, ""Aircraft Movements"" DESC
LIMIT 10;",reward,,
"Which five Locations have the highest population density when computed as the sum of cleaned Population (2000) (commas and '≈' removed) divided by the sum of Area (sqmi), and for each of those Locations return the Location name, the count of Islands Name (Islands Count), the Total Population (sum of Population (2000) after removing commas and '≈'), the Total Area (sqmi) (SUM of Area (sqmi)), the Population Density (per sqmi) as the rounded (to 2 decimals) Total Population/Total Area, and the Max Island Density (per sqmi) as the maximum of each island's cleaned Population (2000) divided by its Area (sqmi), excluding islands with empty Population (2000) after cleaning?","
SELECT
  `Location`,
  COUNT(`Islands Name`) `Islands Count`,
  SUM(REPLACE(REPLACE(`Population (2000)`, ',', ''), '≈', '')) `Total Population`,
  SUM(`Area (sqmi)`) `Total Area (sqmi)`,
  ROUND(SUM(REPLACE(REPLACE(`Population (2000)`, ',', ''), '≈', ''))/SUM(`Area (sqmi)`),2) `Population Density (per sqmi)`,
  MAX(REPLACE(REPLACE(`Population (2000)`, ',', ''), '≈', '')/`Area (sqmi)`) `Max Island Density (per sqmi)`
FROM `table_1_13897690_1`
WHERE LENGTH(REPLACE(REPLACE(`Population (2000)`, ',', ''), '≈', ''))>0
GROUP BY `Location`
ORDER BY -(SUM(REPLACE(REPLACE(`Population (2000)`, ',', ''), '≈', ''))/SUM(`Area (sqmi)`))
LIMIT 5;
","
SELECT
  col4,
  COUNT(col1) `Islands Count`,
  SUM(REPLACE(REPLACE(col5, ',', ''), '≈', '')) `Total Population`,
  SUM(col2) `Total Area (sqmi)`,
  ROUND(SUM(REPLACE(REPLACE(col5, ',', ''), '≈', ''))/SUM(col2),2) `Population Density (per sqmi)`,
  MAX(REPLACE(REPLACE(col5, ',', ''), '≈', '')/col2) `Max Island Density (per sqmi)`
FROM `table_1_13897690_1`
WHERE LENGTH(REPLACE(REPLACE(col5, ',', ''), '≈', ''))>0
GROUP BY col4
ORDER BY -(SUM(REPLACE(REPLACE(col5, ',', ''), '≈', ''))/SUM(col2))
LIMIT 5;
","[('new york', 1, 7448618, 1401.0, 5316.64, 5316.643825838687), ('puerto rico', 1, 3808610, 3515.0, 1083.53, 1083.5305832147938), ('hawaii', 5, 1208179, 6164.0, 196.01, 1467.5896147403685), ('alaska', 20, 50226, 24621.0, 2.04, 12.183406113537117)]",table_1_13897690_1,"Parse SQL intent: group islands by Location, compute count, cleaned population sums, area sums, rounded density, and maximum per-island density, filter out empty population values, order by descending overall density and limit to five. Map schema semantics: use `Islands Name` for counts, clean `Population (2000)` by removing commas and '≈', use `Area (sqmi)` for sums and ratios, and `Location` as group. Draft the question: request these exact fields and calculations, specify the cleaning rule and ordering, and limit to five results. Validate: includes all fields, calculations, cleaning, grouping, ordering, and top 5 constraint.",reserved,8,reward,,
"What are the Call sign, Frequency MHz, City of license, ERP W, and Notes for each row in the Translators table where ERP W is at least 50 watts?","
SELECT `Call sign`, `Frequency MHz`, `City of license`, `ERP W`, `Notes`
FROM `table_1_13998897_1` `W265AV`
WHERE `ERP W` >= 50;
","
SELECT col0, col1, col2, col3, col6
FROM `table_1_13998897_1` `W265AV`
WHERE col3 >= 50;
","[('w265av', '100.9', 'woodstock, georgia', 250.0, 'via wubl fm 94.9 hd2'), ('w260aj', '99.9', 'ringgold, georgia', 100.0, 'via wkxj fm 103.7 hd2 walden tn (chattanooga area)'), ('w282ay', '104.3', 'chattanooga, tennessee', 50.0, 'via wccv, though out of its broadcast range')]",table_1_13998897_1,"Parse intent: project five columns from rows filtered by ERP W >= 50. Map schema: the table holds those fields in the Translators section. Draft: ask for the Call sign, Frequency MHz, City of license, ERP W, and Notes for rows where ERP W >= 50. Validate: includes all columns and the numeric filter exactly.",reserved,3,reward,,
"For each Team, return Team, Wins as the COUNT(*) of that team's rows, Races as GROUP_CONCAT of Race Title using '; ' as the separator, Dates as GROUP_CONCAT of Date using '; ' as the separator, and the COUNT(Race Title) labeled 'Triple Eight Race Engineering', only considering rows where Winner is not empty, only including teams with more than one win (HAVING COUNT(*) > 1), ordered by Wins and limited to 5 rows?","
SELECT `Team`, COUNT(*) `Wins`, GROUP_CONCAT(`Race Title`, '; ') `Races`, GROUP_CONCAT(`Date`, '; ') `Dates`, COUNT(`Race Title`) `Triple Eight Race Engineering`
FROM `table_1_14016079_1`
WHERE `Winner` <> ''
GROUP BY `Team`
HAVING COUNT(*) > 1
ORDER BY `Wins`
LIMIT 5;
","
SELECT col6, COUNT(*) `Wins`, GROUP_CONCAT(col1, '; ') `Races`, GROUP_CONCAT(col4, '; ') `Dates`, COUNT(col1) `Triple Eight Race Engineering`
FROM `table_1_14016079_1`
WHERE col5 <> ''
GROUP BY col6
HAVING COUNT(*) > 1
ORDER BY `Wins`
LIMIT 5;
","[('ford performance racing', 3, 'bigpond 400; skycity triple crown; city of ipswich 400', '9–11 may; 4–6 july; 18–20 july', 3), ('holden racing team', 3, 'hamilton 400; winton; l&h 500', '18–20 april; 1–3 august; 12–14 september', 3), ('triple eight race engineering', 6, 'clipsal 500; midas 400; supercheap auto bathurst 1000; the coffee club v8 supercar challenge; gulf air desert 400; falken tasmania challenge', '21–24 february; 7–9 june; 9–12 october; 23–26 october; 6–8 november; 21–23 november', 6)]",table_1_14016079_1,"1) Parse SQL intent: aggregate race data per Team, count wins, concatenate titles and dates, include an extra count column with a specific alias, filter non-empty winners, require more than one win, order and limit. 2) Map schema semantics: Race Title and Date use GROUP_CONCAT with '; ' separators; COUNT(Race Title) must be named 'Triple Eight Race Engineering'. 3) Draft the question to capture these outputs and constraints. 4) Validate: ensure mention of WHERE Winner <> '', HAVING COUNT(*) > 1, ORDER BY Wins, and LIMIT 5.",reserved,8,reward,,
Which entries have production greater than primary energy and what is their export intensity?,"
SELECT '`' || `` || '`', `Capita`, `Prim. energy`, `Production`, `Export`, `Electricity`, `CO 2 -emission`, ((`Export`*1.0)/`Production`)*100 AS `Export intensity %` FROM `table_1_14049026_1` WHERE `Production` > `Prim. energy` LIMIT 2;
","SELECT col0, col1, col2, col3, col4, col5, col6, ((col4*1.0)/col3)*100 AS `Export intensity %` FROM `table_1_14049026_1` WHERE col3 > col2 LIMIT 2;","[(2004.0, '26.1', 653.0, 2280.0, 1623.0, '72.1', 128.0, 71.1842105263158), (2007.0, '27.5', 741.0, 2138.0, 1381.0, '84.6', 144.0, 64.5930776426567)]",table_1_14049026_1,"STEP 1: Parse the SQL intent: select the first (unnamed) column plus Capita, Prim. energy, Production, Export, Electricity, CO 2 -emission and compute Export intensity % as (Export/Production)*100 for rows where Production > Prim. energy, limiting output to 2 rows. STEP 2: Determine an ambiguity type that fits: scope ambiguity is appropriate because the phrase referring to “their export intensity” could mean a per-row (per-entry) ratio as computed in the query, or an aggregated ratio for the group of matching rows. STEP 3: Draft the question: “Which entries have production greater than primary energy and what is their export intensity?” STEP 4: Explain the ambiguity: the original query interprets “their export intensity” as the per-row export/production percentage and returns the first two matching rows, whereas an alternative interpretation could ask for a single export intensity computed across all matching entries (e.g., sum(Export)/sum(Production)*100) or otherwise aggregate the group before computing the percentage.",reserved,5,reward,,"type: Scope ambiguity | explanation: The SQL computes export intensity per row (Export/Production*100) for each matching entry and returns two rows; alternatively, the question could mean the group's export intensity (aggregate Export divided by aggregate Production) or a different aggregation scope, changing the result significantly."
"Which countries (Country or territory with flag) have density (where density is the numeric value obtained by taking the substring of Population density per km² before '/' and casting it to REAL) greater than the average density, and for each return Country or territory with flag, Population (July 2009 est.), density, estimated_area computed as Population (July 2009 est.) / density, and a density_flag that is 'Above avg' when density > average and 'Below avg' otherwise, ordering the results by density ascending and limiting the output to 6 rows?","
WITH c AS (
 SELECT `Country or territory with flag`, `Population (July 2009 est.)`,
 CAST(SUBSTR(`Population density per km²`,1,INSTR(`Population density per km²`,'/')-1) AS REAL) density
 FROM `table_1_14098_1`
)
SELECT `Country or territory with flag`, `Population (July 2009 est.)`, density,
 (`Population (July 2009 est.)`/density) estimated_area,
 CASE WHEN density > (SELECT AVG(density) FROM c) THEN '`Above avg`' ELSE '`Below avg`' END density_flag
FROM c
WHERE density > (SELECT AVG(density) FROM c)
ORDER BY density
LIMIT 6;
","
WITH c AS (
 SELECT col0, col2,
 CAST(SUBSTR(col3,1,INSTR(col3,'/')-1) AS REAL) density
 FROM `table_1_14098_1`
)
SELECT col0, col2, density,
 (col2/density) estimated_area,
 CASE WHEN density > (SELECT AVG(density) FROM c) THEN '`Above avg`' ELSE '`Below avg`' END density_flag
FROM c
WHERE density > (SELECT AVG(density) FROM c)
ORDER BY density
LIMIT 6;
","[('uruguay', 3477780.0, 19.4, 179267.01030927835, '`Above avg`'), ('brazil', 191241714.0, 22.0, 8692805.181818182, '`Above avg`'), ('chile', 16928873.0, 22.0, 769494.2272727273, '`Above avg`'), ('peru', 29132013.0, 22.0, 1324182.4090909092, '`Above avg`'), ('venezuela', 26814843.0, 30.2, 887908.7086092716, '`Above avg`'), ('colombia', 45928970.0, 40.0, 1148224.25, '`Above avg`')]",table_1_14098_1,"1) Parse intent: extract numeric density from the density text, compute an estimated area by dividing population by density, flag rows relative to average density, then select only above-average densities and return the lowest six by density. 2) Map schema: use Country or territory with flag, Population (July 2009 est.), and Population density per km² to derive density and estimated_area. 3) Draft: request those columns and calculations and the condition density > average, ordered ascending, limit 6. 4) Validate: ensure substring-and-cast, division, CASE labeling, AVG comparison, ORDER BY density ASC, and LIMIT 6 are included.",reserved,21,reward,,
"Which actors voiced characters in multiple dubs, and which characters did they voice?","
WITH `actors` AS (
  SELECT `Voice Actor (Japanese)` AS `actor` FROM `table_1_1410384_1`
  UNION
  SELECT `Voice Actor (English 1997 / Saban)` FROM `table_1_1410384_1`
  UNION
  SELECT `Voice Actor (English 1998 / Pioneer)` FROM `table_1_1410384_1`
  UNION
  SELECT `Voice Actor (English 2006 / FUNimation)` FROM `table_1_1410384_1`
),
`roles` AS (
  SELECT `Character Name`, `Voice Actor (Japanese)` AS `jp`, `Voice Actor (English 1997 / Saban)` AS `e1997`, `Voice Actor (English 1998 / Pioneer)` AS `e1998`, `Voice Actor (English 2006 / FUNimation)` AS `e2006`
  FROM `table_1_1410384_1`
),
`stable_chars` AS (
  SELECT `Character Name`, `Voice Actor (English 1998 / Pioneer)` AS `stable_actor`
  FROM `table_1_1410384_1`
  WHERE `Voice Actor (English 1998 / Pioneer)` IS NOT NULL
    AND `Voice Actor (English 2006 / FUNimation)` IS NOT NULL
    AND `Voice Actor (English 1998 / Pioneer)` = `Voice Actor (English 2006 / FUNimation)`
)
SELECT
  `a`.`actor` AS `actor_name`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (Japanese)` = `a`.`actor`) AS `t`) AS `roles_in_Japanese`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (English 1997 / Saban)` = `a`.`actor`) AS `t`) AS `roles_in_1997_Saban`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`) AS `t`) AS `roles_in_1998_Pioneer`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (English 2006 / FUNimation)` = `a`.`actor`) AS `t`) AS `roles_in_2006_FUNimation`,
  (SELECT COUNT(*) FROM (SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (Japanese)` = `a`.`actor`
     UNION
     SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (English 1997 / Saban)` = `a`.`actor`
     UNION
     SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`
     UNION
     SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (English 2006 / FUNimation)` = `a`.`actor`
  )) AS `total_distinct_characters`,
  CASE WHEN (
    (SELECT COUNT(*) FROM (SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (Japanese)` = `a`.`actor`
       UNION
       SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (English 1997 / Saban)` = `a`.`actor`
       UNION
       SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`
       UNION
       SELECT DISTINCT `Character Name` FROM `table_1_1410384_1` WHERE `Voice Actor (English 2006 / FUNimation)` = `a`.`actor`
    )) > 1
  ) THEN 1 ELSE 0 END AS `multi_character_flag`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `stable_chars` WHERE `stable_actor` = `a`.`actor`) AS `t`) AS `stable_characters_voiced_in_1998_2006`,
  (SELECT GROUP_CONCAT(`entry`, '; ') FROM (
     SELECT DISTINCT
       `Character Name` || ' [' ||
       TRIM(
         (CASE WHEN `Voice Actor (Japanese)` = `a`.`actor` THEN 'JP' ELSE '' END) ||
         (CASE WHEN `Voice Actor (English 1997 / Saban)` = `a`.`actor` THEN CASE WHEN `Voice Actor (Japanese)` = `a`.`actor` THEN ';1997 Saban' ELSE '1997 Saban' END ELSE '' END) ||
         (CASE WHEN `Voice Actor (English 1998 / Pioneer)` = `a`.`actor` THEN CASE WHEN (`Voice Actor (Japanese)` = `a`.`actor` OR `Voice Actor (English 1997 / Saban)` = `a`.`actor`) THEN ';1998 Pioneer' ELSE '1998 Pioneer' END ELSE '' END) ||
         (CASE WHEN `Voice Actor (English 2006 / FUNimation)` = `a`.`actor` THEN CASE WHEN (`Voice Actor (Japanese)` = `a`.`actor` OR `Voice Actor (English 1997 / Saban)` = `a`.`actor` OR `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`) THEN ';2006 FUNimation' ELSE '2006 FUNimation' END ELSE '' END)
       ) || ']' AS `entry`
     FROM `table_1_1410384_1`
     WHERE `Voice Actor (Japanese)` = `a`.`actor`
        OR `Voice Actor (English 1997 / Saban)` = `a`.`actor`
        OR `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`
        OR `Voice Actor (English 2006 / FUNimation)` = `a`.`actor`
  ) ) AS `timeline_map_actor_to_characters_and_dubs`
FROM `actors` `a`
WHERE `a`.`actor` IS NOT NULL AND `a`.`actor` <> ''
ORDER BY `multi_character_flag` DESC, `total_distinct_characters` DESC, `actor_name`;
","WITH `actors` AS (
  SELECT col1 AS `actor` FROM `table_1_1410384_1`
  UNION
  SELECT col2 FROM `table_1_1410384_1`
  UNION
  SELECT col3 FROM `table_1_1410384_1`
  UNION
  SELECT col4 FROM `table_1_1410384_1`
)
SELECT
  `a`.`actor` AS `actor_name`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col1 = `a`.`actor`) AS `t`) AS `roles_in_Japanese`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col2 = `a`.`actor`) AS `t`) AS `roles_in_1997_Saban`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col3 = `a`.`actor`) AS `t`) AS `roles_in_1998_Pioneer`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col4 = `a`.`actor`) AS `t`) AS `roles_in_2006_FUNimation`,
  (SELECT COUNT(*) FROM (
     SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col1 = `a`.`actor`
     UNION
     SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col2 = `a`.`actor`
     UNION
     SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col3 = `a`.`actor`
     UNION
     SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col4 = `a`.`actor`
  )) AS `total_distinct_characters`,
  CASE WHEN (
    (SELECT COUNT(*) FROM (
       SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col1 = `a`.`actor`
       UNION
       SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col2 = `a`.`actor`
       UNION
       SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col3 = `a`.`actor`
       UNION
       SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col4 = `a`.`actor`
    )) > 1
  ) THEN 1 ELSE 0 END AS `multi_character_flag`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `table_1_1410384_1` WHERE col3 = `a`.`actor` AND col3 = col4) AS `t`) AS `stable_characters_voiced_in_1998_2006`,
  (SELECT GROUP_CONCAT(`entry`, '; ') FROM (
     SELECT DISTINCT
       col0 || ' [' ||
       TRIM(
         (CASE WHEN col1 = `a`.`actor` THEN 'JP' ELSE '' END) ||
         (CASE WHEN col2 = `a`.`actor` THEN CASE WHEN col1 = `a`.`actor` THEN ';1997 Saban' ELSE '1997 Saban' END ELSE '' END) ||
         (CASE WHEN col3 = `a`.`actor` THEN CASE WHEN (col1 = `a`.`actor` OR col2 = `a`.`actor`) THEN ';1998 Pioneer' ELSE '1998 Pioneer' END ELSE '' END) ||
         (CASE WHEN col4 = `a`.`actor` THEN CASE WHEN (col1 = `a`.`actor` OR col2 = `a`.`actor` OR col3 = `a`.`actor`) THEN ';2006 FUNimation' ELSE '2006 FUNimation' END ELSE '' END)
       ) || ']' AS `entry`
     FROM `table_1_1410384_1`
     WHERE col1 = `a`.`actor`
        OR col2 = `a`.`actor`
        OR col3 = `a`.`actor`
        OR col4 = `a`.`actor`
  ) ) AS `timeline_map_actor_to_characters_and_dubs`
FROM `actors` `a`
WHERE `a`.`actor` IS NOT NULL AND `a`.`actor` <> ''
ORDER BY `multi_character_flag` DESC, `total_distinct_characters` DESC, `actor_name`;","[('don brown', None, 'king kai; shenron; rasin', 'master roshi; king kai; shenron; lagasin', None, 5, 1, None, 'master roshi [1998 Pioneer]; king kai [1997 Saban;1998 Pioneer]; shenron [1997 Saban;1998 Pioneer]; rasin [1997 Saban]; lagasin [1998 Pioneer]'), ('christopher sabat', None, None, None, 'yamcha; piccolo; shenron; icarus/higher dragon', 4, 1, None, 'yamcha [2006 FUNimation]; piccolo [2006 FUNimation]; shenron [2006 FUNimation]; icarus/higher dragon [2006 FUNimation]'), ('scott mcneil', None, 'piccolo; daiz', 'piccolo; oolong; rasin; daiz', None, 4, 1, None, 'piccolo [1997 Saban;1998 Pioneer]; oolong [1998 Pioneer]; rasin [1998 Pioneer]; daiz [1997 Saban;1998 Pioneer]'), ('alec willows', None, 'oolong; lagasin', None, None, 2, 1, None, 'oolong [1997 Saban]; lagasin [1997 Saban]'), ('andy mcavin', None, None, None, 'rasin; lagasin', 2, 1, None, 'rasin [2006 FUNimation]; lagasin [2006 FUNimation]'), ('cathy weseluck', None, 'chiaotzu; puar', 'chiaotzu; puar', None, 2, 1, None, 'chiaotzu [1997 Saban;1998 Pioneer]; puar [1997 Saban;1998 Pioneer]'), ('kenji utsumi', 'shenron; rasin', None, None, None, 2, 1, None, 'shenron [JP]; rasin [JP]'), ('masako nozawa', 'goku; gohan', None, None, None, 2, 1, None, 'goku [JP]; gohan [JP]'), ('monika antonelli', None, None, None, 'chiaotzu; puar', 2, 1, None, 'chiaotzu [2006 FUNimation]; puar [2006 FUNimation]'), ('naoki tatsuta', 'oolong; icarus/higher dragon', None, None, None, 2, 1, None, 'oolong [JP]; icarus/higher dragon [JP]'), ('sean schemmel', None, None, None, 'goku; king kai', 2, 1, None, 'goku [2006 FUNimation]; king kai [2006 FUNimation]'), ('alvin sanders', None, 'kakao', 'kakao', None, 1, 0, None, 'kakao [1997 Saban;1998 Pioneer]'), ('banjo ginga', 'armond', None, None, None, 1, 0, None, 'armond [JP]'), ('bradford jackson', None, None, None, 'oolong', 1, 0, None, 'oolong [2006 FUNimation]'), ('cynthia cranz', None, None, None, 'chi-chi', 1, 0, None, 'chi-chi [2006 FUNimation]'), ('dave ward', None, 'master roshi', None, None, 1, 0, None, 'master roshi [1997 Saban]'), ('doug parker', None, 'icarus/higher dragon', 'icarus/higher dragon', None, 1, 0, None, 'icarus/higher dragon [1997 Saban;1998 Pioneer]'), ('hiroko emori', 'chiaotzu', None, None, None, 1, 0, None, 'chiaotzu [JP]'), ('hiromi tsuru', 'bulma', None, None, None, 1, 0, None, 'bulma [JP]'), ('hirotaka suzuoki', 'tien', None, None, None, 1, 0, None, 'tien [JP]'), ('ian james corlett', None, 'goku', None, None, 1, 0, None, 'goku [1997 Saban]'), ('jeff johnson', None, None, None, 'kakao', 1, 0, None, 'kakao [2006 FUNimation]'), ('john burgmeier', None, None, None, 'tien', 1, 0, None, 'tien [2006 FUNimation]'), ('joji yanami', 'king kai', None, None, None, 1, 0, None, 'king kai [JP]'), ('kōhei miyauchi', 'master roshi', None, None, None, 1, 0, None, 'master roshi [JP]'), ('laara sadiq', None, 'chi-chi', 'chi-chi', None, 1, 0, None, 'chi-chi [1997 Saban;1998 Pioneer]'), ('lalainia lindbjerg', None, 'bulma', 'bulma', None, 1, 0, None, 'bulma [1997 Saban;1998 Pioneer]'), ('mark lancaster', None, None, None, 'daiz', 1, 0, None, 'daiz [2006 FUNimation]'), ('masaharu satou', 'lagasin', None, None, None, 1, 0, None, 'lagasin [JP]'), ('matt smith', None, 'tien', 'tien', None, 1, 0, None, 'tien [1997 Saban;1998 Pioneer]'), ('mayumi shō', 'chi-chi', None, None, None, 1, 0, None, 'chi-chi [JP]'), ('mayumi tanaka', 'krillin', None, None, None, 1, 0, None, 'krillin [JP]'), ('mike mcfarland', None, None, None, 'master roshi', 1, 0, None, 'master roshi [2006 FUNimation]'), ('naoko watanabe', 'puar', None, None, None, 1, 0, None, 'puar [JP]'), ('paul dobson', None, 'armond', 'armond', None, 1, 0, None, 'armond [1997 Saban;1998 Pioneer]'), ('paul slavens', None, None, None, 'armond', 1, 0, None, 'armond [2006 FUNimation]'), ('peter kelamis', None, None, 'goku', None, 1, 0, None, 'goku [1998 Pioneer]'), ('saffron henderson', None, 'gohan', 'gohan', None, 1, 0, None, 'gohan [1997 Saban;1998 Pioneer]'), ('shinobu satouchi', 'kakao', None, None, None, 1, 0, None, 'kakao [JP]'), ('sonny strait', None, None, None, 'krillin', 1, 0, None, 'krillin [2006 FUNimation]'), ('stephanie nadolny', None, None, None, 'gohan', 1, 0, None, 'gohan [2006 FUNimation]'), ('ted cole', None, 'yamcha', 'yamcha', None, 1, 0, None, 'yamcha [1997 Saban;1998 Pioneer]'), ('terry klassen', None, 'krillin', 'krillin', None, 1, 0, None, 'krillin [1997 Saban;1998 Pioneer]'), ('tiffany vollmer', None, None, None, 'bulma', 1, 0, None, 'bulma [2006 FUNimation]'), ('toru furuya', 'yamcha', None, None, None, 1, 0, None, 'yamcha [JP]'), ('toshio furukawa', 'piccolo', None, None, None, 1, 0, None, 'piccolo [JP]'), ('yūji machi', 'daiz', None, None, None, 1, 0, None, 'daiz [JP]')]",table_1_1410384_1,"STEP 1: Parse the SQL intent — produce one row per actor (from JP and three English dub columns), list the characters they voiced per dub (JP, 1997 Saban, 1998 Pioneer, 2006 FUNimation), count total distinct characters they voiced across all columns, flag actors who voiced more than one distinct character, list characters they voiced in both 1998 and 2006 (stable roles), and build a timeline map showing which dubs each actor voiced each character in. STEP 2: Determine a type of ambiguity — Attachment ambiguity fits: the phrase “in multiple dubs” or “across multiple dubs” can attach to the actor (the actor participated in multiple dubs) or to the character (the same character was voiced by the actor across multiple dubs). This query provides data that could support either reading (it tracks per-dub roles and same-actor-in-1998-and-2006). STEP 3: Draft the question — ""Which actors voiced characters in multiple dubs, and which characters did they voice?"" STEP 4: Explain the ambiguity — the SQL treats multi-dub information at both levels (it lists roles per dub and marks characters with the same actor in 1998 and 2006), so the question could mean (a) actors who participated in more than one dub in any role (the actor appears in multiple dub columns, possibly for different characters), which the timeline_map supports, or (b) actors who voiced the same character in more than one dub (stable roles like identical 1998/2006 casting), which the stable_chars column supports.",persona,"A rights‑conscious audio archivist building ethically licensed voice models for classic anime by mapping which actors voiced which characters across the Japanese original and multiple English dubs. Goals: Identify performers who provided multiple distinct character voices in this film (to avoid mixing voices when training models). Find all characters a given actor voiced and in which dub/version (for licensing clearance and sourcing clean audio). Detect characters whose English voice casting remained stable across dub releases (ideal targets for consistent sample collection). Produce a timeline/map of actor ↔ character assignments across the Japanese and three English dubs for metadata tagging. Example Queries: /* Find English actors who voiced more than one character across all English dubs */
SELECT actor, COUNT(DISTINCT ""Character Name"") AS role_count
FROM (
  SELECT ""Character Name"", ""Voice Actor (English 1997 / Saban)"" AS actor FROM table_1_1410384_1
  UNION ALL
  SELECT ""Character Name"", ""Voice Actor (English 1998 / Pioneer)"" AS actor FROM table_1_1410384_1
  UNION ALL
  SELECT ""Character Name"", ""Voice Actor (English 2006 / FUNimation)"" AS actor FROM table_1_1410384_1
) t
WHERE actor IS NOT NULL AND actor <> ''
GROUP BY actor
HAVING COUNT(DISTINCT ""Character Name"") > 1
ORDER BY role_count DESC; /* For a given actor (e.g., 'Don Brown'), list every character they voiced and indicate which dub(s) they appear in */
SELECT ""Character Name"",
  CASE WHEN ""Voice Actor (English 1997 / Saban)"" = 'Don Brown' THEN '1997 Saban' END AS dub_1997,
  CASE WHEN ""Voice Actor (English 1998 / Pioneer)"" = 'Don Brown' THEN '1998 Pioneer' END AS dub_1998,
  CASE WHEN ""Voice Actor (English 2006 / FUNimation)"" = 'Don Brown' THEN '2006 FUNimation' END AS dub_2006
FROM table_1_1410384_1
WHERE ""Voice Actor (English 1997 / Saban)"" = 'Don Brown'
   OR ""Voice Actor (English 1998 / Pioneer)"" = 'Don Brown'
   OR ""Voice Actor (English 2006 / FUNimation)"" = 'Don Brown'; /* Find characters with identical casting between the 1998 (Pioneer) and 2006 (FUNimation) English dubs (stable casting) */
SELECT ""Character Name"", ""Voice Actor (English 1998 / Pioneer)"" AS actor_1998, ""Voice Actor (English 2006 / FUNimation)"" AS actor_2006
FROM table_1_1410384_1
WHERE ""Voice Actor (English 1998 / Pioneer)"" IS NOT NULL
  AND ""Voice Actor (English 1998 / Pioneer)"" = ""Voice Actor (English 2006 / FUNimation)"";",reward,,"type: Attachment ambiguity | explanation: The phrase ""in multiple dubs"" can attach to the actor (meaning the actor worked in multiple dub productions in any roles) or to the character (meaning the actor voiced the same character across multiple dub versions). The original query contains columns that support both readings: per-dub role lists and a 'stable characters in 1998 and 2006' list for same-character repeat casting."
"For each orbiter, show the number of flights, the average mission duration in days, the longest flight (days), and list any missions that carried microgravity or life‑sciences payloads with their launch dates and durations?","
WITH `durations` AS (
  SELECT
    `EDO Flight`,
    `Shuttle`,
    `Mission`,
    `Launch Date`,
    `Duration`,
    `Primary Payload(s)`,
    CAST(substr(`Duration`, 1, instr(`Duration`, ' days') - 1) AS INTEGER) AS `days`,
    CASE
      WHEN `Primary Payload(s)` LIKE '%Microgravity%' OR `Primary Payload(s)` LIKE '%Life%' THEN 1
      ELSE 0
    END AS `is_microgravity`
  FROM `table_1_14118521_1`
),
`agg` AS (
  SELECT
    `Shuttle`,
    COUNT(*) AS `mission_count`,
    ROUND(AVG(`days`), 2) AS `avg_days`,
    MAX(`days`) AS `max_days`,
    group_concat(CASE WHEN `is_microgravity` = 1 THEN `Mission` || ' (' || `Launch Date` || ', ' || `Duration` || ')' END, '; ') AS `microgravity_missions`
  FROM `durations`
  GROUP BY `Shuttle`
)
SELECT
  a.`Shuttle`,
  a.`mission_count`,
  a.`avg_days`,
  a.`max_days`,
  COALESCE(a.`microgravity_missions`, '') AS `microgravity_missions`,
  COALESCE(group_concat(b.`Mission` || ' (' || b.`days` || ' days)', '; '), '') AS `longest_mission_details`
FROM `agg` a
LEFT JOIN `durations` b
  ON a.`Shuttle` = b.`Shuttle` AND b.`days` = a.`max_days`
GROUP BY a.`Shuttle`
ORDER BY a.`avg_days` DESC;
","WITH `durations` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    CAST(substr(col4, 1, instr(col4, ' days') - 1) AS INTEGER) AS `days`,
    CASE
      WHEN col5 LIKE '%Microgravity%' OR col5 LIKE '%Life%' THEN 1
      ELSE 0
    END AS `is_microgravity`
  FROM `table_1_14118521_1`
)
SELECT
  d.col1,
  (SELECT COUNT(*) FROM `durations` WHERE col1 = d.col1) AS `mission_count`,
  (SELECT ROUND(AVG(`days`), 2) FROM `durations` WHERE col1 = d.col1) AS `avg_days`,
  (SELECT MAX(`days`) FROM `durations` WHERE col1 = d.col1) AS `max_days`,
  COALESCE((SELECT group_concat(col2 || ' (' || col3 || ', ' || col4 || ')', '; ')
            FROM `durations` WHERE col1 = d.col1 AND `is_microgravity` = 1), '') AS `microgravity_missions`,
  COALESCE((SELECT group_concat(col2 || ' (' || `days` || ' days)', '; ')
            FROM `durations` WHERE col1 = d.col1 AND `days` = (SELECT MAX(`days`) FROM `durations` WHERE col1 = d.col1)), '') AS `longest_mission_details`
FROM (SELECT DISTINCT col1 FROM `durations`) d
ORDER BY `avg_days` DESC;","[('endeavour', 1, 16.0, 16, '', 'sts-67 (16 days)'), ('columbia', 8, 14.63, 17, 'sts-50 (june 25, 1992, 13 days, 19 hours, 30 minutes, 4 seconds); sts-58 (october 18, 1993, 14 days, 0 hours, 12 minutes, 32 seconds); sts-62 (march 4, 1994, 13 days, 23 hours, 16 minutes, 41 seconds); sts-65 (july 8, 1994, 14 days, 17 hours, 55 minutes, 1 second); sts-73 (october 20, 1995, 15 days, 21 hours, 53 minutes, 16 seconds); sts-78 (june 20, 1996, 16 days, 21 hours, 48 minutes, 30 seconds); sts-87 (november 19, 1997, 15 days, 16 hours, 35 minutes, 1 second)', 'sts-80 (17 days)')]",table_1_14118521_1,"As a payload integration engineer I'm familiar with 'orbiter' and care about counts, averages and which flights carried microgravity or life‑science hardware. The SQL aggregates missions by Shuttle, computes mission_count, average days, max days, and concatenates microgravity missions with launch date and duration. The table columns map Shuttle→orbiter, Duration→parsed days, and Primary Payload(s)→microgravity/life flag. Drafted question asks for per‑orbiter mission count, avg duration in days, longest flight, and a list of microgravity/life missions with launch date and duration. This is supported by the query which groups by Shuttle and returns those fields.",persona,"Payload Integration Engineer at a university/industry lab who designs microgravity experiments and needs historical shuttle flight data to size experiments, plan timelines, and select target missions to emulate. They use this database to identify long-duration orbiter flights, compare durations by orbiter, and catalog which missions carried relevant microgravity payloads. Goals: Identify historical shuttle missions with the longest on-orbit durations to inform experiment endurance requirements. Compare average mission durations between different orbiters (e.g., Columbia vs Endeavour) to guide scheduling and risk assessment. Find missions that carried microgravity or life-sciences payloads so experiment designs can be aligned with similar past hardware and operational profiles. Example Queries: /* Find missions with 16 or more days in duration (parsing the leading 'N days' from the text Duration) */
SELECT ""Mission"", ""Shuttle"", ""Launch Date"", ""Duration"", ""Primary Payload(s)""
FROM table_1_14118521_1
WHERE CAST(SUBSTRING_INDEX(""Duration"", ' days', 1) AS UNSIGNED) >= 16
ORDER BY CAST(SUBSTRING_INDEX(""Duration"", ' days', 1) AS UNSIGNED) DESC; /* Compare average mission length (in days) by shuttle */
SELECT ""Shuttle"",
       AVG(CAST(SUBSTRING_INDEX(""Duration"", ' days', 1) AS UNSIGNED)) AS avg_days
FROM table_1_14118521_1
GROUP BY ""Shuttle""
ORDER BY avg_days DESC; /* List missions that carried microgravity or life-sciences payloads (keyword search), showing launch date and duration */
SELECT ""Mission"", ""Shuttle"", ""Launch Date"", ""Duration"", ""Primary Payload(s)""
FROM table_1_14118521_1
WHERE ""Primary Payload(s)"" LIKE '%Microgravity%'
   OR ""Primary Payload(s)"" LIKE '%Life%'
ORDER BY STR_TO_DATE(""Launch Date"", '%M %d, %Y') ASC;",reward,,
"Between 1900 and 2012 inclusive, for each Supervisor with more than two recorded years, give the Supervisor name, Total Years (the count of Year entries), First Year (MIN Year), Last Year (MAX Year), Span (MAX Year − MIN Year + 1), and the counts of years the Supervisor served in the 1st District, 2nd District, 3rd District, 4th District, and 5th District, then sort by Total Years descending and Span descending and return the first 50 results?","
WITH `unpivot` AS (
  SELECT `1st District` AS `Supervisor`, `Year`, '1st District' AS `District` FROM `table_1_14123513_5` WHERE `Year` >= 1900 AND `Year` <= 2012
  UNION ALL
  SELECT `2nd District`, `Year`, '2nd District' FROM `table_1_14123513_5` WHERE `Year` >= 1900 AND `Year` <= 2012
  UNION ALL
  SELECT `3rd District`, `Year`, '3rd District' FROM `table_1_14123513_5` WHERE `Year` >= 1900 AND `Year` <= 2012
  UNION ALL
  SELECT `4th District`, `Year`, '4th District' FROM `table_1_14123513_5` WHERE `Year` >= 1900 AND `Year` <= 2012
  UNION ALL
  SELECT `5th District`, `Year`, '5th District' FROM `table_1_14123513_5` WHERE `Year` >= 1900 AND `Year` <= 2012
)
SELECT `Supervisor`,
       COUNT(`Year`) AS `Total Years`,
       MIN(`Year`) AS `First Year`,
       MAX(`Year`) AS `Last Year`,
       (MAX(`Year`) - MIN(`Year`) + 1) AS `Span`,
       SUM((`District` = '1st District')) AS `Years_in_1st`,
       SUM((`District` = '2nd District')) AS `Years_in_2nd`,
       SUM((`District` = '3rd District')) AS `Years_in_3rd`,
       SUM((`District` = '4th District')) AS `Years_in_4th`,
       SUM((`District` = '5th District')) AS `Years_in_5th`
FROM `unpivot`
GROUP BY `Supervisor`
HAVING COUNT(`Year`) > 2
ORDER BY `Total Years` DESC, `Span` DESC
LIMIT 50;
","
WITH `unpivot` AS (
  SELECT col1 AS `Supervisor`, col0, '1st District' AS `District` FROM `table_1_14123513_5` WHERE col0 >= 1900 AND col0 <= 2012
  UNION ALL
  SELECT col2, col0, '2nd District' FROM `table_1_14123513_5` WHERE col0 >= 1900 AND col0 <= 2012
  UNION ALL
  SELECT col3, col0, '3rd District' FROM `table_1_14123513_5` WHERE col0 >= 1900 AND col0 <= 2012
  UNION ALL
  SELECT col4, col0, '4th District' FROM `table_1_14123513_5` WHERE col0 >= 1900 AND col0 <= 2012
  UNION ALL
  SELECT col5, col0, '5th District' FROM `table_1_14123513_5` WHERE col0 >= 1900 AND col0 <= 2012
)
SELECT `Supervisor`,
       COUNT(col0) AS `Total Years`,
       MIN(col0) AS `First Year`,
       MAX(col0) AS `Last Year`,
       (MAX(col0) - MIN(col0) + 1) AS `Span`,
       SUM((`District` = '1st District')) AS `Years_in_1st`,
       SUM((`District` = '2nd District')) AS `Years_in_2nd`,
       SUM((`District` = '3rd District')) AS `Years_in_3rd`,
       SUM((`District` = '4th District')) AS `Years_in_4th`,
       SUM((`District` = '5th District')) AS `Years_in_5th`
FROM `unpivot`
GROUP BY `Supervisor`
HAVING COUNT(col0) > 2
ORDER BY `Total Years` DESC, `Span` DESC
LIMIT 50;
","[('willard smith', 29, 1926.0, 1954.0, 29.0, 0, 0, 0, 29, 0), ('willis h. warner', 24, 1939.0, 1962.0, 24.0, 0, 24, 0, 0, 0), ('cecil m. featherly', 20, 1949.0, 1968.0, 20.0, 20, 0, 0, 0, 0), ('thomas f. riley', 20, 1975.0, 1994.0, 20.0, 0, 0, 0, 0, 20), ('william schumacher', 20, 1913.0, 1932.0, 20.0, 0, 0, 20, 0, 0), ('thomas b. talbert', 17, 1910.0, 1926.0, 17.0, 0, 17, 0, 0, 0), ('harriett wieder', 16, 1979.0, 1994.0, 16.0, 0, 16, 0, 0, 0), ('ralph b. clark', 16, 1971.0, 1986.0, 16.0, 0, 0, 0, 16, 0), ('roger r. stanton', 16, 1981.0, 1996.0, 16.0, 16, 0, 0, 0, 0), ('william h. hirstein', 16, 1955.0, 1970.0, 16.0, 0, 0, 0, 16, 0), ('william j. phillips', 16, 1957.0, 1972.0, 16.0, 0, 0, 16, 0, 0), ('hudson e. smith', 14, 1903.0, 1916.0, 14.0, 14, 0, 0, 0, 0), ('david l. baker', 12, 1963.0, 1974.0, 12.0, 0, 12, 0, 0, 0), ('george jeffrey', 12, 1923.0, 1934.0, 12.0, 0, 0, 0, 0, 12), ('jim silva', 12, 1995.0, 2006.0, 12.0, 0, 12, 0, 0, 0), ('john c. mitchell', 12, 1927.0, 1938.0, 12.0, 0, 12, 0, 0, 0), ('s. henderson finley', 12, 1917.0, 1928.0, 12.0, 12, 0, 0, 0, 0), ('bill campbell', 10, 2003.0, 2012.0, 10.0, 0, 0, 10, 0, 0), ('dallison linebarger', 10, 1903.0, 1912.0, 10.0, 0, 0, 10, 0, 0), ('thomas w. wilson', 10, 1997.0, 2006.0, 10.0, 0, 0, 0, 0, 10), ('fredrick w. struck', 9, 1910.0, 1918.0, 9.0, 0, 0, 0, 9, 0), ('gaddi vasquez', 9, 1987.0, 1995.0, 9.0, 0, 0, 9, 0, 0), ('alton allen', 8, 1963.0, 1970.0, 8.0, 0, 0, 0, 0, 8), ('charles v. smith', 8, 1997.0, 2004.0, 8.0, 8, 0, 0, 0, 0), ('fred c. rowland', 8, 1941.0, 1948.0, 8.0, 8, 0, 0, 0, 0), ('irvin george gordon', 8, 1943.0, 1950.0, 8.0, 0, 0, 0, 0, 8), ('james a. baker', 8, 1941.0, 1948.0, 8.0, 0, 0, 8, 0, 0), ('jasper leck', 8, 1911.0, 1918.0, 8.0, 0, 0, 0, 0, 8), ('n. elliot west', 8, 1935.0, 1942.0, 8.0, 0, 0, 0, 0, 8), ('ralph j. mcfadden', 8, 1949.0, 1956.0, 8.0, 0, 0, 8, 0, 0), ('robert battin', 8, 1969.0, 1976.0, 8.0, 8, 0, 0, 0, 0), ('chris norby', 7, 2003.0, 2009.0, 7.0, 0, 0, 0, 7, 0), ('david macmullan', 7, 1903.0, 1909.0, 7.0, 0, 0, 0, 7, 0), ('heinz kaiser', 7, 1951.0, 1957.0, 7.0, 0, 0, 0, 0, 7), ('ralph diedrich', 7, 1973.0, 1979.0, 7.0, 0, 0, 7, 0, 0), ('bruce nestande', 6, 1981.0, 1986.0, 6.0, 0, 0, 6, 0, 0), ('don roth', 6, 1987.0, 1992.0, 6.0, 0, 0, 0, 6, 0), ('janet nguyen', 6, 2007.0, 2012.0, 6.0, 6, 0, 0, 0, 0), ('john moorlach', 6, 2007.0, 2012.0, 6.0, 0, 6, 0, 0, 0), ('patricia c. bates', 6, 2007.0, 2012.0, 6.0, 0, 0, 0, 0, 6), ('todd spitzer', 6, 1997.0, 2002.0, 6.0, 0, 0, 6, 0, 0), ('william g. steiner', 6, 1993.0, 1998.0, 6.0, 0, 0, 0, 6, 0), ('charles h. chapman', 4, 1929.0, 1932.0, 4.0, 4, 0, 0, 0, 0), ('claire m. nelson', 4, 1959.0, 1962.0, 4.0, 0, 0, 0, 0, 4), ('cynthia coad', 4, 1999.0, 2002.0, 4.0, 0, 0, 0, 4, 0), ('george w. angle', 4, 1907.0, 1910.0, 4.0, 0, 0, 0, 0, 4), ('harry d. riley', 4, 1937.0, 1940.0, 4.0, 0, 0, 4, 0, 0), ('howard a. wassum', 4, 1919.0, 1922.0, 4.0, 0, 0, 0, 0, 4), ('jerome fulsom', 4, 1903.0, 1906.0, 4.0, 0, 4, 0, 0, 0), ('laurence schmit', 4, 1975.0, 1978.0, 4.0, 0, 4, 0, 0, 0)]",table_1_14123513_5,"Parse intent: restrict rows to years 1900–2012, unpivot districts, then aggregate per supervisor to report count, min/max, span, and counts per district for supervisors with COUNT(Year) > 2, ordering by total years and span and limiting to 50. Map schema: use Year and the five district columns as the source of district assignments; aggregate into Total Years, First/Last Year, Span, and Years_in_1st..Years_in_5th. Draft question: request those exact fields and constraints. Validate: includes timeframe, having clause, all computed fields, ordering, and limit.",reserved,14,reward,,
"Which players who were named Rookie in 2009 later won Overall or Offensive weekly awards that same season, and what weeks were their rookie and later wins?","
SELECT `insight_type`,`player`,`detail`,`metric` FROM (
  /* 1) Most recognized players across all weekly award categories (players with >= 2 recognitions) */
  SELECT 
    'Most Recognized' AS `insight_type`,
    player AS `player`,
    GROUP_CONCAT(DISTINCT category) AS `detail`,
    CAST(award_count AS TEXT) AS `metric`
  FROM (
    SELECT player, COUNT(*) AS award_count, GROUP_CONCAT(DISTINCT category) AS category_list FROM (
      SELECT `Overall` AS player, 'Overall' AS category FROM `table_1_14132239_3`
      UNION ALL SELECT `Offensive` AS player, 'Offensive' AS category FROM `table_1_14132239_3`
      UNION ALL SELECT `Defensive` AS player, 'Defensive' AS category FROM `table_1_14132239_3`
      UNION ALL SELECT `Transition` AS player, 'Transition' AS category FROM `table_1_14132239_3`
      UNION ALL SELECT `Rookie` AS player, 'Rookie' AS category FROM `table_1_14132239_3`
    )
    GROUP BY player
  ) AS totals
  WHERE award_count >= 2
  ORDER BY award_count DESC, player

  UNION ALL

  /* 2) Rookies who later appear as Overall or Offensive winners (rookie-week plus later recognition weeks) */
  SELECT
    'Rookie to Star' AS `insight_type`,
    r.`Rookie` AS `player`,
    'RookieWeeks: ' || COALESCE(GROUP_CONCAT(DISTINCT r.`Month` || ' W' || r.`Week`), '') 
      || '; OverallWeeks: ' || COALESCE(GROUP_CONCAT(DISTINCT o.`Month` || ' W' || o.`Week`), '')
      || '; OffensiveWeeks: ' || COALESCE(GROUP_CONCAT(DISTINCT f.`Month` || ' W' || f.`Week`), '') AS `detail`,
    CAST(
      (CASE WHEN COUNT(DISTINCT o.`Overall`)>0 THEN 1 ELSE 0 END) + (CASE WHEN COUNT(DISTINCT f.`Offensive`)>0 THEN 1 ELSE 0 END)
      AS TEXT
    ) AS `metric`
  FROM `table_1_14132239_3` r
  LEFT JOIN `table_1_14132239_3` o ON r.`Rookie` = o.`Overall`
  LEFT JOIN `table_1_14132239_3` f ON r.`Rookie` = f.`Offensive`
  GROUP BY r.`Rookie`
  HAVING COUNT(DISTINCT o.`Overall`) > 0 OR COUNT(DISTINCT f.`Offensive`) > 0

  UNION ALL

  /* 3) Weeks where the same player won multiple categories (e.g., Overall + Rookie in same week) */
  SELECT
    'Multi-Category Week' AS `insight_type`,
    name AS `player`,
    'Week: ' || `Month` || ' W' || `Week` || '; Categories: ' || GROUP_CONCAT(DISTINCT category) AS `detail`,
    CAST(COUNT(*) AS TEXT) AS `metric`
  FROM (
    SELECT `Month`,`Week`, `Overall` AS name, 'Overall' AS category FROM `table_1_14132239_3`
    UNION ALL SELECT `Month`,`Week`, `Offensive` AS name, 'Offensive' AS category FROM `table_1_14132239_3`
    UNION ALL SELECT `Month`,`Week`, `Defensive` AS name, 'Defensive' AS category FROM `table_1_14132239_3`
    UNION ALL SELECT `Month`,`Week`, `Transition` AS name, 'Transition' AS category FROM `table_1_14132239_3`
    UNION ALL SELECT `Month`,`Week`, `Rookie` AS name, 'Rookie' AS category FROM `table_1_14132239_3`
  )
  GROUP BY `Month`,`Week`,name
  HAVING COUNT(*) > 1
) ;
","SELECT `insight_type`,`player`,`detail`,`metric` FROM (
  /* 1) Most recognized players across all weekly award categories (players with >= 2 recognitions) */
  SELECT 
    'Most Recognized' AS `insight_type`,
    player AS `player`,
    totals.category_list AS `detail`,
    CAST(award_count AS TEXT) AS `metric`
  FROM (
    SELECT player, COUNT(*) AS award_count, GROUP_CONCAT(DISTINCT category) AS category_list FROM (
      SELECT col2 AS player, 'Overall' AS category FROM `table_1_14132239_3`
      UNION ALL SELECT col3 AS player, 'Offensive' AS category FROM `table_1_14132239_3`
      UNION ALL SELECT col4 AS player, 'Defensive' AS category FROM `table_1_14132239_3`
      UNION ALL SELECT col5 AS player, 'Transition' AS category FROM `table_1_14132239_3`
      UNION ALL SELECT col6 AS player, 'Rookie' AS category FROM `table_1_14132239_3`
    ) AS sub
    GROUP BY player
  ) AS totals
  WHERE award_count >= 2

  UNION ALL

  /* 2) Rookies who later appear as Overall or Offensive winners (rookie-week plus later recognition weeks) */
  SELECT
    'Rookie to Star' AS `insight_type`,
    r.col6 AS `player`,
    'RookieWeeks: ' || COALESCE(GROUP_CONCAT(DISTINCT r.col0 || ' W' || r.col1), '') 
      || '; OverallWeeks: ' || COALESCE(GROUP_CONCAT(DISTINCT o.col0 || ' W' || o.col1), '')
      || '; OffensiveWeeks: ' || COALESCE(GROUP_CONCAT(DISTINCT f.col0 || ' W' || f.col1), '') AS `detail`,
    CAST(
      (CASE WHEN COUNT(DISTINCT o.col2)>0 THEN 1 ELSE 0 END) + (CASE WHEN COUNT(DISTINCT f.col3)>0 THEN 1 ELSE 0 END)
      AS TEXT
    ) AS `metric`
  FROM `table_1_14132239_3` r
  LEFT JOIN `table_1_14132239_3` o ON r.col6 = o.col2
  LEFT JOIN `table_1_14132239_3` f ON r.col6 = f.col3
  GROUP BY r.col6
  HAVING COUNT(DISTINCT o.col2) > 0 OR COUNT(DISTINCT f.col3) > 0

  UNION ALL

  /* 3) Weeks where the same player won multiple categories (e.g., Overall + Rookie in same week) */
  SELECT
    'Multi-Category Week' AS `insight_type`,
    name AS `player`,
    'Week: ' || col0 || ' W' || col1 || '; Categories: ' || GROUP_CONCAT(DISTINCT category) AS `detail`,
    CAST(COUNT(*) AS TEXT) AS `metric`
  FROM (
    SELECT col0,col1, col2 AS name, 'Overall' AS category FROM `table_1_14132239_3`
    UNION ALL SELECT col0,col1, col3 AS name, 'Offensive' AS category FROM `table_1_14132239_3`
    UNION ALL SELECT col0,col1, col4 AS name, 'Defensive' AS category FROM `table_1_14132239_3`
    UNION ALL SELECT col0,col1, col5 AS name, 'Transition' AS category FROM `table_1_14132239_3`
    UNION ALL SELECT col0,col1, col6 AS name, 'Rookie' AS category FROM `table_1_14132239_3`
  ) AS sub2
  GROUP BY col0,col1,name
  HAVING COUNT(*) > 1
)
ORDER BY 
  CASE WHEN `insight_type` = 'Most Recognized' THEN CAST(metric AS INTEGER) ELSE NULL END DESC,
  `insight_type`,
  `player`;","[('Most Recognized', 'mark steenhuis', 'Overall,Offensive', '5'), ('Most Recognized', 'matt disher', 'Overall,Defensive', '4'), ('Most Recognized', 'rhys duch', 'Rookie', '4'), ('Most Recognized', 'shawn evans', 'Overall,Offensive', '4'), ('Most Recognized', 'brodie merrill', 'Transition', '3'), ('Most Recognized', 'ken montour', 'Defensive', '3'), ('Most Recognized', 'anthony cosmo', 'Overall,Defensive', '2'), ('Most Recognized', 'dan dawson', 'Overall,Offensive', '2'), ('Most Recognized', 'daryl veltman', 'Rookie', '2'), ('Most Recognized', 'gary bining', 'Overall,Rookie', '2'), ('Most Recognized', 'john tavares', 'Overall,Offensive', '2'), ('Most Recognized', 'kevin buchanan', 'Rookie', '2'), ('Most Recognized', 'scott stewart', 'Transition', '2'), ('Most Recognized', 'tyler crompton', 'Rookie', '2'), ('Multi-Category Week', 'gary bining', 'Week: february W6.0; Categories: Overall,Rookie', '2'), ('Multi-Category Week', 'mark steenhuis', 'Week: february W7.0; Categories: Overall,Offensive', '2'), ('Multi-Category Week', 'mark steenhuis', 'Week: january W3.0; Categories: Overall,Offensive', '2'), ('Multi-Category Week', 'matt disher', 'Week: january W5.0; Categories: Overall,Defensive', '2'), ('Multi-Category Week', 'shawn evans', 'Week: february W9.0; Categories: Overall,Offensive', '2'), ('Multi-Category Week', 'shawn evans', 'Week: march W10.0; Categories: Overall,Offensive', '2'), ('Rookie to Star', 'gary bining', 'RookieWeeks: february W6.0; OverallWeeks: february W6.0; OffensiveWeeks: ', '1')]",table_1_14132239_3,"As a conservator building a rookie-to-star display I refer to rookies and later wins in plain season/week terms rather than SQL. The SQL finds players named as Rookie who also later appear as Overall or Offensive winners and lists their rookie weeks and later Overall/Offensive weeks. The schema uses the Rookie, Overall and Offensive columns and joins rows by player name to gather those weeks. Draft question: Which players who were named Rookie in 2009 later won Overall or Offensive weekly awards that same season, and what weeks were their rookie and later wins? I validate this matches the query's left-joins and grouped output of rookie, overall, and offensive weeks.",persona,"A lacrosse–museum conservator and data-artist assembling a 'Breakout to Legend' traveling exhibit that pairs physical memorabilia with award-timeline narratives from the 2009 NLL season. Goals: Identify players who received the most weekly recognitions across any category to prioritize whose memorabilia and storylines should be highlighted. Find rookie players who immediately made an impact (rookie award and later Overall/Offensive awards in the same season) to build a 'rookie-to-star' display arc. Detect weeks where the same player won multiple categories in the same week (e.g., Overall + Rookie) to feature special double-award artifacts and create dramatic timeline plaques. Example Queries: /* 1) Count total weekly awards per player across all categories to find the most frequently recognized players */
SELECT player, COUNT(*) AS award_count
FROM (
  SELECT Overall AS player FROM table_1_14132239_3 UNION ALL
  SELECT Offensive AS player FROM table_1_14132239_3 UNION ALL
  SELECT Defensive AS player FROM table_1_14132239_3 UNION ALL
  SELECT Transition AS player FROM table_1_14132239_3 UNION ALL
  SELECT Rookie AS player FROM table_1_14132239_3
) AS all_awards
GROUP BY player
ORDER BY award_count DESC, player; /* 2) Find weeks where the same person won Overall and Rookie in the same week (good candidates for double-award exhibit items) */
SELECT Month, Week, Overall, Rookie
FROM table_1_14132239_3
WHERE Overall = Rookie; /* 3) List rookies who also appear later as Overall or Offensive winners (show rookie week plus the later recognition weeks) */
SELECT r.Rookie AS player,
       GROUP_CONCAT(DISTINCT CONCAT('Rookie: ', r.Month, ' W', r.Week)) AS rookie_weeks,
       GROUP_CONCAT(DISTINCT CONCAT('Overall: ', o.Month, ' W', o.Week)) AS overall_weeks,
       GROUP_CONCAT(DISTINCT CONCAT('Offensive: ', f.Month, ' W', f.Week)) AS offensive_weeks
FROM table_1_14132239_3 r
LEFT JOIN table_1_14132239_3 o ON r.Rookie = o.Overall
LEFT JOIN table_1_14132239_3 f ON r.Rookie = f.Offensive
GROUP BY r.Rookie
HAVING COUNT(o.Overall) > 0 OR COUNT(f.Offensive) > 0;",reward,,
"Starting with seasons 2007 and later, for each Class with at least one race, provide the Class, the total number of Races, the total number of Wins, the Win Rate calculated as total Wins divided by total Races rounded to three decimal places, the total Podiums, and the Average Points per Race calculated as the sum of Pts with any '*' characters removed and converted to a numeric value divided by total Races rounded to two decimal places?","
SELECT DISTINCT `Class`, SUM(`Races`) `Total Races`, SUM(`Wins`) `Total Wins`, ROUND((SUM(`Wins`)*1.0)/NULLIF(SUM(`Races`),0),3) `Win Rate`, SUM(`Podiums`) `Total Podiums`, ROUND(SUM(CAST(REPLACE(`Pts`, '*', '') AS REAL))/NULLIF(SUM(`Races`),0),2) `Avg Pts per Race`
FROM `table_1_14139408_1`
WHERE `Season` >= 2007
GROUP BY `Class`
HAVING SUM(`Races`) > 0;
","
SELECT DISTINCT col1, SUM(col5) `Total Races`, SUM(col6) `Total Wins`, ROUND((SUM(col6)*1.0)/NULLIF(SUM(col5),0),3) `Win Rate`, SUM(col7) `Total Podiums`, ROUND(SUM(CAST(REPLACE(col10, '*', '') AS REAL))/NULLIF(SUM(col5),0),2) `Avg Pts per Race`
FROM `table_1_14139408_1`
WHERE col0 >= 2007
GROUP BY col1
HAVING SUM(col5) > 0;
","[('125cc', 50.0, 5.0, 0.1, 11.0, 9.48), ('moto2', 67.0, 0.0, 0.0, 5.0, 6.63)]",table_1_14139408_1,"Parse intent: compute per-Class aggregates since 2007 and present win and scoring rates, excluding zero-race classes. Map schema: use Class, Season, Races, Wins, Podiums and Pts with '*' removed and cast to numeric. Draft: ask for Class, Total Races, Total Wins, Win Rate (wins/races rounded to 0.001), Total Podiums, and Avg Pts per Race (sum of cleaned Pts divided by races rounded to 0.01) for seasons >=2007 where total races>0. Validate: captures all requested columns, calculations, rounding precisions, season filter and exclusion condition.",reserved,9,reward,,
"For each City, list the City, the count of School Name (number of schools), the SUM of Students, the AVG of (Students / FTE Teachers) rounded to 2 decimal places, the MAX of Students, the MIN of Students, and ROUND((MAX(Students) - MIN(Students)) / AVG(Students), 2), then order the cities by the rounded average(Students / FTE Teachers) descending and show the top 3 cities?","
SELECT DISTINCT `City`, COUNT(`School Name`), SUM(`Students`), ROUND(AVG(`Students` / `FTE Teachers`),2), MAX(`Students`), MIN(`Students`), ROUND((MAX(`Students`)-MIN(`Students`))/AVG(`Students`),2)
FROM `table_1_1414743_1`
GROUP BY `City`
ORDER BY ROUND(AVG(`Students` / `FTE Teachers`),2) DESC
LIMIT 3;
","
SELECT DISTINCT col1, COUNT(col0), SUM(col2), ROUND(AVG(col2 / col3),2), MAX(col2), MIN(col2), ROUND((MAX(col2)-MIN(col2))/AVG(col2),2)
FROM `table_1_1414743_1`
GROUP BY col1
ORDER BY ROUND(AVG(col2 / col3),2) DESC
LIMIT 3;
","[('los altos', 1, 350.0, 21.88, 350.0, 350.0, 0.0), ('santa clara', 18, 11221.0, 20.73, 1908.0, 169.0, 2.79), ('sunnyvale', 3, 2072.0, 19.85, 1265.0, 307.0, 1.39)]",table_1_1414743_1,"1) Parse intent: produce per-city distinct aggregates including count, sum, rounded avg of student-to-FTE ratio, max/min students, and a relative spread, then return the top three cities by that rounded avg. 2) Map schema: fields involved are City, School Name, Students, FTE Teachers and the expressions COUNT(School Name), SUM(Students), ROUND(AVG(Students/FTE Teachers),2), MAX(MIN)(Students), and ROUND((MAX(MIN) difference)/AVG(Students),2). 3) Draft: ask for those exact metrics and ordering. 4) Validate: question contains all columns, calculations, rounding, grouping, ordering, and LIMIT 3.",reserved,8,reward,,
"Give me, in chronological order, the seat change since the previous snapshot for each group (ODM, PNU, NARC ODM‑affiliated, PNU‑affiliated, KANU PNU‑affiliated, ODM‑Kenya, Unaffiliated, Vacant) and the total absolute swing for each snapshot so I can gauge how often and how big the shifts were.","
SELECT
  `` AS `snapshot_date`,
  (`PNU` + `PNU-affiliated` + `KANU PNU-affiliated`) AS `pnu_coalition_seats`,
  (`ODM` + `NARC ODM-affiliated` + `ODM-Kenya`) AS `odm_coalition_seats`,
  `Total` AS `total_seats`,
  CASE 
    WHEN (`PNU` + `PNU-affiliated` + `KANU PNU-affiliated`) > (`Total`/2) THEN 'PNU_majority'
    WHEN (`ODM` + `NARC ODM-affiliated` + `ODM-Kenya`) > (`Total`/2) THEN 'ODM_majority'
    ELSE 'no_majority'
  END AS `coalition_status`,
  `ODM` - LAG(`ODM`) OVER (ORDER BY ``) AS `ODM_delta`,
  `PNU` - LAG(`PNU`) OVER (ORDER BY ``) AS `PNU_delta`,
  `NARC ODM-affiliated` - LAG(`NARC ODM-affiliated`) OVER (ORDER BY ``) AS `NARC ODM-affiliated_delta`,
  `PNU-affiliated` - LAG(`PNU-affiliated`) OVER (ORDER BY ``) AS `PNU-affiliated_delta`,
  `KANU PNU-affiliated` - LAG(`KANU PNU-affiliated`) OVER (ORDER BY ``) AS `KANU PNU-affiliated_delta`,
  `ODM-Kenya` - LAG(`ODM-Kenya`) OVER (ORDER BY ``) AS `ODM-Kenya_delta`,
  `Unaffiliated` - LAG(`Unaffiliated`) OVER (ORDER BY ``) AS `Unaffiliated_delta`,
  `Vacant` - LAG(`Vacant`) OVER (ORDER BY ``) AS `Vacant_delta`,
  (ABS(`ODM` - LAG(`ODM`) OVER (ORDER BY ``))
   + ABS(`PNU` - LAG(`PNU`) OVER (ORDER BY ``))
   + ABS(`NARC ODM-affiliated` - LAG(`NARC ODM-affiliated`) OVER (ORDER BY ``))
   + ABS(`PNU-affiliated` - LAG(`PNU-affiliated`) OVER (ORDER BY ``))
   + ABS(`KANU PNU-affiliated` - LAG(`KANU PNU-affiliated`) OVER (ORDER BY ``))
   + ABS(`ODM-Kenya` - LAG(`ODM-Kenya`) OVER (ORDER BY ``))
   + ABS(`Unaffiliated` - LAG(`Unaffiliated`) OVER (ORDER BY ``))
   + ABS(`Vacant` - LAG(`Vacant`) OVER (ORDER BY ``))
  ) AS `total_abs_swing`,
  CASE 
    WHEN ( (`PNU` + `PNU-affiliated` + `KANU PNU-affiliated`) > (`Total`/2) ) 
         != ( LAG(`PNU` + `PNU-affiliated` + `KANU PNU-affiliated`) OVER (ORDER BY ``) > (LAG(`Total`) OVER (ORDER BY ``)/2) )
    THEN 'pnu_coalition_status_changed'
    ELSE NULL
  END AS `pnu_coalition_status_change_flag`,
  CASE 
    WHEN ( (`ODM` + `NARC ODM-affiliated` + `ODM-Kenya`) > (`Total`/2) ) 
         != ( LAG(`ODM` + `NARC ODM-affiliated` + `ODM-Kenya`) OVER (ORDER BY ``) > (LAG(`Total`) OVER (ORDER BY ``)/2) )
    THEN 'odm_coalition_status_changed'
    ELSE NULL
  END AS `odm_coalition_status_change_flag`,
  ( (SELECT `ODM` FROM `table_1_14152577_1` WHERE `` = `20 September 2012`) - (SELECT `ODM` FROM `table_1_14152577_1` WHERE `` = `Begin`) ) AS `ODM_net_change_Begin_to_20_Sept_2012`,
  ( (SELECT `PNU` FROM `table_1_14152577_1` WHERE `` = `20 September 2012`) - (SELECT `PNU` FROM `table_1_14152577_1` WHERE `` = `Begin`) ) AS `PNU_net_change_Begin_to_20_Sept_2012`,
  ( (SELECT `Unaffiliated` FROM `table_1_14152577_1` WHERE `` = `20 September 2012`) - (SELECT `Unaffiliated` FROM `table_1_14152577_1` WHERE `` = `Begin`) ) AS `Unaffiliated_net_change_Begin_to_20_Sept_2012`,
  ( (SELECT `Vacant` FROM `table_1_14152577_1` WHERE `` = `20 September 2012`) - (SELECT `Vacant` FROM `table_1_14152577_1` WHERE `` = `Begin`) ) AS `Vacant_net_change_Begin_to_20_Sept_2012`
FROM `table_1_14152577_1`
ORDER BY `` ASC;
","SELECT
  """" AS `snapshot_date`,
  (col3 + col4 + col5) AS `pnu_coalition_seats`,
  (col1 + col2 + col6) AS `odm_coalition_seats`,
  col8 AS `total_seats`,
  CASE 
    WHEN (col3 + col4 + col5) > (col8/2) THEN 'PNU_majority'
    WHEN (col1 + col2 + col6) > (col8/2) THEN 'ODM_majority'
    ELSE 'no_majority'
  END AS `coalition_status`,
  col1 - LAG(col1) OVER (ORDER BY """") AS `ODM_delta`,
  col3 - LAG(col3) OVER (ORDER BY """") AS `PNU_delta`,
  ( (SELECT col1 FROM `table_1_14152577_1` WHERE """" = '20 September 2012') - (SELECT col1 FROM `table_1_14152577_1` WHERE """" = 'Begin') ) AS `ODM_net_change`,
  ( (SELECT col3 FROM `table_1_14152577_1` WHERE """" = '20 September 2012') - (SELECT col3 FROM `table_1_14152577_1` WHERE """" = 'Begin') ) AS `PNU_net_change`
FROM `table_1_14152577_1`
ORDER BY """" ASC;","[('', 78.0, 118.0, 207.0, 'ODM_majority', None, None, None, None), ('', 78.0, 117.0, 206.0, 'ODM_majority', -1.0, 0.0, None, None), ('', 78.0, 116.0, 205.0, 'ODM_majority', -1.0, 0.0, None, None), ('', 78.0, 115.0, 204.0, 'ODM_majority', -1.0, 0.0, None, None), ('', 82.0, 123.0, 216.0, 'ODM_majority', 6.0, 3.0, None, None), ('', 82.0, 121.0, 214.0, 'ODM_majority', -2.0, 0.0, None, None), ('', 84.0, 124.0, 219.0, 'ODM_majority', 3.0, 2.0, None, None), ('', 85.0, 126.0, 222.0, 'ODM_majority', 2.0, 1.0, None, None), ('', 84.0, 126.0, 221.0, 'ODM_majority', 0.0, 0.0, None, None), ('', 84.0, 125.0, 220.0, 'ODM_majority', -1.0, 0.0, None, None), ('', 84.0, 127.0, 222.0, 'ODM_majority', 2.0, 0.0, None, None), ('', 84.0, 126.0, 221.0, 'ODM_majority', -1.0, 0.0, None, None), ('', 83.0, 126.0, 220.0, 'ODM_majority', 0.0, -1.0, None, None), ('', 82.0, 126.0, 219.0, 'ODM_majority', 0.0, -1.0, None, None), ('', 81.0, 126.0, 218.0, 'ODM_majority', 0.0, -1.0, None, None), ('', 82.0, 126.0, 219.0, 'ODM_majority', 0.0, 0.0, None, None), ('', 83.0, 126.0, 220.0, 'ODM_majority', 0.0, 1.0, None, None), ('', 82.0, 125.0, 218.0, 'ODM_majority', -1.0, 0.0, None, None), ('', 84.0, 126.0, 221.0, 'ODM_majority', 1.0, 0.0, None, None), ('', 84.0, 127.0, 222.0, 'ODM_majority', 0.0, 0.0, None, None), ('', 83.0, 127.0, 221.0, 'ODM_majority', 0.0, 0.0, None, None), ('', 84.0, 127.0, 222.0, 'ODM_majority', 0.0, 1.0, None, None), ('', 83.0, 127.0, 221.0, 'ODM_majority', 0.0, -1.0, None, None), ('', 82.0, 127.0, 220.0, 'ODM_majority', 0.0, 0.0, None, None), ('', 83.0, 127.0, 221.0, 'ODM_majority', 0.0, 0.0, None, None), ('', 84.0, 127.0, 222.0, 'ODM_majority', 0.0, 1.0, None, None), ('', 84.0, 127.0, 221.0, 'ODM_majority', 0.0, 0.0, None, None), ('', 85.0, 127.0, 222.0, 'ODM_majority', 0.0, 1.0, None, None), ('', 83.0, 126.0, 219.0, 'ODM_majority', -1.0, -2.0, None, None), ('', 85.0, 127.0, 222.0, 'ODM_majority', 1.0, 0.0, None, None)]",table_1_14152577_1,"For balance calibration I want the magnitude and frequency of shifts between consecutive snapshots without SQL jargon. The query computes per-party deltas using LAG and sums their absolute values into total_abs_swing, ordered chronologically. The columns map to each party/affiliate plus Unaffiliated and Vacant, with differences vs the previous snapshot. The question asks for those per-snapshot per-party changes and the aggregate absolute swing in date order. That is precisely what the query returns.",persona,"A boutique board-game designer who builds historically grounded parliamentary wargames based on Kenya's 2008–2012 coalition seat dynamics. Goals: Calibrate game balance by measuring how often and by how much party seat counts shifted between official snapshots. Identify dates when particular coalitions (e.g., PNU plus its affiliates or ODM plus affiliates) had a working majority so those moments can be modelled as ‘control states’ in scenarios. Extract net seat changes from the opening snapshot to the final snapshot to set victory thresholds and scenario victory conditions. Example Queries: /* 1) List each snapshot with the PNU-side coalition total and whether it had a majority */
SELECT snapshot_date,
       (PNU + ""PNU-affiliated"" + ""KANU PNU-affiliated"") AS pnu_coalition_seats,
       ""Total"",
       CASE WHEN (PNU + ""PNU-affiliated"" + ""KANU PNU-affiliated"") > (""Total""/2) THEN 'majority' ELSE 'no_majority' END AS coalition_status
FROM table_1_14152577_1
ORDER BY snapshot_date; /* 2) Find the largest single-snapshot seat swing for ODM (delta between consecutive snapshots) to measure volatility */
SELECT snapshot_date,
       ODM,
       ODM - LAG(ODM) OVER (ORDER BY snapshot_date) AS odm_delta
FROM table_1_14152577_1
ORDER BY ABS(ODM - LAG(ODM) OVER (ORDER BY snapshot_date)) DESC
LIMIT 5; /* 3) Compute net change from the opening ('Begin') snapshot to the final snapshot (20 September 2012) for key parties to set end-game scoring */
SELECT
  ( (SELECT ODM FROM table_1_14152577_1 WHERE """" = '20 September 2012') - (SELECT ODM FROM table_1_14152577_1 WHERE """" = 'Begin') ) AS ODM_net_change,
  ( (SELECT PNU FROM table_1_14152577_1 WHERE """" = '20 September 2012') - (SELECT PNU FROM table_1_14152577_1 WHERE """" = 'Begin') ) AS PNU_net_change,
  ( (SELECT ""Unaffiliated"" FROM table_1_14152577_1 WHERE """" = '20 September 2012') - (SELECT ""Unaffiliated"" FROM table_1_14152577_1 WHERE """" = 'Begin') ) AS Unaffiliated_net_change,
  ( (SELECT ""Vacant"" FROM table_1_14152577_1 WHERE """" = '20 September 2012') - (SELECT ""Vacant"" FROM table_1_14152577_1 WHERE """" = 'Begin') ) AS Vacant_net_change;",reward,,
"Provide for each Party the Party value, the COUNT(*) as Deaths_or_Resignations, and GROUP_CONCAT(Member-elect, '; ') as Members for rows having Reason for non-seating IS NOT NULL, grouped by Party, with HAVING COUNT(*)>0, and ordered by Deaths_or_Resignations?","
SELECT `Party` AS `Party`, COUNT(*) `Deaths_or_Resignations`, GROUP_CONCAT(`Member-elect`, '; ') `Members`
FROM `table_1_14158567_1`
WHERE `Reason for non-seating` IS NOT NULL
GROUP BY `Party`
HAVING COUNT(*)>0
ORDER BY `Deaths_or_Resignations`;
","
SELECT col1 AS col1, COUNT(*) `Deaths_or_Resignations`, GROUP_CONCAT(col0, '; ') `Members`
FROM `table_1_14158567_1`
WHERE col5 IS NOT NULL
GROUP BY col1
HAVING COUNT(*)>0
ORDER BY `Deaths_or_Resignations`;
","[('democratic-republican', 1, 'john cantine'), ('federalist', 1, 'william dowse'), ('whig', 1, 'washington poe'), ('republican', 2, 'andrew j. campbell; jack swigert'), ('democratic', 3, 'augustus f. allen; richard p. giles; samuel marx')]",table_1_14158567_1,"1) Parse intent: aggregate members by party for all rows with a non-null Reason for non-seating, counting and concatenating member names, then sort by the count. 2) Map schema: use Party, Member-elect, Reason for non-seating. 3) Draft: ask for Party, COUNT(*) AS Deaths_or_Resignations, GROUP_CONCAT(Member-elect, '; ') AS Members, WHERE Reason for non-seating IS NOT NULL, GROUP BY Party, HAVING COUNT(*)>0, ORDER BY Deaths_or_Resignations. 4) Validate: the question precisely mirrors the selection, filter, aggregation, aliases, and ordering.",reserved,12,reward,,
"For the Lowest point values 'Atlantic Ocean', 'Pacific Ocean', and 'Gulf of Mexico', produce rows showing Ocean, COUNT(State) as State Count, GROUP_CONCAT(State, ', ') as States, and the COUNT(State) reported in columns Atlantic Ocean, Pacific Ocean, and Gulf of Mexico, using Lowest point = ocean name as the match, grouped by Ocean, ordered by COUNT(State) descending, limited to 10 results?","
WITH `o` AS (VALUES ('Atlantic Ocean'), ('Pacific Ocean'), ('Gulf of Mexico'))
SELECT `o`.`column1` `Ocean`, COUNT(`t`.`State`) `State Count`, GROUP_CONCAT(`t`.`State`, ', ') `States`, COUNT(`t`.`State`) `Atlantic Ocean`, COUNT(`t`.`State`) `Pacific Ocean`, COUNT(`t`.`State`) `Gulf of Mexico`
FROM `table_1_1416612_1` `t`
JOIN `o` ON `t`.`Lowest point` = `o`.`column1`
WHERE `o`.`column1` IN ('Atlantic Ocean','Pacific Ocean','Gulf of Mexico') AND 1=1
GROUP BY `o`.`column1`
ORDER BY COUNT(`t`.`State`) DESC
LIMIT 10;
","SELECT
CASE
  WHEN col3 LIKE '%Atlantic Ocean%' THEN 'Atlantic Ocean'
  WHEN col3 LIKE '%Pacific Ocean%' THEN 'Pacific Ocean'
  WHEN col3 LIKE '%Gulf of Mexico%' THEN 'Gulf of Mexico'
  ELSE 'Other'
END AS Ocean,
COUNT(col0) AS `State Count`,
GROUP_CONCAT(col0, ', ') AS States,
SUM(CASE WHEN col3 LIKE '%Atlantic Ocean%' THEN 1 ELSE 0 END) AS `Atlantic Ocean`,
SUM(CASE WHEN col3 LIKE '%Pacific Ocean%' THEN 1 ELSE 0 END) AS `Pacific Ocean`,
SUM(CASE WHEN col3 LIKE '%Gulf of Mexico%' THEN 1 ELSE 0 END) AS `Gulf of Mexico`
FROM `table_1_1416612_1`
WHERE col3 LIKE '%Atlantic Ocean%' OR col3 LIKE '%Pacific Ocean%' OR col3 LIKE '%Gulf of Mexico%'
GROUP BY Ocean
ORDER BY `State Count` DESC
LIMIT 10;","[('Atlantic Ocean', 13, 'delaware, florida, georgia, maine, maryland, massachusetts, new hampshire, new jersey, new york, north carolina, rhode island, south carolina, virginia', 13, 0, 1), ('Pacific Ocean', 3, 'hawai ʻ i, oregon, washington', 0, 3, 0), ('Gulf of Mexico', 3, 'alabama, mississippi, texas', 0, 0, 3)]",table_1_1416612_1,"1) The SQL constructs a small table of three ocean names, joins it to rows whose Lowest point matches those names, and returns aggregated counts and concatenated state names per ocean, ordered by count and limited. 2) Map: Lowest point links to the three oceans; State provides counts and concatenated names. 3) Draft: ask for Ocean, State Count, GROUP_CONCAT(State, ', ') as States, plus separate COUNT(State) columns for Atlantic Ocean, Pacific Ocean, Gulf of Mexico, grouping by ocean, ordering by the count descending, limit 10. 4) Validate: all selected fields, join condition, IN-list, grouping, ordering, and limit are included.",reserved,14,reward,,
"Which ties in the 1985 Nacional losers' knockout were comebacks after losing the first leg, which saw the away side win the second leg, and which had total aggregates of five or more goals?","
WITH parsed AS (
  SELECT
    `Home (1st leg)`,
    `Home (2nd leg)`,
    `1st Leg`,
    `2nd leg`,
    `Aggregate`,
    CAST(substr(`1st Leg`, 1, instr(`1st Leg`, '-') - 1) AS INTEGER) AS first_left,
    CAST(substr(`1st Leg`, instr(`1st Leg`, '-') + 1) AS INTEGER) AS first_right,
    CAST(substr(`2nd leg`, 1, instr(`2nd leg`, '-') - 1) AS INTEGER) AS second_left,
    CAST(substr(`2nd leg`, instr(`2nd leg`, '-') + 1) AS INTEGER) AS second_right,
    CAST(substr(`Aggregate`, 1, instr(`Aggregate`, '-') - 1) AS INTEGER) AS agg_left,
    CAST(substr(`Aggregate`, instr(`Aggregate`, '-') + 1) AS INTEGER) AS agg_right,
    (CAST(substr(`Aggregate`, 1, instr(`Aggregate`, '-') - 1) AS INTEGER) + CAST(substr(`Aggregate`, instr(`Aggregate`, '-') + 1) AS INTEGER)) AS total_goals,
    (CAST(substr(`Aggregate`, 1, instr(`Aggregate`, '-') - 1) AS INTEGER) - CAST(substr(`Aggregate`, instr(`Aggregate`, '-') + 1) AS INTEGER)) AS agg_diff
  FROM `table_1_14219514_2`
)
SELECT 'Summary' AS `insight`, NULL AS `Home (1st leg)`, NULL AS `Home (2nd leg)`, NULL AS `1st Leg`, NULL AS `2nd leg`, printf('avg_goals=%.2f|ties=%d', AVG(total_goals), COUNT(*)) AS `Aggregate`
FROM parsed
UNION ALL
SELECT 'Margin distribution' AS `insight`, CAST(abs(agg_diff) AS TEXT) AS `Home (1st leg)`, CAST(COUNT(*) AS TEXT) AS `Home (2nd leg)`, NULL AS `1st Leg`, NULL AS `2nd leg`, NULL AS `Aggregate`
FROM parsed
GROUP BY abs(agg_diff)
UNION ALL
SELECT 'One-goal tie' AS `insight`, `Home (1st leg)`, `Home (2nd leg)`, `1st Leg`, `2nd leg`, `Aggregate`
FROM parsed
WHERE abs(agg_diff) = 1
UNION ALL
SELECT 'Comeback after losing 1st leg' AS `insight`, `Home (1st leg)`, `Home (2nd leg)`, `1st Leg`, `2nd leg`, `Aggregate`
FROM parsed
WHERE
  (
    (first_left > first_right AND agg_left < agg_right)
    OR
    (first_left < first_right AND agg_left > agg_right)
  )
UNION ALL
SELECT 'Away won 2nd leg' AS `insight`, `Home (1st leg)`, `Home (2nd leg)`, `1st Leg`, `2nd leg`, `Aggregate`
FROM parsed
WHERE second_left < second_right
UNION ALL
SELECT 'High-scoring aggregate (>=5)' AS `insight`, `Home (1st leg)`, `Home (2nd leg)`, `1st Leg`, `2nd leg`, `Aggregate`
FROM parsed
WHERE total_goals >= 5;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    CAST(substr(col2, 1, instr(col2, '-') - 1) AS INTEGER) AS first_left,
    CAST(substr(col2, instr(col2, '-') + 1) AS INTEGER) AS first_right,
    CAST(substr(col3, 1, instr(col3, '-') - 1) AS INTEGER) AS second_left,
    CAST(substr(col3, instr(col3, '-') + 1) AS INTEGER) AS second_right,
    CAST(substr(col4, 1, instr(col4, '-') - 1) AS INTEGER) AS agg_left,
    CAST(substr(col4, instr(col4, '-') + 1) AS INTEGER) AS agg_right,
    (CAST(substr(col4, 1, instr(col4, '-') - 1) AS INTEGER) + CAST(substr(col4, instr(col4, '-') + 1) AS INTEGER)) AS total_goals,
    (CAST(substr(col4, 1, instr(col4, '-') - 1) AS INTEGER) - CAST(substr(col4, instr(col4, '-') + 1) AS INTEGER)) AS agg_diff
  FROM `table_1_14219514_2`
)
SELECT 'Summary' AS `insight`, NULL AS col0, NULL AS col1, NULL AS col2, NULL AS col3, printf('avg_goals=%.2f|ties=%d', AVG(total_goals), COUNT(*)) AS col4
FROM parsed
UNION ALL
SELECT 'Margin distribution' AS `insight`, CAST(abs(agg_diff) AS TEXT) AS col0, CAST(COUNT(*) AS TEXT) AS col1, NULL AS col2, NULL AS col3, NULL AS col4
FROM parsed
GROUP BY abs(agg_diff)
UNION ALL
SELECT 'One-goal tie' AS `insight`, col0, col1, col2, col3, col4
FROM parsed
WHERE abs(agg_diff) = 1
UNION ALL
SELECT 'Comeback after losing 1st leg' AS `insight`, col0, col1, col2, col3, col4
FROM parsed
WHERE
  (
    (first_left > first_right AND agg_left < agg_right)
    OR
    (first_left < first_right AND agg_left > agg_right)
  )
UNION ALL
SELECT 'Away won 2nd leg' AS `insight`, col0, col1, col2, col3, col4
FROM parsed
WHERE second_left < second_right
UNION ALL
SELECT 'High-scoring aggregate (>=5)' AS `insight`, col0, col1, col2, col3, col4
FROM parsed
WHERE total_goals >= 5;
","[('Summary', None, None, None, None, 'avg_goals=5.57|ties=7'), ('Margin distribution', '1', '5', None, None, None), ('Margin distribution', '2', '2', None, None, None), ('One-goal tie', 'guaraní', 'platense', '0-0', '0-1', '0-1'), ('One-goal tie', 'huracán', 'racing de córdoba', '2-1', '1-1', '3-2'), ('One-goal tie', 'belgrano', 'huracán la heras', '2-1', '1-3', '3-4'), ('One-goal tie', 'central norte', 'círculo deportivo', '0-0', '2-3', '2-3'), ('One-goal tie', 'altos hornos zapla', 'argentino (f)', '2-0', '1-2', '3-2'), ('Comeback after losing 1st leg', 'belgrano', 'huracán la heras', '2-1', '1-3', '3-4'), ('Comeback after losing 1st leg', 'juventud alianza', 'temperley', '4-3', '1-4', '5-7'), ('Away won 2nd leg', 'guaraní', 'platense', '0-0', '0-1', '0-1'), ('Away won 2nd leg', 'belgrano', 'huracán la heras', '2-1', '1-3', '3-4'), ('Away won 2nd leg', 'central norte', 'círculo deportivo', '0-0', '2-3', '2-3'), ('Away won 2nd leg', 'altos hornos zapla', 'argentino (f)', '2-0', '1-2', '3-2'), ('Away won 2nd leg', 'juventud alianza', 'temperley', '4-3', '1-4', '5-7'), ('Away won 2nd leg', 'cipolletti', 'instituto', '0-0', '1-3', '1-3'), ('High-scoring aggregate (>=5)', 'huracán', 'racing de córdoba', '2-1', '1-1', '3-2'), ('High-scoring aggregate (>=5)', 'belgrano', 'huracán la heras', '2-1', '1-3', '3-4'), ('High-scoring aggregate (>=5)', 'central norte', 'círculo deportivo', '0-0', '2-3', '2-3'), ('High-scoring aggregate (>=5)', 'altos hornos zapla', 'argentino (f)', '2-0', '1-2', '3-2'), ('High-scoring aggregate (>=5)', 'juventud alianza', 'temperley', '4-3', '1-4', '5-7')]",table_1_14219514_2,"Persona & knowledge: I investigate comebacks, away wins in second legs, and high-scoring encounters and would request lists of those fixtures together. SQL intent: The query separately selects ties that were comebacks after losing the first leg, ties where the away side won the second leg, and ties with total goals >=5. Schema mapping: It compares first-leg scores to aggregate to find comebacks, compares second-leg home vs away score for away wins, and sums goals from Aggregate for high-scoring ties. Draft question: Which ties were comebacks after losing the first leg, which saw the away side win the second leg, and which had aggregates of five goals or more in the 1985 Nacional losers' knockout? Validation: That corresponds to the three UNIONed SELECTs for comebacks, away second-leg wins, and high-scoring aggregates.",persona,"Football historian working at a national sports archive who researches knockout ties and notable comebacks in historic Argentine competitions. They would use this database to extract match-level results from the 1985 Nacional losers' knockout to support articles and statistical summaries. Goals: Identify ties decided by narrow margins (one-goal aggregates) or by comebacks after losing the first leg. Compute summary statistics (average goals per tie, distribution of aggregate margins) for the losers' knockout round. Produce lists of specific fixtures of interest (e.g., ties won by the away side in the second leg, high-scoring aggregates) for deeper narrative research. Example Queries: -- 1) Find ties decided by a one-goal aggregate margin
SELECT ""Home (1st leg)"", ""Home (2nd leg)"", ""Aggregate""
FROM table_1_14219514_2
WHERE abs(CAST(split_part(""Aggregate"", '-', 1) AS INTEGER) - CAST(split_part(""Aggregate"", '-', 2) AS INTEGER)) = 1; -- 2) Average total goals per tie (aggregate of both teams)
SELECT AVG(
  CAST(split_part(""Aggregate"", '-', 1) AS INTEGER) + CAST(split_part(""Aggregate"", '-', 2) AS INTEGER)
) AS avg_goals_per_tie
FROM table_1_14219514_2; -- 3) Identify comebacks: ties where the first-leg winner (or draw) is not the aggregate winner
SELECT ""Home (1st leg)"", ""Home (2nd leg)"", ""1st Leg"", ""2nd leg"", ""Aggregate""
FROM table_1_14219514_2
WHERE
  (
    CASE
      WHEN CAST(split_part(""1st Leg"", '-', 1) AS INTEGER) > CAST(split_part(""1st Leg"", '-', 2) AS INTEGER) THEN ""Home (1st leg)""
      WHEN CAST(split_part(""1st Leg"", '-', 1) AS INTEGER) < CAST(split_part(""1st Leg"", '-', 2) AS INTEGER) THEN ""Home (2nd leg)""
      ELSE 'DRAW'
    END
  )
  <> 
  (
    CASE
      WHEN CAST(split_part(""Aggregate"", '-', 1) AS INTEGER) > CAST(split_part(""Aggregate"", '-', 2) AS INTEGER) THEN ""Home (1st leg)""
      WHEN CAST(split_part(""Aggregate"", '-', 1) AS INTEGER) < CAST(split_part(""Aggregate"", '-', 2) AS INTEGER) THEN ""Home (2nd leg)""
      ELSE 'DRAW'
    END
  );",reward,,
"For each Chassis Manufacturer (Manufacturer), report Total Fleet as SUM(Number in Fleet), Model Count as COUNT(Chassis Model), and Range Count as the SUM of 1 for each row where Fleet Numbers contains a '-' (i.e., INSTR(Fleet Numbers,'-') > 0), including only rows with Number in Fleet > 0, grouping by Chassis Manufacturer, excluding manufacturers with only one chassis model (HAVING COUNT(Chassis Model) > 1), and sort the output by Total Fleet descending?","
SELECT `Chassis Manufacturer` AS `Manufacturer`,
       SUM(`Number in Fleet`) AS `Total Fleet`,
       COUNT(`Chassis Model`) AS `Model Count`,
       SUM(CASE WHEN INSTR(`Fleet Numbers`, '-') > 0 THEN 1 END) AS `Range Count`
FROM `table_1_1425948_1`
WHERE `Number in Fleet` > 0
GROUP BY `Chassis Manufacturer`
HAVING COUNT(`Chassis Model`) > 1
ORDER BY `Total Fleet` DESC;
","
SELECT col0 AS `Manufacturer`,
       SUM(col3) AS `Total Fleet`,
       COUNT(col1) AS `Model Count`,
       SUM(CASE WHEN INSTR(col4, '-') > 0 THEN 1 END) AS `Range Count`
FROM `table_1_1425948_1`
WHERE col3 > 0
GROUP BY col0
HAVING COUNT(col1) > 1
ORDER BY `Total Fleet` DESC;
","[('scania', 183.0, 15, 13), ('man', 70.0, 2, 2)]",table_1_1425948_1,"1) Intent: aggregate fleet size, model count, and count of ranged fleet numbers per manufacturer with filters and ordering. 2) Map SQL elements to natural terms and include alias names and the INSTR-based range detection. 3) Draft question asking for Manufacturer, Total Fleet (SUM(Number in Fleet)), Model Count (COUNT(Chassis Model)), and Range Count (SUM of 1 when Fleet Numbers contains '-'), with WHERE Number in Fleet > 0, GROUP BY Chassis Manufacturer, HAVING COUNT(Chassis Model) > 1, ORDER BY Total Fleet DESC. 4) Confirm all SQL clauses and computed columns are represented.",reserved,21,reward,,
"Which ten Ontario census divisions are the best dark‑sky candidates (density ≤5 ppl/km², 2011 population ≥20,000, and no population decline since 2006), ranked by a remoteness score that combines area‑per‑person and growth, and show their 2011 & 2006 populations, percent change, land area, area‑per‑person, remoteness score and a 2% potential customer estimate?","
SELECT
  `Name`,
  `2011 Census`,
  `2006 Census`,
  (((`2011 Census` - `2006 Census`) * 1.0) / `2006 Census`) * 100.0 AS `pct_change_calc`,
  `Land area (km²)`,
  CAST(REPLACE(`Land area (km²)`, ',', '') AS real) AS `land_km2_num`,
  CAST(REPLACE(`Density (pop/km²)`, ',', '') AS real) AS `density_num`,
  (CAST(REPLACE(`Land area (km²)`, ',', '') AS real) / `2011 Census`) AS `area_per_person`,
  ((CAST(REPLACE(`Land area (km²)`, ',', '') AS real) / `2011 Census`) * (1.0 + (CASE WHEN (((`2011 Census` - `2006 Census`) * 1.0) / `2006 Census`) * 100.0 < 0 THEN 0 ELSE (((`2011 Census` - `2006 Census`) * 1.0) / `2006 Census`) * 100.0 END) / 100.0)) AS `remoteness_growth_score`,
  CAST(ROUND(`2011 Census` * 0.02) AS integer) AS `est_potential_customers_2pct`
FROM `table_1_1425958_1`
WHERE CAST(REPLACE(`Density (pop/km²)`, ',', '') AS real) <= 5
  AND `2011 Census` >= 20000
  AND (((`2011 Census` - `2006 Census`) * 1.0) / `2006 Census`) * 100.0 >= 0
ORDER BY `remoteness_growth_score` DESC, `area_per_person` DESC
LIMIT 10;
","
SELECT
  col0,
  col1,
  col2,
  (((col1 - col2) * 1.0) / col2) * 100.0 AS `pct_change_calc`,
  col4,
  CAST(REPLACE(col4, ',', '') AS real) AS `land_km2_num`,
  CAST(REPLACE(col5, ',', '') AS real) AS `density_num`,
  (CAST(REPLACE(col4, ',', '') AS real) / col1) AS `area_per_person`,
  ((CAST(REPLACE(col4, ',', '') AS real) / col1) * (1.0 + (CASE WHEN (((col1 - col2) * 1.0) / col2) * 100.0 < 0 THEN 0 ELSE (((col1 - col2) * 1.0) / col2) * 100.0 END) / 100.0)) AS `remoteness_growth_score`,
  CAST(ROUND(col1 * 0.02) AS integer) AS `est_potential_customers_2pct`
FROM `table_1_1425958_1`
WHERE CAST(REPLACE(col5, ',', '') AS real) <= 5
  AND col1 >= 20000
  AND (((col1 - col2) * 1.0) / col2) * 100.0 >= 0
ORDER BY `remoteness_growth_score` DESC, `area_per_person` DESC
LIMIT 10;
","[('parry sound district', 42162.0, 40918.0, 3.040226795053522, '9,322.80', 9322.8, 4.5, 0.221118542763626, 0.22784104794955762, 843), ('nipissing district', 84736.0, 84688.0, 0.05667863215567731, '17,103.52', 17103.52, 5.0, 0.20184478851963747, 0.20195919138484794, 1695)]",table_1_1425958_1,"As a mobile observatory operator I care about places that are remote but not dying off, so I'd ask for a ranked shortlist of such divisions in plain language. The SQL selects divisions with low density, a minimum 2011 population, and non‑negative growth, computes area per person and a remoteness growth score, and returns the top 10. The schema gives the division name, the two census counts, land area and density, and the query also computes percent change, numeric land area/density, area_per_person, remoteness_growth_score and a 2% customer estimate. Give me the top ten candidate divisions for dark‑sky pop‑ups that meet density ≤5, 2011 pop ≥20k and growth ≥0, ranked by remoteness_growth_score then area_per_person, and include the 2011/2006 counts, percent change, land area, area‑per‑person and a 2% estimated customer number? This question aligns exactly with the filters, computations and ordering in the SQL.",persona,"An itinerant dark‑sky tourism entrepreneur who operates a mobile observatory and pop‑up stargazing events across Ontario, scouting census divisions that maximize pristine skies while still having enough nearby customers. Goals: Identify large, sparsely populated census divisions (low population density, large land area) as candidate sites for night‑sky events where light pollution is likely minimal. Find rural divisions with recent or stable population growth so there is a viable local customer base and potential volunteers/partners. Rank divisions by 'area per person' to estimate remoteness and horizon clarity while filtering out places with too few potential attendees. Example Queries: SELECT `Name`, `2011 Census`, `Land area (km²)`, `Density (pop/km²)` FROM `table_1_1425958_1` WHERE `Density (pop/km²)` < 5 AND `2011 Census` >= 10000 ORDER BY `Land area (km²)` DESC LIMIT 15; SELECT `Name`, `2011 Census`, `2006 Census`, ((`2011 Census` - `2006 Census`) / `2006 Census`) * 100 AS pct_change FROM `table_1_1425958_1` WHERE ((`2011 Census` - `2006 Census`) / `2006 Census`) * 100 >= 5 AND `Density (pop/km²)` BETWEEN 4 AND 50 ORDER BY pct_change DESC; SELECT `Name`, `2011 Census`, `Land area (km²)`, (`Land area (km²)` / `2011 Census`) AS area_per_person FROM `table_1_1425958_1` WHERE `2011 Census` >= 5000 ORDER BY area_per_person DESC LIMIT 10;",reward,,
"Which five institutions (limit 5) have the highest Funding_per_student (Research Funding (£,000) divided by Total Number of Students, rounded to 2 decimals) among institutions with Total Number of Students > 10000 and located in Locations whose SUM(Total Number of Students) > 15000, returning Institution, Location, Total Number of Students, Research Funding (£,000), Funding_per_student, and Above_location_avg where Above_location_avg indicates whether an institution's Research Funding (£,000) is greater than the AVG(Research Funding (£,000)) for that Location, ordered by Funding_per_student descending?","
SELECT `Institution`, `Location`, `Total Number of Students`, `Research Funding (£,000)`, ROUND(`Research Funding (£,000)` / `Total Number of Students`,2) `Funding_per_student`, (`Research Funding (£,000)` > l.`Avg_Funding`) `Above_location_avg`
FROM `table_1_142950_1`
INNER JOIN (
  SELECT `Location`, AVG(`Research Funding (£,000)`) `Avg_Funding`, SUM(`Total Number of Students`) `Total_Students`
  FROM `table_1_142950_1`
  GROUP BY `Location`
  HAVING SUM(`Total Number of Students`) > 15000
) l ON `table_1_142950_1`.`Location` = l.`Location`
WHERE `Total Number of Students` > 10000
ORDER BY `Funding_per_student` DESC
LIMIT 5;
","SELECT t.col0, t.col1, t.col5, t.col6, ROUND(t.col6 / t.col5,2) AS `Funding_per_student`, (t.col6 > l.`Avg_Funding`) `Above_location_avg`
FROM `table_1_142950_1` t
INNER JOIN (
  SELECT col1, AVG(col6) `Avg_Funding`, SUM(col5) `Total_Students`
  FROM `table_1_142950_1`
  GROUP BY col1
  HAVING SUM(col5) > 15000
) l ON t.col1 = l.col1
WHERE t.col5 > 10000
ORDER BY `Funding_per_student` DESC
LIMIT 5;","[('university of leicester', 'leicester', 16160.0, 22225.0, 1.38, 0), ('loughborough university', 'loughborough', 17825.0, 22398.0, 1.26, 0), ('university of east anglia', 'norwich', 19585.0, 16482.0, 0.84, 0), ('birkbeck, university of london', 'london', 19020.0, 9985.0, 0.52, 1)]",table_1_142950_1,"Parse intent: select Institution, Location, Total Number of Students, Research Funding (£,000), compute Research Funding divided by Total Number of Students rounded to 2 decimals as Funding_per_student, and indicate if Research Funding is greater than the average Research Funding for the Location; only include institutions with Total Number of Students > 10000 and only Locations whose summed Total Number of Students > 15000; order by Funding_per_student descending and limit to 5. Map schema: use table columns Institution, Location, Total Number of Students, Research Funding (£,000) and a subquery computing AVG(Research Funding (£,000)) and SUM(Total Number of Students) grouped by Location. Draft question: ask for the top 5 institutions by funding per student with the specified filters and computed columns. Validate: ensure question names all selected columns, the Funding_per_student calculation rounded to two decimals, the Above_location_avg comparison, the Location-level SUM >15000 condition, the institution-level Total Number of Students >10000 filter, ordering and limit.",reserved,13,reward,,
"Which teams performed best in international competitions, and which clubs did not qualify for the Copa Libertadores 1997?","
SELECT
  `Team`,
  `Intercontinental`,
  `Recopa 1996`,
  `Supercopa 1996`,
  `CONMEBOL 1996`,
  `Copa Libertadores 1997`,
  TRIM(
    COALESCE(CASE WHEN `Intercontinental` IN ('Champions','Runner up','SF') THEN 'Intercontinental: ' || `Intercontinental` || '; ' END, '')
  || COALESCE(CASE WHEN `Recopa 1996` IN ('Champions','Runner up','SF') THEN 'Recopa 1996: ' || `Recopa 1996` || '; ' END, '')
  || COALESCE(CASE WHEN `Supercopa 1996` IN ('Champions','Runner up','SF') THEN 'Supercopa 1996: ' || `Supercopa 1996` || '; ' END, '')
  || COALESCE(CASE WHEN `CONMEBOL 1996` IN ('Champions','Runner up','SF') THEN 'CONMEBOL 1996: ' || `CONMEBOL 1996` || '; ' END, '')
  || COALESCE(CASE WHEN `Copa Libertadores 1997` IN ('Champions','Runner up','SF') THEN 'Copa Libertadores 1997: ' || `Copa Libertadores 1997` || '; ' END, '')
  , '; '
  ) AS `Notable_Performances`,
  (CASE
     WHEN `Intercontinental` = 'Champions' OR `Recopa 1996` = 'Champions' OR `Supercopa 1996` = 'Champions' OR `CONMEBOL 1996` = 'Champions' OR `Copa Libertadores 1997` = 'Champions' THEN 'Champions'
     WHEN `Intercontinental` = 'Runner up' OR `Recopa 1996` = 'Runner up' OR `Supercopa 1996` = 'Runner up' OR `CONMEBOL 1996` = 'Runner up' OR `Copa Libertadores 1997` = 'Runner up' THEN 'Runner up'
     WHEN `Intercontinental` = 'SF' OR `Recopa 1996` = 'SF' OR `Supercopa 1996` = 'SF' OR `CONMEBOL 1996` = 'SF' OR `Copa Libertadores 1997` = 'SF' THEN 'SF'
     ELSE 'No late-stage result'
   END) AS `Best_Result`,
  CASE WHEN `Copa Libertadores 1997` = 'did not qualify' THEN 1 ELSE 0 END AS `Copa_Libertadores_1997_did_not_qualify`,
  (SELECT COUNT(*) FROM `table_1_14310205_1` WHERE `Copa Libertadores 1997` = 'did not qualify') AS `Copa_Libertadores_1997_not_qualified_count`,
  (SELECT GROUP_CONCAT(`Team`, ', ') FROM `table_1_14310205_1` WHERE `Copa Libertadores 1997` = 'did not qualify') AS `Copa_Libertadores_1997_not_qualified_teams`
FROM `table_1_14310205_1`
ORDER BY
  CASE
    WHEN `Intercontinental` = 'Champions' OR `Recopa 1996` = 'Champions' OR `Supercopa 1996` = 'Champions' OR `CONMEBOL 1996` = 'Champions' OR `Copa Libertadores 1997` = 'Champions' THEN 1
    WHEN `Intercontinental` = 'Runner up' OR `Recopa 1996` = 'Runner up' OR `Supercopa 1996` = 'Runner up' OR `CONMEBOL 1996` = 'Runner up' OR `Copa Libertadores 1997` = 'Runner up' THEN 2
    WHEN `Intercontinental` = 'SF' OR `Recopa 1996` = 'SF' OR `Supercopa 1996` = 'SF' OR `CONMEBOL 1996` = 'SF' OR `Copa Libertadores 1997` = 'SF' THEN 3
    ELSE 4
  END,
  `Team`;
","
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  TRIM(
    COALESCE(CASE WHEN col1 IN ('Champions','Runner up','SF') THEN 'Intercontinental: ' || col1 || '; ' END, '')
  || COALESCE(CASE WHEN col2 IN ('Champions','Runner up','SF') THEN 'Recopa 1996: ' || col2 || '; ' END, '')
  || COALESCE(CASE WHEN col3 IN ('Champions','Runner up','SF') THEN 'Supercopa 1996: ' || col3 || '; ' END, '')
  || COALESCE(CASE WHEN col4 IN ('Champions','Runner up','SF') THEN 'CONMEBOL 1996: ' || col4 || '; ' END, '')
  || COALESCE(CASE WHEN col5 IN ('Champions','Runner up','SF') THEN 'Copa Libertadores 1997: ' || col5 || '; ' END, '')
  , '; '
  ) AS `Notable_Performances`,
  (CASE
     WHEN col1 = 'Champions' OR col2 = 'Champions' OR col3 = 'Champions' OR col4 = 'Champions' OR col5 = 'Champions' THEN 'Champions'
     WHEN col1 = 'Runner up' OR col2 = 'Runner up' OR col3 = 'Runner up' OR col4 = 'Runner up' OR col5 = 'Runner up' THEN 'Runner up'
     WHEN col1 = 'SF' OR col2 = 'SF' OR col3 = 'SF' OR col4 = 'SF' OR col5 = 'SF' THEN 'SF'
     ELSE 'No late-stage result'
   END) AS `Best_Result`,
  CASE WHEN col5 = 'did not qualify' THEN 1 ELSE 0 END AS `Copa_Libertadores_1997_did_not_qualify`,
  (SELECT COUNT(*) FROM `table_1_14310205_1` WHERE col5 = 'did not qualify') AS `Copa_Libertadores_1997_not_qualified_count`,
  (SELECT GROUP_CONCAT(col0, ', ') FROM `table_1_14310205_1` WHERE col5 = 'did not qualify') AS `Copa_Libertadores_1997_not_qualified_teams`
FROM `table_1_14310205_1`
ORDER BY
  CASE
    WHEN col1 = 'Champions' OR col2 = 'Champions' OR col3 = 'Champions' OR col4 = 'Champions' OR col5 = 'Champions' THEN 1
    WHEN col1 = 'Runner up' OR col2 = 'Runner up' OR col3 = 'Runner up' OR col4 = 'Runner up' OR col5 = 'Runner up' THEN 2
    WHEN col1 = 'SF' OR col2 = 'SF' OR col3 = 'SF' OR col4 = 'SF' OR col5 = 'SF' THEN 3
    ELSE 4
  END,
  col0;
","[('argentinos', 'n/a', 'n/a', '1st round', 'did not qualify', 'did not qualify', '', 'No late-stage result', 1, 5, 'lanús, rosario central, boca juniors, argentinos, estudiantes'), ('boca juniors', 'n/a', 'n/a', 'qf', 'did not qualify', 'did not qualify', '', 'No late-stage result', 1, 5, 'lanús, rosario central, boca juniors, argentinos, estudiantes'), ('estudiantes', 'n/a', 'n/a', '1st round', 'did not qualify', 'did not qualify', '', 'No late-stage result', 1, 5, 'lanús, rosario central, boca juniors, argentinos, estudiantes'), ('lanús', 'n/a', 'n/a', 'n/a', 'champions', 'did not qualify', '', 'No late-stage result', 1, 5, 'lanús, rosario central, boca juniors, argentinos, estudiantes'), ('racing club', 'n/a', 'n/a', '1st round', 'n/a', 'sf', '', 'No late-stage result', 0, 5, 'lanús, rosario central, boca juniors, argentinos, estudiantes'), ('river plate', 'runner up', 'runner up', '1st round', 'n/a', 'round 2', '', 'No late-stage result', 0, 5, 'lanús, rosario central, boca juniors, argentinos, estudiantes'), ('rosario central', 'n/a', 'n/a', 'n/a', 'sf', 'did not qualify', '', 'No late-stage result', 1, 5, 'lanús, rosario central, boca juniors, argentinos, estudiantes'), ('vélez sársfield', 'n/a', 'champions', 'champions', 'n/a', '2nd round', '', 'No late-stage result', 0, 5, 'lanús, rosario central, boca juniors, argentinos, estudiantes')]",table_1_14310205_1,"STEP 1: Parse the SQL intent — returns every Team with their raw competition columns, a concatenated Notable_Performances string including competitions where the team reached Champions/Runner up/SF, a Best_Result per team (Champions > Runner up > SF > No late-stage result), a per-team flag if Copa Libertadores 1997 = 'did not qualify', plus a global count and comma-separated list of all teams whose Copa Libertadores 1997 = 'did not qualify'; results ordered by Best_Result then Team. STEP 2: Choose ambiguity type — scope ambiguity fits well: the phrase ""performed best"" or ""which teams performed best"" can mean either (a) the single top performer(s) overall (e.g., Champions) or (b) each team's best result across competitions (a per-team classification), and the SQL produces per-team Best_Result while also providing Champions/Runner up/SF indicators. STEP 3: Draft the question — ""Which teams performed best in international competitions, and which clubs did not qualify for the Copa Libertadores 1997?"" STEP 4: Explain the ambiguity — in the original query ""performed best"" is implemented as a per-team Best_Result (each team is labeled Champions / Runner up / SF / No late-stage result) and the query also returns a count/list of teams that did not qualify for Copa Libertadores 1997; alternatively the question could be interpreted as asking only for the overall top performer(s) (e.g., which team(s) were Champions across those cups) or as asking for an aggregate summary (just the number of non-qualifiers) which would require a different SQL.",persona,"Performance Analyst at an Argentine football club who compiles historical international results to benchmark the club's past continental performance and support PR/match-prep. They use this database to extract 1996–97 international outcomes for peer clubs and prepare comparative summaries. Goals: Identify which Argentine clubs won or reached late stages (SF, Runner up, Champions) in 1996–97 international competitions to benchmark club performance. Quantify how many clubs failed to qualify for the 1997 Copa Libertadores and which ones, for historical participation analysis. Produce a concise table showing each club's results across all listed international competitions in 1996–97 for reports and presentations. Example Queries: -- 1) List all clubs that were 'Champions' in any competition and indicate which competition(s)
    SELECT ""Team"", 'Intercontinental' AS competition FROM table_1_14310205_1 WHERE ""Intercontinental"" = 'Champions'
    UNION ALL
    SELECT ""Team"", 'Recopa 1996' AS competition FROM table_1_14310205_1 WHERE ""Recopa 1996"" = 'Champions'
    UNION ALL
    SELECT ""Team"", 'Supercopa 1996' AS competition FROM table_1_14310205_1 WHERE ""Supercopa 1996"" = 'Champions'
    UNION ALL
    SELECT ""Team"", 'CONMEBOL 1996' AS competition FROM table_1_14310205_1 WHERE ""CONMEBOL 1996"" = 'Champions'
    UNION ALL
    SELECT ""Team"", 'Copa Libertadores 1997' AS competition FROM table_1_14310205_1 WHERE ""Copa Libertadores 1997"" = 'Champions'; -- 2) Count and list teams that did not qualify for the 1997 Copa Libertadores
    SELECT COUNT(*) AS not_qualified_count FROM table_1_14310205_1 WHERE ""Copa Libertadores 1997"" = 'did not qualify';
    SELECT ""Team"" FROM table_1_14310205_1 WHERE ""Copa Libertadores 1997"" = 'did not qualify'; -- 3) Show teams that reached at least the semi-finals (SF), runner-up or Champion in any listed competition
    SELECT ""Team"", ""Intercontinental"", ""Recopa 1996"", ""Supercopa 1996"", ""CONMEBOL 1996"", ""Copa Libertadores 1997""
    FROM table_1_14310205_1
    WHERE ""Intercontinental"" IN ('Champions','Runner up','SF')
       OR ""Recopa 1996"" IN ('Champions','Runner up','SF')
       OR ""Supercopa 1996"" IN ('Champions','Runner up','SF')
       OR ""CONMEBOL 1996"" IN ('Champions','Runner up','SF')
       OR ""Copa Libertadores 1997"" IN ('Champions','Runner up','SF');",reward,,"type: Scope ambiguity | explanation: The phrase ""performed best"" can be read as (a) asking for the single top performer(s) overall (e.g., team(s) that were Champions) or (b) asking for each team's best result across the listed competitions (Champions/Runner up/SF/No late-stage result); the given SQL implements interpretation (b) while also supplying a global count/list of teams that did not qualify for Copa Libertadores 1997, whereas an alternative query might only return the overall Champion(s) or only the count of non-qualifiers."
"List each Ground with the average absolute difference between the numbers inside parentheses of Home team score and Away team score and the average Crowd, restricting to rows that have the same Report value, and include only Grounds where that average absolute difference is ≤ 10 and the average Crowd is > 30000, sorted by average Crowd in descending order?","
SELECT t1.`Ground` AS `Ground`, AVG(ABS((substr(t1.`Home team score`, instr(t1.`Home team score`,'(')+1, instr(t1.`Home team score`,')') - instr(t1.`Home team score`,'(')-1) + 0) - (substr(t1.`Away team score`, instr(t1.`Away team score`,'(')+1, instr(t1.`Away team score`,')') - instr(t1.`Away team score`,'(')-1) + 0)))), AVG(t1.`Crowd`)
FROM `table_1_14312471_1` t1
JOIN `table_1_14312471_1` t2 ON t1.rowid = t2.rowid
WHERE t1.`Report` = t2.`Report`
GROUP BY t1.`Ground`
HAVING AVG(ABS((substr(t1.`Home team score`, instr(t1.`Home team score`,'(')+1, instr(t1.`Home team score`,')') - instr(t1.`Home team score`,'(')-1) + 0) - (substr(t1.`Away team score`, instr(t1.`Away team score`,'(')+1, instr(t1.`Away team score`,')') - instr(t1.`Away team score`,'(')-1) + 0)))) <= 10 AND AVG(t1.`Crowd`) > 30000
ORDER BY AVG(t1.`Crowd`) DESC;
","SELECT col4 AS col4, AVG(ABS(((substr(col1, instr(col1,'(')+1, instr(col1,')') - instr(col1,'(') - 1)) + 0) - ((substr(col3, instr(col3,'(')+1, instr(col3,')') - instr(col3,'(') - 1)) + 0))) , AVG(col5)
FROM `table_1_14312471_1`
WHERE col7 IS NOT NULL
GROUP BY col4
HAVING AVG(ABS(((substr(col1, instr(col1,'(')+1, instr(col1,')') - instr(col1,'(') - 1)) + 0) - ((substr(col3, instr(col3,'(')+1, instr(col3,')') - instr(col3,'(') - 1)) + 0))) <= 10 AND AVG(col5) > 30000
ORDER BY AVG(col5) DESC;","[('mcg', 4.0, 56746.0)]",table_1_14312471_1,"1) Parse intent: group rows by Ground to compute AVG of absolute margin from totals in parentheses and AVG Crowd, filter groups by margin <=10 and avg crowd >30000, sort by avg crowd descending. 2) Map schema: use Home team score and Away team score parentheses values, Ground, Crowd, and Report equality. 3) Draft: ask for Ground, AVG(ABS(parsed home total - parsed away total)) and AVG(Crowd) with the Report equality restriction and HAVING/ORDER BY constraints. 4) Validate: question mentions extraction from parentheses, ABS, AVG, grouping by Ground, Report match, HAVING thresholds, and descending order by avg Crowd.",reserved,12,reward,,
"For each ground give me total matches, average crowd, peak crowd, how many and which fixtures had crowds over 20,000 with a margin of 12 points or less (date, teams, scores and crowd), and the busiest day of week at that ground with its average crowd?","
WITH `matches` AS (
  SELECT
    `Home team`,
    `Home team score`,
    `Away team`,
    `Away team score`,
    `Ground`,
    `Crowd`,
    `Date`,
    `Report`,
    substr(`Date`, 1, instr(`Date`, ',') - 1) AS `day_of_week`,
    CAST(
      substr(
        `Home team score`,
        instr(`Home team score`, '(') + 1,
        instr(`Home team score`, ')') - instr(`Home team score`, '(') - 1
      ) AS INTEGER
    ) AS `home_points`,
    CAST(
      substr(
        `Away team score`,
        instr(`Away team score`, '(') + 1,
        instr(`Away team score`, ')') - instr(`Away team score`, '(') - 1
      ) AS INTEGER
    ) AS `away_points`,
    ABS(
      CAST(
        substr(
          `Home team score`,
          instr(`Home team score`, '(') + 1,
          instr(`Home team score`, ')') - instr(`Home team score`, '(') - 1
        ) AS INTEGER
      )
      - CAST(
        substr(
          `Away team score`,
          instr(`Away team score`, '(') + 1,
          instr(`Away team score`, ')') - instr(`Away team score`, '(') - 1
        ) AS INTEGER
      )
    ) AS `margin`
  FROM `table_1_14312471_3`
)
SELECT
  m.`Ground`,
  COUNT(*) AS `matches`,
  CAST(AVG(m.`Crowd`) AS INTEGER) AS `avg_crowd`,
  MAX(m.`Crowd`) AS `peak_crowd`,
  SUM(CASE WHEN m.`Crowd` > 20000 AND m.`margin` <= 12 THEN 1 ELSE 0 END) AS `high_risk_matches_count`,
  GROUP_CONCAT(
    CASE WHEN m.`Crowd` > 20000 AND m.`margin` <= 12
      THEN '`' || m.`Date` || ' | ' || m.`Home team` || ' ' || m.`Home team score` || ' vs ' || m.`Away team` || ' ' || m.`Away team score` || ' | crowd ' || CAST(m.`Crowd` AS TEXT) || '`'
    END,
    '; '
  ) AS `high_risk_match_list`,
  -- busiest day of week at this ground (highest average crowd)
  (
    SELECT `day_of_week` FROM (
      SELECT mm.`day_of_week`, AVG(mm.`Crowd`) AS `avg_crowd_day`
      FROM `matches` mm
      WHERE mm.`Ground` = m.`Ground`
      GROUP BY mm.`day_of_week`
      ORDER BY `avg_crowd_day` DESC
      LIMIT 1
    )
  ) AS `busiest_day`,
  (
    SELECT CAST(AVG(mm2.`Crowd`) AS INTEGER) FROM `matches` mm2
    WHERE mm2.`Ground` = m.`Ground`
      AND mm2.`day_of_week` = (
        SELECT `day_of_week` FROM (
          SELECT mm3.`day_of_week`, AVG(mm3.`Crowd`) AS `avg_crowd_day`
          FROM `matches` mm3
          WHERE mm3.`Ground` = m.`Ground`
          GROUP BY mm3.`day_of_week`
          ORDER BY `avg_crowd_day` DESC
          LIMIT 1
        )
      )
  ) AS `busiest_day_avg_crowd`
FROM `matches` m
GROUP BY m.`Ground`
ORDER BY `peak_crowd` DESC;
","
WITH `matches` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    col7,
    substr(col6, 1, instr(col6, ',') - 1) AS `day_of_week`,
    CAST(
      substr(
        col1,
        instr(col1, '(') + 1,
        instr(col1, ')') - instr(col1, '(') - 1
      ) AS INTEGER
    ) AS `home_points`,
    CAST(
      substr(
        col3,
        instr(col3, '(') + 1,
        instr(col3, ')') - instr(col3, '(') - 1
      ) AS INTEGER
    ) AS `away_points`,
    ABS(
      CAST(
        substr(
          col1,
          instr(col1, '(') + 1,
          instr(col1, ')') - instr(col1, '(') - 1
        ) AS INTEGER
      )
      - CAST(
        substr(
          col3,
          instr(col3, '(') + 1,
          instr(col3, ')') - instr(col3, '(') - 1
        ) AS INTEGER
      )
    ) AS `margin`
  FROM `table_1_14312471_3`
)
SELECT
  m.col4,
  COUNT(*) AS `matches`,
  CAST(AVG(m.col5) AS INTEGER) AS `avg_crowd`,
  MAX(m.col5) AS `peak_crowd`,
  SUM(CASE WHEN m.col5 > 20000 AND m.`margin` <= 12 THEN 1 ELSE 0 END) AS `high_risk_matches_count`,
  GROUP_CONCAT(
    CASE WHEN m.col5 > 20000 AND m.`margin` <= 12
      THEN '`' || m.col6 || ' | ' || m.col0 || ' ' || m.col1 || ' vs ' || m.col2 || ' ' || m.col3 || ' | crowd ' || CAST(m.col5 AS TEXT) || '`'
    END,
    '; '
  ) AS `high_risk_match_list`,
  -- busiest day of week at this ground (highest average crowd)
  (
    SELECT `day_of_week` FROM (
      SELECT mm.`day_of_week`, AVG(mm.col5) AS `avg_crowd_day`
      FROM `matches` mm
      WHERE mm.col4 = m.col4
      GROUP BY mm.`day_of_week`
      ORDER BY `avg_crowd_day` DESC
      LIMIT 1
    )
  ) AS `busiest_day`,
  (
    SELECT CAST(AVG(mm2.col5) AS INTEGER) FROM `matches` mm2
    WHERE mm2.col4 = m.col4
      AND mm2.`day_of_week` = (
        SELECT `day_of_week` FROM (
          SELECT mm3.`day_of_week`, AVG(mm3.col5) AS `avg_crowd_day`
          FROM `matches` mm3
          WHERE mm3.col4 = m.col4
          GROUP BY mm3.`day_of_week`
          ORDER BY `avg_crowd_day` DESC
          LIMIT 1
        )
      )
  ) AS `busiest_day_avg_crowd`
FROM `matches` m
GROUP BY m.col4
ORDER BY `peak_crowd` DESC;
","[('mcg', 2, 52320, 58307.0, 0, None, 'friday', 58307), ('telstra dome', 2, 32558, 42238.0, 1, '`sunday, 3 august | st kilda 14.17 (101) vs port adelaide 14.9 (93) | crowd 22878.0`', 'saturday', 42238), ('aami stadium', 1, 40730, 40730.0, 1, '`saturday, 2 august | adelaide 13.16 (94) vs carlton 12.14 (86) | crowd 40730.0`', 'saturday', 40730), ('manuka oval', 1, 13550, 13550.0, 0, None, 'sunday', 13550), ('gold coast stadium', 1, 10037, 10037.0, 0, None, 'saturday', 10037)]",table_1_14312471_3,"As an event-safety planner I speak plainly about grounds, crowds and risky fixtures and I know enough schema words like ground, crowd and margin to be precise. The query summarizes per-ground stats and flags/list matches with crowd >20,000 and margin ≤12 while also finding the busiest weekday. It groups matches by Ground and computes count, average crowd, peak crowd, a count and concatenated list of high-risk matches, and busiest day with its avg crowd. I'll ask for a per-ground report covering totals, averages, peaks, high-risk fixtures and busiest weekday. This question maps to the SQL outputs and doesn't assume any extra fields.",persona,"An emergency-evacuation planner for a city event-safety bureau who mines historical AFL match attendance and match-intensity data to size staffing, medical posts and egress timing models. Goals: Estimate typical and peak spectator loads at each ground to allocate evacuation routes and emergency services capacity. Identify matches that combined high attendance with narrow margins (higher crowd intensity/lingering) to model slower egress and greater demand on services. Find day-of-week patterns (Friday/Saturday/Sunday) in attendance to plan staffing rotas and surge-capable teams. Locate specific high-risk fixtures (large crowds at particular grounds) for targeted infrastructure inspections or temporary crowd-control installations. Example Queries: SELECT ""Ground"", COUNT(*) AS matches, CAST(AVG(""Crowd"") AS INTEGER) AS avg_crowd, MAX(""Crowd"") AS peak_crowd
FROM table_1_14312471_3
GROUP BY ""Ground""
ORDER BY peak_crowd DESC; SELECT ""Date"", ""Ground"", ""Home team"", ""Home team score"", ""Away team"", ""Away team score"", ""Crowd"",
ABS(
  CAST(REGEXP_REPLACE(""Home team score"", '.*\\((\\d+)\\).*', '\\1') AS INTEGER)
  - CAST(REGEXP_REPLACE(""Away team score"", '.*\\((\\d+)\\).*', '\\1') AS INTEGER)
) AS margin
FROM table_1_14312471_3
WHERE ABS(
  CAST(REGEXP_REPLACE(""Home team score"", '.*\\((\\d+)\\).*', '\\1') AS INTEGER)
  - CAST(REGEXP_REPLACE(""Away team score"", '.*\\((\\d+)\\).*', '\\1') AS INTEGER)
) <= 12
AND ""Crowd"" > 20000
ORDER BY ""Crowd"" DESC; SELECT TRIM(SPLIT_PART(""Date"", ',', 1)) AS day_of_week, COUNT(*) AS matches, CAST(AVG(""Crowd"") AS INTEGER) AS avg_crowd
FROM table_1_14312471_3
GROUP BY day_of_week
ORDER BY avg_crowd DESC;",reward,,
"For rows with First elected between 1884 and 1888 inclusive, grouped by Party, what are the Party, the total number of seats (Seats), the count of rows where Result = 'Retired Republican hold' (RetiredRepublicanHold), the count where Result = 'Retired Republican loss' (RetiredRepublicanLoss), the count where Result = 'Retired Democratic hold' (RetiredDemocraticHold), the count where Result = 'Retired Democratic gain' (RetiredDemocraticGain), the count where Result = 'Lost re-election Democratic gain' (LostReelectionDemocraticGain), the count where Result = 'Re-elected' (Reelected), the fraction of seats that are 'Retired Republican hold' (FracRetiredRepublicanHold), and the average First elected year (AvgFirstElected), ordered by Seats descending and limited to the top 10?","
SELECT `Party`, COUNT(*) `Seats`, SUM(`Result` = `Retired Republican hold`) `RetiredRepublicanHold`, SUM(`Result` = `Retired Republican loss`) `RetiredRepublicanLoss`, SUM(`Result` = `Retired Democratic hold`) `RetiredDemocraticHold`, SUM(`Result` = `Retired Democratic gain`) `RetiredDemocraticGain`, SUM(`Result` = `Lost re-election Democratic gain`) `LostReelectionDemocraticGain`, SUM(`Result` = `Re-elected`) `Reelected`, SUM(`Result` = `Retired Republican hold`)*1.0/COUNT(*) `FracRetiredRepublicanHold`, AVG(`First elected`) `AvgFirstElected` FROM `table_1_1431450_4` WHERE `First elected` >= 1884 AND `First elected` <= 1888 GROUP BY `Party` ORDER BY `Seats` DESC LIMIT 10;
","SELECT col2, COUNT(*) `Seats`, SUM(col4 = 'Retired Republican hold') `RetiredRepublicanHold`, SUM(col4 = 'Retired Republican loss') `RetiredRepublicanLoss`, SUM(col4 = 'Retired Democratic hold') `RetiredDemocraticHold`, SUM(col4 = 'Retired Democratic gain') `RetiredDemocraticGain`, SUM(col4 = 'Lost re-election Democratic gain') `LostReelectionDemocraticGain`, SUM(col4 = 'Re-elected') `Reelected`, SUM(col4 = 'Retired Republican hold')*1.0/COUNT(*) `FracRetiredRepublicanHold`, AVG(col3) `AvgFirstElected` FROM `table_1_1431450_4` WHERE col3 >= 1884 AND col3 <= 1888 GROUP BY col2 ORDER BY `Seats` DESC LIMIT 10;","[('republican', 6, 0, 0, 0, 0, 0, 0, 0.0, 1886.0), ('democratic', 2, 0, 0, 0, 0, 0, 0, 0.0, 1887.0)]",table_1_1431450_4,"1) Parse intent: aggregate rows by Party for First elected years 1884–1888, counting seats and specific Result categories, computing a fraction and average year, ordering by seat count and limiting to 10. 2) Map schema: Party -> grouping key; First elected -> filter and average; Result -> categorical counts for exact strings. 3) Draft: ask for Party, total seats, counts for each specified Result value, fraction of Retired Republican hold, and avg First elected, grouped and ordered. 4) Validate: ensures all columns, calculations, filters, group, order, and limit are included.",reserved,8,reward,,
"For each Year, what are the SUMs of ((`Boys singles`='Andre Kurniawan Tedjono')+(`Girls singles`='Andre Kurniawan Tedjono')+(`Boys doubles`='Andre Kurniawan Tedjono')+(`Girls doubles`='Andre Kurniawan Tedjono')+(`Mixed doubles`='Andre Kurniawan Tedjono')) as `Andre Kurniawan Tedjono`, ((`Boys singles`='Pia Zebadiah')+(`Girls singles`='Pia Zebadiah')+(`Boys doubles`='Pia Zebadiah')+(`Girls doubles`='Pia Zebadiah')+(`Mixed doubles`='Pia Zebadiah')) as `Pia Zebadiah`, and ((`Boys singles`='Jones Ralfy Jansen')+(`Girls singles`='Jones Ralfy Jansen')+(`Boys doubles`='Jones Ralfy Jansen')+(`Girls doubles`='Jones Ralfy Jansen')+(`Mixed doubles`='Jones Ralfy Jansen')) as `Jones Ralfy Jansen`, grouped by Year, ordered by `Andre Kurniawan Tedjono` descending and limited to 5 rows?","
SELECT
SUM((`Boys singles`='Andre Kurniawan Tedjono')+(`Girls singles`='Andre Kurniawan Tedjono')+(`Boys doubles`='Andre Kurniawan Tedjono')+(`Girls doubles`='Andre Kurniawan Tedjono')+(`Mixed doubles`='Andre Kurniawan Tedjono')) `Andre Kurniawan Tedjono`,
SUM((`Boys singles`='Pia Zebadiah')+(`Girls singles`='Pia Zebadiah')+(`Boys doubles`='Pia Zebadiah')+(`Girls doubles`='Pia Zebadiah')+(`Mixed doubles`='Pia Zebadiah')) AS `Pia Zebadiah`,
SUM((`Boys singles`='Jones Ralfy Jansen')+(`Girls singles`='Jones Ralfy Jansen')+(`Boys doubles`='Jones Ralfy Jansen')+(`Girls doubles`='Jones Ralfy Jansen')+(`Mixed doubles`='Jones Ralfy Jansen')) AS `Jones Ralfy Jansen`
FROM `table_1_14319023_2`
JOIN (SELECT 1) AS `dummy` ON 1=1
WHERE 1=1 AND 1=1
GROUP BY `Year`
ORDER BY `Andre Kurniawan Tedjono` DESC
LIMIT 5;
","
SELECT
SUM((col1='Andre Kurniawan Tedjono')+(col2='Andre Kurniawan Tedjono')+(col3='Andre Kurniawan Tedjono')+(col4='Andre Kurniawan Tedjono')+(col5='Andre Kurniawan Tedjono')) `Andre Kurniawan Tedjono`,
SUM((col1='Pia Zebadiah')+(col2='Pia Zebadiah')+(col3='Pia Zebadiah')+(col4='Pia Zebadiah')+(col5='Pia Zebadiah')) AS `Pia Zebadiah`,
SUM((col1='Jones Ralfy Jansen')+(col2='Jones Ralfy Jansen')+(col3='Jones Ralfy Jansen')+(col4='Jones Ralfy Jansen')+(col5='Jones Ralfy Jansen')) AS `Jones Ralfy Jansen`
FROM `table_1_14319023_2`
JOIN (SELECT 1) AS `dummy` ON 1=1
WHERE 1=1 AND 1=1
GROUP BY col0
ORDER BY `Andre Kurniawan Tedjono` DESC
LIMIT 5;
","[(0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0)]",table_1_14319023_2,"1) Parse the SQL intent: count, per Year, how many of the five event columns equal each of three specific player names and return the top 5 Years by the count for Andre Kurniawan Tedjono. 2) Map schema semantics: use columns Year, Boys singles, Girls singles, Boys doubles, Girls doubles, Mixed doubles and the three target names. 3) Draft the question: ask for SUM of the five equality checks for each name, grouped by Year, ordered and limited. 4) Validate: ensures sums, grouping by Year, ORDER BY Andre DESC and LIMIT 5 are included.",reserved,16,reward,,
"For each Writer, grouped by Writer after joining the table to itself on Total# = Total# and limiting to Series# >= 1 AND Series# <= 12, provide the Writer, Episode Count as the count of Title, Titles as GROUP_CONCAT(Title, ' | '), First Series# as MIN(Series#), Last Series# as MAX(Series#), and MAX(Title = '"" Total Eclipse ""') showing whether any Title equals '"" Total Eclipse ""'?","
SELECT t1.`Writer`, COUNT(t1.`Title`) `Episode Count`, GROUP_CONCAT(t1.`Title`, ' | ') `Titles`, MIN(t1.`Series#`) `First Series#`, MAX(t1.`Series#`) `Last Series#`, MAX(t1.`Title` = '"" Total Eclipse ""') `"" Total Eclipse ""`
FROM `table_1_14330096_4` t1 JOIN `table_1_14330096_4` t2 ON t1.`Total#` = t2.`Total#`
WHERE t1.`Series#` >= 1 AND t1.`Series#` <= 12
GROUP BY t1.`Writer`;
","
SELECT t1.col3, COUNT(t1.col2) `Episode Count`, GROUP_CONCAT(t1.col2, ' | ') `Titles`, MIN(t1.col1) `First Series#`, MAX(t1.col1) `Last Series#`, MAX(t1.col2 = '"" Total Eclipse ""') `"" Total Eclipse ""`
FROM `table_1_14330096_4` t1 JOIN `table_1_14330096_4` t2 ON t1.col0 = t2.col0
WHERE t1.col1 >= 1 AND t1.col1 <= 12
GROUP BY t1.col3;
","[('chris lang', 1, '"" too hot to handle ""', 7.0, 7.0, 0), ('holly phillips', 1, '"" sins of the father ""', 4.0, 4.0, 0), ('john jackson', 1, '"" the king is dead, long live the king… ""', 8.0, 8.0, 0), ('lisa holdsworth', 2, '"" let the games commence "" | "" bad blood ""', 5.0, 10.0, 0), ('michael chaplin', 2, '"" total eclipse "" | "" a dangerous deal ""', 1.0, 9.0, 0), ('ryan craig', 2, '""lost in translation"" | "" something worth fighting for , part 1""', 3.0, 12.0, 0), ('simon j. ashford', 1, '"" cause and effect ""', 2.0, 2.0, 0), ('timothy prager', 2, '"" do you love me? "" | "" the enemy of my enemy ""', 6.0, 11.0, 0)]",table_1_14330096_4,"1) Parse: compute per-Writer aggregates — count of Title, concatenated Titles with ' | ', min/max Series#, and a max-tested equality for the exact title '"" Total Eclipse ""' — after a self-join on Total# and filtering Series# 1..12. 2) Map: associate SQL fields Title, Series#, Total#, Writer and functions COUNT, GROUP_CONCAT, MIN, MAX. 3) Draft: ask for a result per Writer listing each computed column and the specific title presence check. 4) Validate: confirm the question names each aggregate, the separator, the self-join, the Series# bounds, and the grouping by Writer.",reserved,8,reward,,
"Which reactors rank highest by combined significance (Net MWe × operational years), and for each give the combined significance, suggested edition size, commemorate flag and assigned tier so I can set premium and standard model runs?","
WITH metrics AS (
  SELECT
    `AGR Power Station`,
    `Net MWe`,
    `Construction started`,
    `Connected to grid`,
    `Commercial operation`,
    `Accounting closure date`,
    (`Accounting closure date` - `Commercial operation`) AS `operational_years`,
    (`Commercial operation` - `Construction started`) AS `build_to_commission_years`,
    (`Net MWe` * (`Accounting closure date` - `Commercial operation`)) AS `combined_significance`
  FROM `table_1_143352_1`
)
SELECT
  `AGR Power Station`,
  `Net MWe`,
  `Construction started`,
  `Commercial operation`,
  `Accounting closure date`,
  `operational_years`,
  `build_to_commission_years`,
  `combined_significance`,
  ROUND(max(1, `combined_significance` / 1000.0)) AS `suggested_edition_size`,
  CASE WHEN `Accounting closure date` IN (2019, 2023) THEN 'Commemorate' ELSE '' END AS `commemorate_flag`,
  CASE WHEN rn <= 2 THEN 'Premium' WHEN rn <= 4 THEN 'Standard' ELSE 'Limited' END AS `tier`
FROM (
  SELECT
    m.*,
    ROW_NUMBER() OVER (ORDER BY `combined_significance` DESC) AS rn
  FROM metrics m
) sub
ORDER BY `combined_significance` DESC;
","
WITH metrics AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    (col5 - col4) AS `operational_years`,
    (col4 - col2) AS `build_to_commission_years`,
    (col1 * (col5 - col4)) AS `combined_significance`
  FROM `table_1_143352_1`
)
SELECT
  col0,
  col1,
  col2,
  col4,
  col5,
  `operational_years`,
  `build_to_commission_years`,
  `combined_significance`,
  ROUND(max(1, `combined_significance` / 1000.0)) AS `suggested_edition_size`,
  CASE WHEN col5 IN (2019, 2023) THEN 'Commemorate' ELSE '' END AS `commemorate_flag`,
  CASE WHEN rn <= 2 THEN 'Premium' WHEN rn <= 4 THEN 'Standard' ELSE 'Limited' END AS `tier`
FROM (
  SELECT
    m.*,
    ROW_NUMBER() OVER (ORDER BY `combined_significance` DESC) AS rn
  FROM metrics m
) sub
ORDER BY `combined_significance` DESC;
","[('hinkley point b', 1220.0, 1967.0, 1976.0, 2023.0, 47.0, 9.0, 57340.0, 57.0, 'Commemorate', 'Premium'), ('hunterston b', 1190.0, 1967.0, 1976.0, 2023.0, 47.0, 9.0, 55930.0, 56.0, 'Commemorate', 'Premium'), ('heysham 2', 1250.0, 1980.0, 1989.0, 2023.0, 34.0, 9.0, 42500.0, 43.0, 'Commemorate', 'Standard'), ('dungeness b', 1110.0, 1965.0, 1985.0, 2018.0, 33.0, 20.0, 36630.0, 37.0, '', 'Standard'), ('hartlepool', 1210.0, 1968.0, 1989.0, 2019.0, 30.0, 21.0, 36300.0, 36.0, 'Commemorate', 'Limited'), ('heysham 1', 1150.0, 1970.0, 1989.0, 2019.0, 30.0, 19.0, 34500.0, 35.0, 'Commemorate', 'Limited')]",table_1_143352_1,"I need to rank pieces for edition sizes and premium models, so the persona will ask for top reactors by combined impact using slightly technical phrasing. The SQL ranks reactors by combined_significance (Net MWe × operational_years), computes suggested edition sizes, and assigns tiers with the top two as Premium and next two as Standard. The combined_significance is derived from Net MWe and operational lifespan in the table. Draft the question to return the reactors ordered by combined significance with their combined_significance, suggested edition size, commemorate flag and tier. The query provides exactly those ranked fields for decision-making.",persona,"An independent horologist crafting a limited-edition mechanical watch series that encodes each AGR reactor's operational history and scale into dial features and edition sizes. Goals: Determine each reactor's operational lifespan (years between commercial operation and accounting closure) to use as the watch model's 'life' metric. Rank reactors by combined significance (Net MWe × operational years) to set edition sizes and premium models. Identify sites with long build-to-commission times or notable closure years to inspire design elements and launch schedules (e.g., commemorate reactors closed in 2019 or 2023). Example Queries: SELECT ""AGR Power Station"", ""Net MWe"", (""Accounting closure date"" - ""Commercial operation"") AS operational_years FROM ""table_1_143352_1"" ORDER BY operational_years DESC; SELECT ""AGR Power Station"", ""Net MWe"", (""Accounting closure date"" - ""Commercial operation"") AS operational_years, ROUND((""Net MWe"" * (""Accounting closure date"" - ""Commercial operation"")) / 1000.0) AS suggested_edition_size FROM ""table_1_143352_1"" ORDER BY suggested_edition_size DESC; SELECT ""AGR Power Station"", ""Construction started"", ""Commercial operation"", (""Commercial operation"" - ""Construction started"") AS build_to_commission_years FROM ""table_1_143352_1"" WHERE ""Accounting closure date"" IN (2019, 2023) ORDER BY build_to_commission_years DESC;",reward,,
"List the Player, Position, Starter, Touchdowns, Extra points, Field goals, and Points for each player with Points > 0, and also include Expected Points as (Touchdowns*5 + Extra points + Field goals*5) and Mismatch as (Points - (Touchdowns*5 + Extra points + Field goals*5)), ordering the list by Points in descending order?","
SELECT `Player`, `Position`, `Starter`, `Touchdowns`, `Extra points`, `Field goals`, `Points`, (`Touchdowns`*5 + `Extra points` + `Field goals`*5) `Expected Points`, (`Points` - (`Touchdowns`*5 + `Extra points` + `Field goals`*5)) `Mismatch`
FROM `table_1_14342480_5`
WHERE `Points` > 0
ORDER BY -`Points`;
","
SELECT col0, col1, col2, col3, col4, col5, col6, (col3*5 + col4 + col5*5) `Expected Points`, (col6 - (col3*5 + col4 + col5*5)) `Mismatch`
FROM `table_1_14342480_5`
WHERE col6 > 0
ORDER BY -col6;
","[('tom hammond', 'fullback', 'yes', 2.0, 10.0, 0.0, 20.0, 20.0, 0.0), ('duncan thompson', 'right halfback', 'yes', 4.0, 0.0, 0.0, 20.0, 20.0, 0.0), ('fred norcross', 'right halfback', 'no', 2.0, 0.0, 0.0, 10.0, 10.0, 0.0), ('willie heston', 'left halfback', 'yes', 1.0, 0.0, 0.0, 5.0, 5.0, 0.0), ('joe maddock', 'right tackle', 'yes', 1.0, 0.0, 0.0, 5.0, 5.0, 0.0)]",table_1_14342480_5,"1) Parse: The SQL projects player stats and two expressions: Expected Points and Mismatch, with a Points>0 filter and ordering by Points descending. 2) Map: Columns correspond to identity, role, starter flag, scoring counts, and total Points. 3) Draft: Create a question that requests those columns and calculations and specifies the filter and sort order. 4) Validate: Ensure formulas match exactly and ordering is by Points descending.",reserved,5,reward,,
"Considering only Finished values '1st', '2nd', and '3rd' that are not NULL, what are the Finished value, the COUNT(*) of rows, the average days calculated as AVG(replace(Exited,'Day','') - replace(Entered,'Day','')), and a SurvivalCategory which is 1 when (replace(Exited,'Day','') - replace(Entered,'Day','')) >= 14 else 0, including only groups with COUNT(*)>0 or AVG(...)>0, grouped by Finished, ordered by Average_Days descending, and limited to 5 results?","
WITH `ranks`(`1st`,`2nd`,`3rd`,`4th`,`5th`,`6th`,`7th`,`8th`,`9th`) AS (VALUES('1st','2nd','3rd','4th','5th','6th','7th','8th','9th'))
SELECT `Finished`, COUNT(*) `Count`, AVG((replace(`Exited`,'Day','') - replace(`Entered`,'Day',''))) `Average_Days`, CASE WHEN (replace(`Exited`,'Day','') - replace(`Entered`,'Day','')) >= 14 THEN 1 ELSE 0 END `SurvivalCategory`
FROM `table_1_14345690_3` JOIN `ranks` ON 1=1
WHERE `Finished` IN (`ranks`.`1st`,`ranks`.`2nd`,`ranks`.`3rd`) AND `Finished` IS NOT NULL
GROUP BY `Finished`
HAVING COUNT(*)>0 OR AVG((replace(`Exited`,'Day','') - replace(`Entered`,'Day','')))>0
ORDER BY `Average_Days` DESC
LIMIT 5;
","SELECT col4, COUNT(*) `Count`, AVG((replace(col3,'Day','') - replace(col2,'Day',''))) `Average_Days`, CASE WHEN (replace(col3,'Day','') - replace(col2,'Day','')) >= 14 THEN 1 ELSE 0 END `SurvivalCategory`
FROM `table_1_14345690_3`
WHERE col4 IN ('1st','2nd','3rd') AND col4 IS NOT NULL
GROUP BY col4
HAVING COUNT(*)>0 OR 1=1 OR 1=1
ORDER BY `Average_Days` DESC
LIMIT 5;","[('3rd', 1, 0.0, 0), ('2nd', 1, 0.0, 0), ('1st', 1, 0.0, 0)]",table_1_14345690_3,"1) Parse intent: compute grouped statistics for top three finishers including count, mean stay length from Exited minus Entered after removing 'Day', and a binary survival indicator for stays >=14 days; 2) Map schema: use Finished, Entered, Exited columns and apply replace to strip 'Day'; 3) Draft: ask for Finished, COUNT(*), AVG(replace(Exited,'Day','')-replace(Entered,'Day','')), and CASE WHEN difference>=14 THEN 1 ELSE 0 for Finished in ('1st','2nd','3rd'); 4) Validate: ensure Finished is not NULL, apply HAVING COUNT(*)>0 OR AVG(...)>0, order by average days DESC and limit 5.",reserved,24,reward,,
"For each Position, where Height > 0, can you return Position, the count of players (Count), the average Height rounded to one decimal (Avg Height), the maximum Height (Max Height), the minimum Height (Min Height), the number of players with Height > 200 (Tall Players), the percentage of players with Height > 200 rounded to one decimal (Pct Tall), and also include the literal columns 'Russia', 'United States', and 'Italy', grouping by Position, ordering the results by Avg Height descending, and limiting the output to 10 rows?","
SELECT `Position` `Position`, COUNT(*) `Count`, ROUND(AVG(`Height`),1) `Avg Height`, MAX(`Height`) `Max Height`, MIN(`Height`) `Min Height`, SUM(`Height`>200) `Tall Players`, ROUND(100.0*SUM(`Height`>200)/COUNT(*),1) `Pct Tall`, `Russia` `Russia`, `United States` `United States`, `Italy` `Italy`
FROM `table_1_14363116_1`
WHERE `Height`>0
GROUP BY `Position`
ORDER BY `Avg Height` DESC
LIMIT 10;
","SELECT col5 AS col5, COUNT(*) AS `Count`, ROUND(AVG(col4),1) AS `Avg Height`, MAX(col4) AS `Max Height`, MIN(col4) AS `Min Height`, SUM(CASE WHEN col4>200 THEN 1 ELSE 0 END) AS `Tall Players`, ROUND(100.0*SUM(CASE WHEN col4>200 THEN 1 ELSE 0 END)/COUNT(*),1) AS `Pct Tall`, SUM(CASE WHEN col1='Russia' THEN 1 ELSE 0 END) AS `Russia`, SUM(CASE WHEN col1='United States' THEN 1 ELSE 0 END) AS `United States`, SUM(CASE WHEN col1='Italy' THEN 1 ELSE 0 END) AS `Italy`
FROM `table_1_14363116_1`
WHERE col4>0
GROUP BY col5
ORDER BY `Avg Height` DESC
LIMIT 10;","[('middle blocker', 4, 207.3, 210.0, 203.0, 4, 100.0, 0, 0, 0), ('opposite hitter', 1, 204.0, 204.0, 204.0, 1, 100.0, 0, 0, 0), ('outside hitter', 3, 199.3, 204.0, 196.0, 1, 33.3, 0, 0, 0), ('setter', 3, 193.3, 197.0, 189.0, 0, 0.0, 0, 0, 0), ('libero', 2, 186.5, 188.0, 185.0, 0, 0.0, 0, 0, 0)]",table_1_14363116_1,"1) Parse intent: group players by Position, filter Height>0, compute count, average (rounded 1 decimal), max, min, count of Height>200, percent tall (rounded 1 decimal), include literal country columns, order by average height desc and limit 10. 2) Map schema: use table_1_14363116_1 columns Position and Height and include literal 'Russia', 'United States', 'Italy'. 3) Draft: ask for those aggregated metrics per Position with the specified filter, ordering and limit. 4) Validate: ensures all columns, calculations, filter, grouping, ordering and limit are explicitly requested.",reserved,8,reward,,
"For teams with Played = 114 and 1993-94 < 40, show the Team, Average, Points, and a computed Backticked column that wraps the Team name in backticks (e.g. `Team`), ordered by Average descending and limited to 5 rows.","
SELECT `Team`, `Average`, `Points`, '`' || `Team` || '`' `Backticked`
FROM `table_1_14371754_1`
WHERE `Played` = 114 AND `1993-94` < 40
ORDER BY `Average` DESC
LIMIT 5;
","
SELECT col0, col1, col2, '`' || col0 || '`' `Backticked`
FROM `table_1_14371754_1`
WHERE col3 = 114 AND col6 < 40
ORDER BY col1 DESC
LIMIT 5;
","[(""newell's old boys"", '1.026', 117.0, ""`newell's old boys`""), ('racing club', '1.009', 115.0, '`racing club`'), ('ferro carril oeste', '0.991', 113.0, '`ferro carril oeste`'), ('rosario central', '0.982', 112.0, '`rosario central`'), ('textil mandiyú', '0.947', 108.0, '`textil mandiyú`')]",table_1_14371754_1,"Parse: SQL returns Team, Average, Points and a concatenation of backticks around Team for rows with Played = 114 and 1993-94 < 40, ordered by Average desc, limited to 5. Map: Played and 1993-94 are the WHERE filters; Backticked is the `Team` string. Draft: formulate a question requesting those four outputs for the top five teams by Average under the specified filters. Validate: question mentions all columns, the backticked calculation, the filter, order and limit.",reserved,8,reward,,
"Which Config core [2] groups have an average GFLOPS(@ 200MHz)/Frequency greater than 0.005, and for each such Config core [2] what is that AVG(GFLOPS(@ 200MHz)/Frequency) and the MAX(MPixel/s [1]), considering only entries where GFLOPS(@ 200MHz) is not empty and Frequency > 0, returning at most 5 results?","
SELECT DISTINCT `Config core [2]`, AVG(`GFLOPS(@ 200MHz)`/`Frequency`), MAX(`MPixel/s [1]`) FROM `table_1_1439045_5` WHERE `GFLOPS(@ 200MHz)` <> '' AND `Frequency` > 0 GROUP BY `Config core [2]` HAVING AVG(`GFLOPS(@ 200MHz)`/`Frequency`) > 0.005 LIMIT 5;
","
SELECT DISTINCT col3, AVG(col10/col11), MAX(col5) FROM `table_1_1439045_5` WHERE col10 <> '' AND col11 > 0 GROUP BY col3 HAVING AVG(col10/col11) > 0.005 LIMIT 5;
","[('2/1', 0.008, 200.0), ('2/2', 0.008, 400.0), ('4/2', 0.016, 400.0)]",table_1_1439045_5,"Parse intent: select distinct Config core [2] groups and return AVG(GFLOPS(@ 200MHz)/Frequency) and MAX(MPixel/s [1]) with filters GFLOPS not empty and Frequency > 0, HAVING average > 0.005, limit 5. Map schema: use the specified column names exactly as the aggregates and conditions reference. Draft: phrase a question asking which Config core [2] groups meet the average threshold and what their average and max MPixel/s [1] are, with the filter and limit. Validate: confirm inclusion of all columns, the division GFLOPS(@ 200MHz)/Frequency, the HAVING > 0.005, non-empty GFLOPS(@ 200MHz), Frequency > 0, and LIMIT 5.",reserved,9,reward,,
Which economic classes have population density over 0.05 and what is their largest population?,"
SELECT DISTINCT `Economic Class` AS `Class`, COUNT(*) `Barangay Count`, SUM(`Population (2010)`) `Total Population`, SUM(`Land Area (In sqm.)`) `Total Land Area`, (SUM(`Population (2010)`)*1.0)/NULLIF(SUM(`Land Area (In sqm.)`),0) `Average Density`, MAX(`Population (2010)`) `Max Population`, MIN(`Population (2010)`) `Min Population`, CASE WHEN (SUM(`Population (2010)`)*1.0)/NULLIF(SUM(`Land Area (In sqm.)`),0) > 0.2 THEN MAX(`Population (2010)`) END, NULL
FROM `table_1_1440338_1`
WHERE `Land Area (In sqm.)`>0 AND `Population (2010)`>0
GROUP BY `Economic Class`
HAVING (SUM(`Population (2010)`)*1.0)/NULLIF(SUM(`Land Area (In sqm.)`),0) > 0.05
LIMIT 2;
","
SELECT DISTINCT col2 AS `Class`, COUNT(*) `Barangay Count`, SUM(col1) `Total Population`, SUM(col3) `Total Land Area`, (SUM(col1)*1.0)/NULLIF(SUM(col3),0) `Average Density`, MAX(col1) `Max Population`, MIN(col1) `Min Population`, CASE WHEN (SUM(col1)*1.0)/NULLIF(SUM(col3),0) > 0.2 THEN MAX(col1) END, NULL
FROM `table_1_1440338_1`
WHERE col3>0 AND col1>0
GROUP BY col2
HAVING (SUM(col1)*1.0)/NULLIF(SUM(col3),0) > 0.05
LIMIT 2;
","[('rural', 76, 98959.0, 91656.0, 1.0796783625730995, 4331.0, 170.0, 4331.0, None), ('urban', 14, 37689.0, 85985.0, 0.4383206373204629, 6524.0, 650.0, 6524.0, None)]",table_1_1440338_1,"STEP 1: Parse the SQL intent — group rows by Economic Class for barangays with positive land area and population; compute per-class barangay count, total population (SUM), total land area (SUM), average density (=SUM(pop)/SUM(area)), max and min barangay population; keep only classes whose average density > 0.05 and return up to 2 classes. STEP 2: Determine ambiguity type — attachment ambiguity fits: a phrase like ""largest population"" can attach to either the class as a whole (total population) or to an individual barangay within the class (maximum barangay population). This maps well because the query computes both SUM and MAX but a simple NL phrasing could refer to either. STEP 3: Draft the question — ""Which economic classes have population density over 0.05 and what is their largest population?"" STEP 4: Explain the ambiguity — the original query interprets ""largest population"" as the maximum single-barangay population within each class (it also computes total population), but a reader could instead interpret ""largest population"" to mean the total population of the entire economic class; additionally, the SQL filters by average density (>0.05) and returns only up to two classes, which is not explicit in the NL phrasing.",reserved,15,reward,,"type: Attachment ambiguity | explanation: The phrase ""largest population"" can attach to (a) the class as a whole (total population = SUM of barangays) or (b) an individual barangay within the class (max barangay population = MAX); the SQL returns per-class SUM and MAX but a reader of the question could reasonably mean either interpretation."
"Give me the full list of competitors with name, nationality, first and second jump lengths, the jump difference, points, their nation's average points and athlete count, parsed NT and WC ranks and a flag where they differ, ordered by jump difference (largest first) and then by national average points.","
WITH parsed AS (
  SELECT
    `Rank`,
    `Name`,
    `Nationality`,
    CAST(`1st (m)` AS REAL) AS `1st_m_num`,
    CAST(`2nd (m)` AS REAL) AS `2nd_m_num`,
    CAST(`Points` AS REAL) AS `Points_num`,
    `Overall NT points`,
    `Overall WC points (Rank)`,
    ABS(CAST(`1st (m)` AS REAL) - CAST(`2nd (m)` AS REAL)) AS `jump_diff_m`,
    CAST(
      substr(
        `Overall NT points`,
        instr(`Overall NT points`, '(') + 1,
        instr(`Overall NT points`, ')') - instr(`Overall NT points`, '(') - 1
      ) AS INTEGER
    ) AS `NT_rank`,
    CAST(
      substr(
        `Overall WC points (Rank)`,
        instr(`Overall WC points (Rank)`, '(') + 1,
        instr(`Overall WC points (Rank)`, ')') - instr(`Overall WC points (Rank)`, '(') - 1
      ) AS INTEGER
    ) AS `WC_rank`
  FROM `table_1_14407512_23`
)
SELECT
  `Name`,
  `Nationality`,
  `1st_m_num` AS `1st (m)`,
  `2nd_m_num` AS `2nd (m)`,
  `jump_diff_m`,
  `Points_num` AS `Points`,
  ROUND(AVG(`Points_num`) OVER (PARTITION BY `Nationality`), 3) AS `avg_points_by_nation`,
  COUNT(*) OVER (PARTITION BY `Nationality`) AS `athlete_count_by_nation`,
  `NT_rank`,
  `WC_rank`,
  CASE WHEN `NT_rank` IS NOT NULL AND `WC_rank` IS NOT NULL AND `NT_rank` <> `WC_rank` THEN 1 ELSE 0 END AS `NT_WC_rank_mismatch`
FROM parsed
ORDER BY `jump_diff_m` DESC, `avg_points_by_nation` DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    CAST(col3 AS REAL) AS `1st_m_num`,
    CAST(col4 AS REAL) AS `2nd_m_num`,
    CAST(col5 AS REAL) AS `Points_num`,
    col6,
    col7,
    ABS(CAST(col3 AS REAL) - CAST(col4 AS REAL)) AS `jump_diff_m`,
    CAST(
      substr(
        col6,
        instr(col6, '(') + 1,
        instr(col6, ')') - instr(col6, '(') - 1
      ) AS INTEGER
    ) AS `NT_rank`,
    CAST(
      substr(
        col7,
        instr(col7, '(') + 1,
        instr(col7, ')') - instr(col7, '(') - 1
      ) AS INTEGER
    ) AS `WC_rank`
  FROM `table_1_14407512_23`
)
SELECT
  col1,
  col2,
  `1st_m_num` AS col3,
  `2nd_m_num` AS col4,
  `jump_diff_m`,
  `Points_num` AS col5,
  ROUND(AVG(`Points_num`) OVER (PARTITION BY col2), 3) AS `avg_points_by_nation`,
  COUNT(*) OVER (PARTITION BY col2) AS `athlete_count_by_nation`,
  `NT_rank`,
  `WC_rank`,
  CASE WHEN `NT_rank` IS NOT NULL AND `WC_rank` IS NOT NULL AND `NT_rank` <> `WC_rank` THEN 1 ELSE 0 END AS `NT_WC_rank_mismatch`
FROM parsed
ORDER BY `jump_diff_m` DESC, `avg_points_by_nation` DESC;
","[('gregor schlierenzauer', 'aut', 114.5, 129.0, 14.5, 236.8, 236.8, 1, 3, 2, 1), ('anders bardal', 'nor', 117.5, 128.0, 10.5, 240.4, 238.8, 2, 5, 5, 0), ('janne happonen', 'fin', 118.0, 125.5, 7.5, 236.3, 242.3, 2, 1, 11, 1), ('janne ahonen', 'fin', 122.5, 126.0, 3.5, 248.3, 242.3, 2, 2, 3, 1), ('tom hilde', 'nor', 121.5, 122.5, 1.0, 237.2, 238.8, 2, 4, 4, 0)]",table_1_14407512_23,"In my voice I'd request a sorted list that highlights inconsistent jumpers first while also showing national averages to judge setup tolerances and coaching effects. The SQL orders by jump difference descending then by the nation's average points descending and returns detailed per-athlete info including parsed ranks and mismatch flag. The relevant columns are Name, Nationality, 1st (m), 2nd (m), computed jump_diff_m, Points, avg points by nation, athlete count by nation, NT_rank, WC_rank and NT_WC_rank_mismatch. I would ask for the full roster with those fields sorted by jump variability then national average so I can pick candidates for historical case studies. This mirrors the query's selection and ordering.",persona,"A retired World Cup ski-suit tailor turned data-obsessed historical reconstructor who uses past event tables to re-create period-accurate jump equipment and tuning notes. Goals: Identify athletes with the largest within-competition jump variability to infer which suits or setups tolerated inconsistent conditions (useful for reconstructing adjustable rigging). Compare average competition points by nationality to detect national setup patterns or coaching effects that might influence suit design choices. Find cases where the 'Overall NT points' ranking (national-tour influenced) differs from the 'Overall WC points' ranking to spot jumpers who excelled domestically but underperformed internationally—candidates for tailored historical case studies. Example Queries: SELECT Name, Nationality, ""1st (m)"", ""2nd (m)"", ABS(CAST(""1st (m)"" AS REAL) - CAST(""2nd (m)"" AS REAL)) AS jump_diff
FROM table_1_14407512_23
ORDER BY jump_diff DESC
LIMIT 5; SELECT Nationality, AVG(CAST(Points AS REAL)) AS avg_points, COUNT(*) AS athlete_count
FROM table_1_14407512_23
GROUP BY Nationality
ORDER BY avg_points DESC; SELECT Name, ""Overall NT points"", ""Overall WC points (Rank)"",
       CAST(REGEXP_REPLACE(""Overall NT points"", '.*\((\d+)\).*', '\1') AS INTEGER) AS NT_rank,
       CAST(REGEXP_REPLACE(""Overall WC points (Rank)"", '.*\((\d+)\).*', '\1') AS INTEGER) AS WC_rank
FROM table_1_14407512_23
WHERE CAST(REGEXP_REPLACE(""Overall NT points"", '.*\((\d+)\).*', '\1') AS INTEGER) <> CAST(REGEXP_REPLACE(""Overall WC points (Rank)"", '.*\((\d+)\).*', '\1') AS INTEGER);",reward,,
"Using only competitors with 1st (m) >= 200.0 and 2nd (m) >= 200.0, which top three Nationalities (ordered by Avg_points_per_m = AVG(Points/((1st (m) + 2nd (m)))) descending) have the following per-nationality values: Competitors (COUNT(*)), Avg_total_m (AVG((1st (m) + 2nd (m)))), Avg_points (AVG(Points)), Gregor Schlierenzauer (MAX(Points)), Worst_points (MIN(Points)) and Potential_gain (AVG(Points) - MIN(Points)), considering only nationalities with at least one competitor?","
SELECT `Nationality`, COUNT(*) AS `Competitors`, AVG((`1st (m)` + `2nd (m)`)) AS `Avg_total_m`, AVG(`Points`) AS `Avg_points`, AVG(`Points`/((`1st (m)` + `2nd (m)`))) AS `Avg_points_per_m`, MAX(`Points`) AS `Gregor Schlierenzauer`, MIN(`Points`) AS `Worst_points`, (AVG(`Points`) - MIN(`Points`)) AS `Potential_gain` FROM `table_1_14407512_27` WHERE `1st (m)` >= 200.0 AND `2nd (m)` >= 200.0 GROUP BY `Nationality` HAVING COUNT(*) > 0 ORDER BY `Avg_points_per_m` DESC LIMIT 3;
","
SELECT col2, COUNT(*) AS `Competitors`, AVG((col3 + col4)) AS `Avg_total_m`, AVG(col5) AS `Avg_points`, AVG(col5/((col3 + col4))) AS `Avg_points_per_m`, MAX(col5) AS `Gregor Schlierenzauer`, MIN(col5) AS `Worst_points`, (AVG(col5) - MIN(col5)) AS `Potential_gain` FROM `table_1_14407512_27` WHERE col3 >= 200.0 AND col4 >= 200.0 GROUP BY col2 HAVING COUNT(*) > 0 ORDER BY `Avg_points_per_m` DESC LIMIT 3;
","[('slo', 1, 425.0, 418.5, 0.9847058823529412, '418.5', '418.5', 0.0), ('aut', 2, 447.0, 438.65, 0.9813075552530429, '442.1', '435.2', 3.4499999999999886), ('fin', 2, 416.25, 408.0, 0.9800368351770168, '418.8', '397.2', 10.800000000000011)]",table_1_14407512_27,"1) Parse intent: filter rows by jump thresholds, compute multiple aggregates per nationality, and pick the top three by efficiency. 2) Map schema: include Nationality and computed fields Competitors, Avg_total_m, Avg_points, Avg_points_per_m, Gregor Schlierenzauer, Worst_points, Potential_gain. 3) Draft: frame a question requesting these fields with the same WHERE, GROUP BY, HAVING, ORDER BY and LIMIT conditions. 4) Validate: confirm inclusion of all columns, calculations, and constraints from the query.",reserved,9,reward,,
"List the Team and a computed status that returns 'Below' if that team's Average is below the AVG of the Average column across all rows, for records where Played >= 100 and Points < 130, grouped by Team with HAVING COUNT(*) = 1, ordered by status descending and limited to five rows?","
SELECT `Team`, CASE WHEN `Average` < AVG(CAST(`Average` AS REAL)) OVER () THEN 'Below' END `status`
FROM `table_1_14489821_1`
WHERE `Played` >= 100 AND `Points` < 130
GROUP BY `Team`
HAVING COUNT(*) = 1
ORDER BY `status` DESC
LIMIT 5;
","
SELECT col0, CASE WHEN col1 < AVG(CAST(col1 AS REAL)) OVER () THEN 'Below' END `status`
FROM `table_1_14489821_1`
WHERE col3 >= 100 AND col2 < 130
GROUP BY col0
HAVING COUNT(*) = 1
ORDER BY `status` DESC
LIMIT 5;
","[('ferro carril oeste', 'Below'), ('instituto de córdoba', 'Below'), ('platense', 'Below'), ('racing de córdoba', 'Below'), ('talleres de córdoba', 'Below')]",table_1_14489821_1,"1) Parse the SQL intent: produce Team and a CASE status 'Below' if Average < AVG(Average) over all rows, constrained by Played >= 100 and Points < 130, with GROUP BY Team HAVING COUNT(*) = 1, ORDER BY status DESC, LIMIT 5. 2) Map schema semantics: Average is compared to the global mean of Average; Team, Played and Points are used as filters. 3) Draft the question: ask for the Team and computed 'Below' status under those conditions and grouping constraints. 4) Validate: confirms inclusion of the AVG comparison, filters, grouping/having, ordering and row limit.",reserved,16,reward,,
"Can you give me a prioritized roster of every international version showing country, local show name, host, channel, year aired, original top prize and detected currency, numeric local amount, converted USD prize (EUR→USD @1.08, GBP→USD @1.25, USD→USD @1.00), start/end year, years running, still‑airing flag, a low‑end outlier flag for prizes < $10,000, and the overall priority score, sorted with highest priority first?","
WITH normalized AS (
  SELECT
    `Country`,
    `Local Name`,
    `Host`,
    `Channel`,
    `Year Aired`,
    `Top Prize`,
    CASE
      WHEN `Top Prize` LIKE '%€%' THEN 'EUR'
      WHEN `Top Prize` LIKE '%£%' THEN 'GBP'
      WHEN `Top Prize` LIKE '%$%' THEN 'USD'
      ELSE 'UNKNOWN'
    END AS currency,
    CAST(
      REPLACE(
        REPLACE(
          REPLACE(
            REPLACE(
              REPLACE(
                REPLACE(`Top Prize`, '$', ''),
              '€', ''),
            '£', ''),
          ',', ''),
        '.', ''),
      ' ', '') AS INTEGER) AS amount_local,
    CAST(SUBSTR(`Year Aired`, 1, 4) AS INTEGER) AS start_year,
    CASE
      WHEN `Year Aired` LIKE '%present%' THEN CAST(strftime('%Y','now') AS INTEGER)
      ELSE CAST(SUBSTR(`Year Aired`, -4, 4) AS INTEGER)
    END AS end_year,
    CASE WHEN `Year Aired` LIKE '%present%' THEN 1 ELSE 0 END AS still_airing
  FROM `table_1_14523485_9`
)
SELECT
  `Country`,
  `Local Name`,
  `Host`,
  `Channel`,
  `Year Aired`,
  `Top Prize`,
  currency,
  amount_local,
  CASE
    WHEN currency = 'EUR' THEN amount_local * 1.08
    WHEN currency = 'GBP' THEN amount_local * 1.25
    WHEN currency = 'USD' THEN amount_local * 1.00
    ELSE NULL
  END AS prize_usd,
  start_year,
  end_year,
  (end_year - start_year + 1) AS years_running,
  still_airing,
  CASE
    WHEN (CASE WHEN currency = 'EUR' THEN amount_local * 1.08 WHEN currency = 'GBP' THEN amount_local * 1.25 WHEN currency = 'USD' THEN amount_local * 1.00 ELSE NULL END) < 10000 THEN 1
    ELSE 0
  END AS low_end_outlier,
  (CASE WHEN currency = 'EUR' THEN amount_local * 1.08 WHEN currency = 'GBP' THEN amount_local * 1.25 WHEN currency = 'USD' THEN amount_local * 1.00 ELSE 0 END)
    * (1.0 + ((end_year - start_year + 1) / 10.0))
    * (CASE WHEN still_airing = 1 THEN 1.5 ELSE 1.0 END) AS priority_score
FROM normalized
ORDER BY priority_score DESC;
","
WITH normalized AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    CASE
      WHEN col5 LIKE '%€%' THEN 'EUR'
      WHEN col5 LIKE '%£%' THEN 'GBP'
      WHEN col5 LIKE '%$%' THEN 'USD'
      ELSE 'UNKNOWN'
    END AS currency,
    CAST(
      REPLACE(
        REPLACE(
          REPLACE(
            REPLACE(
              REPLACE(
                REPLACE(col5, '$', ''),
              '€', ''),
            '£', ''),
          ',', ''),
        '.', ''),
      ' ', '') AS INTEGER) AS amount_local,
    CAST(SUBSTR(col4, 1, 4) AS INTEGER) AS start_year,
    CASE
      WHEN col4 LIKE '%present%' THEN CAST(strftime('%Y','now') AS INTEGER)
      ELSE CAST(SUBSTR(col4, -4, 4) AS INTEGER)
    END AS end_year,
    CASE WHEN col4 LIKE '%present%' THEN 1 ELSE 0 END AS still_airing
  FROM `table_1_14523485_9`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  currency,
  amount_local,
  CASE
    WHEN currency = 'EUR' THEN amount_local * 1.08
    WHEN currency = 'GBP' THEN amount_local * 1.25
    WHEN currency = 'USD' THEN amount_local * 1.00
    ELSE NULL
  END AS prize_usd,
  start_year,
  end_year,
  (end_year - start_year + 1) AS years_running,
  still_airing,
  CASE
    WHEN (CASE WHEN currency = 'EUR' THEN amount_local * 1.08 WHEN currency = 'GBP' THEN amount_local * 1.25 WHEN currency = 'USD' THEN amount_local * 1.00 ELSE NULL END) < 10000 THEN 1
    ELSE 0
  END AS low_end_outlier,
  (CASE WHEN currency = 'EUR' THEN amount_local * 1.08 WHEN currency = 'GBP' THEN amount_local * 1.25 WHEN currency = 'USD' THEN amount_local * 1.00 ELSE 0 END)
    * (1.0 + ((end_year - start_year + 1) / 10.0))
    * (CASE WHEN still_airing = 1 THEN 1.5 ELSE 1.0 END) AS priority_score
FROM normalized
ORDER BY priority_score DESC;
","[('germany', 'rich list', 'kai pflaume', 'sat.1', '2007–present', '€100,000', 'EUR', 100000, 108000.0, 2007, 2025, 19, 1, 0, 469800.0), ('australia', 'the rich list', ""andrew o'keefe"", 'seven network', '2007-2009', '$250,000', 'USD', 250000, 250000.0, 2007, 2009, 3, 0, 0, 325000.0), ('united states', 'the rich list', 'eamonn holmes', 'fox', '2006', '$250,000', 'USD', 250000, 250000.0, 2006, 2006, 1, 0, 0, 275000.0), ('united kingdom', 'who dares wins', 'nick knowles', 'bbc one', '2007–present', '£50,000', 'GBP', 50000, 62500.0, 2007, 2025, 19, 1, 0, 271875.0), ('new zealand', 'the rich list', 'jason gunn', 'tvnz', '2007–present', '$50,000', 'USD', 50000, 50000.0, 2007, 2025, 19, 1, 0, 217500.0), ('france', 'la liste gagnante', 'patrice laffont', 'france 3', '2009', '5.000€', 'EUR', 5000, 5400.0, 2009, 2009, 1, 0, 1, 5940.000000000001)]",table_1_14523485_9,"As a format broker/econ nerd I'd ask crisply for a normalized, comparable roster rather than raw trivia. I know the table has country, local show name, host, channel, year aired and a top prize string. The SQL normalizes currency/amount, converts to USD with fixed rates, computes running years, flags still-airing and low-end prizes, and produces a priority score, then orders by that score. So I want a prioritized list of versions with original and normalized prize info, airing years and flags, low-end marker, and the priority score. This question matches the query's intent and output and asks for it in industry terms.",persona,"A niche ‘game-show prize parity’ consultant — a cross between a TV format broker and a micro-economist — who evaluates how attractive each international version's top prize is once normalized and contextualized. Goals: Convert each country's advertised top prize into a common currency (USD) so format-sellers can compare prize attractiveness when negotiating licensing fees. Identify which international versions are still airing (and their launch years) to prioritize markets for format relaunches or spin-offs. Spot low-end outliers (very small local top prizes) that might indicate subsidized/localized formats or opportunities for premiumised revamps. Example Queries: /* Normalize local top prizes to USD (example exchange rates: EUR->1.08, GBP->1.25, USD->1.00). Uses regexp to strip non-digits. */
SELECT ""Country"", ""Local Name"", ""Host"", ""Channel"", ""Year Aired"",
  CASE
    WHEN ""Top Prize"" LIKE '%€%' THEN CAST(REGEXP_REPLACE(""Top Prize"", '[^0-9]', '', 'g') AS NUMERIC) * 1.08
    WHEN ""Top Prize"" LIKE '%£%' THEN CAST(REGEXP_REPLACE(""Top Prize"", '[^0-9]', '', 'g') AS NUMERIC) * 1.25
    WHEN ""Top Prize"" LIKE '%$%' THEN CAST(REGEXP_REPLACE(""Top Prize"", '[^0-9]', '', 'g') AS NUMERIC) * 1.00
    ELSE NULL
  END AS prize_usd
FROM table_1_14523485_9
ORDER BY prize_usd DESC; /* List versions currently airing and extract their start year to estimate longevity. */
SELECT ""Country"", ""Local Name"", ""Host"", ""Channel"", ""Year Aired"",
  SUBSTRING(""Year Aired"" FROM '^\d{4}')::INT AS start_year
FROM table_1_14523485_9
WHERE ""Year Aired"" ILIKE '%present%'; /* Find low local top prizes (under 10,000 in local numeric terms) to flag potential markets for premium upgrades. */
SELECT ""Country"", ""Local Name"", ""Host"", ""Top Prize"",
  CASE
    WHEN ""Top Prize"" LIKE '%€%' THEN 'EUR'
    WHEN ""Top Prize"" LIKE '%£%' THEN 'GBP'
    WHEN ""Top Prize"" LIKE '%$%' THEN 'USD'
    ELSE 'UNKNOWN'
  END AS currency,
  CAST(REGEXP_REPLACE(""Top Prize"", '[^0-9]', '', 'g') AS INTEGER) AS amount_local
FROM table_1_14523485_9
WHERE CAST(REGEXP_REPLACE(""Top Prize"", '[^0-9]', '', 'g') AS INTEGER) < 10000;",reward,,
"Who are the top five directors by Episodes (COUNT(No. in series)) when considering only rows with Production code BETWEEN 101 AND 119 and No. in series >= 1, and for each Directed by show Episodes = COUNT(No. in series), UniqueTitles = COUNT(DISTINCT Title), and a literal 0 AS ""Unaired Pilot"", grouping by Directed by and including only directors with more than one episode?","
SELECT `Directed by`, COUNT(`No. in series`) AS `Episodes`, COUNT(DISTINCT `Title`) AS `UniqueTitles`, 0 `'""Unaired Pilot""'`
FROM `table_1_14562722_1`
WHERE `Production code` BETWEEN 101 AND 119 AND `No. in series` >= 1
GROUP BY `Directed by`
HAVING COUNT(`No. in series`) > 1
ORDER BY `Episodes` DESC
LIMIT 5;
","
SELECT col2, COUNT(col0) AS `Episodes`, COUNT(DISTINCT col1) AS `UniqueTitles`, 0 `'""Unaired Pilot""'`
FROM `table_1_14562722_1`
WHERE col5 BETWEEN 101 AND 119 AND col0 >= 1
GROUP BY col2
HAVING COUNT(col0) > 1
ORDER BY `Episodes` DESC
LIMIT 5;
","[('dave filoni', 8, 8, 0), ('giancarlo volpe', 5, 5, 0), ('lauren macmullan', 4, 4, 0), ('anthony lioi', 2, 2, 0)]",table_1_14562722_1,"1) Parse SQL intent: return director-level aggregates for a constrained set of episodes and limit to five directors with more than one episode. 2) Map schema semantics: include Directed by, Episodes as COUNT(No. in series), UniqueTitles as COUNT(DISTINCT Title), and a constant 0 column named '""Unaired Pilot""'. 3) Draft the question: require WHERE Production code BETWEEN 101 AND 119 and No. in series >= 1, GROUP BY Directed by, HAVING COUNT(No. in series) > 1, ORDER BY Episodes DESC, LIMIT 5. 4) Validate: question mirrors the SQL selection, aggregation, filters, grouping, having, ordering and limit.",reserved,16,reward,,
"Considering only rows where # > 0, what are the top 5 Nature of Situation groups by COUNT(*) AS ""Aircraft crash"" (ordered descending), and for each group what is the Nature of Situation, the count labeled ""Aircraft crash"", the MIN(Original U.S. Airdate) reported as ""First Airdate"", the MAX(Original U.S. Airdate) reported as ""Last Airdate"", and the GROUP_CONCAT of Episode Title separated by '; ' shown as ""Episodes""?","
SELECT `Nature of Situation`, COUNT(*) AS `Aircraft crash`, MIN(`Original U.S. Airdate`) AS `First Airdate`, MAX(`Original U.S. Airdate`) AS `Last Airdate`, GROUP_CONCAT(`Episode Title`, '; ') AS `Episodes` FROM `table_1_14570857_1` WHERE `#` > 0 GROUP BY `Nature of Situation` ORDER BY `Aircraft crash` DESC LIMIT 5;
","
SELECT col4, COUNT(*) AS `Aircraft crash`, MIN(col5) AS `First Airdate`, MAX(col5) AS `Last Airdate`, GROUP_CONCAT(col1, '; ') AS `Episodes` FROM `table_1_14570857_1` WHERE col0 > 0 GROUP BY col4 ORDER BY `Aircraft crash` DESC LIMIT 5;
","[('train derailment', 1, 'november 21, 2007', 'november 21, 2007', 'osaka train wreck'), ('ed flood hospital', 1, 'december 5, 2007', 'december 5, 2007', 'hurricane hospital'), ('earthquake victim rescue', 1, 'november 28, 2007', 'november 28, 2007', 'earthquake rapid response'), ('disabled ship', 1, 'november 14, 2007', 'november 14, 2007', 'ocean emergency'), ('aircraft crash', 1, 'november 7, 2007', 'november 7, 2007', 'alive in the andes')]",table_1_14570857_1,"1) Parse SQL intent: compute per-Nature of Situation aggregates (count, min/max airdate, concatenated titles), limit to five groups by descending count, excluding rows with # <= 0. 2) Map schema semantics: map COUNT(*)→Aircraft crash, MIN/MAX(Original U.S. Airdate)→First/Last Airdate, GROUP_CONCAT(Episode Title, '; ')→Episodes. 3) Draft the question to include all these exact column names, aliases, filter, grouping, ordering, and limit. 4) Validate completeness against the SQL: every column and calculation appears in the question.",reserved,8,reward,,
"Rank car/team Nos. by GT3 wins (tie-break by pole→GT3 conversion then GT4 wins) and return for each their GT3/GT4 win counts, pole count, pole-to-GT3 conversion and the circuits/rounds where a pole turned into a GT3 win?","
WITH `pivot` AS (
  SELECT `GT3 Winner` AS `team`, 'GT3Win' AS `evtype`, `Round`, `Circuit`, `Date`
  FROM `table_1_14574130_3`
  WHERE `GT3 Winner` LIKE 'No.%'
  UNION ALL
  SELECT `GT4 Winner` AS `team`, 'GT4Win' AS `evtype`, `Round`, `Circuit`, `Date`
  FROM `table_1_14574130_3`
  WHERE `GT4 Winner` LIKE 'No.%'
  UNION ALL
  SELECT `Pole Position` AS `team`, 'Pole' AS `evtype`, `Round`, `Circuit`, `Date`
  FROM `table_1_14574130_3`
  WHERE `Pole Position` LIKE 'No.%'
)
SELECT
  main.`team` AS `Team`,
  SUM(CASE WHEN main.`evtype` = 'GT3Win' THEN 1 ELSE 0 END) AS `GT3_Wins`,
  SUM(CASE WHEN main.`evtype` = 'GT4Win' THEN 1 ELSE 0 END) AS `GT4_Wins`,
  SUM(CASE WHEN main.`evtype` = 'Pole' THEN 1 ELSE 0 END) AS `Pole_Count`,
  (SELECT COUNT(DISTINCT p1.`Round` || '|' || p1.`Circuit` || '|' || p1.`Date`)
   FROM `pivot` p1
   JOIN `pivot` p2 ON p1.`team` = p2.`team` AND p1.`Round` = p2.`Round` AND p1.`Circuit` = p2.`Circuit` AND p1.`Date` = p2.`Date`
   WHERE p1.`evtype` = 'Pole' AND p2.`evtype` = 'GT3Win' AND p1.`team` = main.`team`
  ) AS `Pole_to_GT3_Wins`,
  ROUND(
    CASE WHEN SUM(CASE WHEN main.`evtype` = 'Pole' THEN 1 ELSE 0 END) = 0 THEN 0.0
    ELSE CAST((SELECT COUNT(DISTINCT p1.`Round` || '|' || p1.`Circuit` || '|' || p1.`Date`)
               FROM `pivot` p1
               JOIN `pivot` p2 ON p1.`team` = p2.`team` AND p1.`Round` = p2.`Round` AND p1.`Circuit` = p2.`Circuit` AND p1.`Date` = p2.`Date`
               WHERE p1.`evtype` = 'Pole' AND p2.`evtype` = 'GT3Win' AND p1.`team` = main.`team`
              ) AS REAL)
         / SUM(CASE WHEN main.`evtype` = 'Pole' THEN 1 ELSE 0 END)
    END, 3
  ) AS `Pole_To_GT3_Conversion`,
  (SELECT GROUP_CONCAT(DISTINCT p.`Circuit` || ' (R' || p.`Round` || ')', '; ')
   FROM `pivot` p
   JOIN `pivot` q ON p.`team` = q.`team` AND p.`Round` = q.`Round` AND p.`Circuit` = q.`Circuit` AND p.`Date` = q.`Date`
   WHERE p.`evtype` = 'GT3Win' AND q.`evtype` = 'Pole' AND p.`team` = main.`team`
  ) AS `Circuits_When_Poled_And_Won_GT3`
FROM `pivot` AS main
GROUP BY main.`team`
ORDER BY `GT3_Wins` DESC, `Pole_To_GT3_Conversion` DESC, `GT4_Wins` DESC;
","WITH `pivot` AS (
  SELECT col5 AS `team`, 'GT3Win' AS `evtype`, col0, col1, col2
  FROM `table_1_14574130_3`
  WHERE col5 LIKE 'No.%'
  UNION ALL
  SELECT col6 AS `team`, 'GT4Win' AS `evtype`, col0, col1, col2
  FROM `table_1_14574130_3`
  WHERE col6 LIKE 'No.%'
  UNION ALL
  SELECT col4 AS `team`, 'Pole' AS `evtype`, col0, col1, col2
  FROM `table_1_14574130_3`
  WHERE col4 LIKE 'No.%'
)
SELECT
  main.`team` AS `Team`,
  SUM(CASE WHEN main.`evtype` = 'GT3Win' THEN 1 ELSE 0 END) AS `GT3_Wins`,
  SUM(CASE WHEN main.`evtype` = 'GT4Win' THEN 1 ELSE 0 END) AS `GT4_Wins`,
  SUM(CASE WHEN main.`evtype` = 'Pole' THEN 1 ELSE 0 END) AS `Pole_Count`,
  (SELECT COUNT(DISTINCT p1.col0 || '|' || p1.col1 || '|' || p1.col2)
   FROM `pivot` p1
   JOIN `pivot` p2 ON p1.`team` = p2.`team` AND p1.col0 = p2.col0 AND p1.col1 = p2.col1 AND p1.col2 = p2.col2
   WHERE p1.`evtype` = 'Pole' AND p2.`evtype` = 'GT3Win' AND p1.`team` = main.`team`
  ) AS `Pole_to_GT3_Wins`,
  ROUND(
    CASE WHEN SUM(CASE WHEN main.`evtype` = 'Pole' THEN 1 ELSE 0 END) = 0 THEN 0.0
    ELSE CAST((SELECT COUNT(DISTINCT p1.col0 || '|' || p1.col1 || '|' || p1.col2)
               FROM `pivot` p1
               JOIN `pivot` p2 ON p1.`team` = p2.`team` AND p1.col0 = p2.col0 AND p1.col1 = p2.col1 AND p1.col2 = p2.col2
               WHERE p1.`evtype` = 'Pole' AND p2.`evtype` = 'GT3Win' AND p1.`team` = main.`team`
              ) AS REAL)
         / SUM(CASE WHEN main.`evtype` = 'Pole' THEN 1 ELSE 0 END)
    END, 3
  ) AS `Pole_To_GT3_Conversion`,
  (SELECT GROUP_CONCAT(DISTINCT p.col1 || ' (R' || p.col0 || ')')
   FROM `pivot` p
   JOIN `pivot` q ON p.`team` = q.`team` AND p.col0 = q.col0 AND p.col1 = q.col1 AND p.col2 = q.col2
   WHERE p.`evtype` = 'GT3Win' AND q.`evtype` = 'Pole' AND p.`team` = main.`team`
  ) AS `Circuits_When_Poled_And_Won_GT3`
FROM `pivot` AS main
GROUP BY main.`team`
ORDER BY `GT3_Wins` DESC, `Pole_To_GT3_Conversion` DESC, `GT4_Wins` DESC;","[('no. 40 team trimite brookspeed', 4, 0, 0, 0, 0.0, None), ('no. 15 cr scuderia', 3, 0, 1, 0, 0.0, None), ('no. 16 cr scuderia', 2, 0, 2, 1, 0.5, 'knockhill (R3.0)'), ('no. 6 matech gt racing', 1, 0, 2, 1, 0.5, 'snetterton (R8.0)'), ('no. 1 team rpm', 1, 0, 0, 0, 0.0, None), ('no. 14 cr scuderia', 1, 0, 1, 0, 0.0, None), ('no. 23 christian in motorsport', 1, 0, 2, 0, 0.0, None), ('no. 8 tech 9', 1, 0, 0, 0, 0.0, None), ('no. 88 ims motorsport', 0, 8, 0, 0, 0.0, None), ('no. 55 rob austin racing', 0, 3, 0, 0, 0.0, None), ('no. 51 team rpm', 0, 2, 0, 0, 0.0, None), ('no. 52 team rpm', 0, 1, 0, 0, 0.0, None), ('no. 20 abg motorsport', 0, 0, 1, 0, 0.0, None), ('no. 23 christians in motorsport', 0, 0, 2, 0, 0.0, None), ('no. 42 22gt racing', 0, 0, 1, 0, 0.0, None), ('no. 9 tech 9', 0, 0, 2, 0, 0.0, None)]",table_1_14574130_3,"I might want a ranked leaderboard of competitiveness prioritising GT3 success then qualifying efficiency. The SQL orders teams by GT3 wins desc, then pole-to-GT3 conversion desc, then GT4 wins desc while returning the counts, conversion and matching circuits. The mapping is team number to aggregated GT3_Wins, GT4_Wins, Pole_Count, Pole_to_GT3_Wins, Pole_To_GT3_Conversion and Circuits_When_Poled_And_Won_GT3. Draft: request a ranking of car numbers by GT3 wins (breaking ties by pole→GT3 conversion then GT4 wins) and show their stats and the circuits where pole converted to a GT3 win. Validate: this is exactly what the query produces and orders.",persona,"Motorsport data analyst working for a British GT team, responsible for season performance review and pre-race preparation. They would use this calendar/results table to quantify team and driver results by circuit, check pole-to-win conversion and spot circuit-specific strengths/weaknesses. Goals: Count GT3/GT4 victories by car/team across the 2008 season to evaluate competitiveness. Identify circuits and rounds where specific drivers or car numbers performed best (wins or poles). Measure pole-position to race-win conversion (how often the pole team won the GT3 race) to evaluate qualifying effectiveness. Example Queries: /* Count GT3 wins grouped by team (rows where winners are recorded as team numbers like 'No. 15 ...') */
SELECT ""GT3 Winner"" AS team, COUNT(*) AS wins
FROM table_1_14574130_3
WHERE ""GT3 Winner"" LIKE 'No.%'
GROUP BY ""GT3 Winner""
ORDER BY wins DESC; /* List rounds/circuits where a specific driver (e.g. Matt Nicoll-Jones) is listed as GT4 winner */
SELECT DISTINCT ""Round"", ""Circuit"", ""Date""
FROM table_1_14574130_3
WHERE ""GT4 Winner"" LIKE '%Matt Nicoll-Jones%'
ORDER BY ""Date""; /* Find rounds where the pole-position team did NOT win the GT3 race (compare team-formatted entries) */
SELECT DISTINCT ""Round"", ""Circuit"", ""Date"", ""Pole Position"", ""GT3 Winner""
FROM table_1_14574130_3
WHERE ""Pole Position"" LIKE 'No.%'
  AND ""GT3 Winner"" LIKE 'No.%'
  AND ""Pole Position"" <> ""GT3 Winner""
ORDER BY ""Round"";",reward,,
Which states with literacy under 85% have the smallest increase to reach a state with higher literacy and a high gender gap?,"
SELECT t1.`India/State/UT` AS `State`, t1.`Literate Persons (%)` `Literate`, t1.`Males (%)` `Males`, t1.`Females (%)` `Females`, (t1.`Males (%)` - t1.`Females (%)`) `Gender Gap`, MIN((t2.`Literate Persons (%)` - t1.`Literate Persons (%)`)) `MinLeap`, CASE WHEN (t1.`Males (%)` - t1.`Females (%)`) > 10 THEN 'High Gap' ELSE 'Low/Moderate' END `GapCategory` FROM `table_1_14598_9` t1 JOIN `table_1_14598_9` t2 ON (t2.`Literate Persons (%)` > t1.`Literate Persons (%)`) WHERE t1.`Literate Persons (%)` < 85 GROUP BY t1.`India/State/UT` HAVING MIN((t2.`Literate Persons (%)` - t1.`Literate Persons (%)`)) > 0 LIMIT 10;
","
SELECT t1.col1 AS `State`, t1.col2 `Literate`, t1.col3 `Males`, t1.col4 `Females`, (t1.col3 - t1.col4) `Gender Gap`, MIN((t2.col2 - t1.col2)) `MinLeap`, CASE WHEN (t1.col3 - t1.col4) > 10 THEN 'High Gap' ELSE 'Low/Moderate' END `GapCategory` FROM `table_1_14598_9` t1 JOIN `table_1_14598_9` t2 ON (t2.col2 > t1.col2) WHERE t1.col2 < 85 GROUP BY t1.col1 HAVING MIN((t2.col2 - t1.col2)) > 0 LIMIT 10;
","[('andhra pradesh', '67.66', '75.56', '59.74', 15.82, 1.0799999999999983, 'High Gap'), ('arunachal pradesh', '66.95', '73.69', '59.57', 14.119999999999997, 0.10999999999999943, 'High Gap'), ('assam', '73.18', '78.81', '67.27', 11.540000000000006, 0.269999999999996, 'High Gap'), ('bihar', '63.82', '73.39', '53.33', 20.060000000000002, 3.1300000000000026, 'High Gap'), ('chhattisgarh', '71.04', '81.45', '60.59', 20.86, 2.1400000000000006, 'High Gap'), ('dadra and nagar haveli', '77.65', '86.46', '65.93', 20.529999999999987, 1.6599999999999966, 'High Gap'), ('gujarat', '79.31', '87.23', '70.73', 16.5, 0.3199999999999932, 'High Gap'), ('haryana', '76.64', '85.38', '66.77', 18.61, 0.04000000000000625, 'High Gap'), ('himachal pradesh', '83.78', '90.83', '76.60', 14.230000000000004, 2.489999999999995, 'High Gap'), ('jammu and kashmir', '68.74', '78.26', '58.01', 20.250000000000007, 0.980000000000004, 'High Gap')]",table_1_14598_9,"STEP 1: Parse the SQL intent: For each state with 'Literate Persons (%)' < 85, compute the state's literacy, male and female literacy percentages, the gender gap (males - females), a GapCategory ('High Gap' if gap>10 else 'Low/Moderate'), and the minimal positive difference between that state's literacy and any higher state's literacy (the smallest leap to a higher literacy). Only include states that do have a higher-literacy state (MIN difference > 0) and return up to 10 rows. STEP 2: Choose an ambiguity type: Scope ambiguity fits well — the query computes a per-state minimal positive leap, but a natural language phrasing can be read as asking for the single smallest leap overall or for each state's own smallest leap. This scope ambiguity maps naturally onto the MIN(...) per-group vs a global MIN. STEP 3: Draft the question: ""Which states with literacy under 85% have the smallest increase to reach a state with higher literacy and a high gender gap?"" STEP 4: Explain the ambiguity: In the SQL, ""smallest increase to reach a state with higher literacy"" is evaluated per state (the minimum positive difference between that state and any higher state). The NL question can alternatively be read as asking for the state(s) that achieve the single smallest such increase across all states (global minimum), or as asking for each state's individual smallest increase; it can also be read as ambiguous about what ""high gender gap"" means (the SQL uses >10, but a reader might expect a different threshold).",reserved,15,reward,,"type: Scope ambiguity | explanation: The SQL computes a per-state minimum positive gap to any higher-literacy state; the question can be read either as (a) for each state, what is its own smallest increase to a higher state, or (b) which state(s) have the single smallest increase overall — additionally, ""high gender gap"" could be interpreted with different thresholds than the SQL's >10."
"Give the top 10 Class A values and their total_wins (COUNT(*) AS total_wins), excluding empty Class A values, grouping by Class A and ordering the groups by total_wins in descending order?","
SELECT `Class A`, COUNT(*) total_wins FROM `table_1_14603057_2` WHERE `Class A` != '' GROUP BY `Class A` ORDER BY total_wins DESC LIMIT 10;
","
SELECT col1, COUNT(*) total_wins FROM `table_1_14603057_2` WHERE col1 != '' GROUP BY col1 ORDER BY total_wins DESC LIMIT 10;
","[('rule', 4), ('plains', 4), ('valley view', 2), ('san isidro', 2), ('nazareth', 2), ('henrietta midway', 2), ('garden city', 2), ('westbrook', 1), ('sterling city', 1), ('poolville', 1)]",table_1_14603057_2,"Parse intent: return counts per Class A (COUNT(*) AS total_wins) for non-empty Class A, sorted descending and limited to 10. Map schema: 'Class A' is the grouping column and total_wins is the aggregated count. Draft: request top 10 Class A values and their total_wins with specified filters and ordering. Validate: ensure the question references Class A, total_wins (COUNT(*)), exclusion of empty values, grouping by Class A, ordering by total_wins DESC, and limit 10.",reserved,8,reward,,
"List up to 10 Networks with COUNT(DISTINCT Call sign) AS Station Count and SUM(Physical) AS Physical Total considering only rows where Physical > 0 and Virtual >= 0, grouping by Network and ordered by Physical Total in descending order?","
SELECT `Network`, COUNT(DISTINCT `Call sign`) AS `Station Count`, SUM(`Physical`) `Physical Total`
FROM `table_1_14623167_1`
WHERE `Physical` > 0 AND `Virtual` >= 0
GROUP BY `Network`
HAVING 1
ORDER BY `Physical Total` DESC
LIMIT 10;
","
SELECT col4, COUNT(DISTINCT col2) AS `Station Count`, SUM(col1) `Physical Total`
FROM `table_1_14623167_1`
WHERE col1 > 0 AND col0 >= 0
GROUP BY col4
HAVING 1
ORDER BY `Physical Total` DESC
LIMIT 10;
","[('nbc', 1, 31.0), ('fox', 1, 26.0), ('pbs', 1, 22.0), ('abc', 1, 17.0), ('cbs', 1, 12.0)]",table_1_14623167_1,"1) The SQL computes per-Network aggregates (distinct station count and sum of Physical) after filtering Physical > 0 and Virtual >= 0, then sorts by the summed Physical and returns up to 10 groups. 2) Schema mapping: Network groups, Call sign counted distinctly, Physical summed. 3) Draft a question that requests Network plus the two aggregate metrics with the exact filters, grouping, sort, and limit. 4) Ensure wording includes COUNT(DISTINCT Call sign) AS Station Count and SUM(Physical) AS Physical Total explicitly.",reserved,14,reward,,
"Show School Year, Class A, Class AA, Class AAA, Class AAAA, Class AAAAA, compute DuplicatePairs as ((Class A = Class AA) + (Class A = Class AAA) + (Class A = Class AAAA) + (Class A = Class AAAAA) + (Class AA = Class AAA) + (Class AA = Class AAAA) + (Class AA = Class AAAAA) + (Class AAA = Class AAAA) + (Class AAA = Class AAAAA) + (Class AAAA = Class AAAAA)), and include the literal '`Abilene`' AS Backticked_Abilene, the literal '`Dalhart`' AS Backticked_Dalhart, and the literal '`Lazbuddie`' AS Backticked_Lazbuddie', restricted to rows where this DuplicatePairs value is > 0?","
SELECT `School Year`, `Class A`, `Class AA`, `Class AAA`, `Class AAAA`, `Class AAAAA`, ((`Class A` = `Class AA`) + (`Class A` = `Class AAA`) + (`Class A` = `Class AAAA`) + (`Class A` = `Class AAAAA`) + (`Class AA` = `Class AAA`) + (`Class AA` = `Class AAAA`) + (`Class AA` = `Class AAAAA`) + (`Class AAA` = `Class AAAA`) + (`Class AAA` = `Class AAAAA`) + (`Class AAAA` = `Class AAAAA`)) `DuplicatePairs`, '`Abilene`' `Backticked_Abilene`, '`Dalhart`' `Backticked_Dalhart`, '`Lazbuddie`' `Backticked_Lazbuddie` FROM `table_1_14630796_1` WHERE ((`Class A` = `Class AA`) + (`Class A` = `Class AAA`) + (`Class A` = `Class AAAA`) + (`Class A` = `Class AAAAA`) + (`Class AA` = `Class AAA`) + (`Class AA` = `Class AAAA`) + (`Class AA` = `Class AAAAA`) + (`Class AAA` = `Class AAAA`) + (`Class AAA` = `Class AAAAA`) + (`Class AAAA` = `Class AAAAA`)) > 0;
","SELECT col0, col1, col2, col3, col4, col5 FROM `table_1_14630796_1` LIMIT 10;","[('1986-87', 'menard', 'florence', 'dalhart', 'monahans', 'wichita falls rider'), ('1987-88', 'happy', 'troup', 'orangefield', 'wichita falls', 'round rock westwood'), ('1988-89', 'abbott', 'olney', 'falfurrias', 'port neches-groves', 'converse judson'), ('1989-90', 'jayton', '(tie) brackettville/overton', 'gonzales', 'midlothian', 'wichita falls rider'), ('1990-91', 'abbott', 'rosebud-lott', 'orangefield', 'stephenville', 'duncanville'), ('1991-92', 'trenton', 'cooper', 'troy', 'mineral wells', 'weslaco'), ('1992-93', 'trenton', 'rosebud-lott', 'ferris', 'livingston', 'abilene'), ('1993-94', 'lazbuddie', 'rosebud-lott', 'mont belvieu barbers hill', 'port neches-groves', 'duncanville'), ('1994-95', 'lazbuddie', 'idalou', 'friona', 'rockwall', 'fort worth paschal'), ('1995-96', 'lazbuddie', 'rosebud-lott', 'mont belvieu barbers hill', 'carthage', 'humble kingwood')]",table_1_14630796_1,"Parse intent: retrieve each School Year row with the six class columns, the numeric DuplicatePairs equal to the sum of all pairwise equality checks among those class columns, include three backticked-string alias columns, and only show rows where the sum is greater than zero. Map semantics: the query highlights years with duplicate class winners and also adds three constant-labeled fields. Draft question: ask for the six columns, the explicit DuplicatePairs expression, the three backticked literal aliases, and the WHERE DuplicatePairs > 0 restriction. Validate: ensure inclusion of every equality term, the aliases DuplicatePairs and Backticked_Abilene/Backticked_Dalhart/Backticked_Lazbuddie, and the filter condition.",reserved,3,reward,,
"For each Written by value (as Writer) who wrote more than one episode with No. in series between 53 and 64 inclusive, return Writer, the EpisodeCount (COUNT of episodes), FirstNo (MIN of No. in series), LastNo (MAX of No. in series), Broadcasts (all TV broadcast values concatenated with "", ""), and All Titles including '""Virtual Unreality""' (all Title values concatenated with "" | ""), limiting the output to 10 rows.","
SELECT
`Written by` `Writer`,
COUNT(*) `EpisodeCount`,
MIN(`No. in series`) `FirstNo`,
MAX(`No. in series`) `LastNo`,
group_concat(`TV broadcast`, ', ') `Broadcasts`,
group_concat(`Title`, ' | ') AS `All Titles including '""Virtual Unreality""'`
FROM `table_1_14637853_3`
WHERE `No. in series` >= 53 AND `No. in series` <= 64
GROUP BY `Written by`
HAVING COUNT(*) > 1
LIMIT 10;
","
SELECT
col2 `Writer`,
COUNT(*) `EpisodeCount`,
MIN(col0) `FirstNo`,
MAX(col0) `LastNo`,
group_concat(col5, ', ') `Broadcasts`,
group_concat(col1, ' | ') AS `All Titles including '""Virtual Unreality""'`
FROM `table_1_14637853_3`
WHERE col0 >= 53 AND col0 <= 64
GROUP BY col2
HAVING COUNT(*) > 1
LIMIT 10;
","[('glenn leopold', 3, 53.0, 61.0, 's03e01, s03e02, s03e09', '""biker knights of the round table (part 1)"" | ""biker knights of the round table (part 2)"" | ""caveat mentor""'), ('jess winfield', 4, 55.0, 62.0, 's03e03, s03e05, s03e06, s03e10', '""virtual unreality"" | ""diet of worms"" | ""rocketh and rideth"" | ""where no mouse has gone before""')]",table_1_14637853_3,"1) The SQL groups rows by `Written by` for series numbers between 53 and 64, computing COUNT(*), MIN(No. in series), MAX(No. in series), and two group_concats; it then keeps groups with COUNT(*) > 1 and limits to 10. 2) Map headers: `Written by` -> writer, `No. in series` for min/max, `TV broadcast` and `Title` for concatenation, and rows 53–64 constraint. 3) Draft a question that requests Writer, EpisodeCount, FirstNo, LastNo, Broadcasts (comma-separated), and All Titles including '""Virtual Unreality""' (pipe-separated) for writers with more than one episode in that range, up to 10 results. 4) Validate that the question includes every selected column, calculation, filter, grouping, having, and limit from the SQL.",reserved,9,reward,,
"Which Positions have more than one entry, and for each such Position provide the Position, the Count of entries for that Position, the Earliest Pick number (minimum Pick # for that Position), and Players (all Player values concatenated), returning only the record where Pick # equals that Earliest Pick?","
SELECT t.`Position`, (SELECT COUNT(*) FROM `table_1_14650373_1` u WHERE u.`Position` = t.`Position`) `Count`, (SELECT MIN(u.`Pick #`) FROM `table_1_14650373_1` u WHERE u.`Position` = t.`Position`) `Earliest Pick`, (SELECT GROUP_CONCAT(u.`Player`) FROM `table_1_14650373_1` u WHERE u.`Position` = t.`Position`) `Players` FROM `table_1_14650373_1` t WHERE t.`Pick #` = (SELECT MIN(u2.`Pick #`) FROM `table_1_14650373_1` u2 WHERE u2.`Position` = t.`Position`) AND (SELECT COUNT(*) FROM `table_1_14650373_1` v WHERE v.`Position` = t.`Position`) > 1;
","
SELECT t.col3, (SELECT COUNT(*) FROM `table_1_14650373_1` u WHERE u.col3 = t.col3) `Count`, (SELECT MIN(u.col0) FROM `table_1_14650373_1` u WHERE u.col3 = t.col3) `Earliest Pick`, (SELECT GROUP_CONCAT(u.col2) FROM `table_1_14650373_1` u WHERE u.col3 = t.col3) `Players` FROM `table_1_14650373_1` t WHERE t.col0 = (SELECT MIN(u2.col0) FROM `table_1_14650373_1` u2 WHERE u2.col3 = t.col3) AND (SELECT COUNT(*) FROM `table_1_14650373_1` v WHERE v.col3 = t.col3) > 1;
","[('defensive end', 2, 34.0, 'shawn patterson,nate hill'), ('running back', 2, 61.0, 'keith woodside,patrick collins')]",table_1_14650373_1,"1) Parse intent: report positions with multiple players and summarize pick and player info by the earliest pick per position. 2) Map schema: Position groups use Pick # for earliest and Player for the concatenated list. 3) Draft the question: request Position, Count of entries for that Position, Earliest Pick (MIN Pick #), and Players (GROUP_CONCAT of Player) but limit to Positions whose count > 1 and to the row whose Pick # equals that minimum. 4) Validate: all columns and calculations (Count, MIN Pick #, GROUP_CONCAT Players) and the >1 and MIN-based row constraint are included.",reserved,4,reward,,
"For each type of Obamacare exchange, which states contribute the most and the least per person, and what are the average net contribution per person and the total population for those exchange types among states with more than one million people?","
WITH `clean` AS (
 SELECT `State`, CAST(REPLACE(REPLACE(REPLACE(`Net contribution per capita`,'$',''),',',''),'$','') AS REAL) AS `netpc`, `Population`, `Obamacare: Fed/ State/ Partnership`
 FROM `table_1_14700336_1`
)
SELECT c.`Obamacare: Fed/ State/ Partnership` AS `aca_type`,
 COUNT(*) AS `count_states`,
 SUM(`Population`) AS `total_pop`,
 AVG(`netpc`) AS `avg_netpc`,
 (SELECT `State` FROM `clean` WHERE `Obamacare: Fed/ State/ Partnership` = c.`Obamacare: Fed/ State/ Partnership` ORDER BY `netpc` DESC LIMIT 1) AS `top_contributor`,
 (SELECT `State` FROM `clean` WHERE `Obamacare: Fed/ State/ Partnership` = c.`Obamacare: Fed/ State/ Partnership` ORDER BY `netpc` ASC LIMIT 1) AS `top_receiver`
FROM `clean` c
WHERE `Population` > 1000000
GROUP BY c.`Obamacare: Fed/ State/ Partnership`
HAVING COUNT(*)>1
ORDER BY `avg_netpc` DESC
LIMIT 10;
","
WITH `clean` AS (
 SELECT col1, CAST(REPLACE(REPLACE(REPLACE(col7,'$',''),',',''),'$','') AS REAL) AS `netpc`, col3, col11
 FROM `table_1_14700336_1`
)
SELECT c.col11 AS `aca_type`,
 COUNT(*) AS `count_states`,
 SUM(col3) AS `total_pop`,
 AVG(`netpc`) AS `avg_netpc`,
 (SELECT col1 FROM `clean` WHERE col11 = c.col11 ORDER BY `netpc` DESC LIMIT 1) AS `top_contributor`,
 (SELECT col1 FROM `clean` WHERE col11 = c.col11 ORDER BY `netpc` ASC LIMIT 1) AS `top_receiver`
FROM `clean` c
WHERE col3 > 1000000
GROUP BY c.col11
HAVING COUNT(*)>1
ORDER BY `avg_netpc` DESC
LIMIT 10;
","[('partnership', 7, 40560996.0, 656.0, 'delaware', 'west virginia'), ('state-based', 15, 104313760.0, 611.1333333333333, 'minnesota', 'district of columbia'), ('federal-based', 20, 148426663.0, -1329.8, 'nebraska', 'alaska')]",table_1_14700336_1,"STEP 1: Parse the SQL intent: the query cleans Net contribution per capita to a numeric, filters rows with Population > 1,000,000, groups rows by Obamacare exchange type, keeps groups with more than one state, and for each group returns count of states, sum of Population, average net contribution per capita, the state with the highest net contribution per capita, and the state with the lowest net contribution per capita; results ordered by avg_netpc desc and limited to 10. STEP 2: Determine ambiguity type: Entity vagueness fits well — phrases like “contribute the most” can refer to per-capita contribution (what the SQL uses) or to total contribution (netpc * population), so the natural language can be read in multiple valid ways. STEP 3: Draft the question: ""For each type of Obamacare exchange, which states contribute the most and the least per person, and what are the average net contribution per person and the total population for those exchange types among states with more than one million people?"" STEP 4: Explain the ambiguity: in the original query ""contribute the most/least per person"" is implemented as net contribution per capita and averages are computed over the >1M population subset per exchange type; an alternative interpretation of the NL could treat ""contribute the most"" as highest total contribution (netpc * population) or could scope the population filter or the aggregates differently (e.g., apply ""more than one million"" only to listed states but not to averages).",reserved,36,reward,,"type: Entity Vagueness | explanation: The phrase ""contribute the most"" can mean per-capita (net contribution per person, which the SQL uses) or total contribution (net contribution per capita multiplied by population); additionally, the placement of the ""more than one million people"" constraint could be interpreted as applying to which parts of the question (only the listed states vs. all aggregated measures)."
Which players have more appearances and a higher proportion of European appearances than the average for their position?,"
SELECT main.`Name` `Player`, main.`Position` `Position`, main.`Total` `TotalAppearances`, main.`Europe` `EuropeanAppearances`, ROUND((main.`Europe`*1.0)/main.`Total`,3) `EuropeShare`, agg.`AvgTotal` `PositionAvgTotal`, agg.`AvgEuropeShare` `PositionAvgEuropeShare`
FROM `table_1_14707564_1` main
JOIN (
  SELECT `Position`, AVG(`Total`) `AvgTotal`, AVG((`Europe`*1.0)/`Total`) `AvgEuropeShare`
  FROM `table_1_14707564_1`
  GROUP BY `Position`
  HAVING COUNT(*)>0
) AS agg
ON main.`Position`=agg.`Position`
WHERE main.`Total`>agg.`AvgTotal` AND (main.`Europe`*1.0)/main.`Total`>agg.`AvgEuropeShare`
ORDER BY main.`Europe`
LIMIT 5;
","
SELECT main.col2 `Player`, main.col3 col3, main.col9 `TotalAppearances`, main.col7 `EuropeanAppearances`, ROUND((main.col7*1.0)/main.col9,3) `EuropeShare`, agg.`AvgTotal` `PositionAvgTotal`, agg.`AvgEuropeShare` `PositionAvgEuropeShare`
FROM `table_1_14707564_1` main
JOIN (
  SELECT col3, AVG(col9) `AvgTotal`, AVG((col7*1.0)/col9) `AvgEuropeShare`
  FROM `table_1_14707564_1`
  GROUP BY col3
  HAVING COUNT(*)>0
) AS agg
ON main.col3=agg.col3
WHERE main.col9>agg.`AvgTotal` AND (main.col7*1.0)/main.col9>agg.`AvgEuropeShare`
ORDER BY main.col7
LIMIT 5;
","[('migueli', 'df', 549.0, 85.0, 0.155, 511.3333333333333, 0.15298603446943096), ('víctor valdés category:articles with hcards', 'gk', 518.0, 112.0, 0.216, 464.0, 0.19103493737640082), ('carles puyol category:articles with hcards', 'df', 583.0, 128.0, 0.22, 511.3333333333333, 0.15298603446943096), ('xavi hernández category:articles with hcards', 'mf', 692.0, 153.0, 0.221, 528.3333333333334, 0.18758954099855865)]",table_1_14707564_1,"STEP 1: Parse the SQL intent: the query computes, per player, Total and Europe counts and the Europe share (Europe/Total), joins each player to the average Total and average EuropeShare for that player's Position, then selects players whose Total > position-average Total AND whose Europe/Total > position-average EuropeShare, returning those players ordered by Europe (ascending) and limited to 5. STEP 2: Chosen ambiguity type: scope ambiguity — fits well because the natural-language phrasing can be read as requiring both conditions simultaneously (SQL's AND) or as requiring either condition (an OR) or as ambiguity about which parts of the comparison the phrase ""their position average"" attaches to. STEP 3: Draft the question: ""Which players have more appearances and a higher proportion of European appearances than the average for their position?"" STEP 4: Explain ambiguity: In the original SQL this is interpreted conjunctively (players must exceed the position average in both Total and EuropeShare, with EuropeShare computed as Europe/Total and averages computed per Position). Alternatively the question could be read as asking for players who satisfy either condition (more Total OR higher Europe proportion), or as applying ""than the average for their position"" only to one of the two metrics, or as comparing raw European appearances rather than the proportion.",reserved,14,reward,,"type: Scope ambiguity | explanation: The SQL requires both conditions (Total > position-average Total AND Europe/Total > position-average EuropeShare). The natural-language phrasing is ambiguous because it could mean both conditions must hold (as in the query), or it could be interpreted as either condition sufficing, or that the phrase ""than the average for their position"" applies only to one of the two comparisons (or that ""higher proportion"" might be misread as higher absolute European appearances)."
Which NHL teams had Canadian picks and how many picks did they have?,"
SELECT DISTINCT `NHL team` AS `Team`,
COUNT(*) `Picks`,
group_concat(`Position`, ', ') `Positions`,
SUM(`Nationality` = 'Canada') `Canadian Picks`,
group_concat(`Player`, ', ') `Players`
FROM `table_1_1473672_9`
WHERE `Player` <> ''
GROUP BY `NHL team`
HAVING COUNT(*) > 0
LIMIT 5;
","
SELECT DISTINCT col4 AS `Team`,
COUNT(*) `Picks`,
group_concat(col2, ', ') `Positions`,
SUM(col3 = 'Canada') `Canadian Picks`,
group_concat(col1, ', ') `Players`
FROM `table_1_1473672_9`
WHERE col1 <> ''
GROUP BY col4
HAVING COUNT(*) > 0
LIMIT 5;
","[('atlanta flames', 2, 'defence, right wing', 0, 'pierre roy, jean lamarre'), ('california golden seals', 1, 'centre', 0, 'denis meloche'), ('chicago black hawks', 1, 'right wing', 0, 'gary donaldson'), ('detroit red wings', 1, 'defence', 0, 'george kuzmicz'), ('minnesota north stars', 1, 'right wing', 0, 'glen mikkelson')]",table_1_1473672_9,"STEP 1: Parse the SQL intent — group rows by NHL team, return each team (limited to 5), the total number of picks per team (COUNT(*)) , a comma-joined list of Positions, the number of picks whose Nationality = 'Canada' (SUM(...)), and a comma-joined list of Players; only include rows where Player <> '' and groups with at least one pick. STEP 2: Determine ambiguity type — attachment ambiguity fits well because the natural-language modifier ""Canadian"" or the phrase ""how many picks"" can attach to different parts of the question (the team, the picks, or the players), creating multiple plausible readings while the SQL actually provides both total picks and Canadian-pick counts. STEP 3: Draft the question — ""Which NHL teams had Canadian picks and how many picks did they have?"" STEP 4: Explain the ambiguity — in the original query the result includes both total picks and the number of Canadian picks per team, so the question could be read as asking (a) which teams had at least one Canadian player and how many total picks those teams made, (b) which teams had Canadian picks and how many of those picks were Canadian, or (c) which teams (that are Canadian) made how many picks; the SQL corresponds to interpretation (a) and (b) because it returns both total picks and Canadian picks counts, but the plain question is ambiguous about which count is requested.",reserved,9,reward,,"type: Attachment ambiguity | explanation: The phrase ""Canadian picks"" can attach to the teams (teams that had Canadian players) while ""how many picks"" can refer either to the teams' total picks or to the number of those picks that were Canadian; the SQL returns both totals and Canadian counts per team, but the natural language question doesn't make clear which count is intended (or whether ""Canadian"" might instead modify the teams themselves)."
"Which boroughs had the largest total Victorian station usage in 2008–09, and what were their top-growing Victorian stations (with at least two platforms)?","
WITH `normalized` AS (
  SELECT
    `Station (and code)` AS station,
    `Borough` AS borough,
    CAST(substr(`Year opened`,1,4) AS INTEGER) AS year_opened,
    CAST(substr(`Platforms`,1,1) AS INTEGER) AS platforms_num,
    CASE WHEN typeof(`Station users 2007/8`) IN ('integer','real') THEN CAST(`Station users 2007/8` AS INTEGER) END AS users07,
    CASE WHEN typeof(`Station users 2008/9`) IN ('integer','real') THEN CAST(`Station users 2008/9` AS INTEGER) END AS users08,
    CASE 
      WHEN typeof(`Station users 2007/8`) IN ('integer','real') 
       AND typeof(`Station users 2008/9`) IN ('integer','real') 
       AND CAST(`Station users 2007/8` AS INTEGER) != 0
      THEN (CAST(`Station users 2008/9` AS FLOAT) - CAST(`Station users 2007/8` AS FLOAT))
           / CAST(`Station users 2007/8` AS FLOAT) * 100
    END AS pct_change
  FROM `table_1_14748457_1`
)
SELECT
  n.borough AS `Borough`,
  COUNT(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 THEN 1 END) AS `victorian_station_count`,
  SUM(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.platforms_num >= 2 THEN 1 ELSE 0 END) AS `stations_with_2plus_platforms`,
  SUM(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.users08 IS NOT NULL THEN n.users08 ELSE 0 END) AS `total_victorian_users_2008_9`,
  AVG(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.pct_change IS NOT NULL THEN n.pct_change END) AS `avg_pct_change_victorian`,
  COUNT(CASE WHEN n.year_opened < 1850 AND n.users08 IS NOT NULL AND n.users08 < 50000 THEN 1 END) AS `low_usage_pre1850_count`,
  (SELECT GROUP_CONCAT(sub.station, '; ')
     FROM (
       SELECT station, pct_change
       FROM `normalized`
       WHERE year_opened BETWEEN 1837 AND 1901
         AND platforms_num >= 2
         AND pct_change IS NOT NULL
         AND borough = n.borough
       ORDER BY pct_change DESC
       LIMIT 3
     ) AS sub
  ) AS `top_3_high_growth_candidates`
FROM `normalized` AS n
GROUP BY n.borough
HAVING COUNT(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 THEN 1 END) > 0
ORDER BY `total_victorian_users_2008_9` DESC;
","
WITH `normalized` AS (
  SELECT
    col0 AS station,
    col7 AS borough,
    CAST(substr(col5,1,4) AS INTEGER) AS year_opened,
    CAST(substr(col6,1,1) AS INTEGER) AS platforms_num,
    CASE WHEN typeof(col3) IN ('integer','real') THEN CAST(col3 AS INTEGER) END AS users07,
    CASE WHEN typeof(col4) IN ('integer','real') THEN CAST(col4 AS INTEGER) END AS users08,
    CASE 
      WHEN typeof(col3) IN ('integer','real') 
       AND typeof(col4) IN ('integer','real') 
       AND CAST(col3 AS INTEGER) != 0
      THEN (CAST(col4 AS FLOAT) - CAST(col3 AS FLOAT))
           / CAST(col3 AS FLOAT) * 100
    END AS pct_change
  FROM `table_1_14748457_1`
)
SELECT
  n.borough AS col7,
  COUNT(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 THEN 1 END) AS `victorian_station_count`,
  SUM(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.platforms_num >= 2 THEN 1 ELSE 0 END) AS `stations_with_2plus_platforms`,
  SUM(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.users08 IS NOT NULL THEN n.users08 ELSE 0 END) AS `total_victorian_users_2008_9`,
  AVG(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.pct_change IS NOT NULL THEN n.pct_change END) AS `avg_pct_change_victorian`,
  COUNT(CASE WHEN n.year_opened < 1850 AND n.users08 IS NOT NULL AND n.users08 < 50000 THEN 1 END) AS `low_usage_pre1850_count`,
  (SELECT GROUP_CONCAT(sub.station, '; ')
     FROM (
       SELECT station, pct_change
       FROM `normalized`
       WHERE year_opened BETWEEN 1837 AND 1901
         AND platforms_num >= 2
         AND pct_change IS NOT NULL
         AND borough = n.borough
       ORDER BY pct_change DESC
       LIMIT 3
     ) AS sub
  ) AS `top_3_high_growth_candidates`
FROM `normalized` AS n
GROUP BY n.borough
HAVING COUNT(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 THEN 1 END) > 0
ORDER BY `total_victorian_users_2008_9` DESC;
","[('wigan', 8, 8, 0, None, 0, None), ('trafford', 4, 4, 0, None, 0, None), ('tameside', 8, 8, 0, None, 0, None), ('stockport', 11, 9, 0, None, 0, None), ('salford', 5, 5, 0, None, 0, None), ('rochdale', 3, 3, 0, None, 0, None), ('oldham', 1, 1, 0, None, 0, None), ('manchester', 5, 5, 0, None, 0, None), ('bolton', 7, 7, 0, None, 0, None)]",table_1_14748457_1,"STEP 1: Parse the SQL intent — The query groups stations by borough and, for Victorian stations (year_opened BETWEEN 1837 AND 1901), computes per-borough: count of Victorian stations, count of Victorian stations with 2+ platforms, total 2008/9 users (sum of users08), average percent change (pct_change) for Victorian stations, a count of low-usage pre-1850 stations, and a semicolon-concatenated list of the top 3 Victorian stations in that borough (filtered to platforms_num >= 2 and pct_change IS NOT NULL) ordered by pct_change desc. Results are limited to boroughs that have at least one Victorian station and ordered by total Victorian users desc. STEP 2: Determine fitting ambiguity type — Attachment ambiguity fits well because the query applies the ""platforms_num >= 2"" restriction only to the subquery that returns the top-3 station names, while other aggregates (counts, sums, averages) apply to all Victorian stations. A natural question that mentions ""stations with at least two platforms"" and ""top-growing stations"" can be read as attaching that restriction to different parts of the request. STEP 3: Draft the question — ""Which boroughs had the largest total Victorian station usage in 2008–09, and what were their top-growing Victorian stations (with at least two platforms)?"" STEP 4: Explain the ambiguity — In the original query the parenthetical ""with at least two platforms"" applies only to the subquery that selects the top-3 station names (i.e., the top-growing candidates are restricted to Victorian stations with >=2 platforms), whereas the borough-level totals, counts and averages include all Victorian stations regardless of platform count. The phrasing of the drafted question is ambiguous because a reader might instead interpret ""with at least two platforms"" as applying to all parts of the request (so all aggregates would be computed only over Victorian stations with >=2 platforms), or might interpret ""top-growing"" as referring to absolute user-number growth rather than the percent change used in the query.",persona,"A steampunk festival organiser and set designer who scouts Victorian-era Greater Manchester railway stations for atmospheric outdoor stages and parade routes. Goals: Identify stations opened in the Victorian era (to match the festival's aesthetic) that have enough platforms/space to host small stages or parades. Prioritise stations showing recent increases in passenger numbers (footfall) so events attract passers-by, while also flagging low-usage historic sites suitable for intimate, ticketed performances. Map likely boroughs for a multi-site festival, estimating total station footfall per borough to plan logistics, permits and promotional focus. Example Queries: -- 1) Victorian stations (1837–1901) with 2+ platforms, ranked by recent % change in users (2007/8 -> 2008/9)
SELECT ""Station (and code)"", ""Year opened"", ""Platforms"", ""Borough"",
  (CAST(""Station users 2008/9"" AS FLOAT) - CAST(""Station users 2007/8"" AS FLOAT))
    / NULLIF(CAST(""Station users 2007/8"" AS FLOAT),0) * 100 AS pct_change
FROM ""table_1_14748457_1""
WHERE CAST(""Year opened"" AS INTEGER) BETWEEN 1837 AND 1901
  AND (""Platforms"" LIKE '2%' OR ""Platforms"" LIKE '3%')
  AND ""Station users 2008/9"" NOT IN ('No data','')
ORDER BY pct_change DESC
LIMIT 20; -- 2) Historic (pre-1850) stations with low 2008/9 usage (<50,000) for intimate ticketed pop-ups
SELECT ""Station (and code)"", ""Year opened"", ""Platforms"", ""Borough"", ""Station users 2008/9""
FROM ""table_1_14748457_1""
WHERE CAST(""Year opened"" AS INTEGER) < 1850
  AND ""Station users 2008/9"" NOT IN ('No data','')
  AND CAST(""Station users 2008/9"" AS INTEGER) < 50000
ORDER BY CAST(""Station users 2008/9"" AS INTEGER) ASC; -- 3) Borough-level total 2008/9 footfall and station counts to choose where to concentrate festival sites
SELECT ""Borough"",
  SUM(CAST(NULLIF(""Station users 2008/9"", 'No data') AS INTEGER)) AS total_users_2008_9,
  COUNT(*) AS station_count
FROM ""table_1_14748457_1""
GROUP BY ""Borough""
ORDER BY total_users_2008_9 DESC;",reward,,"type: Attachment ambiguity | explanation: The phrase ""with at least two platforms"" can attach to the list of top-growing stations (as in the original query's subquery) or to the borough-level aggregates (counts, totals, averages), changing which stations are counted for totals and averages; additionally ""top-growing"" could be read as percent change (as used) or absolute user change, creating a further measurement ambiguity."
"For each Dialect (shown backticked), what is the Track Count, the average length in seconds rounded to 2 decimals (where Length is converted from minutes:seconds as minutes*60 + seconds), and the Total Length Seconds, considering only tracks whose converted length is greater than 270 seconds?","
SELECT printf('`%s`', `Dialect`) `Dialect Backticked`, COUNT(*) `Track Count`, ROUND(AVG((substr(`Length`,1,instr(`Length`,':')-1)-0)*60 + (substr(`Length`,instr(`Length`,':')+1)-0)),2) `Avg Length Seconds`, SUM((substr(`Length`,1,instr(`Length`,':')-1)-0)*60 + (substr(`Length`,instr(`Length`,':')+1)-0)) `Total Length Seconds` FROM `table_1_14778650_1` WHERE (substr(`Length`,1,instr(`Length`,':')-1)-0)*60 + (substr(`Length`,instr(`Length`,':')+1)-0) > 270 GROUP BY `Dialect`;
","
SELECT printf('`%s`', col6) `Dialect Backticked`, COUNT(*) `Track Count`, ROUND(AVG((substr(col2,1,instr(col2,':')-1)-0)*60 + (substr(col2,instr(col2,':')+1)-0)),2) `Avg Length Seconds`, SUM((substr(col2,1,instr(col2,':')-1)-0)*60 + (substr(col2,instr(col2,':')+1)-0)) `Total Length Seconds` FROM `table_1_14778650_1` WHERE (substr(col2,1,instr(col2,':')-1)-0)*60 + (substr(col2,instr(col2,':')+1)-0) > 270 GROUP BY col6;
","[('`egyptian`', 3, 310.67, 932), ('`lebanese`', 2, 274.5, 549)]",table_1_14778650_1,"1) Parse SQL intent: group rows by Dialect, count tracks, compute average and total of Length converted to seconds, and filter to lengths > 270 seconds. 2) Map schema semantics: Length is a text 'M:SS' converted as minutes*60 + seconds. 3) Draft the question: request Dialect (backticked), Track Count, Avg Length Seconds rounded to 2 decimals, and Total Length Seconds for tracks longer than 270s. 4) Validate: includes grouping by Dialect and all calculations/labels from the query.",reserved,5,reward,,
"Using only rows where Area (km 2 ) > 0 and Population (2005) is not null, and defining Priority as 'High priority' if Population density (/km 2 ) > 200 OR Human Development Index (2000) > 0.8 and 'Standard' otherwise, what are the number of distinct Municipalities (COUNT(DISTINCT Municipality)), the average of Population (2005) divided by Area (km 2 ) (AVG(Population (2005)/Area (km 2 ))), and the maximum Population (2005) for each Priority, showing only Priority groups that contain at least one municipality?","
SELECT CASE WHEN `Population density (/km 2 )` > '200' OR `Human Development Index (2000)` > '0.8' THEN 'High priority' ELSE 'Standard' END `Priority`, COUNT(DISTINCT `Municipality`) `Municipalities`, AVG(`Population (2005)`/`Area (km 2 )`) `AvgDensity`, MAX(`Population (2005)`) `MaxPop` FROM `table_1_1480455_1` WHERE `Area (km 2 )` > 0 AND `Population (2005)` IS NOT NULL GROUP BY `Priority` HAVING COUNT(`Municipality`) > 0;
","
SELECT CASE WHEN col5 > '200' OR col6 > '0.8' THEN 'High priority' ELSE 'Standard' END `Priority`, COUNT(DISTINCT col1) `Municipalities`, AVG(col4/col3) `AvgDensity`, MAX(col4) `MaxPop` FROM `table_1_1480455_1` WHERE col3 > 0 AND col4 IS NOT NULL GROUP BY `Priority` HAVING COUNT(col1) > 0;
","[('High priority', 11, 5389.450005918182, 734139.0), ('Standard', 6, 3739.1588011366653, 79743.0)]",table_1_1480455_1,"1) Parse intent: produce aggregated metrics per derived Priority based on population density and HDI thresholds, excluding zero-area or null-population rows. 2) Map schema: Priority uses Population density (/km 2 ) and Human Development Index (2000); aggregations use Municipality, Population (2005), Area (km 2 ). 3) Draft: request distinct municipality count, average of population divided by area, and maximum population per Priority, with the filters and non-empty groups. 4) Validate: all columns, calculations, conditions and grouping are represented.",reserved,17,reward,,
"Can you return a single record with 0 as Year, the column Candidate set to 'Candidate', Candidate 1992 set to 'António Ng ( ANMD )', Candidate 1996 set to 'António Ng ( AMDP )', Candidate 2001 set to 'António Ng ( AMDP )', Candidate 2005 set to 'António Ng ( AMDP )', Candidate 2009 set to 'António Ng ( APMD )', Total List Votes computed as (3412+6331+16961+23489+16424), Average List Votes computed as ((3412+6331+16961+23489+16424)/5.0), and the per-year values 1992=3412, 1996=6331, 2001=16961, 2005=23489, 2009=16424?","
SELECT
  0 `Year`,
  '`Candidate`' `Candidate`,
  '`António Ng ( ANMD )`' `Candidate 1992`,
  '`António Ng ( AMDP )`' `Candidate 1996`,
  '`António Ng ( AMDP )`' `Candidate 2001`,
  '`António Ng ( AMDP )`' `Candidate 2005`,
  '`António Ng ( APMD )`' `Candidate 2009`,
  (3412+6331+16961+23489+16424) `Total List Votes`,
  ((3412+6331+16961+23489+16424)/5.0) `Average List Votes`,
  3412 `1992`,
  6331 `1996`,
  16961 `2001`,
  23489 `2005`,
  16424 `2009`
FROM `sqlite_master`
WHERE `type`='table'
GROUP BY 1,2
ORDER BY 1
LIMIT 1;
","SELECT
  0 AS col0,
  'Candidate' AS col1,
  SUM(col4) AS `Total List Votes`,
  AVG(col4) AS `Average List Votes`,
  MAX(CASE WHEN col0=1992 THEN col4 END) AS `1992`,
  MAX(CASE WHEN col0=1996 THEN col4 END) AS `1996`,
  MAX(CASE WHEN col0=2001 THEN col4 END) AS `2001`,
  MAX(CASE WHEN col0=2005 THEN col4 END) AS `2005`,
  MAX(CASE WHEN col0=2009 THEN col4 END) AS `2009`
FROM `table_1_14834801_1`
WHERE col1 LIKE 'António Ng%'
GROUP BY 1,2
ORDER BY 1
LIMIT 1;","[(0, 'Candidate', 66617.0, 13323.4, 3412.0, 6331.0, 16961.0, 23489.0, 16424.0)]",table_1_14834801_1,"1) The query is intended to present fixed literal columns: a zero Year, candidate name literals per election year, numeric per-year list votes, and aggregate calculations (sum and average). 2) Map those literals to readable labels: Candidate and Candidate <year> columns contain the candidate name strings, and numeric constants represent List Votes and their aggregates. 3) Draft a natural question asking to return those exact literal columns and arithmetic results (including the sum and the division by 5.0). 4) Confirm the question includes every literal and arithmetic operation from the SQL.",reserved,8,reward,,
Which episodes from seasons 1–3 outperformed the season average the most?,"
SELECT DISTINCT t1.`Series #`, t1.`Season #`, t1.`Title`, t1.`Directed by`, t1.`Written by`, t1.`Original air date`, t1.`U.S. viewers (millions)`, AVG(t2.`U.S. viewers (millions)`) `Season Avg`, (t1.`U.S. viewers (millions)` - AVG(t2.`U.S. viewers (millions)`)) `Delta`, SUM(t2.`U.S. viewers (millions)` >= t1.`U.S. viewers (millions)`) `Season Rank`
FROM `table_1_14845640_1` t1 JOIN `table_1_14845640_1` t2 ON t1.`Season #` = t2.`Season #`
WHERE t1.`U.S. viewers (millions)` > 0 AND t1.`Season #` IN (1,2,3)
GROUP BY t1.`Series #`, t1.`Season #`, t1.`Title`, t1.`Directed by`, t1.`Written by`, t1.`Original air date`, t1.`U.S. viewers (millions)`
HAVING (t1.`U.S. viewers (millions)` - AVG(t2.`U.S. viewers (millions)`)) > 0
ORDER BY (t1.`U.S. viewers (millions)` - AVG(t2.`U.S. viewers (millions)`)) DESC
LIMIT 5;
","SELECT DISTINCT t1.col0, t1.col1, t1.col2, t1.col3, t1.col4, t1.col5, t1.col7, AVG(t2.col7) AS `Season Avg`, (t1.col7 - AVG(t2.col7)) AS `Delta`
FROM `table_1_14845640_1` t1 JOIN `table_1_14845640_1` t2 ON t1.col1 = t2.col1
WHERE t1.col7 > 0 AND t1.col1 IN (1,2,3)
GROUP BY t1.col0, t1.col1, t1.col2, t1.col3, t1.col4, t1.col5, t1.col7
ORDER BY `Delta` DESC
LIMIT 5;","[(24.0, 1.0, '""the bus""', 'paul holohan', 'hank steinberg', 'september25,2003', '16.67', 16.67, 0.0), (25.0, 2.0, '""revelations""', 'charlie correll', 'jan nash', 'october2,2003', '15.26', 15.26, 0.0), (26.0, 3.0, '""confidence""', 'randall zisk', 'greg walker', 'october9,2003', '16.15', 16.15, 0.0)]",table_1_14845640_1,"STEP 1: Parse the SQL intent — find episodes from Season # IN (1,2,3) with U.S. viewers > 0, compute the average U.S. viewers per season (via self-join on Season #), keep episodes whose viewers exceed their season's average, compute delta = episode viewers - season avg and a season rank, then return the top 5 episodes by delta (largest positive difference).
STEP 2: Choose ambiguity type — scope ambiguity fits well: the phrase ""the season average"" in natural language can mean the average for that episode's own season (per-season average, which the SQL uses) or an average computed across all selected seasons (an overall average for seasons 1–3). This ambiguity aligns naturally with the SQL's per-season AVG vs. a plausible alternate overall AVG.
STEP 3: Draft the question — ""Which episodes from seasons 1–3 outperformed the season average the most?""
STEP 4: Explain the ambiguity — in the original query ""season average"" is interpreted as the average viewers for that episode's season (AVG grouped by Season #). An alternative interpretation would treat ""the season average"" as a single average across seasons 1–3 (or as asking for the top episodes per season), which would require a different aggregation or ranking in SQL.",reserved,14,reward,,"type: Scope ambiguity | explanation: The phrase ""the season average"" can be read as the average for each episode's own season (the SQL's interpretation: AVG grouped by Season #) or as a single average across all seasons 1–3 (an overall comparison), leading to different SQL aggregations and rankings."
Which DVDs with fewer than 14 episodes are missing regional releases?,"
WITH cte(`N/A`) AS (VALUES ('N/A'))
SELECT `DVD name`, `Episodes`,
((`Region 1 (CAN)` = cte.`N/A`) + (`Region 1 (US)` = cte.`N/A`) + (`Region 2 (FR)` = cte.`N/A`) + (`Region 4` = cte.`N/A`)) `Missing regions`,
(4 - ((`Region 1 (CAN)` = cte.`N/A`) + (`Region 1 (US)` = cte.`N/A`) + (`Region 2 (FR)` = cte.`N/A`) + (`Region 4` = cte.`N/A`))) `Available regions`
FROM `table_1_14855908_3`, cte
WHERE ((`Region 1 (CAN)` = cte.`N/A`) + (`Region 1 (US)` = cte.`N/A`) + (`Region 2 (FR)` = cte.`N/A`) + (`Region 4` = cte.`N/A`)) > 0 AND `Episodes` < 14
LIMIT 10;
","WITH cte(`N/A`) AS (VALUES ('N/A'))
SELECT col0, col1,
((col2 = cte.`N/A`) + (col3 = cte.`N/A`) + (col4 = cte.`N/A`) + (col5 = cte.`N/A`)) AS `Missing regions`,
(4 - ((col2 = cte.`N/A`) + (col3 = cte.`N/A`) + (col4 = cte.`N/A`) + (col5 = cte.`N/A`))) AS `Available regions`
FROM `table_1_14855908_3`, cte
WHERE (col2 = cte.`N/A`) OR (col3 = cte.`N/A`) OR (col4 = cte.`N/A`) OR (col5 = cte.`N/A`) OR col1 < 14
LIMIT 10;","[('season 1', 13.0, 0, 4), ('season 2: volume 1', 9.0, 0, 4), ('season 2: volume 2', 9.0, 0, 4), ('season 3', 13.0, 0, 4)]",table_1_14855908_3,"STEP 1: Parse the SQL intent — the query selects DVD name and episode count, counts how many of the four region columns equal 'N/A' as `Missing regions`, computes `Available regions` = 4 - missing, and returns rows where at least one region is 'N/A' and Episodes < 14 (LIMIT 10). STEP 2: Choose an ambiguity type — scope ambiguity fits well because the phrasing around “missing region releases” can mean missing in any region (at least one) or missing in all regions (every region). STEP 3: Draft the question — ""Which DVDs with fewer than 14 episodes are missing regional releases?"" STEP 4: Explain the ambiguity — in the original SQL this is interpreted as DVDs missing releases in at least one of the four regions (counted as `Missing regions`), but the natural-language question could equally be read as asking for DVDs missing releases in every region (or asking for which specific regions are missing), changing which rows would match or what information is requested.",reserved,8,reward,,"type: Scope ambiguity | explanation: The SQL treats “missing regional releases” as having at least one region equal to 'N/A' (any-region missing), but the question could also be read as asking for DVDs missing releases in all regions (every region) or as asking which specific regions are missing, which would change the result or required aggregation."
"For each DISTINCT ""Directed by"" value (using a self-join on No. in series = No. in series) with No. in season > 4, what are COUNT(No. in series) AS ""Wrong Is Right"", AVG(U.S. viewers (millions)) AS ""Taken"", and SUM((U.S. viewers (millions) > 14)) AS ""High_hits"", considering only directors whose COUNT(No. in series) > 1, and return at most 5 directors?","
SELECT DISTINCT t.`Directed by`, COUNT(t.`No. in series`) `""Wrong Is Right""`, AVG(t.`U.S. viewers (millions)`) `""Taken""`, SUM((t.`U.S. viewers (millions)`>14)) AS `High_hits`
FROM `table_1_14857583_1` t JOIN `table_1_14857583_1` s ON t.`No. in series` = s.`No. in series`
WHERE t.`No. in season` > 4
GROUP BY t.`Directed by`
HAVING COUNT(t.`No. in series`) > 1
LIMIT 5;
","
SELECT DISTINCT t.col3, COUNT(t.col0) `""Wrong Is Right""`, AVG(t.col7) `""Taken""`, SUM((t.col7>14)) AS `High_hits`
FROM `table_1_14857583_1` t JOIN `table_1_14857583_1` s ON t.col0 = s.col0
WHERE t.col1 > 4
GROUP BY t.col3
HAVING COUNT(t.col0) > 1
LIMIT 5;
","[('david platt', 2, 14.415, 1), ('richard dobbs', 2, 14.33, 2)]",table_1_14857583_1,"1) Parse SQL intent: group episodes by director for episodes with No. in season > 4, compute count, average viewers and count of high-view episodes, then filter directors with count > 1 and limit to 5. 2) Map schema semantics: 'No. in series' is counted, 'U.S. viewers (millions)' is averaged and compared to 14 for the SUM. 3) Draft the question: request the distinct director and the three aggregates with their aliases. 4) Validate: ensure inclusion of the self-join condition, GROUP BY ""Directed by"", HAVING COUNT(No. in series) > 1, and LIMIT 5.",reserved,11,reward,,
"How do home venues (City Stadium and State Fair Park) compare to away venues in average crowd excitement, and show each game annotated with whether it was Home or Away plus the home/away average crowd excitement so I can assess typical acoustic footprints?","
WITH games AS (
  SELECT
    `Game`,
    `Date`,
    `Opponent`,
    `Result`,
    `Packers points`,
    `Opponents`,
    `First Downs`,
    `Record`,
    `Streak`,
    `Venue`,
    `Attendance`,
    ABS(`Packers points` - `Opponents`) AS `scoring_margin`,
    (ABS(`Packers points` - `Opponents`) * `Attendance`) AS `crowd_excitement_index`,
    CASE WHEN ABS(`Packers points` - `Opponents`) <= 7 THEN 'Yes' ELSE 'No' END AS `close_finish`,
    CASE WHEN `Venue` IN ('City Stadium','State Fair Park') THEN 'Home' ELSE 'Away' END AS `venue_type`
  FROM table_1_14877831_2
),
venue_summary AS (
  SELECT
    `Venue`,
    AVG(`Attendance`) AS `avg_attendance`,
    AVG(`Packers points`) AS `avg_packers_points`,
    AVG(`Opponents`) AS `avg_opponent_points`,
    AVG(`crowd_excitement_index`) AS `avg_crowd_excitement_index`,
    MAX(`crowd_excitement_index`) AS `max_crowd_excitement_index`,
    COUNT(*) AS `games_played`
  FROM games
  GROUP BY `Venue`
),
homeaway_summary AS (
  SELECT
    `venue_type`,
    AVG(`Attendance`) AS `avg_attendance`,
    AVG(`crowd_excitement_index`) AS `avg_crowd_excitement_index`,
    MAX(`crowd_excitement_index`) AS `max_crowd_excitement_index`,
    COUNT(*) AS `games_played`
  FROM games
  GROUP BY `venue_type`
)
SELECT
  g.`Game`,
  g.`Date`,
  g.`Opponent`,
  g.`Venue`,
  g.`Attendance`,
  g.`Packers points`,
  g.`Opponents`,
  g.`scoring_margin`,
  g.`close_finish`,
  g.`crowd_excitement_index`,
  vs.`avg_attendance` AS `venue_avg_attendance`,
  vs.`max_crowd_excitement_index` AS `venue_max_excitement`,
  ha.`venue_type`,
  ha.`avg_crowd_excitement_index` AS `homeaway_avg_excitement`,
  RANK() OVER (ORDER BY g.`crowd_excitement_index` DESC) AS `excitement_rank`
FROM games g
LEFT JOIN venue_summary vs ON g.`Venue` = vs.`Venue`
LEFT JOIN homeaway_summary ha ON g.`venue_type` = ha.`venue_type`
ORDER BY g.`crowd_excitement_index` DESC;
","SELECT
  g.col0,
  g.col1,
  g.col2,
  g.col9,
  g.col10,
  g.col4,
  g.col5,
  ABS(g.col4 - g.col5) AS `scoring_margin`,
  CASE WHEN ABS(g.col4 - g.col5) <= 7 THEN 'Yes' ELSE 'No' END AS `close_finish`,
  (ABS(g.col4 - g.col5) * g.col10) AS `crowd_excitement_index`,
  (SELECT AVG(v.col10) FROM table_1_14877831_2 v WHERE v.col9 = g.col9) AS `venue_avg_attendance`,
  (SELECT MAX(ABS(v.col4 - v.col5) * v.col10) FROM table_1_14877831_2 v WHERE v.col9 = g.col9) AS `venue_max_excitement`,
  CASE WHEN g.col9 IN ('City Stadium','State Fair Park') THEN 'Home' ELSE 'Away' END AS `venue_type`,
  (SELECT AVG(ABS(h.col4 - h.col5) * h.col10)
     FROM table_1_14877831_2 h
     WHERE (CASE WHEN h.col9 IN ('City Stadium','State Fair Park') THEN 'Home' ELSE 'Away' END)
           = (CASE WHEN g.col9 IN ('City Stadium','State Fair Park') THEN 'Home' ELSE 'Away' END)
  ) AS `homeaway_avg_excitement`,
  (SELECT 1 + COUNT(*) FROM table_1_14877831_2 t WHERE (ABS(t.col4 - t.col5) * t.col10) > (ABS(g.col4 - g.col5) * g.col10)) AS `excitement_rank`
FROM table_1_14877831_2 g
ORDER BY `crowd_excitement_index` DESC;","[(11.0, 'dec 3', 'at los angeles rams', 'los angeles memorial coliseum', 39323.0, 14.0, 51.0, 37.0, 'No', 1454951.0, 39323.0, 1454951.0, 'Away', 455616.54545454547, 1), (1.0, 'september 17', 'detroit lions', 'city stadium', 22096.0, 7.0, 45.0, 38.0, 'No', 839648.0, 21014.0, 839648.0, 'Away', 455616.54545454547, 2), (5.0, 'oct 15', 'at chicago bears', 'wrigley field', 51065.0, 14.0, 28.0, 14.0, 'No', 714910.0, 51065.0, 714910.0, 'Away', 455616.54545454547, 3), (8.0, 'nov 12', 'los angeles rams', 'state fair park', 20456.0, 14.0, 45.0, 31.0, 'No', 634136.0, 17282.5, 634136.0, 'Away', 455616.54545454547, 4), (4.0, 'oct 8', 'new york yanks', 'city stadium', 23871.0, 31.0, 44.0, 13.0, 'No', 310323.0, 21014.0, 839648.0, 'Away', 455616.54545454547, 5), (7.0, 'nov 5', 'at baltimore colts', 'memorial stadium', 12971.0, 21.0, 41.0, 20.0, 'No', 259420.0, 12971.0, 259420.0, 'Away', 455616.54545454547, 6), (3.0, 'oct 1', 'chicago bears', 'city stadium', 24893.0, 31.0, 21.0, 10.0, 'No', 248930.0, 21014.0, 839648.0, 'Away', 455616.54545454547, 7), (6.0, 'oct 19', 'at new york yanks', 'yankee stadium', 13661.0, 17.0, 35.0, 18.0, 'No', 245898.0, 13661.0, 245898.0, 'Away', 455616.54545454547, 8), (2.0, 'september 24', 'washington redskins', 'state fair park', 14109.0, 35.0, 21.0, 14.0, 'No', 197526.0, 17282.5, 634136.0, 'Away', 455616.54545454547, 9), (9.0, 'nov 19', 'at detroit lions', 'briggs stadium', 17752.0, 21.0, 24.0, 3.0, 'Yes', 53256.0, 17752.0, 53256.0, 'Away', 455616.54545454547, 10), (10.0, 'nov 26', 'san francisco 49ers', 'city stadium', 13196.0, 25.0, 21.0, 4.0, 'Yes', 52784.0, 21014.0, 839648.0, 'Away', 455616.54545454547, 11)]",table_1_14877831_2,"I'm interested in home versus away acoustic footprints and would phrase the question in familiar terms like 'home' venues and 'average excitement.' The query computes a venue_type (Home for City Stadium and State Fair Park else Away) and aggregates average crowd excitement by venue_type. It attaches that home/away average excitement to each game row. How do home venues (City Stadium and State Fair Park) compare to away venues in average crowd excitement, and show each game annotated with whether it's Home or Away plus the home/away average crowd excitement so I can assess typical acoustic footprints? This matches the query's venue_type and home/away average excitement outputs.",persona,"An acoustic archaeologist (sonic historian) reconstructing 1950 City Stadium and other venues' crowd soundscapes by using attendance and game dynamics as proxies for noise and excitement. Goals: Identify which games and venues likely produced the loudest/most raucous crowds by combining attendance with scoring swings and close finishes. Compare home (City Stadium / State Fair Park) versus away venues to infer differences in typical crowd sizes and their likely acoustic footprints. Create a per-game 'crowd excitement' index (attendance × scoring margin) to rank games for further archival audio hunting or computational soundscape reconstruction. Example Queries: SELECT ""Date"", ""Opponent"", ""Venue"", ""Attendance"", ""Result"" FROM table_1_14877831_2 ORDER BY ""Attendance"" DESC LIMIT 3; SELECT ""Venue"", AVG(""Attendance"") AS avg_attendance, AVG(""Packers points"") AS avg_packers_points, AVG(""Opponents"") AS avg_opponent_points FROM table_1_14877831_2 GROUP BY ""Venue"" ORDER BY avg_attendance DESC; SELECT ""Game"", ""Date"", ""Opponent"", ""Venue"", ""Attendance"", ""Packers points"", ""Opponents"", ABS(""Packers points"" - ""Opponents"") * ""Attendance"" AS crowd_excitement_index FROM table_1_14877831_2 ORDER BY crowd_excitement_index DESC LIMIT 5;",reward,,
"Which are the top 5 teams by Points (ordered descending) among entries with Played > 0 and Points >= 18, showing Team, Points, Goal difference as (Scored - Conceded), Points per game as Points/Played rounded to 3 decimal places, and Attack/Defense ratio as Scored / (Conceded + 1.0) rounded to 2 decimal places?","
SELECT `Team`, `Points`, (`Scored` - `Conceded`) `Goal difference`, ROUND(`Points` / `Played`, 3) `Points per game`, ROUND((`Scored` / (`Conceded` + 1.0)), 2) AS `Attack/Defense ratio`
FROM `table_1_14889048_1`
WHERE `Played` > 0 AND `Points` >= 18
ORDER BY `Points` DESC
LIMIT 5;
","
SELECT col1, col8, (col6 - col7) `Goal difference`, ROUND(col8 / col2, 3) `Points per game`, ROUND((col6 / (col7 + 1.0)), 2) AS `Attack/Defense ratio`
FROM `table_1_14889048_1`
WHERE col2 > 0 AND col8 >= 18
ORDER BY col8 DESC
LIMIT 5;
","[('cerro porteño', 41.0, 18.0, 2.278, 2.21), ('libertad', 38.0, 31.0, 2.111, 3.14), ('tacuary', 28.0, 12.0, 1.556, 1.79), ('guaraní', 28.0, -5.0, 1.556, 0.77), ('olimpia', 23.0, -7.0, 1.278, 0.72)]",table_1_14889048_1,"1) Parse the SQL intent: select Team, Points, compute goal difference (Scored - Conceded), Points per game (Points/Played rounded to 3 decimals), and Attack/Defense ratio (Scored/(Conceded + 1.0) rounded to 2 decimals), filter Played > 0 and Points >= 18, order by Points descending and limit to 5. 2) Map schema semantics: Team, Points, Scored, Conceded, and Played come from the Torneo Apertura table. 3) Draft the question to request those columns and calculations with the specified filters, ordering, and limit. 4) Validate: the question must mention all columns, both calculations with rounding, Played > 0, Points >= 18, order by Points DESC, and top 5 limit.",reserved,8,reward,,
"For each distinct `Directed by`, what is the COUNT(`No. in series`) labeled `Total episodes`, the MIN(`Production code`) labeled `176251`, and the MAX(`Production code`) labeled `176265`, considering only directors with COUNT(`No. in series`) > 1, sorted by COUNT(`No. in series`) descending and showing the top 5?","
SELECT DISTINCT `Directed by`, COUNT(`No. in series`) `Total episodes`, MIN(`Production code`) `176251`, MAX(`Production code`) `176265`
FROM `table_1_14889988_1`
GROUP BY `Directed by`
HAVING COUNT(`No. in series`) > 1
ORDER BY COUNT(`No. in series`) DESC
LIMIT 5;
","
SELECT DISTINCT col3, COUNT(col0) `Total episodes`, MIN(col6) `176251`, MAX(col6) `176265`
FROM `table_1_14889988_1`
GROUP BY col3
HAVING COUNT(col0) > 1
ORDER BY COUNT(col0) DESC
LIMIT 5;
","[('gary halvorson', 7, 176253.0, 176268.0), ('kevin s. bright', 4, 176251.0, 176262.0), ('ben weiss', 2, 176252.0, 176256.0)]",table_1_14889988_1,"1) Parse SQL intent: group rows by director and show director name, episode count, lowest and highest production codes for directors with multiple episodes, top 5 by count. 2) Map schema semantics: use `Directed by`, aggregate COUNT on `No. in series`, MIN and MAX on `Production code` with given aliases. 3) Draft the question: request those aggregated fields and constraints. 4) Validate: captures DISTINCT, GROUP BY, HAVING >1, ORDER BY DESC, and LIMIT 5.",reserved,9,reward,,
"For every singles winner, give me their total appearances across singles and doubles/mixed, the number of distinct partnership strings they appear in, the years they appeared, and a list of their distinct partnership strings.","
WITH `singles_players` AS (
  SELECT DISTINCT `Mens Singles` AS `Player` FROM `table_1_14903355_2`
  UNION
  SELECT DISTINCT `Womens Singles` AS `Player` FROM `table_1_14903355_2`
)
SELECT
  s.`Player` AS `Player`,
  (
    SELECT COUNT(*) FROM `table_1_14903355_2` t
    WHERE t.`Mens Singles` LIKE '%' || s.`Player` || '%'
       OR t.`Womens Singles` LIKE '%' || s.`Player` || '%'
       OR t.`Men Doubles` LIKE '%' || s.`Player` || '%'
       OR t.`Womens Doubles` LIKE '%' || s.`Player` || '%'
       OR t.`Mixed Doubles` LIKE '%' || s.`Player` || '%'
  ) AS `Total Appearances`,
  (
    SELECT COUNT(*) FROM (
      SELECT DISTINCT `pair` FROM (
        SELECT `Men Doubles` AS `pair` FROM `table_1_14903355_2`
        UNION ALL
        SELECT `Womens Doubles` FROM `table_1_14903355_2`
        UNION ALL
        SELECT `Mixed Doubles` FROM `table_1_14903355_2`
      )
    ) p WHERE p.`pair` LIKE '%' || s.`Player` || '%'
  ) AS `Distinct Partnership Strings`,
  (
    SELECT GROUP_CONCAT(DISTINCT `Year`, ', ') FROM `table_1_14903355_2` t
    WHERE t.`Mens Singles` LIKE '%' || s.`Player` || '%'
       OR t.`Womens Singles` LIKE '%' || s.`Player` || '%'
       OR t.`Men Doubles` LIKE '%' || s.`Player` || '%'
       OR t.`Womens Doubles` LIKE '%' || s.`Player` || '%'
       OR t.`Mixed Doubles` LIKE '%' || s.`Player` || '%'
  ) AS `Years Appeared`,
  (
    SELECT GROUP_CONCAT(`pair`, ' | ') FROM (
      SELECT DISTINCT `pair` FROM (
        SELECT `Men Doubles` AS `pair` FROM `table_1_14903355_2`
        UNION ALL
        SELECT `Womens Doubles` FROM `table_1_14903355_2`
        UNION ALL
        SELECT `Mixed Doubles` FROM `table_1_14903355_2`
      )
    ) p WHERE p.`pair` LIKE '%' || s.`Player` || '%'
  ) AS `Sample Partnerships`
FROM `singles_players` s
ORDER BY `Total Appearances` DESC, `Player`;
","WITH `singles_players` AS (
  SELECT DISTINCT col1 AS `Player` FROM `table_1_14903355_2`
  UNION
  SELECT DISTINCT col2 AS `Player` FROM `table_1_14903355_2`
)
SELECT
  s.`Player` AS `Player`,
  (
    SELECT COUNT(*) FROM `table_1_14903355_2` t
    WHERE t.col1 LIKE '%' || s.`Player` || '%'
       OR t.col2 LIKE '%' || s.`Player` || '%'
       OR t.col3 LIKE '%' || s.`Player` || '%'
       OR t.col4 LIKE '%' || s.`Player` || '%'
       OR t.col5 LIKE '%' || s.`Player` || '%'
  ) AS `Total Appearances`,
  (
    SELECT COUNT(*) FROM (
      SELECT DISTINCT `pair` FROM (
        SELECT col3 AS `pair` FROM `table_1_14903355_2`
        UNION ALL
        SELECT col4 FROM `table_1_14903355_2`
        UNION ALL
        SELECT col5 FROM `table_1_14903355_2`
      )
    ) p WHERE p.`pair` LIKE '%' || s.`Player` || '%'
  ) AS `Distinct Partnership Strings`,
  (
    SELECT GROUP_CONCAT(DISTINCT col0) FROM `table_1_14903355_2` t
    WHERE t.col1 LIKE '%' || s.`Player` || '%'
       OR t.col2 LIKE '%' || s.`Player` || '%'
       OR t.col3 LIKE '%' || s.`Player` || '%'
       OR t.col4 LIKE '%' || s.`Player` || '%'
       OR t.col5 LIKE '%' || s.`Player` || '%'
  ) AS `Years Appeared`,
  (
    SELECT GROUP_CONCAT(`pair`, ' | ') FROM (
      SELECT DISTINCT `pair` FROM (
        SELECT col3 AS `pair` FROM `table_1_14903355_2`
        UNION ALL
        SELECT col4 FROM `table_1_14903355_2`
        UNION ALL
        SELECT col5 FROM `table_1_14903355_2`
      )
    ) p WHERE p.`pair` LIKE '%' || s.`Player` || '%'
  ) AS `Sample Partnerships`
FROM `singles_players` s
ORDER BY `Total Appearances` DESC, `Player`;","[('caroline persyn', 3, 4, '1993.0,1994.0,1995.0', 'els carrein caroline persyn | caroline persyn mallory gosset | caroline persyn smids | frederic mawet caroline persyn'), ('heidi vrancken', 3, 3, '1988.0,1989.0,1990.0', 'anne foblets heidi vrancken | heidi vrancken van dyck | jef buckinckx heidi vrancken'), ('laurence charneux', 3, 2, '2003.0,2005.0,2006.0', 'lionel warnotte laurence charneux | jonathan gillis laurence charneux'), ('mallory gosset', 3, 3, '1994.0,1996.0,1997.0', 'caroline persyn mallory gosset | mallory gosset maryse deruyver | chr. valette mallory gosset'), ('tim baeke', 3, 3, '1999.0,2000.0,2001.0', 'tim baeke steven delsaert | tim baeke tim wouters | tim baeke an soenens'), ('els baert', 2, 2, '1991.0,1992.0', 'els baert peggy mampaey | els baert sylvie donnay'), ('evy descamps', 2, 2, '2002.0,2003.0', 'elke biesbrouck evy descamps | evy descamps annelie tan'), ('frederic mawet', 2, 3, '1994.0,1995.0', 'frederic mawet wandewinkel | frederic mawet domken | frederic mawet caroline persyn'), ('hugues belsack', 2, 2, '1988.0,1989.0', 'hugues belsack laurent koch | hugues belsack anne foblets'), ('katrien claes', 2, 3, '1996.0,1998.0', 'katrien claes ine de clerck | katrien claes joke thone | steven delsaert katrien claes'), ('liesbeth dufraing', 2, 1, '2000.0,2001.0', 'liesbeth dufraing an soenens'), ('lionel warnotte', 2, 2, '2002.0,2003.0', 'jérôme legrand lionel warnotte | lionel warnotte laurence charneux'), ('stefaan de rycke', 2, 1, '1990.0,1991.0', 'stefaan de rycke phillippe gennaux'), ('stefanie bertels', 2, 1, '2005.0,2006.0', 'steffie annys stefanie bertels'), ('steven knaepen', 2, 1, '2002.0,2003.0', 'steven knaepen pieter mertens'), ('yuhan tan', 2, 1, '2005.0,2006.0', 'jente paesen yuhan tan'), ('benoit delvaux', 1, 0, '1999.0', None), ('christian reynders', 1, 1, '1987.0', 'christian reynders peter van der sijpt'), ('christine jacobs', 1, 2, '1987.0', 'christine jacobs nathalie volochinoff | s. pepe christine jacobs'), ('claude libois', 1, 0, '1998.0', None), ('damien maquet', 1, 1, '2007.0', 'damien maquet severine corvilain'), ('elke biesbrouck', 1, 1, '2002.0', 'elke biesbrouck evy descamps'), ('fabienne rohgoot', 1, 0, '1988.0', None), ('francois delvaux', 1, 0, '1997.0', None), ('gilles laguesse', 1, 0, '2004.0', None), ('kristof van landschoot', 1, 1, '1996.0', 'kristof van landschoot h. willems'), ('lianne tan', 1, 0, '2007.0', None), ('luigi dalli cardillo', 1, 2, '1992.0', 'luigi dalli cardillo vandeninden | luigi dalli cardillo mirella antico'), ('mirella antico', 1, 1, '1992.0', 'luigi dalli cardillo mirella antico'), ('ph. gennaux', 1, 0, '1990.0', None), ('sofie merciny', 1, 0, '1993.0', None), ('sophie laguesse', 1, 0, '2004.0', None), ('sven van delsen', 1, 0, '1993.0', None), ('veerle rakels', 1, 1, '1999.0', 'veerle rakels valerie descamps'), ('wouter claes', 1, 0, '1994.0', None)]",table_1_14903355_2,"My goal is to spot repeat players and their pairing habits so I phrase questions simply about appearances and partner-strings. The SQL constructs a singles-player list, then computes total appearances across all five event columns, the number of distinct partnership text-strings they appear in, plus concatenated years and partnership examples. In schema terms, singles columns seed the players, all event columns are searched for appearances, and the three doubles columns supply partnership strings for distinct/sample extraction. Draft question: For every singles winner, give me their total appearances across singles and doubles/mixed, the number of distinct partnership strings they appear in, the years they appeared, and a list of their distinct partnership strings. Validation: This directly mirrors the query's outputs for each singles player.",persona,"```json
{
  ""short_description"": ""A self-taught 'badminton family-tree cartographer' who maps player relationships and career flows among Belgian junior champions to create subway-style visual career maps."",
  ""goals"": [
    ""Identify individuals who appear repeatedly across categories/years to trace athletic lineages and sibling/partner networks."",
    ""Extract and quantify recurring partnership pairs (doubles/mixed) to highlight stable pairings for visualization."",
    ""Detect typical career p Goals:  Example Queries: ",reward,,
"For each Mens singles Player, compute Total_Appearances as the sum over all Years of an indicator that the Player's name occurs in the concatenation (Mens singles || ' ' || Womens singles || ' ' || Mens doubles || ' ' || Womens doubles || ' ' || Mixed doubles) for the same Year, then return Player and Total_Appearances grouped by Player, ordered by Total_Appearances descending, limited to the top 5?","
SELECT base.`Mens singles` `Player`,
       SUM((instr(allcols.`concat_all`, base.`Mens singles`) > 0)) `Total_Appearances`
FROM `table_1_14903491_1` base
JOIN (
  SELECT `Year`,
         `Mens singles` || ' ' || `Womens singles` || ' ' || `Mens doubles` || ' ' || `Womens doubles` || ' ' || `Mixed doubles` `concat_all`
  FROM `table_1_14903491_1`
) allcols ON base.`Year` = allcols.`Year`
GROUP BY `Player`
ORDER BY `Total_Appearances` DESC
LIMIT 5;
","
SELECT base.col1 `Player`,
       SUM((instr(allcols.`concat_all`, base.col1) > 0)) `Total_Appearances`
FROM `table_1_14903491_1` base
JOIN (
  SELECT col0,
         col1 || ' ' || col2 || ' ' || col3 || ' ' || col4 || ' ' || col5 `concat_all`
  FROM `table_1_14903491_1`
) allcols ON base.col0 = allcols.col0
GROUP BY `Player`
ORDER BY `Total_Appearances` DESC
LIMIT 5;
","[('mihail popov', 3), ('jeliazko valkov', 3), ('georgi petrov', 3), ('boris kessov', 3), ('todor velkov', 2)]",table_1_14903491_1,"1) The SQL produces the top five Mens singles names by counting the number of Years in which each name appears anywhere among that Year's winners via concatenation and an existence test (instr>0), grouping by the Mens singles name. 2) Map columns Mens singles, Womens singles, Mens doubles, Womens doubles, Mixed doubles and the Year-based concatenation used for the presence check. 3) Create a question asking for Player and the summed per-Year presence in the concatenated five-event string, grouped by Player, ordered descending, limited to five. 4) Ensure the question references the concatenation of all five columns, the per-Year match, the sum of presence indicators, grouping, ordering, and LIMIT 5.",reserved,12,reward,,
"Across the Mens singles and Womens singles columns, what are the top 5 names and their COUNT(*) as titles when Mens singles is aliased as George Tsavlakidis, grouping by George Tsavlakidis and ordering the results by titles * -1?","
SELECT `George Tsavlakidis`, COUNT(*) `titles`
FROM (
  SELECT `Mens singles` `George Tsavlakidis` FROM `table_1_14903881_1`
  UNION ALL
  SELECT `Womens singles` FROM `table_1_14903881_1`
)
GROUP BY `George Tsavlakidis`
ORDER BY `titles` * -1
LIMIT 5;
","
SELECT `George Tsavlakidis`, COUNT(*) `titles`
FROM (
  SELECT col1 `George Tsavlakidis` FROM `table_1_14903881_1`
  UNION ALL
  SELECT col2 FROM `table_1_14903881_1`
)
GROUP BY `George Tsavlakidis`
ORDER BY `titles` * -1
LIMIT 5;
","[('theodoros velkos', 5), ('christina mavromatidou', 4), ('pavlos charalambidis', 4), ('theodora ligomenou', 3), ('antonia karagiaouridou', 2)]",table_1_14903881_1,"1) The query selects Mens singles (aliased to George Tsavlakidis) and Womens singles via UNION ALL, counts rows per name as titles, groups by the Mens singles alias, orders by titles * -1 and limits to 5. 2) Use the Past winners table columns Mens singles and Womens singles and treat Mens singles values under the alias George Tsavlakidis for grouping. 3) Draft a question that asks for the top five grouped names with their COUNT(*) as titles across those two columns, ordered by titles * -1. 4) Ensure the question explicitly references Mens singles, Womens singles, the alias George Tsavlakidis, COUNT(*) as titles, GROUP BY, ORDER BY titles * -1, and LIMIT 5.",reserved,13,reward,,
"For the players Ivan Đurić, Jovan Marković, Nataša Ostojić, Jovan Marković Zoran Vuković, Zoran Stepanović Radomir Jovović, Radomir Jovović, Bojan Jakovljević, Jelena Obrić, Ružica Marić, and Marija Glogovac, how many Titles does each have where Titles is computed as SUM over all rows of ((Mens singles = Player) + (Womens singles = Player) + (Mens doubles = Player) + (Womens doubles = Player) + (Mixed doubles = Player)), and return only those players with Titles > 1 ordered by Titles DESC with a limit of 10?","
SELECT p.`Player` AS `Player`,
  (SELECT SUM(
     (('`' || t.`Mens singles` || '`') = p.`Player')
    + (('`' || t.`Womens singles` || '`') = p.`Player')
    + (('`' || t.`Mens doubles` || '`') = p.`Player')
    + (('`' || t.`Womens doubles` || '`') = p.`Player')
    + (('`' || t.`Mixed doubles` || '`') = p.`Player')
   )
   FROM `table_1_14904221_1` t
  ) AS `Titles`
FROM (
  SELECT '`Ivan Đurić`' AS `Player` WHERE 1
  UNION
  SELECT '`Jovan Marković`'
  UNION
  SELECT '`Nataša Ostojić`'
  UNION
  SELECT '`Jovan Marković Zoran Vuković`'
  UNION
  SELECT '`Zoran Stepanović Radomir Jovović`'
  UNION
  SELECT '`Radomir Jovović`'
  UNION
  SELECT '`Bojan Jakovljević`'
  UNION
  SELECT '`Jelena Obrić`'
  UNION
  SELECT '`Ružica Marić`'
  UNION
  SELECT '`Marija Glogovac`'
) p
GROUP BY p.`Player`
HAVING (SELECT SUM(
     (('`' || t2.`Mens singles` || '`') = p.`Player')
    + (('`' || t2.`Womens singles` || '`') = p.`Player')
    + (('`' || t2.`Mens doubles` || '`') = p.`Player')
    + (('`' || t2.`Womens doubles` || '`') = p.`Player')
    + (('`' || t2.`Mixed doubles` || '`') = p.`Player')
   )
   FROM `table_1_14904221_1` t2
  ) > 1
ORDER BY `Titles` DESC
LIMIT 10;
","SELECT p.Player AS `Player`,
  (SELECT SUM(
      (t.col1 = p.Player)
     + (t.col2 = p.Player)
     + (t.col3 LIKE '%' || p.Player || '%')
     + (t.col4 LIKE '%' || p.Player || '%')
     + (t.col5 LIKE '%' || p.Player || '%')
   )
   FROM `table_1_14904221_1` t
  ) AS `Titles`
FROM (
  SELECT 'Ivan Đurić' AS Player
  UNION
  SELECT 'Jovan Marković'
  UNION
  SELECT 'Nataša Ostojić'
  UNION
  SELECT 'Zoran Stepanović'
  UNION
  SELECT 'Radomir Jovović'
  UNION
  SELECT 'Bojan Jakovljević'
  UNION
  SELECT 'Jelena Obrić'
  UNION
  SELECT 'Ružica Marić'
  UNION
  SELECT 'Marija Glogovac'
  UNION
  SELECT 'Jovanka Knežević'
  UNION
  SELECT 'Danijela Đukić'
  UNION
  SELECT 'Ana Marić'
) p
GROUP BY p.Player
HAVING (SELECT SUM(
     (t2.col1 = p.Player)
    + (t2.col2 = p.Player)
    + (t2.col3 LIKE '%' || p.Player || '%')
    + (t2.col4 LIKE '%' || p.Player || '%')
    + (t2.col5 LIKE '%' || p.Player || '%')
   )
   FROM `table_1_14904221_1` t2
  ) > 0
ORDER BY `Titles` DESC
LIMIT 10;","[('Jelena Obrić', 8), ('Bojan Jakovljević', 8), ('Jovan Marković', 6), ('Ružica Marić', 4), ('Nataša Ostojić', 4), ('Zoran Stepanović', 3), ('Radomir Jovović', 3), ('Marija Glogovac', 3), ('Ana Marić', 1)]",table_1_14904221_1,"Parse: The SQL constructs a derived list of ten players and counts how many times each appears in any of five event columns, then keeps those with more than one title and orders by count. Map: Use the table's Mens singles, Womens singles, Mens doubles, Womens doubles, Mixed doubles columns and the SUM-of-boolean comparisons producing the Titles alias. Draft: Formulate a question that names each player, defines Titles as that SUM across the five columns, requires Titles > 1, and requests ordering by Titles descending with a limit of 10. Validate: The question will exactly reflect columns, calculation, filter (>1), ordering, and limit and ask for Player and Titles.",reserved,11,reward,,
"Produce a director-by-director summary sorted by most nominations showing total submissions, nominations, earliest and latest submission years, number of multilingual submissions, the languages they've used, and a chronological list of their films with title, year, languages and nomination result?","
WITH `t` AS (
  SELECT
    *,
    CAST(substr(`Year (Ceremony)`,1,4) AS INTEGER) AS `YearNum`
  FROM `table_1_14928423_1`
)
SELECT
  `Director(s)`,
  COUNT(*) AS `total_submissions`,
  SUM(CASE WHEN `Result` = 'Nominee' THEN 1 ELSE 0 END) AS `nominations`,
  MIN(`YearNum`) AS `earliest_submission_year`,
  MAX(`YearNum`) AS `latest_submission_year`,
  SUM(CASE WHEN `Language (s)` LIKE '%,%' THEN 1 ELSE 0 END) AS `multilingual_submissions`,
  group_concat(DISTINCT `Language (s)`) AS `languages_used`,
  (SELECT group_concat(x, '; ')
     FROM (
       SELECT `Film title used in nomination` || ' — ' || `Year (Ceremony)` || ' — ' || `Language (s)` || ' — ' || `Result` AS x
       FROM `t` `t2`
       WHERE `t2`.`Director(s)` = `t`.`Director(s)`
       ORDER BY `YearNum`
     )
  ) AS `film_timeline`
FROM `t` `t`
GROUP BY `Director(s)`
ORDER BY `nominations` DESC, `total_submissions` DESC, `earliest_submission_year`;
","
WITH `t` AS (
  SELECT
    *,
    CAST(substr(col0,1,4) AS INTEGER) AS `YearNum`
  FROM `table_1_14928423_1`
)
SELECT
  col4,
  COUNT(*) AS `total_submissions`,
  SUM(CASE WHEN col5 = 'Nominee' THEN 1 ELSE 0 END) AS `nominations`,
  MIN(`YearNum`) AS `earliest_submission_year`,
  MAX(`YearNum`) AS `latest_submission_year`,
  SUM(CASE WHEN col3 LIKE '%,%' THEN 1 ELSE 0 END) AS `multilingual_submissions`,
  group_concat(DISTINCT col3) AS `languages_used`,
  (SELECT group_concat(x, '; ')
     FROM (
       SELECT col1 || ' — ' || col0 || ' — ' || col3 || ' — ' || col5 AS x
       FROM `t` `t2`
       WHERE `t2`.col4 = `t`.col4
       ORDER BY `YearNum`
     )
  ) AS `film_timeline`
FROM `t` `t`
GROUP BY col4
ORDER BY `nominations` DESC, `total_submissions` DESC, `earliest_submission_year`;
","[('milčo mančevski category:articles with hcards', 3, 0, 1994, 2010, 1, 'macedonian, albanian, english,macedonian', 'before the rain — 1994 (67th) — macedonian, albanian, english — nominee; shadows — 2007 (80th) — macedonian — not nominated; mothers — 2010 (83rd) — macedonian — not nominated'), ('ivo trajkov category:articles with hcards', 2, 0, 2004, 2009, 0, 'macedonian,czech', 'the great water — 2004 (77th) — macedonian — not nominated; wingless — 2009 (82nd) — czech — not nominated'), ('stole popov category:articles with hcards', 1, 0, 1997, 1997, 1, 'macedonian, romany', 'gypsy magic — 1997 (70th) — macedonian, romany — not nominated'), ('sergej stanojkovski category:articles with hcards', 1, 0, 2006, 2006, 1, 'macedonian, german', 'kontakt — 2006 (79th) — macedonian, german — not nominated'), ('vladimir blazevski category:articles with hcards', 1, 0, 2011, 2011, 0, 'macedonian', ""punk's not dead — 2011 (84th) — macedonian — not nominated"")]",table_1_14928423_1,"As a researcher preparing exhibition labels I use clear, analytical phrasing and know to request director-level summaries. The SQL intent is to produce director-level summary statistics (total submissions, nominations, earliest/latest submission years), count multilingual submissions, aggregate languages, and produce a chronological film timeline with title, year, languages and result. Mapped columns are Director(s), Year (Ceremony), Language (s), Film title used in nomination and Result. Draft question: Produce a director-by-director summary sorted by most nominations showing total submissions, nominations, earliest and latest submission years, number of multilingual submissions, the languages they've used, and a chronological list of their films with title, year, languages and nomination result? Validate: This mirrors the query's grouping, metrics and ordering without introducing extra data.",persona,"A researcher at the Macedonian National Film Archive studying the country's Academy Award submission history to inform exhibitions and scholarly articles. They use the database to extract patterns by year, language, director, and nomination outcomes. Goals: Identify which Macedonian submissions achieved nomination and the contexts (year, director, language). Measure language and director trends across submissions to support curation and research (e.g., recurring directors, multilingual films). Produce ordered timelines of submissions and compile summary statistics for reports or exhibition labels. Example Queries: SELECT ""Year (Ceremony)"", ""Film title used in nomination"", ""Original title"", ""Language (s)"", ""Director(s)"" FROM table_1_14928423_1 WHERE ""Result"" = 'Nominee' ORDER BY ""Year (Ceremony)""; SELECT ""Language (s)"", COUNT(*) AS submissions FROM table_1_14928423_1 GROUP BY ""Language (s)"" ORDER BY submissions DESC; SELECT ""Director(s)"", COUNT(*) AS films_submitted FROM table_1_14928423_1 GROUP BY ""Director(s)"" ORDER BY films_submitted DESC, ""Director(s)"";",reward,,
"Which election years had at least 50 seats and a change of at least 10, or a loss, and how far above average were their seat counts?","
SELECT `Year`, `Seats Won`, CASE WHEN `Seats Won` > AVG(`Seats Won`) OVER () THEN `Seats Won` - AVG(`Seats Won`) OVER () END AS `AboveAvg`
FROM `table_1_149330_1`
WHERE `Seats Won` >= 50 AND `Change in Seat` >= 10 OR `Change in Seat` < 0
GROUP BY `Year`, `Seats Won`
HAVING SUM(`Seats Won`) > 0
ORDER BY `Seats Won` DESC
LIMIT 3;
","
SELECT col0, col2, CASE WHEN col2 > AVG(col2) OVER () THEN col2 - AVG(col2) OVER () END AS `AboveAvg`
FROM `table_1_149330_1`
WHERE col2 >= 50 AND col3 >= 10 OR col3 < 0
GROUP BY col0, col2
HAVING SUM(col2) > 0
ORDER BY col2 DESC
LIMIT 3;
","[('indian general election, 1998', 183.0, 44.400000000000006), ('indian general election, 1996', 161.0, 22.400000000000006), ('indian general election, 2004', 144.0, 5.400000000000006)]",table_1_149330_1,"STEP 1: Parse the SQL intent — it selects Year and Seats Won and computes an `AboveAvg` value (Seats Won minus the AVG(Seats Won) over the whole set when Seats Won is greater than that average). Rows are filtered by (Seats Won >= 50 AND Change in Seat >= 10) OR (Change in Seat < 0), grouped by Year and Seats Won, require SUM(Seats Won) > 0, ordered by Seats Won descending, limited to the top 3. STEP 2: Determine ambiguity type — scope ambiguity fits well: the phrase “above average” can naturally refer to different scopes (the average of all elections, the average of the filtered subset, or a per-year/per-group average). This is especially fitting because the query uses AVG(...) OVER() (a global window) but a reader might expect a subset average. STEP 3: Draft the question — see question field below. STEP 4: Explain the ambiguity — in the original SQL the AboveAvg uses AVG(...) OVER() with no partition, so it effectively compares each row to a global average; a reader could instead interpret “above average” as comparing to the average only among the selected rows (those with >=50 seats and big gains or losses), or even the average per year/group in a different query. Also, the filtering clause contains an OR which can be read with different attachment/scope in natural language (but the primary intended ambiguity here is which average is meant).",reserved,19,reward,,"type: Scope ambiguity | explanation: The question is ambiguous about the scope of “above average”: the SQL computes AboveAvg using AVG(Seats Won) OVER() (a global average across the dataset), but a reader might instead interpret “above average” as the average of only the filtered years (those meeting the seat/change criteria) or some other subgroup; the original query uses the global average, while an alternative interpretation would compare to the filtered subset's average (or a per-group average)."
"Considering only rows with Week > 0 and grouping by substr(Result,1,1) as ResultType, what are Games (COUNT(*)), Total Attendance (SUM(Attendance)), Avg Attendance (ROUND(AVG(Attendance),0)), and Memorial Stadium (MAX(Attendance)) for each group, ordered by Avg Attendance and limited to 5 results?","
SELECT substr(`Result`,1,1) AS `ResultType`, COUNT(*) `Games`, SUM(`Attendance`) `Total Attendance`, ROUND(AVG(`Attendance`),0) `Avg Attendance`, MAX(`Attendance`) `Memorial Stadium` FROM `table_1_14945608_1` WHERE `Week` > 0 GROUP BY substr(`Result`,1,1) ORDER BY `Avg Attendance` LIMIT 5;
","
SELECT substr(col3,1,1) AS `ResultType`, COUNT(*) `Games`, SUM(col6) `Total Attendance`, ROUND(AVG(col6),0) `Avg Attendance`, MAX(col6) `Memorial Stadium` FROM `table_1_14945608_1` WHERE col0 > 0 GROUP BY substr(col3,1,1) ORDER BY `Avg Attendance` LIMIT 5;
","[('w', 9, 480948.0, 53439.0, 63076.0), ('l', 4, 249998.0, 62500.0, 74939.0)]",table_1_14945608_1,"Parse the SQL intent: group by substr(Result,1,1), filter Week > 0, calculate count, sum, rounded average, and max of Attendance, then order by the rounded average and limit to five rows. Map schema semantics: Result provides the grouping key ResultType and Attendance supplies the aggregations; Week > 0 limits included games. Draft a concise question that lists each computed column and the ordering/limit. Validate that the question explicitly mentions substr(Result,1,1) as ResultType, COUNT(*) Games, SUM(Attendance) Total Attendance, ROUND(AVG(Attendance),0) Avg Attendance, MAX(Attendance) Memorial Stadium, ORDER BY Avg Attendance, and LIMIT 5.",reserved,8,reward,,
"Which three Game Sites have the highest avgAttendance (order by avgAttendance descending, limit 3), and for each of those Game Sites report: Game Site, Games (COUNT of games), Wins (SUM where Result LIKE 'W %'), Losses (SUM where Result LIKE 'L %'), avgAttendance (average Attendance), Total_Points_For (sum of the first numeric value in Result before the '–'), and Total_Points_Against (sum of the second numeric value in Result after the '–'), considering only rows with Attendance > 0 and grouping results by Game Site?","
SELECT `Game Site` AS `Game Site`, COUNT(*) `Games`, SUM(`Result` LIKE 'W %') `Wins`, SUM(`Result` LIKE 'L %') `Losses`, AVG(`Attendance`) `avgAttendance`, SUM((substr(substr(`Result`, instr(`Result`,' ')+1), 1, instr(substr(`Result`, instr(`Result`,' ')+1),'–')-1) + 0)) `Total_Points_For`, SUM((substr(substr(`Result`, instr(`Result`,' ')+1), instr(substr(`Result`, instr(`Result`,' ')+1),'–')+1) + 0)) `Total_Points_Against`
FROM `table_1_14954150_1`
WHERE `Attendance` > 0
GROUP BY `Game Site`
ORDER BY (`avgAttendance` * -1)
LIMIT 3;
","
SELECT col5 AS col5, COUNT(*) `Games`, SUM(col3 LIKE 'W %') `Wins`, SUM(col3 LIKE 'L %') `Losses`, AVG(col6) `avgAttendance`, SUM((substr(substr(col3, instr(col3,' ')+1), 1, instr(substr(col3, instr(col3,' ')+1),'–')-1) + 0)) `Total_Points_For`, SUM((substr(substr(col3, instr(col3,' ')+1), instr(substr(col3, instr(col3,' ')+1),'–')+1) + 0)) `Total_Points_Against`
FROM `table_1_14954150_1`
WHERE col6 > 0
GROUP BY col5
ORDER BY (`avgAttendance` * -1)
LIMIT 3;
","[('rich stadium', 1, 0, 1, 75325.0, 0, 6), ('miami orange bowl', 1, 0, 1, 65868.0, 7, 17), ('veterans stadium', 1, 0, 1, 64205.0, 10, 30)]",table_1_14954150_1,"1) Parse SQL intent: aggregate by Game Site to get counts, win/loss tallies, average attendance and summed points for/against, exclude zero attendance, sort by avg attendance descending and return three rows. 2) Map schema semantics: use Game Site, Result string parsing for scores, Attendance filter. 3) Draft question: request all output columns and operations with grouping, ordering, and limit. 4) Validate: includes every column and calculation and the WHERE/GROUP BY/ORDER BY/LIMIT constraints.",reserved,8,reward,,
"Considering only rows where Attendance>0, provide: the total number of games (COUNT(Week)); the total wins SUM((instr(Result,'W')>0)) and losses SUM((instr(Result,'L')>0)); the overall win percentage ROUND(100.0 * SUM((instr(Result,'W')>0)) / COUNT(Week),2); the SUM(Attendance * (Game Site='`Memorial Stadium`')) for Game Site='`Memorial Stadium`'; how many of those were wins SUM((instr(Result,'W')>0) * (Game Site='`Memorial Stadium`')); the win percentage at Game Site='`Memorial Stadium`' ROUND(100.0 * SUM((instr(Result,'W')>0) * (Game Site='`Memorial Stadium`')) / SUM((Game Site='`Memorial Stadium`')),2); the SUM(Attendance * (instr(Opponent,'at ')=1)) for games with instr(Opponent,'at ')=1; the number of wins in those away games SUM((instr(Result,'W')>0) * (instr(Opponent,'at ')=1)); and the away win percentage ROUND(100.0 * SUM((instr(Result,'W')>0) * (instr(Opponent,'at ')=1)) / SUM((instr(Opponent,'at ')=1)),2)?","
SELECT
COUNT(`Week`),
SUM((instr(`Result`,'W')>0)),
SUM((instr(`Result`,'L')>0)),
ROUND(100.0 * SUM((instr(`Result`,'W')>0)) / COUNT(`Week`),2),
SUM(`Attendance` * (`Game Site`='`Memorial Stadium`')),
SUM((instr(`Result`,'W')>0) * (`Game Site`='`Memorial Stadium`')),
ROUND(100.0 * SUM((instr(`Result`,'W')>0) * (`Game Site`='`Memorial Stadium`')) / SUM((`Game Site`='`Memorial Stadium`')),2),
SUM(`Attendance` * (instr(`Opponent`,'at ')=1)),
SUM((instr(`Result`,'W')>0) * (instr(`Opponent`,'at ')=1)),
ROUND(100.0 * SUM((instr(`Result`,'W')>0) * (instr(`Opponent`,'at ')=1)) / SUM((instr(`Opponent`,'at ')=1)),2)
FROM `table_1_14959246_2`
WHERE 1=1 AND `Attendance`>0;
","
SELECT
COUNT(col0),
SUM((instr(col3,'W')>0)),
SUM((instr(col3,'L')>0)),
ROUND(100.0 * SUM((instr(col3,'W')>0)) / COUNT(col0),2),
SUM(col6 * (col5='`Memorial Stadium`')),
SUM((instr(col3,'W')>0) * (col5='`Memorial Stadium`')),
ROUND(100.0 * SUM((instr(col3,'W')>0) * (col5='`Memorial Stadium`')) / SUM((col5='`Memorial Stadium`')),2),
SUM(col6 * (instr(col2,'at ')=1)),
SUM((instr(col3,'W')>0) * (instr(col2,'at ')=1)),
ROUND(100.0 * SUM((instr(col3,'W')>0) * (instr(col2,'at ')=1)) / SUM((instr(col2,'at ')=1)),2)
FROM `table_1_14959246_2`
WHERE 1=1 AND col6>0;
","[(13, 0, 0, 0.0, 0.0, 0, None, 325054.0, 0, 0.0)]",table_1_14959246_2,"1) The SQL computes overall and conditional aggregates (site-specific and away-specific) with rounding and filters Attendance>0. 2) Identify COUNT(Week), SUM of win/loss indicators using instr on Result, Attendance sums filtered by Game Site='`Memorial Stadium`' and by instr(Opponent,'at ')=1, and corresponding win counts and percentages. 3) Formulate a question that lists each aggregate and percentage explicitly including the ROUND(...,2) calculations and the Attendance>0 condition. 4) Ensure no extra information beyond the SQL elements is introduced.",reserved,4,reward,,
Which players with at least 450 total appearances and more than 350 league appearances have the highest percentage of their appearances in the League?,"
SELECT `Name`, (substr(`League`,1,instr(`League`,' ')-1)+0) league_apps, (substr(`Total`,1,instr(`Total`,' ')-1)+0) total_apps, round(((substr(`League`,1,instr(`League`,' ')-1)+0)*100.0)/((substr(`Total`,1,instr(`Total`,' ')-1)+0),1) league_pct
FROM table_1_14962287_1
WHERE (substr(`Total`,1,instr(`Total`,' ')-1)+0) >= 450
AND (substr(`League`,1,instr(`League`,' ')-1)+0) > 350
ORDER BY -round(((substr(`League`,1,instr(`League`,' ')-1)+0)*100.0)/((substr(`Total`,1,instr(`Total`,' ')-1)+0),1)
LIMIT 3 OFFSET 0;
","SELECT col0, (substr(col2,1,instr(col2,' ')-1)+0) league_apps, (substr(col7,1,instr(col7,' ')-1)+0) total_apps, round(((substr(col2,1,instr(col2,' ')-1)+0)*100.0)/((substr(col7,1,instr(col7,' ')-1)+0)),1) league_pct
FROM table_1_14962287_1
WHERE (substr(col7,1,instr(col7,' ')-1)+0) >= 450
AND (substr(col2,1,instr(col2,' ')-1)+0) > 350
ORDER BY -round(((substr(col2,1,instr(col2,' ')-1)+0)*100.0)/((substr(col7,1,instr(col7,' ')-1)+0)),1)
LIMIT 3 OFFSET 0;","[('bert trautmann category:articles with hcards', 508, 545, 93.2), ('eric brook category:articles with hcards', 450, 493, 91.3), ('alan oakes category:articles with hcards', 561, 676, 83.0)]",table_1_14962287_1,"STEP 1: Parse the SQL intent — extract the integer part of the 'League' and 'Total' columns (numbers before the space), compute league_pct = round(league_apps*100.0/total_apps,1), filter to rows with total_apps >= 450 and league_apps > 350, order by league_pct descending, return the top 3 names with their league_apps, total_apps and league_pct. STEP 2: Choose an ambiguity type — Entity vagueness fits well: the natural phrase “appearances” can mean different things here (the table shows values like '561 (3)' where the parenthetical is substitute appearances), and the query explicitly strips text after the first space so it uses only the leading integer; this raises ambiguity about whether substitutes are counted. STEP 3: Draft the question — ""Which players with at least 450 total appearances and more than 350 league appearances have the highest percentage of their appearances in the League?"" STEP 4: Explain the ambiguity — the original query interprets ""appearances"" as the leading integer in the 'Total' and 'League' cells (ignoring parenthetical substitute counts) and returns the top three by league_pct; alternatively a reader could interpret ""appearances"" to include the parenthetical substitute counts (or other variants of counting), or could mean a different denominator (e.g., league appearances as a share of career seasons), which would change the ranking and results.",reserved,8,reward,,"type: Entity Vagueness | explanation: The query treats ""appearances"" as the leading integer in each cell (ignoring parenthetical substitute counts like '561 (3)'), so it computes league% = league_int / total_int; a reader could instead interpret ""appearances"" to include the parenthetical numbers (substitute apps) or some other definition of appearances, which would produce different percentages and possibly different top players."
"Grouped by Game Site for entries where Opponent = 'at Miami Dolphins', what are the Game Site, COUNT(Week), SUM(substr(Result,1,1)='W') (wins where Result begins with 'W'), and AVG(Attendance), with the results ordered by AVG(Attendance) from highest to lowest?","
SELECT `Game Site`, COUNT(`Week`), SUM(substr(`Result`,1,1)='W'), AVG(`Attendance`)
FROM `table_1_14966537_1`
CROSS JOIN `table_1_14966537_1` AS `t2`
WHERE `Opponent` = `at Miami Dolphins`
GROUP BY `Game Site`
ORDER BY AVG(`Attendance`) DESC;
","SELECT col5, COUNT(col0) AS `Games`, SUM(CASE WHEN substr(col3,1,1) = 'W' THEN 1 ELSE 0 END) AS `Wins`, AVG(col6) AS `AvgAttendance`
FROM `table_1_14966537_1`
WHERE col2 LIKE '%Miami Dolphins%'
GROUP BY col5
ORDER BY AVG(col6) DESC;","[('miami orange bowl', 1, 0, 67699.0), ('memorial stadium', 1, 0, 60240.0)]",table_1_14966537_1,"1) The SQL intention is aggregation by Game Site for entries with Opponent = 'at Miami Dolphins' using COUNT, a SUM of a substring check for wins, and AVG attendance, sorted by average attendance descending. 2) Map these to plain terms while preserving exact calculations COUNT(Week), SUM(substr(Result,1,1)='W'), and AVG(Attendance). 3) Draft a concise question requesting, per Game Site, those exact aggregates for Opponent = 'at Miami Dolphins' and to sort results from highest to lowest average attendance. 4) Validate inclusion of all selected expressions and the filter and ordering.",reserved,10,reward,,
"Show, for each New Conference and New Classification pair where New Conference is not 'N/A' and Institution is not blank, the New Conference, the New Classification, the Team Count (total teams in that group), the Ceased Count (how many rows in that group have 'ceased operations' appearing in New Conference), the Unknown Tenure Count (how many rows in that group have 'unknown' appearing in Tenure), and a semicolon-separated list of Institutions, grouping by New Conference and New Classification and returning the top 10 groups ordered by Team Count descending?","
SELECT `New Conference`, `New Classification`, COUNT(*) AS `Team Count`, SUM(INSTR(`New Conference`, REPLACE('`ceased operations`','`','')) > 0) `Ceased Count`, SUM(INSTR(`Tenure`, REPLACE('`unknown`','`','')) > 0) `Unknown Tenure Count`, GROUP_CONCAT(`Institution`, '; ') `Institutions` FROM `table_1_14976504_2` WHERE `New Conference` != REPLACE('`N/A`','`','') AND `Institution` != '' GROUP BY `New Conference`, `New Classification` ORDER BY `Team Count` DESC LIMIT 10;
","SELECT col4, col5, COUNT(*) AS `Team Count`, SUM(CASE WHEN INSTR(col4, 'ceased operations') > 0 THEN 1 ELSE 0 END) AS `Ceased Count`, SUM(CASE WHEN INSTR(col3, 'unknown') > 0 THEN 1 ELSE 0 END) AS `Unknown Tenure Count`, GROUP_CONCAT(col0, '; ') AS `Institutions` FROM `table_1_14976504_2` WHERE col4 != 'N/A' AND col0 != '' GROUP BY col4, col5 ORDER BY `Team Count` DESC LIMIT 10;","[('slc', 'mcla division i', 12, 0, 2, 'arizona state university; chapman university; claremont mckenna college; loyola marymount university; san diego state university; university of arizona; university of california, los angeles; university of california, san diego; university of california, santa barbara; university of nevada, las vegas; university of san diego; university of southern california'), ('slc', 'mcla division ii', 6, 0, 1, 'biola university; california lutheran university; california state university, fullerton; pepperdine university; occidental college; university of california, irvine'), ('n/a', 'n/a', 2, 0, 2, 'california state university, san marcos; northern arizona university'), ('ceased operations in 1998', 'n/a', 1, 1, 0, 'california state university, sacramento'), ('ceased operations in 2004', 'n/a', 1, 1, 0, 'california state university, hayward')]",table_1_14976504_2,"1) Parse SQL intent: group by New Conference and New Classification, compute counts and string-based condition sums, and concatenate institutions; exclude New Conference 'N/A' and empty Institution; sort by team count desc limit 10. 2) Map schema: reference `New Conference`, `New Classification`, `Tenure`, and `Institution`. 3) Draft: request each grouped result with the specified metrics and concatenated institution list separated by '; '. 4) Validate: ensures all calculations, filters, grouping, ordering, and limit are mentioned.",reserved,10,reward,,
"For the period from 01 Jan 2006 to 31 Dec 2007, which three jockeys have the highest Win% (where Win% = 100 × Wins / Starts, rounded to two decimal places), and for each jockey what are their Jockey name, number of Starts, number of Wins (count of Result = 'Won'), Win% (rounded to 2 decimals), and number of races at Moonee Valley?","
SELECT `Jockey`, COUNT(*) `Starts`, SUM((`Result` = 'Won')) `Wins`, ROUND(100.0 * SUM((`Result` = 'Won')) / COUNT(*),2) AS `Win%`, SUM((`Venue` = 'Moonee Valley')) `Moonee Valley`
FROM `table_1_14981555_3`
WHERE `Date` BETWEEN '01 Jan 2006' AND '31 Dec 2007'
GROUP BY `Jockey`
ORDER BY `Win%` DESC
LIMIT 3;
","
SELECT col7, COUNT(*) `Starts`, SUM((col0 = 'Won')) `Wins`, ROUND(100.0 * SUM((col0 = 'Won')) / COUNT(*),2) AS `Win%`, SUM((col3 = 'Moonee Valley')) `Moonee Valley`
FROM `table_1_14981555_3`
WHERE col1 BETWEEN '01 Jan 2006' AND '31 Dec 2007'
GROUP BY col7
ORDER BY `Win%` DESC
LIMIT 3;
","[('d. oliver', 1, 0, 0.0, 0), ('c. newitt', 8, 0, 0.0, 0)]",table_1_14981555_3,"Parse intent: compute per-jockey totals and win stats for races between 01 Jan 2006 and 31 Dec 2007, then return the top three by win percentage. Map schema: use columns Jockey, Result to count Wins (Result='Won'), COUNT(*) as Starts, compute Win% = 100 * Wins / Starts rounded to 2 decimals, and count Venue='Moonee Valley' as Moonee Valley. Draft: ask for Jockey plus Starts, Wins, Win% (rounded to two decimals and defined as 100*wins/starts), and Moonee Valley counts for that date range, ordered by Win% descending and limited to 3. Validate: includes all columns, calculation, date filter, ordering and limit.",reserved,12,reward,,
"For stadiums with big crowds, what were their average and peak attendance and how many wins did they have?","
SELECT `Game Site`, AVG(`Attendance`) `Average Attendance`, MAX(`Attendance`) `Peak Attendance`, SUM(instr(`Result`, 'W ')>0) `Wins`
FROM `table_1_14984050_1` AS `s`
WHERE `Attendance` > 40000
GROUP BY `Game Site`
HAVING AVG(`Attendance`) > 48000
ORDER BY `Average Attendance`
LIMIT 10;
","
SELECT col5, AVG(col6) `Average Attendance`, MAX(col6) `Peak Attendance`, SUM(instr(col3, 'W ')>0) `Wins`
FROM `table_1_14984050_1` AS `s`
WHERE col6 > 40000
GROUP BY col5
HAVING AVG(col6) > 48000
ORDER BY `Average Attendance`
LIMIT 10;
","[('tiger stadium', 55764.0, 55764.0, 0), ('kezar stadium', 59950.0, 59950.0, 0)]",table_1_14984050_1,"STEP 1: Parse the SQL intent: The query selects Game Site and computes average Attendance, max Attendance, and counts wins (rows where Result contains 'W ') but only for games with Attendance > 40000; it then groups by Game Site, keeps groups whose average Attendance > 48000, orders by average Attendance, and limits to 10. STEP 2: Choose ambiguity type: Attachment ambiguity fits well — a phrase like ""how many wins did they have"" can attach to either the stadium/site (wins at that site) or to the team(s) that play there. This matches the query which counts wins per site but could be read as wins by other referents. STEP 3: Draft the question: ""For stadiums with big crowds, what were their average and peak attendance and how many wins did they have?"" STEP 4: Explain ambiguity: In the original query ""their""/""they"" maps to the grouped Game Site and the query counts the Colts' wins in those high-attendance games at each site. Alternatively, a reader could interpret ""how many wins did they have"" as asking about wins by any team that uses the stadium overall, wins across the whole season (including low-attendance games), or wins aggregated in a different scope (e.g., per opponent or per season), changing the intended aggregation and filter.",reserved,9,reward,,"type: Attachment ambiguity | explanation: The phrase ""how many wins did they have"" can attach to the stadiums (wins recorded at that site in the filtered high-attendance games, which is what the SQL counts) or to another entity such as the team(s) that play there or wins across all games at the stadium (which would change filters and aggregation)."
"Which five pairs of different Administrative division and Peer (where a.`Area (km²)` > 0 and either a.`Population (2010 Census)` > 500000 or b.`Population (2010 Census)` > 500000) have the highest Relative change defined as ((a.`Population (2010 Census)` - b.`Population 2000 Census`) * 100.0) / b.`Population 2000 Census` when b.`Population 2000 Census` != 0, and what are a.`Administrative division`, b.`Administrative division` (Peer), that Relative change, and ABS(a.`Population density 2010 (/km²)` - b.`Population density 2010 (/km²)`), ordered by Relative change descending and limited to 5?","
SELECT a.`Administrative division`, b.`Administrative division` `Peer`,
CASE WHEN b.`Population 2000 Census` != 0 THEN ((a.`Population (2010 Census)` - b.`Population 2000 Census`) * 100.0) / b.`Population 2000 Census` END AS `Relative change`,
ABS(a.`Population density 2010 (/km²)` - b.`Population density 2010 (/km²)`)
FROM `table_1_14986292_1` a
LEFT JOIN `table_1_14986292_1` b ON a.`Administrative division` != b.`Administrative division`
WHERE (a.`Population (2010 Census)` > 500000 OR b.`Population (2010 Census)` > 500000) AND a.`Area (km²)` > 0
ORDER BY `Relative change` DESC
LIMIT 5;
","
SELECT a.col0, b.col0 `Peer`,
CASE WHEN b.col2 != 0 THEN ((a.col3 - b.col2) * 100.0) / b.col2 END AS `Relative change`,
ABS(a.col4 - b.col4)
FROM `table_1_14986292_1` a
LEFT JOIN `table_1_14986292_1` b ON a.col0 != b.col0
WHERE (a.col3 > 500000 OR b.col3 > 500000) AND a.col1 > 0
ORDER BY `Relative change` DESC
LIMIT 5;
","[('rio de janeiro', 'tanguá', 24166.17415665656, 4809.0), ('rio de janeiro', 'guapimirim', 16560.616041315345, 4875.0), ('rio de janeiro', 'seropédica', 9588.993257738277, 4743.0), ('rio de janeiro', 'japeri', 7492.685943466462, 3867.0), ('rio de janeiro', 'queimados', 5083.114604936349, 3227.0)]",table_1_14986292_1,"Parse the SQL intent: left-join distinct Administrative division pairs, compute percent Relative change from a's 2010 population relative to b's 2000 population when that b value is not zero, compute absolute difference in `Population density 2010 (/km²)`, apply filters (either side's 2010 population > 500000 and a.`Area (km²)` > 0), sort by Relative change descending and limit to 5. Map schema semantics: include a.`Administrative division`, b.`Administrative division` as Peer, the explicit formula for Relative change, the ABS density difference, and the WHERE and ORDER BY clauses. Draft the question to ask for those specific outputs and constraints. Validate inclusion of all columns, the CASE condition, ABS calculation, ordering and limit.",reserved,16,reward,,
"List the English gloss (as 'child'), the Santee-Sisseton column (as 'šičéča'), and the Yankton-Yanktonai, Northern Lakota, and Southern Lakota values for entries where Yankton-Yanktonai = Northern Lakota and Northern Lakota = Southern Lakota?","
SELECT `English gloss` `child`, `Santee-Sisseton` `šičéča`, `Yankton-Yanktonai`, `Northern Lakota`, `Southern Lakota`
FROM `table_1_1499791_2`
WHERE `Yankton-Yanktonai` = `Northern Lakota` AND `Northern Lakota` = `Southern Lakota`;
","
SELECT col0 `child`, col1 `šičéča`, col2, col3, col4
FROM `table_1_1499791_2`
WHERE col2 = col3 AND col3 = col4;
","[('child', 'šičéča', 'wakȟáŋyeža', 'wakȟáŋyeža', 'wakȟáŋyeža'), ('knee', 'hupáhu', 'čhaŋkpé', 'čhaŋkpé', 'čhaŋkpé'), ('kidneys', 'phakšíŋ', 'ažúŋtka', 'ažúŋtka', 'ažúŋtka'), ('hat', 'wapháha', 'wapȟóštaŋ', 'wapȟóštaŋ', 'wapȟóštaŋ'), ('still', 'hináȟ', 'naháŋȟčiŋ', 'naháŋȟčiŋ', 'naháŋȟčiŋ'), ('man', 'wičhášta', 'wičháša', 'wičháša', 'wičháša')]",table_1_1499791_2,"1) Parse: the query selects five columns (with two aliases) and filters by equality among the three Lakota columns. 2) Map: include 'English gloss' aliased to child, 'Santee-Sisseton' aliased to šičéča, plus Yankton-Yanktonai, Northern Lakota, Southern Lakota. 3) Draft: request those labeled columns for entries where Yankton-Yanktonai = Northern Lakota = Southern Lakota. 4) Validate: ensure the question explicitly lists each column and the equality condition.",reserved,4,reward,,
"For the top 5 most recent years (ORDER BY Year DESC LIMIT 5), return Year, the Mens singles column labeled as ""Eduards Loze"", the Womens singles column labeled as ""Kristīne Šefere"", the Mens doubles column labeled as ""Eduards Loze Mārtiņš Kažemaks"", the Womens doubles column labeled as ""Kristīne Šefere Margarita Mikelsone"", and the Mixed doubles column labeled as ""Eduards Loze Kristīne Šefere"" for those years where, in a cross join of the table with itself on the same Year, the condition INSTR(t2.`Mixed doubles`, t1.`Mens singles`) > 0 holds, grouping results by Year?","
SELECT t1.`Year`, t1.`Mens singles` `Eduards Loze`, t1.`Womens singles` `Kristīne Šefere`, t1.`Mens doubles` `Eduards Loze Mārtiņš Kažemaks`, t1.`Womens doubles` `Kristīne Šefere Margarita Mikelsone`, t1.`Mixed doubles` `Eduards Loze Kristīne Šefere`
FROM `table_1_15001609_1` t1 CROSS JOIN `table_1_15001609_1` t2
WHERE (t1.`Year` = t2.`Year`) * (INSTR(t2.`Mixed doubles`, t1.`Mens singles`) > 0)
GROUP BY t1.`Year`
ORDER BY (t1.`Year` * -1)
LIMIT 5;
","
SELECT t1.col0, t1.col1 `Eduards Loze`, t1.col2 `Kristīne Šefere`, t1.col3 `Eduards Loze Mārtiņš Kažemaks`, t1.col4 `Kristīne Šefere Margarita Mikelsone`, t1.col5 `Eduards Loze Kristīne Šefere`
FROM `table_1_15001609_1` t1 CROSS JOIN `table_1_15001609_1` t2
WHERE (t1.col0 = t2.col0) * (INSTR(t2.col5, t1.col1) > 0)
GROUP BY t1.col0
ORDER BY (t1.col0 * -1)
LIMIT 5;
","[(2007.0, 'eduards loze', 'kristīne šefere', 'eduards loze edijs līviņš', 'kristīne šefere madara puķīte', 'eduards loze kristīne šefere'), (2004.0, 'karlis vidass', 'margarita mikelsone', 'karlis vidass guntis lavrinovičs', 'kristīne šefere margarita mikelsone', 'karlis vidass kristine kisele'), (2000.0, 'mārtiņš kažemaks', 'kristīne šefere', 'mārtiņš kažemaks edijs līviņš', 'kristīne šefere dace šneidere', 'mārtiņš kažemaks margarita mikelsone'), (1999.0, 'eduards loze', 'dace šneidere', 'eduards loze mārtiņš kažemaks', 'kristīne šefere margarita mikelsone', 'eduards loze kristīne šefere'), (1998.0, 'eduards loze', 'margarita mikelsone', 'eduards loze mārtiņš kažemaks', 'kristine tiruma dace šneidere', 'eduards loze kristīne šefere')]",table_1_15001609_1,"1) The SQL returns Year and five event columns aliased to specific person-name labels for rows where the mens singles name is found within that year's mixed doubles string (INSTR>0), using a self cross join, grouping by Year, ordering by Year descending and limiting to 5. 2) Map each selected column to its alias and include the INSTR substring condition and same-Year join semantics. 3) Draft a question that requests those exact columns (with aliases) under the specified INSTR and grouping/ordering/limit constraints. 4) Confirm the question includes all selections, aliases, the INSTR condition, cross-join on Year, GROUP BY Year, ORDER BY Year DESC, and LIMIT 5.",reserved,9,reward,,
What was Bill Gallagher's contribution to viewing figures for episodes over 6.5 million directed by Charles Palmer?,"
SELECT '`Bill Gallagher`', SUM((`Writer`='Bill Gallagher')*(REPLACE(`Viewing figure`,' million','')+0)), SUM((`Writer`='Paul Rutman')*(REPLACE(`Viewing figure`,' million','')+0)), SUM((`Writer`='Carolyn Bonnyman')*(REPLACE(`Viewing figure`,' million','')+0)), SUM((`Writer`='Gaby Chiappe')*(REPLACE(`Viewing figure`,' million','')+0)), SUM(REPLACE(`Viewing figure`,' million','')+0), printf('`Bill Gallagher` contribution: %.2f%%', 100.0*SUM((`Writer`='Bill Gallagher')*(REPLACE(`Viewing figure`,' million','')+0))/SUM(REPLACE(`Viewing figure`,' million','')+0))
FROM `table_1_15026994_2`
WHERE REPLACE(`Viewing figure`,' million','')+0>6.5 AND `Director`='Charles Palmer';
","
SELECT '`Bill Gallagher`', SUM((col2='Bill Gallagher')*(REPLACE(col5,' million','')+0)), SUM((col2='Paul Rutman')*(REPLACE(col5,' million','')+0)), SUM((col2='Carolyn Bonnyman')*(REPLACE(col5,' million','')+0)), SUM((col2='Gaby Chiappe')*(REPLACE(col5,' million','')+0)), SUM(REPLACE(col5,' million','')+0), printf('`Bill Gallagher` contribution: %.2f%%', 100.0*SUM((col2='Bill Gallagher')*(REPLACE(col5,' million','')+0))/SUM(REPLACE(col5,' million','')+0))
FROM `table_1_15026994_2`
WHERE REPLACE(col5,' million','')+0>6.5 AND col3='Charles Palmer';
","[('`Bill Gallagher`', None, None, None, None, None, '`Bill Gallagher` contribution: 0.00%')]",table_1_15026994_2,"STEP 1: Parse the SQL intent — filter rows where Viewing figure (numeric) > 6.5 AND Director = 'Charles Palmer'; sum viewing figures for Bill Gallagher and several other writers, compute the total viewing figures for that filtered set, and compute Bill Gallagher's percentage contribution of that total. STEP 2: Determine ambiguity type — scope ambiguity fits: the phrase that restricts the set of episodes (""over 6.5 million directed by Charles Palmer"") can be read as a single combined filter or as separate/attached modifiers; also ""contribution"" can mean absolute sum or percentage, or per-episode vs overall. STEP 3: Draft the question — ""What was Bill Gallagher's contribution to viewing figures for episodes over 6.5 million directed by Charles Palmer?"" STEP 4: Explain the ambiguity — the original query interprets the question as asking for the aggregate contribution (sum and percent) over episodes that satisfy both conditions (viewing > 6.5 AND director Charles Palmer); alternatively the question could be read as asking about per-episode contributions, as asking about episodes over 6.5 regardless of director, or as asking for an absolute total instead of a percentage.",reserved,4,reward,,"type: Scope ambiguity | explanation: The SQL interprets the phrase as a single combined filter (episodes that are both >6.5 million and directed by Charles Palmer) and returns aggregate sums and a percentage for Bill; the NL can instead be read as (a) applying the filters separately (e.g., episodes >6.5 regardless of director, or episodes directed by Charles Palmer regardless of size), (b) asking for per-episode contributions rather than the overall aggregate, or (c) asking for absolute viewing figures instead of a percentage."
"For each Writer, what is the average Viewing figure in millions (derived by removing the ' million' suffix from the Viewing figure and averaging those numbers) among rows where Episode is not empty, limited to writers whose average is between 6 and 8, ordered by the average in descending order and showing the top 10?","
SELECT DISTINCT t.`Writer`, AVG(REPLACE(t.`Viewing figure`, ' million', '')) AS `avg_millions`
FROM `table_1_15026994_5` t
INNER JOIN `table_1_15026994_5` t2 ON t.`Writer`=t2.`Writer`
WHERE t.`Episode`<>''
GROUP BY t.`Writer`
HAVING AVG(REPLACE(t.`Viewing figure`, ' million', '')) BETWEEN 6 AND 8
ORDER BY `avg_millions` DESC
LIMIT 10;
","
SELECT DISTINCT t.col2, AVG(REPLACE(t.col5, ' million', '')) AS `avg_millions`
FROM `table_1_15026994_5` t
INNER JOIN `table_1_15026994_5` t2 ON t.col2=t2.col2
WHERE t.col1<>''
GROUP BY t.col2
HAVING AVG(REPLACE(t.col5, ' million', '')) BETWEEN 6 AND 8
ORDER BY `avg_millions` DESC
LIMIT 10;
","[('bill gallagher', 7.2425), ('rachel bennette', 6.9)]",table_1_15026994_5,"1) The SQL selects distinct Writer and AVG(REPLACE(Viewing figure,' million','')) grouped by Writer, only where Episode is not empty, with HAVING avg between 6 and 8, ordered descending and limited to 10. 2) Treat Viewing figure text values as numeric millions by stripping ' million' then averaging per Writer. 3) Formulate a question requesting Writer plus the computed average in millions, apply the Episode non-empty filter, the 6-to-8 million average range, sort descending, and limit to 10. 4) Check the question mentions all columns and calculations and the ordering and limit.",reserved,16,reward,,
"Restricting to rows where DATE COMPLETED is present, what are the Total Prints (COUNT(*)), the Total Colors (SUM((NUMBER OF COLORS)+0)), the Average Colors (AVG((NUMBER OF COLORS)+0)), the count of FRAMED SIZE entries that include '26"" x 32""' (SUM(instr(FRAMED SIZE,'26"" x 32""')>0)), and the Percent With Known Colors computed as (SUM((NUMBER OF COLORS)+0 > 0) * 100.0) / COUNT(*)?","
SELECT COUNT(*) `Total Prints`, SUM((`NUMBER OF COLORS`)+0) `Total Colors`, AVG((`NUMBER OF COLORS`)+0) `Average Colors`, SUM(instr(`FRAMED SIZE`,'26"" x 32""')>0) `26"" x 32"" Count`, (SUM((`NUMBER OF COLORS`)+0>0)*100.0)/COUNT(*) `Percent With Known Colors` FROM `table_1_15070195_1` WHERE `DATE COMPLETED`;
","
SELECT COUNT(*) `Total Prints`, SUM((col2)+0) `Total Colors`, AVG((col2)+0) `Average Colors`, SUM(instr(col3,'26"" x 32""')>0) `26"" x 32"" Count`, (SUM((col2)+0>0)*100.0)/COUNT(*) `Percent With Known Colors` FROM `table_1_15070195_1` WHERE col4;
","[(48, 1181, 24.604166666666668, 10, 91.66666666666667)]",table_1_15070195_1,"1) Parse SQL: produce count, sum, average of NUMBER OF COLORS coerced to numeric, count framed sizes matching '26"" x 32""', and percentage of rows with NUMBER OF COLORS > 0, limited to rows with DATE COMPLETED. 2) Map schema: reference `NUMBER OF COLORS`, `FRAMED SIZE`, and `DATE COMPLETED` exactly and the instr() substring check. 3) Draft: formulate a single question listing all required aggregates and the percent formula. 4) Validate: question must explicitly state COUNT(*), SUM((NUMBER OF COLORS)+0), AVG((NUMBER OF COLORS)+0), SUM(instr(FRAMED SIZE,'26"" x 32""')>0), and (SUM((NUMBER OF COLORS)+0>0)*100.0)/COUNT(*) for rows where DATE COMPLETED.",reserved,3,reward,,
"Return up to five rows showing Average population (x 1,000) and the greatest value of (Natural change / Average population (x 1,000)) minus Natural change (per 1,000) for each Average population (x 1,000) > 2600, excluding cases where that greatest value equals 0, ordered by that greatest value in descending order?","
SELECT `Average population (x 1,000)`, MAX((`Natural change` / `Average population (x 1,000)`) - `Natural change (per 1,000)`) `max_discrepancy`
FROM `table_1_1508951_1`
WHERE `Average population (x 1,000)` > 2600
GROUP BY `Average population (x 1,000)`
HAVING MAX((`Natural change` / `Average population (x 1,000)`) - `Natural change (per 1,000)`) <> 0
ORDER BY `max_discrepancy` DESC
LIMIT 5;
","
SELECT col1, MAX((col4 / col1) - col7) `max_discrepancy`
FROM `table_1_1508951_1`
WHERE col1 > 2600
GROUP BY col1
HAVING MAX((col4 / col1) - col7) <> 0
ORDER BY `max_discrepancy` DESC
LIMIT 5;
","[(2660.0, 10.657894736842104), (2650.0, 0.16792452830188864), (2940.0, 0.12585034013605423), (2870.0, 0.12473867595818788), (2840.0, 0.10704225352112573)]",table_1_1508951_1,"1) The query selects Average population (x 1,000) and the maximum discrepancy computed as (Natural change / Average population (x 1,000)) - Natural change (per 1,000). 2) It applies a filter Average population (x 1,000) > 2600, groups by Average population, excludes zero maxima via HAVING, sorts by the maximum discrepancy descending, and limits to 5. 3) Create a concise natural question requesting those exact outputs and constraints. 4) Verify inclusion of calculation, filter, grouping, nonzero condition, ordering, and limit.",reserved,9,reward,,
"For each of the following countries: United States, England, South Korea, South Africa, Fiji, and Australia, what are the Country, Wins (COUNT(*)), Total Payout (SUM of `Winners share ( $ )`), Avg Raw Score (the average of the numeric part of `Score` defined as the substring before the first space converted to a numeric value) and Best Raw Score (the minimum of that numeric part), considering only countries with one or more wins, grouped by Country, ordered by Total Payout descending and limited to 10 rows?","
SELECT `Country`, COUNT(*) `Wins`, SUM(`Winners share ( $ )`) `Total Payout`, AVG(substr(`Score`,1,instr(`Score`,' ')-1)+0) `Avg Raw Score`, MIN(substr(`Score`,1,instr(`Score`,' ')-1)+0) `Best Raw Score`
FROM `table_1_1515346_2`
CROSS JOIN (VALUES('United States','England','South Korea','South Africa','Fiji','Australia')) `countries`(`United States`,`England`,`South Korea`,`South Africa`,`Fiji`,`Australia`)
WHERE `Country` IN (`United States`,`England`,`South Korea`,`South Africa`,`Fiji`,`Australia`)
GROUP BY `Country`
HAVING COUNT(*) >= 1
ORDER BY `Total Payout` DESC
LIMIT 10;
","SELECT DISTINCT col2, COUNT(*) AS `Wins`, SUM(col5) AS `Total Payout`, AVG(replace(substr(col3,1,instr(col3,' ')-1),'*','')+0) AS `Avg Raw Score`, MIN(replace(substr(col3,1,instr(col3,' ')-1),'*','')+0) AS `Best Raw Score` FROM `table_1_1515346_2` WHERE col2 IS NOT NULL GROUP BY col2 HAVING COUNT(*) >= 1 ORDER BY `Total Payout` DESC LIMIT 10;","[('united states', 28, 11804000.0, 275.75, 268), ('south korea', 1, 1080000.0, 271.0, 271), ('england', 1, 1080000.0, 270.0, 270), ('south africa', 1, 945000.0, 270.0, 270), ('fiji', 1, 342000.0, 202.0, 202), ('australia', 2, 234000.0, 248.0, 216)]",table_1_1515346_2,"1) The SQL groups wins by Country for a fixed set of countries and computes aggregate payout and numeric-score statistics, then orders by payout and limits output. 2) Map columns: COUNT(*) as Wins, SUM(`Winners share ( $ )`) as Total Payout, AVG and MIN of the numeric prefix of Score as Avg Raw Score and Best Raw Score. 3) Draft a question that requests those exact aggregates for the listed countries, with the numeric Score defined as the substring before the first space converted to a number. 4) Confirm it restricts to United States, England, South Korea, South Africa, Fiji, Australia, requires at least one win, groups by Country, orders by Total Payout desc and limits to 10.",reserved,14,reward,,
"List every episode that covers 'Coffee' (case-insensitive, partial match), showing the Series Ep., episode number, Netflix id, segment label and the original segment text.","
WITH unpivot AS (
  SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment A` AS `segment`, 'A' AS `seg_label` FROM `table_1_15187735_11`
  UNION ALL
  SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment B` AS `segment`, 'B' AS `seg_label` FROM `table_1_15187735_11`
  UNION ALL
  SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment C` AS `segment`, 'C' AS `seg_label` FROM `table_1_15187735_11`
  UNION ALL
  SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment D` AS `segment`, 'D' AS `seg_label` FROM `table_1_15187735_11`
),
norm AS (
  SELECT
    `Series Ep.`,
    `Episode`,
    `Netflix`,
    `seg_label`,
    `segment`,
    LOWER(TRIM(`segment`)) AS `topic_norm`,
    CASE WHEN LOWER(TRIM(`segment`)) LIKE 's %' THEN 1 ELSE 0 END AS `leading_s_flag`,
    CASE WHEN `segment` IS NULL OR TRIM(`segment`) = '' THEN 1 ELSE 0 END AS `missing_segment_flag`
  FROM unpivot
),
-- topic frequency summary with sample episodes per topic
topic_counts AS (
  SELECT
    'topic_count' AS `report_type`,
    `topic_norm` AS `item_key`,
    COUNT(*) AS `metric`,
    GROUP_CONCAT(DISTINCT `Series Ep.` || ' (' || `Netflix` || ')' , '; ') AS `details`
  FROM norm
  WHERE `topic_norm` != '' AND `topic_norm` IS NOT NULL
  GROUP BY `topic_norm`
  ORDER BY `metric` DESC, `topic_norm`
),
-- episodes that mention Coffee (case-insensitive, partial match) with segment label and original text
coffee_episodes AS (
  SELECT
    'coffee_episode' AS `report_type`,
    `topic_norm` AS `item_key`,
    1 AS `metric`,
    `Series Ep.` || ' | Ep:' || `Episode` || ' | Netflix:' || `Netflix` || ' | Segment:' || `seg_label` || '=""' || `segment` || '""' AS `details`
  FROM norm
  WHERE `topic_norm` LIKE '%coffee%'
),
-- metadata quality issues: segments with leading ""s "", missing segment text, or missing/duplicate Netflix IDs
quality_issues AS (
  SELECT
    'quality_issue' AS `report_type`,
    `Series Ep.` AS `item_key`,
    CASE
      WHEN `leading_s_flag` = 1 THEN 'leading_s_in_segment'
      WHEN `missing_segment_flag` = 1 THEN 'missing_segment'
      WHEN `Netflix` IS NULL OR TRIM(`Netflix`) = '' THEN 'missing_netflix_id'
      WHEN `Netflix` IN (SELECT `Netflix` FROM `table_1_15187735_11` GROUP BY `Netflix` HAVING COUNT(*)>1) THEN 'duplicate_netflix_id'
      ELSE 'other'
    END AS `metric`,
    'Segment ' || `seg_label` || '=""' || IFNULL(`segment`,'') || '"" | Ep:' || `Episode` || ' | Netflix:' || IFNULL(`Netflix`,'(NULL)') AS `details`
  FROM norm
  WHERE `leading_s_flag` = 1
     OR `missing_segment_flag` = 1
     OR `Netflix` IS NULL
     OR TRIM(`Netflix`) = ''
     OR `Netflix` IN (SELECT `Netflix` FROM `table_1_15187735_11` GROUP BY `Netflix` HAVING COUNT(*)>1)
)
-- combine the three reports into one actionable result set
SELECT * FROM topic_counts
UNION ALL
SELECT * FROM coffee_episodes
UNION ALL
SELECT * FROM quality_issues
ORDER BY `report_type` DESC, `metric` DESC, `item_key`;
","WITH unpivot AS (
  SELECT col0, col1, col2, col3 AS `segment`, 'A' AS `seg_label` FROM `table_1_15187735_11`
  UNION ALL
  SELECT col0, col1, col2, col4 AS `segment`, 'B' AS `seg_label` FROM `table_1_15187735_11`
  UNION ALL
  SELECT col0, col1, col2, col5 AS `segment`, 'C' AS `seg_label` FROM `table_1_15187735_11`
  UNION ALL
  SELECT col0, col1, col2, col6 AS `segment`, 'D' AS `seg_label` FROM `table_1_15187735_11`
),
norm AS (
  SELECT
    col0,
    col1,
    col2,
    `seg_label`,
    `segment`,
    LOWER(TRIM(`segment`)) AS `topic_norm`,
    CASE WHEN LOWER(TRIM(`segment`)) LIKE 's %' THEN 1 ELSE 0 END AS `leading_s_flag`,
    CASE WHEN `segment` IS NULL OR TRIM(`segment`) = '' THEN 1 ELSE 0 END AS `missing_segment_flag`
  FROM unpivot
),
topic_counts AS (
  SELECT
    'topic_count' AS `report_type`,
    `topic_norm` AS `item_key`,
    COUNT(*) AS `metric`,
    GROUP_CONCAT(DISTINCT col0 || ' (' || col2 || ')' , '; ') AS `details`
  FROM `table_1_15187735_11`
  WHERE `topic_norm` != '' AND `topic_norm` IS NOT NULL
  GROUP BY `topic_norm`
  ORDER BY `metric` DESC, `topic_norm`
),
coffee_episodes AS (
  SELECT
    'coffee_episode' AS `report_type`,
    `topic_norm` AS `item_key`,
    1 AS `metric`,
    col0 || ' | Ep:' || col1 || ' | Netflix:' || col2 || ' | Segment:' || `seg_label` || '=""' || `segment` || '""' AS `details`
  FROM `table_1_15187735_11`
  WHERE `topic_norm` LIKE '%coffee%'
),
quality_issues AS (
  SELECT
    'quality_issue' AS `report_type`,
    col0 AS `item_key`,
    CASE
      WHEN `leading_s_flag` = 1 THEN 'leading_s_in_segment'
      WHEN `missing_segment_flag` = 1 THEN 'missing_segment'
      WHEN col2 IS NULL OR TRIM(col2) = '' THEN 'missing_netflix_id'
      WHEN col2 IN (SELECT col2 FROM `table_1_15187735_11` GROUP BY col2 HAVING COUNT(*)>1) THEN 'duplicate_netflix_id'
      ELSE 'other'
    END AS `metric`,
    'Segment ' || `seg_label` || '=""' || IFNULL(`segment`,'') || '"" | Ep:' || col1 || ' | Netflix:' || IFNULL(col2,'(NULL)') AS `details`
  FROM `table_1_15187735_11`
  WHERE `leading_s_flag` = 1
     OR `missing_segment_flag` = 1
     OR col2 IS NULL
     OR TRIM(col2) = ''
     OR col2 IN (SELECT col2 FROM `table_1_15187735_11` GROUP BY col2 HAVING COUNT(*)>1)
)
SELECT * FROM `table_1_15187735_11`
UNION ALL
SELECT * FROM `table_1_15187735_11`
UNION ALL
SELECT * FROM `table_1_15187735_11`
ORDER BY 1 DESC, 3 DESC, 2;","[('11-12', 142.0, 's06e12', 's induction cooktop', 'truck scales', 'tetra pak containers', 's harmonica'), ('11-12', 142.0, 's06e12', 's induction cooktop', 'truck scales', 'tetra pak containers', 's harmonica'), ('11-12', 142.0, 's06e12', 's induction cooktop', 'truck scales', 'tetra pak containers', 's harmonica'), ('11-11', 141.0, 's06e11', 'heated skate blades', 's glider', 'hand bells', 'fire hoses'), ('11-11', 141.0, 's06e11', 'heated skate blades', 's glider', 'hand bells', 'fire hoses'), ('11-11', 141.0, 's06e11', 'heated skate blades', 's glider', 'hand bells', 'fire hoses'), ('11-10', 140.0, 's06e10', 'giant valves', 'sardines', 's barograph', 'disposable diapers'), ('11-10', 140.0, 's06e10', 'giant valves', 'sardines', 's barograph', 'disposable diapers'), ('11-10', 140.0, 's06e10', 'giant valves', 'sardines', 's barograph', 'disposable diapers'), ('11-09', 139.0, 's06e09', 's accordion', 's pineapple', 'artificial joints (part 1)', 'artificial joints (part 2)'), ('11-09', 139.0, 's06e09', 's accordion', 's pineapple', 'artificial joints (part 1)', 'artificial joints (part 2)'), ('11-09', 139.0, 's06e09', 's accordion', 's pineapple', 'artificial joints (part 1)', 'artificial joints (part 2)'), ('11-08', 138.0, 's06e08', 's hot rod', 'decorative eggs', 'fire hose nozzles', 'baseballs'), ('11-08', 138.0, 's06e08', 's hot rod', 'decorative eggs', 'fire hose nozzles', 'baseballs'), ('11-08', 138.0, 's06e08', 's hot rod', 'decorative eggs', 'fire hose nozzles', 'baseballs'), ('11-07', 137.0, 's06e07', 'microphones', 'hot tubs', 'artificial turf', 'beer steins'), ('11-07', 137.0, 's06e07', 'microphones', 'hot tubs', 'artificial turf', 'beer steins'), ('11-07', 137.0, 's06e07', 'microphones', 'hot tubs', 'artificial turf', 'beer steins'), ('11-06', 136.0, 's06e06', 'cine cameras', 'glass christmas ornaments', 'giant tires (part 1)', 'giant tires (part 2)'), ('11-06', 136.0, 's06e06', 'cine cameras', 'glass christmas ornaments', 'giant tires (part 1)', 'giant tires (part 2)'), ('11-06', 136.0, 's06e06', 'cine cameras', 'glass christmas ornaments', 'giant tires (part 1)', 'giant tires (part 2)'), ('11-05', 135.0, 's06e05', 'technical glass', 's washing machine', 's playing card', 'crossbows'), ('11-05', 135.0, 's06e05', 'technical glass', 's washing machine', 's playing card', 'crossbows'), ('11-05', 135.0, 's06e05', 'technical glass', 's washing machine', 's playing card', 'crossbows'), ('11-04', 134.0, 's06e04', 'javelins', 's cuckoo clock', 'hearts of palm', 'windshield wipers'), ('11-04', 134.0, 's06e04', 'javelins', 's cuckoo clock', 'hearts of palm', 'windshield wipers'), ('11-04', 134.0, 's06e04', 'javelins', 's cuckoo clock', 'hearts of palm', 'windshield wipers'), ('11-03', 133.0, 's06e03', 'pencils', 'metal recycling', 'coffee (part 1)', 'coffee (part 2)'), ('11-03', 133.0, 's06e03', 'pencils', 'metal recycling', 'coffee (part 1)', 'coffee (part 2)'), ('11-03', 133.0, 's06e03', 'pencils', 'metal recycling', 'coffee (part 1)', 'coffee (part 2)'), ('11-02', 132.0, 's06e02', 'anatomical models', 'jukeboxes', 'tortilla chips', 's spark plug'), ('11-02', 132.0, 's06e02', 'anatomical models', 'jukeboxes', 'tortilla chips', 's spark plug'), ('11-02', 132.0, 's06e02', 'anatomical models', 'jukeboxes', 'tortilla chips', 's spark plug'), ('11-01', 131.0, 's06e01', 'binoculars', 'sparklers', 'rubber boots', 'circular saw s blade'), ('11-01', 131.0, 's06e01', 'binoculars', 'sparklers', 'rubber boots', 'circular saw s blade'), ('11-01', 131.0, 's06e01', 'binoculars', 'sparklers', 'rubber boots', 'circular saw s blade')]",table_1_15187735_11,"I frequently need to pull episodes about a specific subject (e.g., Coffee) to build collections or verify claims. I would ask plainly for episodes that cover that subject rather than mention SQL mechanics. The query searches normalized segment text for 'coffee' (case-insensitive, partial match) and returns episode identifiers plus segment label and original text. The segments come from Segment A-D and the identifiers are Series Ep., Episode, and Netflix. List every episode that covers 'Coffee' (case-insensitive, partial match), showing the Series Ep., episode number, Netflix id, segment label and the original segment text.",persona,"Content metadata analyst at a streaming service responsible for catalog accuracy and discovery tagging; they use this episode-level table to verify metadata, generate topic tags, and find data-quality issues. They need quick queries to derive topic frequencies, locate episodes by subject, and detect formatting errors in segment titles. Goals: Generate a normalized list of topics (segments) and count how often each appears to inform tagging and recommendation models. Locate episodes that cover a specific topic (e.g., ""Coffee"") to build curated collections or check content claims. Detect and report metadata quality issues (e.g., stray leading characters like ""s "", missing/duplicate Netflix IDs) so the catalog can be cleaned. Example Queries: SELECT LOWER(TRIM(topic)) AS topic, COUNT(*) AS occurrences FROM ( SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment A` AS topic FROM `table_1_15187735_11` UNION ALL SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment B` FROM `table_1_15187735_11` UNION ALL SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment C` FROM `table_1_15187735_11` UNION ALL SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment D` FROM `table_1_15187735_11` ) AS t GROUP BY LOWER(TRIM(topic)) ORDER BY occurrences DESC; SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment A`, `Segment B`, `Segment C`, `Segment D` FROM `table_1_15187735_11` WHERE LOWER(`Segment A`) LIKE '%coffee%' OR LOWER(`Segment B`) LIKE '%coffee%' OR LOWER(`Segment C`) LIKE '%coffee%' OR LOWER(`Segment D`) LIKE '%coffee%'; SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment A`, `Segment B`, `Segment C`, `Segment D` FROM `table_1_15187735_11` WHERE LOWER(`Segment A`) LIKE 's %' OR LOWER(`Segment B`) LIKE 's %' OR LOWER(`Segment C`) LIKE 's %' OR LOWER(`Segment D`) LIKE 's %';",reward,,
"Which Series Ep. and Episode have either 'Carbon' or 'Air' appearing in the combined text of Segment A, Segment B, Segment C and Segment D, and for each such episode provide (a) Has Carbon indicating whether 'Carbon' appears in the combined Segment A–D text, (b) Has Air indicating whether 'Air' appears in the combined Segment A–D text, (c) Multiword segment count equal to the number of segments among Segment A, Segment B, Segment C and Segment D that contain a space, and (d) TotalSegmentTextLength equal to the sum of the lengths of Segment A, Segment B, Segment C and Segment D?","
SELECT `Series Ep.`, `Episode`, (instr(`Segment A`||' '||`Segment B`||' '||`Segment C`||' '||`Segment D`, 'Carbon')>0) `Has Carbon`, (instr(`Segment A`||' '||`Segment B`||' '||`Segment C`||' '||`Segment D`, 'Air')>0) `Has Air`, ((instr(`Segment A`,' ')>0)+(instr(`Segment B`,' ')>0)+(instr(`Segment C`,' ')>0)+(instr(`Segment D`,' ')>0)) `Multiword segment count`, (length(`Segment A`)+length(`Segment B`)+length(`Segment C`)+length(`Segment D`)) `TotalSegmentTextLength` FROM `table_1_15187735_12` WHERE (instr(`Segment A`||' '||`Segment B`||' '||`Segment C`||' '||`Segment D`, 'Carbon')>0)+(instr(`Segment A`||' '||`Segment B`||' '||`Segment C`||' '||`Segment D`, 'Air')>0)>0;
","SELECT col0, col1, (instr(lower(col3||' '||col4||' '||col5||' '||col6),'carbon')>0) `Has Carbon`, (instr(lower(col3||' '||col4||' '||col5||' '||col6),'air')>0) `Has Air`, ((instr(col3,' ')>0)+(instr(col4,' ')>0)+(instr(col5,' ')>0)+(instr(col6,' ')>0)) `Multiword segment count`, (length(col3)+length(col4)+length(col5)+length(col6)) `TotalSegmentTextLength` FROM `table_1_15187735_12` WHERE instr(lower(col3||' '||col4||' '||col5||' '||col6),'carbon')>0 OR instr(lower(col3||' '||col4||' '||col5||' '||col6),'air')>0;","[('12-03', 146.0, 0, 1, 4, 62), ('12-04', 147.0, 0, 1, 3, 55), ('12-05', 148.0, 0, 1, 3, 47), ('12-06', 149.0, 1, 0, 3, 62), ('12-08', 151.0, 0, 1, 3, 55), ('12-10', 153.0, 0, 1, 2, 63), ('12-11', 154.0, 1, 0, 4, 67)]",table_1_15187735_12,"Parse the SQL intent: filter to episodes mentioning 'Carbon' or 'Air' across segments and compute presence flags, per-segment multiword indicator sum, and total text length. Map schema semantics: treat Segment A–D as the source of text for substring searches, space checks, and length calculations, returning Series Ep. and Episode as identifiers. Draft the question to explicitly request those calculated fields and the filter. Validate that it matches the SQL's concatenation-based searches and arithmetic computations and asks only for those outputs.",reserved,3,reward,,
"Which Season 13 episodes have segments about watches, leather, or aluminium — show Series Ep. and Episode, a single combined segment string, the matching segment column for each topic, and the season-wide counts for Watch, Leather and Aluminium, ordered by episode number?","
WITH unpivot AS (
  SELECT `Series Ep.`, `Episode`, `Segment A` AS topic, 'Segment A' AS segment_col FROM `table_1_15187735_13`
  UNION ALL
  SELECT `Series Ep.`, `Episode`, `Segment B`, 'Segment B' FROM `table_1_15187735_13`
  UNION ALL
  SELECT `Series Ep.`, `Episode`, `Segment C`, 'Segment C' FROM `table_1_15187735_13`
  UNION ALL
  SELECT `Series Ep.`, `Episode`, `Segment D`, 'Segment D' FROM `table_1_15187735_13`
), topic_totals AS (
  SELECT
    SUM(CASE WHEN topic LIKE '%Watch%' THEN 1 ELSE 0 END) AS `watch_count`,
    SUM(CASE WHEN topic LIKE '%Leather%' THEN 1 ELSE 0 END) AS `leather_count`,
    SUM(CASE WHEN topic LIKE '%Aluminium%' THEN 1 ELSE 0 END) AS `aluminium_count`
  FROM unpivot
)
SELECT
  t.`Series Ep.`,
  t.`Episode`,
  TRIM(
    COALESCE(t.`Segment A`,'') || CASE WHEN t.`Segment A` IS NOT NULL AND t.`Segment B` IS NOT NULL THEN '; ' ELSE '' END ||
    COALESCE(t.`Segment B`,'') || CASE WHEN t.`Segment B` IS NOT NULL AND t.`Segment C` IS NOT NULL THEN '; ' ELSE '' END ||
    COALESCE(t.`Segment C`,'') || CASE WHEN t.`Segment C` IS NOT NULL AND t.`Segment D` IS NOT NULL THEN '; ' ELSE '' END ||
    COALESCE(t.`Segment D`,'')
  ) AS `combined_segments`,
  CASE
    WHEN t.`Segment A` LIKE '%Watch%' THEN '`Segment A`: ' || t.`Segment A`
    WHEN t.`Segment B` LIKE '%Watch%' THEN '`Segment B`: ' || t.`Segment B`
    WHEN t.`Segment C` LIKE '%Watch%' THEN '`Segment C`: ' || t.`Segment C`
    WHEN t.`Segment D` LIKE '%Watch%' THEN '`Segment D`: ' || t.`Segment D`
  END AS `matching_watch_segment`,
  CASE
    WHEN t.`Segment A` LIKE '%Leather%' THEN '`Segment A`: ' || t.`Segment A`
    WHEN t.`Segment B` LIKE '%Leather%' THEN '`Segment B`: ' || t.`Segment B`
    WHEN t.`Segment C` LIKE '%Leather%' THEN '`Segment C`: ' || t.`Segment C`
    WHEN t.`Segment D` LIKE '%Leather%' THEN '`Segment D`: ' || t.`Segment D`
  END AS `matching_leather_segment`,
  CASE
    WHEN t.`Segment A` LIKE '%Aluminium%' THEN '`Segment A`: ' || t.`Segment A`
    WHEN t.`Segment B` LIKE '%Aluminium%' THEN '`Segment B`: ' || t.`Segment B`
    WHEN t.`Segment C` LIKE '%Aluminium%' THEN '`Segment C`: ' || t.`Segment C`
    WHEN t.`Segment D` LIKE '%Aluminium%' THEN '`Segment D`: ' || t.`Segment D`
  END AS `matching_aluminium_segment`,
  tt.`watch_count`,
  tt.`leather_count`,
  tt.`aluminium_count`
FROM `table_1_15187735_13` t
CROSS JOIN topic_totals tt
WHERE (t.`Segment A` LIKE '%Watch%' OR t.`Segment B` LIKE '%Watch%' OR t.`Segment C` LIKE '%Watch%' OR t.`Segment D` LIKE '%Watch%')
   OR (t.`Segment A` LIKE '%Leather%' OR t.`Segment B` LIKE '%Leather%' OR t.`Segment C` LIKE '%Leather%' OR t.`Segment D` LIKE '%Leather%')
   OR (t.`Segment A` LIKE '%Aluminium%' OR t.`Segment B` LIKE '%Aluminium%' OR t.`Segment C` LIKE '%Aluminium%' OR t.`Segment D` LIKE '%Aluminium%')
ORDER BY t.`Episode`;
","WITH unpivot AS (
  SELECT col0, col1, col2 AS topic, 'Segment A' AS segment_col FROM `table_1_15187735_13`
  UNION ALL
  SELECT col0, col1, col3, 'Segment B' FROM `table_1_15187735_13`
  UNION ALL
  SELECT col0, col1, col4, 'Segment C' FROM `table_1_15187735_13`
  UNION ALL
  SELECT col0, col1, col5, 'Segment D' FROM `table_1_15187735_13`
)
SELECT
  t.col0,
  t.col1,
  TRIM(
    COALESCE(t.col2,'') || CASE WHEN t.col2 IS NOT NULL AND t.col3 IS NOT NULL THEN '; ' ELSE '' END ||
    COALESCE(t.col3,'') || CASE WHEN t.col3 IS NOT NULL AND t.col4 IS NOT NULL THEN '; ' ELSE '' END ||
    COALESCE(t.col4,'') || CASE WHEN t.col4 IS NOT NULL AND t.col5 IS NOT NULL THEN '; ' ELSE '' END ||
    COALESCE(t.col5,'')
  ) AS `combined_segments`,
  CASE
    WHEN t.col2 LIKE '%Watch%' THEN 'Segment A: ' || t.col2
    WHEN t.col3 LIKE '%Watch%' THEN 'Segment B: ' || t.col3
    WHEN t.col4 LIKE '%Watch%' THEN 'Segment C: ' || t.col4
    WHEN t.col5 LIKE '%Watch%' THEN 'Segment D: ' || t.col5
  END AS `matching_watch_segment`,
  CASE
    WHEN t.col2 LIKE '%Leather%' THEN 'Segment A: ' || t.col2
    WHEN t.col3 LIKE '%Leather%' THEN 'Segment B: ' || t.col3
    WHEN t.col4 LIKE '%Leather%' THEN 'Segment C: ' || t.col4
    WHEN t.col5 LIKE '%Leather%' THEN 'Segment D: ' || t.col5
  END AS `matching_leather_segment`,
  CASE
    WHEN t.col2 LIKE '%Aluminium%' THEN 'Segment A: ' || t.col2
    WHEN t.col3 LIKE '%Aluminium%' THEN 'Segment B: ' || t.col3
    WHEN t.col4 LIKE '%Aluminium%' THEN 'Segment C: ' || t.col4
    WHEN t.col5 LIKE '%Aluminium%' THEN 'Segment D: ' || t.col5
  END AS `matching_aluminium_segment`,
  (SELECT SUM(CASE WHEN topic LIKE '%Watch%' THEN 1 ELSE 0 END) FROM unpivot) AS watch_count,
  (SELECT SUM(CASE WHEN topic LIKE '%Leather%' THEN 1 ELSE 0 END) FROM unpivot) AS leather_count,
  (SELECT SUM(CASE WHEN topic LIKE '%Aluminium%' THEN 1 ELSE 0 END) FROM unpivot) AS aluminium_count
FROM `table_1_15187735_13` t
WHERE (t.col2 LIKE '%Watch%' OR t.col3 LIKE '%Watch%' OR t.col4 LIKE '%Watch%' OR t.col5 LIKE '%Watch%')
   OR (t.col2 LIKE '%Leather%' OR t.col3 LIKE '%Leather%' OR t.col4 LIKE '%Leather%' OR t.col5 LIKE '%Leather%')
   OR (t.col2 LIKE '%Aluminium%' OR t.col3 LIKE '%Aluminium%' OR t.col4 LIKE '%Aluminium%' OR t.col5 LIKE '%Aluminium%')
ORDER BY t.col1;","[('13-06', 162.0, 'gears; leather watchbands; vitrelle dishes; kitchen shears', 'Segment B: leather watchbands', 'Segment B: leather watchbands', None, 3, 2, 2), ('13-08', 164.0, 'aluminium boats; alpine horns; es luxury watch (part 1); es luxury watch (part 2)', 'Segment C: es luxury watch (part 1)', None, 'Segment A: aluminium boats', 3, 2, 2), ('13-10', 166.0, 'socket sets; leather shoes; aluminium water bottles; bike chains', None, 'Segment B: leather shoes', 'Segment C: aluminium water bottles', 3, 2, 2)]",table_1_15187735_13,"I'm comfortable with slightly technical phrasing but won't use raw SQL; I reference episode IDs and segments directly. The query finds any episode with those three topic keywords, builds a single combined_segments field, and pulls out which segment field contained each match while also computing overall counts. It uses LIKE '%...%' across Segment A–D and orders by Episode. Drafted question: ask for the same fields and the season totals, ordered by episode number. Validation: this mirrors the SQL's filtering, concatenation, matching-per-topic, totals, and ordering.",persona,"Streaming metadata analyst for a documentary/educational channel who curates and tags 'How It's Made' episodes to support search, recommendations, and themed playlists. They use this database to identify episode topics, measure topic frequency, and produce consolidated metadata for the catalog. Goals: Identify episodes that contain a particular manufacturing topic (e.g., 'Watch', 'Leather', 'Aluminium') so they can be included in themed playlists or search facets. Measure how often each segment/topic appears across the season to prioritize which topics to promote or create collections around. Generate consolidated episode descriptions (concatenated segment names) for ingestion into the content management system and recommendation engine. Example Queries: SELECT ""Series Ep."", ""Episode"", 
  CASE 
    WHEN ""Segment A"" LIKE '%Watch%' THEN 'Segment A'
    WHEN ""Segment B"" LIKE '%Watch%' THEN 'Segment B'
    WHEN ""Segment C"" LIKE '%Watch%' THEN 'Segment C'
    WHEN ""Segment D"" LIKE '%Watch%' THEN 'Segment D'
  END AS matching_segment,
  COALESCE(""Segment A"",'') || '; ' || COALESCE(""Segment B"",'') || '; ' || COALESCE(""Segment C"",'') || '; ' || COALESCE(""Segment D"",'') AS all_segments
FROM table_1_15187735_13
WHERE ""Segment A"" LIKE '%Watch%' OR ""Segment B"" LIKE '%Watch%' OR ""Segment C"" LIKE '%Watch%' OR ""Segment D"" LIKE '%Watch%'; SELECT topic, COUNT(*) AS occurrences
FROM (
  SELECT ""Segment A"" AS topic FROM table_1_15187735_13 UNION ALL
  SELECT ""Segment B"" FROM table_1_15187735_13 UNION ALL
  SELECT ""Segment C"" FROM table_1_15187735_13 UNION ALL
  SELECT ""Segment D"" FROM table_1_15187735_13
) AS unpivoted
GROUP BY topic
ORDER BY occurrences DESC; SELECT ""Series Ep."", ""Episode"",
  TRIM(
    COALESCE(""Segment A"",'') || CASE WHEN ""Segment A"" IS NOT NULL AND ""Segment B"" IS NOT NULL THEN ', ' ELSE '' END ||
    COALESCE(""Segment B"",'') || CASE WHEN (""Segment B"" IS NOT NULL AND ""Segment C"" IS NOT NULL) THEN ', ' ELSE '' END ||
    COALESCE(""Segment C"",'') || CASE WHEN (""Segment C"" IS NOT NULL AND ""Segment D"" IS NOT NULL) THEN ', ' ELSE '' END ||
    COALESCE(""Segment D"",'')
  ) AS combined_segments
FROM table_1_15187735_13
ORDER BY ""Episode"";",reward,,
"Give me a list (by episode number) of Season 18 episodes where any heavy industrial, food-production, or title-anomaly was detected, and show the matching segment titles.","
WITH tagged AS (
  SELECT
    `Series Ep.`,
    `Episode`,
    `Segment A`,
    `Segment B`,
    `Segment C`,
    `Segment D`,
    -- heavy industrial matching per segment
    LTRIM(
      (CASE WHEN `Segment A` LIKE '%Motor%' OR `Segment A` LIKE '%Plough%' OR `Segment A` LIKE '%Siren%' OR `Segment A` LIKE '%Slicer%' OR `Segment A` LIKE '%Packing%' OR `Segment A` LIKE '%Pre-packaged%' OR `Segment A` LIKE '%Shovel%' OR `Segment A` LIKE '%Paddle%' OR `Segment A` LIKE '%Road Case%' OR `Segment A` LIKE '%Deli%' OR `Segment A` LIKE '%Pipe Cleaners%' OR `Segment A` LIKE '%Telescope%' OR `Segment A` LIKE '%Snow%' OR `Segment A` LIKE '%Fountain%' OR `Segment A` LIKE '%Floating%' OR `Segment A` LIKE '%Motorcycle%' OR `Segment A` LIKE '%Siding%' THEN '|' || `Segment A` ELSE '' END) ||
      (CASE WHEN `Segment B` LIKE '%Motor%' OR `Segment B` LIKE '%Plough%' OR `Segment B` LIKE '%Siren%' OR `Segment B` LIKE '%Slicer%' OR `Segment B` LIKE '%Packing%' OR `Segment B` LIKE '%Pre-packaged%' OR `Segment B` LIKE '%Shovel%' OR `Segment B` LIKE '%Paddle%' OR `Segment B` LIKE '%Road Case%' OR `Segment B` LIKE '%Deli%' OR `Segment B` LIKE '%Pipe Cleaners%' OR `Segment B` LIKE '%Telescope%' OR `Segment B` LIKE '%Snow%' OR `Segment B` LIKE '%Fountain%' OR `Segment B` LIKE '%Floating%' OR `Segment B` LIKE '%Motorcycle%' OR `Segment B` LIKE '%Siding%' THEN '|' || `Segment B` ELSE '' END) ||
      (CASE WHEN `Segment C` LIKE '%Motor%' OR `Segment C` LIKE '%Plough%' OR `Segment C` LIKE '%Siren%' OR `Segment C` LIKE '%Slicer%' OR `Segment C` LIKE '%Packing%' OR `Segment C` LIKE '%Pre-packaged%' OR `Segment C` LIKE '%Shovel%' OR `Segment C` LIKE '%Paddle%' OR `Segment C` LIKE '%Road Case%' OR `Segment C` LIKE '%Deli%' OR `Segment C` LIKE '%Pipe Cleaners%' OR `Segment C` LIKE '%Telescope%' OR `Segment C` LIKE '%Snow%' OR `Segment C` LIKE '%Fountain%' OR `Segment C` LIKE '%Floating%' OR `Segment C` LIKE '%Motorcycle%' OR `Segment C` LIKE '%Siding%' THEN '|' || `Segment C` ELSE '' END) ||
      (CASE WHEN `Segment D` LIKE '%Motor%' OR `Segment D` LIKE '%Plough%' OR `Segment D` LIKE '%Siren%' OR `Segment D` LIKE '%Slicer%' OR `Segment D` LIKE '%Packing%' OR `Segment D` LIKE '%Pre-packaged%' OR `Segment D` LIKE '%Shovel%' OR `Segment D` LIKE '%Paddle%' OR `Segment D` LIKE '%Road Case%' OR `Segment D` LIKE '%Deli%' OR `Segment D` LIKE '%Pipe Cleaners%' OR `Segment D` LIKE '%Telescope%' OR `Segment D` LIKE '%Snow%' OR `Segment D` LIKE '%Fountain%' OR `Segment D` LIKE '%Floating%' OR `Segment D` LIKE '%Motorcycle%' OR `Segment D` LIKE '%Siding%' THEN '|' || `Segment D` ELSE '' END)
    , '|') AS `heavy_segments`,
    -- food / wet / organic production matching per segment
    LTRIM(
      (CASE WHEN `Segment A` LIKE '%Chocolate%' OR `Segment A` LIKE '%Blueberry%' OR `Segment A` LIKE '%Tapioca%' OR `Segment A` LIKE '%Pork%' OR `Segment A` LIKE '%Sandwich%' OR `Segment A` LIKE '%Cheese%' OR `Segment A` LIKE '%Sticky Bun%' OR `Segment A` LIKE '%Chocolate Coins%' OR `Segment A` LIKE '%Deli%' OR `Segment A` LIKE '%Pie%' OR `Segment A` LIKE '%Oyster%' THEN '|' || `Segment A` ELSE '' END) ||
      (CASE WHEN `Segment B` LIKE '%Chocolate%' OR `Segment B` LIKE '%Blueberry%' OR `Segment B` LIKE '%Tapioca%' OR `Segment B` LIKE '%Pork%' OR `Segment B` LIKE '%Sandwich%' OR `Segment B` LIKE '%Cheese%' OR `Segment B` LIKE '%Sticky Bun%' OR `Segment B` LIKE '%Chocolate Coins%' OR `Segment B` LIKE '%Deli%' OR `Segment B` LIKE '%Pie%' OR `Segment B` LIKE '%Oyster%' THEN '|' || `Segment B` ELSE '' END) ||
      (CASE WHEN `Segment C` LIKE '%Chocolate%' OR `Segment C` LIKE '%Blueberry%' OR `Segment C` LIKE '%Tapioca%' OR `Segment C` LIKE '%Pork%' OR `Segment C` LIKE '%Sandwich%' OR `Segment C` LIKE '%Cheese%' OR `Segment C` LIKE '%Sticky Bun%' OR `Segment C` LIKE '%Chocolate Coins%' OR `Segment C` LIKE '%Deli%' OR `Segment C` LIKE '%Pie%' OR `Segment C` LIKE '%Oyster%' THEN '|' || `Segment C` ELSE '' END) ||
      (CASE WHEN `Segment D` LIKE '%Chocolate%' OR `Segment D` LIKE '%Blueberry%' OR `Segment D` LIKE '%Tapioca%' OR `Segment D` LIKE '%Pork%' OR `Segment D` LIKE '%Sandwich%' OR `Segment D` LIKE '%Cheese%' OR `Segment D` LIKE '%Sticky Bun%' OR `Segment D` LIKE '%Chocolate Coins%' OR `Segment D` LIKE '%Deli%' OR `Segment D` LIKE '%Pie%' OR `Segment D` LIKE '%Oyster%' THEN '|' || `Segment D` ELSE '' END)
    , '|') AS `food_segments`,
    -- anomalous / OCR-like leading fragments per segment
    LTRIM(
      (CASE WHEN `Segment A` LIKE 's %' OR `Segment A` LIKE 'ed %' THEN '|' || `Segment A` ELSE '' END) ||
      (CASE WHEN `Segment B` LIKE 's %' OR `Segment B` LIKE 'ed %' THEN '|' || `Segment B` ELSE '' END) ||
      (CASE WHEN `Segment C` LIKE 's %' OR `Segment C` LIKE 'ed %' THEN '|' || `Segment C` ELSE '' END) ||
      (CASE WHEN `Segment D` LIKE 's %' OR `Segment D` LIKE 'ed %' THEN '|' || `Segment D` ELSE '' END)
    , '|') AS `anomalous_segments`,
    -- classify anomaly type with priority: leading_s, leading_ed, embedded_s, ok
    CASE
      WHEN `Segment A` LIKE 's %' OR `Segment B` LIKE 's %' OR `Segment C` LIKE 's %' OR `Segment D` LIKE 's %' THEN 'leading_s'
      WHEN `Segment A` LIKE 'ed %' OR `Segment B` LIKE 'ed %' OR `Segment C` LIKE 'ed %' OR `Segment D` LIKE 'ed %' THEN 'leading_ed'
      WHEN (`Segment A` || ' ' || `Segment B` || ' ' || `Segment C` || ' ' || `Segment D`) LIKE '% s %' THEN 'embedded_s'
      ELSE 'ok'
    END AS `anomaly_type`
  FROM `table_1_15187735_18`
)
SELECT
  `Series Ep.`,
  `Episode`,
  `Segment A`,
  `Segment B`,
  `Segment C`,
  `Segment D`,
  `heavy_segments`,
  `food_segments`,
  `anomaly_type`,
  `anomalous_segments`,
  CASE
    WHEN `heavy_segments` <> '' AND `food_segments` <> '' THEN 'heavy+food (both palettes)'
    WHEN `heavy_segments` <> '' THEN 'heavy_industrial (drone candidates)'
    WHEN `food_segments` <> '' THEN 'food_production (wet/organic texture)'
    ELSE 'none'
  END AS `recommendation`
FROM tagged
WHERE `heavy_segments` <> '' OR `food_segments` <> '' OR `anomaly_type` <> 'ok'
ORDER BY `Episode`;
","
WITH tagged AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    -- heavy industrial matching per segment
    LTRIM(
      (CASE WHEN col2 LIKE '%Motor%' OR col2 LIKE '%Plough%' OR col2 LIKE '%Siren%' OR col2 LIKE '%Slicer%' OR col2 LIKE '%Packing%' OR col2 LIKE '%Pre-packaged%' OR col2 LIKE '%Shovel%' OR col2 LIKE '%Paddle%' OR col2 LIKE '%Road Case%' OR col2 LIKE '%Deli%' OR col2 LIKE '%Pipe Cleaners%' OR col2 LIKE '%Telescope%' OR col2 LIKE '%Snow%' OR col2 LIKE '%Fountain%' OR col2 LIKE '%Floating%' OR col2 LIKE '%Motorcycle%' OR col2 LIKE '%Siding%' THEN '|' || col2 ELSE '' END) ||
      (CASE WHEN col3 LIKE '%Motor%' OR col3 LIKE '%Plough%' OR col3 LIKE '%Siren%' OR col3 LIKE '%Slicer%' OR col3 LIKE '%Packing%' OR col3 LIKE '%Pre-packaged%' OR col3 LIKE '%Shovel%' OR col3 LIKE '%Paddle%' OR col3 LIKE '%Road Case%' OR col3 LIKE '%Deli%' OR col3 LIKE '%Pipe Cleaners%' OR col3 LIKE '%Telescope%' OR col3 LIKE '%Snow%' OR col3 LIKE '%Fountain%' OR col3 LIKE '%Floating%' OR col3 LIKE '%Motorcycle%' OR col3 LIKE '%Siding%' THEN '|' || col3 ELSE '' END) ||
      (CASE WHEN col4 LIKE '%Motor%' OR col4 LIKE '%Plough%' OR col4 LIKE '%Siren%' OR col4 LIKE '%Slicer%' OR col4 LIKE '%Packing%' OR col4 LIKE '%Pre-packaged%' OR col4 LIKE '%Shovel%' OR col4 LIKE '%Paddle%' OR col4 LIKE '%Road Case%' OR col4 LIKE '%Deli%' OR col4 LIKE '%Pipe Cleaners%' OR col4 LIKE '%Telescope%' OR col4 LIKE '%Snow%' OR col4 LIKE '%Fountain%' OR col4 LIKE '%Floating%' OR col4 LIKE '%Motorcycle%' OR col4 LIKE '%Siding%' THEN '|' || col4 ELSE '' END) ||
      (CASE WHEN col5 LIKE '%Motor%' OR col5 LIKE '%Plough%' OR col5 LIKE '%Siren%' OR col5 LIKE '%Slicer%' OR col5 LIKE '%Packing%' OR col5 LIKE '%Pre-packaged%' OR col5 LIKE '%Shovel%' OR col5 LIKE '%Paddle%' OR col5 LIKE '%Road Case%' OR col5 LIKE '%Deli%' OR col5 LIKE '%Pipe Cleaners%' OR col5 LIKE '%Telescope%' OR col5 LIKE '%Snow%' OR col5 LIKE '%Fountain%' OR col5 LIKE '%Floating%' OR col5 LIKE '%Motorcycle%' OR col5 LIKE '%Siding%' THEN '|' || col5 ELSE '' END)
    , '|') AS `heavy_segments`,
    -- food / wet / organic production matching per segment
    LTRIM(
      (CASE WHEN col2 LIKE '%Chocolate%' OR col2 LIKE '%Blueberry%' OR col2 LIKE '%Tapioca%' OR col2 LIKE '%Pork%' OR col2 LIKE '%Sandwich%' OR col2 LIKE '%Cheese%' OR col2 LIKE '%Sticky Bun%' OR col2 LIKE '%Chocolate Coins%' OR col2 LIKE '%Deli%' OR col2 LIKE '%Pie%' OR col2 LIKE '%Oyster%' THEN '|' || col2 ELSE '' END) ||
      (CASE WHEN col3 LIKE '%Chocolate%' OR col3 LIKE '%Blueberry%' OR col3 LIKE '%Tapioca%' OR col3 LIKE '%Pork%' OR col3 LIKE '%Sandwich%' OR col3 LIKE '%Cheese%' OR col3 LIKE '%Sticky Bun%' OR col3 LIKE '%Chocolate Coins%' OR col3 LIKE '%Deli%' OR col3 LIKE '%Pie%' OR col3 LIKE '%Oyster%' THEN '|' || col3 ELSE '' END) ||
      (CASE WHEN col4 LIKE '%Chocolate%' OR col4 LIKE '%Blueberry%' OR col4 LIKE '%Tapioca%' OR col4 LIKE '%Pork%' OR col4 LIKE '%Sandwich%' OR col4 LIKE '%Cheese%' OR col4 LIKE '%Sticky Bun%' OR col4 LIKE '%Chocolate Coins%' OR col4 LIKE '%Deli%' OR col4 LIKE '%Pie%' OR col4 LIKE '%Oyster%' THEN '|' || col4 ELSE '' END) ||
      (CASE WHEN col5 LIKE '%Chocolate%' OR col5 LIKE '%Blueberry%' OR col5 LIKE '%Tapioca%' OR col5 LIKE '%Pork%' OR col5 LIKE '%Sandwich%' OR col5 LIKE '%Cheese%' OR col5 LIKE '%Sticky Bun%' OR col5 LIKE '%Chocolate Coins%' OR col5 LIKE '%Deli%' OR col5 LIKE '%Pie%' OR col5 LIKE '%Oyster%' THEN '|' || col5 ELSE '' END)
    , '|') AS `food_segments`,
    -- anomalous / OCR-like leading fragments per segment
    LTRIM(
      (CASE WHEN col2 LIKE 's %' OR col2 LIKE 'ed %' THEN '|' || col2 ELSE '' END) ||
      (CASE WHEN col3 LIKE 's %' OR col3 LIKE 'ed %' THEN '|' || col3 ELSE '' END) ||
      (CASE WHEN col4 LIKE 's %' OR col4 LIKE 'ed %' THEN '|' || col4 ELSE '' END) ||
      (CASE WHEN col5 LIKE 's %' OR col5 LIKE 'ed %' THEN '|' || col5 ELSE '' END)
    , '|') AS `anomalous_segments`,
    -- classify anomaly type with priority: leading_s, leading_ed, embedded_s, ok
    CASE
      WHEN col2 LIKE 's %' OR col3 LIKE 's %' OR col4 LIKE 's %' OR col5 LIKE 's %' THEN 'leading_s'
      WHEN col2 LIKE 'ed %' OR col3 LIKE 'ed %' OR col4 LIKE 'ed %' OR col5 LIKE 'ed %' THEN 'leading_ed'
      WHEN (col2 || ' ' || col3 || ' ' || col4 || ' ' || col5) LIKE '% s %' THEN 'embedded_s'
      ELSE 'ok'
    END AS `anomaly_type`
  FROM `table_1_15187735_18`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  `heavy_segments`,
  `food_segments`,
  `anomaly_type`,
  `anomalous_segments`,
  CASE
    WHEN `heavy_segments` <> '' AND `food_segments` <> '' THEN 'heavy+food (both palettes)'
    WHEN `heavy_segments` <> '' THEN 'heavy_industrial (drone candidates)'
    WHEN `food_segments` <> '' THEN 'food_production (wet/organic texture)'
    ELSE 'none'
  END AS `recommendation`
FROM tagged
WHERE `heavy_segments` <> '' OR `food_segments` <> '' OR `anomaly_type` <> 'ok'
ORDER BY col1;
","[('18-01', 222.0, 'ed pattern glass panels', 's road case', 'stop-frame animation (part 1)', 'stop-frame animation (part 2)', 's road case', '', 'leading_s', 'ed pattern glass panels|s road case', 'heavy_industrial (drone candidates)'), ('18-02', 223.0, 'industrial wire s rope', 'living walls', 'large format cameras', 's gemstone', '', '', 'leading_s', 's gemstone', 'none'), ('18-03', 224.0, 'chocolate coins', 'floor heating system', 'pedal cars', 'latex swords', '', 'chocolate coins', 'ok', '', 'food_production (wet/organic texture)'), ('18-04', 225.0, 'ed farm caviar', 'intake s manifold', 'motorcycle s jacket', 'shovels & s spade', 'motorcycle s jacket|shovels & s spade', '', 'leading_ed', 'ed farm caviar', 'heavy_industrial (drone candidates)'), ('18-05', 226.0, 'wax figures', 's awning', 'sandwich s cracker', 'pewter s tankard', '', 'sandwich s cracker', 'leading_s', 's awning', 'food_production (wet/organic texture)'), ('18-06', 227.0, 'pipe cleaners', 'blue stilton cheese', 'smart electric meters', 'telescopes', 'pipe cleaners|telescopes', 'blue stilton cheese', 'ok', '', 'heavy+food (both palettes)'), ('18-07', 228.0, 'fish s replica', 'siren s system', 'pre-packaged sandwiches', 's candlestick', 'siren s system|pre-packaged sandwiches', 'pre-packaged sandwiches', 'leading_s', 's candlestick', 'heavy+food (both palettes)'), ('18-08', 229.0, 'tapioca pudding', 'snow ploughs', 'paddle s boat', 'fibre cement siding', 'snow ploughs|paddle s boat|fibre cement siding', 'tapioca pudding', 'embedded_s', '', 'heavy+food (both palettes)'), ('18-09', 230.0, 's rally car', 'pork s pie', 'floating fountains', 'artificial stone s ornament', 'floating fountains', 'pork s pie', 'leading_s', 's rally car', 'heavy+food (both palettes)'), ('18-10', 231.0, 's cufflink', 'blueberry s turnover', 's dashboard', 'earthenware pottery', '', 'blueberry s turnover', 'leading_s', 's cufflink|s dashboard', 'food_production (wet/organic texture)'), ('18-11', 232.0, 'pharmaceutical blister packs', 'deli slicers', 's oyster', 's weathervane', 'deli slicers', 'deli slicers|s oyster', 'leading_s', 's oyster|s weathervane', 'heavy+food (both palettes)'), ('18-12', 233.0, 'top & bowler hats', 'solar water heaters', 's sticky bun', 'electrostatic s speaker', '', 's sticky bun', 'leading_s', 's sticky bun', 'food_production (wet/organic texture)')]",table_1_15187735_18,"I'll ask for a concise, ordered shortlist since I'm preparing timecode correction and audio pulls and I care about episode order. The SQL filters to episodes where heavy_segments or food_segments or anomaly_type <> 'ok' and orders results by Episode. The schema provides episode numbers and the four segment title fields, plus the constructed heavy_segments/food_segments/anomalous_segments. Draft question: ask for a listing of episodes (in episode order) where any heavy, food, or title-anomaly matches occurred, showing which segment titles matched. This mirrors the WHERE and ORDER BY behavior and the selected output columns.",persona,"An acoustic archaeologist / immersive soundscape curator assembling authentic manufacturing sound layers from Season 18 of 'How It's Made' for a museum installation. Goals: Locate episodes and specific segments that contain continuous mechanical, packaging, or cutting noises (good for long drone/background tracks). Separate food-production segments (distinct wet/organic sounds) from heavy-industrial segments to build contrasting audio palettes. Detect metadata/OCR anomalies in segment titles (e.g., truncated words like leading ""s"" or ""ed"") so the curator can request corrected transcripts and accurate timecodes before audio extraction. Example Queries: SELECT ""Series Ep."", Episode, ""Segment A"", ""Segment B"", ""Segment C"", ""Segment D"" FROM table_1_15187735_18 WHERE CONCAT(""Segment A"", ' ', ""Segment B"", ' ', ""Segment C"", ' ', ""Segment D"") REGEXP 'Motor|Plough|Siren|Slicer|Packing|Pre-packaged|Snow|Shovels|Paddle|Road Case|Deli|Pipe Cleaners|Telescope' ORDER BY Episode; SELECT ""Series Ep."", Episode, ""Segment A"", ""Segment B"", ""Segment C"", ""Segment D"" FROM table_1_15187735_18 WHERE CONCAT(""Segment A"", ' ', ""Segment B"", ' ', ""Segment C"", ' ', ""Segment D"") REGEXP 'Chocolate|Blueberry|Tapioca|Pork|Sandwich|Cheese|Sticky Bun|Chocolate Coins|Pre-packaged Sandwiches' ORDER BY Episode; SELECT ""Series Ep."", Episode, CASE WHEN ""Segment A"" LIKE 's %' OR ""Segment B"" LIKE 's %' OR ""Segment C"" LIKE 's %' OR ""Segment D"" LIKE 's %' THEN 'leading_s' WHEN ""Segment A"" LIKE 'ed %' OR ""Segment B"" LIKE 'ed %' OR ""Segment C"" LIKE 'ed %' OR ""Segment D"" LIKE 'ed %' THEN 'leading_ed' WHEN CONCAT(""Segment A"", ' ', ""Segment B"", ' ', ""Segment C"", ' ', ""Segment D"") LIKE '% s %' THEN 'embedded_s' ELSE 'ok' END AS issue FROM table_1_15187735_18 WHERE ""Segment A"" LIKE 's %' OR ""Segment B"" LIKE 's %' OR ""Segment C"" LIKE 's %' OR ""Segment D"" LIKE 's %' OR ""Segment A"" LIKE 'ed %' OR ""Segment B"" LIKE 'ed %' OR ""Segment C"" LIKE 'ed %' OR ""Segment D"" LIKE 'ed %' OR CONCAT(""Segment A"", ' ', ""Segment B"", ' ', ""Segment C"", ' ', ""Segment D"") LIKE '% s %';",reward,,
"Provide the distinct Episode values as EpisodePair (ordered ascending and limited to 5) for episodes where Episode > 260 and the first word of Segment A (the substring up to the first space, or the whole Segment A if no space) is equal to the first word of Segment B (the substring up to the first space, or the whole Segment B if no space) in a different episode (i.e., the Episode values are not the same).","
SELECT DISTINCT t1.`Episode` AS `EpisodePair`
FROM `table_1_15187735_21` t1 JOIN `table_1_15187735_21` t2 ON
substr(t1.`Segment A`,1,IIF(instr(t1.`Segment A`,' ')=0,length(t1.`Segment A`),instr(t1.`Segment A`,' ')-1))
=
substr(t2.`Segment B`,1,IIF(instr(t2.`Segment B`,' ')=0,length(t2.`Segment B`),instr(t2.`Segment B`,' ')-1))
WHERE t1.`Episode` != t2.`Episode` AND t1.`Episode` > 260
ORDER BY `EpisodePair`
LIMIT 5;
","
SELECT DISTINCT t1.col1 AS `EpisodePair`
FROM `table_1_15187735_21` t1 JOIN `table_1_15187735_21` t2 ON
substr(t1.col2,1,IIF(instr(t1.col2,' ')=0,length(t1.col2),instr(t1.col2,' ')-1))
=
substr(t2.col3,1,IIF(instr(t2.col3,' ')=0,length(t2.col3),instr(t2.col3,' ')-1))
WHERE t1.col1 != t2.col1 AND t1.col1 > 260
ORDER BY `EpisodePair`
LIMIT 5;
","[(267.0,)]",table_1_15187735_21,"Parse: the query selects distinct Episode values where the leading substring (first word) of Segment A equals the leading substring of Segment B from a different row, only for Episode > 260, ordered and limited to 5. Map schema: Episode, Segment A, Segment B are the relevant columns. Draft: formulate question requesting EpisodePair results with all specified substring logic, episode inequality, Episode > 260, ORDER BY and LIMIT 5. Validate: ensure mention of alias EpisodePair, first-word extraction rule, different episodes, Episode > 260, ordering and limit.",reserved,11,reward,,
"Produce a combined report that lists, first, Season 3 episodes that pair a food/organic segment with an industrial/chemical segment (showing episode codes, Netflix IDs, and which segments are the food vs industrial parts), and then list each occurrence of any of my distinctive segments with their episode metadata.","
SELECT
  'paired_episode' AS `row_type`,
  `Series Ep.`,
  `Episode`,
  `Netflix`,
  (
    (CASE WHEN `Segment A` IN ('Cranberries','Vegetable Oil','Yogurt','Dog and Cat Food','Prepared Mustard','Tofu','Couscous','Phyllo Dough','Chicken','Fresh Cut Flowers','Hard Candies') THEN '`' || `Segment A` || '`' || ', ' ELSE '' END)
  || (CASE WHEN `Segment B` IN ('Cranberries','Vegetable Oil','Yogurt','Dog and Cat Food','Prepared Mustard','Tofu','Couscous','Phyllo Dough','Chicken','Fresh Cut Flowers','Hard Candies') THEN '`' || `Segment B` || '`' || ', ' ELSE '' END)
  || (CASE WHEN `Segment C` IN ('Cranberries','Vegetable Oil','Yogurt','Dog and Cat Food','Prepared Mustard','Tofu','Couscous','Phyllo Dough','Chicken','Fresh Cut Flowers','Hard Candies') THEN '`' || `Segment C` || '`' || ', ' ELSE '' END)
  || (CASE WHEN `Segment D` IN ('Cranberries','Vegetable Oil','Yogurt','Dog and Cat Food','Prepared Mustard','Tofu','Couscous','Phyllo Dough','Chicken','Fresh Cut Flowers','Hard Candies') THEN '`' || `Segment D` || '`' || ', ' ELSE '' END)
  ) AS `Food_Segments`,
  (
    (CASE WHEN `Segment A` IN ('Asphalt Shingles','Expanded Polystyrene Products','Neon Signs','Adhesive Tape','PVC Gloves','Thermo-formed Glass','Temporary Metal Fences','Combination Locks','Wheel Loaders','Car Radiators','Electric Baseboard Heaters','Inflatable Watercraft','Wind Generators','ed Mould Pulp Containers') THEN '`' || `Segment A` || '`' || ', ' ELSE '' END)
  || (CASE WHEN `Segment B` IN ('Asphalt Shingles','Expanded Polystyrene Products','Neon Signs','Adhesive Tape','PVC Gloves','Thermo-formed Glass','Temporary Metal Fences','Combination Locks','Wheel Loaders','Car Radiators','Electric Baseboard Heaters','Inflatable Watercraft','Wind Generators','ed Mould Pulp Containers') THEN '`' || `Segment B` || '`' || ', ' ELSE '' END)
  || (CASE WHEN `Segment C` IN ('Asphalt Shingles','Expanded Polystyrene Products','Neon Signs','Adhesive Tape','PVC Gloves','Thermo-formed Glass','Temporary Metal Fences','Combination Locks','Wheel Loaders','Car Radiators','Electric Baseboard Heaters','Inflatable Watercraft','Wind Generators','ed Mould Pulp Containers') THEN '`' || `Segment C` || '`' || ', ' ELSE '' END)
  || (CASE WHEN `Segment D` IN ('Asphalt Shingles','Expanded Polystyrene Products','Neon Signs','Adhesive Tape','PVC Gloves','Thermo-formed Glass','Temporary Metal Fences','Combination Locks','Wheel Loaders','Car Radiators','Electric Baseboard Heaters','Inflatable Watercraft','Wind Generators','ed Mould Pulp Containers') THEN '`' || `Segment D` || '`' || ', ' ELSE '' END)
  ) AS `Industrial_Segments`,
  (CASE WHEN (
       `Segment A` IN ('Candles','Asphalt Shingles','Fresh Cut Flowers','Neon Signs','Vegetable Oil','Yogurt','Tofu','Phyllo Dough','Chicken','Hard Candies')
    OR `Segment B` IN ('Candles','Asphalt Shingles','Fresh Cut Flowers','Neon Signs','Vegetable Oil','Yogurt','Tofu','Phyllo Dough','Chicken','Hard Candies')
    OR `Segment C` IN ('Candles','Asphalt Shingles','Fresh Cut Flowers','Neon Signs','Vegetable Oil','Yogurt','Tofu','Phyllo Dough','Chicken','Hard Candies')
    OR `Segment D` IN ('Candles','Asphalt Shingles','Fresh Cut Flowers','Neon Signs','Vegetable Oil','Yogurt','Tofu','Phyllo Dough','Chicken','Hard Candies')
  ) THEN 1 ELSE 0 END) AS `Distinctive_Flag`
FROM `table_1_15187735_3`
WHERE (
      `Segment A` IN ('Cranberries','Vegetable Oil','Yogurt','Dog and Cat Food','Prepared Mustard','Tofu','Couscous','Phyllo Dough','Chicken','Fresh Cut Flowers','Hard Candies')
   OR `Segment B` IN ('Cranberries','Vegetable Oil','Yogurt','Dog and Cat Food','Prepared Mustard','Tofu','Couscous','Phyllo Dough','Chicken','Fresh Cut Flowers','Hard Candies')
   OR `Segment C` IN ('Cranberries','Vegetable Oil','Yogurt','Dog and Cat Food','Prepared Mustard','Tofu','Couscous','Phyllo Dough','Chicken','Fresh Cut Flowers','Hard Candies')
   OR `Segment D` IN ('Cranberries','Vegetable Oil','Yogurt','Dog and Cat Food','Prepared Mustard','Tofu','Couscous','Phyllo Dough','Chicken','Fresh Cut Flowers','Hard Candies')
)
AND (
      `Segment A` IN ('Asphalt Shingles','Expanded Polystyrene Products','Neon Signs','Adhesive Tape','PVC Gloves','Thermo-formed Glass','Temporary Metal Fences','Combination Locks','Wheel Loaders','Car Radiators','Electric Baseboard Heaters','Inflatable Watercraft','Wind Generators','ed Mould Pulp Containers')
   OR `Segment B` IN ('Asphalt Shingles','Expanded Polystyrene Products','Neon Signs','Adhesive Tape','PVC Gloves','Thermo-formed Glass','Temporary Metal Fences','Combination Locks','Wheel Loaders','Car Radiators','Electric Baseboard Heaters','Inflatable Watercraft','Wind Generators','ed Mould Pulp Containers')
   OR `Segment C` IN ('Asphalt Shingles','Expanded Polystyrene Products','Neon Signs','Adhesive Tape','PVC Gloves','Thermo-formed Glass','Temporary Metal Fences','Combination Locks','Wheel Loaders','Car Radiators','Electric Baseboard Heaters','Inflatable Watercraft','Wind Generators','ed Mould Pulp Containers')
   OR `Segment D` IN ('Asphalt Shingles','Expanded Polystyrene Products','Neon Signs','Adhesive Tape','PVC Gloves','Thermo-formed Glass','Temporary Metal Fences','Combination Locks','Wheel Loaders','Car Radiators','Electric Baseboard Heaters','Inflatable Watercraft','Wind Generators','ed Mould Pulp Containers')
)
UNION ALL
SELECT
  'distinctive_segment' AS `row_type`,
  `Series Ep.`,
  `Episode`,
  `Netflix`,
  '`' || `segment` || '`' AS `Food_Segments`,
  NULL AS `Industrial_Segments`,
  NULL AS `Distinctive_Flag`
FROM (
  SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment A` AS `segment` FROM `table_1_15187735_3`
  UNION ALL SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment B` FROM `table_1_15187735_3`
  UNION ALL SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment C` FROM `table_1_15187735_3`
  UNION ALL SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment D` FROM `table_1_15187735_3`
) AS `all_segments`
WHERE `segment` IN ('Candles','Asphalt Shingles','Fresh Cut Flowers','Neon Signs','Vegetable Oil','Yogurt','Tofu','Phyllo Dough','Chicken','Hard Candies')
ORDER BY `row_type` DESC, `Series Ep.`, `Episode`;
","SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  col6,
  (CASE WHEN (
     col3 LIKE '%Cranberries%' OR col4 LIKE '%Cranberries%' OR col5 LIKE '%Cranberries%' OR col6 LIKE '%Cranberries%'
     OR col3 LIKE '%Vegetable Oil%' OR col4 LIKE '%Vegetable Oil%' OR col5 LIKE '%Vegetable Oil%' OR col6 LIKE '%Vegetable Oil%'
     OR col3 LIKE '%Yogurt%' OR col4 LIKE '%Yogurt%' OR col5 LIKE '%Yogurt%' OR col6 LIKE '%Yogurt%'
     OR col3 LIKE '%Dog and Cat Food%' OR col4 LIKE '%Dog and Cat Food%' OR col5 LIKE '%Dog and Cat Food%' OR col6 LIKE '%Dog and Cat Food%'
     OR col3 LIKE '%Prepared Mustard%' OR col4 LIKE '%Prepared Mustard%' OR col5 LIKE '%Prepared Mustard%' OR col6 LIKE '%Prepared Mustard%'
     OR col3 LIKE '%Tofu%' OR col4 LIKE '%Tofu%' OR col5 LIKE '%Tofu%' OR col6 LIKE '%Tofu%'
     OR col3 LIKE '%Couscous%' OR col4 LIKE '%Couscous%' OR col5 LIKE '%Couscous%' OR col6 LIKE '%Couscous%'
     OR col3 LIKE '%Phyllo Dough%' OR col4 LIKE '%Phyllo Dough%' OR col5 LIKE '%Phyllo Dough%' OR col6 LIKE '%Phyllo Dough%'
     OR col3 LIKE '%Chicken%' OR col4 LIKE '%Chicken%' OR col5 LIKE '%Chicken%' OR col6 LIKE '%Chicken%'
     OR col3 LIKE '%Hard Candies%' OR col4 LIKE '%Hard Candies%' OR col5 LIKE '%Hard Candies%' OR col6 LIKE '%Hard Candies%'
     OR col3 LIKE '%Fresh Cut Flowers%' OR col4 LIKE '%Fresh Cut Flowers%' OR col5 LIKE '%Fresh Cut Flowers%' OR col6 LIKE '%Fresh Cut Flowers%'
  ) THEN 1 ELSE 0 END) AS `Food_Found`,
  (CASE WHEN (
     col3 LIKE '%Asphalt%' OR col4 LIKE '%Asphalt%' OR col5 LIKE '%Asphalt%' OR col6 LIKE '%Asphalt%'
     OR col3 LIKE '%Asphalt Shingles%' OR col4 LIKE '%Asphalt Shingles%' OR col5 LIKE '%Asphalt Shingles%' OR col6 LIKE '%Asphalt Shingles%'
     OR col3 LIKE '%Expanded Polystyrene%' OR col4 LIKE '%Expanded Polystyrene%' OR col5 LIKE '%Expanded Polystyrene%' OR col6 LIKE '%Expanded Polystyrene%'
     OR col3 LIKE '%Neon Signs%' OR col4 LIKE '%Neon Signs%' OR col5 LIKE '%Neon Signs%' OR col6 LIKE '%Neon Signs%'
     OR col3 LIKE '%Adhesive Tape%' OR col4 LIKE '%Adhesive Tape%' OR col5 LIKE '%Adhesive Tape%' OR col6 LIKE '%Adhesive Tape%'
     OR col3 LIKE '%PVC%' OR col4 LIKE '%PVC%' OR col5 LIKE '%PVC%' OR col6 LIKE '%PVC%'
     OR col3 LIKE '%Thermo-formed Glass%' OR col4 LIKE '%Thermo-formed Glass%' OR col5 LIKE '%Thermo-formed Glass%' OR col6 LIKE '%Thermo-formed Glass%'
     OR col3 LIKE '%Temporary Metal Fences%' OR col4 LIKE '%Temporary Metal Fences%' OR col5 LIKE '%Temporary Metal Fences%' OR col6 LIKE '%Temporary Metal Fences%'
     OR col3 LIKE '%Inflatable Watercraft%' OR col4 LIKE '%Inflatable Watercraft%' OR col5 LIKE '%Inflatable Watercraft%' OR col6 LIKE '%Inflatable Watercraft%'
     OR col3 LIKE '%Wind Generators%' OR col4 LIKE '%Wind Generators%' OR col5 LIKE '%Wind Generators%' OR col6 LIKE '%Wind Generators%'
     OR col3 LIKE '%Car Radiators%' OR col4 LIKE '%Car Radiators%' OR col5 LIKE '%Car Radiators%' OR col6 LIKE '%Car Radiators%'
     OR col3 LIKE '%Electric Baseboard Heaters%' OR col4 LIKE '%Electric Baseboard Heaters%' OR col5 LIKE '%Electric Baseboard Heaters%' OR col6 LIKE '%Electric Baseboard Heaters%'
     OR col3 LIKE '%Wheel Loaders%' OR col4 LIKE '%Wheel Loaders%' OR col5 LIKE '%Wheel Loaders%' OR col6 LIKE '%Wheel Loaders%'
     OR col3 LIKE '%Combination Locks%' OR col4 LIKE '%Combination Locks%' OR col5 LIKE '%Combination Locks%' OR col6 LIKE '%Combination Locks%'
     OR col3 LIKE '%Mould Pulp%' OR col4 LIKE '%Mould Pulp%' OR col5 LIKE '%Mould Pulp%' OR col6 LIKE '%Mould Pulp%'
  ) THEN 1 ELSE 0 END) AS `Industrial_Found`,
  (CASE WHEN (
     col3 LIKE '%Candles%' OR col4 LIKE '%Candles%' OR col5 LIKE '%Candles%' OR col6 LIKE '%Candles%'
     OR col3 LIKE '%Asphalt%' OR col4 LIKE '%Asphalt%' OR col5 LIKE '%Asphalt%' OR col6 LIKE '%Asphalt%'
     OR col3 LIKE '%Fresh Cut Flowers%' OR col4 LIKE '%Fresh Cut Flowers%' OR col5 LIKE '%Fresh Cut Flowers%' OR col6 LIKE '%Fresh Cut Flowers%'
     OR col3 LIKE '%Neon Signs%' OR col4 LIKE '%Neon Signs%' OR col5 LIKE '%Neon Signs%' OR col6 LIKE '%Neon Signs%'
     OR col3 LIKE '%Vegetable Oil%' OR col4 LIKE '%Vegetable Oil%' OR col5 LIKE '%Vegetable Oil%' OR col6 LIKE '%Vegetable Oil%'
     OR col3 LIKE '%Yogurt%' OR col4 LIKE '%Yogurt%' OR col5 LIKE '%Yogurt%' OR col6 LIKE '%Yogurt%'
     OR col3 LIKE '%Tofu%' OR col4 LIKE '%Tofu%' OR col5 LIKE '%Tofu%' OR col6 LIKE '%Tofu%'
     OR col3 LIKE '%Phyllo Dough%' OR col4 LIKE '%Phyllo Dough%' OR col5 LIKE '%Phyllo Dough%' OR col6 LIKE '%Phyllo Dough%'
     OR col3 LIKE '%Hard Candies%' OR col4 LIKE '%Hard Candies%' OR col5 LIKE '%Hard Candies%' OR col6 LIKE '%Hard Candies%'
  ) THEN 1 ELSE 0 END) AS `Distinctive_Flag`
FROM `table_1_15187735_3`
WHERE (
  col3 LIKE '%Cranberries%' OR col4 LIKE '%Cranberries%' OR col5 LIKE '%Cranberries%' OR col6 LIKE '%Cranberries%'
  OR col3 LIKE '%Vegetable Oil%' OR col4 LIKE '%Vegetable Oil%' OR col5 LIKE '%Vegetable Oil%' OR col6 LIKE '%Vegetable Oil%'
  OR col3 LIKE '%Yogurt%' OR col4 LIKE '%Yogurt%' OR col5 LIKE '%Yogurt%' OR col6 LIKE '%Yogurt%'
  OR col3 LIKE '%Dog and Cat Food%' OR col4 LIKE '%Dog and Cat Food%' OR col5 LIKE '%Dog and Cat Food%' OR col6 LIKE '%Dog and Cat Food%'
  OR col3 LIKE '%Prepared Mustard%' OR col4 LIKE '%Prepared Mustard%' OR col5 LIKE '%Prepared Mustard%' OR col6 LIKE '%Prepared Mustard%'
  OR col3 LIKE '%Tofu%' OR col4 LIKE '%Tofu%' OR col5 LIKE '%Tofu%' OR col6 LIKE '%Tofu%'
  OR col3 LIKE '%Couscous%' OR col4 LIKE '%Couscous%' OR col5 LIKE '%Couscous%' OR col6 LIKE '%Couscous%'
  OR col3 LIKE '%Phyllo Dough%' OR col4 LIKE '%Phyllo Dough%' OR col5 LIKE '%Phyllo Dough%' OR col6 LIKE '%Phyllo Dough%'
  OR col3 LIKE '%Chicken%' OR col4 LIKE '%Chicken%' OR col5 LIKE '%Chicken%' OR col6 LIKE '%Chicken%'
  OR col3 LIKE '%Hard Candies%' OR col4 LIKE '%Hard Candies%' OR col5 LIKE '%Hard Candies%' OR col6 LIKE '%Hard Candies%'
  OR col3 LIKE '%Fresh Cut Flowers%' OR col4 LIKE '%Fresh Cut Flowers%' OR col5 LIKE '%Fresh Cut Flowers%' OR col6 LIKE '%Fresh Cut Flowers%'
  OR col3 LIKE '%Candles%' OR col4 LIKE '%Candles%' OR col5 LIKE '%Candles%' OR col6 LIKE '%Candles%'
  OR col3 LIKE '%Asphalt%' OR col4 LIKE '%Asphalt%' OR col5 LIKE '%Asphalt%' OR col6 LIKE '%Asphalt%'
  OR col3 LIKE '%Neon Signs%' OR col4 LIKE '%Neon Signs%' OR col5 LIKE '%Neon Signs%' OR col6 LIKE '%Neon Signs%'
);
","[('3-01', 27.0, 's02e01', 'pre-inked stamps', 'cranberries', 'cotton yarn', 'road signs', 1, 0, 0), ('3-03', 29.0, 's02e03', 'wheel loaders', 'vegetable oil', 'hand tools', 'cotton swabs', 1, 1, 1), ('3-04', 30.0, 's02e04', 'temporary metal fences', 'asphalt shingles', 'expanded polystyrene products', 'hard candies', 1, 1, 1), ('3-05', 31.0, 's02e05', 's horse-drawn carriage', 'artificial eyes', 'dog and cat food', 's mirror', 1, 0, 0), ('3-06', 32.0, 's02e06', 'yogurt', 'candles', 'neon signs', 's bookbinding', 1, 1, 1), ('3-07', 33.0, 's02e07', 'prepared mustard', 's violin', 'nuts and bolts', 'toilet paper', 1, 0, 0), ('3-08', 34.0, 's02e08', 'fresh cut flowers', 'adhesive tape', 'tofu', 's lottery ticket', 1, 1, 1), ('3-09', 35.0, 's02e09', 'inflatable watercraft', 'couscous', 'modelling dough', 'wicker products', 1, 1, 0), ('3-11', 37.0, 's02e11', 'car radiators', 'hatchery chicks', 'phyllo dough', 'cross-country skis', 1, 1, 1), ('3-12', 38.0, 's02e12', 'electric baseboard heaters', 'ed mould pulp containers', 'chicken', 's video game', 1, 1, 0)]",table_1_15187735_3,"I'm likely to ask for a combined, ordered output as a curator: paired episodes first, then single distinctive-segment hits, so I can triage scouting and licensing. The SQL produces two row types ('paired_episode' and 'distinctive_segment') and orders them so the paired episodes come before the single-segment rows. The schema supplies episode identifiers and the concatenated food/industrial lists for paired rows and single-segment rows for distinctive items. Draft question: ask for a combined report that lists paired episodes first then the distinctive-segment occurrences, with episode metadata. Validation: this maps to the UNION ALL and the ORDER BY row_type, Series Ep., Episode in the query.",persona,"An olfactory historian-perfumer who composes site-specific 'manufacturing-smell' installations inspired by How It's Made episodes in Season 3. Goals: Identify episodes that feature edible or organic items (top/mid-note sources) so I can sample authentic raw materials or reference aromas. Find episodes where a food/organic segment is paired with an industrial/chemical segment to design contrasting scent layers (e.g., yogurt + asphalt). Compile a shortlist of segments with strong, distinctive odor associations (candles, asphalt, fresh cut flowers, neon signs, cooking oils, etc.) and get their episode metadata for licensing and exhibit labels. Example Queries: SELECT ""Series Ep."", ""Episode"", ""Netflix"", ""Segment A"", ""Segment B"", ""Segment C"", ""Segment D"" 
FROM table_1_15187735_3
WHERE ""Segment A"" LIKE '%Cranberries%' OR ""Segment B"" LIKE '%Cranberries%' OR ""Segment C"" LIKE '%Cranberries%' OR ""Segment D"" LIKE '%Cranberries%'
   OR ""Segment A"" LIKE '%Vegetable Oil%' OR ""Segment B"" LIKE '%Vegetable Oil%' OR ""Segment C"" LIKE '%Vegetable Oil%' OR ""Segment D"" LIKE '%Vegetable Oil%'
   OR ""Segment A"" LIKE '%Yogurt%' OR ""Segment B"" LIKE '%Yogurt%' OR ""Segment C"" LIKE '%Yogurt%' OR ""Segment D"" LIKE '%Yogurt%'
   OR ""Segment A"" LIKE '%Hard Candies%' OR ""Segment B"" LIKE '%Hard Candies%' OR ""Segment C"" LIKE '%Hard Candies%' OR ""Segment D"" LIKE '%Hard Candies%'
   OR ""Segment A"" LIKE '%Dog and Cat Food%' OR ""Segment B"" LIKE '%Dog and Cat Food%' OR ""Segment C"" LIKE '%Dog and Cat Food%' OR ""Segment D"" LIKE '%Dog and Cat Food%'
   OR ""Segment A"" LIKE '%Prepared Mustard%' OR ""Segment B"" LIKE '%Prepared Mustard%' OR ""Segment C"" LIKE '%Prepared Mustard%' OR ""Segment D"" LIKE '%Prepared Mustard%'
   OR ""Segment A"" LIKE '%Tofu%' OR ""Segment B"" LIKE '%Tofu%' OR ""Segment C"" LIKE '%Tofu%' OR ""Segment D"" LIKE '%Tofu%'
   OR ""Segment A"" LIKE '%Couscous%' OR ""Segment B"" LIKE '%Couscous%' OR ""Segment C"" LIKE '%Couscous%' OR ""Segment D"" LIKE '%Couscous%'
   OR ""Segment A"" LIKE '%Phyllo Dough%' OR ""Segment B"" LIKE '%Phyllo Dough%' OR ""Segment C"" LIKE '%Phyllo Dough%' OR ""Segment D"" LIKE '%Phyllo Dough%'
   OR ""Segment A"" LIKE '%Chicken%' OR ""Segment B"" LIKE '%Chicken%' OR ""Segment C"" LIKE '%Chicken%' OR ""Segment D"" LIKE '%Chicken%'; SELECT ""Series Ep."", ""Episode"", ""Netflix"", ""Segment A"", ""Segment B"", ""Segment C"", ""Segment D""
FROM table_1_15187735_3
WHERE (
      ""Segment A"" LIKE '%Yogurt%' OR ""Segment B"" LIKE '%Yogurt%' OR ""Segment C"" LIKE '%Yogurt%' OR ""Segment D"" LIKE '%Yogurt%'
   OR ""Segment A"" LIKE '%Chicken%' OR ""Segment B"" LIKE '%Chicken%' OR ""Segment C"" LIKE '%Chicken%' OR ""Segment D"" LIKE '%Chicken%'
   OR ""Segment A"" LIKE '%Couscous%' OR ""Segment B"" LIKE '%Couscous%' OR ""Segment C"" LIKE '%Couscous%' OR ""Segment D"" LIKE '%Couscous%'
)
AND (
      ""Segment A"" LIKE '%PVC%' OR ""Segment B"" LIKE '%PVC%' OR ""Segment C"" LIKE '%PVC%' OR ""Segment D"" LIKE '%PVC%'
   OR ""Segment A"" LIKE '%Asphalt%' OR ""Segment B"" LIKE '%Asphalt%' OR ""Segment C"" LIKE '%Asphalt%' OR ""Segment D"" LIKE '%Asphalt%'
   OR ""Segment A"" LIKE '%Expanded Polystyrene%' OR ""Segment B"" LIKE '%Expanded Polystyrene%' OR ""Segment C"" LIKE '%Expanded Polystyrene%' OR ""Segment D"" LIKE '%Expanded Polystyrene%'
   OR ""Segment A"" LIKE '%Thermo-formed Glass%' OR ""Segment B"" LIKE '%Thermo-formed Glass%' OR ""Segment C"" LIKE '%Thermo-formed Glass%' OR ""Segment D"" LIKE '%Thermo-formed Glass%'
   OR ""Segment A"" LIKE '%Adhesive Tape%' OR ""Segment B"" LIKE '%Adhesive Tape%' OR ""Segment C"" LIKE '%Adhesive Tape%' OR ""Segment D"" LIKE '%Adhesive Tape%'
); SELECT DISTINCT segment, ""Series Ep."", ""Netflix""
FROM (
  SELECT ""Series Ep."", ""Netflix"", ""Segment A"" AS segment FROM table_1_15187735_3
  UNION ALL SELECT ""Series Ep."", ""Netflix"", ""Segment B"" FROM table_1_15187735_3
  UNION ALL SELECT ""Series Ep."", ""Netflix"", ""Segment C"" FROM table_1_15187735_3
  UNION ALL SELECT ""Series Ep."", ""Netflix"", ""Segment D"" FROM table_1_15187735_3
) AS all_segments
WHERE segment LIKE '%Candles%' OR segment LIKE '%Asphalt%' OR segment LIKE '%Fresh Cut Flowers%' OR segment LIKE '%Neon Signs%'
   OR segment LIKE '%Vegetable Oil%' OR segment LIKE '%Yogurt%' OR segment LIKE '%Tofu%' OR segment LIKE '%Phyllo Dough%'
ORDER BY segment;",reward,,
"For each Netflix value (returned as 'Season Episode'), what is the Episode Count (COUNT(*) of rows where Segment A contains the substring 'Plastic') and what are the Segment A Samples (a comma-separated GROUP_CONCAT of Segment A values with each value wrapped in backticks '`...`'), grouped by Netflix, only including groups with COUNT(*)>0, ordered by Episode Count, limit 10?","
SELECT `Netflix` AS `Season Episode`, COUNT(*) AS `Episode Count`, GROUP_CONCAT('`' || `Segment A` || '`', ', ') AS `Segment A Samples` FROM `table_1_15187735_4` WHERE instr(`Segment A`, 'Plastic')>0 GROUP BY `Netflix` HAVING COUNT(*)>0 ORDER BY `Episode Count` LIMIT 10;
","SELECT col2 AS `Season Episode`, COUNT(*) `Episode Count`, GROUP_CONCAT(col3, ', ') `Segment A Samples` FROM `table_1_15187735_4` GROUP BY col2 ORDER BY `Episode Count` DESC LIMIT 10;","[('s02e25', 1, 's decorative moulding'), ('s02e24', 1, 'laminate'), ('s02e23', 1, 'plastic cups and cutlery'), ('s02e22', 1, 'car engines'), ('s02e21', 1, 'ceramic tiles'), ('s02e20', 1, '3d commercial signs'), ('s02e19', 1, 'es brush and push brooms'), ('s02e18', 1, 'grinding wheels'), ('s02e17', 1, 'conga drums'), ('s02e16', 1, 'high-precision cutting tools')]",table_1_15187735_4,"1) Parse intent: count rows and collect Segment A values for each Netflix code where Segment A contains 'Plastic'; 2) Map schema: Netflix is labeled as 'Season Episode', Segment A is the segment text; 3) Draft: request Season Episode, episode count, and a comma-separated list of Segment A samples wrapped in backticks; 4) Validate: includes GROUP BY Netflix, HAVING count>0, ORDER BY Episode Count, and LIMIT 10.",reserved,9,reward,,
Which Netflix has the most priority episodes?,"
SELECT DISTINCT `Netflix`,
  SUM(CASE WHEN `Episode` IN (110,114) THEN 1 ELSE 0 END) AS `Priority_Count`
FROM `table_1_15187735_9`
WHERE `Episode` IS 110 OR `Episode` = 114
GROUP BY `Netflix`
ORDER BY `Priority_Count` DESC
LIMIT 3;
","
SELECT DISTINCT col2,
  SUM(CASE WHEN col1 IN (110,114) THEN 1 ELSE 0 END) AS `Priority_Count`
FROM `table_1_15187735_9`
WHERE col1 IS 110 OR col1 = 114
GROUP BY col2
ORDER BY `Priority_Count` DESC
LIMIT 3;
","[('s05e10', 1), ('s05e06', 1)]",table_1_15187735_9,"STEP 1: Parse the SQL intent: the query filters rows to Episode 110 or 114, groups rows by the Netflix column, counts how many of those two episodes appear per Netflix value (via SUM CASE), orders by that count descending, and returns the top three Netflix values with their counts. STEP 2: Determine a type of ambiguity: scope ambiguity fits well — the phrasing “the most” or “has the most” can refer to different scopes (a single overall winner, top N winners, or a per-episode winner). STEP 3: Draft the question: Which Netflix has the most priority episodes? STEP 4: Explain the ambiguity: in the original query this is implemented as counting occurrences of episodes 110 and 114 per Netflix and returning the top three overall; alternatively the same question could mean (a) ask for the single Netflix with the highest combined count, (b) ask for the top Netflix for each of episodes 110 and 114 separately, or (c) ask for all Netflix entries that contain any priority episode rather than ranking them.",reserved,19,reward,,"type: Scope ambiguity | explanation: The SQL treats 'the most' as a combined count of episodes 110 and 114 per Netflix and returns the top three; however a reader could instead interpret 'the most' as asking for a single top Netflix, the top Netflix for each episode separately, or simply which Netflix entries contain any priority episode rather than ranking them."
"Provide up to 10 Districts for which the ""Median monthly per capita / labour force income (HKD)"" contains a ' / ' and where the summed product of the labour-force median (the numeric value after ' / ' with commas removed) times Population (2006_est.) is greater than 3000000000; for each District, show the District name, the per-capita median (the numeric part before ' / ' with commas removed), the labour-force median (the numeric part after ' / ' with commas removed), the Population (2006_est.), and the EstimatedMonthlyLabourTotal calculated as the sum of (LabourForce * Population) for that District.","
SELECT DISTINCT `District`,
(REPLACE(SUBSTR(`Median monthly per capita / labour force income (HKD)`,1,INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')-1),',','')+0) `PerCapita`,
(REPLACE(SUBSTR(`Median monthly per capita / labour force income (HKD)`,INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')+3),',','')+0) `LabourForce`,
(`Population (2006_est.)`+0) `Population`,
SUM((REPLACE(SUBSTR(`Median monthly per capita / labour force income (HKD)`,INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')+3),',','')+0)*(`Population (2006_est.)`+0)) AS `EstimatedMonthlyLabourTotal`
FROM `table_1_151994_1`
WHERE INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')>0
GROUP BY `District`
HAVING SUM((REPLACE(SUBSTR(`Median monthly per capita / labour force income (HKD)`,INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')+3),',','')+0)*(`Population (2006_est.)`+0))>3000000000
LIMIT 10;
","
SELECT DISTINCT col0,
(REPLACE(SUBSTR(col4,1,INSTR(col4,' / ')-1),',','')+0) `PerCapita`,
(REPLACE(SUBSTR(col4,INSTR(col4,' / ')+3),',','')+0) `LabourForce`,
(col1+0) `Population`,
SUM((REPLACE(SUBSTR(col4,INSTR(col4,' / ')+3),',','')+0)*(col1+0)) AS `EstimatedMonthlyLabourTotal`
FROM `table_1_151994_1`
WHERE INSTR(col4,' / ')>0
GROUP BY col0
HAVING SUM((REPLACE(SUBSTR(col4,INSTR(col4,' / ')+3),',','')+0)*(col1+0))>3000000000
LIMIT 10;
","[('central and western ( 中西 )', 9722, 17178, 250064.0, 4295599392.0), ('eastern ( 東 )', 7235, 13558, 587690.0, 7967901020.0), ('hong kong island ( 香港島 )', 7931, 14568, 1268112.0, 18473855616.0), ('kowloon ( 九龍 )', 5184, 10311, 2019533.0, 20823404763.0), ('kowloon city ( 九龍城 )', 6897, 13122, 362501.0, 4756738122.0), ('kwai tsing ( 葵青 )', 4833, 9718, 523300.0, 5085429400.0), ('kwun tong ( 觀塘 )', 4845, 9908, 587423.0, 5820187084.0), ('land total', 5753, 11055, 6861280.0, 75851450400.0), ('new territories ( 新界 )', 5667, 10860, 3573635.0, 38809676100.0), ('sai kung ( 西貢 )', 6774, 12183, 406442.0, 4951682886.0)]",table_1_151994_1,"1) The SQL filters rows that have a ' / ' in the median income field, parses both median values to numbers by removing commas, multiplies the labour-force median by population, sums per District, and keeps groups with sum > 3,000,000,000, limiting output to 10. 2) Map to schema: Median monthly per capita / labour force income (HKD) -> PerCapita and LabourForce, Population (2006_est.) -> Population, and compute EstimatedMonthlyLabourTotal = SUM(LabourForce * Population). 3) Draft a question that asks for District, parsed PerCapita, parsed LabourForce, Population, and the aggregated EstimatedMonthlyLabourTotal, with the specified filter and limit. 4) Validate inclusion of the parsing, numeric conversion (remove commas), multiplication, aggregation, threshold >3000000000, and limit 10 in the question.",reserved,9,reward,,
"For the exhibit, could you list the Football League War Cup, VE Celebration Match and VJ Celebration Match with played, Derby County wins, Nottingham Forest wins, draws, goals for each, goal difference and win/draw percentages, and then a combined TOTAL?","
WITH relevant AS (
  SELECT
    `Competition`,
    `Played`,
    `Derby County` AS `Derby County Wins`,
    `Nottingham Forest` AS `Nottingham Forest Wins`,
    `Draw`,
    `Derby County Goals`,
    `Nottingham Forest Goals`,
    (`Derby County Goals` - `Nottingham Forest Goals`) AS `Goal_Diff`,
    ROUND(100.0 * `Derby County` / `Played`, 1) AS `Derby_Win_Pct`,
    ROUND(100.0 * `Nottingham Forest` / `Played`, 1) AS `Nottingham_Win_Pct`,
    ROUND(100.0 * `Draw` / `Played`, 1) AS `Draw_Pct`
  FROM `table_1_15201666_3`
  WHERE `Competition` IN ('Football League War Cup', 'VE Celebration Match', 'VJ Celebration Match')
)
SELECT
  `Competition`,
  `Played`,
  `Derby County Wins`,
  `Nottingham Forest Wins`,
  `Draw`,
  `Derby County Goals`,
  `Nottingham Forest Goals`,
  `Goal_Diff`,
  `Derby_Win_Pct`,
  `Nottingham_Win_Pct`,
  `Draw_Pct`
FROM relevant
UNION ALL
SELECT
  'TOTAL' AS `Competition`,
  SUM(`Played`) AS `Played`,
  SUM(`Derby County Wins`) AS `Derby County Wins`,
  SUM(`Nottingham Forest Wins`) AS `Nottingham Forest Wins`,
  SUM(`Draw`) AS `Draw`,
  SUM(`Derby County Goals`) AS `Derby County Goals`,
  SUM(`Nottingham Forest Goals`) AS `Nottingham Forest Goals`,
  SUM(`Goal_Diff`) AS `Goal_Diff`,
  ROUND(100.0 * SUM(`Derby County Wins`) / SUM(`Played`), 1) AS `Derby_Win_Pct`,
  ROUND(100.0 * SUM(`Nottingham Forest Wins`) / SUM(`Played`), 1) AS `Nottingham_Win_Pct`,
  ROUND(100.0 * SUM(`Draw`) / SUM(`Played`), 1) AS `Draw_Pct`
FROM relevant;
","WITH relevant AS (
  SELECT
    col0,
    col1,
    col2 AS `Derby County Wins`,
    col4 AS `Nottingham Forest Wins`,
    col3,
    col5,
    col6,
    (col5 - col6) AS `Goal_Diff`,
    ROUND(100.0 * col2 / col1, 1) AS `Derby_Win_Pct`,
    ROUND(100.0 * col4 / col1, 1) AS `Nottingham_Win_Pct`,
    ROUND(100.0 * col3 / col1, 1) AS `Draw_Pct`
  FROM `table_1_15201666_3`
  WHERE col0 IN ('Football League War Cup', 'VE Celebration Match', 'VJ Celebration Match')
)
SELECT
  col0,
  col1,
  `Derby County Wins`,
  `Nottingham Forest Wins`,
  col3,
  col5,
  col6,
  `Goal_Diff`,
  `Derby_Win_Pct`,
  `Nottingham_Win_Pct`,
  `Draw_Pct`
FROM relevant
UNION ALL
SELECT
  'TOTAL' AS col0,
  SUM(col1) AS col1,
  SUM(col2) AS `Derby County Wins`,
  SUM(col4) AS `Nottingham Forest Wins`,
  SUM(col3) AS col3,
  SUM(col5) AS col5,
  SUM(col6) AS col6,
  SUM(col5) - SUM(col6) AS `Goal_Diff`,
  ROUND(100.0 * SUM(col2) / SUM(col1), 1) AS `Derby_Win_Pct`,
  ROUND(100.0 * SUM(col4) / SUM(col1), 1) AS `Nottingham_Win_Pct`,
  ROUND(100.0 * SUM(col3) / SUM(col1), 1) AS `Draw_Pct`
FROM `table_1_15201666_3`
WHERE col0 IN ('Football League War Cup', 'VE Celebration Match', 'VJ Celebration Match');","[('TOTAL', None, None, None, None, None, None, None, None, None, None)]",table_1_15201666_3,"As someone preparing exhibit copy I'd ask for wartime and civic fixtures and a combined summary without using SQL jargon. The query intent is to return those three named competitions with computed percentages and then append a TOTAL row summing the numeric columns. The columns map to Competition, Played, Derby/Forest wins, Draw, goals, computed Goal_Diff and percent columns. For the exhibit, could you list the Football League War Cup, VE Celebration Match and VJ Celebration Match with played, Derby County wins, Nottingham Forest wins, draws, goals for each, goal difference and win/draw percentages, and then a combined TOTAL? That phrasing asks for exactly the per-row stats and the aggregated totals the query produces.",persona,"```json
{
  ""short_persona_description"": ""A living‑history museum curator who designs an interactive wartime football installation that pairs oral testimony from East Midlands communities with match statistics from minor Derby County vs Nottingham Forest competitions."",
  ""goals"": [
    ""Identify which minor competitions were explicitly wartime or civic‑celebration fixtures (e.g., War Cup, VE/VJ Celebration matches) to anchor panels and audio stations in the exhibit."",
    ""Compare outcomes and Goals:  Example Queries: ",reward,,
"For episodes where Countries Visited contains 'USA' or 'Australia', what is each Presenter's Presenter name, the Total_Episodes (COUNT of those episodes per Presenter), and USA (the SUM counting 1 when Countries Visited contains 'USA' and 0 otherwise), showing only presenters with at least one such episode and ordering the output by Total_Episodes descending?","
SELECT `Presenter` AS `Presenter`, COUNT(*) AS `Total_Episodes`,
SUM(CASE WHEN `Countries Visited` LIKE '%USA%' THEN 1 ELSE 0 END) `USA`
FROM `table_1_15211468_1`
WHERE `Countries Visited` LIKE '%USA%' OR `Countries Visited` LIKE '%Australia%'
GROUP BY `Presenter`
HAVING COUNT(*)>0
ORDER BY `Total_Episodes` DESC;
","
SELECT col3 AS col3, COUNT(*) AS `Total_Episodes`,
SUM(CASE WHEN col5 LIKE '%USA%' THEN 1 ELSE 0 END) `USA`
FROM `table_1_15211468_1`
WHERE col5 LIKE '%USA%' OR col5 LIKE '%Australia%'
GROUP BY col3
HAVING COUNT(*)>0
ORDER BY `Total_Episodes` DESC;
","[('michael frayn', 1, 0), ('ludovic kennedy', 1, 1)]",table_1_15211468_1,"1) The SQL retrieves Presenter, counts episodes, and sums episodes that visited USA, limited to rows where Countries Visited contains 'USA' or 'Australia', grouped and ordered by count. 2) Interpret Presenter as the presenter name column, Total_Episodes as COUNT(*), and USA as SUM of a conditional test on Countries Visited LIKE '%USA%'. 3) Draft a question asking for Presenter, Total_Episodes and USA with the WHERE restriction to Countries Visited containing 'USA' or 'Australia', grouping by Presenter, requiring COUNT(*)>0, and ordering by Total_Episodes descending. 4) Check that the question mentions the Presenter column, the COUNT and conditional SUM calculation, the filter, grouping, HAVING and ordering.",reserved,19,reward,,
"Give me candidate hulls around 300–350 ft and under 4,000 tons with Bergen, MAK or Wärtsilä engines of 7,000+ HP — list the name, length, tonnage, year built, builder, engine and any former names, oldest first?","
SELECT
  `Name`,
  CAST(REPLACE(`Length`, ' Feet', '') AS REAL) AS `length_ft`,
  `Length`,
  `Tonnage`,
  `Year`,
  `Built by`,
  `Engines`,
  `Horsepowers`,
  `Former Names`,
  CASE
    WHEN `Engines` LIKE '%Bergen Diesel%' THEN '`Bergen Diesel`'
    WHEN `Engines` LIKE '%MAK%' THEN '`MAK`'
    WHEN `Engines` LIKE '%Wärtsilä%' THEN '`Wärtsilä`'
    ELSE '`Other`'
  END AS `Engine_Make_Tag`,
  '`' || `Name` || '`' AS `ShipName_backticked`,
  '`' || `Former Names` || '`' AS `Former_Names_backticked`
FROM `table_1_15230458_1`
WHERE CAST(REPLACE(`Length`, ' Feet', '') AS REAL) BETWEEN 300 AND 350
  AND `Tonnage` < 4000
  AND (`Engines` LIKE '%Bergen Diesel%' OR `Engines` LIKE '%MAK%' OR `Engines` LIKE '%Wärtsilä%')
  AND `Horsepowers` >= 7000
ORDER BY `Year` ASC, `Horsepowers` DESC;
","
SELECT
  col0,
  CAST(REPLACE(col1, ' Feet', '') AS REAL) AS `length_ft`,
  col1,
  col2,
  col4,
  col3,
  col5,
  col6,
  col7,
  CASE
    WHEN col5 LIKE '%Bergen Diesel%' THEN '`Bergen Diesel`'
    WHEN col5 LIKE '%MAK%' THEN '`MAK`'
    WHEN col5 LIKE '%Wärtsilä%' THEN '`Wärtsilä`'
    ELSE '`Other`'
  END AS `Engine_Make_Tag`,
  '`' || col0 || '`' AS `ShipName_backticked`,
  '`' || col7 || '`' AS `Former_Names_backticked`
FROM `table_1_15230458_1`
WHERE CAST(REPLACE(col1, ' Feet', '') AS REAL) BETWEEN 300 AND 350
  AND col2 < 4000
  AND (col5 LIKE '%Bergen Diesel%' OR col5 LIKE '%MAK%' OR col5 LIKE '%Wärtsilä%')
  AND col6 >= 7000
ORDER BY col4 ASC, col6 DESC;
","[('northern hawk', 310.1, '310.1 feet', 3732.0, 1981.0, 'brount marine corp, warren, ri.', '2, bergen diesel , brm-8', 8790.0, 'state trust', '`Bergen Diesel`', '`northern hawk`', '`state trust`')]",table_1_15230458_1,"They know enough to name engine makes and HP but not to write SQL, so the phrasing is practical and instrument-focused. The SQL selects ships in the 300–350 ft range, tonnage <4000, engine make in Bergen/MAK/Wärtsilä and horsepower >=7000. That corresponds to columns Length, Tonnage, Engines, Horsepowers, Year, Built by and Former Names. Give me candidate hulls ~300–350 ft and under 4,000 tons with Bergen/MAK/Wärtsilä powerplants of 7,000+ HP, listing name, length, tonnage, year, builder, engine and former names, oldest first? I ensure the question stays within the filters and returned fields of the query.",persona,"An experimental acoustic luthier who composes orchestral pieces using retired commercial trawlers as giant resonant instruments, selecting hulls and engine types to tune playable frequencies. Goals: Find candidate ships with hull lengths and tonnages that produce desired resonant pitches (e.g., mid-range resonances around 300–350 ft). Identify ships equipped with particular engine makes/models (mechanical excitation sources) and sufficient horsepower to drive low-frequency vibrations. Prioritize older builds (thicker-plate steel, simpler internal framing) for easier acoustic modification and predictability of modal behavior. Trace provenance and former names to contact previous caretakers or to research historical modifications affecting internal structure. Example Queries: -- 1) Select candidate hulls in the 300–350 ft range with moderate tonnage (casting Length text to numeric)
    SELECT ""Name"", CAST(REPLACE(""Length"", ' Feet', '') AS REAL) AS length_ft, ""Tonnage"", ""Year""
    FROM table_1_15230458_1
    WHERE CAST(REPLACE(""Length"", ' Feet', '') AS REAL) BETWEEN 300 AND 350
      AND ""Tonnage"" < 4000
    ORDER BY length_ft; -- 2) Find ships with Bergen Diesel (or MAK) engines and list horsepower and build year to evaluate engine-driven excitation options
    SELECT ""Name"", ""Engines"", ""Horsepowers"", ""Year""
    FROM table_1_15230458_1
    WHERE ""Engines"" LIKE '%Bergen Diesel%'
       OR ""Engines"" LIKE '%MAK%'
    ORDER BY ""Horsepowers"" DESC; -- 3) Pull ships with notable former names (for provenance/contact research) and include build yard/year
    SELECT ""Name"", ""Former Names"", ""Built by"", ""Year""
    FROM table_1_15230458_1
    WHERE ""Former Names"" LIKE '%Ranger%'
       OR ""Former Names"" LIKE '%Princess%'
       OR ""Former Names"" LIKE '%Bure%'
    ORDER BY ""Year"";",reward,,
"Which directors have multiple submissions since 1990, and how many nominations do they have?","
SELECT DISTINCT `Director`, COUNT(*) `Total Submissions`, SUM(`Result` = 'Nominee') `Nominations`
FROM `table_1_15277629_1`
WHERE `Year (Ceremony)` >= 1990
GROUP BY `Director`
HAVING COUNT(*) > 1
LIMIT 10;
","
SELECT DISTINCT col3, COUNT(*) `Total Submissions`, SUM(col4 = 'Nominee') `Nominations`
FROM `table_1_15277629_1`
WHERE col0 >= 1990
GROUP BY col3
HAVING COUNT(*) > 1
LIMIT 10;
","[('bruno barreto', 2, 0), ('cacá diegues', 3, 0), ('fábio barreto', 2, 0), ('walter salles', 2, 0)]",table_1_15277629_1,"STEP 1: Parse the SQL intent — Return up to 10 directors who have more than one submission with Year (Ceremony) >= 1990, showing each director's total submissions and the number of those submissions that were 'Nominee'. STEP 2: Choose ambiguity type — Scope ambiguity is suitable because phrases like 'multiple' and the temporal modifier 'since 1990' can attach to different parts of the request (submissions vs. nominations), causing different interpretations. STEP 3: Draft the question — ""Which directors have multiple submissions since 1990, and how many nominations do they have?"" STEP 4: Explain the ambiguity — The SQL treats 'multiple' as applying to submissions since 1990 and counts nominations among those submissions. Alternative readings could treat 'multiple' as referring to nominations instead of submissions, or could interpret 'since 1990' as applying only to submissions, only to nominations, or to both.",reserved,8,reward,,"type: Scope ambiguity | explanation: The SQL interprets 'multiple' as referring to submissions since 1990 and reports nominations among those submissions; alternatively, a user could mean directors with multiple nominations (not submissions), or mean that 'since 1990' applies to nominations only, to submissions only, or to both, yielding different result sets."
"For rows where No. in season is between 1 and 17 inclusive, what are the Total episodes (COUNT(*)), Disc 1_count (SUM((No. disc)=1)), Disc 2_count (SUM((No. disc)=2)), Disc 3_count (SUM((No. disc)=3)), Disc 4_count (SUM((No. disc)=4)), Disc 5_count (SUM((No. disc)=5)), First_ep (MIN(No. in season)), Last_ep (MAX(No. in season)), and Avg_ep (AVG(No. in season))?","
SELECT COUNT(*) `Total episodes`, SUM((`No. disc`)=1) `Disc 1_count`, SUM((`No. disc`)=2) `Disc 2_count`, SUM((`No. disc`)=3) `Disc 3_count`, SUM((`No. disc`)=4) `Disc 4_count`, SUM((`No. disc`)=5) `Disc 5_count`, MIN(`No. in season`) `First_ep`, MAX(`No. in season`) `Last_ep`, AVG(`No. in season`) `Avg_ep`
FROM `table_1_15284274_1`
WHERE (`No. in season` >= 1) AND (`No. in season` <= 17);
","
SELECT COUNT(*) `Total episodes`, SUM((col1)=1) `Disc 1_count`, SUM((col1)=2) `Disc 2_count`, SUM((col1)=3) `Disc 3_count`, SUM((col1)=4) `Disc 4_count`, SUM((col1)=5) `Disc 5_count`, MIN(col0) `First_ep`, MAX(col0) `Last_ep`, AVG(col0) `Avg_ep`
FROM `table_1_15284274_1`
WHERE (col0 >= 1) AND (col0 <= 17);
","[(14, 4, 3, 4, 2, 1, 1.0, 17.0, 8.428571428571429)]",table_1_15284274_1,"1) Parse the SQL intent: compute overall episode count, per-disc counts for discs 1–5, and min/max/avg of episode numbers restricted to No. in season between 1 and 17. 2) Map schema semantics: use the columns No. in season and No. disc and the aggregations COUNT(*), SUM((No. disc)=n), MIN(No. in season), MAX(No. in season), AVG(No. in season). 3) Draft the question: request each aggregate with their labels (Total episodes, Disc 1_count … Disc 5_count, First_ep, Last_ep, Avg_ep) and the filter. 4) Validate: confirm all columns, calculations, and the range condition 1–17 are mentioned.",reserved,4,reward,,
"List each MotoGP winner (Winner) with the COUNT(*) as Wins, the MIN(Round) as First, and the MAX(Round) as Last, excluding NULL MotoGP winners, grouped by MotoGP winner and restricted to those with Wins > 1 and Wins in (2, 3, 4, 5), ordered by Wins (ascending) and limited to 10 rows?","
SELECT DISTINCT `MotoGP winner` AS `Winner`, COUNT(*) `Wins`, MIN(`Round`) `First`, MAX(`Round`) `Last`
FROM `table_1_15299235_1`
WHERE `MotoGP winner` IS NOT NULL
GROUP BY `MotoGP winner`
HAVING COUNT(*) > 1 AND COUNT(*) IN (2,3,4,5)
ORDER BY `Wins`
LIMIT 10;
","
SELECT DISTINCT col6 AS `Winner`, COUNT(*) `Wins`, MIN(col0) `First`, MAX(col0) `Last`
FROM `table_1_15299235_1`
WHERE col6 IS NOT NULL
GROUP BY col6
HAVING COUNT(*) > 1 AND COUNT(*) IN (2,3,4,5)
ORDER BY `Wins`
LIMIT 10;
","[('casey stoner', 4, 1.0, 16.0), ('jorge lorenzo', 4, 2.0, 14.0)]",table_1_15299235_1,"1) Parse intent: compute win totals and the earliest/latest round per MotoGP winner, include only winners with 2–5 wins. 2) Map schema: use `MotoGP winner` and `Round` for aggregations. 3) Draft: request Winner, Wins, First, Last with non-null filter, group, HAVING, ORDER BY, LIMIT. 4) Validate: question mirrors COUNT, MIN, MAX, HAVING IN and ORDER constraints.",reserved,16,reward,,
"Which Momentum, Kinetic energy or Rapidity lines pair a simple proper velocity (½, 1, √3, 2) or a clean γ (2, √2, √5, √5/2) or have a velocity-angle ½, 1, 2 or ln[...] — list their coordinate velocity, velocity angle, proper velocity and γ so I can sketch suggested gear pairs?","
SELECT 
  `Condition/Parameter`,
  `Coordinate velocity v dx/dt in units of c`,
  `Velocity angle η in i-radians`,
  `Proper velocity w dx/dτ in units of c`,
  `Lorentz factor γ dt/dτ = E/mc 2`,
  (`Proper velocity w dx/dτ in units of c` || '  |  ' || `Lorentz factor γ dt/dτ = E/mc 2`) AS `Suggested_gear_pair`
FROM table_1_15314901_1
WHERE (
    `Proper velocity w dx/dτ in units of c` IN ('½','1','√3 ≅ 1.732','2')
    OR `Lorentz factor γ dt/dτ = E/mc 2` IN ('2','√2 ≅ 1.414','√5 ≅ 2.236','√5/2 ≅ 1.118')
    OR `Velocity angle η in i-radians` IN ('½','1','2')
    OR `Velocity angle η in i-radians` LIKE 'ln[%'
)
AND (
    `Condition/Parameter` LIKE '%Momentum%'
    OR `Condition/Parameter` LIKE '%Kinetic energy%'
    OR `Condition/Parameter` LIKE '%Rapidity%'
)
ORDER BY 
  CASE 
    WHEN `Velocity angle η in i-radians` IN ('½','1','2') THEN 0 
    WHEN `Velocity angle η in i-radians` LIKE 'ln[%' THEN 1 
    ELSE 2 
  END,
  `Proper velocity w dx/dτ in units of c`;
","
SELECT 
  col0,
  col1,
  col2,
  col3,
  col4,
  (col3 || '  |  ' || col4) AS `Suggested_gear_pair`
FROM table_1_15314901_1
WHERE (
    col3 IN ('½','1','√3 ≅ 1.732','2')
    OR col4 IN ('2','√2 ≅ 1.414','√5 ≅ 2.236','√5/2 ≅ 1.118')
    OR col2 IN ('½','1','2')
    OR col2 LIKE 'ln[%'
)
AND (
    col0 LIKE '%Momentum%'
    OR col0 LIKE '%Kinetic energy%'
    OR col0 LIKE '%Rapidity%'
)
ORDER BY 
  CASE 
    WHEN col2 IN ('½','1','2') THEN 0 
    WHEN col2 LIKE 'ln[%' THEN 1 
    ELSE 2 
  END,
  col3;
","[('rapidity of 2 hyperbolic radians', '(e 4 −1)/(e 4 +1) ≅ 0.964', '2', '½(e 2 − 1/e 2 ) ≅ 3.627', '½(e 2 + 1/e 2 ) ≅ 3.762', '½(e 2 − 1/e 2 ) ≅ 3.627  |  ½(e 2 + 1/e 2 ) ≅ 3.762'), ('rapidity of 1 hyperbolic radian', '(e 2 − 1)/(e 2 + 1) ≅ 0.761', '1', '½(e − 1/e) ≅ 1.175', '½(e + 1/e) ≅ 1.543', '½(e − 1/e) ≅ 1.175  |  ½(e + 1/e) ≅ 1.543'), ('rapidity of 0.5 hyperbolic radian', '(e − 1)/(e + 1) ≅ 0.462', '½', '½(√e − 1/√e) ≅ 0.521', '½(√e + 1/√e) ≅ 1.128', '½(√e − 1/√e) ≅ 0.521  |  ½(√e + 1/√e) ≅ 1.128'), ('momentum = mc ⇔ 1 map-lightyear/traveler-year', '1/√2 ≅ 0.707', 'ln[1 + √2] ≅ 0.881', '1', '√2 ≅ 1.414', '1  |  √2 ≅ 1.414'), ('momentum = 2mc ⇔ 2 map-lightyears/traveler-year', '2/√5 ≅ 0.894', 'ln[2 + √5] ≅ 1.444', '2', '√5 ≅ 2.236', '2  |  √5 ≅ 2.236'), ('momentum = ½mc ⇔ 0.5 map-lightyear/traveler-year', '1/√5 ≅ 0.447', 'ln[(1 + √5)/2] ≅ 0.481', '½', '√5/2 ≅ 1.118', '½  |  √5/2 ≅ 1.118'), ('kinetic energy = mc 2 ⇔ 2 map-years/traveler-year', '√3/2 ≅ 0.866', 'ln[√3 + 2] ≅ 1.317', '√3 ≅ 1.732', '2', '√3 ≅ 1.732  |  2')]",table_1_15314901_1,"I like a slightly poetic inventory request but still know the schema enough to name the conditions and the physical quantities I need. The SQL filters for rows with named conditions and where proper velocity, γ, or velocity-angle match a set of aesthetic values (fractions, integers, radicals, or ln forms) and then orders by nice angles first. This maps to Condition/Parameter, coordinate velocity, velocity angle, proper velocity and Lorentz factor columns, and concatenates proper velocity and γ as a suggested gear pair. Draft question: Which Momentum, Kinetic energy or Rapidity lines pair a simple proper velocity (½, 1, √3, 2) or a clean γ (2, √2, √5, √5/2) or have a velocity-angle ½, 1, 2 or ln[...] — list their coordinate velocity, velocity angle, proper velocity and γ so I can sketch suggested gear pairs? This mirrors the SQL's selection, ordering and output.",persona,"A boutique horologist-artist (a 'relativistic watchmaker') crafting mechanical wristwatches that display traveler-years vs map-years and whose gear ratios are driven by neat proper-velocity / Lorentz-factor values from this relativistic lookup table. Goals: Identify rows where proper velocity or Lorentz factor is a simple integer, simple radical, or clean fraction so they can be converted into compact gear ratios and dial markings. Find velocities with simple rapidities or velocity-angles (nice fractions or integers of i-radians) to design escapement steps that map directly to hyperbolic angle increments on the watch face. Select aesthetic, named conditions (e.g., 'Momentum = mc', 'Kinetic energy = mc²') and pull their coordinate velocity, proper velocity and γ so engravings and dual-time displays show both map-year and traveler-year correlations precisely. Example Queries: SELECT `Condition/Parameter`, `Coordinate velocity v dx/dt in units of c`, `Proper velocity w dx/dτ in units of c`, `Lorentz factor γ dt/dτ = E/mc 2` FROM table_1_15314901_1 WHERE `Proper velocity w dx/dτ in units of c` IN ('½','1','√3','2'); SELECT `Condition/Parameter`, `Velocity angle η in i-radians`, `Coordinate velocity v dx/dt in units of c`, `Lorentz factor γ dt/dτ = E/mc 2` FROM table_1_15314901_1 WHERE `Velocity angle η in i-radians` IN ('½','1','2') OR `Velocity angle η in i-radians` LIKE 'ln%'; SELECT * FROM table_1_15314901_1 WHERE `Coordinate velocity v dx/dt in units of c` LIKE '%≅ 0.8%' OR `Coordinate velocity v dx/dt in units of c` LIKE '%≅ 0.9%' OR `Coordinate velocity v dx/dt in units of c` LIKE '%≅ 0.96%' ORDER BY `Proper velocity w dx/dτ in units of c`;",reward,,
Which Class A schools have appeared in Class AA and Class AAA in different years?,"
SELECT t1.`Class A` AS `school`, COUNT(*) 
FROM `table_1_15315103_1` t1
INNER JOIN `table_1_15315103_1` t2 ON t1.`Class A` = t2.`Class AA`
INNER JOIN `table_1_15315103_1` t3 ON t1.`Class A` = t3.`Class AAA`
WHERE t1.`School Year` <> t2.`School Year` AND t1.`School Year` <> t3.`School Year`
GROUP BY t1.`Class A`
HAVING COUNT(*) > 1
ORDER BY COUNT(*) DESC
LIMIT 10;
","SELECT DISTINCT col1 AS `school`, COUNT(*) AS `cnt` FROM `table_1_15315103_1` WHERE (col1 IS NOT NULL AND col1 <> '') OR col1 IN ('Martin''s Mill') GROUP BY col1 HAVING COUNT(*) > 1 ORDER BY `cnt` DESC LIMIT 10;","[(""martin's mill"", 6), ('lindsay', 2), ('anton', 2)]",table_1_15315103_1,"STEP 1: Parse the SQL intent: the query finds values from Class A (named as school) that match entries in Class AA and in Class AAA from other rows (joins on t1.Class A = t2.Class AA and t1.Class A = t3.Class AAA with t1.School Year <> t2.School Year and t1.School Year <> t3.School Year), counts the matching combinations per Class A, keeps those with COUNT(*) > 1, and returns the top 10 by that count. STEP 2: Determine ambiguity type: scope ambiguity — the phrasing ""appeared in Class AA and Class AAA in different years"" can be read as requiring both appearances (the SQL interpretation) or as requiring either appearance (an alternative interpretation), and the temporal attachment of ""in different years"" can also be scoped differently. STEP 3: Draft the question: ""Which Class A schools have appeared in Class AA and Class AAA in different years?"" STEP 4: Explain the ambiguity: in the original query the school must match entries in both Class AA and Class AAA in other School Years (i.e., it appeared in both other classes across different years) and the COUNT>1 filters to schools with multiple matching combinations; alternatively the natural-language question could be read to mean schools that appeared in either Class AA or Class AAA (not necessarily both), or that the appearances might be within the same year, or that ""different years"" applies only to one of the appearances rather than both.",reserved,18,reward,,"type: Scope ambiguity | explanation: The SQL requires the school to appear in both Class AA and Class AAA in other years (both must match), but the wording could instead be read as asking for schools that appeared in either Class AA or Class AAA (not necessarily both), or as unclear whether ""in different years"" applies to both appearances or just one."
"For each distinct Country, what is the Wins count, the Avg Winner Share Pct defined as ROUND(AVG(CAST(Winners share ($) AS REAL)/Purse ($)),6), and the Payout flag that reads 'Below avg payout' when that AVG rounded to 6 decimals is < 0.142, returning only countries with more than 0 wins and limiting the output to 100 rows?","
SELECT DISTINCT `Country`, COUNT(*) `Wins`, ROUND(AVG(CAST(`Winners share ($)` AS REAL)/`Purse ($)`),6) `Avg Winner Share Pct`, CASE WHEN ROUND(AVG(CAST(`Winners share ($)` AS REAL)/`Purse ($)`),6) < 0.142 THEN '`Below avg payout`' END `Payout flag` FROM `table_1_15315816_1` GROUP BY `Country` HAVING COUNT(*)>0 LIMIT 100;
","
SELECT DISTINCT col3, COUNT(*) `Wins`, ROUND(AVG(CAST(col7 AS REAL)/col6),6) `Avg Winner Share Pct`, CASE WHEN ROUND(AVG(CAST(col7 AS REAL)/col6),6) < 0.142 THEN '`Below avg payout`' END `Payout flag` FROM `table_1_15315816_1` GROUP BY col3 HAVING COUNT(*)>0 LIMIT 100;
","[('australia', 2, 0.14, '`Below avg payout`'), ('brazil', 1, 0.14, '`Below avg payout`'), ('canada', 1, 0.14, '`Below avg payout`'), ('paraguay', 1, 0.14, '`Below avg payout`'), ('south korea', 3, 0.14, '`Below avg payout`'), ('taiwan', 1, 0.15, None), ('thailand', 1, 0.14, '`Below avg payout`'), ('united states', 3, 0.143333, None)]",table_1_15315816_1,"1) Parse the SQL intent: produce per-country distinct rows with total wins, the mean winners-share-to-purse ratio rounded to six decimals, and a flag if that mean is below 0.142, restricting to countries with at least one win and up to 100 rows. 2) Map schema semantics: Country, Winners share ($), Purse ($), COUNT(*) → Wins. 3) Draft the question: include explicit rounding to 6 decimals and the exact flag text. 4) Validate: ensure rounding, threshold, HAVING condition, and LIMIT 100 are all present.",reserved,12,reward,,
"For entries where Played = 20, and grouping results by Team with groups having SUM(Points) >= 10, what are the Team, Points, the goal difference computed as (For - Against) and labeled ""Palmeiras"", and the Points per Game (Points / Played), ordered by Points and limited to 5 rows?","
SELECT `Team`, `Points`, (`For` - `Against`) `Palmeiras`, (`Points` / `Played`) `Points per Game`
FROM `table_1_15318779_1`
WHERE `Played` = 20
GROUP BY `Team`
HAVING SUM(`Points`) >= 10
ORDER BY `Points`
LIMIT 5;
","
SELECT col1, col2, (col7 - col8) `Palmeiras`, (col2 / col3) `Points per Game`
FROM `table_1_15318779_1`
WHERE col3 = 20
GROUP BY col1
HAVING SUM(col2) >= 10
ORDER BY col2
LIMIT 5;
","[('nacional-sp', 10.0, -22.0, 0.5), ('comercial-sp', 11.0, -34.0, 0.55), ('portuguesa santista', 15.0, -15.0, 0.75), ('juventus', 16.0, -16.0, 0.8), ('santos', 19.0, 6.0, 0.95)]",table_1_15318779_1,"1) The SQL intent is to produce a grouped list by Team for Played = 20 including Points and two computed fields, only keeping teams whose summed Points >= 10, sorted by Points and limited to five results. 2) Columns For and Against are used to compute (For - Against) aliased Palmeiras; Points and Played are used to compute Points per Game. 3) Formulate a question that requests those exact outputs and applies the WHERE, GROUP BY, HAVING, ORDER BY, and LIMIT constraints. 4) Ensure the question mentions the alias ""Palmeiras"" for the goal difference and the Points per Game calculation.",reserved,9,reward,,
"For Census Years between 1971 and 2001, which three records (showing Census Year, Number of Muslims 000 and decadal_growth_pct) comparing each year to the previous decade (previous.Census Year = current.Census Year - 10) with previous.Registered Mosques > 0 yield decadal_growth_pct computed as ROUND(CASE WHEN previous.`Number of Muslims 000` = 0 THEN 0 ELSE (current.`Number of Muslims 000` - previous.`Number of Muslims 000`) * 100.0 / previous.`Number of Muslims 000` END), ordered by decadal_growth_pct and limited to 3?","
SELECT t1.`Census Year`, t1.`Number of Muslims 000`, ROUND(CASE WHEN t2.`Number of Muslims 000` = 0 THEN 0 ELSE (t1.`Number of Muslims 000` - t2.`Number of Muslims 000`) * 100.0 / t2.`Number of Muslims 000` END) AS `decadal_growth_pct` FROM `table_1_1532779_1` t1 JOIN `table_1_1532779_1` t2 ON t2.`Census Year` = t1.`Census Year` - 10 WHERE t1.`Census Year` BETWEEN 1971 AND 2001 AND t2.`Registered Mosques` > 0 ORDER BY `decadal_growth_pct` BY LIMIT 3;
","SELECT t1.col0, t1.col1, (CASE WHEN t2.col1 = 0 THEN 0 ELSE (t1.col1 - t2.col1) * 100.0 / t2.col1 END) AS `decadal_growth_pct` FROM `table_1_1532779_1` t1 JOIN `table_1_1532779_1` t2 ON t2.col0 = t1.col0 - 10 WHERE (t1.col0 BETWEEN 1971 AND 2001) * (t2.col4 <> 0) = 1 ORDER BY `decadal_growth_pct` LIMIT 3;","[(2001.0, 1600.0, 68.42105263157895), (1991.0, 950.0, 71.79023508137432), (1981.0, 553.0, 144.69026548672565)]",table_1_1532779_1,"1) Parse intent: self-join to compare current and previous decade Muslim population and compute rounded percentage growth, filter years 1971–2001 and require previous Registered Mosques > 0, then order and limit to 3. 2) Map schema: current and previous rows from the same table using Census Year offset of 10. 3) Draft: request the Census Year, Number of Muslims 000 and the rounded decadal_growth_pct with exact formula. 4) Validate: question includes all columns, calculation, join, filter, ORDER BY decadal_growth_pct and LIMIT 3.",reserved,16,reward,,
"List Season, # of Episodes, Timeslot (Tuesday 8:30pm), Season Premiere (26 August 2008), Season Final, Peak Audience, Average Audience, the Audience Delta (Peak Audience - Average Audience), and the Audience Ratio % as ROUND((Peak Audience / Average Audience) * 100.0, 2) for every row where Peak Audience > Average Audience.","
SELECT `Season`, `# of Episodes`, `Timeslot` `Tuesday 8:30pm`, `Season Premiere` `26 August 2008`, `Season Final`, `Peak Audience`, `Average Audience`, (`Peak Audience` - `Average Audience`) `Audience Delta`, ROUND((`Peak Audience` / `Average Audience`) * 100.0, 2) AS `Audience Ratio %` FROM `table_1_15358729_6` WHERE `Peak Audience` > `Average Audience`;
","
SELECT col0, col1, col2 `Tuesday 8:30pm`, col3 `26 August 2008`, col4, col5, col6, (col5 - col6) `Audience Delta`, ROUND((col5 / col6) * 100.0, 2) AS `Audience Ratio %` FROM `table_1_15358729_6` WHERE col5 > col6;
","[(1.0, 22.0, 'tuesday 8:30pm', '26 august 2008', '24 march 2009', 2067000.0, 1904364.0, 162636.0, 108.54), (2.0, 22.0, 'tuesday 8:30pm', '30 june 2009', '24 november 2009', 2185000.0, 1881000.0, 304000.0, 116.16), (3.0, 22.0, 'tuesday 8:30pm', '29 june 2010', '16 november 2010', 2335000.0, 1894000.0, 441000.0, 123.28), (4.0, 22.0, 'tuesday 8:30pm', '8 february 2011', '20 march 2012', 2011000.0, 1803000.0, 208000.0, 111.54), (5.0, 22.0, 'tuesday 8:30pm', '17 april 2012', '16 april 2013', 1762000.0, 1509000.0, 253000.0, 116.77)]",table_1_15358729_6,"1) Intent: display selected columns plus two derived metrics for rows where Peak Audience exceeds Average Audience. 2) Map schema: fields are Season, # of Episodes, Timeslot, Season Premiere, Season Final, Peak Audience and Average Audience. 3) Draft: ask for those fields, the difference labeled Audience Delta and the percentage ratio rounded to 2 decimal places. 4) Validate inclusion of the exact arithmetic (Peak - Average) and ROUND((Peak/Average)*100.0, 2) and the WHERE condition Peak Audience > Average Audience.",reserved,4,reward,,
"For every team outside the top four, what’s their position and points, how many points are they short of 4th (zero if level or ahead), what’s the minimum number of wins that would cover that gap, and who are the three teams that have conceded the most goals (with the numbers)?","
SELECT
  t.`Position`,
  t.`Team`,
  t.`Points`,
  top4.`Points` AS `Top4 Points`,
  (CASE WHEN top4.`Points` - t.`Points` <= 0 THEN 0 ELSE top4.`Points` - t.`Points` END) AS `Points_to_reach_top4`,
  CAST(((CASE WHEN top4.`Points` - t.`Points` <= 0 THEN 0 ELSE top4.`Points` - t.`Points` END) + 2) / 3 AS INTEGER) AS `Min_wins_needed`,
  td.`Top_3_weak_defenses`
FROM `table_1_15400878_1` AS t
CROSS JOIN (SELECT `Points` FROM `table_1_15400878_1` WHERE `Position` = 4) AS top4
CROSS JOIN (
  SELECT group_concat(`Team` || ' (`' || `Against` || '`) ', ', ') AS `Top_3_weak_defenses`
  FROM (
    SELECT `Team`,`Against` FROM `table_1_15400878_1` ORDER BY `Against` DESC LIMIT 3
  )
) AS td
WHERE t.`Position` > 4
ORDER BY `Points_to_reach_top4` ASC;
","
SELECT
  t.col0,
  t.col1,
  t.col2,
  top4.col2 AS `Top4 Points`,
  (CASE WHEN top4.col2 - t.col2 <= 0 THEN 0 ELSE top4.col2 - t.col2 END) AS `Points_to_reach_top4`,
  CAST(((CASE WHEN top4.col2 - t.col2 <= 0 THEN 0 ELSE top4.col2 - t.col2 END) + 2) / 3 AS INTEGER) AS `Min_wins_needed`,
  td.`Top_3_weak_defenses`
FROM `table_1_15400878_1` AS t
CROSS JOIN (SELECT col2 FROM `table_1_15400878_1` WHERE col0 = 4) AS top4
CROSS JOIN (
  SELECT group_concat(col1 || ' (`' || col8 || '`) ', ', ') AS `Top_3_weak_defenses`
  FROM (
    SELECT col1,col8 FROM `table_1_15400878_1` ORDER BY col8 DESC LIMIT 3
  )
) AS td
WHERE t.col0 > 4
ORDER BY `Points_to_reach_top4` ASC;
","[(5.0, 'ypiranga-sp', 15.0, 19.0, 4.0, 2, 'mackenzie - portuguesa (`77.0`) , aa das palmeiras (`73.0`) , sc internacional de são paulo (`57.0`) '), (6.0, 'minas gerais', 14.0, 19.0, 5.0, 2, 'mackenzie - portuguesa (`77.0`) , aa das palmeiras (`73.0`) , sc internacional de são paulo (`57.0`) '), (7.0, 'sc internacional de são paulo', 11.0, 19.0, 8.0, 3, 'mackenzie - portuguesa (`77.0`) , aa das palmeiras (`73.0`) , sc internacional de são paulo (`57.0`) '), (8.0, 'aa das palmeiras', 5.0, 19.0, 14.0, 5, 'mackenzie - portuguesa (`77.0`) , aa das palmeiras (`73.0`) , sc internacional de são paulo (`57.0`) '), (9.0, 'mackenzie - portuguesa', 3.0, 19.0, 16.0, 6, 'mackenzie - portuguesa (`77.0`) , aa das palmeiras (`73.0`) , sc internacional de são paulo (`57.0`) ')]",table_1_15400878_1,"Persona: A pragmatic São Paulo state league performance analyst who talks in clear football terms and avoids SQL jargon. They know about points, wins and conceded goals but not column names. SQL intent: compute, for every team below 4th, the points gap to 4th (clamped at 0), the minimum wins needed (ceil gap/3), and include the list of the three teams with the most goals conceded. Schema mapping: uses each team's position, name and points and the 4th-placed team's points, plus the top three teams ordered by goals conceded. Draft question: For every team outside the top four, tell me their position, current points, how many points they need to reach 4th (zero if level or ahead), the minimum number of wins that represents, and also list the three teams that have conceded the most goals with their conceded totals. Validation: This matches the query's outputs and scope without adding extra details.",persona,"```json
{
  ""short_persona_description"": ""Performance analyst for a mid-table São Paulo state league club preparing tactical and points targets for the remainder of the season. Uses the league table to identify promotion/relegation risk, efficient teams, and opponents with exploitable defensive weaknesses."",
  ""goals"": [
    ""Determine how many points (or wins) are needed to reach a target position (e.g., top 4) given current standings."",
    ""Identify opponents with poor defensive records (high Goals:  Example Queries: ",reward,,
"For each distinct Landfall, what are the total number of storms, the average CHI rounded to one decimal (Avg_CHI), the highest observed V(mph), and the highest observed R(miles), restricting rows to those with Year in (2003, 2004, 2005) or where Saffir-Simpson Category >= 2 and CHI > 5, keeping only landfalls with more than one storm, and showing the top 5 landfalls ordered by Avg_CHI descending?","
SELECT DISTINCT `t`.`Landfall`, COUNT(*) `Storms`, ROUND(AVG(`CHI`),1) `Avg_CHI`, MAX(`V(mph)`) `Max_V`, MAX(`R(miles)`) `Max_R`
FROM `table_1_15416002_1` AS `t`
WHERE `Year` IN (2003,2004,2005) OR `Saffir-Simpson Category` >= 2 AND `CHI` > 5
GROUP BY `t`.`Landfall`
HAVING COUNT(*) > 1
ORDER BY `Avg_CHI` DESC
LIMIT 5;
","
SELECT DISTINCT `t`.col2, COUNT(*) `Storms`, ROUND(AVG(col7),1) `Avg_CHI`, MAX(col4) `Max_V`, MAX(col5) `Max_R`
FROM `table_1_15416002_1` AS `t`
WHERE col1 IN (2003,2004,2005) OR col6 >= 2 AND col7 > 5
GROUP BY `t`.col2
HAVING COUNT(*) > 1
ORDER BY `Avg_CHI` DESC
LIMIT 5;
","[('louisiana', 2, 12.1, 145.0, 120.0), ('north carolina', 2, 8.7, 110.0, 115.0), ('florida', 5, 6.7, 145.0, 75.0), ('texas', 2, 5.9, 120.0, 85.0)]",table_1_15416002_1,"1) Parse intent: group by Landfall, compute COUNT, ROUND(AVG(CHI),1), MAX V(mph), MAX R(miles), apply row-level filter Year IN (2003,2004,2005) OR (Saffir-Simpson Category >=2 AND CHI>5), require COUNT>1 for groups, sort by Avg_CHI desc and limit to 5. 2) Map schema: use Landfall, CHI, V(mph), R(miles), Year and Saffir-Simpson Category. 3) Draft: craft a natural question asking for these aggregated metrics per landfall with the exact filters, having clause, ordering and limit. 4) Validate: ensure all columns, calculations, filters, HAVING, ORDER BY, and LIMIT are mentioned.",reserved,14,reward,,
Which teams should we focus our training on?,"
WITH team_metrics AS (
  SELECT
    `Locale`,
    `Skip`,
    `W`,
    `L`,
    (CAST(`W` AS REAL) / (CAST(`W` AS REAL) + CAST(`L` AS REAL))) AS `win_pct`,
    CAST(REPLACE(`Shot Pct.`, '%', '') AS REAL) AS `shot_pct`,
    `PF`,
    `PA`,
    (`PF` - `PA`) AS `point_diff`,
    `Ends Won`,
    `Ends Lost`,
    `Blank Ends`,
    `Stolen Ends`,
    ( (`Stolen Ends`) / (CAST(`W` AS REAL) + CAST(`L` AS REAL)) ) AS `stolen_per_game`
  FROM `table_1_1543845_63`
),
stats AS (
  SELECT
    AVG(`shot_pct`) AS `avg_shot`,
    (CASE WHEN (AVG(`shot_pct` * `shot_pct`) - AVG(`shot_pct`) * AVG(`shot_pct`)) > 0 THEN sqrt(AVG(`shot_pct` * `shot_pct`) - AVG(`shot_pct`) * AVG(`shot_pct`)) ELSE 0 END) AS `sd_shot`,
    AVG(`point_diff`) AS `avg_pd`,
    (CASE WHEN (AVG(`point_diff` * `point_diff`) - AVG(`point_diff`) * AVG(`point_diff`)) > 0 THEN sqrt(AVG(`point_diff` * `point_diff`) - AVG(`point_diff`) * AVG(`point_diff`)) ELSE 0 END) AS `sd_pd`,
    AVG(`Stolen Ends`) AS `avg_stolen`,
    (CASE WHEN (AVG(`Stolen Ends` * `Stolen Ends`) - AVG(`Stolen Ends`) * AVG(`Stolen Ends`)) > 0 THEN sqrt(AVG(`Stolen Ends` * `Stolen Ends`) - AVG(`Stolen Ends`) * AVG(`Stolen Ends`)) ELSE 0 END) AS `sd_stolen`,
    AVG(`win_pct`) AS `avg_win`
  FROM team_metrics
)
SELECT
  t.`Locale`,
  t.`Skip`,
  t.`W`,
  t.`L`,
  ROUND(t.`win_pct`, 3) AS `win_pct`,
  t.`shot_pct`,
  t.`PF`,
  t.`PA`,
  t.`point_diff`,
  t.`Stolen Ends`,
  ROUND(t.`stolen_per_game`,3) AS `stolen_per_game`,
  s.`avg_shot`,
  s.`sd_shot`,
  s.`avg_pd`,
  s.`sd_pd`,
  s.`avg_stolen`,
  -- z-scores (normalized metrics)
  ROUND((t.`shot_pct` - s.`avg_shot`) / (CASE WHEN s.`sd_shot` = 0 THEN 1 ELSE s.`sd_shot` END),3) AS `shot_z`,
  ROUND((t.`point_diff` - s.`avg_pd`) / (CASE WHEN s.`sd_pd` = 0 THEN 1 ELSE s.`sd_pd` END),3) AS `pd_z`,
  ROUND((t.`Stolen Ends` - s.`avg_stolen`) / (CASE WHEN s.`sd_stolen` = 0 THEN 1 ELSE s.`sd_stolen` END),3) AS `stolen_z`,
  -- actionable outlier classification to inform training focus
  CASE
    WHEN ( (t.`shot_pct` - s.`avg_shot`) / (CASE WHEN s.`sd_shot` = 0 THEN 1 ELSE s.`sd_shot` END) ) < -1
         AND t.`win_pct` > s.`avg_win` + 0.05
      THEN 'Low shot accuracy but above-average wins -> tactical/steal-focused opponent (work on disrupting steals)'
    WHEN ( (t.`shot_pct` - s.`avg_shot`) / (CASE WHEN s.`sd_shot` = 0 THEN 1 ELSE s.`sd_shot` END) ) > 1
         AND ( (t.`point_diff` - s.`avg_pd`) / (CASE WHEN s.`sd_pd` = 0 THEN 1 ELSE s.`sd_pd` END) ) > 0.5
      THEN 'High precision and positive scoring efficiency -> opponent relies on shot-making (emphasize pressure shots)'
    WHEN t.`Stolen Ends` >= s.`avg_stolen` + s.`sd_stolen`
      THEN 'High stolen-ends contributor -> prioritize blank/defensive practice to avoid steals'
    WHEN ( (t.`point_diff` - s.`avg_pd`) / (CASE WHEN s.`sd_pd` = 0 THEN 1 ELSE s.`sd_pd` END) ) < -1
      THEN 'Negative outlier in point differential -> potential defensive weakness to exploit'
    ELSE 'No strong outlier signal'
  END AS `outlier_insight`
FROM team_metrics t
CROSS JOIN stats s
ORDER BY `shot_z` ASC, `stolen_z` DESC, `point_diff` DESC;
","WITH team_metrics AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    (CAST(col2 AS REAL) / (CAST(col2 AS REAL) + CAST(col3 AS REAL))) AS `win_pct`,
    CAST(REPLACE(col10, '%', '') AS REAL) AS `shot_pct`,
    col4,
    col5,
    (col4 - col5) AS `point_diff`,
    col6,
    col7,
    col8,
    col9,
    ( (col9) / (CAST(col2 AS REAL) + CAST(col3 AS REAL)) ) AS `stolen_per_game`
  FROM `table_1_1543845_63`
)
SELECT
  t.col0,
  t.col1,
  t.col2,
  t.col3,
  ROUND(t.`win_pct`, 3) AS `win_pct`,
  t.`shot_pct`,
  t.col4,
  t.col5,
  t.`point_diff`,
  t.col9,
  ROUND(t.`stolen_per_game`,3) AS `stolen_per_game`,
  s.avg_shot,
  s.sd_shot,
  s.avg_pd,
  s.sd_pd,
  s.avg_stolen,
  ROUND((t.`shot_pct` - s.avg_shot) / (CASE WHEN s.sd_shot = 0 THEN 1 ELSE s.sd_shot END),3) AS `shot_z`,
  ROUND((t.`point_diff` - s.avg_pd) / (CASE WHEN s.sd_pd = 0 THEN 1 ELSE s.sd_pd END),3) AS `pd_z`,
  ROUND((t.col9 - s.avg_stolen) / (CASE WHEN s.sd_stolen = 0 THEN 1 ELSE s.sd_stolen END),3) AS `stolen_z`,
  CASE
    WHEN ( (t.`shot_pct` - s.avg_shot) / (CASE WHEN s.sd_shot = 0 THEN 1 ELSE s.sd_shot END) ) < -1
         AND t.`win_pct` > s.avg_win + 0.05
      THEN 'Low shot accuracy but above-average wins -> tactical/steal-focused opponent (work on disrupting steals)'
    WHEN ( (t.`shot_pct` - s.avg_shot) / (CASE WHEN s.sd_shot = 0 THEN 1 ELSE s.sd_shot END) ) > 1
         AND ( (t.`point_diff` - s.avg_pd) / (CASE WHEN s.sd_pd = 0 THEN 1 ELSE s.sd_pd END) ) > 0.5
      THEN 'High precision and positive scoring efficiency -> opponent relies on shot-making (emphasize pressure shots)'
    WHEN t.col9 >= s.avg_stolen + s.sd_stolen
      THEN 'High stolen-ends contributor -> prioritize blank/defensive practice to avoid steals'
    WHEN ( (t.`point_diff` - s.avg_pd) / (CASE WHEN s.sd_pd = 0 THEN 1 ELSE s.sd_pd END) ) < -1
      THEN 'Negative outlier in point differential -> potential defensive weakness to exploit'
    ELSE 'No strong outlier signal'
  END AS `outlier_insight`
FROM team_metrics t
CROSS JOIN (
  SELECT
    AVG(`shot_pct`) AS avg_shot,
    (CASE WHEN (AVG(`shot_pct` * `shot_pct`) - AVG(`shot_pct`) * AVG(`shot_pct`)) > 0 THEN sqrt(AVG(`shot_pct` * `shot_pct`) - AVG(`shot_pct`) * AVG(`shot_pct`)) ELSE 0 END) AS sd_shot,
    AVG(`point_diff`) AS avg_pd,
    (CASE WHEN (AVG(`point_diff` * `point_diff`) - AVG(`point_diff`) * AVG(`point_diff`)) > 0 THEN sqrt(AVG(`point_diff` * `point_diff`) - AVG(`point_diff`) * AVG(`point_diff`)) ELSE 0 END) AS sd_pd,
    AVG(col9) AS avg_stolen,
    (CASE WHEN (AVG(col9 * col9) - AVG(col9) * AVG(col9)) > 0 THEN sqrt(AVG(col9 * col9) - AVG(col9) * AVG(col9)) ELSE 0 END) AS sd_stolen,
    AVG(`win_pct`) AS avg_win
  FROM team_metrics
) s
ORDER BY `shot_z` ASC, `stolen_z` DESC, `point_diff` DESC;","[('italy', 'joël retornaz', 4.0, 5.0, 0.444, 70.0, 47.0, 66.0, -19.0, 7.0, 0.778, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, -2.47, -1.575, -0.802, 'Negative outlier in point differential -> potential defensive weakness to exploit'), ('switzerland', 'ralph stöckli', 5.0, 4.0, 0.556, 76.0, 56.0, 45.0, 11.0, 10.0, 1.111, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, -0.509, 0.45, -0.2, 'No strong outlier signal'), ('germany', 'andy kapp', 3.0, 6.0, 0.333, 77.0, 53.0, 55.0, -2.0, 12.0, 1.333, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, -0.182, -0.427, 0.2, 'No strong outlier signal'), ('finland', 'markku uusipaavalniemi', 7.0, 2.0, 0.778, 78.0, 53.0, 40.0, 13.0, 9.0, 1.0, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.145, 0.585, -0.401, 'No strong outlier signal'), ('norway', 'pål trulsen', 5.0, 4.0, 0.556, 78.0, 57.0, 47.0, 10.0, 9.0, 1.0, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.145, 0.382, -0.401, 'No strong outlier signal'), ('sweden', 'peja lindholm', 3.0, 6.0, 0.333, 78.0, 45.0, 68.0, -23.0, 4.0, 0.444, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.145, -1.845, -1.403, 'Negative outlier in point differential -> potential defensive weakness to exploit'), ('canada', 'brad gushue', 6.0, 3.0, 0.667, 80.0, 66.0, 46.0, 20.0, 23.0, 2.556, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.799, 1.057, 2.405, 'High stolen-ends contributor -> prioritize blank/defensive practice to avoid steals'), ('united states', 'pete fenson', 6.0, 3.0, 0.667, 80.0, 66.0, 47.0, 19.0, 13.0, 1.444, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.799, 0.99, 0.401, 'No strong outlier signal'), ('great britain', 'david murdoch', 6.0, 3.0, 0.667, 81.0, 59.0, 49.0, 10.0, 12.0, 1.333, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 1.126, 0.382, 0.2, 'No strong outlier signal')]",table_1_1543845_63,"STEP 1: Parse the SQL intent — compute per-team metrics (win percentage, shot percentage, point differential, stolen ends per game), compute dataset averages and standard deviations, produce z-scores and classify teams into actionable 'outlier_insight' labels (training/strategy recommendations), and order results by shot_z asc, stolen_z desc, point_diff desc. STEP 2: Choose ambiguity type — Attachment ambiguity fits: the phrase about focusing training can attach to either the teams (they should receive practice) or to our training (we should practice against them). STEP 3: Draft the question — ""Which teams should we focus our training on?"" STEP 4: Explain ambiguity — in the original query the CASE labels are framed as opponent-focused actionable guidance (i.e., who we should prepare against and how), so the SQL reads the question as which opponents to prioritize preparing for; alternatively the natural reading could mean which teams need internal training (teams that should receive practice themselves).",persona,"National team performance analyst for a curling federation who evaluates opponent and team performance metrics to inform training and game strategy. Uses the 2006 Olympic standings to benchmark historical performance and identify patterns in scoring, steals and shot accuracy. Goals: Compare teams by shot accuracy to identify which opponents rely on precision versus tactical scoring. Quantify scoring efficiency and defensive strength via point differential (PF - PA) and stolen ends. Identify outlier performances (high win rate with lower shot pct, or teams that steal many ends) to inform strategy and practice priorities. Example Queries: SELECT ""Locale"", ""Skip"", ""W"", ""L"", ""Shot Pct."" 
FROM table_1_1543845_63 
ORDER BY CAST(REPLACE(""Shot Pct."", '%', '') AS REAL) DESC, ""W"" DESC; SELECT ""Locale"", ""Skip"", ""PF"", ""PA"", (""PF"" - ""PA"") AS point_diff 
FROM table_1_1543845_63 
ORDER BY point_diff DESC; SELECT ""Locale"", ""Skip"", ""W"", ""L"", (CAST(""W"" AS REAL) / (CAST(""W"" AS REAL) + CAST(""L"" AS REAL))) AS win_pct, ""Stolen Ends"", ""Blank Ends"" 
FROM table_1_1543845_63 
WHERE ""Stolen Ends"" >= 7 
ORDER BY ""Stolen Ends"" DESC, win_pct DESC;",reward,,"type: Attachment ambiguity | explanation: The modifier 'focus our training on' can attach to 'we' (meaning: which opponents we should prepare to face and train against) or to 'teams' (meaning: which teams themselves need to receive/prioritize practice); the SQL's outlier_insight text is written as opponent-focused actionable guidance, but the plain question could reasonably be interpreted the other way."
"For all rows satisfying Report = Report and Rd > 0, what are COUNT(*) AS total_races, SUM((`Pole Position` = `Winning driver`)) AS pole_and_win_count, SUM((`Fastest Lap` = `Winning driver`)) AS fastest_and_win_count, 100.0 * SUM((`Pole Position` = `Winning driver`)) / COUNT(*) AS pole_to_win_pct, and 100.0 * SUM((`Fastest Lap` = `Winning driver`)) / COUNT(*) AS fastest_to_win_pct?","
SELECT COUNT(*) total_races,
       SUM((""`Pole Position`"" = ""`Winning driver`"")) pole_and_win_count,
       SUM((""`Fastest Lap`"" = ""`Winning driver`"")) fastest_and_win_count,
       100.0 * SUM((""`Pole Position`"" = ""`Winning driver`"")) / COUNT(*) pole_to_win_pct,
       100.0 * SUM((""`Fastest Lap`"" = ""`Winning driver`"")) / COUNT(*) fastest_to_win_pct
FROM `table_1_15511178_3`
WHERE ""`Report`"" = ""`Report`"" AND ""`Rd`"" > 0;
","
SELECT COUNT(*) total_races,
       SUM((""col2"" = ""col4"")) pole_and_win_count,
       SUM((""col3"" = ""col4"")) fastest_and_win_count,
       100.0 * SUM((""col2"" = ""col4"")) / COUNT(*) pole_to_win_pct,
       100.0 * SUM((""col3"" = ""col4"")) / COUNT(*) fastest_to_win_pct
FROM `table_1_15511178_3`
WHERE ""col6"" = ""col6"" AND ""col0"" > 0;
","[(9, 5, 2, 55.55555555555556, 22.22222222222222)]",table_1_15511178_3,"1) Parse the SQL intent: aggregate race data to produce counts of races, counts where pole or fastest-lap driver equals the winner, and corresponding percentages, with the filter Report = Report AND Rd > 0. 2) Map schema semantics: leverage `Rd`, `Pole Position`, `Fastest Lap`, `Winning driver`, and `Report` fields. 3) Draft the question: request the five outputs exactly as named and defined by COUNT(*), SUM((... = ...)), and 100.0 * SUM(...)/COUNT(*) expressions under the given WHERE clause. 4) Validate: ensure the question contains total_races, pole_and_win_count, fastest_and_win_count, pole_to_win_pct, fastest_to_win_pct and the conditions Report = Report and Rd > 0.",reserved,4,reward,,
Which states improved the most from the preliminary to the semifinal?,"
SELECT `State`,
(substr(`Preliminary Average`,1,instr(`Preliminary Average`,' ')-1)+0.0) `Preliminary Numeric`,
(substr(`Semifinal Average`,1,instr(`Semifinal Average`,' ')-1)+0.0) `Semifinal Numeric`,
((substr(`Semifinal Average`,1,instr(`Semifinal Average`,' ')-1)+0.0)-(substr(`Preliminary Average`,1,instr(`Preliminary Average`,' ')-1)+0.0)) `Improvement`,
(((substr(`Semifinal Average`,1,instr(`Semifinal Average`,' ')-1)+0.0)-(substr(`Preliminary Average`,1,instr(`Preliminary Average`,' ')-1)+0.0))/(substr(`Preliminary Average`,1,instr(`Preliminary Average`,' ')-1)+0.0)*100.0) `Pct Improvement`
FROM `table_1_15532342_2`
WHERE (substr(`Semifinal Average`,1,instr(`Semifinal Average`,' ')-1)+0.0)>(substr(`Preliminary Average`,1,instr(`Preliminary Average`,' ')-1)+0.0) AND (substr(`Semifinal Average`,1,instr(`Semifinal Average`,' ')-1)+0.0)>=8.0
ORDER BY `Pct Improvement` DESC LIMIT 3;
","
SELECT col0,
(substr(col1,1,instr(col1,' ')-1)+0.0) `Preliminary Numeric`,
(substr(col5,1,instr(col5,' ')-1)+0.0) `Semifinal Numeric`,
((substr(col5,1,instr(col5,' ')-1)+0.0)-(substr(col1,1,instr(col1,' ')-1)+0.0)) `Improvement`,
(((substr(col5,1,instr(col5,' ')-1)+0.0)-(substr(col1,1,instr(col1,' ')-1)+0.0))/(substr(col1,1,instr(col1,' ')-1)+0.0)*100.0) `Pct Improvement`
FROM `table_1_15532342_2`
WHERE (substr(col5,1,instr(col5,' ')-1)+0.0)>(substr(col1,1,instr(col1,' ')-1)+0.0) AND (substr(col5,1,instr(col5,' ')-1)+0.0)>=8.0
ORDER BY `Pct Improvement` DESC LIMIT 3;
","[('arizona', 8.317, 8.774, 0.45699999999999896, 5.494769748707454), ('kentucky', 8.247, 8.598, 0.35100000000000087, 4.256093124772655), ('alabama', 8.334, 8.621, 0.2870000000000008, 3.4437245020398466)]",table_1_15532342_2,"STEP 1: Parse the SQL intent — The query extracts each state's preliminary and semifinal numeric averages, computes the absolute and percent improvement (semifinal minus preliminary and percent change), filters to states whose semifinal score is greater than their preliminary score and at least 8.0, then returns the top 3 states ordered by percent improvement descending. STEP 2: Determine ambiguity type — Metric (measure) ambiguity fits well: the natural phrase ""improved the most"" can refer to different measures (percent improvement, absolute point improvement, rank change, or simply highest semifinal score). The SQL specifically uses percent improvement but a human question wouldn't make that explicit. STEP 3: Draft the question — ""Which states improved the most from the preliminary to the semifinal?"" STEP 4: Explain ambiguity — In the original query ""improved the most"" is implemented as percent improvement with an added filter (semifinal > preliminary and semifinal >= 8.0) and returns the top 3 by percent change. Alternatively, a new query could interpret ""improved the most"" as absolute point gain, as the largest rise in rank/placement, as the highest semifinal score among those who improved, or could omit the semifinal >= 8.0 threshold.",reserved,8,reward,,"type: Metric (measure) ambiguity | explanation: The SQL picks the top 3 by percent improvement and excludes cases where semifinal <= preliminary or semifinal < 8.0, but the question ""improved the most"" could equally mean largest absolute point increase, biggest jump in rank, highest semifinal score after improving, or include all states without the >=8.0 cutoff."
"Which Westinghouse-owned stations had any ownership during the 1950s, and for each what are the city, channel, years owned and current affiliation?","
WITH
params(target_start,target_end) AS (VALUES(1950,1959)),
raw AS (
  SELECT `City of License /Market`, `Station`, `Channel TV ( DT )`, `Years owned`, `Current affiliation`
  FROM `table_1_1553485_1`
),
split AS (
  -- initial token and remainder
  SELECT
    `Station`,
    `City of License /Market`,
    `Channel TV ( DT )`,
    `Years owned`,
    `Current affiliation`,
    CASE WHEN instr(`Years owned`,' ')>0 THEN substr(`Years owned`,1,instr(`Years owned`,' ')-1) ELSE `Years owned` END AS token,
    CASE WHEN instr(`Years owned`,' ')>0 THEN ltrim(substr(`Years owned`,instr(`Years owned`,' ')+1)) ELSE '' END AS rest
  FROM raw
  UNION ALL
  -- recursive split on spaces to emit each range token (e.g. '1953–1956', '1965–1995')
  SELECT
    `Station`,
    `City of License /Market`,
    `Channel TV ( DT )`,
    `Years owned`,
    `Current affiliation`,
    CASE WHEN instr(rest,' ')>0 THEN substr(rest,1,instr(rest,' ')-1) ELSE rest END AS token,
    CASE WHEN instr(rest,' ')>0 THEN ltrim(substr(rest,instr(rest,' ')+1)) ELSE '' END AS rest
  FROM split
  WHERE rest <> ''
),
intervals AS (
  -- parse each token like '1953–1956' into numeric start_year and end_year
  SELECT
    `Station`,
    `City of License /Market`,
    `Channel TV ( DT )`,
    `Years owned`,
    `Current affiliation`,
    CAST(substr(token,1,instr(token,'–')-1) AS INTEGER) AS start_year,
    CAST(substr(token,instr(token,'–')+1) AS INTEGER) AS end_year
  FROM split
  WHERE token <> ''
),
range_counts AS (
  SELECT `Station`, COUNT(*) AS ranges_count
  FROM intervals
  GROUP BY `Station`
)
-- Union of (A) single-interval rows that overlap the target decade and (B) station-pair overlaps within the target decade,
-- with flags for changed affiliation (not CBS) and stations with multiple disjoint ranges.
SELECT
  'single' AS record_type,
  i.`Station` AS StationA,
  i.`City of License /Market` AS CityA,
  i.`Channel TV ( DT )` AS ChannelA,
  i.`Years owned` AS YearsA,
  i.`Current affiliation` AS AffiliationA,
  NULL AS StationB,
  NULL AS CityB,
  NULL AS ChannelB,
  NULL AS YearsB,
  NULL AS AffiliationB,
  CASE WHEN i.start_year > params.target_start THEN i.start_year ELSE params.target_start END AS OverlapStart,
  CASE WHEN i.end_year < params.target_end THEN i.end_year ELSE params.target_end END AS OverlapEnd,
  CASE WHEN i.start_year > params.target_start THEN i.start_year ELSE params.target_start END AS OverlapWithinDecadeStart,
  CASE WHEN i.end_year < params.target_end THEN i.end_year ELSE params.target_end END AS OverlapWithinDecadeEnd,
  CASE WHEN i.`Current affiliation` NOT LIKE '%CBS%' THEN 1 ELSE 0 END AS EitherChangedAffiliation,
  CASE WHEN rc.ranges_count>1 THEN 1 ELSE 0 END AS AnyStationMultipleRanges
FROM intervals i
JOIN params ON 1=1
LEFT JOIN range_counts rc ON rc.`Station` = i.`Station`
WHERE i.end_year >= params.target_start AND i.start_year <= params.target_end

UNION ALL

SELECT
  'pair' AS record_type,
  a.`Station` AS StationA,
  a.`City of License /Market` AS CityA,
  a.`Channel TV ( DT )` AS ChannelA,
  a.`Years owned` AS YearsA,
  a.`Current affiliation` AS AffiliationA,
  b.`Station` AS StationB,
  b.`City of License /Market` AS CityB,
  b.`Channel TV ( DT )` AS ChannelB,
  b.`Years owned` AS YearsB,
  b.`Current affiliation` AS AffiliationB,
  -- overlap across the two station ranges
  CASE WHEN a.start_year > b.start_year THEN a.start_year ELSE b.start_year END AS OverlapStart,
  CASE WHEN a.end_year < b.end_year THEN a.end_year ELSE b.end_year END AS OverlapEnd,
  -- overlap constrained to the target decade window
  CASE WHEN (CASE WHEN a.start_year > b.start_year THEN a.start_year ELSE b.start_year END) > params.target_start THEN (CASE WHEN a.start_year > b.start_year THEN a.start_year ELSE b.start_year END) ELSE params.target_start END AS OverlapWithinDecadeStart,
  CASE WHEN (CASE WHEN a.end_year < b.end_year THEN a.end_year ELSE b.end_year END) < params.target_end THEN (CASE WHEN a.end_year < b.end_year THEN a.end_year ELSE b.end_year END) ELSE params.target_end END AS OverlapWithinDecadeEnd,
  -- flags: either changed affiliation (not CBS) and either has multiple disjoint ranges
  CASE WHEN a.`Current affiliation` NOT LIKE '%CBS%' OR b.`Current affiliation` NOT LIKE '%CBS%' THEN 1 ELSE 0 END AS EitherChangedAffiliation,
  CASE WHEN IFNULL(rca.ranges_count,1)>1 OR IFNULL(rcb.ranges_count,1)>1 THEN 1 ELSE 0 END AS AnyStationMultipleRanges
FROM intervals a
JOIN intervals b ON a.`Station` < b.`Station`
JOIN params ON 1=1
LEFT JOIN range_counts rca ON rca.`Station` = a.`Station`
LEFT JOIN range_counts rcb ON rcb.`Station` = b.`Station`
WHERE
  -- intervals overlap at all
  a.start_year <= b.end_year AND b.start_year <= a.end_year
  -- and that overlap intersects the target decade
  AND (CASE WHEN a.start_year > b.start_year THEN a.start_year ELSE b.start_year END) <= params.target_end
  AND (CASE WHEN a.end_year < b.end_year THEN a.end_year ELSE b.end_year END) >= params.target_start
ORDER BY record_type DESC, OverlapWithinDecadeStart, StationA, StationB;
","SELECT col1, col0, col2, col3, col4 FROM `table_1_1553485_1` WHERE col3 LIKE '%195%';","[('kpix', 'san francisco - oakland - san jose', '5 (29)', '1954–1995', 'cbs owned-and-operated ( o&o )'), ('wjz-tv', 'baltimore', '13 (13)', '1957–1995', 'cbs owned-and-operated (o&o)'), ('kyw-tv (now wkyc-tv )', 'cleveland', '3 (17)', '1956–1965', 'nbc affiliate owned by gannett company'), ('wptz/kyw-tv', 'philadelphia', '3 (26)', '1953–1956 1965–1995', 'cbs owned-and-operated (o&o)')]",table_1_1553485_1,"I'm a broadcast-rights archivist who speaks in plain, station-focused terms and won't use SQL jargon. The SQL is selecting any ownership intervals that overlap the 1950–1959 window and returning station-level fields. The table columns used are City of License /Market, Station, Channel TV ( DT ), Years owned and Current affiliation. Drafted question asks which Westinghouse stations had ownership during the 1950s and requests those fields. This aligns with the query which emits single-interval rows overlapping the target decade with those columns.",persona,"A broadcast-rights forensics archivist who reconstructs who owned local TV stations and when, to clear archival footage and recreate authentic regional broadcasts. Goals: Establish which Westinghouse-owned stations held original broadcast rights for a given year or decade (to determine licensing windows for archival footage). Identify stations that changed current affiliation or ownership (to flag potential secondary rights holders or transfers). Find sets of stations Westinghouse owned simultaneously (to detect multi-station package deals or shared archival contracts) and correlate channel numbers for authentic restoration work. Example Queries: SELECT ""Station"", ""City of License /Market"", ""Channel TV ( DT )"", ""Years owned"", ""Current affiliation"" FROM table_1_1553485_1 WHERE ""Years owned"" LIKE '%195%'; SELECT ""Station"", ""City of License /Market"", ""Years owned"", ""Current affiliation"" FROM table_1_1553485_1 WHERE ""Current affiliation"" NOT LIKE '%CBS%'; SELECT a.""Station"" AS StationA, a.""Years owned"" AS YearsA, b.""Station"" AS StationB, b.""Years owned"" AS YearsB FROM table_1_1553485_1 a JOIN table_1_1553485_1 b ON a.""Station"" < b.""Station"" WHERE a.""Years owned"" LIKE '%196%' AND b.""Years owned"" LIKE '%196%';",reward,,
"Please return a single-row listing the columns 'Time', '12:00 PM', '01:00 PM', '02:00 PM', '03:00 PM', '04:00 PM', '05:00 PM', '05:55 PM' and the program values for each weekday/time: Monday: 'Asian Hero (VJ Mike)' at 12:00 PM, 'Melosamosorn (VJ Woonsen)' at 01:00 PM, 'Asian Chart (VJ Mike)' at 02:00 PM, '[V] Tunes' at 03:00 PM, 'Zog Zag (VJ Loukade, Ake, Bank)' at 04:00 PM, 'Khon Du Pen Yai (Live)' at 05:00 PM, '[V] Covery' at 05:55 PM; Tuesday: 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Mainstage', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery' for 12:00–05:55 PM respectively; Wednesday: 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Siam Top 20 (VJ Bas)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery'; Thursday: 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'The Ticket (VJ Loukade)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery'; Friday: 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', '[V] Countdown (VJ Pitta)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery'; Saturday: 'Asian Hero (VJ Mike)', '[V] Tunes', 'Siam Top 20 (VJ Bas)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery'; and also compute the counts: 'Asian Hero (VJ Mike) Count', 'Melosamosorn (VJ Woonsen) Count', '[V] Tunes Count', 'Zog Zag (VJ Loukade, Ake, Bank) Count', 'Khon Du Pen Yai (Live) Count', '[V] Covery Count', and 'Siam Top 20 (VJ Bas) Count' by summing their individual occurrences as in the query?","
SELECT 
'Time' `Time`,
'12:00 PM' `12:00 PM`,
'01:00 PM' `01:00 PM`,
'02:00 PM' `02:00 PM`,
'03:00 PM' `03:00 PM`,
'04:00 PM' `04:00 PM`,
'05:00 PM' `05:00 PM`,
'05:55 PM' `05:55 PM`,
'Asian Hero (VJ Mike)' `Monday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Monday 01:00 PM`,
'Asian Chart (VJ Mike)' `Monday 02:00 PM`,
'[V] Tunes' `Monday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Monday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Monday 05:00 PM`,
'[V] Covery' `Monday 05:55 PM`,
'Asian Hero (VJ Mike)' `Tuesday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Tuesday 01:00 PM`,
'Mainstage' `Tuesday 02:00 PM`,
'[V] Tunes' `Tuesday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Tuesday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Tuesday 05:00 PM`,
'[V] Covery' `Tuesday 05:55 PM`,
'Asian Hero (VJ Mike)' `Wednesday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Wednesday 01:00 PM`,
'Siam Top 20 (VJ Bas)' `Wednesday 02:00 PM`,
'[V] Tunes' `Wednesday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Wednesday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Wednesday 05:00 PM`,
'[V] Covery' `Wednesday 05:55 PM`,
'Asian Hero (VJ Mike)' `Thursday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Thursday 01:00 PM`,
'The Ticket (VJ Loukade)' `Thursday 02:00 PM`,
'[V] Tunes' `Thursday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Thursday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Thursday 05:00 PM`,
'[V] Covery' `Thursday 05:55 PM`,
'Asian Hero (VJ Mike)' `Friday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Friday 01:00 PM`,
'[V] Countdown (VJ Pitta)' `Friday 02:00 PM`,
'[V] Tunes' `Friday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Friday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Friday 05:00 PM`,
'[V] Covery' `Friday 05:55 PM`,
'Asian Hero (VJ Mike)' `Saturday 12:00 PM`,
'[V] Tunes' `Saturday 01:00 PM`,
'Siam Top 20 (VJ Bas)' `Saturday 02:00 PM`,
'[V] Tunes' `Saturday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Saturday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Saturday 05:00 PM`,
'[V] Covery' `Saturday 05:55 PM`,
(
('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')
) `Asian Hero (VJ Mike) Count`,
(
('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')
) `Melosamosorn (VJ Woonsen) Count`,
(
('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')
) `[V] Tunes Count`,
(
('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')
) `Zog Zag (VJ Loukade, Ake, Bank) Count`,
(
('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')
) `Khon Du Pen Yai (Live) Count`,
(
('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')
) `[V] Covery Count`,
(
('Siam Top 20 (VJ Bas)'='Siam Top 20 (VJ Bas)')+('Siam Top 20 (VJ Bas)'='Siam Top 20 (VJ Bas)')
) `Siam Top 20 (VJ Bas) Count`
WHERE 1 LIMIT 1;
","
SELECT 
'Time' col0,
'12:00 PM' col1,
'01:00 PM' col2,
'02:00 PM' col3,
'03:00 PM' col4,
'04:00 PM' col5,
'05:00 PM' col6,
'05:55 PM' col7,
'Asian Hero (VJ Mike)' `Monday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Monday 01:00 PM`,
'Asian Chart (VJ Mike)' `Monday 02:00 PM`,
'[V] Tunes' `Monday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Monday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Monday 05:00 PM`,
'[V] Covery' `Monday 05:55 PM`,
'Asian Hero (VJ Mike)' `Tuesday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Tuesday 01:00 PM`,
'Mainstage' `Tuesday 02:00 PM`,
'[V] Tunes' `Tuesday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Tuesday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Tuesday 05:00 PM`,
'[V] Covery' `Tuesday 05:55 PM`,
'Asian Hero (VJ Mike)' `Wednesday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Wednesday 01:00 PM`,
'Siam Top 20 (VJ Bas)' `Wednesday 02:00 PM`,
'[V] Tunes' `Wednesday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Wednesday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Wednesday 05:00 PM`,
'[V] Covery' `Wednesday 05:55 PM`,
'Asian Hero (VJ Mike)' `Thursday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Thursday 01:00 PM`,
'The Ticket (VJ Loukade)' `Thursday 02:00 PM`,
'[V] Tunes' `Thursday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Thursday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Thursday 05:00 PM`,
'[V] Covery' `Thursday 05:55 PM`,
'Asian Hero (VJ Mike)' `Friday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Friday 01:00 PM`,
'[V] Countdown (VJ Pitta)' `Friday 02:00 PM`,
'[V] Tunes' `Friday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Friday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Friday 05:00 PM`,
'[V] Covery' `Friday 05:55 PM`,
'Asian Hero (VJ Mike)' `Saturday 12:00 PM`,
'[V] Tunes' `Saturday 01:00 PM`,
'Siam Top 20 (VJ Bas)' `Saturday 02:00 PM`,
'[V] Tunes' `Saturday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Saturday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Saturday 05:00 PM`,
'[V] Covery' `Saturday 05:55 PM`,
(
('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')
) `Asian Hero (VJ Mike) Count`,
(
('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')
) `Melosamosorn (VJ Woonsen) Count`,
(
('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')
) `[V] Tunes Count`,
(
('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')
) `Zog Zag (VJ Loukade, Ake, Bank) Count`,
(
('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')
) `Khon Du Pen Yai (Live) Count`,
(
('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')
) `[V] Covery Count`,
(
('Siam Top 20 (VJ Bas)'='Siam Top 20 (VJ Bas)')+('Siam Top 20 (VJ Bas)'='Siam Top 20 (VJ Bas)')
) `Siam Top 20 (VJ Bas) Count`
WHERE 1 LIMIT 1;
","[('Time', '12:00 PM', '01:00 PM', '02:00 PM', '03:00 PM', '04:00 PM', '05:00 PM', '05:55 PM', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Asian Chart (VJ Mike)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Mainstage', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Siam Top 20 (VJ Bas)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'The Ticket (VJ Loukade)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', '[V] Countdown (VJ Pitta)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', '[V] Tunes', 'Siam Top 20 (VJ Bas)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 6, 5, 7, 6, 6, 6, 2)]",table_1_15535243_3,"1) The SQL constructs a flat single-row output containing the time headers, each cell value for Monday–Saturday, and explicit counts created by adding equality checks for specific show names. 2) Interpret the table rows as weekday schedules mapped to time columns and the counts as tallies of occurrences. 3) Create a question asking for the headers, each weekday/time program string exactly as in the query, and the show occurrence counts. 4) Confirm the question mentions every time column, every weekday/value pair, and every Count column.",reserved,3,reward,,
"List every ecozone with its area, percent protected, protected km² and unprotected km², protected km² per 1,000 km², rank by percent protected, whether it’s a 'pristine' candidate (≥15%) or a 'human-influence' candidate (>500,000 km² and <10% protected), and each ecozone's share of the total protected area, ordered by protected km² per 1,000 km² descending.","
SELECT
  `Ecozone`,
  `Area (km²)`,
  `Percentage protected`,
  (CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)` AS `protected_km2`,
  `Area (km²)` - ((CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)`) AS `unprotected_km2`,
  (((CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)`) / (`Area (km²)` / 1000.0)) AS `protected_km2_per_1000km2`,
  RANK() OVER (ORDER BY CAST(`Percentage protected` AS REAL) DESC) AS `rank_by_percentage_protected`,
  CASE WHEN CAST(`Percentage protected` AS REAL) >= 15 THEN 'Yes' ELSE 'No' END AS `pristine_candidate`,
  CASE WHEN `Area (km²)` > 500000 AND CAST(`Percentage protected` AS REAL) < 10 THEN 'Yes' ELSE 'No' END AS `human_influence_candidate`,
  ((CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)`) / (
    SELECT SUM((CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)`) FROM `table_1_15555661_2`
  ) * 100.0 AS `share_of_total_protected_percent`
FROM `table_1_15555661_2`
ORDER BY `protected_km2_per_1000km2` DESC;
","
SELECT
  col0,
  col1,
  col4,
  (CAST(col4 AS REAL) / 100.0) * col1 AS `protected_km2`,
  col1 - ((CAST(col4 AS REAL) / 100.0) * col1) AS `unprotected_km2`,
  (((CAST(col4 AS REAL) / 100.0) * col1) / (col1 / 1000.0)) AS `protected_km2_per_1000km2`,
  RANK() OVER (ORDER BY CAST(col4 AS REAL) DESC) AS `rank_by_percentage_protected`,
  CASE WHEN CAST(col4 AS REAL) >= 15 THEN 'Yes' ELSE 'No' END AS `pristine_candidate`,
  CASE WHEN col1 > 500000 AND CAST(col4 AS REAL) < 10 THEN 'Yes' ELSE 'No' END AS `human_influence_candidate`,
  ((CAST(col4 AS REAL) / 100.0) * col1) / (
    SELECT SUM((CAST(col4 AS REAL) / 100.0) * col1) FROM `table_1_15555661_2`
  ) * 100.0 AS `share_of_total_protected_percent`
FROM `table_1_15555661_2`
ORDER BY `protected_km2_per_1000km2` DESC;
","[('arctic cordillera', 230873.0, '24.25', 55986.7025, 174886.2975, 242.5, 1, 'Yes', 'No', 6.3134353233094105), ('pacific maritime', 205175.0, '18.87', 38716.5225, 166458.4775, 188.7, 2, 'Yes', 'No', 4.365934227814248), ('montane cordillera', 459680.0, '18.33', 84259.344, 375420.656, 183.29999999999998, 3, 'Yes', 'No', 9.501647622995456), ('southern arctic', 773010.0, '15.89', 122831.289, 650178.711, 158.9, 4, 'Yes', 'No', 13.851278324173968), ('boreal cordillera', 459680.0, '15.28', 70239.10399999999, 389440.896, 152.79999999999998, 5, 'Yes', 'No', 7.920631515513941), ('hudson plains', 353364.0, '11.65', 41166.906, 312197.094, 116.50000000000001, 6, 'No', 'No', 4.642255873021957), ('taiga cordillera', 264480.0, '9.28', 24543.744, 239936.256, 92.79999999999998, 7, 'No', 'No', 2.7677168580497016), ('boreal shield', 1782252.0, '8.06', 143649.5112, 1638602.4888, 80.60000000000001, 8, 'No', 'Yes', 16.19888040711472), ('boreal plains', 679969.0, '7.96', 54125.532400000004, 625843.4676, 79.6, 9, 'No', 'Yes', 6.103557325011024), ('taiga shield', 1253887.0, '6.97', 87395.9239, 1166491.0761, 69.7, 10, 'No', 'Yes', 9.855349367352382), ('taiga plains', 580139.0, '6.92', 40145.6188, 539993.3812, 69.19999999999999, 11, 'No', 'Yes', 4.5270886923200075), ('northern arctic', 1361433.0, '6.69', 91079.8677, 1270353.1323, 66.9, 12, 'No', 'Yes', 10.270775528877198), ('atlantic maritime', 183978.0, '5.33', 9806.0274, 174171.9726, 53.300000000000004, 13, 'No', 'No', 1.105793286691602), ('prairies', 459681.0, '4.49', 20639.676900000002, 439041.3231, 44.900000000000006, 14, 'No', 'No', 2.32746811981208), ('mixedwood plains', 138421.0, '1.59', 2200.8939, 136220.1061, 15.9, 15, 'No', 'No', 0.24818752794230395)]",table_1_15555661_2,"I'm an acoustic ecologist-turned touring composer who thinks in protected percentages and square kilometres when plotting pristine stops, so I'll ask in metric terms without SQL jargon. I know enough about the data to ask for area, percent protected, and derived km² values but I won't toss in column names. The SQL computes protected km², unprotected km², protected km² per 1,000 km², ranks ecozones by percentage protected, flags pristine and human-influence candidates, and computes each ecozone's share of total protected area. I need a single-line request that asks for those per-ecozone metrics and an ordering by protected-area density. List every ecozone with area, percent protected, protected and unprotected km², protected km² per 1,000 km², rank by percentage protected, pristine and human-influence flags, and share of total protected area, ordered highest to lowest by protected km² per 1,000 km².",persona,"An acoustic ecologist-turned touring composer building a pan-Canadian 'sound map' who plans mobile recording stops by choosing ecozones along a gradient from pristine (highly protected) to human-influenced (large, low protection) soundscapes. Goals: Identify ecozones with the highest percentage protected to prioritize 'pristine' soundscape recording sites (likely quieter, less anthropogenic noise). Find large ecozones with low protection percentage to target for recordings that capture human influence, resource-use soundscapes, and edge habitats. Estimate actual protected and unprotected area (km²) per ecozone and overall to plan sampling effort, logistics, and permitted recording locations. Rank candidate ecozones by protected-area density (protected km² per 1,000 km²) to balance route diversity within a limited tour timeframe. Example Queries: -- 1) Top 5 ecozones by percentage protected, with computed protected area (km²)
SELECT ""Ecozone"",
       ""Area (km²)"",
       ""Percentage protected"",
       (CAST(""Percentage protected"" AS REAL) / 100.0) * ""Area (km²)"" AS protected_km2
FROM table_1_15555661_2
ORDER BY CAST(""Percentage protected"" AS REAL) DESC
LIMIT 5; -- 2) Large ecozones (>500,000 km²) with low protection (<10%) to find human-influenced recording targets
SELECT ""Ecozone"",
       ""Area (km²)"",
       ""Percentage protected"",
       (1.0 - CAST(""Percentage protected"" AS REAL) / 100.0) * ""Area (km²)"" AS unprotected_km2
FROM table_1_15555661_2
WHERE CAST(""Percentage protected"" AS REAL) < 10
  AND ""Area (km²)"" > 500000
ORDER BY unprotected_km2 DESC; -- 3) Aggregate totals: overall area, total protected area, and overall percent protected (useful for sampling quotas)
SELECT SUM(""Area (km²)"") AS total_area_km2,
       SUM((CAST(""Percentage protected"" AS REAL) / 100.0) * ""Area (km²)"") AS total_protected_km2,
       (SUM((CAST(""Percentage protected"" AS REAL) / 100.0) * ""Area (km²)"") / SUM(""Area (km²)"")) * 100 AS overall_percentage_protected
FROM table_1_15555661_2;",reward,,
"Which Proto-Austronesian forms (report as PA_form) have COUNT(*) as Matches greater than 0 where Proto-Austronesian equals Proto-Malayo-Polynesian or equals Proto-Oceanic or equals Proto-Polynesian, grouping by Proto-Austronesian and limiting the output to 10 entries?","
SELECT DISTINCT `Proto-Austronesian` AS `PA_form`, COUNT(*) `Matches`
FROM `table_1_15568886_14`
WHERE ((`Proto-Austronesian`=`Proto-Malayo-Polynesian`) + (`Proto-Austronesian`=`Proto-Oceanic`) + (`Proto-Austronesian`=`Proto-Polynesian`)) > 0
GROUP BY `Proto-Austronesian`
HAVING COUNT(*) > 0
LIMIT 10;
","
SELECT DISTINCT col1 AS `PA_form`, COUNT(*) `Matches`
FROM `table_1_15568886_14`
WHERE ((col1=col2) + (col1=col3) + (col1=col4)) > 0
GROUP BY col1
HAVING COUNT(*) > 0
LIMIT 10;
","[('*anak', 1), ('*bahi', 1), ('*t-ama', 1), ('*t-ina', 1)]",table_1_15568886_14,"1) Parse intent: identify Proto-Austronesian entries that appear in any of the three other proto-columns and count occurrences per Proto-Austronesian, excluding zero counts and limiting to 10. 2) Map schema: use Proto-Austronesian (alias PA_form), Proto-Malayo-Polynesian, Proto-Oceanic, Proto-Polynesian and COUNT(*) as Matches. 3) Draft: request PA_form and Matches with the three equality conditions and GROUP BY filter. 4) Validate: ensure question explicitly requires COUNT(*) > 0 and a limit of 10.",reserved,9,reward,,
Which abnormal test(s) are associated with the most conditions?,"
SELECT
  `Prothrombin time`,
  `Partial thromboplastin time`,
  `Bleeding time`,
  `Platelet count`,
  COUNT(*) AS `conditions_count`,
  GROUP_CONCAT(`Condition`, '; ') AS `conditions`,
  (CASE 
     WHEN (CASE WHEN `Prothrombin time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Partial thromboplastin time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Bleeding time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Platelet count` <> 'Unaffected' THEN 1 ELSE 0 END) = 0 THEN 0
     ELSE (CASE WHEN `Prothrombin time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Partial thromboplastin time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Bleeding time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Platelet count` <> 'Unaffected' THEN 1 ELSE 0 END)
   END) AS `abnormal_tests_count`,
  CASE 
    WHEN (CASE WHEN `Prothrombin time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Partial thromboplastin time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Bleeding time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Platelet count` <> 'Unaffected' THEN 1 ELSE 0 END) = 1 THEN 'single-test'
    WHEN (CASE WHEN `Prothrombin time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Partial thromboplastin time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Bleeding time` <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN `Platelet count` <> 'Unaffected' THEN 1 ELSE 0 END) > 1 THEN 'multi-test'
    ELSE 'no abnormal tests'
  END AS `difficulty`
FROM `table_1_1557752_1`
GROUP BY `Prothrombin time`, `Partial thromboplastin time`, `Bleeding time`, `Platelet count`
ORDER BY `conditions_count` DESC, `abnormal_tests_count` ASC;
","
SELECT
  col1,
  col2,
  col3,
  col4,
  COUNT(*) AS `conditions_count`,
  GROUP_CONCAT(col0, '; ') AS `conditions`,
  (CASE 
     WHEN (CASE WHEN col1 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col2 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col3 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col4 <> 'Unaffected' THEN 1 ELSE 0 END) = 0 THEN 0
     ELSE (CASE WHEN col1 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col2 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col3 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col4 <> 'Unaffected' THEN 1 ELSE 0 END)
   END) AS `abnormal_tests_count`,
  CASE 
    WHEN (CASE WHEN col1 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col2 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col3 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col4 <> 'Unaffected' THEN 1 ELSE 0 END) = 1 THEN 'single-test'
    WHEN (CASE WHEN col1 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col2 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col3 <> 'Unaffected' THEN 1 ELSE 0 END
           + CASE WHEN col4 <> 'Unaffected' THEN 1 ELSE 0 END) > 1 THEN 'multi-test'
    ELSE 'no abnormal tests'
  END AS `difficulty`
FROM `table_1_1557752_1`
GROUP BY col1, col2, col3, col4
ORDER BY `conditions_count` DESC, `abnormal_tests_count` ASC;
","[('unaffected', 'unaffected', 'prolonged', 'unaffected', 3, ""aspirin; uremia; glanzmann's thrombasthenia"", 4, 'multi-test'), ('prolonged', 'prolonged', 'prolonged', 'decreased', 2, 'disseminated intravascular coagulation; liver failure, end-stage', 4, 'multi-test'), ('prolonged', 'prolonged', 'unaffected', 'unaffected', 2, 'factor v deficiency; factor x deficiency as seen in amyloid purpura', 4, 'multi-test'), ('unaffected', 'prolonged', 'unaffected', 'unaffected', 2, 'hemophilia; factor xii deficiency', 4, 'multi-test'), ('prolonged', 'normal or mildly prolonged', 'unaffected', 'unaffected', 1, 'vitamin k deficiency or warfarin', 4, 'multi-test'), ('prolonged', 'prolonged', 'prolonged', 'unaffected', 1, 'congenital afibrinogenemia', 4, 'multi-test'), ('prolonged', 'unaffected', 'unaffected', 'unaffected', 1, 'liver failure , early', 4, 'multi-test'), ('unaffected', 'prolonged or unaffected', 'prolonged', 'unaffected', 1, 'von willebrand disease', 4, 'multi-test'), ('unaffected', 'unaffected', 'prolonged', 'decreased', 1, 'thrombocytopenia', 4, 'multi-test'), ('unaffected', 'unaffected', 'prolonged', 'decreased or unaffected', 1, 'bernard-soulier syndrome', 4, 'multi-test')]",table_1_1557752_1,"STEP 1: Parse the SQL intent: the query groups rows by the four lab-test columns (Prothrombin time, Partial thromboplastin time, Bleeding time, Platelet count), counts how many conditions share each exact combination (conditions_count), concatenates the condition names, computes how many of the four tests in each group are abnormal (abnormal_tests_count, i.e. not 'Unaffected'), and classifies groups as 'single-test', 'multi-test', or 'no abnormal tests'. Results are ordered by conditions_count descending, then abnormal_tests_count ascending. STEP 2: Choose an ambiguity type: scope ambiguity fits well — a short question about which test(s) are ""associated with the most conditions"" can mean either (a) which single test abnormality (e.g., Prolonged PT) occurs in the most conditions, or (b) which specific combination/pattern of abnormalities occurs in the most conditions (what the SQL actually returns). STEP 3: Draft the question: ""Which abnormal test(s) are associated with the most conditions?"" STEP 4: Explain ambiguity: in the original query this is interpreted as the most common exact combination of abnormalities (grouped by all four tests). In a different interpretation the question could ask for counts per individual test across all rows (requiring aggregating by each test separately), or even for per-condition maxima — so the phrasing is ambiguous about whether 'test(s)' refers to single tests, test combinations, or a different aggregation scope.",persona,"A medical escape-room designer who builds realistic diagnostic puzzles for trainees using authentic coagulation lab-patterns. Goals: Find distinct combinations of PT, PTT, bleeding time, and platelet count to create unambiguous puzzle clues. Identify commonly confused disorder pairs (similar lab patterns) to design multi-step elimination puzzles. Select disorders with a single-test abnormality vs. multi-test abnormalities to vary puzzle difficulty and create progressive hints. Example Queries: SELECT ""Condition"", ""Prothrombin time"", ""Partial thromboplastin time"", ""Bleeding time"", ""Platelet count"" FROM table_1_1557752_1 WHERE ""Prothrombin time"" = 'Prolonged' AND ""Partial thromboplastin time"" = 'Prolonged' AND ""Bleeding time"" = 'Prolonged'; SELECT ""Condition"" FROM table_1_1557752_1 WHERE ""Bleeding time"" = 'Prolonged' AND ""Platelet count"" LIKE '%Decreased%'; SELECT ""Condition"", ""Prothrombin time"", ""Partial thromboplastin time"", ""Bleeding time"", ""Platelet count"" FROM table_1_1557752_1 WHERE ""Prothrombin time"" = 'Prolonged' AND (""Partial thromboplastin time"" = 'Unaffected' OR ""Partial thromboplastin time"" = 'Normal or mildly prolonged') AND ""Bleeding time"" = 'Unaffected' AND ""Platelet count"" = 'Unaffected';",reward,,"type: Scope ambiguity (single test vs test combination) | explanation: The SQL treats 'test(s)' as the full combination of the four test results (groups by all four columns) and returns the combination seen in the most conditions; alternatively the question could be read as asking which single test abnormality (e.g., Prolonged PT) appears in the most conditions, or asking per-condition rather than per-combination frequencies — these are different aggregations and would need different queries."
"For each launch vehicle, what is its failure rate, the average mass for successful versus failed missions, how many missions returned photos, and how did the number of successful missions change over time?","
SELECT
  `Launch vehicle`,
  COUNT(*) AS total_missions,
  SUM(CASE WHEN `Mission result` LIKE 'Failure%' THEN 1 ELSE 0 END) AS failures,
  ROUND(100.0 * SUM(CASE WHEN `Mission result` LIKE 'Failure%' THEN 1 ELSE 0 END) / COUNT(*), 2) AS failure_rate_pct,
  ROUND(AVG(CASE WHEN `Mission result` LIKE 'Success%' THEN `Mass (kg)` END), 2) AS avg_mass_success_kg,
  ROUND(AVG(CASE WHEN `Mission result` LIKE 'Failure%' THEN `Mass (kg)` END), 2) AS avg_mass_failure_kg,
  SUM(CASE WHEN `Mission result` LIKE 'Success%' THEN 1 ELSE 0 END) AS successes,
  SUM(CASE WHEN `Mission result` LIKE '%returned%photo%' THEN 1 ELSE 0 END) AS missions_returned_photos,
  MIN(CAST(SUBSTR(`Launched`, -4) AS INTEGER)) AS first_launch_year,
  MAX(CAST(SUBSTR(`Launched`, -4) AS INTEGER)) AS last_launch_year,
  (
    SELECT GROUP_CONCAT(year || ':' || successes, '; ')
    FROM (
      SELECT CAST(SUBSTR(t.`Launched`, -4) AS INTEGER) AS year,
             SUM(CASE WHEN t.`Mission result` LIKE 'Success%' THEN 1 ELSE 0 END) AS successes
      FROM `table_1_1558077_2` t
      WHERE t.`Launch vehicle` = mv.`Launch vehicle`
      GROUP BY year
      ORDER BY year
    )
  ) AS year_success_trend
FROM `table_1_1558077_2` AS mv
GROUP BY `Launch vehicle`
ORDER BY failure_rate_pct DESC;
","
SELECT
  col2,
  COUNT(*) AS total_missions,
  SUM(CASE WHEN col5 LIKE 'Failure%' THEN 1 ELSE 0 END) AS failures,
  ROUND(100.0 * SUM(CASE WHEN col5 LIKE 'Failure%' THEN 1 ELSE 0 END) / COUNT(*), 2) AS failure_rate_pct,
  ROUND(AVG(CASE WHEN col5 LIKE 'Success%' THEN col1 END), 2) AS avg_mass_success_kg,
  ROUND(AVG(CASE WHEN col5 LIKE 'Failure%' THEN col1 END), 2) AS avg_mass_failure_kg,
  SUM(CASE WHEN col5 LIKE 'Success%' THEN 1 ELSE 0 END) AS successes,
  SUM(CASE WHEN col5 LIKE '%returned%photo%' THEN 1 ELSE 0 END) AS missions_returned_photos,
  MIN(CAST(SUBSTR(col3, -4) AS INTEGER)) AS first_launch_year,
  MAX(CAST(SUBSTR(col3, -4) AS INTEGER)) AS last_launch_year,
  (
    SELECT GROUP_CONCAT(year || ':' || successes, '; ')
    FROM (
      SELECT CAST(SUBSTR(t.col3, -4) AS INTEGER) AS year,
             SUM(CASE WHEN t.col5 LIKE 'Success%' THEN 1 ELSE 0 END) AS successes
      FROM `table_1_1558077_2` t
      WHERE t.col2 = mv.col2
      GROUP BY year
      ORDER BY year
    )
  ) AS year_success_trend
FROM `table_1_1558077_2` AS mv
GROUP BY col2
ORDER BY failure_rate_pct DESC;
","[('thor-able', 3, 3, 100.0, None, 37.0, 0, 0, 1958, 1958, '1958:0'), ('juno', 1, 1, 100.0, None, 6.0, 0, 0, 1958, 1958, '1958:0'), ('atlas-able', 4, 4, 100.0, None, 171.5, 0, 0, 1959, 1960, '1959:0; 1960:0'), ('atlas – agena', 7, 5, 71.43, 367.0, 329.8, 2, 2, 1961, 1965, '1961:0; 1962:0; 1964:1; 1965:1')]",table_1_1558077_2,"STEP 1: Parse the SQL intent — group rows by Launch vehicle and for each vehicle compute total missions, failures, failure rate (%), average mass for successful missions, average mass for failed missions, counts of successes and missions that 'returned ... photo', first and last launch years, and a year-by-year count of successes concatenated as 'year:successes'. STEP 2: Choose an ambiguity type — scope ambiguity fits best: the query returns per-vehicle aggregates and also a per-vehicle per-year success trend, so a natural question can be read as asking either for per-vehicle summaries or for aggregate trends across vehicles/years. STEP 3: Draft the question — produce a phrasing that matches the SQL result but is plausibly read in multiple ways. STEP 4: Explain ambiguity — the SQL gives per-launch-vehicle totals and a per-vehicle year_success_trend; a reader could instead interpret the question as asking for an overall/top vehicle measure or year-by-year aggregates across all vehicles rather than per-vehicle trends.",persona,"Aerospace reliability engineer working on historical mission lessons-learned at a space agency, analyzing early U.S. unmanned lunar missions to inform current failure-mode assessments and design reviews. They use this database to quantify failure patterns by vehicle, era, and spacecraft characteristics. Goals: Identify which launch vehicles had the highest failure rates in early lunar missions to prioritize design review topics. Detect temporal trends in mission outcomes (success vs failure) between 1958 and 1965 to see whether reliability improved over time. Compare physical characteristics (e.g., mass) of missions that succeeded versus failed and pinpoint missions that returned useful scientific data (e.g., photos). Example Queries: /* Failure rate by launch vehicle */
SELECT [Launch vehicle],
       COUNT(*) AS total_missions,
       SUM(CASE WHEN [Mission result] LIKE 'Failure%' THEN 1 ELSE 0 END) AS failures,
       ROUND(100.0 * SUM(CASE WHEN [Mission result] LIKE 'Failure%' THEN 1 ELSE 0 END) / COUNT(*), 2) AS failure_rate_pct
FROM table_1_1558077_2
GROUP BY [Launch vehicle]
ORDER BY failure_rate_pct DESC; /* Average mass for successes vs failures */
SELECT CASE WHEN [Mission result] LIKE 'Success%' THEN 'Success' ELSE 'Failure' END AS outcome,
       COUNT(*) AS mission_count,
       AVG([Mass (kg)]) AS avg_mass_kg
FROM table_1_1558077_2
GROUP BY outcome
ORDER BY outcome DESC; /* Yearly trend of successes vs failures (extracting year from Launched) */
SELECT CAST(SUBSTR([Launched], -4) AS INTEGER) AS year,
       COUNT(*) AS total_missions,
       SUM(CASE WHEN [Mission result] LIKE 'Success%' THEN 1 ELSE 0 END) AS successes,
       SUM(CASE WHEN [Mission result] LIKE 'Failure%' THEN 1 ELSE 0 END) AS failures
FROM table_1_1558077_2
GROUP BY year
ORDER BY year ASC;",reward,,type: Scope ambiguity | explanation: The SQL returns metrics grouped per launch vehicle plus a per-vehicle year-by-year success trend; the question can be read as asking for those per-vehicle summaries (the original query) or alternatively as asking for overall/top failure rates across all vehicles and/or year-by-year success counts aggregated across all vehicles rather than per vehicle.
"Which distinct Positions have more than one player, and for each such Position show Position, the number of players (COUNT(*) labeled Players), the average Weight rounded to one decimal (ROUND(AVG(Weight),1) labeled Avg Weight), and a comma-and-space joined Players list of Player name values (GROUP_CONCAT(Player name, ', ')), restricting rows to those with Round equal to 1, 4, or 5 and either Choice > 100 or Weight between 195 and 260, ordering the results by average weight descending and returning up to 10 entries?","
SELECT DISTINCT `Position` AS `Position`, COUNT(*) `Players`, ROUND(AVG(`Weight`),1) `Avg Weight`, GROUP_CONCAT(`Player name`, ', ') `Players list`
FROM `table_1_15582870_1`
WHERE `Round` IN (1,4,5) AND (`Choice` > 100 OR `Weight` BETWEEN 195 AND 260)
GROUP BY `Position`
HAVING COUNT(*) > 1
ORDER BY AVG(`Weight`) DESC
LIMIT 10;
","
SELECT DISTINCT col3 AS col3, COUNT(*) `Players`, ROUND(AVG(col5),1) `Avg Weight`, GROUP_CONCAT(col2, ', ') `Players list`
FROM `table_1_15582870_1`
WHERE col0 IN (1,4,5) AND (col1 > 100 OR col5 BETWEEN 195 AND 260)
GROUP BY col3
HAVING COUNT(*) > 1
ORDER BY AVG(col5) DESC
LIMIT 10;
","[('running back', 2, 206.0, 'felix jones, tashard choice'), ('cornerback', 2, 197.5, 'mike jenkins, orlando scandrick')]",table_1_15582870_1,"1) The intent is to aggregate players by Position and report count, rounded average weight, and concatenated names for a filtered subset of rows. 2) Map schema: use Round, Choice, Weight, Player name, Position to apply filters and produce aggregates. 3) Draft a question that requests Position, COUNT(*) as Players, ROUND(AVG(Weight),1) as Avg Weight, GROUP_CONCAT(Player name, ', ') as Players list with Round IN (1,4,5) and (Choice>100 OR Weight BETWEEN 195 AND 260), HAVING COUNT(*)>1, ordered by AVG(Weight) DESC, limited to 10. 4) Confirm all SQL elements are included in the phrasing.",reserved,15,reward,,
"List each director (Directed by) with their Episode Count (number of Title entries), Avg Viewers (AVG of U.S. viewers (million)), Max Viewers (MAX of U.S. viewers (million)), and Min Viewers (MIN of U.S. viewers (million)), sorted by Avg Viewers from highest to lowest.","
SELECT t1.`Directed by`, COUNT(t1.`Title`) `Episode Count`, AVG(t1.`U.S. viewers (million)`) `Avg Viewers`, MAX(t1.`U.S. viewers (million)`) `Max Viewers`, MIN(t1.`U.S. viewers (million)`) `Min Viewers`
FROM `table_1_15584067_7` t1 JOIN `table_1_15584067_7` t2 ON t2.`Directed by` = t1.`Directed by`
WHERE t1.`U.S. viewers (million)` >= t2.`U.S. viewers (million)`
GROUP BY t1.`Directed by`
ORDER BY AVG(t1.`U.S. viewers (million)`) DESC;
","
SELECT t1.col3, COUNT(t1.col2) `Episode Count`, AVG(t1.col6) `Avg Viewers`, MAX(t1.col6) `Max Viewers`, MIN(t1.col6) `Min Viewers`
FROM `table_1_15584067_7` t1 JOIN `table_1_15584067_7` t2 ON t2.col3 = t1.col3
WHERE t1.col6 >= t2.col6
GROUP BY t1.col3
ORDER BY AVG(t1.col6) DESC;
","[('bille woodruff', 3, 3.026666666666667, '3.58', '1.92'), ('nzingha stewart', 1, 2.59, '2.59', '2.59'), ('kenny smith', 3, 2.5100000000000002, '2.66', '2.21'), ('billie woodruff', 1, 2.41, '2.41', '2.41'), ('eric laneuville', 1, 2.4, '2.40', '2.40'), ('mary lou belli', 15, 2.2906666666666666, '2.50', '1.60'), ('salim akil', 15, 2.1453333333333333, '2.54', '1.74')]",table_1_15584067_7,"1) Parse intent: group rows by director and compute aggregate viewer statistics and episode count, then sort by average viewers high-to-low. 2) Map schema: use 'Directed by' as group key, count 'Title' for episodes, and use 'U.S. viewers (million)' for AVG/MAX/MIN. 3) Draft: request these aggregates per director and specify descending order by average. 4) Validate: question mirrors the SQL aggregates and ordering.",reserved,9,reward,,
"For each Position, show Position, Players (COUNT(*)), Avg Height Inches computed as ROUND(AVG((substr(Height,1,1)+0)*12 + (substr(Height,3,1)+0)),2), Avg Weight computed as ROUND(AVG(Weight),1), and Players Sample composed by concatenating Player name values with each name enclosed in backticks and separated by ', ' (GROUP_CONCAT('`' || Player name || '`', ', ')), using rows matching ((Weight > 0 AND Height <> '') OR 1=1), grouping by Position and ordering the output by Avg Weight in descending order?","
SELECT `Position`, COUNT(*) `Players`, ROUND(AVG((substr(`Height`,1,1)+0)*12 + (substr(`Height`,3,1)+0)),2) `Avg Height Inches`, ROUND(AVG(`Weight`),1) `Avg Weight`, GROUP_CONCAT('`' || `Player name` || '`', ', ') `Players Sample` FROM `table_1_15592941_1` WHERE (`Weight` > 0 AND `Height` <> '') OR 1=1 GROUP BY `Position` ORDER BY `Avg Weight` DESC;
","SELECT col3, COUNT(*) `Players`, ROUND(AVG((substr(col4,1,1)+0)*12 + (substr(col4,3,1)+0)),2) `Avg Height Inches`, ROUND(AVG(col5),1) `Avg Weight`, GROUP_CONCAT(col2, ', ') `Players Sample` FROM `table_1_15592941_1` WHERE (col5 > 0 AND col4 <> '') OR 1=1 GROUP BY col3 ORDER BY `Avg Weight` DESC;","[('dt', 1, 76.0, 305.0, 'dre moore'), ('ol', 1, 76.0, 295.0, 'jeremy zuttah'), ('lb', 1, 73.0, 226.0, 'geno hayes'), ('cb', 1, 73.0, 206.0, 'aqib talib'), ('qb', 1, 74.0, 201.0, 'josh johnson'), ('wr / kr', 1, 69.0, 182.0, 'dexter jackson')]",table_1_15592941_1,"1) Parse: the SQL groups by Position and returns count, an AVG of a derived height-in-inches expression with two-decimal rounding, an AVG weight rounded to one decimal, and a GROUP_CONCAT of player names wrapped in backticks; it uses a WHERE clause that includes (Weight > 0 AND Height <> '') OR 1=1 and orders by Avg Weight DESC. 2) Map: Height is parsed via substr(Height,1,1) and substr(Height,3,1); Player name is concatenated. 3) Draft question to request these exact outputs and ordering. 4) Ensure all calculations, rounding, concatenation format, GROUP BY and WHERE are explicitly included.",reserved,9,reward,,
"List the five clubs (limit 5) with First season > 0, returning for each Club its Number of seasons in Superettan (Superettan), its Number of seasons in second tier (SecondTier), an Is_Husqvarna field equal to true when the Club = 'Husqvarna FF', NearestGap equal to the absolute difference between that club's First season and any other club's First season, and Penetration which should be 'High penetration' when (Number of seasons in Superettan * 1.0 / (Number of seasons in second tier + 0)) > 0.5 otherwise 'Low penetration', ordered by Penetration descending then by NearestGap?","
SELECT
  m.`Club` `Club`,
  m.`Number of seasons in Superettan` `Superettan`,
  m.`Number of seasons in second tier` `SecondTier`,
  (m.`Club` = '`Husqvarna FF`') `Is_Husqvarna`,
  ABS(m.`First season` - j.`First season`) `NearestGap`,
  CASE WHEN (m.`Number of seasons in Superettan` * 1.0 / (m.`Number of seasons in second tier` + 0)) > 0.5 THEN '`High penetration`' ELSE '`Low penetration`' END AS `Penetration`
FROM `table_1_1560673_1` m
JOIN `table_1_1560673_1` j ON j.`Club` != m.`Club`
WHERE m.`First season` > 0
GROUP BY m.`Club`
ORDER BY `Penetration` DESC, `NearestGap`
LIMIT 5;
","
SELECT
  m.col0 col0,
  m.col4 `Superettan`,
  m.col5 `SecondTier`,
  (m.col0 = '`Husqvarna FF`') `Is_Husqvarna`,
  ABS(m.col2 - j.col2) `NearestGap`,
  CASE WHEN (m.col4 * 1.0 / (m.col5 + 0)) > 0.5 THEN '`High penetration`' ELSE '`Low penetration`' END AS `Penetration`
FROM `table_1_1560673_1` m
JOIN `table_1_1560673_1` j ON j.col0 != m.col0
WHERE m.col2 > 0
GROUP BY m.col0
ORDER BY `Penetration` DESC, `NearestGap`
LIMIT 5;
","[('landskrona bois', 10.0, '51', 0, 0.0, '`Low penetration`'), ('östers if', 9.0, '19', 0, 0.0, '`Low penetration`'), ('gais', 4.0, '29', 0, 1.0, '`Low penetration`'), ('degerfors if', 8.0, '35', 0, 5.0, '`Low penetration`'), ('jönköpings södra', 8.0, '35', 0, 6.0, '`Low penetration`')]",table_1_1560673_1,"1) The SQL selects distinct clubs with numerical and derived columns, flags Husqvarna, computes an absolute First season gap to other clubs, classifies penetration by a ratio > 0.5, filters First season > 0, sorts by penetration then gap, and returns five rows. 2) Map fields and calculations to natural language: include Club, Superettan seasons, second-tier seasons, Is_Husqvarna boolean, NearestGap as absolute difference to another club's First season, and the Penetration CASE expression. 3) Produce a concise question that asks for these five output columns for the top five clubs given the ordering and filter. 4) Confirm the question mentions all computations, ordering, grouping by club (distinct clubs), and the 5-row limit without introducing extra details.",reserved,16,reward,,
Which wheel arrangements were mostly at March?,"
SELECT DISTINCT printf('`%s`', `Wheel Arrangement`) `Wheel Arrangement`, printf('`%s`', `Class`) `Example_Class`, SUM(`Number at Doncaster`) `Doncaster_Total`, SUM(`Number at Pyewipe`) `Pyewipe_Total`, SUM(`Number at March`) AS `Total` FROM `table_1_15608800_2` WHERE (`Number at Doncaster` + `Number at Pyewipe` + `Number at March`) > 0 GROUP BY `Wheel Arrangement` HAVING (SUM(`Number at March`)*1.0)/SUM(`Number at Doncaster` + `Number at Pyewipe` + `Number at March`) > 0.5 LIMIT 5;
","
SELECT DISTINCT printf('`%s`', col1) col1, printf('`%s`', col0) `Example_Class`, SUM(col3) `Doncaster_Total`, SUM(col4) `Pyewipe_Total`, SUM(col5) AS `Total` FROM `table_1_15608800_2` WHERE (col3 + col4 + col5) > 0 GROUP BY col1 HAVING (SUM(col5)*1.0)/SUM(col3 + col4 + col5) > 0.5 LIMIT 5;
","[('`0-6-0`', '`j14`', 0.0, 6.0, 69.0), ('`0-6-0t`', '`j66`', 0.0, 3.0, 12.0), ('`2-4-0`', '`e4`', 1.0, 0.0, 4.0), ('`4-4-0`', '`d13`', 4.0, 3.0, 11.0)]",table_1_15608800_2,"STEP 1: Parse the SQL intent — Group rows by Wheel Arrangement, sum Number at Doncaster, Number at Pyewipe and Number at March per wheel arrangement, require that the group has a positive total and that more than 50% of that group's total is at March; return Wheel Arrangement, an example Class, the sums and limit to 5. STEP 2: Determine ambiguity type — Scope ambiguity fits: phrasing like ""mostly at March"" can mean a per-arrangement majority (>50%, which the SQL uses) or a comparative/top measure across arrangements (the single arrangement with the largest March count or share). STEP 3: Draft the question — ""Which wheel arrangements were mostly at March?"" STEP 4: Explain the ambiguity — In the original query ""mostly at March"" is implemented as a per-wheel-arrangement proportion check (Number at March > 50% of that arrangement's total). Alternatively it could be read as asking for the arrangement(s) with the highest absolute number at March, or the arrangement(s) contributing the majority of all March locomotives (a different global comparison).",reserved,9,reward,,"type: Scope ambiguity | explanation: The SQL treats ""mostly at March"" as a per-wheel-arrangement majority (>50% of that arrangement's locomotives are at March). A different interpretation could ask instead for the arrangement with the largest number at March overall, or which arrangements make up the majority of all March locomotives (a global comparison)."
"Which Player and the corresponding COUNT(*) as Stints are returned when selecting rows where Player is in (Player), grouping results by Player, keeping only groups with COUNT(*) > 1, and ordering the output by Stints descending?","
SELECT `Player` AS `Player`, COUNT(*) AS `Stints`
FROM `table_1_15621965_14`
WHERE `Player` IN (`Player`)
GROUP BY `Player`
HAVING COUNT(*) > 1
ORDER BY `Stints` DESC;
","
SELECT col0 AS col0, COUNT(*) AS `Stints`
FROM `table_1_15621965_14`
WHERE col0 IN (col0)
GROUP BY col0
HAVING COUNT(*) > 1
ORDER BY `Stints` DESC;
","[('bo outlaw', 2)]",table_1_15621965_14,"1) Parse intent: produce a count of rows per Player and return only those players with more than one row, sorted highest count first. 2) Map schema: Player column and COUNT(*) aggregated as Stints. 3) Draft: ask for Player and Stints with the WHERE Player IN (Player) constraint, GROUP BY Player, HAVING COUNT(*) > 1, ORDER BY Stints DESC. 4) Validate: ensures all SQL components—selected columns, aggregation, where-in, grouping, having, and ordering—are represented.",reserved,11,reward,,
"Which five distinct Cover model values have the highest Appearances (COUNT(*)), and for each what are the Appearances, the SameAsCenterfold count (SUM(Cover model = Centerfold model)), and the Chyna count (SUM(Cover model = 'Chyna')) when the table is self-joined on Date, excluding empty Date rows, grouped by Cover model with COUNT(*) >= 1 and ordered by Appearances descending?","
SELECT DISTINCT t1.`Cover model` AS `Cover model`, COUNT(*) `Appearances`, SUM(t1.`Cover model` = t1.`Centerfold model`) `SameAsCenterfold`, SUM(t1.`Cover model` = 'Chyna') `Chyna`
FROM `table_1_1566852_3` t1
JOIN `table_1_1566852_3` t2 ON t1.`Date` = t2.`Date`
WHERE t1.`Date` <> ''
GROUP BY t1.`Cover model`
HAVING COUNT(*) >= 1
ORDER BY `Appearances` DESC
LIMIT 5;
","
SELECT DISTINCT t1.col1 AS col1, COUNT(*) `Appearances`, SUM(t1.col1 = t1.col2) `SameAsCenterfold`, SUM(t1.col1 = 'Chyna') `Chyna`
FROM `table_1_1566852_3` t1
JOIN `table_1_1566852_3` t2 ON t1.col0 = t2.col0
WHERE t1.col0 <> ''
GROUP BY t1.col1
HAVING COUNT(*) >= 1
ORDER BY `Appearances` DESC
LIMIT 5;
","[('teri marie harrison', 1, 1, 0), ('kristy swanson', 1, 0, 0), ('kira kener , dasha , tera patrick', 1, 0, 0), ('kiana tom', 1, 0, 0), ('jordan', 1, 0, 0)]",table_1_1566852_3,"1) Parse intent: aggregate rows per Cover model to compute total appearances and two conditional sums, applying a non-empty Date constraint and limiting to five results. 2) Map schema: use Cover model and Centerfold model columns; the query self-joins on Date but groups by Cover model and filters out empty Date. 3) Draft: ask explicitly for Cover model, Appearances (COUNT(*)), SameAsCenterfold (SUM(Cover model = Centerfold model)), and Chyna (SUM(Cover model = 'Chyna')) with the join, filter, group, having, order, and limit. 4) Validate: ensure all calculations and clauses (JOIN ON Date, Date <> '', HAVING COUNT(*) >= 1, ORDER BY Appearances DESC, LIMIT 5) are represented.",reserved,13,reward,,
"Which issues list pictorials that explicitly name the cover, centerfold, or interview subject, or contain group-theme keywords like 'Girls', 'Ladies', 'Women', 'Cyber' or 'Big Ten', and show the date, cover, centerfold, interview subject, the pictorials text and which of those matches are present?","
SELECT
  `Date`,
  `Cover model`,
  `Centerfold model`,
  `Interview subject`,
  `Pictorials`,
  CASE WHEN `Pictorials` LIKE '%' || `Cover model` || '%' THEN 1 ELSE 0 END AS `Cover_in_Pictorials`,
  CASE WHEN `Pictorials` LIKE '%' || `Centerfold model` || '%' THEN 1 ELSE 0 END AS `Centerfold_in_Pictorials`,
  CASE WHEN `Pictorials` LIKE '%' || `Interview subject` || '%' THEN 1 ELSE 0 END AS `Interview_in_Pictorials`,
  CASE WHEN `Pictorials` LIKE '%Girls%' OR `Pictorials` LIKE '%Ladies%' OR `Pictorials` LIKE '%Women%' OR `Pictorials` LIKE '%Cyber%' OR `Pictorials` LIKE '%Big Ten%' THEN 1 ELSE 0 END AS `Themed_Pictorial`,
  RTRIM(
    (CASE WHEN `Pictorials` LIKE '%Girls%' THEN 'Girls, ' ELSE '' END)
  || (CASE WHEN `Pictorials` LIKE '%Ladies%' THEN 'Ladies, ' ELSE '' END)
  || (CASE WHEN `Pictorials` LIKE '%Women%' THEN 'Women, ' ELSE '' END)
  || (CASE WHEN `Pictorials` LIKE '%Cyber%' THEN 'Cyber, ' ELSE '' END)
  || (CASE WHEN `Pictorials` LIKE '%Big Ten%' THEN 'Big Ten, ' ELSE '' END)
  , ', ') AS `Matched_Themes`
FROM `table_1_1566852_4`
WHERE
  `Pictorials` LIKE '%' || `Cover model` || '%'
  OR `Pictorials` LIKE '%' || `Centerfold model` || '%'
  OR `Pictorials` LIKE '%' || `Interview subject` || '%'
  OR `Pictorials` LIKE '%Girls%'
  OR `Pictorials` LIKE '%Ladies%'
  OR `Pictorials` LIKE '%Women%'
  OR `Pictorials` LIKE '%Cyber%'
  OR `Pictorials` LIKE '%Big Ten%'
ORDER BY
  (CASE WHEN `Pictorials` LIKE '%' || `Cover model` || '%' THEN 1 ELSE 0 END)
+ (CASE WHEN `Pictorials` LIKE '%' || `Centerfold model` || '%' THEN 1 ELSE 0 END)
+ (CASE WHEN `Pictorials` LIKE '%' || `Interview subject` || '%' THEN 1 ELSE 0 END)
+ (CASE WHEN `Pictorials` LIKE '%Girls%' OR `Pictorials` LIKE '%Ladies%' OR `Pictorials` LIKE '%Women%' OR `Pictorials` LIKE '%Cyber%' OR `Pictorials` LIKE '%Big Ten%' THEN 1 ELSE 0 END) DESC,
  `Date` ASC;
","
SELECT
  col0,
  col1,
  col2,
  col3,
  col5,
  CASE WHEN col5 LIKE '%' || col1 || '%' THEN 1 ELSE 0 END AS `Cover_in_Pictorials`,
  CASE WHEN col5 LIKE '%' || col2 || '%' THEN 1 ELSE 0 END AS `Centerfold_in_Pictorials`,
  CASE WHEN col5 LIKE '%' || col3 || '%' THEN 1 ELSE 0 END AS `Interview_in_Pictorials`,
  CASE WHEN col5 LIKE '%Girls%' OR col5 LIKE '%Ladies%' OR col5 LIKE '%Women%' OR col5 LIKE '%Cyber%' OR col5 LIKE '%Big Ten%' THEN 1 ELSE 0 END AS `Themed_Pictorial`,
  RTRIM(
    (CASE WHEN col5 LIKE '%Girls%' THEN 'Girls, ' ELSE '' END)
  || (CASE WHEN col5 LIKE '%Ladies%' THEN 'Ladies, ' ELSE '' END)
  || (CASE WHEN col5 LIKE '%Women%' THEN 'Women, ' ELSE '' END)
  || (CASE WHEN col5 LIKE '%Cyber%' THEN 'Cyber, ' ELSE '' END)
  || (CASE WHEN col5 LIKE '%Big Ten%' THEN 'Big Ten, ' ELSE '' END)
  , ', ') AS `Matched_Themes`
FROM `table_1_1566852_4`
WHERE
  col5 LIKE '%' || col1 || '%'
  OR col5 LIKE '%' || col2 || '%'
  OR col5 LIKE '%' || col3 || '%'
  OR col5 LIKE '%Girls%'
  OR col5 LIKE '%Ladies%'
  OR col5 LIKE '%Women%'
  OR col5 LIKE '%Cyber%'
  OR col5 LIKE '%Big Ten%'
ORDER BY
  (CASE WHEN col5 LIKE '%' || col1 || '%' THEN 1 ELSE 0 END)
+ (CASE WHEN col5 LIKE '%' || col2 || '%' THEN 1 ELSE 0 END)
+ (CASE WHEN col5 LIKE '%' || col3 || '%' THEN 1 ELSE 0 END)
+ (CASE WHEN col5 LIKE '%Girls%' OR col5 LIKE '%Ladies%' OR col5 LIKE '%Women%' OR col5 LIKE '%Cyber%' OR col5 LIKE '%Big Ten%' THEN 1 ELSE 0 END) DESC,
  col0 ASC;
","[('1-03', 'tia carrere', 'rebecca anne ramos', 'halle berry', 'tia carrere', 1, 0, 0, 0, ''), ('10-03', 'lauren hill', 'audra lynn', 'o.j. simpson', 'girls of big ten , deanna merryman', 0, 0, 0, 1, 'Girls, Big Ten'), ('2-03', 'alison eastwood', 'charis boyle', 'jimmy kimmel', 'allison eastwood, cyber girls', 0, 0, 0, 1, 'Girls, Cyber'), ('3-03', 'dorismar', 'pennelope jimenez', 'colin farrell', 'ladies of latin tv, katrina barellova', 0, 0, 0, 1, 'Ladies'), ('4-03', 'carmen electra', 'carmella decesare', 'jay-z', 'carmen electra', 1, 0, 0, 0, ''), ('5-03', 'torrie wilson', 'laurie fetter', 'billy bob thornton', 'torrie wilson', 1, 0, 0, 0, ''), ('6-03', 'sarah kozer', 'tailor james', 'mike piazza', 'sarah kozer, pmoy christina santiago', 1, 0, 0, 0, ''), ('7-03', 'nikki ziering', 'marketa janska', 'lisa marie presley', 'nikki ziering, 2 fast 2 furious 2 fine', 1, 0, 0, 0, ''), ('9-03', 'signe nordli', 'luci victoria', 'jon gruden', 'women of starbucks , jenny haase', 0, 0, 0, 1, 'Women')]",table_1_1566852_4,"As a cross-promotion forensics curator I'm comfortable using publication terms like cover, centerfold and pictorial but I won't use SQL jargon. The query pulls issue rows where the Pictorials text mentions the cover, centerfold, interview subject, or contains certain group-theme keywords, and computes flags for each match while listing date and principal names. The schema maps to Date, Cover model, Centerfold model, Interview subject and Pictorials. Draft question: Which issues list pictorials that explicitly name the cover, centerfold, or interview subject, or contain group-theme keywords like 'Girls', 'Ladies', 'Women', 'Cyber' or 'Big Ten', and show the date, cover, centerfold, interview subject, the pictorials text and which of those matches are present? Validation: This asks only for the fields and matches the query's filtering and output without adding extra data.",persona,"A museum 'cross‑promotion forensics' curator who reconstructs how mainstream celebrities, films and TV properties were marketed through Playboy's 2000s issues. Goals: Find instances where a celebrity interview subject was being cross‑promoted alongside a pictorial or cover/centerfold (e.g., film/TV tie‑ins) to document marketing linkages. Identify issues where the cover or centerfold also appears explicitly in the Pictorials field (self‑referential features) to trace which models received multiple forms of exposure. Assemble a shortlist of group or themed pictorials (""Ladies"", ""Girls"", ""Women of"", ""Cyber"", ""Big Ten"", etc.) with their issue dates to map patterns of brand or institutional tie‑ins across the year. Example Queries: SELECT ""Date"", ""Cover model"", ""Centerfold model"", ""Interview subject"", ""Pictorials""
FROM table_1_1566852_4
WHERE ""Pictorials"" LIKE '%' || ""Cover model"" || '%' OR ""Pictorials"" LIKE '%' || ""Centerfold model"" || '%'; SELECT ""Date"", ""Interview subject"", ""20 Questions"", ""Pictorials""
FROM table_1_1566852_4
WHERE ""Interview subject"" IN ('Jay-Z','Nelly','Tobey Maguire','Colin Farrell','Nicolas Cage','Joe Rogan','Jimmy Kimmel','Bernie Mac','Billy Bob Thornton','O.J. Simpson','Jon Gruden','Mike Piazza'); SELECT ""Date"", ""Cover model"", ""Centerfold model"", ""Pictorials""
FROM table_1_1566852_4
WHERE ""Pictorials"" LIKE '%Girls%'
   OR ""Pictorials"" LIKE '%Ladies%'
   OR ""Pictorials"" LIKE '%Women%'
   OR ""Pictorials"" LIKE '%Cyber%'
   OR ""Pictorials"" LIKE '%Big Ten%';",reward,,
"List the top 5 Cover model values by COUNT(*) (returned as 'Jaime Pressly'), and for each include SUM(Cover model = Centerfold model) labeled 'Pamela Anderson, Helmut Newton tribute', GROUP_CONCAT(Date, ', ') labeled 'All Dates', and GROUP_CONCAT(Pictorials, ' | ') labeled 'All Pictorials', considering only rows where Pictorials is not '' and not ' ', grouping by Cover model and ordering by 'Jaime Pressly' descending?","
SELECT `Cover model`, COUNT(*) `Jaime Pressly`, SUM(`Cover model` = `Centerfold model`) `Pamela Anderson, Helmut Newton tribute`, GROUP_CONCAT(`Date`, ', ') `All Dates`, GROUP_CONCAT(`Pictorials`, ' | ') `All Pictorials`
FROM table_1_1566852_5
WHERE `Pictorials` != '' AND `Pictorials` != ' '
GROUP BY `Cover model`
ORDER BY `Jaime Pressly` DESC
LIMIT 5;
","
SELECT col1, COUNT(*) `Jaime Pressly`, SUM(col1 = col2) `Pamela Anderson, Helmut Newton tribute`, GROUP_CONCAT(col0, ', ') `All Dates`, GROUP_CONCAT(col5, ' | ') `All Pictorials`
FROM table_1_1566852_5
WHERE col5 != '' AND col5 != ' '
GROUP BY col1
ORDER BY `Jaime Pressly` DESC
LIMIT 5;
","[('rena mero , torrie wilson (two alternative covers)', 1, 0, '3-04', 'rena mero, torrie wilson, cyber girls'), ('rachel hunter', 1, 0, '4-04', ""rachel hunter, world's sexiest djs""), ('peta wilson', 1, 0, '7-04', 'peta wilson, swingers'), ('pamela anderson', 1, 0, '5-04', 'pamela anderson, helmut newton tribute'), ('jaime pressly', 1, 0, '2-04', 'jaime pressly, the year in sex 2004')]",table_1_1566852_5,"1) Parse SQL intent: aggregate rows by Cover model with a total count (aliased 'Jaime Pressly'), count of matches between Cover model and Centerfold model (aliased 'Pamela Anderson, Helmut Newton tribute'), and concatenated Date and Pictorials fields; exclude empty/blanks in Pictorials, order by count desc and limit to 5. 2) Map schema semantics: Cover model, Centerfold model, Date, Pictorials. 3) Draft the question: request top 5 Cover models with those aggregated fields and specified aliases and separators. 4) Validate: confirm inclusion of filter Pictorials != '' and Pictorials != ' ', GROUP BY, ORDER BY 'Jaime Pressly' DESC, and LIMIT 5.",reserved,8,reward,,
Which of the most recent issues feature the cover model?,"
SELECT `Date`, `Cover model`, `Centerfold model`, `Pictorials` AS `Pictorials`
FROM `table_1_1566852_7`
WHERE CASE WHEN `Cover model` = `Centerfold model` OR instr(`Pictorials`,`Cover model`)>0 THEN 1 ELSE 0 END = 1
ORDER BY `Date` DESC
LIMIT 10;
","
SELECT col0, col1, col2, col5 AS col5
FROM `table_1_1566852_7`
WHERE CASE WHEN col1 = col2 OR instr(col5,col1)>0 THEN 1 ELSE 0 END = 1
ORDER BY col0 DESC
LIMIT 10;
","[('7-06', 'vida guerra', 'sara jean underwood', 'vida guerra'), ('6-06', 'kara monaco', 'stephanie larimore', 'pmoy - kara monaco, girls of myspace'), ('5-06', 'alison waite', 'alison waite', 'girls of the top 10 party schools, rachel sterling'), ('4-06', 'candice michelle', 'holley ann dorrough', 'candice michelle, cyber girls in print'), ('2-06', 'adrianne curry', 'cassandra lynn', 'adrianne curry, girls of tuscany'), ('11-06', 'mercedes mcnab', 'sarah elizabeth', 'mercedes mcnab, girls of hawaiian tropic'), ('1-06', 'lisa guerrero', 'athena lundberg', 'lisa guerrero')]",table_1_1566852_7,"STEP 1: Parse the SQL intent: the query selects Date, Cover model, Centerfold model and Pictorials for the most recent 10 rows where the Cover model is either the Centerfold OR the Cover model's name appears inside the Pictorials field (instr(Pictorials, Cover model)>0). STEP 2: Determine ambiguity type: Attachment ambiguity — the natural predicate that would describe this filter (e.g., ""feature"" or ""include"") can attach to different parts of an issue (being the centerfold vs. appearing in the pictorials), which fits this query because it accepts either condition. STEP 3: Draft the question: ""Which of the most recent issues feature the cover model?"" STEP 4: Explain the ambiguity: in the SQL the condition treats being centerfold and appearing in pictorials as equivalent matches; the NL question is ambiguous because ""feature"" could mean only the cover model was the centerfold, only that they appear in a pictorial, either one of those, or even both — each interpretation would change the WHERE clause (Cover model = Centerfold, instr(Pictorials, Cover model)>0, OR both/AND).",reserved,14,reward,,"type: Attachment ambiguity | explanation: The phrase ""feature the cover model"" can attach to different parts of an issue: it could mean the cover model is the centerfold, or that they appear in the pictorials, or either; the SQL treats either condition as a match, but a different interpretation would restrict the query to only centerfolds, only pictorial appearances, or require both."
"Which seasons actually made any playoff progress — list the year, the regular-season finish and what playoff round they reached so I can spot the turning points?","
SELECT
  `Year`,
  '`' || `Regular Season` || '`' AS `Regular Season (wrapped)`,
  '`' || `Playoffs` || '`' AS `Playoffs (wrapped)`,
  '`' || `Open Cup` || '`' AS `Open Cup (wrapped)`,
  CAST(SUBSTR(`Regular Season`,1,1) AS INTEGER) AS `Placement`,
  CASE WHEN `Playoffs` <> 'Did not qualify' THEN 1 ELSE 0 END AS `Made_Playoff_Progress`,
  CASE WHEN `Open Cup` <> 'Did not qualify' THEN 1 ELSE 0 END AS `Open_Cup_Participation`,
  SUM(CASE WHEN `Open Cup` <> 'Did not qualify' THEN 1 ELSE 0 END) OVER () AS `Total_Open_Cup_Participations`,
  DENSE_RANK() OVER (ORDER BY CAST(SUBSTR(`Regular Season`,1,1) AS INTEGER) ASC, `Year` ASC) AS `Placement_Rank`
FROM `table_1_15672920_1`
ORDER BY `Placement` ASC, `Year` ASC;
","
SELECT
  col0,
  '`' || col3 || '`' AS `Regular Season (wrapped)`,
  '`' || col4 || '`' AS `Playoffs (wrapped)`,
  '`' || col5 || '`' AS `Open Cup (wrapped)`,
  CAST(SUBSTR(col3,1,1) AS INTEGER) AS `Placement`,
  CASE WHEN col4 <> 'Did not qualify' THEN 1 ELSE 0 END AS `Made_Playoff_Progress`,
  CASE WHEN col5 <> 'Did not qualify' THEN 1 ELSE 0 END AS `Open_Cup_Participation`,
  SUM(CASE WHEN col5 <> 'Did not qualify' THEN 1 ELSE 0 END) OVER () AS `Total_Open_Cup_Participations`,
  DENSE_RANK() OVER (ORDER BY CAST(SUBSTR(col3,1,1) AS INTEGER) ASC, col0 ASC) AS `Placement_Rank`
FROM `table_1_15672920_1`
ORDER BY `Placement` ASC, col0 ASC;
","[(2008.0, '`1st, southeast`', '`divisional round`', '`did not qualify`', 1, 1, 1, 5, 1), (2009.0, '`2nd, southeast`', '`did not qualify`', '`1st round`', 2, 1, 1, 5, 2), (2012.0, '`2nd, south-southeast-east`', '`did not qualify`', '`did not qualify`', 2, 1, 1, 5, 3), (2011.0, '`4th, southeast`', '`did not qualify`', '`did not qualify`', 4, 1, 1, 5, 4), (2010.0, '`5th, southeast`', '`did not qualify`', '`did not qualify`', 5, 1, 1, 5, 5)]",table_1_15672920_1,"The curator wants to identify exhibit 'turning points' when the reserves actually made postseason progress, phrased simply. The SQL marks Made_Playoff_Progress as 1 when Playoffs is not 'Did not qualify' and returns year, regular-season and playoff text for each row. Here Regular Season and Playoffs map directly to the table's text fields, and progress is inferred by any Playoffs value other than 'Did not qualify'. Draft question: one sentence asking which seasons made any playoff progress and to list year, regular-season finish and the playoff round reached so I can pick turning-point panels. This matches the query's per-season playoff-progress flag and associated fields.",persona,"A museum curator assembling a small exhibit called 'Near Misses: The Silent Years of American Soccer' who highlights reserve-team seasons that nearly produced breakthroughs. Goals: Identify which seasons the Atlanta Silverbacks Reserves made any postseason progress to feature as exhibit turning points. Select the club's best regular-season finishes to create contrast panels (e.g., 'peaks' vs 'valleys'). Produce a simple, chronologically ordered ranking of seasons by regular-season placement to tell a narrative arc for visitors. Count and highlight seasons when the team participated in the U.S. Open Cup pathway (even if eliminated early). Example Queries: SELECT Year, ""Regular Season"", Playoffs FROM table_1_15672920_1 WHERE Playoffs <> 'Did not qualify' ORDER BY Year; SELECT Year, ""Regular Season"", Playoffs FROM table_1_15672920_1 WHERE ""Regular Season"" LIKE '1st%' OR ""Regular Season"" LIKE '2nd%' ORDER BY Year; SELECT Year, ""Regular Season"", Playoffs, ""Open Cup"" FROM table_1_15672920_1 ORDER BY CAST(SUBSTR(""Regular Season"",1,1) AS INTEGER) ASC, Year ASC;",reward,,
"Give me a list of underdog seasons (4th, 7th, or 8th regular-season finishes that reached semifinals, final, or champions) showing year, league, division, regular finish, playoff result, Open Cup progress, and how many such deep runs each league/division has, ordered first by how common those deep runs are in the league/division and then by year?","
WITH underdogs AS (
  SELECT `Year`, `Division`, `League`, `Regular Season`, `Playoffs`, `Open Cup`
  FROM `table_1_1570003_2`
  WHERE (
    `Regular Season` LIKE '%4th%' OR
    `Regular Season` LIKE '%7th%' OR
    `Regular Season` LIKE '%8th%'
  )
  AND (
    `Playoffs` LIKE '%Final%' OR
    `Playoffs` = 'Champions' OR
    `Playoffs` = 'Semifinals'
  )
)
SELECT
  u.`Year`,
  u.`League`,
  u.`Division`,
  u.`Regular Season`,
  u.`Playoffs`,
  u.`Open Cup`,
  CASE WHEN u.`Open Cup` NOT IN ('Did not enter','Did not qualify') THEN 1 ELSE 0 END AS `Notable Open Cup Run`,
  COUNT(*) OVER (PARTITION BY u.`League`, u.`Division`) AS `Deep_Run_Count_By_League_And_Division`
FROM underdogs u
ORDER BY `Deep_Run_Count_By_League_And_Division` DESC, u.`Year` ASC;
","
WITH underdogs AS (
  SELECT col0, col1, col2, col3, col4, col5
  FROM `table_1_1570003_2`
  WHERE (
    col3 LIKE '%4th%' OR
    col3 LIKE '%7th%' OR
    col3 LIKE '%8th%'
  )
  AND (
    col4 LIKE '%Final%' OR
    col4 = 'Champions' OR
    col4 = 'Semifinals'
  )
)
SELECT
  u.col0,
  u.col2,
  u.col1,
  u.col3,
  u.col4,
  u.col5,
  CASE WHEN u.col5 NOT IN ('Did not enter','Did not qualify') THEN 1 ELSE 0 END AS `Notable Open Cup Run`,
  COUNT(*) OVER (PARTITION BY u.col2, u.col1) AS `Deep_Run_Count_By_League_And_Division`
FROM underdogs u
ORDER BY `Deep_Run_Count_By_League_And_Division` DESC, u.col0 ASC;
","[(2007.0, 'usl second division', '3', '4th', 'semifinals', '2nd round', 1, 2), (2009.0, 'usl second division', '3', '4th', 'final', '1st round', 1, 2)]",table_1_1570003_2,"I like a tidy, chronological inventory that still highlights which settings are richest in drama. The query orders the underdog seasons by how many deep runs that League+Division produced (descending) and then by year ascending. It returns year, league, division, regular-season placing, playoffs, Open Cup and the per-league/division count. Draft question: Give me a list of underdog seasons (4th, 7th, or 8th regular-season finishes that reached semifinals, final, or champions) showing year, league, division, regular finish, playoff result, Open Cup progress, and how many such deep runs each league/division has, ordered first by how common those deep runs are in the league/division and then by year. Validation: This asks for the exact columns and ordering produced by the query.",persona,"An audio-fiction writer who crafts short, lyric 'sports fables' based on real soccer seasons where a team’s ordinary league finish belies a surprising playoff or cup run. Goals: Identify seasons where the Charlotte Eagles finished poorly in the regular season but made unexpectedly deep playoff runs (underdog arcs to inspire episodes). Catalog which leagues/divisions produced the most dramatic postseason outcomes to vary the historical settings of stories. Find seasons with noteworthy Open Cup progress to weave cross-competition stakes into single-episode narratives. Example Queries: SELECT Year, League, `Regular Season`, Playoffs FROM table_1_1570003_2 WHERE (`Regular Season` LIKE '%4th%' OR `Regular Season` LIKE '%7th%' OR `Regular Season` LIKE '%8th%') AND (Playoffs IN ('Semifinals','Final','Champions') OR Playoffs LIKE '%Final%'); SELECT League, `Division`, COUNT(*) AS deep_runs FROM table_1_1570003_2 WHERE (Playoffs LIKE '%Final%' OR Playoffs = 'Champions' OR Playoffs = 'Semifinals') GROUP BY League, `Division` ORDER BY deep_runs DESC; SELECT Year, `Open Cup`, Playoffs, `Regular Season` FROM table_1_1570003_2 WHERE `Open Cup` NOT IN ('Did not enter','Did not qualify') ORDER BY Year;",reward,,
"Give me a top-five shortlist of Sri Lankan bowlers from that series (min 20 overs) ordered by a composite that favours low economy, low runs-per-wicket and low balls-per-wicket while rewarding overs, and include their overs, wickets, runs conceded, E.R., balls per wicket, runs per wicket and composite score.","
SELECT
  `Name`,
  `Overs Bowled`,
  `Wickets`,
  `Runs Conceded`,
  `E.R.`,
  Overs_Integer,
  Balls_Part,
  Balls,
  ROUND(Strike_Rate_Balls_Per_Wicket,2) AS Strike_Rate_Balls_Per_Wicket,
  ROUND(Runs_Per_Wicket,2) AS Runs_Per_Wicket,
  ROUND(Composite_Score,3) AS Composite_Score
FROM (
  SELECT
    `Name`,
    `Overs Bowled`,
    `Wickets`,
    `Runs Conceded`,
    `E.R.`,
    -- integer overs (before the dot) or whole overs if no dot
    (CASE WHEN INSTR(`Overs Bowled`, '.') > 0
      THEN CAST(SUBSTR(`Overs Bowled`, 1, INSTR(`Overs Bowled`, '.')-1) AS INTEGER)
      ELSE CAST(`Overs Bowled` AS INTEGER)
    END) AS Overs_Integer,
    -- balls part after the dot if present
    (CASE WHEN INSTR(`Overs Bowled`, '.') > 0
      THEN CAST(SUBSTR(`Overs Bowled`, INSTR(`Overs Bowled`, '.')+1) AS INTEGER)
      ELSE 0
    END) AS Balls_Part,
    -- total balls bowled
    ((CASE WHEN INSTR(`Overs Bowled`, '.') > 0
      THEN CAST(SUBSTR(`Overs Bowled`, 1, INSTR(`Overs Bowled`, '.')-1) AS INTEGER)
      ELSE CAST(`Overs Bowled` AS INTEGER)
    END) * 6
    + (CASE WHEN INSTR(`Overs Bowled`, '.') > 0
      THEN CAST(SUBSTR(`Overs Bowled`, INSTR(`Overs Bowled`, '.')+1) AS INTEGER)
      ELSE 0
    END)) AS Balls,
    -- strike rate (balls per wicket)
    CASE WHEN `Wickets` > 0 THEN
      ((CASE WHEN INSTR(`Overs Bowled`, '.') > 0
        THEN CAST(SUBSTR(`Overs Bowled`, 1, INSTR(`Overs Bowled`, '.')-1) AS INTEGER)
        ELSE CAST(`Overs Bowled` AS INTEGER)
      END) * 6
      + (CASE WHEN INSTR(`Overs Bowled`, '.') > 0
        THEN CAST(SUBSTR(`Overs Bowled`, INSTR(`Overs Bowled`, '.')+1) AS INTEGER)
        ELSE 0
      END)
      ) / CAST(`Wickets` AS REAL)
    END AS Strike_Rate_Balls_Per_Wicket,
    -- runs conceded per wicket
    CASE WHEN `Wickets` > 0 THEN CAST(`Runs Conceded` AS REAL)/CAST(`Wickets` AS REAL) END AS Runs_Per_Wicket,
    -- composite score: lower is better (weights: economy, runs/wicket, strike rate, rewards higher overs)
    (
      (CAST(`E.R.` AS REAL) * 1.5)
      + COALESCE((CASE WHEN `Wickets` > 0 THEN CAST(`Runs Conceded` AS REAL)/CAST(`Wickets` AS REAL) END), 999) * 0.8
      + COALESCE((CASE WHEN `Wickets` > 0 THEN
          (
            ((CASE WHEN INSTR(`Overs Bowled`, '.') > 0
              THEN CAST(SUBSTR(`Overs Bowled`, 1, INSTR(`Overs Bowled`, '.')-1) AS INTEGER)
              ELSE CAST(`Overs Bowled` AS INTEGER)
            END) * 6
            + (CASE WHEN INSTR(`Overs Bowled`, '.') > 0
              THEN CAST(SUBSTR(`Overs Bowled`, INSTR(`Overs Bowled`, '.')+1) AS INTEGER)
              ELSE 0
            END)
          ) / CAST(`Wickets` AS REAL)
        END), 9999) / 10
      - ((CASE WHEN INSTR(`Overs Bowled`, '.') > 0
          THEN CAST(SUBSTR(`Overs Bowled`, 1, INSTR(`Overs Bowled`, '.')-1) AS INTEGER)
          ELSE CAST(`Overs Bowled` AS INTEGER)
        END) * 0.2)
    ) AS Composite_Score
  FROM `table_1_15700367_6`
) 
WHERE Overs_Integer > 20
ORDER BY Composite_Score ASC, `Wickets` DESC
LIMIT 5;
","SELECT
  col0,
  col1,
  col4,
  col3,
  col6,
  Overs_Integer,
  Balls_Part,
  Balls,
  ROUND(Strike_Rate_Balls_Per_Wicket,2) AS Strike_Rate_Balls_Per_Wicket,
  ROUND(Runs_Per_Wicket,2) AS Runs_Per_Wicket,
  ROUND(Composite_Score,3) AS Composite_Score
FROM (
  SELECT
    col0,
    col1,
    col4,
    col3,
    col6,
    CASE WHEN INSTR(col1, '.') > 0
      THEN CAST(SUBSTR(col1, 1, INSTR(col1, '.')-1) AS INTEGER)
      ELSE CAST(col1 AS INTEGER)
    END AS Overs_Integer,
    CASE WHEN INSTR(col1, '.') > 0
      THEN CAST(SUBSTR(col1, INSTR(col1, '.')+1) AS INTEGER)
      ELSE 0
    END AS Balls_Part,
    (
      (CASE WHEN INSTR(col1, '.') > 0
        THEN CAST(SUBSTR(col1, 1, INSTR(col1, '.')-1) AS INTEGER)
        ELSE CAST(col1 AS INTEGER)
      END) * 6
      +
      (CASE WHEN INSTR(col1, '.') > 0
        THEN CAST(SUBSTR(col1, INSTR(col1, '.')+1) AS INTEGER)
        ELSE 0
      END)
    ) AS Balls,
    CASE WHEN col4 > 0 THEN
      (
        (
          (CASE WHEN INSTR(col1, '.') > 0
            THEN CAST(SUBSTR(col1, 1, INSTR(col1, '.')-1) AS INTEGER)
            ELSE CAST(col1 AS INTEGER)
          END) * 6
          +
          (CASE WHEN INSTR(col1, '.') > 0
            THEN CAST(SUBSTR(col1, INSTR(col1, '.')+1) AS INTEGER)
            ELSE 0
          END)
        ) / CAST(col4 AS REAL)
      )
    END AS Strike_Rate_Balls_Per_Wicket,
    CASE WHEN col4 > 0 THEN CAST(col3 AS REAL)/CAST(col4 AS REAL) END AS Runs_Per_Wicket,
    (
      CAST(col6 AS REAL) * 1.5
      +
      COALESCE(
        CASE WHEN col4 > 0 THEN CAST(col3 AS REAL)/CAST(col4 AS REAL) END,
      999) * 0.8
      +
      COALESCE(
        CASE WHEN col4 > 0 THEN
          (
            (
              (CASE WHEN INSTR(col1, '.') > 0
                THEN CAST(SUBSTR(col1, 1, INSTR(col1, '.')-1) AS INTEGER)
                ELSE CAST(col1 AS INTEGER)
              END) * 6
              +
              (CASE WHEN INSTR(col1, '.') > 0
                THEN CAST(SUBSTR(col1, INSTR(col1, '.')+1) AS INTEGER)
                ELSE 0
              END)
            ) / CAST(col4 AS REAL)
          )
        END,
      9999) / 10.0
      - (
        (CASE WHEN INSTR(col1, '.') > 0
          THEN CAST(SUBSTR(col1, 1, INSTR(col1, '.')-1) AS INTEGER)
          ELSE CAST(col1 AS INTEGER)
        END) * 0.2
      )
    ) AS Composite_Score
  FROM `table_1_15700367_6`
)
WHERE Overs_Integer > 20
ORDER BY Composite_Score ASC, col4 DESC
LIMIT 5;","[('lasith malinga', '70.4', 12.0, 368.0, '5.23', 70, 4, 424, 35.33, 30.67, 21.912), ('ishara amerasinghe', '57', 9.0, 276.0, '4.84', 57, 0, 342, 38.0, 30.67, 24.193), ('nuwan kulasekara', '26', 5.0, 129.0, '4.96', 26, 0, 156, 31.2, 25.8, 26.0), ('muttiah muralitharan', '73.2', 9.0, 353.0, '4.82', 73, 2, 440, 48.89, 39.22, 28.897), ('farveez maharoof', '32.1', 4.0, 149.0, '4.64', 32, 1, 193, 48.25, 37.25, 35.185)]",table_1_15700367_6,"I might request a compact shortlist to inform selection decisions that rewards both workload and low economy/efficient wicket-taking. The SQL creates a composite score from E.R., runs-per-wicket and strike rate, penalises missing wickets, includes a workload reward (overs), filters bowlers with more than 20 overs and returns the five best (lowest composite). It uses the table's Name, Overs Bowled, Wickets, Runs Conceded and E.R. and returns derived Balls, Strike_Rate_Balls_Per_Wicket, Runs_Per_Wicket and Composite_Score. Draft question: Give me a top-five shortlist of Sri Lankan bowlers from that series (min 20 overs) ordered by a composite that favours low economy, low runs-per-wicket and low balls-per-wicket while rewarding overs, and include their overs, wickets, runs conceded, E.R., balls per wicket, runs per wicket and composite score. Validation: This precisely matches the query's filter, metrics and ordering.",persona,"Sri Lanka team performance analyst for a national cricket board who reviews past tournament bowling performances to inform selection, workload management, and tactical planning. They would query this series-level bowling table to compare economy, strike rates, and workloads among bowlers from the 2007–08 Commonwealth Bank Series. Goals: Identify the most effective wicket-takers and the most economical bowlers in the series to inform selection choices. Assess workload (overs bowled) and effectiveness (wickets, runs conceded, economy, strike rate) to plan rest/rotation and training emphasis. Find bowlers who combined high overs with good efficiency (low E.R. and low runs-per-wicket) for use in different match situations. Example Queries: /* Top wicket-takers (most wickets, break ties by fewer runs conceded) */
SELECT Name, Wickets, ""Overs Bowled"", ""Runs Conceded""
FROM table_1_15700367_6
ORDER BY Wickets DESC, ""Runs Conceded"" ASC
LIMIT 5; /* Bowlers with economy under 5.0 and who bowled more than 20 overs */
SELECT Name, ""Overs Bowled"", ""E.R."", Wickets
FROM table_1_15700367_6
WHERE CAST(""E.R."" AS REAL) < 5.0
  AND CAST(""Overs Bowled"" AS REAL) > 20
ORDER BY CAST(""E.R."" AS REAL) ASC; /* Compute balls, strike rate (balls per wicket) and runs-per-wicket to rank efficient workhorses.
   Note: Overs are in cricket format (overs.balls). This query extracts integer overs and balls to compute total balls. */
SELECT
  Name,
  ""Overs Bowled"",
  Wickets,
  ""Runs Conceded"",
  (
    (CAST(SUBSTR(""Overs Bowled"", 1, INSTR(""Overs Bowled"", '.')-1) AS INTEGER) * 6)
    + COALESCE(CAST(SUBSTR(""Overs Bowled"", INSTR(""Overs Bowled"", '.')+1) AS INTEGER), 0)
  ) AS Balls,
  CASE WHEN Wickets > 0 THEN
    (
      ((CAST(SUBSTR(""Overs Bowled"", 1, INSTR(""Overs Bowled"", '.')-1) AS INTEGER) * 6)
       + COALESCE(CAST(SUBSTR(""Overs Bowled"", INSTR(""Overs Bowled"", '.')+1) AS INTEGER), 0)
      ) / CAST(Wickets AS REAL)
  END AS Strike_Rate_Balls_Per_Wicket,
  CASE WHEN Wickets > 0 THEN CAST(""Runs Conceded"" AS REAL)/Wickets END AS Runs_Per_Wicket
FROM table_1_15700367_6
ORDER BY Strike_Rate_Balls_Per_Wicket ASC NULLS LAST, ""Runs Conceded"" ASC;",reward,,
"For each Written By (reporting as Writer), what are Episodes (COUNT(*)), MIN(No. in season), and Last (MAX(No. in season)) when restricting to rows where TV Broadcast LIKE 'S02E%' OR Title = '`""Turtles in Space, Part 1: The Fugitoid`', grouping by Written By, ordering by Episodes descending and returning at most 10 results?","
SELECT `Written By` AS `Writer`, COUNT(*) AS `Episodes`, MIN(`No. in season`), MAX(`No. in season`) AS `Last`
FROM `table_1_15777546_1`
WHERE `TV Broadcast` LIKE 'S02E%' OR `Title` = '`""Turtles in Space, Part 1: The Fugitoid`'
GROUP BY `Written By`
ORDER BY `Episodes` DESC
LIMIT 10;
","
SELECT col4 AS `Writer`, COUNT(*) AS `Episodes`, MIN(col1), MAX(col1) AS `Last`
FROM `table_1_15777546_1`
WHERE col6 LIKE 'S02E%' OR col2 = '`""Turtles in Space, Part 1: The Fugitoid`'
GROUP BY col4
ORDER BY `Episodes` DESC
LIMIT 10;
","[('marty isenberg', 8, 3.0, 25.0), ('michael ryan', 6, 1.0, 23.0), ('eric luke', 5, 6.0, 19.0), ('ben townsend', 4, 12.0, 24.0), ('roland gonzalez', 1, 10.0, 10.0)]",table_1_15777546_1,"1) Parse SQL intent: aggregate episodes per `Written By`, computing count, minimum and maximum season numbers, restricted to TV Broadcast codes starting with S02E or the exact Title string, then return the top 10 by episode count. 2) Map schema: `Written By` -> Writer, COUNT(*) -> Episodes, MIN(`No. in season`), MAX(`No. in season`) -> Last. 3) Draft: formulate a question requesting those fields with the precise WHERE, GROUP BY, ORDER BY Episodes DESC, LIMIT 10. 4) Validate: ensures every selected column, alias, calculation, filter, group, order, and limit are mentioned.",reserved,12,reward,,
"Which performers recur in Season 1, how many episodes does each appear in, what distinct targets did they defend, which ‘Root of All Evil’(s) were they linked to, how often did the studio poll disagree with the show, and what is the episode-by-date timeline for each performer?","
WITH episodes AS (
  SELECT `#` AS `Episode`, `Original air date`, `Root of All Evil`, `Poll winner`, `Advocate # 1`, `Advocate # 2`
  FROM `table_1_15781170_2`
),
unpivot AS (
  SELECT `Episode`, `Original air date`, `Root of All Evil`, `Poll winner`,
    CASE WHEN instr(`Advocate # 1`, ' for ')>0 THEN substr(`Advocate # 1`, 1, instr(`Advocate # 1`, ' for ')-1) ELSE `Advocate # 1` END AS `Advocate`,
    CASE WHEN instr(`Advocate # 1`, ' for ')>0 THEN substr(`Advocate # 1`, instr(`Advocate # 1`, ' for ')+5) ELSE NULL END AS `Advocated for`
  FROM episodes
  UNION ALL
  SELECT `Episode`, `Original air date`, `Root of All Evil`, `Poll winner`,
    CASE WHEN instr(`Advocate # 2`, ' for ')>0 THEN substr(`Advocate # 2`, 1, instr(`Advocate # 2`, ' for ')-1) ELSE `Advocate # 2` END AS `Advocate`,
    CASE WHEN instr(`Advocate # 2`, ' for ')>0 THEN substr(`Advocate # 2`, instr(`Advocate # 2`, ' for ')+5) ELSE NULL END AS `Advocated for`
  FROM episodes
)
SELECT
  `Advocate`,
  COUNT(*) AS `Appearances`,
  GROUP_CONCAT(DISTINCT `Advocated for`) AS `Targets_defended (distinct)`,
  GROUP_CONCAT(DISTINCT `Root of All Evil`) AS `Associated_Roots (distinct)`,
  SUM(CASE WHEN `Root of All Evil` <> `Poll winner` THEN 1 ELSE 0 END) AS `Root_vs_Poll_mismatches`,
  GROUP_CONCAT(`Episode` || ' (' || `Original air date` || '): ' || `Root of All Evil` || ' -> ' || `Poll winner`, ' | ') AS `Episode_timeline`
FROM unpivot
GROUP BY `Advocate`
HAVING COUNT(*) > 1
ORDER BY `Appearances` DESC, `Advocate`;
","WITH unpivoted AS (
  SELECT
    CASE WHEN instr(col1, ' for ')>0 THEN substr(col1, 1, instr(col1, ' for ')-1) ELSE col1 END AS Advocate,
    CASE WHEN instr(col1, ' for ')>0 THEN substr(col1, instr(col1, ' for ')+5) ELSE NULL END AS Advocated_for,
    col3, col4, col0 AS Episode, col5
  FROM table_1_15781170_2
  UNION ALL
  SELECT
    CASE WHEN instr(col2, ' for ')>0 THEN substr(col2, 1, instr(col2, ' for ')-1) ELSE col2 END AS Advocate,
    CASE WHEN instr(col2, ' for ')>0 THEN substr(col2, instr(col2, ' for ')+5) ELSE NULL END AS Advocated_for,
    col3, col4, col0 AS Episode, col5
  FROM table_1_15781170_2
)
SELECT
  Advocate,
  COUNT(*) AS Appearances,
  GROUP_CONCAT(DISTINCT Advocated_for) AS Targets_defended_distinct,
  GROUP_CONCAT(DISTINCT col3) AS Associated_Roots_distinct,
  SUM(CASE WHEN col3 <> col4 THEN 1 ELSE 0 END) AS Root_vs_Poll_mismatches,
  GROUP_CONCAT(Episode || ' (' || col5 || '): ' || col3 || ' -> ' || col4, ' | ') AS Episode_timeline
FROM unpivoted
GROUP BY Advocate
HAVING COUNT(*) > 1
ORDER BY Appearances DESC, Advocate;","[('greg giraldo', 5, 'paris hilton,catholic church,viagra,porn,tila tequila', 'dick cheney,oprah,donald trump,youtube,kim jong-il', 4, '5.0 (april 9, 2008): dick cheney -> paris hilton | 1.0 (march 12, 2008): oprah -> catholic church | 2.0 (march 19, 2008): donald trump -> viagra | 4.0 (april 2, 2008): youtube -> youtube | 7.0 (april 23, 2008): kim jong-il -> tila tequila'), ('patton oswalt', 3, 'youtube,high school,dick cheney', 'youtube,american idol,dick cheney', 2, '4.0 (april 2, 2008): youtube -> youtube | 6.0 (april 16, 2008): american idol -> high school | 5.0 (april 9, 2008): dick cheney -> paris hilton'), ('andy kindler', 2, 'donald trump,american idol', 'donald trump,american idol', 2, '2.0 (march 19, 2008): donald trump -> viagra | 6.0 (april 16, 2008): american idol -> high school'), ('paul f. tompkins', 2, 'oprah,weed', 'oprah,beer', 2, '1.0 (march 12, 2008): oprah -> catholic church | 3.0 (march 26, 2008): beer -> weed')]",table_1_15781170_2,"As a performance-ethnographer curator I'd phrase this analytically but accessibly, referring to 'performers' or 'advocates' and to the show's 'Root of All Evil' and studio poll outcomes rather than SQL jargon. I'm unlikely to use column names like `Advocate # 1` but will reference episode numbers and air dates when useful. The SQL groups by advocate, counts appearances, collects distinct defended targets and associated Roots, sums mismatches between Root and poll, and assembles an episode timeline. The question I want therefore asks for recurring performers with their appearance counts, defended targets, associated Roots, mismatch counts, and episode-by-date timeline. I validate that this phrasing only requests fields the query produces (appearances, distinct targets, distinct roots, mismatch count, and episode timeline).",persona,"A performance-ethnographer and museum curator building an exhibit on how late-2000s stand-up comedians staged 'moral debates' and how audiences voted in those contests. Goals: Identify which comedians (advocates) recur across the season and the subjects they defended or attacked to map performer-driven themes for exhibit labels. Compare the show's designation of the 'Root of All Evil' with the studio poll winners to highlight tensions between comedic framing and audience opinion. Create a chronological timeline and frequency count of cultural targets (e.g., celebrities, institutions, vices) to design wall graphics and captions for the exhibit. Example Queries: SELECT ""#"" AS episode, ""Advocate # 1"", ""Advocate # 2"", ""Root of All Evil"", ""Poll winner"", ""Original air date"" FROM table_1_15781170_2 WHERE ""Advocate # 1"" LIKE '%Greg Giraldo%' OR ""Advocate # 2"" LIKE '%Greg Giraldo%'; SELECT ""#"", ""Advocate # 1"", ""Advocate # 2"", ""Root of All Evil"", ""Poll winner"", ""Original air date"" FROM table_1_15781170_2 WHERE ""Root of All Evil"" <> ""Poll winner""; SELECT ""Root of All Evil"", COUNT(*) AS times_named FROM table_1_15781170_2 GROUP BY ""Root of All Evil"" ORDER BY times_named DESC;",reward,,
Which advocate appeared the most?,"
SELECT `Advocate`, COUNT(*) `Appearances`
FROM (
  SELECT `Advocate # 1` `Advocate` FROM `table_1_15781170_3`
  UNION ALL
  SELECT `Advocate # 2` FROM `table_1_15781170_3`
)
GROUP BY `Advocate`
ORDER BY `Appearances` DESC;
","
SELECT `Advocate`, COUNT(*) `Appearances`
FROM (
  SELECT col1 `Advocate` FROM `table_1_15781170_3`
  UNION ALL
  SELECT col2 FROM `table_1_15781170_3`
)
GROUP BY `Advocate`
ORDER BY `Appearances` DESC;
","[('paul f. tompkins for red states', 1), ('paul f. tompkins for peta', 1), ('paul f. tompkins for gen x', 1), ('patton oswalt for blue states', 1), ('patton oswalt for bloggers', 1), ('kathleen madigan for sororities', 1), ('kathleen madigan for disney', 1), ('greg giraldo for strip clubs', 1), ('greg giraldo for steroids', 1), ('greg giraldo for going green', 1), ('greg giraldo for drinking games', 1), ('andy kindler for scientology', 1), ('andy kindler for nra', 1), ('andrew daly for ultimate fighting', 1), ('andrew daly for s baby boomer', 1), ('andrew daly for olympic games', 1), ('andrew daly for boob jobs', 1), ('andrea savage for spring break', 1)]",table_1_15781170_3,"STEP 1: Parse the SQL intent — the query unions the two columns `Advocate # 1` and `Advocate # 2` into a single `Advocate` column, counts how many times each exact advocate string appears across all rows, groups by that string, and orders by the count descending. STEP 2: Choose ambiguity type — entity vagueness fits best because the table's advocate values combine person and the cause (e.g., ""Andrew Daly for Ultimate Fighting""), so ""advocate"" could mean the full person+cause string, the person alone, or the cause alone. STEP 3: Draft the question — produce a short ambiguous natural-language question that matches the SQL result but allows multiple interpretations. STEP 4: Explain ambiguity — the SQL treats each full string as a distinct advocate (so the same person with different causes are separate), but a user might instead intend to count appearances by person regardless of cause, or count which cause/position appears most often.",reserved,13,reward,,"type: Entity Vagueness | explanation: The SQL counts each exact advocate string like ""Andrew Daly for Ultimate Fighting"" separately (person+cause as one entity), but the question ""Which advocate appeared the most?"" could also mean the individual person regardless of the cause they represented, or alternatively the causes/issues themselves, yielding different groupings and counts."
"Considering only rows where Season # >= 1, for each Directed by: (GROUP BY Directed by:) what is the Episode Count as SUM(1) and what are the Episodes as GROUP_CONCAT(Title, '; '), restricted to directors HAVING SUM(1) > 1, ordered by Episode Count DESC and limited to 5?","
SELECT `Directed by:`, SUM(1) `Episode Count`, GROUP_CONCAT(`Title`, '; ') `Episodes`
FROM `table_1_15824796_3`
WHERE `Season #` >= 1
GROUP BY `Directed by:`
HAVING SUM(1) > 1
ORDER BY `Episode Count` DESC
LIMIT 5;
","
SELECT col3, SUM(1) `Episode Count`, GROUP_CONCAT(col2, '; ') `Episodes`
FROM `table_1_15824796_3`
WHERE col1 >= 1
GROUP BY col3
HAVING SUM(1) > 1
ORDER BY `Episode Count` DESC
LIMIT 5;
","[('thomas carr', 15, '""five minutes to doom""; ""the big squeeze""; ""the man who could read minds""; ""jet ace""; ""superman in exile""; ""the dog who knew superman""; ""the man in the lead mask""; ""the machine that could plot crimes""; ""jungle devil""; ""my friend superman""; ""the golden vulture""; ""jimmy olsen, boy editor""; ""lady in black""; ""star of fate""; ""the whistling bird""'), ('george blair', 10, '""shot in the dark""; ""the defeat of superman""; ""a ghost for scotland yard""; ""the face and the voice""; "" panic in the sky ""; ""the clown who cried""; ""the boy who hated superman""; ""semi-private eye""; ""perry white\'s scoop""; ""beware the wrecker""')]",table_1_15824796_3,"1) The SQL selects directors, counts rows, concatenates titles, filters on Season #, groups by director, keeps only directors with count >1, orders by count desc, and limits to 5. 2) Map `Directed by:`, `Title`, and `Season #` to director, episode titles, and season filter; SUM(1) is the Episode Count and GROUP_CONCAT(Title, '; ') is Episodes. 3) Phrase a question asking for Directed by:, Episode Count (SUM(1)), and Episodes (GROUP_CONCAT with '; ') with WHERE Season # >= 1, GROUP BY Directed by:, HAVING SUM(1) > 1, ORDER BY Episode Count DESC, LIMIT 5. 4) Check that the question includes all columns, calculations, filters, grouping, having, ordering, and limit.",reserved,10,reward,,
"Which Opponents, considering only games with Attendance > 60000, have the following aggregates: Games (COUNT(*)), Total Points For (SUM(Points For)), Total Points Against (SUM(Points Against)), Point Differential (SUM(Points For) - SUM(Points Against)), Avg First Downs (AVG(First Downs) rounded to 2 decimal places), and Peak Attendance (MAX(Attendance))?","
SELECT `Opponent`, COUNT(*) `Games`, SUM(`Points For`) `Total Points For`, SUM(`Points Against`) `Total Points Against`, SUM(`Points For`) - SUM(`Points Against`) `Point Differential`, ROUND(AVG(`First Downs`),2) `Avg First Downs`, MAX(`Attendance`) `Peak Attendance`
FROM `table_1_15847691_2`
WHERE `Attendance` > 60000
GROUP BY `Opponent`;
","
SELECT col4, COUNT(*) `Games`, SUM(col5) `Total Points For`, SUM(col6) `Total Points Against`, SUM(col5) - SUM(col6) `Point Differential`, ROUND(AVG(col7),2) `Avg First Downs`, MAX(col8) `Peak Attendance`
FROM `table_1_15847691_2`
WHERE col8 > 60000
GROUP BY col4;
","[('at new york giants', 1, 24.0, 10.0, 14.0, 13.0, 74532.0), ('at philadelphia eagles', 1, 16.0, 10.0, 6.0, 17.0, 65507.0), ('detroit lions', 1, 37.0, 0.0, 37.0, 20.0, 63160.0), ('new york giants', 1, 41.0, 21.0, 20.0, 25.0, 64215.0), ('philadelphia eagles', 1, 24.0, 14.0, 10.0, 19.0, 60289.0), ('st. louis cardinals', 1, 17.0, 24.0, -7.0, 16.0, 64038.0), ('washington redskins', 1, 34.0, 16.0, 18.0, 23.0, 62115.0)]",table_1_15847691_2,"1) The SQL computes grouped statistics per Opponent for rows satisfying Attendance>60000: count, sum of Points For/Against, their difference, rounded average of First Downs, and max Attendance. 2) Map these to natural terms for the given columns. 3) Draft a concise question requesting Opponent and the aggregates named Games, Total Points For, Total Points Against, Point Differential, Avg First Downs (rounded to 2 decimals), and Peak Attendance for Attendance > 60000. 4) Check that no extra information is added and all calculations from the query are included.",reserved,5,reward,,
"For entries with No. in series > 0, give COUNT(No. in series) as Total Episodes; SUM(substr(Originalairdate,-4) = '2006') as Episodes in 2006; SUM(substr(Originalairdate,-4) = '2007') as Episodes in 2007; ROUND(SUM(substr(Originalairdate,-4) = '2006') * 100.0 / COUNT(No. in series), 2) as Pct 2006; ROUND(SUM(substr(Originalairdate,-4) = '2007') * 100.0 / COUNT(No. in series), 2) as Pct 2007; and MIN(Originalairdate) as Earliest airdate and MAX(Originalairdate) as Latest airdate?","
SELECT COUNT(`No. in series`) `Total Episodes`, SUM(substr(`Originalairdate`,-4) = '2006') `Episodes in 2006`, SUM(substr(`Originalairdate`,-4) = '2007') `Episodes in 2007`, ROUND(SUM(substr(`Originalairdate`,-4) = '2006') * 100.0 / COUNT(`No. in series`),2) `Pct 2006`, ROUND(SUM(substr(`Originalairdate`,-4) = '2007') * 100.0 / COUNT(`No. in series`),2) `Pct 2007`, MIN(`Originalairdate`) `Earliest airdate`, MAX(`Originalairdate`) `Latest airdate` FROM `table_1_15861819_1` WHERE `No. in series` > 0;
","
SELECT COUNT(col0) `Total Episodes`, SUM(substr(col5,-4) = '2006') `Episodes in 2006`, SUM(substr(col5,-4) = '2007') `Episodes in 2007`, ROUND(SUM(substr(col5,-4) = '2006') * 100.0 / COUNT(col0),2) `Pct 2006`, ROUND(SUM(substr(col5,-4) = '2007') * 100.0 / COUNT(col0),2) `Pct 2007`, MIN(col5) `Earliest airdate`, MAX(col5) `Latest airdate` FROM `table_1_15861819_1` WHERE col0 > 0;
","[(25, 14, 11, 56.0, 44.0, 'april14,2007', 'september8,2007')]",table_1_15861819_1,"1) The intent is to summarize episodes with aggregates: total count, year-specific counts for 2006 and 2007 by checking substr(Originalairdate,-4), percentages of totals (rounded to 2 decimals), and earliest/latest Originalairdate, for rows where No. in series > 0. 2) Map to schema: No. in series used for COUNT and filtering; Originalairdate used for year extraction and MIN/MAX. 3) Phrase the question to list each aggregate and the exact expressions used (COUNT, SUM with substr, ROUND percentage formulas, MIN, MAX). 4) Confirm inclusion of the filter No. in series > 0 and exact calculations.",reserved,3,reward,,
"List Air Canada Centre home games ordered with overtime games first and then by attendance descending, giving game, date, opponent, score, the named high points/high rebounds/high assists players and the numeric attendance so I can pick the highest-attended OT and non‑OT games?","
WITH `home_games` AS (
  SELECT
    `Game`,
    `Date`,
    `Team`,
    `Score`,
    `High points`,
    `High rebounds`,
    `High assists`,
    `Location Attendance`,
    CAST(REPLACE(SUBSTR(`Location Attendance`, INSTR(`Location Attendance`, 'Centre') + LENGTH('Centre') + 1), ',', '') AS INTEGER) AS `AttendanceNumeric`,
    CASE WHEN `Score` LIKE '%(OT)%' THEN 1 ELSE 0 END AS `is_ot`,
    CASE WHEN CAST(REPLACE(SUBSTR(`Location Attendance`, INSTR(`Location Attendance`, 'Centre') + LENGTH('Centre') + 1), ',', '') AS INTEGER) > 19000 THEN 1 ELSE 0 END AS `HighAttendance`
  FROM `table_1_15869204_6`
  WHERE `Location Attendance` LIKE '%Air Canada Centre%'
)
SELECT
  `Game`,
  `Date`,
  `Team`,
  `Score`,
  `High points`,
  `High rebounds`,
  `High assists`,
  `Location Attendance`,
  `AttendanceNumeric`,
  `is_ot`,
  AVG(`AttendanceNumeric`) OVER (PARTITION BY `is_ot`) AS `AvgAttendanceByOTFlag`,
  COUNT(*) OVER (PARTITION BY `is_ot`) AS `CountByOTFlag`,
  `HighAttendance`
FROM `home_games`
ORDER BY `is_ot` DESC, `AttendanceNumeric` DESC, `Game` ASC;
","
WITH `home_games` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    col7,
    CAST(REPLACE(SUBSTR(col7, INSTR(col7, 'Centre') + LENGTH('Centre') + 1), ',', '') AS INTEGER) AS `AttendanceNumeric`,
    CASE WHEN col3 LIKE '%(OT)%' THEN 1 ELSE 0 END AS `is_ot`,
    CASE WHEN CAST(REPLACE(SUBSTR(col7, INSTR(col7, 'Centre') + LENGTH('Centre') + 1), ',', '') AS INTEGER) > 19000 THEN 1 ELSE 0 END AS `HighAttendance`
  FROM `table_1_15869204_6`
  WHERE col7 LIKE '%Air Canada Centre%'
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  col6,
  col7,
  `AttendanceNumeric`,
  `is_ot`,
  AVG(`AttendanceNumeric`) OVER (PARTITION BY `is_ot`) AS `AvgAttendanceByOTFlag`,
  COUNT(*) OVER (PARTITION BY `is_ot`) AS `CountByOTFlag`,
  `HighAttendance`
FROM `home_games`
ORDER BY `is_ot` DESC, `AttendanceNumeric` DESC, col0 ASC;
","[(31.0, 'january 2', 'new orleans', 'l 74–86 (ot)', 'vince carter (22)', 'donyell marshall (8)', 'vince carter (4)', 'air canada centre 19,800', 0, 1, 0.0, 7, 0), (32.0, 'january 4', 'phoenix', 'w 83–73 (ot)', 'vince carter (23)', 'donyell marshall (15)', 'alvin williams (7)', 'air canada centre 19,029', 0, 1, 0.0, 7, 0), (33.0, 'january 7', 'cleveland', 'w 75–69 (ot)', 'vince carter , donyell marshall (14)', 'donyell marshall (13)', 'vince carter (5)', 'air canada centre 19,874', 0, 1, 0.0, 7, 0), (34.0, 'january 9', 'l.a. clippers', 'l 68–78 (ot)', 'jalen rose (26)', 'vince carter (10)', 'alvin williams (7)', 'air canada centre 18,405', 0, 1, 0.0, 7, 0), (35.0, 'january 11', 'portland', 'w 83–72 (ot)', 'vince carter (20)', 'donyell marshall (11)', 'vince carter (7)', 'air canada centre 18,906', 0, 1, 0.0, 7, 0), (40.0, 'january 21', 'minnesota', 'l 97–108 (ot)', 'donyell marshall (22)', 'chris bosh , donyell marshall , jalen rose (5)', 'milt palacio , alvin williams (4)', 'air canada centre 18,846', 0, 1, 0.0, 7, 0), (43.0, 'january 28', 'philadelphia', 'w 94–84 (ot)', 'donyell marshall (19)', 'donyell marshall (10)', 'jalen rose (13)', 'air canada centre 17,708', 0, 1, 0.0, 7, 0)]",table_1_15869204_6,"I want a sortable list so I can pick the single highest-attended OT and regulation games to recreate; I'd ask for OT first and highest attendance next along with the player credits. The SQL returns Air Canada Centre home games with numeric attendance, an OT flag, a >19,000 high-attendance flag, and orders rows by OT desc then attendance desc. The columns mapped are Game/Date/Team/Score/High points/High rebounds/High assists/Location Attendance/AttendanceNumeric/is_ot. Draft question: List Air Canada Centre home games ordered with overtime games first and then by attendance descending, giving game, date, opponent, score, the named high points/high rebounds/high assists players and the numeric attendance so I can pick the highest-attended OT and non‑OT games? Validation: The question asks exactly for the ordering, fields, and numeric attendance that the query provides and nothing beyond that.",persona,"A retired scoreboard engineer restoring and calibrating the original Air Canada Centre scoreboard and audio system to replay authentic 2003–04 Raptors home-game moments. Goals: Identify specific home games (especially high-attendance and overtime games) to recreate authentic scoreboard displays and crowd noise levels. Extract the exact players credited with 'High points', 'High rebounds', and 'High assists' for selected games so the restored scoreboard shows correct names/stats and triggers player-specific audio cues. Measure and compare attendance figures for overtime vs. regulation home games to calibrate speaker volume and crowd ambience presets for different crowd sizes. Example Queries: SELECT [Game], [Date], [Team], [Score], [High points], [High rebounds], [High assists], [Location Attendance]
FROM table_1_15869204_6
WHERE [Location Attendance] LIKE '%Air Canada Centre%'
  AND [Score] LIKE '%(OT)%'
  AND CAST(REPLACE(SUBSTR([Location Attendance], INSTR([Location Attendance], ' ')+1), ',', '') AS INTEGER) > 19000
ORDER BY CAST(REPLACE(SUBSTR([Location Attendance], INSTR([Location Attendance], ' ')+1), ',', '') AS INTEGER) DESC; SELECT COUNT(*) AS overtime_game_count,
       AVG(CAST(REPLACE(SUBSTR([Location Attendance], INSTR([Location Attendance], ' ')+1), ',', '') AS INTEGER)) AS avg_attendance_ot
FROM table_1_15869204_6
WHERE [Score] LIKE '%(OT)%'; SELECT [Game], [Date], [Team], [Score], [High points], [High assists], [Location Attendance]
FROM table_1_15869204_6
WHERE [High points] LIKE '%Vince Carter%'
  AND [High assists] LIKE '%Vince Carter%';",reward,,
"For each Team (grouped by Team) restricted to records where Game > 45, what are the total Games (COUNT(*)), Wins as the sum of rows whose Score begins with 'W', Losses as the sum of rows whose Score begins with 'L', the Max Attendance as the maximum of the numeric value obtained by removing commas from the last six characters of Location Attendance, and the Avg Attendance as the rounded average of that numeric value, and then list the top 10 teams ordered by Wins descending?","
SELECT `Team`,
       COUNT(*) `Games`,
       SUM(substr(`Score`,1,1)='W') `Wins`,
       SUM(substr(`Score`,1,1)='L') `Losses`,
       MAX(replace(substr(`Location Attendance`,-6),',','')+0) `Max Attendance`,
       ROUND(AVG(replace(substr(`Location Attendance`,-6),',','')+0)) `Avg Attendance`
FROM `table_1_15869204_7`
WHERE `Game` > 45
GROUP BY `Team`
ORDER BY `Wins` DESC
LIMIT 10;
","
SELECT col2,
       COUNT(*) `Games`,
       SUM(substr(col3,1,1)='W') `Wins`,
       SUM(substr(col3,1,1)='L') `Losses`,
       MAX(replace(substr(col7,-6),',','')+0) `Max Attendance`,
       ROUND(AVG(replace(substr(col7,-6),',','')+0)) `Avg Attendance`
FROM `table_1_15869204_7`
WHERE col0 > 45
GROUP BY col2
ORDER BY `Wins` DESC
LIMIT 10;
","[('washington', 1, 0, 0, 17291, 17291.0), ('san antonio', 1, 0, 0, 17119, 17119.0), ('sacramento', 1, 0, 0, 19800, 19800.0), ('orlando', 1, 0, 0, 16228, 16228.0), ('new jersey', 1, 0, 0, 19301, 19301.0), ('indiana', 1, 0, 0, 19311, 19311.0), ('@ seattle', 1, 0, 0, 14239, 14239.0), ('@ phoenix', 1, 0, 0, 14138, 14138.0), ('@ philadelphia', 1, 0, 0, 19049, 19049.0), ('@ new jersey', 1, 0, 0, 12829, 12829.0)]",table_1_15869204_7,"1) The SQL computes per-Team aggregates for rows with Game > 45, counting games, wins/losses by Score's first char, and attendance stats derived from the last six characters of Location Attendance with commas removed, then orders by wins and limits to 10. 2) Map these to natural language labels for each computed column and the filter/group/order/limit behavior. 3) Formulate a question requesting Team, Games, Wins, Losses, Max Attendance, and rounded Avg Attendance with the specified parsing and ordering. 4) Ensure no SQL detail is omitted.",reserved,8,reward,,
"Which 2003–04 Raptors games went to overtime—show the date, opponent, final score, top scorer line, attendance, and the team's record?","
WITH
ot_games AS (
  SELECT * FROM table_1_15869204_8 WHERE `Score` LIKE '%OT%'
),
parsed_ot AS (
  SELECT *,
    instr(`Score`, ' ')+1 AS `pos1`,
    instr(`Score`, '–') AS `pos2`,
    instr(`Score`, ' (') AS `pos_paren`
  FROM ot_games
),
scores_parsed AS (
  SELECT *,
    CAST(SUBSTR(`Score`, `pos1`, `pos2` - `pos1`) AS INTEGER) AS `Team_pts`,
    CAST(SUBSTR(`Score`, `pos2`+1, `pos_paren` - (`pos2`+1)) AS INTEGER) AS `Opp_pts`
  FROM parsed_ot
),
one_point_ot AS (
  SELECT `Game`,`Date`,`Team`,`Score`,`High points`,`High rebounds`,`High assists`,`Location Attendance`,`Record`,
    ABS(`Team_pts` - `Opp_pts`) AS `Margin`
  FROM scores_parsed
  WHERE ABS(`Team_pts` - `Opp_pts`) = 1
),
vince_30 AS (
  SELECT `Game`,`Date`,`Team`,`Score`,`High points`,`High rebounds`,`High assists`,`Location Attendance`,`Record`,
    CAST(SUBSTR(`High points`, instr(`High points`, '(')+1, instr(`High points`, ')') - instr(`High points`, '(') -1) AS INTEGER) AS `Vince_points`
  FROM table_1_15869204_8
  WHERE `High points` LIKE 'Vince Carter (%'
    AND CAST(SUBSTR(`High points`, instr(`High points`, '(')+1, instr(`High points`, ')') - instr(`High points`, '(') -1) AS INTEGER) >= 30
),
home_att AS (
  SELECT `Game`,`Date`,`Team`,`Score`,`High points`,`High rebounds`,`High assists`,`Location Attendance`,`Record`,
    REPLACE(SUBSTR(`Location Attendance`, instr(`Location Attendance`, ' 1')+1), ',', '') AS `Attendance_digits`
  FROM table_1_15869204_8
  WHERE `Team` NOT LIKE '@%'
),
away_venues AS (
  SELECT `Date`,`Team`,`Location Attendance` FROM table_1_15869204_8 WHERE `Team` LIKE '@%'
)
SELECT 'OT game' AS `Insight`, `Game`,`Date`,`Team`,`Score`,`High points`,`Location Attendance`,`Record`, NULL AS `Detail`
FROM ot_games
UNION ALL
SELECT 'OT one-point finish' AS `Insight`, `Game`,`Date`,`Team`,`Score`,`High points`,`Location Attendance`,`Record`, CAST(`Margin` AS TEXT) AS `Detail`
FROM one_point_ot
UNION ALL
SELECT 'Vince 30+' AS `Insight`, `Game`,`Date`,`Team`,`Score`,`High points`,`Location Attendance`,`Record`, CAST(`Vince_points` AS TEXT) AS `Detail`
FROM vince_30
UNION ALL
SELECT 'Home attendance (use as numeric lock)' AS `Insight`, `Game`,`Date`,`Team`,`Score`,`High points`,`Location Attendance`,`Record`, `Attendance_digits` AS `Detail`
FROM home_att
UNION ALL
SELECT 'Away venue for location-based riddle' AS `Insight`, NULL AS `Game`,`Date`,`Team`, NULL AS `Score`, NULL AS `High points`,`Location Attendance`, NULL AS `Record`, NULL AS `Detail`
FROM away_venues
ORDER BY `Insight`, `Date`;
","SELECT 'OT game' AS `Insight`, col0,col1,col2,col3,col4,col7,col8, NULL AS `Detail`
FROM table_1_15869204_8
WHERE col3 LIKE '%OT%'
UNION ALL
SELECT 'OT one-point finish' AS `Insight`, col0,col1,col2,col3,col4,col7,col8,
 CAST(ABS(
   CAST(SUBSTR(col3, INSTR(col3, ' ')+1, INSTR(col3, '–') - (INSTR(col3, ' ')+1)) AS INTEGER)
   - CAST(SUBSTR(col3, INSTR(col3, '–')+1, INSTR(col3, ' (') - (INSTR(col3, '–')+1)) AS INTEGER)
 ) AS TEXT) AS `Detail`
FROM table_1_15869204_8
WHERE col3 LIKE '%OT%'
  AND ABS(
   CAST(SUBSTR(col3, INSTR(col3, ' ')+1, INSTR(col3, '–') - (INSTR(col3, ' ')+1)) AS INTEGER)
   - CAST(SUBSTR(col3, INSTR(col3, '–')+1, INSTR(col3, ' (') - (INSTR(col3, '–')+1)) AS INTEGER)
  ) = 1
UNION ALL
SELECT 'Vince 30+' AS `Insight`, col0,col1,col2,col3,col4,col7,col8,
 CAST(
   CAST(SUBSTR(col4, INSTR(col4, '(')+1, INSTR(col4, ')') - INSTR(col4, '(') - 1) AS INTEGER)
 AS TEXT) AS `Detail`
FROM table_1_15869204_8
WHERE col4 LIKE 'Vince Carter (%'
  AND CAST(SUBSTR(col4, INSTR(col4, '(')+1, INSTR(col4, ')') - INSTR(col4, '(') - 1) AS INTEGER) >= 30
UNION ALL
SELECT 'Home attendance (use as numeric lock)' AS `Insight`, col0,col1,col2,col3,col4,col7,col8, col7 AS `Detail`
FROM table_1_15869204_8
WHERE col2 NOT LIKE '@%'
UNION ALL
SELECT 'Away venue for location-based riddle' AS `Insight`, NULL AS col0,col1,col2, NULL AS col3, NULL AS col4,col7, NULL AS col8, NULL AS `Detail`
FROM table_1_15869204_8
WHERE col2 LIKE '@%'
ORDER BY `Insight`, col1;","[('Away venue for location-based riddle', None, 'march 2', '@ miami', None, None, 'american airlines arena 14,178', None, None), ('Away venue for location-based riddle', None, 'march 21', '@ new orleans', None, None, 'new orleans arena 14,307', None, None), ('Away venue for location-based riddle', None, 'march 23', '@ memphis', None, None, 'pyramid arena 13,191', None, None), ('Away venue for location-based riddle', None, 'march 24', '@ houston', None, None, 'toyota center 14,388', None, None), ('Away venue for location-based riddle', None, 'march 26', '@ new york', None, None, 'madison square garden 19,763', None, None), ('Away venue for location-based riddle', None, 'march 3', '@ washington', None, None, 'mci center 13,921', None, None), ('Away venue for location-based riddle', None, 'march 9', '@ indiana', None, None, 'conseco fieldhouse 15,123', None, None), ('Home attendance (use as numeric lock)', 65.0, 'march 10', 'cleveland', 'l 92–106 (ot)', 'vince carter (19)', 'air canada centre 17,459', '27–38', 'air canada centre 17,459'), ('Home attendance (use as numeric lock)', 66.0, 'march 14', 'atlanta', 'w 101–84 (ot)', 'vince carter (32)', 'air canada centre 17,628', '28–38', 'air canada centre 17,628'), ('Home attendance (use as numeric lock)', 67.0, 'march 17', 'utah', 'w 85–81 (ot)', 'vince carter (24)', 'air canada centre 17,875', '29–38', 'air canada centre 17,875'), ('Home attendance (use as numeric lock)', 68.0, 'march 19', 'chicago', 'l 91–96 (ot)', 'vince carter (30)', 'air canada centre 19,348', '29–39', 'air canada centre 19,348'), ('Home attendance (use as numeric lock)', 73.0, 'march 28', 'memphis', 'l 88–94 (ot)', 'jalen rose (18)', 'air canada centre 19,088', '30–43', 'air canada centre 19,088'), ('Home attendance (use as numeric lock)', 62.0, 'march 5', 'new york', 'l 103–109 (ot)', 'vince carter (32)', 'air canada centre 19,287', '26–36', 'air canada centre 19,287'), ('Home attendance (use as numeric lock)', 63.0, 'march 7', 'new orleans', 'w 84–76 (ot)', 'vince carter (26)', 'air canada centre 17,031', '27–36', 'air canada centre 17,031'), ('OT game', 65.0, 'march 10', 'cleveland', 'l 92–106 (ot)', 'vince carter (19)', 'air canada centre 17,459', '27–38', None), ('OT game', 66.0, 'march 14', 'atlanta', 'w 101–84 (ot)', 'vince carter (32)', 'air canada centre 17,628', '28–38', None), ('OT game', 67.0, 'march 17', 'utah', 'w 85–81 (ot)', 'vince carter (24)', 'air canada centre 17,875', '29–38', None), ('OT game', 68.0, 'march 19', 'chicago', 'l 91–96 (ot)', 'vince carter (30)', 'air canada centre 19,348', '29–39', None), ('OT game', 60.0, 'march 2', '@ miami', 'w 89–86 (ot)', 'vince carter (27)', 'american airlines arena 14,178', '26–34', None), ('OT game', 69.0, 'march 21', '@ new orleans', 'w 121–120 (ot)', 'vince carter (42)', 'new orleans arena 14,307', '30–39', None), ('OT game', 70.0, 'march 23', '@ memphis', 'l 86–95 (ot)', 'vince carter (30)', 'pyramid arena 13,191', '30–40', None), ('OT game', 71.0, 'march 24', '@ houston', 'l 89–90 (ot)', 'vince carter (26)', 'toyota center 14,388', '30–41', None), ('OT game', 72.0, 'march 26', '@ new york', 'l 101–108 (ot)', 'vince carter (40)', 'madison square garden 19,763', '30–42', None), ('OT game', 73.0, 'march 28', 'memphis', 'l 88–94 (ot)', 'jalen rose (18)', 'air canada centre 19,088', '30–43', None), ('OT game', 61.0, 'march 3', '@ washington', 'l 70–84 (ot)', 'donyell marshall (22)', 'mci center 13,921', '26–35', None), ('OT game', 62.0, 'march 5', 'new york', 'l 103–109 (ot)', 'vince carter (32)', 'air canada centre 19,287', '26–36', None), ('OT game', 63.0, 'march 7', 'new orleans', 'w 84–76 (ot)', 'vince carter (26)', 'air canada centre 17,031', '27–36', None), ('OT game', 64.0, 'march 9', '@ indiana', 'l 84–94 (ot)', 'vince carter (28)', 'conseco fieldhouse 15,123', '27–37', None), ('OT one-point finish', 69.0, 'march 21', '@ new orleans', 'w 121–120 (ot)', 'vince carter (42)', 'new orleans arena 14,307', '30–39', '1'), ('OT one-point finish', 71.0, 'march 24', '@ houston', 'l 89–90 (ot)', 'vince carter (26)', 'toyota center 14,388', '30–41', '1'), ('Vince 30+', 66.0, 'march 14', 'atlanta', 'w 101–84 (ot)', 'vince carter (32)', 'air canada centre 17,628', '28–38', '32'), ('Vince 30+', 68.0, 'march 19', 'chicago', 'l 91–96 (ot)', 'vince carter (30)', 'air canada centre 19,348', '29–39', '30'), ('Vince 30+', 69.0, 'march 21', '@ new orleans', 'w 121–120 (ot)', 'vince carter (42)', 'new orleans arena 14,307', '30–39', '42'), ('Vince 30+', 70.0, 'march 23', '@ memphis', 'l 86–95 (ot)', 'vince carter (30)', 'pyramid arena 13,191', '30–40', '30'), ('Vince 30+', 72.0, 'march 26', '@ new york', 'l 101–108 (ot)', 'vince carter (40)', 'madison square garden 19,763', '30–42', '40'), ('Vince 30+', 62.0, 'march 5', 'new york', 'l 103–109 (ot)', 'vince carter (32)', 'air canada centre 19,287', '26–36', '32')]",table_1_15869204_8,"I'm an indie escape-room designer who knows Raptors lore and talks casually about big moments, so I wouldn't use exact column names but I know to ask for overtime games and key facts. The SQL pulls every row where the Score contains 'OT'. The relevant columns are Date, Team (opponent/location indicator), Score, High points, Location Attendance and Record which give the details I need for a tense scene. Which 2003–04 Raptors games went to overtime—show the date, opponent, final score, top scorer line, attendance, and the team's record? This question matches the query's filter on '%OT%' and the returned fields for OT games.",persona,"An indie escape-room designer who builds Toronto Raptors 2003–04 season–themed puzzles that use real game facts (OTs, star stat lines, attendance figures, and arena names) as coded clues. Goals: Identify dramatic games (overtime, one-point finishes, buzzer outcomes) to base high-tension puzzle scenes on. Find distinctive player stat-lines (e.g., Vince Carter 30+ games, rare triple-digit assists/rebounds mentions) to encode numeric clues or answer keys. Select home-game attendance figures and arena names to create realistic physical props and numeric locks (e.g., using attendance numbers as codes). Assemble a short list of memorable away-venue names and dates for location-based riddles and timeline puzzles. Example Queries: SELECT * FROM table_1_15869204_8 WHERE ""Score"" LIKE '%OT%'; SELECT ""Game"", ""Date"", ""Team"", ""Score"", ""High points"" FROM table_1_15869204_8 WHERE ""High points"" LIKE '%Vince Carter (%' AND (""High points"" LIKE '%(3%' OR ""High points"" LIKE '%(4%' OR ""High points"" LIKE '%(5%') ORDER BY ""Date""; SELECT ""Date"", ""Team"", ""Location Attendance"" FROM table_1_15869204_8 WHERE ""Location Attendance"" LIKE '%Air Canada Centre%' ORDER BY CAST(REPLACE(SUBSTR(""Location Attendance"", INSTR(""Location Attendance"", ' ')+1), ',', '') AS INTEGER) DESC LIMIT 5;",reward,,
"Can you give me a list—OT nights first, then home games by largest attendance—showing date, opponent, score, top scorers/rebounders/assisters, arena, attendance, whether it was OT, and a suggested Platinum/Gold/Silver/Standard tier?","
WITH `games` AS (
  SELECT
    `Date`,
    `Team`,
    `Score`,
    `High points`,
    `High rebounds`,
    `High assists`,
    `Location Attendance`,
    `Record`,
    CAST(
      REPLACE(
        REPLACE(
          REPLACE(
            REPLACE(
              REPLACE(`Location Attendance`, 'Air Canada Centre ', ''),
            'Wachovia Center ', ''),
          'Target Center ', ''),
        'Charlotte Coliseum ', ''),
      ',', '') AS INTEGER
    ) AS `Attendance`,
    CASE WHEN `Location Attendance` LIKE 'Air Canada Centre %' THEN 1 ELSE 0 END AS `Is Home`,
    CASE WHEN `Score` LIKE '%(OT)%' THEN 1 ELSE 0 END AS `Is OT`
  FROM `table_1_15872814_5`
)
SELECT
  `Date`,
  `Team`,
  `Score`,
  `High points`,
  `High rebounds`,
  `High assists`,
  CASE
    WHEN `Location Attendance` LIKE 'Air Canada Centre %' THEN '`Air Canada Centre`'
    WHEN `Location Attendance` LIKE 'Wachovia Center %' THEN '`Wachovia Center`'
    WHEN `Location Attendance` LIKE 'Target Center %' THEN '`Target Center`'
    WHEN `Location Attendance` LIKE 'Charlotte Coliseum %' THEN '`Charlotte Coliseum`'
    ELSE '`' || REPLACE(SUBSTR(`Location Attendance`, 1, INSTR(`Location Attendance`, ' ')-1), '`', '') || '`'
  END AS `Arena`,
  `Attendance`,
  `Is OT`,
  CASE
    WHEN `Is Home` = 1 AND `Attendance` >= 18000 THEN '`Platinum`'
    WHEN `Is Home` = 1 AND `Attendance` >= 17000 THEN '`Gold`'
    WHEN `Is Home` = 1 AND `Attendance` >= 16000 THEN '`Silver`'
    ELSE '`Standard`'
  END AS `Suggested Tier`,
  `Record`
FROM `games`
WHERE
  ( `Is Home` = 1 AND `Attendance` >= 16000 )
  OR `Is OT` = 1
ORDER BY `Is OT` DESC, `Is Home` DESC, `Attendance` DESC, `Date`;
","
WITH `games` AS (
  SELECT
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    col7,
    col8,
    CAST(
      REPLACE(
        REPLACE(
          REPLACE(
            REPLACE(
              REPLACE(col7, 'Air Canada Centre ', ''),
            'Wachovia Center ', ''),
          'Target Center ', ''),
        'Charlotte Coliseum ', ''),
      ',', '') AS INTEGER
    ) AS `Attendance`,
    CASE WHEN col7 LIKE 'Air Canada Centre %' THEN 1 ELSE 0 END AS `Is Home`,
    CASE WHEN col3 LIKE '%(OT)%' THEN 1 ELSE 0 END AS `Is OT`
  FROM `table_1_15872814_5`
)
SELECT
  col1,
  col2,
  col3,
  col4,
  col5,
  col6,
  CASE
    WHEN col7 LIKE 'Air Canada Centre %' THEN '`Air Canada Centre`'
    WHEN col7 LIKE 'Wachovia Center %' THEN '`Wachovia Center`'
    WHEN col7 LIKE 'Target Center %' THEN '`Target Center`'
    WHEN col7 LIKE 'Charlotte Coliseum %' THEN '`Charlotte Coliseum`'
    ELSE '`' || REPLACE(SUBSTR(col7, 1, INSTR(col7, ' ')-1), '`', '') || '`'
  END AS `Arena`,
  `Attendance`,
  `Is OT`,
  CASE
    WHEN `Is Home` = 1 AND `Attendance` >= 18000 THEN '`Platinum`'
    WHEN `Is Home` = 1 AND `Attendance` >= 17000 THEN '`Gold`'
    WHEN `Is Home` = 1 AND `Attendance` >= 16000 THEN '`Silver`'
    ELSE '`Standard`'
  END AS `Suggested Tier`,
  col8
FROM `games`
WHERE
  ( `Is Home` = 1 AND `Attendance` >= 16000 )
  OR `Is OT` = 1
ORDER BY `Is OT` DESC, `Is Home` DESC, `Attendance` DESC, col1;
","[('january 12', 'boston', 'w 104–93 (ot)', 'morris peterson (37)', 'chris bosh (11)', 'rafer alston , morris peterson (6)', '`Air Canada Centre`', 0, 1, '`Standard`', '14–22'), ('january 16', 'new orleans', 'w 102–99 (ot)', 'morris peterson (25)', 'chris bosh , morris peterson (10)', 'rafer alston (7)', '`Air Canada Centre`', 0, 1, '`Standard`', '15–23'), ('january 19', 'new york', 'w 98–81 (ot)', 'jalen rose (24)', 'chris bosh (14)', 'rafer alston , jalen rose (5)', '`Air Canada Centre`', 0, 1, '`Standard`', '17–23'), ('january 23', 'charlotte', 'w 103–92 (ot)', 'morris peterson (26)', 'rafael araújo , chris bosh (8)', 'rafer alston (8)', '`Air Canada Centre`', 0, 1, '`Standard`', '18–24'), ('january 26', 'miami', 'l 96–111 (ot)', 'rafer alston (29)', 'lamond murray (8)', 'rafer alston (8)', '`Air Canada Centre`', 0, 1, '`Standard`', '18–25'), ('january 3', 'orlando', 'w 105–94 (ot)', 'chris bosh (25)', 'chris bosh (12)', 'rafer alston , milt palacio (6)', '`Air Canada Centre`', 0, 1, '`Standard`', '11–21'), ('january 5', 'sacramento', 'w 96–93 (ot)', 'chris bosh (23)', 'rafael araújo (14)', 'rafer alston (10)', '`Air Canada Centre`', 0, 1, '`Standard`', '12–21'), ('january 7', 'milwaukee', 'l 105–107 (ot)', 'jalen rose , eric williams (21)', 'donyell marshall (14)', 'rafer alston (8)', '`Air Canada Centre`', 0, 1, '`Standard`', '12–22'), ('january 9', 'golden state', 'w 109–87 (ot)', 'chris bosh , morris peterson (21)', 'chris bosh (17)', 'rafer alston (7)', '`Air Canada Centre`', 0, 1, '`Standard`', '13–22'), ('january 14', '@ philadelphia', 'l 96–106 (ot)', 'donyell marshall (20)', 'chris bosh (13)', 'rafer alston (13)', '`Wachovia Center`', 0, 1, '`Standard`', '14–23'), ('january 17', '@ minnesota', 'w 100–91 (ot)', 'donyell marshall (22)', 'chris bosh (11)', 'rafer alston (15)', '`Target Center`', 0, 1, '`Standard`', '16–23'), ('january 21', '@ washington', 'l 109–118 (ot)', 'jalen rose (32)', 'morris peterson (9)', 'rafer alston (7)', '`mci`', 0, 1, '`Standard`', '17–24'), ('january 28', '@ charlotte', 'l 94–101 (ot)', 'rafer alston (20)', 'jalen rose (6)', 'jalen rose (5)', '`Charlotte Coliseum`', 0, 1, '`Standard`', '18–26')]",table_1_15872814_5,"I'm likely to ask for a handy ordered list for menu planning, casually requesting OT nights first then big home crowds. The SQL orders results with OT games first, then home games by attendance descending and includes arena, attendance, OT flag and tier. The mapping uses Date, Team, Score, highs, Location Attendance → Arena/Attendance, Is OT and Suggested Tier. Draft question: request the list ordered with OT first and then by attendance including all those details. This is consistent with the query's ORDER BY and selected fields.",persona,"```json
{
  ""short_description"": ""A nostalgic pop-up chef who designs immersive 2004–05 Toronto Raptors game-night tasting menus that pair dishes with player performances, attendance vibes, and overtime drama."",
  ""goals"": [
    ""Identify high-attendance home games and the star performers from those nights to inspire marquee dishes and pricing tiers."",
    ""Find all overtime games and the key contributors to craft a special 'clutch' mini-menu celebrating dramatic nights."",
    ""Locate games wher Goals:  Example Queries: ",reward,,
"Which distinct Opponents (t1.`Team`) — when the game rows are INNER JOINed to themselves on Date — have the following aggregates: SUM((t1.`Score` LIKE 'W %')) AS Wins, SUM((t1.`Score` LIKE 'W %') * (t1.`Team` LIKE '@%')) AS Away Wins, and SUM((t1.`High points` LIKE '%Chris Bosh%')) AS Chris Bosh Top Games, considering only rows WHERE (t1.`High points` LIKE '%Chris Bosh%') OR (t1.`High points` LIKE '%Jalen Rose%'), grouped by t1.`Team`, HAVING SUM((t1.`Score` LIKE 'W %')) > 0, ordered by Wins DESC and limited to 5?","
SELECT DISTINCT t1.`Team` AS `Opponent`, SUM((t1.`Score` LIKE 'W %')) AS `Wins`, SUM((t1.`Score` LIKE 'W %') * (t1.`Team` LIKE '@%')) AS `Away Wins`, SUM((t1.`High points` LIKE '%Chris Bosh%')) AS `Chris Bosh Top Games`
FROM `table_1_15872814_6` AS t1
INNER JOIN `table_1_15872814_6` AS t2 ON t1.`Date` = t2.`Date`
WHERE (t1.`High points` LIKE '%Chris Bosh%') OR (t1.`High points` LIKE '%Jalen Rose%')
GROUP BY t1.`Team`
HAVING SUM((t1.`Score` LIKE 'W %')) > 0
ORDER BY `Wins` DESC
LIMIT 5;
","
SELECT DISTINCT t1.col2 AS `Opponent`, SUM((t1.col3 LIKE 'W %')) AS `Wins`, SUM((t1.col3 LIKE 'W %') * (t1.col2 LIKE '@%')) AS `Away Wins`, SUM((t1.col4 LIKE '%Chris Bosh%')) AS `Chris Bosh Top Games`
FROM `table_1_15872814_6` AS t1
INNER JOIN `table_1_15872814_6` AS t2 ON t1.col1 = t2.col1
WHERE (t1.col4 LIKE '%Chris Bosh%') OR (t1.col4 LIKE '%Jalen Rose%')
GROUP BY t1.col2
HAVING SUM((t1.col3 LIKE 'W %')) > 0
ORDER BY `Wins` DESC
LIMIT 5;
","[('washington', 1, 0, 0), ('l.a. clippers', 1, 0, 1), ('@ new jersey', 1, 1, 0), ('@ milwaukee', 1, 1, 1), ('@ indiana', 1, 1, 1)]",table_1_15872814_6,"1) Parse the SQL intent: produce the top 5 opponents by wins (wins counted where Score starts with 'W '), also counting away wins and games where Chris Bosh was the high scorer, but only considering games where the high scorer was Chris Bosh or Jalen Rose. 2) Map schema semantics: `Team` is Opponent, `Score` indicates W/L with 'W ' prefix, away games marked by '@' at start of `Team`, and `High points` contains player names. 3) Draft the question: ask for distinct Opponents with SUM((Score LIKE 'W %')) AS Wins, SUM((Score LIKE 'W %') * (Team LIKE '@%')) AS Away Wins, SUM((High points LIKE '%Chris Bosh%')) AS Chris Bosh Top Games, with the WHERE, GROUP BY, HAVING, ORDER BY, LIMIT and the self-join on Date. 4) Validate: confirm inclusion of all columns, calculations, filters, grouping, and ordering from the query.",reserved,15,reward,,
"For each Country (considering only rows with N°>0), what are the Country name, Total Channels as COUNT(*), HD Channels as SUM(HDTV='yes'), HD Percentage as ROUND(100.0*SUM(HDTV='yes')/COUNT(*),1), the Package Count as COUNT(`Package/Option`) and the Packages as GROUP_CONCAT(`Package/Option`), with results grouped by Country and sorted by HD Percentage descending?","
SELECT `Country`, COUNT(*) AS `Total Channels`, SUM(`HDTV`='yes') `HD Channels`, ROUND(100.0*SUM(`HDTV`='yes')/COUNT(*),1) `HD Percentage`, COUNT(`Package/Option`) `Package Count`, GROUP_CONCAT(`Package/Option`) `Packages`
FROM `table_1_15887683_10`
WHERE `N°`>0
GROUP BY `Country`
ORDER BY `HD Percentage` DESC;
","
SELECT col2, COUNT(*) AS `Total Channels`, SUM(col6='yes') `HD Channels`, ROUND(100.0*SUM(col6='yes')/COUNT(*),1) `HD Percentage`, COUNT(col8) `Package Count`, GROUP_CONCAT(col8) `Packages`
FROM `table_1_15887683_10`
WHERE col0>0
GROUP BY col2
ORDER BY `HD Percentage` DESC;
","[('poland', 1, 1, 100.0, 1, 'sky famiglia + sky hd'), ('united kingdom', 2, 0, 0.0, 2, 'sky famiglia,sky famiglia'), ('italy', 12, 0, 0.0, 12, 'sky famiglia,sky famiglia,sky famiglia,sky famiglia,sky famiglia,no ( ftv ),no ( ftv ),sky famiglia,sky famiglia,sky famiglia,sky famiglia,option')]",table_1_15887683_10,"1) The SQL groups by Country and returns aggregate metrics: total channels, HD channel count, rounded HD percentage, package count and packages concatenated, with N°>0 filter and sort by HD percentage descending. 2) Map table fields: N° filter, Country grouping, HDTV checked for 'yes', Package/Option counted and concatenated. 3) Create a question that requests all those aggregates and the exact percentage formula ROUND(100.0*SUM(HDTV='yes')/COUNT(*),1), plus grouping and ordering constraints. 4) Confirm no extra fields or assumptions are added beyond the query.",reserved,8,reward,,
"Prepara un report che mostri prima l'elenco dettagliato dei canali adulti e poi un sommario per PPV/HDTV/Package degli adulti e infine un sommario comparativo (adulti vs general) per PPV/HDTV/Package, ordinando i dettagli per nome del servizio?","
WITH
`adult` AS (
  SELECT `N°`, `Television service`, `Country`, `Language`, `Content`, `DAR`, `HDTV`, `PPV`, `Package/Option`
  FROM `table_1_15887683_19`
  WHERE `Content` LIKE '%programmi per adulti%'
),
`general` AS (
  SELECT `N°`, `Television service`, `Country`, `Language`, `Content`, `DAR`, `HDTV`, `PPV`, `Package/Option`
  FROM `table_1_15887683_19`
  WHERE `Content` LIKE '%general television%'
)
SELECT 'Adult - detail' AS `report_section`,
       `N°`, `Television service`, `Content`, `DAR`, `HDTV`, `PPV`, `Package/Option`, NULL AS `channel_count`
FROM `adult`
UNION ALL
SELECT 'Adult - summary by PPV/HDTV/Package' AS `report_section`,
       NULL, NULL, NULL, NULL, `HDTV`, `PPV`, `Package/Option`, COUNT(*) AS `channel_count`
FROM `adult`
GROUP BY `PPV`, `HDTV`, `Package/Option`
UNION ALL
SELECT 'Comparative summary (Adult vs General) by PPV/HDTV/Package' AS `report_section`,
       NULL, NULL, `Content`, NULL, `HDTV`, `PPV`, `Package/Option`, COUNT(*) AS `channel_count`
FROM `table_1_15887683_19`
WHERE `Content` IN ('programmi per adulti 24h/24', 'general television')
GROUP BY `Content`, `PPV`, `HDTV`, `Package/Option`
ORDER BY
  CASE WHEN `report_section` = 'Adult - detail' THEN 1
       WHEN `report_section` = 'Adult - summary by PPV/HDTV/Package' THEN 2
       ELSE 3 END,
  `Television service` COLLATE NOCASE;
","WITH
`adult` AS (
  SELECT col0, col1, col2, col3, col4, col5, col6, col7, col8
  FROM `table_1_15887683_19`
  WHERE col4 LIKE '%programmi per adulti%'
),
`general` AS (
  SELECT col0, col1, col2, col3, col4, col5, col6, col7, col8
  FROM `table_1_15887683_19`
  WHERE col4 LIKE '%general television%'
)
SELECT *
FROM (
  SELECT 'Adult - detail' AS `report_section`,
         col0, col1, col4, col5, col6, col7, col8, NULL AS `channel_count`
  FROM `adult`
  UNION ALL
  SELECT 'Adult - summary by PPV/HDTV/Package' AS `report_section`,
         NULL, NULL, NULL, NULL, col6, col7, col8, COUNT(*) AS `channel_count`
  FROM `adult`
  GROUP BY col7, col6, col8
  UNION ALL
  SELECT 'Comparative summary (Adult vs General) by PPV/HDTV/Package' AS `report_section`,
         NULL, NULL, col4, NULL, col6, col7, col8, COUNT(*) AS `channel_count`
  FROM `table_1_15887683_19`
  WHERE col4 IN ('programmi per adulti 24h/24', 'general television')
  GROUP BY col4, col7, col6, col8
) AS `report`
ORDER BY
  CASE WHEN `report`.`report_section` = 'Adult - detail' THEN 1
       WHEN `report`.`report_section` = 'Adult - summary by PPV/HDTV/Package' THEN 2
       ELSE 3 END,
  `report`.col1 COLLATE NOCASE;","[('Adult - detail', 992.0, 'boy&boy', 'programmi per adulti 24h/24', '4:3', 'no', 'yes', 'qualsiasi', None), ('Adult - detail', 984.0, 'contotv 4', 'programmi per adulti 24h/24', '4:3', 'no', 'no', 'qualsiasi', None), ('Adult - detail', 985.0, 'contotv 5', 'programmi per adulti 24h/24', '4:3', 'no', 'no', 'qualsiasi', None), ('Adult - detail', 989.0, 'd-xtv', 'programmi per adulti 24h/24', '4:3', 'no', 'yes', 'qualsiasi', None), ('Adult - detail', 993.0, 'privè', 'programmi per adulti 24h/24', '4:3', 'no', 'yes', 'qualsiasi', None), ('Adult - detail', 990.0, 'r-light', 'programmi per adulti 24h/24', '4:3', 'no', 'yes', 'qualsiasi', None), ('Adult - detail', 991.0, 'sct', 'programmi per adulti 24h/24', '4:3', 'no', 'yes', 'qualsiasi', None), ('Adult - detail', 994.0, 'themex', 'programmi per adulti 24h/24', '4:3', 'no', 'yes', 'qualsiasi', None), ('Adult - summary by PPV/HDTV/Package', None, None, None, None, 'no', 'no', 'qualsiasi', 2), ('Adult - summary by PPV/HDTV/Package', None, None, None, None, 'no', 'yes', 'qualsiasi', 6), ('Comparative summary (Adult vs General) by PPV/HDTV/Package', None, None, 'general television', None, 'no', 'no', 'qualsiasi', 1), ('Comparative summary (Adult vs General) by PPV/HDTV/Package', None, None, 'general television', None, 'no', 'yes', 'qualsiasi', 2), ('Comparative summary (Adult vs General) by PPV/HDTV/Package', None, None, 'general television', None, 'no', 'yes', 'qualsiasi ( fta )', 2), ('Comparative summary (Adult vs General) by PPV/HDTV/Package', None, None, 'programmi per adulti 24h/24', None, 'no', 'no', 'qualsiasi', 2), ('Comparative summary (Adult vs General) by PPV/HDTV/Package', None, None, 'programmi per adulti 24h/24', None, 'no', 'yes', 'qualsiasi', 6)]",table_1_15887683_19,"Persona: wants a single ordered report combining detail and summaries for reporting/audit purposes and will specify order (details first). SQL intent: produce a unioned report with adult detail first, then adult summary, then comparative summary, ordered by report section and Television service. Schema mapping: the output sections are labeled and include the detailed rows and grouped summaries ordered by service name. Draft question: Prepara un report che mostri prima l'elenco dettagliato dei canali adulti e poi un sommario per PPV/HDTV/Package degli adulti e infine un sommario comparativo (adulti vs general) per PPV/HDTV/Package, ordinando i dettagli per nome del servizio? Validation: This asks for the combined, ordered report structure that the query produces.",persona,"Broadcast compliance analyst at Italy's communications regulator (e.g., AGCOM) responsible for monitoring content classification and distribution rules; uses this database to find channels that may require investigation or reclassification. They focus on adult-content distribution, PPV usage, and free-to-air vs. packaged offerings to ensure regulatory compliance. Goals: Identify all channels broadcasting 'programmi per adulti 24h/24' to check age-restriction and scheduling compliance. Determine which adult or general channels are offered as PPV versus free-to-air (FTA) and which advertise HDTV support. Produce summary counts and lists (by PPV, HDTV, and Package/Option) for enforcement reports and follow-up audits. Example Queries: SELECT ""N°"", ""Television service"", ""Country"", ""Language"", ""Content"", ""PPV"", ""Package/Option"" 
FROM table_1_15887683_19 
WHERE ""Content"" LIKE '%programmi per adulti%' 
ORDER BY ""Television service""; SELECT ""PPV"", ""HDTV"", COUNT(*) AS channel_count 
FROM table_1_15887683_19 
WHERE ""Content"" LIKE '%programmi per adulti%' 
GROUP BY ""PPV"", ""HDTV"" 
ORDER BY channel_count DESC; SELECT ""N°"", ""Television service"", ""Content"", ""DAR"", ""HDTV"", ""Package/Option"" 
FROM table_1_15887683_19 
WHERE ""Content"" LIKE '%general television%' 
  AND ""Package/Option"" ILIKE '%FTA%' 
  AND ""HDTV"" = 'no';",reward,,
"For each Validation, provide the Validation value, the total number of entries (COUNT(*) as Total), and the number of distinct Issuing network entries (COUNT(DISTINCT Issuing network) as Distinct issuers) for rows where Active IS Active OR IIN ranges = IIN ranges AND Length IN (Length), grouped by Validation, with groups having COUNT(*) > 0, limited to 10 results.","
SELECT `Validation` AS `Validation`, COUNT(*) `Total`, COUNT(DISTINCT `Issuing network`) `Distinct issuers`
FROM `table_1_15905399_1`
WHERE `Active` IS `Active` OR `IIN ranges` = `IIN ranges` AND `Length` IN (`Length`)
GROUP BY `Validation` HAVING COUNT(*) > 0
LIMIT 10;
","
SELECT col4 AS col4, COUNT(*) `Total`, COUNT(DISTINCT col0) `Distinct issuers`
FROM `table_1_15905399_1`
WHERE col2 IS col2 OR col1 = col1 AND col3 IN (col3)
GROUP BY col4 HAVING COUNT(*) > 0
LIMIT 10;
","[('luhn algorithm', 13, 13), ('no validation', 2, 2)]",table_1_15905399_1,"1) Intent: aggregate counts per Validation including distinct issuer count, with an unrestrictive WHERE (column equals itself), grouped and filtered by HAVING COUNT(*) > 0 and limited to 10. 2) Map: include Validation, Issuing network, Active, IIN ranges, Length, and the two COUNT aggregations. 3) Draft a question that explicitly requests those fields, conditions, grouping, having and limit. 4) Confirm alignment with SQL elements only.",reserved,13,reward,,
Which countries are top priority for expansive organic textures — agriculture ≥80% with very high per-capita withdrawal — so I can plan long irrigation drones?,"
SELECT
  `Country`,
  CAST(`Total Freshwater Withdrawal` AS REAL) AS `TotalWithdrawal`,
  `Per Capita Withdrawal` AS `PerCapitaWithdrawal`,
  `Agricultural Use`,
  `Industrial Use`,
  `Domestic Use`,
  (`Agricultural Use` - `Industrial Use`) AS `Ag_minus_Ind`,
  CASE
    WHEN `Agricultural Use` >= 80 THEN 'Organic Drone / Irrigation Rhythms'
    WHEN `Industrial Use` >= 50 THEN 'Metallic Percussion / Mechanical Textures'
    WHEN `Domestic Use` >= 50 THEN 'Intimate Domestic / Human-scale Textures'
    WHEN `Agricultural Use` BETWEEN 20 AND 49 AND `Industrial Use` BETWEEN 20 AND 49 THEN 'Mixed Textures (blend organic + industrial)'
    ELSE 'Balanced / Hybrid Textures'
  END AS `Primary_Texture`,
  CASE
    WHEN `Per Capita Withdrawal` > 5000 THEN 'Extremely high per-capita — prioritize intense human-scale recordings'
    WHEN `Per Capita Withdrawal` > 2000 AND CAST(`Total Freshwater Withdrawal` AS REAL) < 30 THEN 'Surprising contrast: high per-capita + low total — field trip candidate'
    WHEN CAST(`Total Freshwater Withdrawal` AS REAL) < 5 THEN 'Tiny total nation — intimate, low-footprint recording opportunity'
    ELSE NULL
  END AS `Actionable_Note`,
  CASE
    WHEN `Agricultural Use` >= 80 AND `Per Capita Withdrawal` >= 2000 THEN 1  -- top priority: expansive organic textures with strong per-capita presence
    WHEN `Agricultural Use` >= 80 THEN 2                                   -- agriculture-dominated
    WHEN `Industrial Use` >= 50 THEN 3                                      -- industrial-dominated
    WHEN (`Agricultural Use` - `Industrial Use`) >= 20 THEN 4               -- strong agricultural vs industrial contrast
    WHEN `Per Capita Withdrawal` > 2000 THEN 5                              -- high per-capita surprises
    ELSE 10
  END AS `Priority`
FROM `table_1_15909409_3`
ORDER BY `Priority` ASC, `PerCapitaWithdrawal` DESC, `Ag_minus_Ind` DESC;
","SELECT col0 AS `Country`,
  CAST(col1 AS REAL) AS `TotalWithdrawal`,
  col2 AS `PerCapitaWithdrawal`,
  col5,
  col4,
  col3,
  (col5 - col4) AS `Ag_minus_Ind`,
  CASE
    WHEN col5 >= 80 THEN 'Organic Drone / Irrigation Rhythms'
    WHEN col4 >= 50 THEN 'Metallic Percussion / Mechanical Textures'
    WHEN col3 >= 50 THEN 'Intimate Domestic / Human-scale Textures'
    WHEN col5 BETWEEN 20 AND 49 AND col4 BETWEEN 20 AND 49 THEN 'Mixed Textures (blend organic + industrial)'
    ELSE 'Balanced / Hybrid Textures'
  END AS `Primary_Texture`,
  CASE
    WHEN col2 > 5000 THEN 'Extremely high per-capita — prioritize intense human-scale recordings'
    WHEN col2 > 2000 AND CAST(col1 AS REAL) < 30 THEN 'Surprising contrast: high per-capita + low total — field trip candidate'
    WHEN CAST(col1 AS REAL) < 5 THEN 'Tiny total nation — intimate, low-footprint recording opportunity'
    ELSE NULL
  END AS `Actionable_Note`,
  CASE
    WHEN col5 >= 80 AND col2 >= 2000 THEN 1
    WHEN col5 >= 80 THEN 2
    WHEN col4 >= 50 THEN 3
    WHEN (col5 - col4) >= 20 THEN 4
    WHEN col2 > 2000 THEN 5
    ELSE 10
  END AS `Priority`
FROM `table_1_15909409_3`
ORDER BY `Priority` ASC, `PerCapitaWithdrawal` DESC, `Ag_minus_Ind` DESC;","[('turkmenistan', 24.65, 5104.0, 98.0, 1.0, 2.0, 97.0, 'Organic Drone / Irrigation Rhythms', 'Extremely high per-capita — prioritize intense human-scale recordings', 1), ('kazakhstan', 35.0, 2360.0, 82.0, 17.0, 2.0, 65.0, 'Organic Drone / Irrigation Rhythms', None, 1), ('uzbekistan', 58.34, 2194.0, 93.0, 2.0, 5.0, 91.0, 'Organic Drone / Irrigation Rhythms', None, 1), ('guyana', 1.64, 2187.0, 98.0, 1.0, 2.0, 97.0, 'Organic Drone / Irrigation Rhythms', 'Surprising contrast: high per-capita + low total — field trip candidate', 1), ('kyrgyzstan', 10.08, 1916.0, 94.0, 3.0, 3.0, 91.0, 'Organic Drone / Irrigation Rhythms', None, 2), ('tajikistan', 11.96, 1837.0, 92.0, 5.0, 4.0, 87.0, 'Organic Drone / Irrigation Rhythms', None, 2), ('suriname', 0.67, 1489.0, 93.0, 3.0, 4.0, 90.0, 'Organic Drone / Irrigation Rhythms', 'Tiny total nation — intimate, low-footprint recording opportunity', 2), ('iraq', 42.7, 1482.0, 92.0, 5.0, 3.0, 87.0, 'Organic Drone / Irrigation Rhythms', None, 2), ('thailand', 82.75, 1288.0, 95.0, 2.0, 2.0, 93.0, 'Organic Drone / Irrigation Rhythms', None, 2), ('ecuador', 16.98, 1283.0, 82.0, 5.0, 12.0, 77.0, 'Organic Drone / Irrigation Rhythms', None, 2), ('hungary', 21.03, 2082.0, 32.0, 59.0, 9.0, -27.0, 'Metallic Percussion / Mechanical Textures', 'Surprising contrast: high per-capita + low total — field trip candidate', 3), ('canada', 44.72, 1386.0, 12.0, 69.0, 20.0, -57.0, 'Metallic Percussion / Mechanical Textures', None, 3), ('azerbaijan', 17.25, 2051.0, 68.0, 28.0, 5.0, 40.0, 'Balanced / Hybrid Textures', 'Surprising contrast: high per-capita + low total — field trip candidate', 4), ('usa', 477.0, 1600.0, 41.0, 46.0, 13.0, -5.0, 'Mixed Textures (blend organic + industrial)', None, 10)]",table_1_15909409_3,"As an aural-hydrology composer I speak in textures and prioritize sites that will give me long, organic drones; I know basic terms like per-capita and agricultural share but won't use SQL jargon. The SQL selects countries, their total and per-capita withdrawals, sector shares, computes agricultural minus industrial, classifies a primary texture, adds actionable notes for extreme per-capita or tiny totals, and assigns a Priority rank. The schema maps to country, Total Freshwater Withdrawal, Per Capita Withdrawal, Agricultural Use, Industrial Use, and Domestic Use. Which countries are top-priority for expansive organic textures — where agriculture is overwhelmingly dominant (≥80%) and per-capita withdrawal is very high — so I can plan slow irrigation drones? I checked that the query flags those as top priority and annotates them with texture and actionable notes.",persona,"An aural-hydrology composer who creates immersive sound installations by translating national water-use signatures (per-capita withdrawal and sectoral splits) into layered soundscapes. Goals: Identify countries where agriculture overwhelmingly dominates freshwater withdrawal so I can design long, slow organic textures (e.g., sustained drones and irrigation rhythms). Find industrial-dominated or mixed-use countries to produce metallic, percussive sound elements and contrast them with agricultural textures. Locate surprising contrasts (very high per-capita withdrawal vs. low total withdrawal, or tiny total nations with unusual per-capita use) to craft intimate, human-scale domestic sound pieces and plan field recording trips. Example Queries: -- 1) Agriculture-dominated countries with high per-capita withdrawal (good for expansive, slow-field recordings)
    SELECT Country,
           CAST(""Total Freshwater Withdrawal"" AS REAL) AS TotalWithdrawal,
           ""Per Capita Withdrawal"",
           ""Agricultural Use""
    FROM table_1_15909409_3
    WHERE ""Agricultural Use"" >= 80
    ORDER BY ""Per Capita Withdrawal"" DESC; -- 2) Industrial-dominated countries to source metallic/percussive sound material
    SELECT Country,
           ""Industrial Use"",
           ""Domestic Use"",
           ""Per Capita Withdrawal""
    FROM table_1_15909409_3
    WHERE ""Industrial Use"" >= 50
    ORDER BY ""Per Capita Withdrawal"" ASC; -- 3) Compute sectoral dominance to find extreme contrasts (agriculture minus industry) for pairing textures
    SELECT Country,
           (""Agricultural Use"" - ""Industrial Use"") AS Ag_minus_Ind,
           ""Per Capita Withdrawal"",
           CAST(""Total Freshwater Withdrawal"" AS REAL) AS TotalWithdrawal
    FROM table_1_15909409_3
    ORDER BY Ag_minus_Ind DESC
    LIMIT 5;",reward,,
"From episodes with 'and' present in 'Who knows the most about the guest host? panelists', return up to 7 rows showing Episode Number, Air Date, Guest Host, the expression (LENGTH('Who knows the most about the guest host? panelists') - LENGTH(REPLACE('Who knows the most about the guest host? panelists', ',', '')) + 1) as Panelist Count, the expression (LENGTH('Musical Guest (Song performed)') - LENGTH(REPLACE('Musical Guest (Song performed)', '(', '')) - LENGTH(REPLACE('Musical Guest (Song performed)', ')', ''))) as ParenthesisChars, and the Guest Host again titled Billie Piper.","
SELECT `Episode Number`, `Air Date`, `Guest Host` `Guest Host`, (LENGTH(`Who knows the most about the guest host? panelists`) - LENGTH(REPLACE(`Who knows the most about the guest host? panelists`, ',', '')) + 1) `Panelist Count`, (LENGTH(`Musical Guest (Song performed)`) - LENGTH(REPLACE(`Musical Guest (Song performed)`, '(', '')) - LENGTH(REPLACE(`Musical Guest (Song performed)`, ')', ''))) `ParenthesisChars`, `Guest Host` `Billie Piper` FROM `table_1_1590967_2` WHERE instr(`Who knows the most about the guest host? panelists`, 'and') > 0 LIMIT 7;
","
SELECT col0, col1, col2 col2, (LENGTH(col4) - LENGTH(REPLACE(col4, ',', '')) + 1) `Panelist Count`, (LENGTH(col3) - LENGTH(REPLACE(col3, '(', '')) - LENGTH(REPLACE(col3, ')', ''))) `ParenthesisChars`, col2 `Billie Piper` FROM `table_1_1590967_2` WHERE instr(col4, 'and') > 0 LIMIT 7;
","[(1.0, '6 january 2006', 'billie piper', 1, -13, 'billie piper'), (2.0, '13 january 2006', 'lorraine kelly', 1, -16, 'lorraine kelly'), (3.0, '20 january 2006', 'christian slater', 1, -29, 'christian slater'), (4.0, '27 january 2006', 'denise van outen', 1, -25, 'denise van outen'), (5.0, '3 february 2006', 'michael barrymore', 1, -37, 'michael barrymore'), (6.0, '10 february 2006', 'jamie oliver', 1, -11, 'jamie oliver'), (7.0, '17 february 2006', 'jessie wallace', 1, -22, 'jessie wallace')]",table_1_1590967_2,"1) Parse SQL intent: select Episode Number, Air Date, Guest Host (twice with alias), compute panelist count via comma-based LENGTH/REPLACE formula, compute parenthesis-character expression from Musical Guest, filter rows where panelists contains 'and', and limit to 7 results. 2) Map schema: reference exact column names. 3) Draft question: combine all selections, calculations, filter and limit into one request. 4) Validate: ensure all columns, both calculations, the 'and' condition and the limit are explicitly included.",reserved,4,reward,,
"For episodes where the Musical Guest (Song performed) length exceeds 10 characters, what are the Episode Number, Air Date, Guest Host, Musical Guest (Song performed), Who knows the most about the guest host? panelists, and Coat Of Cash Wearing Celebrity, together with Song_length equal to LENGTH(Musical Guest (Song performed)), Panelists_and_pos equal to INSTR(Who knows the most about the guest host? panelists,' and '), Panelist_balance equal to LENGTH(Who knows the most about the guest host? panelists) minus that INSTR value, CoatHost_overlap equal to INSTR(Coat Of Cash Wearing Celebrity, Guest Host), and Actionable_score equal to ((2 * LENGTH(Musical Guest (Song performed))) + LENGTH(Who knows the most about the guest host? panelists) - (5 * INSTR(Who knows the most about the guest host? panelists,' and ')))?","
SELECT `Episode Number`, `Air Date`, `Guest Host`, `Musical Guest (Song performed)`, `Who knows the most about the guest host? panelists`, `Coat Of Cash Wearing Celebrity`, LENGTH(`Musical Guest (Song performed)`) `Song_length`, INSTR(`Who knows the most about the guest host? panelists`, ' and ') `Panelists_and_pos`, (LENGTH(`Who knows the most about the guest host? panelists`) - INSTR(`Who knows the most about the guest host? panelists`, ' and ')) `Panelist_balance`, INSTR(`Coat Of Cash Wearing Celebrity`, `Guest Host`) `CoatHost_overlap`, ((LENGTH(`Musical Guest (Song performed)`) * 2) + LENGTH(`Who knows the most about the guest host? panelists`) - (INSTR(`Who knows the most about the guest host? panelists`, ' and ') * 5)) `Actionable_score` FROM `table_1_1590967_4` WHERE LENGTH(`Musical Guest (Song performed)`) > 10;
","
SELECT col0, col1, col2, col3, col4, col5, LENGTH(col3) `Song_length`, INSTR(col4, ' and ') `Panelists_and_pos`, (LENGTH(col4) - INSTR(col4, ' and ')) `Panelist_balance`, INSTR(col5, col2) `CoatHost_overlap`, ((LENGTH(col3) * 2) + LENGTH(col4) - (INSTR(col4, ' and ') * 5)) `Actionable_score` FROM `table_1_1590967_4` WHERE LENGTH(col3) > 10;
","[(1.0, '5 january 2007', 'david tennant', ""amy winehouse ( you know i'm no good )"", 'amy winehouse and george galloway', 'lauren harries', 38, 14, 19, 0, 39), (2.0, '12 january 2007', 'tamzin outhwaite', 'just jack ( starz in their eyes )', 'kate thornton and tito jackson', 'bradley mcintosh', 33, 14, 16, 0, 26), (3.0, '19 january 2007', 'james nesbitt', 'mika ( grace kelly )', 'leo sayer and kirstie allsopp', 'shahbaz chauhdry', 20, 10, 19, 0, 19), (5.0, '2 february 2007', 'jamie oliver', 'klaxons ( golden skans )', 'jermaine jackson and nora sands', 'ian ""h"" watkins', 24, 17, 14, 0, -6), (6.0, '9 february 2007', 'steven seagal', 'ghosts ( stay the night )', 'gemma atkinson and jamelia', 'steven seagal', 25, 15, 11, 1, 1)]",table_1_1590967_4,"1) The SQL returns base columns for each qualifying row and computes multiple derived values including an Actionable_score based on lengths and the position of ' and '. 2) Map each computed field and the WHERE clause to natural language. 3) Formulate a direct question requesting all columns and each computed metric with the precise arithmetic: (LENGTH*2 + LENGTH(panelists) - INSTR(panelists,' and ')*5). 4) Ensure the question contains no additional information beyond the SQL.",reserved,3,reward,,
"List every episode row with episode number, ISO-formatted air date, guest host, musical guest split into performer and song, panelists, the coat-of-cash celebrity, a count of episodes for that performer, and a compact rights-reference string, sorted by air date.","
WITH parsed AS (
  SELECT
    `Episode Number`,
    `Air Date`,
    `Guest Host`,
    `Musical Guest (Song performed)` AS `MusicalFull`,
    `Who knows the most about the guest host? Panelists`,
    `Coat Of Cash Wearing Celebrity`,
    instr(`Musical Guest (Song performed)`, '(') AS pos_open,
    instr(`Musical Guest (Song performed)`, ')') AS pos_close,
    instr(`Air Date`, ' ') AS pos1,
    instr(substr(`Air Date`, instr(`Air Date`, ' ')+1), ' ') AS pos2_rel
  FROM `table_1_1590967_7`
)
SELECT
  `Episode Number`,
  `Air Date`,
  '`' || `Guest Host` || '`' AS `Guest Host`,
  '`' || TRIM(substr(`MusicalFull`, 1, pos_open - 1)) || '`' AS `Musical Performer`,
  '`' || TRIM(substr(`MusicalFull`, pos_open + 1, pos_close - pos_open - 1)) || '`' AS `Song Performed`,
  `Who knows the most about the guest host? Panelists`,
  `Coat Of Cash Wearing Celebrity`,
  printf(
    '%04d-%02d-%02d',
    CAST(TRIM(substr(`Air Date`, pos1 + pos2_rel + 1)) AS INTEGER),
    CASE TRIM(substr(`Air Date`, pos1 + 1, pos2_rel - 1))
      WHEN 'January' THEN 1 WHEN 'February' THEN 2 WHEN 'March' THEN 3 WHEN 'April' THEN 4
      WHEN 'May' THEN 5 WHEN 'June' THEN 6 WHEN 'July' THEN 7 WHEN 'August' THEN 8
      WHEN 'September' THEN 9 WHEN 'October' THEN 10 WHEN 'November' THEN 11 WHEN 'December' THEN 12
      ELSE 0 END,
    CAST(TRIM(substr(`Air Date`, 1, pos1 - 1)) AS INTEGER)
  ) AS `ISO Air Date`,
  COUNT(*) OVER (PARTITION BY TRIM(substr(`MusicalFull`, 1, pos_open - 1))) AS `Episodes by Musical Performer`,
  '`' || `Air Date` || '` - `' || TRIM(substr(`MusicalFull`, 1, pos_open - 1)) || '` performing `' || TRIM(substr(`MusicalFull`, pos_open + 1, pos_close - pos_open - 1)) || '`' AS `Music Rights Reference`
FROM parsed
ORDER BY `ISO Air Date`;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3 AS `MusicalFull`,
    col4,
    col5,
    instr(col3, '(') AS pos_open,
    instr(col3, ')') AS pos_close,
    instr(col1, ' ') AS pos1,
    instr(substr(col1, instr(col1, ' ')+1), ' ') AS pos2_rel
  FROM `table_1_1590967_7`
)
SELECT
  col0,
  col1,
  '`' || col2 || '`' AS col2,
  '`' || TRIM(substr(`MusicalFull`, 1, pos_open - 1)) || '`' AS `Musical Performer`,
  '`' || TRIM(substr(`MusicalFull`, pos_open + 1, pos_close - pos_open - 1)) || '`' AS `Song Performed`,
  col4,
  col5,
  printf(
    '%04d-%02d-%02d',
    CAST(TRIM(substr(col1, pos1 + pos2_rel + 1)) AS INTEGER),
    CASE TRIM(substr(col1, pos1 + 1, pos2_rel - 1))
      WHEN 'January' THEN 1 WHEN 'February' THEN 2 WHEN 'March' THEN 3 WHEN 'April' THEN 4
      WHEN 'May' THEN 5 WHEN 'June' THEN 6 WHEN 'July' THEN 7 WHEN 'August' THEN 8
      WHEN 'September' THEN 9 WHEN 'October' THEN 10 WHEN 'November' THEN 11 WHEN 'December' THEN 12
      ELSE 0 END,
    CAST(TRIM(substr(col1, 1, pos1 - 1)) AS INTEGER)
  ) AS `ISO Air Date`,
  COUNT(*) OVER (PARTITION BY TRIM(substr(`MusicalFull`, 1, pos_open - 1))) AS `Episodes by Musical Performer`,
  '`' || col1 || '` - `' || TRIM(substr(`MusicalFull`, 1, pos_open - 1)) || '` performing `' || TRIM(substr(`MusicalFull`, pos_open + 1, pos_close - pos_open - 1)) || '`' AS `Music Rights Reference`
FROM parsed
ORDER BY `ISO Air Date`;
","[(5.0, '6 july 2008', '`david hasselhoff`', '`the feeling`', '`turn it up`', 'scott mills and sally lindsay', 'sylvia barrie', '2008-00-06', 1, '`6 july 2008` - `the feeling` performing `turn it up`'), (1.0, '8 june 2008', '`katie price and peter andre`', '`the courteeners`', ""`no you didn't, no you don't`"", 'cerys matthews and michelle dewberry', 'andy abraham', '2008-00-08', 1, ""`8 june 2008` - `the courteeners` performing `no you didn't, no you don't`""), (6.0, '13 july 2008', '`barbara windsor`', '`the ting tings`', '`shut up and let me go`', 'patsy palmer and anna karen', 'jennifer clark', '2008-00-13', 1, '`13 july 2008` - `the ting tings` performing `shut up and let me go`'), (2.0, '15 june 2008', '`pamela anderson`', ""`five o'clock heroes feat. agyness deyn`"", '`who`', 'paul daniels and danny dyer', 'ricky whittle', '2008-00-15', 1, ""`15 june 2008` - `five o'clock heroes feat. agyness deyn` performing `who`""), (3.0, '22 june 2008', '`mark ronson`', '`n.e.r.d.`', '`everyone nose`', 'pharrell williams and miquita oliver', 'stephanie mcmichael', '2008-00-22', 1, '`22 june 2008` - `n.e.r.d.` performing `everyone nose`'), (4.0, '29 june 2008', '`ronan keating , stephen gately , and shane lynch`', '`estelle`', '`no substitute love`', 'lulu and estelle', 'carly stratton', '2008-00-29', 1, '`29 june 2008` - `estelle` performing `no substitute love`')]",table_1_1590967_7,"I would naturally ask for data formatted for rights clearance and cataloguing, using terms like performer, song and ISO date. The SQL parses the 'Musical Guest (Song performed)' field into performer and song, converts the textual air date into ISO format, and computes a per-performer episode count. It reads episode number, air date, guest host, panelists and the coat-of-cash celebrity too. Draft question: request rows with those parsed fields, the per-performer count and a rights reference. This matches the query's parsing, counting and ordering by ISO date.",persona,"Broadcast archive metadata manager at a television network who catalogs programme-level metadata and supports rights clearance. They would use this database to verify episode dates, guest hosts, musical performances and credited panelists for cataloguing, licensing and program guides. Goals: Extract complete episode metadata (air date, guest host, musical guest and song, panelists, special credited celebrities) to populate the archive catalogue. Identify musical performances and performers with air dates to support music-rights clearance and licensing requests. Quickly find episodes featuring a specific guest host or panelist for re-runs, clip selection, or promotional materials. Example Queries: SELECT [Episode Number], [Air Date], [Guest Host], [Musical Guest (Song performed)], [Who knows the most about the guest host? Panelists], [Coat Of Cash Wearing Celebrity]
FROM table_1_1590967_7
WHERE [Air Date] LIKE '%June 2008%' OR [Air Date] LIKE '%July 2008%'; SELECT [Episode Number], [Air Date], [Guest Host], [Musical Guest (Song performed)]
FROM table_1_1590967_7
WHERE [Who knows the most about the guest host? Panelists] LIKE '%Patsy Palmer%'; SELECT [Guest Host], COUNT(*) AS episode_count, GROUP_CONCAT([Coat Of Cash Wearing Celebrity], ', ') AS coat_of_cash_celebrities
FROM table_1_1590967_7
GROUP BY [Guest Host]
ORDER BY episode_count DESC;",reward,,
"For each distinct Country with Seasons > 1, what is the COUNT(t.Seasons) as 'Seasons Above Peers' produced by joining the table to itself on t.Seasons > s.Seasons AND s.Seasons >= 1, while also returning two empty-string columns named 'Project Runway Canada' and 'Project Runway Malaysia', grouping by Country, keeping only groups where that COUNT(t.Seasons) > 0, and limiting the result to 10 rows?","
SELECT DISTINCT t.`Country`, COUNT(t.`Seasons`) `Seasons Above Peers`, '' `Project Runway Canada`, '' `Project Runway Malaysia`
FROM `table_1_1597866_3` t
JOIN `table_1_1597866_3` s
ON t.`Seasons` > s.`Seasons` AND s.`Seasons` >= 1
WHERE t.`Seasons` > 1
GROUP BY t.`Country`
HAVING COUNT(t.`Seasons`) > 0
LIMIT 10;
","
SELECT DISTINCT t.col0, COUNT(t.col6) `Seasons Above Peers`, '' `Project Runway Canada`, '' `Project Runway Malaysia`
FROM `table_1_1597866_3` t
JOIN `table_1_1597866_3` s
ON t.col6 > s.col6 AND s.col6 >= 1
WHERE t.col6 > 1
GROUP BY t.col0
HAVING COUNT(t.col6) > 0
LIMIT 10;
","[('arab world', 4, '', ''), ('canada', 4, '', ''), ('south korea', 6, '', '')]",table_1_1597866_3,"1) Parse SQL intent: count, per country, how many rows have fewer Seasons than that country's Seasons (t.Seasons > s.Seasons) with s.Seasons >= 1, only for countries with t.Seasons > 1, returning groups with count > 0 and limiting to 10. 2) Map schema: use Country and Seasons columns from the table; COUNT(t.Seasons) is aliased as 'Seasons Above Peers'; include two empty-string columns named 'Project Runway Canada' and 'Project Runway Malaysia'. 3) Draft question: ask for distinct Country, the COUNT as 'Seasons Above Peers', two empty-string columns, group and filter as in SQL, limit 10. 4) Validate: the question mentions the join condition, s.Seasons constraint, t.Seasons filter, grouping, having, and limit.",reserved,11,reward,,
"Group member states (excluding the 'European Union') whose GDP per capita in PPP US$ (2012) is between 20000 and 45000 into Fiscal Risk = 'High fiscal stress' if Public Debt % of GDP (2013 Q1) > 100 else 'Lower stress', and for each group report the number of Members, the average GDP per capita in PPP US$ (2012) rounded to the nearest whole number, and the average Public Debt % of GDP (2013 Q1) rounded to one decimal place, but only show groups with more than one member?","
SELECT
  CASE WHEN `Public Debt % of GDP (2013 Q1)` > 100 THEN '`High fiscal stress`' ELSE '`Lower stress`' END AS `Fiscal Risk`,
  COUNT(*) `Members`,
  ROUND(AVG(`GDP per capita in PPP US$ (2012)`),0) `Avg GDPpc`,
  ROUND(AVG(`Public Debt % of GDP (2013 Q1)`),1) `Avg Debt`
FROM `table_1_1598533_8`
JOIN `table_1_1598533_8` ON 1=1
WHERE `Member State sorted by GDP` <> '`European Union`' AND `GDP per capita in PPP US$ (2012)` BETWEEN 20000 AND 45000
GROUP BY `Fiscal Risk`
HAVING COUNT(*) > 1;
","SELECT
  CASE WHEN col5 > 100 THEN 'High fiscal stress' ELSE 'Lower stress' END AS `Fiscal Risk`,
  COUNT(*) AS `Members`,
  ROUND(AVG(col4),0) AS `Avg GDPpc`,
  ROUND(AVG(col5),1) AS `Avg Debt`
FROM `table_1_1598533_8`
WHERE col0 <> 'European Union' AND col4 BETWEEN 20000 AND 45000
GROUP BY `Fiscal Risk`
HAVING COUNT(*) > 1;","[('High fiscal stress', 21, 32414.0, 81.4)]",table_1_1598533_8,"Parse SQL intent: create two groups by Public Debt % of GDP (2013 Q1) > 100 and compute counts and rounded averages only for countries with GDP per capita between 20000 and 45000 excluding 'European Union'. Map schema semantics: use the specified column names and rounding: ROUND(AVG(GDP per capita in PPP US$ (2012)),0) and ROUND(AVG(Public Debt % of GDP (2013 Q1)),1); require COUNT(*) > 1. Draft and validate the question to include all these elements.",reserved,16,reward,,
"For episodes whose Viewers (in millions) exceed the overall average viewers (avg_v) and whose Run time converted to seconds ((minutes before ':' * 60) + seconds after ':') exceed the overall average run time in seconds (avg_s), what are the Episode, Broadcast date, Run time, Viewers (in millions), Archive, and pct_above_avg defined as (Viewers (in millions)) / avg_v - 1, ordered by Viewers (in millions) descending and limited to 5 rows?","
WITH `overall`(`avg_v`,`avg_s`) AS (
  SELECT AVG(`Viewers (in millions)`+0), AVG((substr(`Run time`,1,instr(`Run time`,':')-1)+0)*60 + (substr(`Run time`,instr(`Run time`,':')+1)+0))
  FROM `table_1_1601935_1`
)
SELECT `Episode`,`Broadcast date`,`Run time`,`Viewers (in millions)`,`Archive`,
       (`Viewers (in millions)`+0)/`avg_v`-1 `pct_above_avg`
FROM `table_1_1601935_1`,`overall`
WHERE (`Viewers (in millions)`+0) > `avg_v`
AND ((substr(`Run time`,1,instr(`Run time`,':')-1)+0)*60 + (substr(`Run time`,instr(`Run time`,':')+1)+0)) > `avg_s`
ORDER BY `Viewers (in millions)`+0 DESC
LIMIT 5;
","WITH `overall`(`avg_v`,`avg_s`) AS (
  SELECT AVG(col3+0), AVG((substr(col2,1,instr(col2,':')-1)+0)*60 + (substr(col2,instr(col2,':')+1)+0))
  FROM `table_1_1601935_1`
)
SELECT col0, col1, col2, col3, col4,
       ((col3+0)/`avg_v` - 1) AS `pct_above_avg`
FROM `table_1_1601935_1`, `overall`
WHERE ((col3+0) > `avg_v`)
   OR (((substr(col2,1,instr(col2,':')-1)+0)*60 + (substr(col2,instr(col2,':')+1)+0)) > `avg_s`)
   AND 1=1
ORDER BY (col3+0) DESC
LIMIT 5;","[('"" episode 4 ""', '5october1968', '19:14', '7.3', '16mm t/r', 0.06413994169096227), ('"" episode 3 ""', '28september1968', '19:29', '7.2', '16mm t/r', 0.04956268221574356), ('"" episode 1 ""', '14september1968', '21:27', '6.6', '16mm t/r', -0.03790087463556846), ('"" episode 2 ""', '21september1968', '21:39', '6.5', '16mm t/r', -0.052478134110787056)]",table_1_1601935_1,"1) Parse: the query builds overall averages and selects rows exceeding both averages, computing a percent above average. 2) Schema mapping: include Episode, Broadcast date, Run time, Viewers (in millions), Archive, and pct_above_avg = (Viewers)/avg_v - 1; avg_s is AVG(run time in seconds). 3) Draft: ask for those fields for episodes where Viewers > avg_v and run time (converted to seconds) > avg_s, sorted by viewers desc, limit 5. 4) Validate that conversion method for Run time and arithmetic for pct_above_avg are stated.",reserved,11,reward,,
"Give me a consolidated report of all K.J. Choi's PGA Tour wins listing date, tournament, winning score, to‑par, margin and runner(s)-up, and also highlight his largest and closest margin wins, his average winning to‑par, year-by-year win totals, plus any wins at tournaments named 'Chrysler'.","
SELECT 'Win' AS `ReportSection`,
       `Date`,
       `Tournament`,
       `Winning score`,
       `To par`,
       `Margin of victory`,
       CAST(REPLACE(REPLACE(`Margin of victory`, ' strokes', ''), ' stroke', '') AS INTEGER) AS `Margin_strokes`,
       REPLACE(`To par`, '−', '-') AS `To_par_normalized`,
       SUBSTR(`Date`, LENGTH(`Date`) - 3, 4) AS `Year`,
       `Runner(s)-up` AS `Notes`
FROM `table_1_1602858_1`
UNION ALL
SELECT 'Largest margin' AS `ReportSection`,
       `Date`,
       `Tournament`,
       `Winning score`,
       `To par`,
       `Margin of victory`,
       CAST(REPLACE(REPLACE(`Margin of victory`, ' strokes', ''), ' stroke', '') AS INTEGER) AS `Margin_strokes`,
       REPLACE(`To par`, '−', '-') AS `To_par_normalized`,
       SUBSTR(`Date`, LENGTH(`Date`) - 3, 4) AS `Year`,
       `Runner(s)-up` AS `Notes`
FROM `table_1_1602858_1`
WHERE CAST(REPLACE(REPLACE(`Margin of victory`, ' strokes', ''), ' stroke', '') AS INTEGER) = (
    SELECT MAX(CAST(REPLACE(REPLACE(`Margin of victory`, ' strokes', ''), ' stroke', '') AS INTEGER))
    FROM `table_1_1602858_1`
)
UNION ALL
SELECT 'Closest margin' AS `ReportSection`,
       `Date`,
       `Tournament`,
       `Winning score`,
       `To par`,
       `Margin of victory`,
       CAST(REPLACE(REPLACE(`Margin of victory`, ' strokes', ''), ' stroke', '') AS INTEGER) AS `Margin_strokes`,
       REPLACE(`To par`, '−', '-') AS `To_par_normalized`,
       SUBSTR(`Date`, LENGTH(`Date`) - 3, 4) AS `Year`,
       `Runner(s)-up` AS `Notes`
FROM `table_1_1602858_1`
WHERE CAST(REPLACE(REPLACE(`Margin of victory`, ' strokes', ''), ' stroke', '') AS INTEGER) = (
    SELECT MIN(CAST(REPLACE(REPLACE(`Margin of victory`, ' strokes', ''), ' stroke', '') AS INTEGER))
    FROM `table_1_1602858_1`
)
UNION ALL
SELECT 'Average To par' AS `ReportSection`,
       NULL AS `Date`,
       NULL AS `Tournament`,
       NULL AS `Winning score`,
       CAST(AVG(CAST(REPLACE(`To par`, '−', '-') AS INTEGER)) AS TEXT) AS `To par`,
       NULL AS `Margin of victory`,
       NULL AS `Margin_strokes`,
       NULL AS `To_par_normalized`,
       NULL AS `Year`,
       NULL AS `Notes`
FROM `table_1_1602858_1`
UNION ALL
SELECT 'Yearly wins' AS `ReportSection`,
       NULL AS `Date`,
       NULL AS `Tournament`,
       NULL AS `Winning score`,
       NULL AS `To par`,
       NULL AS `Margin of victory`,
       NULL AS `Margin_strokes`,
       NULL AS `To_par_normalized`,
       SUBSTR(`Date`, LENGTH(`Date`) - 3, 4) AS `Year`,
       CAST(COUNT(*) AS TEXT) AS `Notes`
FROM `table_1_1602858_1`
GROUP BY SUBSTR(`Date`, LENGTH(`Date`) - 3, 4)
UNION ALL
SELECT 'Sponsor pattern - `Chrysler`' AS `ReportSection`,
       `Date`,
       `Tournament`,
       `Winning score`,
       `To par`,
       `Margin of victory`,
       CAST(REPLACE(REPLACE(`Margin of victory`, ' strokes', ''), ' stroke', '') AS INTEGER) AS `Margin_strokes`,
       REPLACE(`To par`, '−', '-') AS `To_par_normalized`,
       SUBSTR(`Date`, LENGTH(`Date`) - 3, 4) AS `Year`,
       `Runner(s)-up` AS `Notes`
FROM `table_1_1602858_1`
WHERE `Tournament` LIKE '%Chrysler%'
ORDER BY `Year` ASC;
","
SELECT 'Win' AS `ReportSection`,
       col1,
       col2,
       col3,
       col4,
       col5,
       CAST(REPLACE(REPLACE(col5, ' strokes', ''), ' stroke', '') AS INTEGER) AS `Margin_strokes`,
       REPLACE(col4, '−', '-') AS `To_par_normalized`,
       SUBSTR(col1, LENGTH(col1) - 3, 4) AS `Year`,
       col6 AS `Notes`
FROM `table_1_1602858_1`
UNION ALL
SELECT 'Largest margin' AS `ReportSection`,
       col1,
       col2,
       col3,
       col4,
       col5,
       CAST(REPLACE(REPLACE(col5, ' strokes', ''), ' stroke', '') AS INTEGER) AS `Margin_strokes`,
       REPLACE(col4, '−', '-') AS `To_par_normalized`,
       SUBSTR(col1, LENGTH(col1) - 3, 4) AS `Year`,
       col6 AS `Notes`
FROM `table_1_1602858_1`
WHERE CAST(REPLACE(REPLACE(col5, ' strokes', ''), ' stroke', '') AS INTEGER) = (
    SELECT MAX(CAST(REPLACE(REPLACE(col5, ' strokes', ''), ' stroke', '') AS INTEGER))
    FROM `table_1_1602858_1`
)
UNION ALL
SELECT 'Closest margin' AS `ReportSection`,
       col1,
       col2,
       col3,
       col4,
       col5,
       CAST(REPLACE(REPLACE(col5, ' strokes', ''), ' stroke', '') AS INTEGER) AS `Margin_strokes`,
       REPLACE(col4, '−', '-') AS `To_par_normalized`,
       SUBSTR(col1, LENGTH(col1) - 3, 4) AS `Year`,
       col6 AS `Notes`
FROM `table_1_1602858_1`
WHERE CAST(REPLACE(REPLACE(col5, ' strokes', ''), ' stroke', '') AS INTEGER) = (
    SELECT MIN(CAST(REPLACE(REPLACE(col5, ' strokes', ''), ' stroke', '') AS INTEGER))
    FROM `table_1_1602858_1`
)
UNION ALL
SELECT 'Average To par' AS `ReportSection`,
       NULL AS col1,
       NULL AS col2,
       NULL AS col3,
       CAST(AVG(CAST(REPLACE(col4, '−', '-') AS INTEGER)) AS TEXT) AS col4,
       NULL AS col5,
       NULL AS `Margin_strokes`,
       NULL AS `To_par_normalized`,
       NULL AS `Year`,
       NULL AS `Notes`
FROM `table_1_1602858_1`
UNION ALL
SELECT 'Yearly wins' AS `ReportSection`,
       NULL AS col1,
       NULL AS col2,
       NULL AS col3,
       NULL AS col4,
       NULL AS col5,
       NULL AS `Margin_strokes`,
       NULL AS `To_par_normalized`,
       SUBSTR(col1, LENGTH(col1) - 3, 4) AS `Year`,
       CAST(COUNT(*) AS TEXT) AS `Notes`
FROM `table_1_1602858_1`
GROUP BY SUBSTR(col1, LENGTH(col1) - 3, 4)
UNION ALL
SELECT 'Sponsor pattern - `Chrysler`' AS `ReportSection`,
       col1,
       col2,
       col3,
       col4,
       col5,
       CAST(REPLACE(REPLACE(col5, ' strokes', ''), ' stroke', '') AS INTEGER) AS `Margin_strokes`,
       REPLACE(col4, '−', '-') AS `To_par_normalized`,
       SUBSTR(col1, LENGTH(col1) - 3, 4) AS `Year`,
       col6 AS `Notes`
FROM `table_1_1602858_1`
WHERE col2 LIKE '%Chrysler%'
ORDER BY `Year` ASC;
","[('Average To par', None, None, None, '-15.5714285714286', None, None, None, None, None), ('Win', '5 may 2002', 'compaq classic of new orleans', '68-65-71-67=271', '−17', '4 strokes', 4, '-17', '2002', 'dudley hart , geoff ogilvy'), ('Win', '22 sep 2002', 'tampa bay classic', '63-68-68-68=267', '−17', '7 strokes', 7, '-17', '2002', 'glen day'), ('Largest margin', '22 sep 2002', 'tampa bay classic', '63-68-68-68=267', '−17', '7 strokes', 7, '-17', '2002', 'glen day'), ('Yearly wins', None, None, None, None, None, None, None, '2002', '2'), ('Win', '2 oct 2005', 'chrysler classic of greensboro', '64-69-67-66=266', '−22', '2 strokes', 2, '-22', '2005', 'shigeki maruyama'), ('Yearly wins', None, None, None, None, None, None, None, '2005', '1'), ('Sponsor pattern - `Chrysler`', '2 oct 2005', 'chrysler classic of greensboro', '64-69-67-66=266', '−22', '2 strokes', 2, '-22', '2005', 'shigeki maruyama'), ('Win', '29 oct 2006', 'chrysler championship', '68-66-70-67=271', '−13', '4 strokes', 4, '-13', '2006', 'paul goydos , brett wetterich'), ('Yearly wins', None, None, None, None, None, None, None, '2006', '1'), ('Sponsor pattern - `Chrysler`', '29 oct 2006', 'chrysler championship', '68-66-70-67=271', '−13', '4 strokes', 4, '-13', '2006', 'paul goydos , brett wetterich'), ('Win', '3 jun 2007', 'memorial tournament', '69-70-67-65=271', '−17', '1 stroke', 1, '-17', '2007', 'ryan moore'), ('Win', '8 jul 2007', 'at&t national', '66-67-70-68=271', '−9', '3 strokes', 3, '-9', '2007', 'steve stricker'), ('Closest margin', '3 jun 2007', 'memorial tournament', '69-70-67-65=271', '−17', '1 stroke', 1, '-17', '2007', 'ryan moore'), ('Yearly wins', None, None, None, None, None, None, None, '2007', '2'), ('Win', '13 jan 2008', 'sony open in hawaii', '64-65-66-71=266', '−14', '3 strokes', 3, '-14', '2008', 'rory sabbatini'), ('Yearly wins', None, None, None, None, None, None, None, '2008', '1')]",table_1_1602858_1,"As a golf data analyst I'd use jargon like to‑par, margin and year-by-year; I'm familiar with sponsor names like 'Chrysler' in tournament titles. The SQL builds a consolidated report: it returns every win row and then appends rows for largest and closest margins, average to‑par, yearly win counts, and filters wins with 'Chrysler' in the tournament name. The table columns map to Date, Tournament, Winning score, To par, Margin of victory and Runner(s)-up, with Year extracted from the Date. Draft question: Give me a consolidated report of all K.J. Choi's PGA Tour wins listing date, tournament, winning score, to‑par, margin and runner(s)-up, and also highlight his largest and closest margin wins, his average winning to‑par, year-by-year win totals, plus any wins at tournaments named 'Chrysler'. Validation: This asks exactly for the full set of rows and summary rows the query produces.",persona,"Sports data analyst at a golf media outlet who prepares player profiles, infographics and trend pieces; uses this database to extract K.J. Choi's PGA Tour win details for articles and visualizations. Goals: Summarize all of K.J. Choi's PGA Tour wins and key stats (dates, tournaments, scores, margins). Identify his largest and closest victories and quantify typical winning 'to-par' performance. Produce year-by-year win counts and highlight notable tournaments or repeat patterns for editorial graphics. Example Queries: -- 1) Find the single win with the largest margin of victory (normalize 'strokes' text to integer) SELECT ""Tournament"", ""Date"", ""Margin of victory""
FROM table_1_1602858_1
ORDER BY CAST(REPLACE(REPLACE(""Margin of victory"", ' strokes', ''), ' stroke', '') AS INTEGER) DESC
LIMIT 1; -- 2) Compute the average 'To par' across all wins (normalize Unicode minus to ASCII minus then cast) SELECT AVG(CAST(REPLACE(""To par"", '−', '-') AS INTEGER)) AS avg_to_par
FROM table_1_1602858_1; -- 3) Count wins per year (extract year from the 'Date' text) for a year-by-year summary SELECT SUBSTR(""Date"", LENGTH(""Date"") - 3, 4) AS year, COUNT(*) AS wins
FROM table_1_1602858_1
GROUP BY year
ORDER BY year;",reward,,
"What are the Country, COUNT(*), and GROUP_CONCAT(RR Romaja, '; ') values for each Country when grouped by Country and ordered by COUNT(*) DESC?","
SELECT `Country` AS `Country`, COUNT(*) , GROUP_CONCAT(`RR Romaja`, '; ') FROM `table_1_160510_5` WHERE 1=1 AND 1=1 GROUP BY `Country` ORDER BY COUNT(*) DESC;
","
SELECT col8 AS col8, COUNT(*) , GROUP_CONCAT(col0, '; ') FROM `table_1_160510_5` WHERE 1=1 AND 1=1 GROUP BY col8 ORDER BY COUNT(*) DESC;
","[('south korea', 9, 'chungcheongbuk; chungcheongnam; gangwon; gyeonggi; gyeongsangbuk; gyeongsangnam; jeju; jeollabuk; jeollanam'), ('north korea', 8, 'gangwon; hamgyeongbuk; hamgyeongnam; hwanghaebuk; hwanghaenam; jagang; pyeonganbuk; pyeongannam')]",table_1_160510_5,"1) The SQL selects Country, counts rows, concatenates RR Romaja with '; ', groups by Country, and sorts by count descending. 2) RR Romaja are the province romanizations and Country is the country label in the dataset. 3) Formulate a question asking explicitly for Country, COUNT(*), and GROUP_CONCAT(RR Romaja, '; ') with GROUP BY Country and ORDER BY COUNT(*) DESC. 4) This captures all calculations and ordering present in the query.",reserved,9,reward,,
"Using Channel, Station, Network, Video Frequency and Audio Frequency, convert Video Frequency and Audio Frequency by removing '- MHz' and spaces and treating the results as numbers as Video_freq and Audio_freq, compute Gap as (Audio_freq - Video_freq) and compute OverallAvg as the average Gap across the table; then (1) for each Network excluding '`MPB`' return Network, COUNT(Station) as Stations, AVG(Gap) as AvgGap and MAX(Gap) as MaxGap for networks having COUNT(Station) > 1 (limit 10), UNION (2) return DISTINCT Station, Network, Gap and Video_freq for rows where Gap > OverallAvg AND Status = '`Commercial`' (limit 5)?","
WITH freqs AS (
  SELECT
    `Channel`,
    `Station`,
    `Network`,
    (REPLACE(REPLACE(`Video Frequency`, '- MHz', ''), ' ', '') + 0) `Video_freq`,
    (REPLACE(REPLACE(`Audio Frequency`, '- MHz', ''), ' ', '') + 0) `Audio_freq`,
    ((REPLACE(REPLACE(`Audio Frequency`, '- MHz', ''), ' ', '') + 0) - (REPLACE(REPLACE(`Video Frequency`, '- MHz', ''), ' ', '') + 0)) `Gap`
  FROM `table_1_160728_4`
),
stats AS (
  SELECT AVG(((REPLACE(REPLACE(`Audio Frequency`, '- MHz', ''), ' ', '') + 0) - (REPLACE(REPLACE(`Video Frequency`, '- MHz', ''), ' ', '') + 0))) `OverallAvg`
  FROM `table_1_160728_4`
)
SELECT `Network`, COUNT(`Station`) `Stations`, AVG(`Gap`) `AvgGap`, MAX(`Gap`) `MaxGap`
FROM freqs, stats
WHERE `Network` <> '`MPB`'
GROUP BY `Network`
HAVING COUNT(`Station`) > 1
LIMIT 10
UNION
SELECT DISTINCT `Station`, `Network`, `Gap`, `Video_freq`
FROM freqs
WHERE `Gap` > `OverallAvg` AND `Status` = '`Commercial`'
LIMIT 5;
","WITH freqs AS (
  SELECT
    col0,
    col4,
    col5,
    col8,
    (REPLACE(REPLACE(col2, '- MHz', ''), ' ', '') + 0) AS `Video_freq`,
    (REPLACE(REPLACE(col3, '- MHz', ''), ' ', '') + 0) AS `Audio_freq`,
    ((REPLACE(REPLACE(col3, '- MHz', ''), ' ', '') + 0) - (REPLACE(REPLACE(col2, '- MHz', ''), ' ', '') + 0)) AS `Gap`
  FROM `table_1_160728_4`
),
stats AS (
  SELECT AVG(((REPLACE(REPLACE(col3, '- MHz', ''), ' ', '') + 0) - (REPLACE(REPLACE(col2, '- MHz', ''), ' ', '') + 0))) AS `OverallAvg`
  FROM `table_1_160728_4`
)
SELECT col5, COUNT(col4) AS `Stations`, AVG(`Gap`) AS `AvgGap`, MAX(`Gap`) AS `MaxGap`
FROM freqs, stats
WHERE col5 <> 'MPB' AND col5 IS NOT NULL
GROUP BY col5
HAVING COUNT(col4) > 1
UNION
SELECT DISTINCT col4, col5, `Gap`, `Video_freq`
FROM freqs, stats
WHERE `Gap` > `OverallAvg` AND col8 = 'Commercial'
ORDER BY col5 DESC
LIMIT 10;","[('rtm', 2, 5.5, 5.5), ('mpb', 4, 5.5, 5.5)]",table_1_160728_4,"Parse intent: compute numeric Video_freq and Audio_freq from the Video Frequency and Audio Frequency text, compute Gap = Audio_freq - Video_freq, get overall average Gap, then produce a grouped Network summary excluding '`MPB`' and a second set of distinct commercial stations whose Gap exceeds the overall average. Map schema: Video Frequency and Audio Frequency are strings like '189.250- MHz' that must have '- MHz' and spaces removed and be cast to numbers; use Station, Network, Status and Channel as available. Draft: request both the grouped aggregated Network metrics and the distinct station rows with the specified filters, aliases and limits. Validate: ensure the question mentions Channel, Station, Network, Video_freq, Audio_freq, Gap, OverallAvg, the exclusion '`MPB`', Status '`Commercial`', aliases Stations/AvgGap/MaxGap, GROUP/HAVING, DISTINCT and the two LIMITs.",reserved,19,reward,,
"For every Primary conference, what are the Primary conference name, the count of Institution as Institutions, the SUM(Enrollment) as Total Enrollment, the ROUND of AVG(Enrollment) as Avg Enrollment, and the explicit zeros 0 for Central Washington University, 0 for College of Idaho, 0 for Gonzaga University, 0 for Pacific Lutheran University, 0 for University of Portland, 0 for University of Puget Sound, 0 for Southern Oregon University, 0 for Western Oregon University, and 0 for Western Washington University?","
SELECT `Primary conference`, COUNT(`Institution`) `Institutions`, SUM(`Enrollment`) `Total Enrollment`, ROUND(AVG(`Enrollment`)) `Avg Enrollment`, 0 `Central Washington University`, 0 `College of Idaho`, 0 `Gonzaga University`, 0 `Pacific Lutheran University`, 0 `University of Portland`, 0 `University of Puget Sound`, 0 `Southern Oregon University`, 0 `Western Oregon University`, 0 `Western Washington University`
FROM `table_1_16078390_2`
WHERE 1=1
GROUP BY `Primary conference`;
","
SELECT col6, COUNT(col0) `Institutions`, SUM(col4) `Total Enrollment`, ROUND(AVG(col4)) `Avg Enrollment`, 0 `Central Washington University`, 0 `College of Idaho`, 0 `Gonzaga University`, 0 `Pacific Lutheran University`, 0 `University of Portland`, 0 `University of Puget Sound`, 0 `Southern Oregon University`, 0 `Western Oregon University`, 0 `Western Washington University`
FROM `table_1_16078390_2`
WHERE 1=1
GROUP BY col6;
","[('cascade ( naia )', 2, 5610.0, 2805.0, 0, 0, 0, 0, 0, 0, 0, 0, 0), ('gnac ( division ii )', 3, 30629.0, 10210.0, 0, 0, 0, 0, 0, 0, 0, 0, 0), ('nwc ( division iii )', 2, 6269.0, 3135.0, 0, 0, 0, 0, 0, 0, 0, 0, 0), ('wcc ( division i )', 2, 10809.0, 5405.0, 0, 0, 0, 0, 0, 0, 0, 0, 0)]",table_1_16078390_2,"1) The query selects Primary conference and computes COUNT(Institution), SUM(Enrollment), ROUND(AVG(Enrollment)), plus nine constant zero columns for each institution, grouping by Primary conference. 2) Map these operations to the table columns Primary conference, Institution, and Enrollment. 3) Create a question that requests exactly those aggregate values and the zero placeholders for each listed institution for every Primary conference. 4) Ensure the question contains all column names, aggregate functions, the rounding, and the zero-valued institution columns.",reserved,5,reward,,
"List the `Directed by` value, COUNT(*) AS EpisodeCount, and SUM(Originalairdate LIKE '%2008') AS Episodes2008 for directors with `No. in season` > 0 and `Directed by` <> '', grouping by `Directed by`, ordering by Episodes2008 (ascending) and returning only the first 3 results?","
SELECT `Directed by`, COUNT(*) `EpisodeCount`, SUM(`Originalairdate` LIKE '%2008') AS `Episodes2008`
FROM `table_1_16090262_1`
WHERE `No. in season` > 0 AND `Directed by` <> ''
GROUP BY `Directed by`
ORDER BY `Episodes2008`
LIMIT 3;
","
SELECT col3, COUNT(*) `EpisodeCount`, SUM(col5 LIKE '%2008') AS `Episodes2008`
FROM `table_1_16090262_1`
WHERE col1 > 0 AND col3 <> ''
GROUP BY col3
ORDER BY `Episodes2008`
LIMIT 3;
","[('roy burdine', 13, 11)]",table_1_16090262_1,"1) Parse intent: aggregate episodes per director and count those with Originalairdate in 2008, applying filters and returning three rows ordered by the 2008 count. 2) Map schema: use `Directed by`, `No. in season`, and `Originalairdate` to compute COUNT(*) AS EpisodeCount and SUM(Originalairdate LIKE '%2008') AS Episodes2008 grouped by `Directed by`. 3) Draft: form a question asking for the director name, EpisodeCount, and Episodes2008 with the WHERE, GROUP BY, ORDER BY Episodes2008, and LIMIT 3 constraints. 4) Validate: confirms all SQL elements are present in the question.",reserved,12,reward,,
"Which Vehicle and corresponding national_g/mi (defined by casting as INTEGER the substring of 'U.S. national average electric mix' from the first character up to the first space) ranks highest when ordering by national_g/mi in descending order, considering only rows where Vehicle is not empty and returning the top result?","
SELECT t1.`Vehicle`, CAST(substr(t1.`U.S. national average electric mix`,1,instr(t1.`U.S. national average electric mix`,' ')-1) AS INTEGER) `national_g/mi`
FROM `table_1_16105186_2` t1 JOIN `table_1_16105186_2` t2 ON 1=1
WHERE 1=1 AND t1.`Vehicle` <> ''
ORDER BY `national_g/mi` DESC LIMIT 1;
","
SELECT t1.col0, CAST(substr(t1.col6,1,instr(t1.col6,' ')-1) AS INTEGER) `national_g/mi`
FROM `table_1_16105186_2` t1 JOIN `table_1_16105186_2` t2 ON 1=1
WHERE 1=1 AND t1.col0 <> ''
ORDER BY `national_g/mi` DESC LIMIT 1;
","[('chevrolet volt', 260)]",table_1_16105186_2,"1) The intent is to compute an integer national_g/mi from the 'U.S. national average electric mix' by taking characters before the first space and casting to INTEGER, then pick the max Vehicle. 2) Map this to the Vehicle column and the computed national_g/mi derived from substr(...,1,instr(...,' ')-1). 3) Draft a concise question asking for the Vehicle and the integer national_g/mi computed by that exact substring-and-cast procedure, excluding empty Vehicle values and returning the top-ranked row. 4) Validate that the question requests the single Vehicle with the largest computed national_g/mi and includes the calculation details.",reserved,11,reward,,
"For each genre, which titles are included and how many are multiplayer-capable?","
SELECT `Genre`, COUNT(*) total_games, GROUP_CONCAT(`Western Title`, '; ') titles, COUNT(*) multiplayer_capable
FROM `table_1_1616608_2`
WHERE `Western Title` != '`Polarium`' AND `Released Date` != '`2005`'
GROUP BY `Genre`
ORDER BY total_games
LIMIT 5;
","
SELECT col4, COUNT(*) total_games, GROUP_CONCAT(col0, '; ') titles, COUNT(*) multiplayer_capable
FROM `table_1_1616608_2`
WHERE col0 != '`Polarium`' AND col3 != '`2005`'
GROUP BY col4
ORDER BY total_games
LIMIT 5;
","[('puzzle', 1, 'polarium', 1), ('platform', 4, 'nintendogs; new super mario bros.; super mario 64 ds; yoshi touch & go', 4)]",table_1_1616608_2,"STEP 1: Parse the SQL intent: group rows by Genre (excluding the row with Western Title 'Polarium' and Released Date '2005'), return Genre, total number of rows per genre (COUNT(*) as total_games), a concatenated list of Western Title values per genre, and an additional COUNT(*) column aliased multiplayer_capable (which in this SQL is identical to total_games). Results are ordered by total_games (ascending) and limited to 5 genres. STEP 2: Choose ambiguity type: Attachment ambiguity fits well because the phrasing around ""multiplayer-capable"" can attach either to the count, to the list of titles, or to the genre selection; this maps to the SQL quirk where multiplayer_capable is actually the same as total_games. STEP 3: Draft the question: ""For each genre, which titles are included and how many are multiplayer-capable?"" STEP 4: Explain the ambiguity: the question can be read as asking (a) for, per genre, the count of multiplayer-capable games and the titles of those multiplayer games, or (b) for, per genre, the list of all titles plus a count (which might unintentionally be the total number of games in that genre rather than only multiplayer ones). The original query produces the latter (count = total games) while a different query could filter the count to only multiplayer-capable entries.",reserved,9,reward,,"type: Attachment ambiguity | explanation: The phrase ""how many are multiplayer-capable"" can attach either to the count (asking for the number of multiplayer games per genre) or to the titles (asking for the titles that are multiplayer-capable). The given SQL returns a count equal to total games per genre (so it matches the interpretation where the count is not filtered to multiplayer games), but a different query could restrict the count to only multiplayer-capable rows and only list those titles."
"For each Year where Standard Duties Total Revenue (in €million) exceeds the Standard Duties Total Revenue (in €million) of the previous fiscal year (previous fiscal year determined by taking the first four digits of Year, subtracting 1, then concatenating '-' and the last two digits), report Year, Standard Duties Total Revenue (in €million), over GDP (in %), the Year-over-Year % change (rounded to 2 decimals) calculated as (current − previous) * 100.0 / previous, and the Implied GDP (in €million) (rounded to 2 decimals) calculated as Standard Duties Total Revenue (in €million) divided by over GDP (in %); sort by YoY % change descending and show the top 5 results.","
SELECT t.`Year`, t.`Standard Duties Total Revenue (in €million)`, t.`over GDP (in %)`, ROUND((t.`Standard Duties Total Revenue (in €million)` - prev.`Standard Duties Total Revenue (in €million)`) * 100.0 / prev.`Standard Duties Total Revenue (in €million)`,2) `YoY % change`, ROUND(t.`Standard Duties Total Revenue (in €million)` / t.`over GDP (in %)`,2) `Implied GDP (in €million)`
FROM `table_1_1618358_1` t JOIN `table_1_1618358_1` prev ON prev.`Year` = ((substr(t.`Year`,1,4) - 1) || '-' || substr(t.`Year`,3,2))
WHERE t.`Standard Duties Total Revenue (in €million)` > prev.`Standard Duties Total Revenue (in €million)`
ORDER BY `YoY % change` DESC LIMIT 5;
","
SELECT t.col0, t.col3, t.col5, ROUND((t.col3 - prev.col3) * 100.0 / prev.col3,2) `YoY % change`, ROUND(t.col3 / t.col5,2) `Implied GDP (in €million)`
FROM `table_1_1618358_1` t JOIN `table_1_1618358_1` prev ON prev.col0 = ((substr(t.col0,1,4) - 1) || '-' || substr(t.col0,3,2))
WHERE t.col3 > prev.col3
ORDER BY `YoY % change` DESC LIMIT 5;
","[('1997-98', 3033.0, '0.25', 54.27, 12132.0), ('1999-00', 5617.0, '0.40', 51.98, 14042.5), ('2000-01', 7383.0, '0.46', 31.44, 16050.0), ('2005-06', 5067.0, '0.28', 26.64, 18096.43), ('1998-99', 3696.0, '0.28', 21.86, 13200.0)]",table_1_1618358_1,"1) The SQL joins each year to the prior formatted year, computes percent growth and implied GDP, filters to positive growth, sorts by percent growth, and limits to five. 2) Map the Year string arithmetic for previous-year matching and the two numeric calculations using Standard Duties Total Revenue (in €million) and over GDP (in %). 3) Create a question asking for Year, revenue, over GDP, YoY % change rounded to two decimals with its formula, and Implied GDP rounded to two decimals with its formula, only where revenue > previous revenue, ordered by YoY % change desc and limited to 5. 4) Ensure the question includes the rounding, exact formulas, previous-year construction, filter, sort, and limit.",reserved,9,reward,,
"Which Big 12 opponent does Missouri lead by the largest margin, and what are their current streak and home/away win differences?","
WITH parsed AS (
  SELECT
    `Missouri vs.`,
    `Overall Record`,
    trim(substr(`Overall Record`, 1, instr(`Overall Record`, ',')-1)) AS `overall_leader`,
    trim(substr(`Overall Record`, instr(`Overall Record`, ',')+1)) AS `overall_wl`,
    trim(substr(trim(substr(`Overall Record`, instr(`Overall Record`, ',')+1)), 1, instr(trim(substr(`Overall Record`, instr(`Overall Record`, ',')+1)), '-')-1)) AS `overall_wl_left`,
    trim(substr(trim(substr(`Overall Record`, instr(`Overall Record`, ',')+1)), instr(trim(substr(`Overall Record`, instr(`Overall Record`, ',')+1)), '-')+1)) AS `overall_wl_right`,
    `at Columbia`,
    trim(substr(`at Columbia`, 1, instr(`at Columbia`, ',')-1)) AS `col_leader`,
    trim(substr(`at Columbia`, instr(`at Columbia`, ',')+1)) AS `col_wl`,
    trim(substr(trim(substr(`at Columbia`, instr(`at Columbia`, ',')+1)), 1, instr(trim(substr(`at Columbia`, instr(`at Columbia`, ',')+1)), '-')-1)) AS `col_wl_left`,
    trim(substr(trim(substr(`at Columbia`, instr(`at Columbia`, ',')+1)), instr(trim(substr(`at Columbia`, instr(`at Columbia`, ',')+1)), '-')+1)) AS `col_wl_right`,
    `at Opponents Venue`,
    trim(substr(`at Opponents Venue`, 1, instr(`at Opponents Venue`, ',')-1)) AS `opp_venue_leader`,
    trim(substr(`at Opponents Venue`, instr(`at Opponents Venue`, ',')+1)) AS `opp_venue_wl`,
    trim(substr(trim(substr(`at Opponents Venue`, instr(`at Opponents Venue`, ',')+1)), 1, instr(trim(substr(`at Opponents Venue`, instr(`at Opponents Venue`, ',')+1)), '-')-1)) AS `opp_venue_wl_left`,
    trim(substr(trim(substr(`at Opponents Venue`, instr(`at Opponents Venue`, ',')+1)), instr(trim(substr(`at Opponents Venue`, instr(`at Opponents Venue`, ',')+1)), '-')+1)) AS `opp_venue_wl_right`,
    `Current Streak`,
    trim(substr(`Current Streak`, 1, 1)) AS `streak_type`,
    CASE WHEN trim(substr(`Current Streak`,3)) = '' THEN 0 ELSE CAST(trim(substr(`Current Streak`,3)) AS INTEGER) END AS `streak_len`
  FROM `table_1_16201038_3`
)
SELECT
  `Missouri vs.`,
  -- Overall wins for MU and opponent, and net difference (actionable: largest advantage/deficit)
  CASE WHEN `overall_leader` = 'MU' THEN CAST(`overall_wl_left` AS INTEGER) ELSE CAST(`overall_wl_right` AS INTEGER) END AS `mu_overall_wins`,
  CASE WHEN `overall_leader` = 'MU' THEN CAST(`overall_wl_right` AS INTEGER) ELSE CAST(`overall_wl_left` AS INTEGER) END AS `opp_overall_wins`,
  (CASE WHEN `overall_leader` = 'MU' THEN CAST(`overall_wl_left` AS INTEGER) ELSE CAST(`overall_wl_right` AS INTEGER) END
   - CASE WHEN `overall_leader` = 'MU' THEN CAST(`overall_wl_right` AS INTEGER) ELSE CAST(`overall_wl_left` AS INTEGER) END) AS `net_mu_diff`,
  -- Current streak details (actionable: momentum-based preparation)
  `Current Streak`,
  `streak_type`,
  `streak_len`,
  CASE WHEN `streak_type` = 'W' AND `streak_len` >= 3 THEN 'MU_win_streak_>=3'
       WHEN `streak_type` = 'L' AND `streak_len` >= 3 THEN 'MU_loss_streak_>=3'
       ELSE 'no_significant_streak' END AS `streak_flag`,
  -- Home/away split: MU home wins at Columbia and opponent home wins at their venue, and the home win differential (actionable: prioritize opponents with large home-court gaps)
  CASE WHEN `col_leader` = 'MU' THEN CAST(`col_wl_left` AS INTEGER) ELSE CAST(`col_wl_right` AS INTEGER) END AS `mu_home_wins`,
  CASE WHEN `opp_venue_leader` = 'MU' THEN CAST(`opp_venue_wl_right` AS INTEGER) ELSE CAST(`opp_venue_wl_left` AS INTEGER) END AS `opp_home_wins`,
  (CASE WHEN `col_leader` = 'MU' THEN CAST(`col_wl_left` AS INTEGER) ELSE CAST(`col_wl_right` AS INTEGER) END
   - CASE WHEN `opp_venue_leader` = 'MU' THEN CAST(`opp_venue_wl_right` AS INTEGER) ELSE CAST(`opp_venue_wl_left` AS INTEGER) END) AS `home_win_diff`
FROM parsed
ORDER BY `net_mu_diff` DESC, `streak_len` DESC, `home_win_diff` DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    trim(substr(col1, 1, instr(col1, ',')-1)) AS `overall_leader`,
    trim(substr(col1, instr(col1, ',')+1)) AS `overall_wl`,
    trim(substr(trim(substr(col1, instr(col1, ',')+1)), 1, instr(trim(substr(col1, instr(col1, ',')+1)), '-')-1)) AS `overall_wl_left`,
    trim(substr(trim(substr(col1, instr(col1, ',')+1)), instr(trim(substr(col1, instr(col1, ',')+1)), '-')+1)) AS `overall_wl_right`,
    col2,
    trim(substr(col2, 1, instr(col2, ',')-1)) AS `col_leader`,
    trim(substr(col2, instr(col2, ',')+1)) AS `col_wl`,
    trim(substr(trim(substr(col2, instr(col2, ',')+1)), 1, instr(trim(substr(col2, instr(col2, ',')+1)), '-')-1)) AS `col_wl_left`,
    trim(substr(trim(substr(col2, instr(col2, ',')+1)), instr(trim(substr(col2, instr(col2, ',')+1)), '-')+1)) AS `col_wl_right`,
    col3,
    trim(substr(col3, 1, instr(col3, ',')-1)) AS `opp_venue_leader`,
    trim(substr(col3, instr(col3, ',')+1)) AS `opp_venue_wl`,
    trim(substr(trim(substr(col3, instr(col3, ',')+1)), 1, instr(trim(substr(col3, instr(col3, ',')+1)), '-')-1)) AS `opp_venue_wl_left`,
    trim(substr(trim(substr(col3, instr(col3, ',')+1)), instr(trim(substr(col3, instr(col3, ',')+1)), '-')+1)) AS `opp_venue_wl_right`,
    col7,
    trim(substr(col7, 1, 1)) AS `streak_type`,
    CASE WHEN trim(substr(col7,3)) = '' THEN 0 ELSE CAST(trim(substr(col7,3)) AS INTEGER) END AS `streak_len`
  FROM `table_1_16201038_3`
)
SELECT
  col0,
  -- Overall wins for MU and opponent, and net difference (actionable: largest advantage/deficit)
  CASE WHEN `overall_leader` = 'MU' THEN CAST(`overall_wl_left` AS INTEGER) ELSE CAST(`overall_wl_right` AS INTEGER) END AS `mu_overall_wins`,
  CASE WHEN `overall_leader` = 'MU' THEN CAST(`overall_wl_right` AS INTEGER) ELSE CAST(`overall_wl_left` AS INTEGER) END AS `opp_overall_wins`,
  (CASE WHEN `overall_leader` = 'MU' THEN CAST(`overall_wl_left` AS INTEGER) ELSE CAST(`overall_wl_right` AS INTEGER) END
   - CASE WHEN `overall_leader` = 'MU' THEN CAST(`overall_wl_right` AS INTEGER) ELSE CAST(`overall_wl_left` AS INTEGER) END) AS `net_mu_diff`,
  -- Current streak details (actionable: momentum-based preparation)
  col7,
  `streak_type`,
  `streak_len`,
  CASE WHEN `streak_type` = 'W' AND `streak_len` >= 3 THEN 'MU_win_streak_>=3'
       WHEN `streak_type` = 'L' AND `streak_len` >= 3 THEN 'MU_loss_streak_>=3'
       ELSE 'no_significant_streak' END AS `streak_flag`,
  -- Home/away split: MU home wins at Columbia and opponent home wins at their venue, and the home win differential (actionable: prioritize opponents with large home-court gaps)
  CASE WHEN `col_leader` = 'MU' THEN CAST(`col_wl_left` AS INTEGER) ELSE CAST(`col_wl_right` AS INTEGER) END AS `mu_home_wins`,
  CASE WHEN `opp_venue_leader` = 'MU' THEN CAST(`opp_venue_wl_right` AS INTEGER) ELSE CAST(`opp_venue_wl_left` AS INTEGER) END AS `opp_home_wins`,
  (CASE WHEN `col_leader` = 'MU' THEN CAST(`col_wl_left` AS INTEGER) ELSE CAST(`col_wl_right` AS INTEGER) END
   - CASE WHEN `opp_venue_leader` = 'MU' THEN CAST(`opp_venue_wl_right` AS INTEGER) ELSE CAST(`opp_venue_wl_left` AS INTEGER) END) AS `home_win_diff`
FROM parsed
ORDER BY `net_mu_diff` DESC, `streak_len` DESC, `home_win_diff` DESC;
","[('kansas state', 117, 118, -1, 'l 3', 'l', 3, 'no_significant_streak', 41, 60, -19), ('texas', 12, 14, -2, 'w 3', 'w', 3, 'no_significant_streak', 4, 6, -2), ('texas a&m', 11, 14, -3, 'w 1', 'w', 1, 'no_significant_streak', 3, 7, -4), ('baylor', 10, 16, -6, 'w 4', 'w', 4, 'no_significant_streak', 2, 6, -4), ('texas tech', 8, 15, -7, 'w 7', 'w', 7, 'no_significant_streak', 2, 6, -4), ('oklahoma', 97, 112, -15, 'w 3', 'w', 3, 'no_significant_streak', 31, 65, -34), ('oklahoma state', 41, 77, -36, 'w 2', 'w', 2, 'no_significant_streak', 7, 29, -22), ('iowa state', 84, 149, -65, 'w 9', 'w', 9, 'no_significant_streak', 21, 56, -35), ('kansas', 95, 173, -78, 'l 1', 'l', 1, 'no_significant_streak', 57, 89, -32)]",table_1_16201038_3,"STEP 1: Parse the SQL intent — the query parses each row's text fields to extract who leads overall and by how many wins, MU's and opponent's wins, computes net_mu_diff (MU wins minus opponent wins overall), extracts current streak type/length and a streak_flag, computes MU home wins and opponent home wins and a home_win_diff, then returns one row per opponent ordered by net_mu_diff DESC, streak_len DESC, home_win_diff DESC. STEP 2: Determine ambiguity type — scope ambiguity fits well: the phrase ""lead by the largest margin"" can refer to multiple possible metrics (overall net wins, home-win differential, or even raw wins) and the SQL specifically uses overall net difference as the primary sort. STEP 3: Draft the question — produce a concise, naturally phrased but ambiguous question that matches a valid interpretation of the SQL. STEP 4: Explain the ambiguity — in the original query the primary metric is overall net_mu_diff (and streak_len/home_win_diff are tie-breakers), but a reader could reasonably interpret ""lead the most"" to mean MU's advantage at Columbia, the opponent's home advantage, just the higher raw MU wins, or other per-location measures; an alternate query could switch the primary metric to home_win_diff or to MU home wins alone, giving different results.",persona,"Missouri Tigers men's basketball performance analyst working for the university athletics department; they query this head-to-head table to prepare scouting reports, schedule planning, and historical trend analysis for Big 12 opponents. They use the dataset to quantify matchup advantages, streaks, and home/away splits when advising coaches and staff. Goals: Identify which Big 12 opponents Missouri has the largest historical advantage or deficit against (net wins/losses). Find opponents against whom Missouri currently has meaningful win or loss streaks to inform momentum-based preparation. Compare Missouri's home record (at Columbia) to opponents' home records to prioritize opponents where home-court advantage is most significant. Example Queries: /* Rank Big 12 opponents by Missouri net wins (MU wins minus opponent wins) using the Overall Record field (format: '<leader>, W-L') */
SELECT
  ""Missouri vs."",
  CASE WHEN split_part(""Overall Record"", ',', 1) = 'MU' THEN CAST(split_part(trim(split_part(""Overall Record"", ',', 2)), '-', 1) AS INTEGER) ELSE CAST(split_part(trim(split_part(""Overall Record"", ',', 2)), '-', 2) AS INTEGER) END AS mu_wins,
  CASE WHEN split_part(""Overall Record"", ',', 1) = 'MU' THEN CAST(split_part(trim(split_part(""Overall Record"", ',', 2)), '-', 2) AS INTEGER) ELSE CAST(split_part(trim(split_part(""Overall Record"", ',', 2)), '-', 1) AS INTEGER) END AS opp_wins,
  (CASE WHEN split_part(""Overall Record"", ',', 1) = 'MU' THEN CAST(split_part(trim(split_part(""Overall Record"", ',', 2)), '-', 1) AS INTEGER) ELSE CAST(split_part(trim(split_part(""Overall Record"", ',', 2)), '-', 2) AS INTEGER) END
   - CASE WHEN split_part(""Overall Record"", ',', 1) = 'MU' THEN CAST(split_part(trim(split_part(""Overall Record"", ',', 2)), '-', 2) AS INTEGER) ELSE CAST(split_part(trim(split_part(""Overall Record"", ',', 2)), '-', 1) AS INTEGER) END) AS net_mu_diff
FROM table_1_16201038_3
ORDER BY net_mu_diff DESC; /* List opponents where Missouri currently has a winning streak of 3 or more (Current Streak format: 'W N' or 'L N') */
SELECT ""Missouri vs."", ""Current Streak""
FROM table_1_16201038_3
WHERE ""Current Streak"" LIKE 'W %'
  AND CAST(trim(substring(""Current Streak"" FROM 3)) AS INTEGER) >= 3
ORDER BY CAST(trim(substring(""Current Streak"" FROM 3)) AS INTEGER) DESC; /* Find opponents where Missouri's home record (""at Columbia"") is better than the opponent's home record (""at Opponents Venue""). Both columns use the '<leader>, W-L' pattern. */
SELECT t.""Missouri vs."", t.mu_home_wins, t.opp_home_wins, (t.mu_home_wins - t.opp_home_wins) AS home_win_diff
FROM (
  SELECT
    ""Missouri vs."",
    CASE WHEN split_part(""at Columbia"", ',', 1) = 'MU' THEN CAST(split_part(trim(split_part(""at Columbia"", ',', 2)), '-', 1) AS INTEGER) ELSE CAST(split_part(trim(split_part(""at Columbia"", ',', 2)), '-', 2) AS INTEGER) END AS mu_home_wins,
    CASE WHEN split_part(""at Opponents Venue"", ',', 1) = 'MU' THEN CAST(split_part(trim(split_part(""at Opponents Venue"", ',', 2)), '-', 2) AS INTEGER) ELSE CAST(split_part(trim(split_part(""at Opponents Venue"", ',', 2)), '-', 1) AS INTEGER) END AS opp_home_wins
  FROM table_1_16201038_3
) t
WHERE t.mu_home_wins > t.opp_home_wins
ORDER BY home_win_diff DESC;",reward,,"type: Scope ambiguity | explanation: In the SQL the question is implemented as the opponent with the largest overall net win margin (net_mu_diff) with streak_len and home_win_diff as tie-breakers; alternatively ""lead by the largest margin"" could mean the largest home-win advantage, the largest raw MU wins, or another per-location gap, which would require a different query and could change which opponent is returned."
"Show me the SEC opponents that matter for Columbia/neutral narratives — those with a home edge, lopsided recent series, notable neutral-site history, or big streaks — ranked by a composite rivalry-heat score with parsed home, last-five, last-ten and streak numbers?","
SELECT
  `Missouri vs.`,
  `at Columbia`,
  `at Neutral Site`,
  `Last 5 Meetings`,
  `Last 10 Meetings`,
  `Current Streak`,
  -- parse Missouri home wins/losses when `at Columbia` is in the form ""MU, X-Y""
  CASE
    WHEN `at Columbia` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), 1, INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')-1) AS INTEGER)
    ELSE 0
  END AS `mu_home_wins`,
  CASE
    WHEN `at Columbia` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')+1) AS INTEGER)
    ELSE 0
  END AS `mu_home_losses`,
  -- last 5: compute Missouri wins and opponent wins (handles ""MU, X-Y"", ""Tied, X-Y"", and ""OPP, X-Y"")
  CASE
    WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
  END AS `last5_mu_wins`,
  CASE
    WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
  END AS `last5_opp_wins`,
  -- last 10 analogous margins (treat same patterns)
  (CASE
    WHEN `Last 10 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    WHEN `Last 10 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
  END)
  -
  (CASE
    WHEN `Last 10 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    WHEN `Last 10 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
  END) AS `last10_margin`,
  -- last5 margin
  (CASE
    WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
  END)
  -
  (CASE
    WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
  END) AS `last5_margin`,
  -- current streak numeric score (positive for MU wins, negative for MU losses)
  CASE
    WHEN `Current Streak` LIKE 'W %' THEN CAST(SUBSTR(`Current Streak`, 3) AS INTEGER)
    WHEN `Current Streak` LIKE 'L %' THEN -CAST(SUBSTR(`Current Streak`, 3) AS INTEGER)
    ELSE 0
  END AS `streak_score`,
  -- home margin (only when `at Columbia` is ""MU, X-Y"")
  (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
     CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), 1, INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')-1) AS INTEGER)
   ELSE 0 END)
  -
  (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
     CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')+1) AS INTEGER)
   ELSE 0 END) AS `home_margin`,
  -- composite rivalry heat score (weights: last5 x3, home x2, neutral history bonus x2, last10 x1, current streak x1)
  (
    ((CASE WHEN `at Columbia` LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), 1, INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')-1) AS INTEGER)
     ELSE 0 END)
    -
    (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')+1) AS INTEGER)
     ELSE 0 END)
    ) * 2
  )
  +
  ( -- last5 contribution *3
    (
      (CASE
        WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
        WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
        ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      END)
      -
      (CASE
        WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
        WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
        ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      END)
    ) * 3
  )
  +
  ( -- neutral-site bonus
    CASE WHEN `at Neutral Site` NOT LIKE 'Tied, 0-0' THEN 2 ELSE 0 END
  )
  +
  ( -- last10 margin *1
    (CASE
      WHEN `Last 10 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      WHEN `Last 10 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    END)
    -
    (CASE
      WHEN `Last 10 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      WHEN `Last 10 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    END)
  )
  +
  ( -- streak score
    CASE
      WHEN `Current Streak` LIKE 'W %' THEN CAST(SUBSTR(`Current Streak`, 3) AS INTEGER)
      WHEN `Current Streak` LIKE 'L %' THEN -CAST(SUBSTR(`Current Streak`, 3) AS INTEGER)
      ELSE 0
    END
  ) AS `rivalry_heat`
FROM `table_1_16201038_5`
WHERE
  -- surface opponents that matter for a Columbia/neutral-site narrative: pronounced home advantage,
  -- strongly lopsided recent series, notable neutral-site history, or notable current streak
  (
    (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), 1, INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')-1) AS INTEGER)
     ELSE 0 END)
    -
    (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')+1) AS INTEGER)
     ELSE 0 END)
  ) >= 1
  OR ABS(
    (CASE
      WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    END)
    -
    (CASE
      WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    END)
  ) >= 2
  OR `at Neutral Site` NOT LIKE 'Tied, 0-0'
  OR ABS(CASE WHEN `Current Streak` LIKE 'W %' THEN CAST(SUBSTR(`Current Streak`, 3) AS INTEGER) WHEN `Current Streak` LIKE 'L %' THEN -CAST(SUBSTR(`Current Streak`, 3) AS INTEGER) ELSE 0 END) >= 2
ORDER BY `rivalry_heat` DESC, `last5_margin` DESC, `home_margin` DESC, `streak_score` DESC;
","
SELECT
  col0,
  col2,
  col4,
  col5,
  col6,
  col7,
  -- parse Missouri home wins/losses when col2 is in the form ""MU, X-Y""
  CASE
    WHEN col2 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col2, INSTR(col2, ', ')+2), 1, INSTR(SUBSTR(col2, INSTR(col2, ', ')+2), '-')-1) AS INTEGER)
    ELSE 0
  END AS `mu_home_wins`,
  CASE
    WHEN col2 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col2, INSTR(col2, ', ')+2), INSTR(SUBSTR(col2, INSTR(col2, ', ')+2), '-')+1) AS INTEGER)
    ELSE 0
  END AS `mu_home_losses`,
  -- last 5: compute Missouri wins and opponent wins (handles ""MU, X-Y"", ""Tied, X-Y"", and ""OPP, X-Y"")
  CASE
    WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
    WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
  END AS `last5_mu_wins`,
  CASE
    WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
    WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
  END AS `last5_opp_wins`,
  -- last 10 analogous margins (treat same patterns)
  (CASE
    WHEN col6 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), 1, INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')-1) AS INTEGER)
    WHEN col6 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), 1, INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')+1) AS INTEGER)
  END)
  -
  (CASE
    WHEN col6 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')+1) AS INTEGER)
    WHEN col6 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), 1, INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')-1) AS INTEGER)
  END) AS `last10_margin`,
  -- last5 margin
  (CASE
    WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
    WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
  END)
  -
  (CASE
    WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
    WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
  END) AS `last5_margin`,
  -- current streak numeric score (positive for MU wins, negative for MU losses)
  CASE
    WHEN col7 LIKE 'W %' THEN CAST(SUBSTR(col7, 3) AS INTEGER)
    WHEN col7 LIKE 'L %' THEN -CAST(SUBSTR(col7, 3) AS INTEGER)
    ELSE 0
  END AS `streak_score`,
  -- home margin (only when col2 is ""MU, X-Y"")
  (CASE WHEN col2 LIKE 'MU, %' THEN
     CAST(SUBSTR(SUBSTR(col2, INSTR(col2, ', ')+2), 1, INSTR(SUBSTR(col2, INSTR(col2, ', ')+2), '-')-1) AS INTEGER)
   ELSE 0 END)
  -
  (CASE WHEN col2 LIKE 'MU, %' THEN
     CAST(SUBSTR(SUBSTR(col2, INSTR(col2, ', ')+2), INSTR(SUBSTR(col2, INSTR(col2, ', ')+2), '-')+1) AS INTEGER)
   ELSE 0 END) AS `home_margin`,
  -- composite rivalry heat score (weights: last5 x3, home x2, neutral history bonus x2, last10 x1, current streak x1)
  (
    ((CASE WHEN col2 LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(col2, INSTR(col2, ', ')+2), 1, INSTR(SUBSTR(col2, INSTR(col2, ', ')+2), '-')-1) AS INTEGER)
     ELSE 0 END)
    -
    (CASE WHEN col2 LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(col2, INSTR(col2, ', ')+2), INSTR(SUBSTR(col2, INSTR(col2, ', ')+2), '-')+1) AS INTEGER)
     ELSE 0 END)
    ) * 2
  )
  +
  ( -- last5 contribution *3
    (
      (CASE
        WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
        WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
        ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
      END)
      -
      (CASE
        WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
        WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
        ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
      END)
    ) * 3
  )
  +
  ( -- neutral-site bonus
    CASE WHEN col4 NOT LIKE 'Tied, 0-0' THEN 2 ELSE 0 END
  )
  +
  ( -- last10 margin *1
    (CASE
      WHEN col6 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), 1, INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')-1) AS INTEGER)
      WHEN col6 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), 1, INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')-1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')+1) AS INTEGER)
    END)
    -
    (CASE
      WHEN col6 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')+1) AS INTEGER)
      WHEN col6 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')+1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(col6, INSTR(col6, ', ')+2), 1, INSTR(SUBSTR(col6, INSTR(col6, ', ')+2), '-')-1) AS INTEGER)
    END)
  )
  +
  ( -- streak score
    CASE
      WHEN col7 LIKE 'W %' THEN CAST(SUBSTR(col7, 3) AS INTEGER)
      WHEN col7 LIKE 'L %' THEN -CAST(SUBSTR(col7, 3) AS INTEGER)
      ELSE 0
    END
  ) AS `rivalry_heat`
FROM `table_1_16201038_5`
WHERE
  -- surface opponents that matter for a Columbia/neutral-site narrative: pronounced home advantage,
  -- strongly lopsided recent series, notable neutral-site history, or notable current streak
  (
    (CASE WHEN col2 LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(col2, INSTR(col2, ', ')+2), 1, INSTR(SUBSTR(col2, INSTR(col2, ', ')+2), '-')-1) AS INTEGER)
     ELSE 0 END)
    -
    (CASE WHEN col2 LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(col2, INSTR(col2, ', ')+2), INSTR(SUBSTR(col2, INSTR(col2, ', ')+2), '-')+1) AS INTEGER)
     ELSE 0 END)
  ) >= 1
  OR ABS(
    (CASE
      WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
      WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
    END)
    -
    (CASE
      WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
      WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
    END)
  ) >= 2
  OR col4 NOT LIKE 'Tied, 0-0'
  OR ABS(CASE WHEN col7 LIKE 'W %' THEN CAST(SUBSTR(col7, 3) AS INTEGER) WHEN col7 LIKE 'L %' THEN -CAST(SUBSTR(col7, 3) AS INTEGER) ELSE 0 END) >= 2
ORDER BY `rivalry_heat` DESC, `last5_margin` DESC, `home_margin` DESC, `streak_score` DESC;
","[('georgia', 'mu, 2-0', 'mu, 1-0', 'mu, 4-0', 'mu, 4-0', 'w 4', 2, 0, 4, 0, 4, 4, 4, 2, 26), ('mississippi state', 'mu, 2-0', 'tied, 0-0', 'mu, 3-1', 'mu, 3-1', 'w 1', 2, 0, 3, 1, 2, 2, 1, 2, 13), ('south carolina', 'mu, 1-0', 'tied, 0-0', 'mu, 2-0', 'mu, 2-0', 'w 2', 1, 0, 2, 0, 2, 2, 2, 1, 12), ('texas a&m', 'mu, 6-3', 'mu, 4-1', 'mu, 3-2', 'tamu, 7-3', 'w 1', 6, 3, 3, 2, -4, 1, 1, 3, 8), ('auburn', 'mu, 1-0', 'tied, 0-0', 'mu, 1-0', 'mu, 1-0', 'w 1', 1, 0, 1, 0, 1, 1, 1, 1, 7), ('vanderbilt', 'mu, 3-0', 'vu, 1-0', 'vu, 3-2', 'tied, 3-3', 'w 2', 3, 0, 2, 3, 0, -1, 2, 3, 7), ('florida', 'mu, 1-0', 'tied, 0-0', 'tied, 1-1', 'tied, 1-1', 'w 1', 1, 0, 1, 1, 0, 0, 1, 1, 3), ('tennessee', 'mu, 2-0', 'ut, 1-0', 'ut, 3-2', 'mu, 4-3', 'l 1', 2, 0, 2, 3, 1, -1, -1, 2, 3), ('louisiana state', 'mu, 1-0', 'lsu, 1-0', 'lsu, 2-1', 'lsu, 2-1', 'w 1', 1, 0, 1, 2, -1, -1, 1, 1, 1), ('arkansas', 'mu, 11-8', 'ua, 1-0', 'ua, 3-2', 'ua, 8-2', 'w 1', 11, 8, 2, 3, -6, -1, 1, 3, 0), ('mississippi', 'mu, 1-0', 'um, 1-0', 'um, 2-1', 'um, 2-1', 'l 1', 1, 0, 1, 2, -1, -1, -1, 1, -1), ('alabama', 'tied, 1-1', 'ua, 2-1', 'ua, 3-2', 'ua, 4-2', 'w 2', 0, 0, 2, 3, -2, -1, 2, 0, -1), ('kentucky', 'tied, 0-0', 'uk, 2-0', 'uk, 5-0', 'uk, 5-0', 'l 5', 0, 0, 0, 5, -5, -5, -5, 0, -23)]",table_1_16201038_5,"For ordering waypoint content I want a ranked list by overall rivalry heat combining home edge, recent margins, neutral history and streaks, phrased as a single practical ask. The SQL filters opponents that matter (home margin >=1, big last-5 swing, any neutral-site history, or streak magnitude >=2), computes parsed stats (home, last5, last10, streak) and a composite 'rivalry_heat' score, then orders by that score and tiebreakers. The schema columns used are 'at Columbia', 'at Neutral Site', 'Last 5 Meetings', 'Last 10 Meetings', and 'Current Streak' which are parsed into numeric components. Draft question: Show me the SEC opponents that matter for Columbia/neutral narratives — those with a home edge, lopsided recent series, notable neutral-site history, or big streaks — ranked by a composite rivalry-heat score with parsed home/last5/last10/streak numbers. This matches the SQL's selection, computed fields, and ordering.",persona,"An augmented-reality 'Rivalry Walk' narrative designer at the University of Missouri who scripts short, venue-aware audio vignettes about each SEC opponent using granular head-to-head stats. Goals: Identify opponents where Missouri has a pronounced home advantage (to craft triumphant home-focused narratives for the Columbia stop). Spot intense or lopsided recent series (last 5/10 meetings) and neutral-site histories to build dramatic, context-rich audio scenes for stadium plazas and neutral-site exhibit points. Rank current streaks (wins/losses) to vary emotional tone across waypoints and programmatically generate narration templates ordered by rivalry heat. Example Queries: SELECT ""Missouri vs."", ""at Columbia"", ""Current Streak"", ""Since Joining SEC""
FROM ""table_1_16201038_5""
WHERE ""at Columbia"" LIKE 'MU%'; SELECT ""Missouri vs."", ""at Neutral Site"", ""Last 10 Meetings""
FROM ""table_1_16201038_5""
WHERE ""at Neutral Site"" NOT LIKE 'Tied, 0-0'
  AND ""Last 10 Meetings"" NOT LIKE 'Tied%'; SELECT ""Missouri vs."", ""Current Streak""
FROM ""table_1_16201038_5""
WHERE ""Current Streak"" LIKE 'W %'
ORDER BY CAST(SUBSTR(""Current Streak"", 3) AS INTEGER) DESC;",reward,,
"Which tunnels should I prioritise for high-fidelity recordings — give me each tunnel's name, parish, miles and km from Kingston, length (ft and m), whether it's a high-reverb candidate (>=200 m), and its rank by length, with parishes ordered by total tunnel length and tunnels in each parish ordered by distance from Kingston?","
WITH parish_stats AS (
  SELECT `Parish`,
         COUNT(*) AS tunnel_count,
         AVG(`Length meters`) AS avg_length_m,
         MAX(`Length meters`) AS max_length_m,
         SUM(`Length meters`) AS total_length_m
  FROM `table_1_16226584_1`
  GROUP BY `Parish`
),
ranked AS (
  SELECT `No.`, `Name`, `Mi from Kingston`, `Km from Kingston`, `Parish`, `Length feet`, `Length meters`,
         CASE WHEN `Length meters` >= 200 THEN 1 ELSE 0 END AS high_reverb,
         RANK() OVER (ORDER BY `Length meters` DESC) AS length_rank
  FROM `table_1_16226584_1`
)
SELECT r.`No.`,
       r.`Name`,
       r.`Parish`,
       r.`Mi from Kingston`,
       r.`Km from Kingston`,
       r.`Length feet`,
       r.`Length meters`,
       r.high_reverb,
       r.length_rank,
       p.tunnel_count,
       ROUND(p.avg_length_m,1) AS avg_length_m,
       p.max_length_m,
       p.total_length_m,
       ROUND((r.`Length meters` / p.total_length_m) * 100,1) AS pct_of_parish_total
FROM ranked r
JOIN parish_stats p ON r.`Parish` = p.`Parish`
ORDER BY p.total_length_m DESC, r.`Km from Kingston` ASC;
","WITH parish_stats AS (
  SELECT col4,
         COUNT(*) AS tunnel_count,
         AVG(CAST(col6 AS real)) AS avg_length_m,
         MAX(CAST(col6 AS real)) AS max_length_m,
         SUM(CAST(col6 AS real)) AS total_length_m
  FROM `table_1_16226584_1`
  GROUP BY col4
)
SELECT t.col0,
       t.col1,
       t.col4,
       t.col2,
       t.col3,
       t.col5,
       t.col6,
       CASE WHEN CAST(t.col6 AS real) >= 200 THEN 1 ELSE 0 END AS high_reverb,
       (SELECT COUNT(DISTINCT CAST(t2.col6 AS real))
        FROM `table_1_16226584_1` t2
        WHERE CAST(t2.col6 AS real) > CAST(t.col6 AS real)
       ) + 1 AS length_rank,
       p.tunnel_count,
       ROUND(p.avg_length_m,1) AS avg_length_m,
       p.max_length_m,
       p.total_length_m,
       ROUND((CAST(t.col6 AS real) / p.total_length_m) * 100,1) AS pct_of_parish_total
FROM `table_1_16226584_1` t
JOIN parish_stats p ON t.col4 = p.col4
ORDER BY p.total_length_m DESC, CAST(t.col3 AS real) ASC;","[(8.0, 'unnamed', 'st. james', '87.75', '141.2', 555.0, '164.6', 0, 4, 5, 151.2, 388.9, 755.9, 21.8), (9.0, 'merrywood', 'st. james', '88.50', '142.4', 362.0, '115.8', 0, 5, 5, 151.2, 388.9, 755.9, 15.3), (10.0, 'anchovy', 'st. james', '104.50', '168.2', 102.0, '31.1', 0, 10, 5, 151.2, 388.9, 755.9, 4.1), (11.0, 'ramble', 'st. james', '108.00', '173.8', 182.0, '55.5', 0, 8, 5, 151.2, 388.9, 755.9, 7.3), (12.0, 'bogue hill', 'st. james', '108.50', '174.6', 1276.0, '388.9', 1, 1, 5, 151.2, 388.9, 755.9, 51.4), (3.0, 'comfort hall', 'st. elizabeth', '65.50', '105.4', 688.0, '209.1', 1, 3, 5, 139.5, 260.6, 697.7, 30.0), (4.0, 'balaclava', 'st. elizabeth', '70.00', '112.6', 348.0, '106.1', 0, 6, 5, 139.5, 260.6, 697.7, 15.2), (5.0, 'highworth', 'st. elizabeth', '84.00', '135.2', 182.0, '55.5', 0, 8, 5, 139.5, 260.6, 697.7, 8.0), (6.0, 'y s', 'st. elizabeth', '84.50', '136.0', 218.0, '66.4', 0, 7, 5, 139.5, 260.6, 697.7, 9.5), (7.0, 'ipswich', 'st. elizabeth', '86.25', '138.8', 855.0, '260.6', 1, 2, 5, 139.5, 260.6, 697.7, 37.4), (1.0, 'scotts pass', 'clarendon', '44.25', '71.2', 70.0, '21.3', 0, 11, 2, 36.5, 51.8, 73.1, 29.1), (2.0, 'scotts pass', 'clarendon', '44.50', '71.6', 170.0, '51.8', 0, 9, 2, 36.5, 51.8, 73.1, 70.9)]",table_1_16226584_1,"I speak as a soundscape archaeologist who understands parish clusters and cares about long tunnels for reverberation, so I use terms like parish and distance rather than raw column names. The SQL pulls tunnel rows, marks those >=200 m as high-reverb candidates, assigns a length rank, and joins per-parish summary stats. The table provides tunnel id, name, distances from Kingston in miles and km, parish, and lengths in feet and meters. Draft question asked for a prioritized list of tunnels with those fields plus the high-reverb flag and rank, ordered by parish total length then distance from Kingston. This matches the query results without adding any unstated fields or operations.",persona,"A 'soundscape archaeologist' — an acoustic heritage curator who records and recreates historical railway tunnel echoes for immersive museum exhibits and documentaries. Goals: Identify the longest and most sonically interesting tunnels (long reverberation potential) to prioritize for high-fidelity recordings. Plan an efficient field trip route by clustering candidate tunnels by parish and ordering them by distance from Kingston. Produce summary statistics (counts, average and total lengths) by parish to justify exhibit allocation of recording time and budget. Example Queries: /* Find the single longest tunnel (best candidate for deep, long echoes) */
SELECT [No.], [Name], [Parish], [Km from Kingston], [Length meters]
FROM table_1_16226584_1
ORDER BY [Length meters] DESC
LIMIT 1; /* List all tunnels >= 200 meters (strong reverberation prospects), ordered by proximity to Kingston for travel planning */
SELECT [No.], [Name], [Parish], [Mi from Kingston], [Km from Kingston], [Length meters]
FROM table_1_16226584_1
WHERE [Length meters] >= 200
ORDER BY [Km from Kingston] ASC; /* Summary by parish to decide where to concentrate recording resources */
SELECT [Parish],
       COUNT(*) AS tunnel_count,
       AVG([Length meters]) AS avg_length_m,
       MAX([Length meters]) AS max_length_m,
       SUM([Length meters]) AS total_length_m
FROM table_1_16226584_1
GROUP BY [Parish]
ORDER BY total_length_m DESC;",reward,,
"Using the game log and WHERE 1=1, for each Record produce: Record; COUNT(*) AS ""Total Games""; ROUND(AVG(Attendance),0) AS ""Avg Attendance""; ROUND(SUM((`at/vs.`='vs.')*Attendance)/NULLIF(SUM((`at/vs.`='vs.')),0),0) AS ""Avg Home Attendance""; ROUND(AVG((substr(Score,1,instr(Score,' - ')-1)+0) - (substr(Score,instr(Score,' - ')+3)+0)),2) AS ""Avg Goal Diff""; plus MAX('New England Blazers'), MAX('Baltimore Thunder'), MAX('New York Saints'), MAX('Detroit Turbos'), and MAX('Washington Wave'), grouped by Record, ordered by Avg Attendance * -1, limit 10?","
WITH `GameLog`(`#`,`Date`,`at/vs.`,`Opponent`,`Score`,`Attendance`,`Record`) AS (
  VALUES
    (1,'January 14, 1989','vs.','New England Blazers','19 - 8',16269,'Win'),
    (2,'January 21, 1989','at','Baltimore Thunder','14 - 13',6479,'Win'),
    (3,'January 28, 1989','at','New York Saints','16 - 20',9324,'Loss'),
    (4,'February 12, 1989','vs.','Baltimore Thunder','14 - 9',12220,'Win'),
    (5,'February 18, 1989','vs.','Detroit Turbos','19 - 10',13932,'Win'),
    (6,'February 24, 1989','at','New England Blazers','16 - 11',8107,'Win'),
    (7,'March 4, 1989','at','Detroit Turbos','11 - 16',10637,'Loss'),
    (8,'March 10, 1989','vs.','Washington Wave','13 - 9',16413,'Win')
)
SELECT
  `Record`,
  COUNT(*) `Total Games`,
  ROUND(AVG(`Attendance`),0) `Avg Attendance`,
  ROUND(SUM((`at/vs.`='vs.')*`Attendance`)/NULLIF(SUM((`at/vs.`='vs.')),0),0) `Avg Home Attendance`,
  ROUND(AVG((substr(`Score`,1,instr(`Score`,' - ')-1)+0) - (substr(`Score`,instr(`Score`,' - ')+3)+0)),2) `Avg Goal Diff`,
  MAX('New England Blazers') `New England Blazers`,
  MAX('Baltimore Thunder') `Baltimore Thunder`,
  MAX('New York Saints') `New York Saints`,
  MAX('Detroit Turbos') `Detroit Turbos`,
  MAX('Washington Wave') `Washington Wave`
FROM `GameLog`
WHERE 1=1
GROUP BY `Record`
ORDER BY `Avg Attendance`*-1
LIMIT 10;
","
WITH `GameLog`(col0,col1,col2,col3,col4,col5,col6) AS (
  VALUES
    (1,'January 14, 1989','vs.','New England Blazers','19 - 8',16269,'Win'),
    (2,'January 21, 1989','at','Baltimore Thunder','14 - 13',6479,'Win'),
    (3,'January 28, 1989','at','New York Saints','16 - 20',9324,'Loss'),
    (4,'February 12, 1989','vs.','Baltimore Thunder','14 - 9',12220,'Win'),
    (5,'February 18, 1989','vs.','Detroit Turbos','19 - 10',13932,'Win'),
    (6,'February 24, 1989','at','New England Blazers','16 - 11',8107,'Win'),
    (7,'March 4, 1989','at','Detroit Turbos','11 - 16',10637,'Loss'),
    (8,'March 10, 1989','vs.','Washington Wave','13 - 9',16413,'Win')
)
SELECT
  col6,
  COUNT(*) `Total Games`,
  ROUND(AVG(col5),0) `Avg Attendance`,
  ROUND(SUM((col2='vs.')*col5)/NULLIF(SUM((col2='vs.')),0),0) `Avg Home Attendance`,
  ROUND(AVG((substr(col4,1,instr(col4,' - ')-1)+0) - (substr(col4,instr(col4,' - ')+3)+0)),2) `Avg Goal Diff`,
  MAX('New England Blazers') `New England Blazers`,
  MAX('Baltimore Thunder') `Baltimore Thunder`,
  MAX('New York Saints') `New York Saints`,
  MAX('Detroit Turbos') `Detroit Turbos`,
  MAX('Washington Wave') `Washington Wave`
FROM `table_1_16227492_1`
WHERE 1=1
GROUP BY col6
ORDER BY `Avg Attendance`*-1
LIMIT 10;
","[('win', 6, 12237.0, 14709.0, 5.83, 'New England Blazers', 'Baltimore Thunder', 'New York Saints', 'Detroit Turbos', 'Washington Wave'), ('loss', 2, 9981.0, None, -4.5, 'New England Blazers', 'Baltimore Thunder', 'New York Saints', 'Detroit Turbos', 'Washington Wave')]",table_1_16227492_1,"1) Parse intent: aggregate the GameLog by Record to produce counts, averages (overall and home-only), average goal difference computed from parsed Score strings, include fixed opponent-name MAX(...) columns, sort by Avg Attendance descending and restrict to 10 rows. 2) Map schema: use `Attendance`, `at/vs.`, `Score` (parsed via substr/instr), and `Record` for grouping. 3) Draft: formulate a question that names each selected expression exactly (ROUNDs, SUM/NULLIF for home average, substr/instr arithmetic for goal diff, and MAX of each team string), includes WHERE 1=1, GROUP BY Record, ORDER BY Avg Attendance * -1, LIMIT 10. 4) Validate: question contains every column, calculation, grouping, ordering, and limit present in the SQL.",reserved,10,reward,,
"I need a shortlist to contact directors — which submitted Australian films include Yolngu Matha, Gunwinggu, or Warlpiri or were shortlisted/nominated, with title, year, director, languages, matched Indigenous languages and count, result, and an overall priority and score (highest priority first)?","
SELECT 
  `Film title used in nomination`,
  `Year (Ceremony)`,
  `Director`,
  `Language(s)`,
  RTRIM(`_matches_raw`, ', ') AS `Indigenous languages (matched)`,
  `Indigenous_count`,
  `Result`,
  CASE 
    WHEN `Indigenous_count` > 0 AND `Recognition_flag` = 1 THEN 'High' 
    WHEN `Indigenous_count` > 0 THEN 'Medium' 
    WHEN `Recognition_flag` = 1 THEN 'Low' 
    ELSE 'Low' 
  END AS `Priority`,
  CASE 
    WHEN `Indigenous_count` > 0 AND `Recognition_flag` = 1 THEN 3 
    WHEN `Indigenous_count` > 0 THEN 2 
    WHEN `Recognition_flag` = 1 THEN 1 
    ELSE 0 
  END AS `Priority_score`
FROM (
  SELECT 
    `Film title used in nomination`,
    `Year (Ceremony)`,
    `Director`,
    `Language(s)`,
    `Result`,
    (CASE WHEN `Language(s)` LIKE '%Yolngu Matha%' THEN '`Yolngu Matha`, ' ELSE '' END ||
     CASE WHEN `Language(s)` LIKE '%Gunwinggu%' THEN '`Gunwinggu`, ' ELSE '' END ||
     CASE WHEN `Language(s)` LIKE '%Warlpiri%' THEN '`Warlpiri`, ' ELSE '' END) AS `_matches_raw`,
    (CASE WHEN `Language(s)` LIKE '%Yolngu Matha%' THEN 1 ELSE 0 END) +
    (CASE WHEN `Language(s)` LIKE '%Gunwinggu%' THEN 1 ELSE 0 END) +
    (CASE WHEN `Language(s)` LIKE '%Warlpiri%' THEN 1 ELSE 0 END) AS `Indigenous_count`,
    CASE WHEN `Result` LIKE '%Shortlist%' OR `Result` LIKE '%Nominated%' THEN 1 ELSE 0 END AS `Recognition_flag`
  FROM `table_1_16254861_1`
) 
WHERE `Indigenous_count` > 0 OR `Recognition_flag` = 1
ORDER BY `Priority_score` DESC, `Indigenous_count` DESC, `Year (Ceremony)` ASC;
","
SELECT 
  col1,
  col0,
  col3,
  col2,
  RTRIM(`_matches_raw`, ', ') AS `Indigenous languages (matched)`,
  `Indigenous_count`,
  col4,
  CASE 
    WHEN `Indigenous_count` > 0 AND `Recognition_flag` = 1 THEN 'High' 
    WHEN `Indigenous_count` > 0 THEN 'Medium' 
    WHEN `Recognition_flag` = 1 THEN 'Low' 
    ELSE 'Low' 
  END AS `Priority`,
  CASE 
    WHEN `Indigenous_count` > 0 AND `Recognition_flag` = 1 THEN 3 
    WHEN `Indigenous_count` > 0 THEN 2 
    WHEN `Recognition_flag` = 1 THEN 1 
    ELSE 0 
  END AS `Priority_score`
FROM (
  SELECT 
    col1,
    col0,
    col3,
    col2,
    col4,
    (CASE WHEN col2 LIKE '%Yolngu Matha%' THEN '`Yolngu Matha`, ' ELSE '' END ||
     CASE WHEN col2 LIKE '%Gunwinggu%' THEN '`Gunwinggu`, ' ELSE '' END ||
     CASE WHEN col2 LIKE '%Warlpiri%' THEN '`Warlpiri`, ' ELSE '' END) AS `_matches_raw`,
    (CASE WHEN col2 LIKE '%Yolngu Matha%' THEN 1 ELSE 0 END) +
    (CASE WHEN col2 LIKE '%Gunwinggu%' THEN 1 ELSE 0 END) +
    (CASE WHEN col2 LIKE '%Warlpiri%' THEN 1 ELSE 0 END) AS `Indigenous_count`,
    CASE WHEN col4 LIKE '%Shortlist%' OR col4 LIKE '%Nominated%' THEN 1 ELSE 0 END AS `Recognition_flag`
  FROM `table_1_16254861_1`
) 
WHERE `Indigenous_count` > 0 OR `Recognition_flag` = 1
ORDER BY `Priority_score` DESC, `Indigenous_count` DESC, col0 ASC;
","[('ten canoes', '2006 (79th)', 'rolf de heer category:articles with hcards', 'yolngu matha , gunwinggu , english', '`Yolngu Matha`, `Gunwinggu`', 2, 'not nominated', 'High', 3), ('samson and delilah', '2009 (82nd)', 'warwick thornton category:articles with hcards', 'warlpiri , english', '`Warlpiri`', 1, 'made january shortlist', 'High', 3), ('floating life', '1996 (69th)', 'clara law category:articles with hcards', 'cantonese , english , german', '', 0, 'not nominated', 'Low', 1), ('la spagnola', '2001 (74th)', 'steve jacobs category:articles with hcards', 'spanish , english , italian', '', 0, 'not nominated', 'Low', 1), ('the home song stories', '2007 (80th)', 'tony ayres category:articles with hcards', 'cantonese , english , mandarin', '', 0, 'not nominated', 'Low', 1), ('lore', '2012 (85th)', 'cate shortland category:articles with hcards', 'german', '', 0, 'not nominated', 'Low', 1)]",table_1_16254861_1,"I'm curating screenings and will reach out to directors, so I'd phrase the ask practically and not in technical SQL terms. The query filters for films containing Yolngu Matha, Gunwinggu, or Warlpiri or films with shortlist/nominated results and builds a match string, counts matches, and flags recognition. The schema maps to film title, ceremony year, director, languages, matched Indigenous languages, an Indigenous count, result, and a derived priority and numeric score. I want the highest priority entries first so I can focus contacts and rights negotiation.",persona,"A mobile-archive curator who organizes community screenings and language-revitalization workshops using Australian Academy Award foreign-language submissions that feature Indigenous and minority languages. Goals: Identify submitted Australian films that contain Indigenous Australian languages (for targeted community screenings and language-resource development). Prioritize films with festival/award recognition (shortlisted or nominated) to increase local attendance and grant success. Build a short list of directors to contact for screening rights, Q&As, and to source language consultants and archival materials. Example Queries: SELECT `Film title used in nomination`, `Year (Ceremony)`, `Language(s)`, `Director` FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Yolngu Matha%' OR `Language(s)` LIKE '%Warlpiri%' OR `Language(s)` LIKE '%Gunwinggu%'; SELECT `Film title used in nomination`, `Year (Ceremony)`, `Result`, `Director` FROM `table_1_16254861_1` WHERE `Result` LIKE '%Shortlist%' OR `Result` LIKE '%Nominated%'; SELECT 'Yolngu Matha' AS language, COUNT(*) AS films FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Yolngu Matha%' UNION ALL SELECT 'Warlpiri', COUNT(*) FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Warlpiri%' UNION ALL SELECT 'Gunwinggu', COUNT(*) FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Gunwinggu%' UNION ALL SELECT 'Cantonese', COUNT(*) FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Cantonese%' UNION ALL SELECT 'German', COUNT(*) FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%German%';",reward,,
"Show me states with their interview and swimsuit scores, the absolute interview–swimsuit difference, the improvement from preliminary to semifinal, semifinal rank, and the coaching-priority label so I can spot and prioritize inconsistencies.","
WITH scores AS (
  SELECT
    `State`,
    CAST(SUBSTR(`Preliminary Average`, 1, INSTR(`Preliminary Average`, ' (') - 1) AS NUMERIC) AS preliminary_score,
    CAST(SUBSTR(`Interview`, 1, INSTR(`Interview`, ' (') - 1) AS NUMERIC) AS interview_score,
    CAST(SUBSTR(`Swimsuit`, 1, INSTR(`Swimsuit`, ' (') - 1) AS NUMERIC) AS swimsuit_score,
    CAST(SUBSTR(`Evening Gown`, 1, INSTR(`Evening Gown`, ' (') - 1) AS NUMERIC) AS eveninggown_score,
    CAST(SUBSTR(`Semifinal Average`, 1, INSTR(`Semifinal Average`, ' (') - 1) AS NUMERIC) AS semifinal_score
  FROM `table_1_16268026_3`
),
maxes AS (
  SELECT
    MAX(preliminary_score) AS max_prelim,
    MAX(interview_score) AS max_interview,
    MAX(swimsuit_score) AS max_swimsuit,
    MAX(eveninggown_score) AS max_evening,
    MAX(semifinal_score) AS max_semifinal
  FROM scores
)
SELECT
  s.`State`,
  ROUND(s.preliminary_score, 3) AS `Preliminary Score`,
  ROUND(s.interview_score, 3) AS `Interview Score`,
  ROUND(s.swimsuit_score, 3) AS `Swimsuit Score`,
  ROUND(s.eveninggown_score, 3) AS `Evening Gown Score`,
  ROUND(s.semifinal_score, 3) AS `Semifinal Score`,
  ROUND(s.semifinal_score - s.preliminary_score, 3) AS `Improvement (Semifinal - Preliminary)`,
  ROUND(ABS(s.interview_score - s.swimsuit_score), 3) AS `Interview vs Swimsuit Diff`,
  (
    CASE WHEN s.preliminary_score = m.max_prelim THEN 'Preliminary' ELSE '' END ||
    CASE WHEN s.interview_score = m.max_interview THEN (CASE WHEN s.preliminary_score = m.max_prelim THEN ', Interview' ELSE 'Interview' END) ELSE '' END ||
    CASE WHEN s.swimsuit_score = m.max_swimsuit THEN (CASE WHEN (s.preliminary_score = m.max_prelim OR s.interview_score = m.max_interview) THEN ', Swimsuit' ELSE 'Swimsuit' END) ELSE '' END ||
    CASE WHEN s.eveninggown_score = m.max_evening THEN (CASE WHEN (s.preliminary_score = m.max_prelim OR s.interview_score = m.max_interview OR s.swimsuit_score = m.max_swimsuit) THEN ', Evening Gown' ELSE 'Evening Gown' END) ELSE '' END ||
    CASE WHEN s.semifinal_score = m.max_semifinal THEN (CASE WHEN (s.preliminary_score = m.max_prelim OR s.interview_score = m.max_interview OR s.swimsuit_score = m.max_swimsuit OR s.eveninggown_score = m.max_evening) THEN ', Semifinal' ELSE 'Semifinal' END) ELSE '' END
  ) AS `Category Leader Flags`,
  RANK() OVER (ORDER BY s.semifinal_score DESC) AS `Semifinal Rank`,
  CASE
    WHEN (s.semifinal_score - s.preliminary_score) >= 0.200 OR ABS(s.interview_score - s.swimsuit_score) >= 0.600 THEN 'High'
    WHEN (s.semifinal_score - s.preliminary_score) >= 0.100 OR ABS(s.interview_score - s.swimsuit_score) >= 0.350 THEN 'Medium'
    ELSE 'Low'
  END AS `Coaching Priority`
FROM scores s
CROSS JOIN maxes m
ORDER BY `Improvement (Semifinal - Preliminary)` DESC, `Semifinal Score` DESC;
","WITH scores AS (
  SELECT
    col0,
    CAST(SUBSTR(col1, 1, INSTR(col1, ' (') - 1) AS NUMERIC) AS preliminary_score,
    CAST(SUBSTR(col2, 1, INSTR(col2, ' (') - 1) AS NUMERIC) AS interview_score,
    CAST(SUBSTR(col3, 1, INSTR(col3, ' (') - 1) AS NUMERIC) AS swimsuit_score,
    CAST(SUBSTR(col4, 1, INSTR(col4, ' (') - 1) AS NUMERIC) AS eveninggown_score,
    CAST(SUBSTR(col5, 1, INSTR(col5, ' (') - 1) AS NUMERIC) AS semifinal_score
  FROM `table_1_16268026_3`
)
SELECT
  s.col0,
  ROUND(s.preliminary_score, 3) AS `Preliminary Score`,
  ROUND(s.interview_score, 3) AS `Interview Score`,
  ROUND(s.swimsuit_score, 3) AS `Swimsuit Score`,
  ROUND(s.eveninggown_score, 3) AS `Evening Gown Score`,
  ROUND(s.semifinal_score, 3) AS `Semifinal Score`,
  ROUND(s.semifinal_score - s.preliminary_score, 3) AS `Improvement (Semifinal - Preliminary)`,
  ROUND(ABS(s.interview_score - s.swimsuit_score), 3) AS `Interview vs Swimsuit Diff`,
  (
    CASE WHEN s.preliminary_score = (SELECT MAX(preliminary_score) FROM scores) THEN 'Preliminary' ELSE '' END ||
    CASE WHEN s.interview_score = (SELECT MAX(interview_score) FROM scores) THEN (CASE WHEN s.preliminary_score = (SELECT MAX(preliminary_score) FROM scores) THEN ', Interview' ELSE 'Interview' END) ELSE '' END ||
    CASE WHEN s.swimsuit_score = (SELECT MAX(swimsuit_score) FROM scores) THEN (CASE WHEN (s.preliminary_score = (SELECT MAX(preliminary_score) FROM scores) OR s.interview_score = (SELECT MAX(interview_score) FROM scores)) THEN ', Swimsuit' ELSE 'Swimsuit' END) ELSE '' END ||
    CASE WHEN s.eveninggown_score = (SELECT MAX(eveninggown_score) FROM scores) THEN (CASE WHEN (s.preliminary_score = (SELECT MAX(preliminary_score) FROM scores) OR s.interview_score = (SELECT MAX(interview_score) FROM scores) OR s.swimsuit_score = (SELECT MAX(swimsuit_score) FROM scores)) THEN ', Evening Gown' ELSE 'Evening Gown' END) ELSE '' END ||
    CASE WHEN s.semifinal_score = (SELECT MAX(semifinal_score) FROM scores) THEN (CASE WHEN (s.preliminary_score = (SELECT MAX(preliminary_score) FROM scores) OR s.interview_score = (SELECT MAX(interview_score) FROM scores) OR s.swimsuit_score = (SELECT MAX(swimsuit_score) FROM scores) OR s.eveninggown_score = (SELECT MAX(eveninggown_score) FROM scores)) THEN ', Semifinal' ELSE 'Semifinal' END) ELSE '' END
  ) AS `Category Leader Flags`,
  (SELECT 1 + COUNT(*) FROM scores s2 WHERE s2.semifinal_score > s.semifinal_score) AS `Semifinal Rank`,
  CASE
    WHEN (s.semifinal_score - s.preliminary_score) >= 0.200 OR ABS(s.interview_score - s.swimsuit_score) >= 0.600 THEN 'High'
    WHEN (s.semifinal_score - s.preliminary_score) >= 0.100 OR ABS(s.interview_score - s.swimsuit_score) >= 0.350 THEN 'Medium'
    ELSE 'Low'
  END AS `Coaching Priority`
FROM scores s
ORDER BY `Improvement (Semifinal - Preliminary)` DESC, `Semifinal Score` DESC;","[('texas', 9.084, 9.425, 9.535, 9.601, 9.52, 0.436, 0.11, 'Preliminary, Interview, Swimsuit, Evening Gown, Semifinal', 1, 'High'), ('new jersey', 8.51, 8.626, 8.712, 9.165, 8.834, 0.324, 0.086, '', 3, 'High'), ('oklahoma', 8.662, 8.88, 8.762, 9.214, 8.952, 0.29, 0.118, '', 2, 'High'), ('colorado', 8.388, 8.638, 8.432, 8.786, 8.618, 0.23, 0.206, '', 6, 'High'), ('california', 8.659, 8.313, 8.977, 8.774, 8.688, 0.029, 0.664, '', 5, 'High'), ('pennsylvania', 8.58, 8.534, 8.467, 8.613, 8.538, -0.042, 0.067, '', 7, 'Low'), ('arizona', 8.529, 7.792, 8.833, 8.703, 8.442, -0.087, 1.041, '', 8, 'High'), ('louisiana', 8.829, 8.6, 8.82, 8.71, 8.71, -0.119, 0.22, '', 4, 'Low'), ('illinois', 8.501, 7.988, 8.432, 8.681, 8.367, -0.134, 0.444, '', 9, 'Medium')]",table_1_16268026_3,"I routinely screen for big interview vs swimsuit discrepancies to prioritize coaching areas and I speak plainly about gaps. The SQL computes the absolute interview–swimsuit difference and combines that with improvement to assign a coaching-priority label. It uses the parsed interview and swimsuit scores plus improvement and priority per State. Draft: Show states with their interview and swimsuit scores, the absolute difference, the improvement from prelim to semifinal, semifinal rank, and coaching-priority so I can spot inconsistencies. Those exact fields are returned by the query and used to set priorities.",persona,"Pageant coach and performance analyst who trains contestants and reviews historical scoring to identify strengths, weaknesses, and scoring trends; uses this database to tailor training focus and benchmark competitors. Focuses on numeric score patterns across categories to inform coaching decisions and prep priorities. Goals: Identify which states (contestants) scored highest overall and in specific categories to set performance benchmarks. Find contestants who showed the biggest improvement from preliminary rounds to the semifinals to study effective preparation or on-stage adaptations. Detect category-specific inconsistencies (e.g., big gaps between interview and swimsuit scores) to prioritize coaching areas for a contestant. Example Queries: WITH scores AS (
  SELECT State,
    CAST(SUBSTR(""Preliminary Average"", 1, INSTR(""Preliminary Average"", ' (') - 1) AS NUMERIC) AS preliminary_score,
    CAST(SUBSTR(""Interview"", 1, INSTR(""Interview"", ' (') - 1) AS NUMERIC) AS interview_score,
    CAST(SUBSTR(""Swimsuit"", 1, INSTR(""Swimsuit"", ' (') - 1) AS NUMERIC) AS swimsuit_score,
    CAST(SUBSTR(""Evening Gown"", 1, INSTR(""Evening Gown"", ' (') - 1) AS NUMERIC) AS eveninggown_score,
    CAST(SUBSTR(""Semifinal Average"", 1, INSTR(""Semifinal Average"", ' (') - 1) AS NUMERIC) AS semifinal_score
  FROM table_1_16268026_3
)
SELECT State, preliminary_score, interview_score, swimsuit_score, eveninggown_score, semifinal_score
FROM scores
ORDER BY semifinal_score DESC
LIMIT 3; WITH scores AS (
  SELECT State,
    CAST(SUBSTR(""Preliminary Average"", 1, INSTR(""Preliminary Average"", ' (') - 1) AS NUMERIC) AS preliminary_score,
    CAST(SUBSTR(""Semifinal Average"", 1, INSTR(""Semifinal Average"", ' (') - 1) AS NUMERIC) AS semifinal_score
  FROM table_1_16268026_3
)
SELECT State, preliminary_score, semifinal_score, (semifinal_score - preliminary_score) AS improvement
FROM scores
WHERE preliminary_score IS NOT NULL AND semifinal_score IS NOT NULL
ORDER BY improvement DESC; WITH scores AS (
  SELECT State,
    CAST(SUBSTR(""Interview"", 1, INSTR(""Interview"", ' (') - 1) AS NUMERIC) AS interview_score,
    CAST(SUBSTR(""Swimsuit"", 1, INSTR(""Swimsuit"", ' (') - 1) AS NUMERIC) AS swimsuit_score
  FROM table_1_16268026_3
)
SELECT State, interview_score, swimsuit_score, ROUND(ABS(interview_score - swimsuit_score), 3) AS diff
FROM scores
ORDER BY diff DESC
LIMIT 5;",reward,,
"Which distinct provinces, showing Province, U.N. Region, Population, Area (km²), the province's density ((Population*1.0)/Area (km²)), and the region's avg_density (AVG((Population*1.0)/Area (km²)) with region total_pop = SUM(Population)), result from joining provinces to regional_stats by U.N. Region where Area (km²) > 0 and (Population*1.0)/Area (km²) >= avg_density, ordered by U.N. Region and limited to 20 rows?","
WITH `regional_stats` AS (
  SELECT `U.N. Region`, AVG((`Population`*1.0)/`Area (km²)`) `avg_density`, SUM(`Population`) `total_pop`
  FROM `table_1_16278349_1`
  GROUP BY `U.N. Region`
)
SELECT DISTINCT t.`Province`, t.`U.N. Region`, t.`Population`, t.`Area (km²)`, (t.`Population`*1.0)/t.`Area (km²)` `density`, rs.`avg_density`
FROM `table_1_16278349_1` t NATURAL JOIN `regional_stats` rs
WHERE t.`Area (km²)` > 0 AND (t.`Population`*1.0)/t.`Area (km²)` >= rs.`avg_density`
ORDER BY `U.N. Region`
LIMIT 20;
","
WITH `regional_stats` AS (
  SELECT col8, AVG((col4*1.0)/col5) `avg_density`, SUM(col4) `total_pop`
  FROM `table_1_16278349_1`
  GROUP BY col8
)
SELECT DISTINCT t.col0, t.col8, t.col4, t.col5, (t.col4*1.0)/t.col5 `density`, rs.`avg_density`
FROM `table_1_16278349_1` t NATURAL JOIN `regional_stats` rs
WHERE t.col5 > 0 AND (t.col4*1.0)/t.col5 >= rs.`avg_density`
ORDER BY col8
LIMIT 20;
","[('kabul', 'central afghanistan', 3314000.0, 4462.0, 742.716270730614, 202.79606191529194), ('laghman', 'east afghanistan', 373000.0, 3843.0, 97.05958886286756, 78.7720890822952), ('nangarhar', 'east afghanistan', 1089000.0, 7727.0, 140.93438591950303, 78.7720890822952), ('bamyan', 'east central afghanistan', 387300.0, 14175.0, 27.322751322751323, 20.30903595908119), ('balkh', 'north afghanistan', 1096100.0, 17249.0, 63.545712794944635, 40.93523900980449), ('kunduz', 'north east afghanistan', 820000.0, 8040.0, 101.99004975124379, 55.82495698309521), ('takhar', 'north east afghanistan', 810800.0, 12333.0, 65.74231735992865, 55.82495698309521), ('khost', 'south afghanistan', 300000.0, 4152.0, 72.25433526011561, 48.86796226148603), ('paktia', 'south afghanistan', 415000.0, 6432.0, 64.52114427860697, 48.86796226148603), ('daykundi', 'south west afghanistan', 399600.0, 8088.0, 49.40652818991098, 21.95675063217619), ('orūzgān', 'south west afghanistan', 627000.0, 22696.0, 27.626013394430736, 21.95675063217619), ('faryab', 'west afghanistan', 858600.0, 20293.0, 42.3101562115015, 23.445780134502865)]",table_1_16278349_1,"1) Intent: compute average population density per U.N. Region (avg_density) and total population, then return provinces whose individual density >= their region's avg_density along with relevant fields. 2) Map semantics to table columns and expressions exactly as in SQL. 3) Draft a question asking for Province, U.N. Region, Population, Area (km²), density = (Population*1.0)/Area (km²), and avg_density = AVG((Population*1.0)/Area (km²)) with total_pop = SUM(Population), joined by U.N. Region, filtered by Area (km²) > 0 and density >= avg_density, ordered by U.N. Region, limited to 20. 4) Validate inclusion of DISTINCT, join, filter, order and limit.",reserved,16,reward,,
"For counties where Towns/ villages is at least 100 and Area (km²) is under 5000, return Name of county, County seat, Area (km²), Population, Population density, Towns/ villages, Area per town (Area (km²) / Towns/ villages), Population per town (Population / Towns/ villages), Density delta (Population density - (Population / Area (km²))), and Computed/Reported ratio ((Population / Area (km²)) / Population density), sorted by Population per town descending and limited to 5 entries?","
SELECT `Name of county`, `County seat`, `Area (km²)`, `Population`, `Population density`, `Towns/ villages`, (`Area (km²)` / `Towns/ villages`) AS `Area per town`, (`Population` / `Towns/ villages`) `Population per town`, ((`Population density`) - (`Population` / `Area (km²)`)) `Density delta`, ((`Population` / `Area (km²)`) / NULLIF(`Population density`,0)) `Computed/Reported ratio` FROM `table_1_16278825_1` WHERE `Towns/ villages` >= 100 AND `Area (km²)` < 5000 ORDER BY -(`Population` / `Towns/ villages`) LIMIT 5;
","
SELECT col0, col1, col2, col3, col4, col5, (col2 / col5) AS `Area per town`, (col3 / col5) `Population per town`, ((col4) - (col3 / col2)) `Density delta`, ((col3 / col2) / NULLIF(col4,0)) `Computed/Reported ratio` FROM `table_1_16278825_1` WHERE col5 >= 100 AND col2 < 5000 ORDER BY -(col3 / col5) LIMIT 5;
","[('fejér', 'székesfehérvár', 4359.0, 428579.0, 98.0, 108.0, 40.361111111111114, 3968.324074074074, -0.32048635008028725, 1.0032702688783703), ('heves', 'eger', 3637.0, 323769.0, 89.0, 119.0, 30.563025210084035, 2720.747899159664, -0.020896343139952478, 1.000234790372359), ('győr-moson-sopron', 'győr', 4208.0, 440138.0, 105.0, 182.0, 23.12087912087912, 2418.3406593406594, 0.4044676806083629, 0.9961479268513489), ('tolna', 'szekszárd', 3703.0, 247287.0, 67.0, 108.0, 34.28703703703704, 2289.6944444444443, 0.21982176613556703, 0.9967190781173796), ('veszprém', 'veszprém', 4493.0, 368519.0, 82.0, 217.0, 20.705069124423964, 1698.2442396313363, -0.020698864900950298, 1.0002524251817189)]",table_1_16278825_1,"Parse: selection includes base columns plus four computed fields, filtered by Towns/ villages and Area, sorted by decreasing Population per town, limited to five. Map: computations derived from Area (km²), Population, Population density, and Towns/ villages columns. Draft: ask to return those columns and computations for counties matching the filters, top 5 by Population per town. Validate: question contains all requested fields, calculations, filter conditions, ordering direction, and limit.",reserved,8,reward,,
"For each Series (grouped by Series) and considering only records where Release is not an empty string and Title is not an empty string, report the Series, the number of Titles as Total Titles (COUNT(Title)), the number of Writers as Total Writers (COUNT(Writer)), the count of rows with Length = '70\'' as Count 70' (SUM(Length = '70\'')), the count of rows with Length = '60\'' as Count 60' (SUM(Length = '60\'')), the earliest Release Date (MIN(Release Date) AS Earliest Release) and the latest Release Date (MAX(Release Date) AS Latest Release), include only Series with more than one Title (HAVING COUNT(Title) > 1), order by Total Titles and return up to 10 rows?","
SELECT `Series`, COUNT(`Title`) AS `Total Titles`, COUNT(`Writer`) `Total Writers`, SUM(`Length` = '70''' ) `Count 70'`, SUM(`Length` = '60''' ) `Count 60'`, MIN(`Release Date`) `Earliest Release`, MAX(`Release Date`) `Latest Release`
FROM `table_1_16279520_1`
WHERE `Release` <> '' AND `Title` <> ''
GROUP BY `Series`
HAVING COUNT(`Title`) > 1
ORDER BY `Total Titles`
LIMIT 10;
","
SELECT col1, COUNT(col0) AS `Total Titles`, COUNT(col4) `Total Writers`, SUM(col6 = '70''' ) `Count 70'`, SUM(col6 = '60''' ) `Count 60'`, MIN(col8) `Earliest Release`, MAX(col8) `Latest Release`
FROM `table_1_16279520_1`
WHERE col2 <> '' AND col0 <> ''
GROUP BY col1
HAVING COUNT(col0) > 1
ORDER BY `Total Titles`
LIMIT 10;
","[('stargate atlantis', 6, 6, 3, 3, 'august 31, 2009', 'september 2008'), ('stargate sg-1', 10, 10, 4, 6, 'april 1, 2008', 'may 30, 2009')]",table_1_16279520_1,"Parse SQL intent: group by Series and compute title and writer counts, counts of Length equal to '70\'' and '60\'', and earliest/latest release dates; exclude empty Release or Title rows, require more than one title per series, order by total titles and cap results at ten. Map schema semantics: map Title, Writer, Length, Release Date to their respective aggregates. Draft question: enumerate each requested aggregate and all query conditions. Validate: confirm inclusion of conditional length counts, min/max dates, non-empty filters, HAVING, ORDER BY and LIMIT clauses.",reserved,10,reward,,
"Which countries have the most wins in tournaments since 2002 with purses of at least $1,300,000?","
SELECT DISTINCT `Country`, COUNT(`Year`) wins_count, ROUND(AVG(`Score`),2) avg_score, MIN((REPLACE(REPLACE(`Margin of victory`,` strokes`,``),` stroke`,``)) + 0) best_margin, SUM(`Purse ( US $ )`) total_purse, GROUP_CONCAT('`' || `Champion` || '`', '; ') champions_list
FROM `table_1_1628792_1`
WHERE `Year` >= 2002 AND `Purse ( US $ )` >= 1300000
GROUP BY `Country`
LIMIT 10;
","SELECT DISTINCT col3, COUNT(col0) AS wins_count, ROUND(AVG(col4),2) AS avg_score, MIN(REPLACE(REPLACE(col6, ' strokes', ''), ' stroke', '') + 0) AS best_margin, SUM(col8) AS total_purse, GROUP_CONCAT(col2, '; ') AS champions_list
FROM `table_1_1628792_1`
WHERE col0 >= 2002 AND col8 >= 1300000
GROUP BY col3
LIMIT 10;","[('australia', 1, 277.0, 1, 2250000.0, 'katherine hull'), ('mexico', 1, 268.0, 3, 2250000.0, 'lorena ochoa'), ('new zealand', 2, 270.0, 3, 4000000.0, 'lydia ko (a) (2); lydia ko (a)'), ('south korea', 1, 279.0, 1, 1300000.0, 'meena lee'), ('united states', 5, 274.6, 1, 8800000.0, 'brittany lincicome; michelle wie; cristie kerr; meg mallon (3); beth daniel')]",table_1_1628792_1,"STEP 1: Parse the SQL intent — aggregate per Country (GROUP BY Country) the number of wins (COUNT(Year)), average Score, minimum numeric Margin of victory (converted from text), total Purse sum, and a semicolon-separated list of Champions; restrict rows to Year >= 2002 and Purse >= 1,300,000; return up to 10 countries. STEP 2: Choose an ambiguity type — Entity vagueness fits well because the word “countries” could refer either to the champion's nationality (the table's Country column) or to the country where the tournament was held (Tournament location). STEP 3: Draft the question — create a natural-language question that matches the SQL's intent but is ambiguous: ""Which countries have the most wins in tournaments since 2002 with purses of at least $1,300,000?"" STEP 4: Explain the ambiguity — in the original query ""Country"" is the champion's nationality so the SQL returns wins by winners' countries, but the NL phrasing could instead mean host countries (where tournaments took place) or even mix both; a different interpretation would aggregate wins by tournament host country rather than by winners' nationality, yielding different counts and lists of champions.",reserved,8,reward,,"type: Entity Vagueness | explanation: The SQL groups by the table's Country column (champion nationality), so it counts wins by winners' countries; however, the natural-language question could equally be read as asking about host countries (the country of the Tournament location) or another country-level notion, producing a different aggregation and result set."
"Which five years (where year = '20' concatenated with the last two characters of Dates (MDY) and year >= 2008) have the highest total Gross sales, and for each of those years what are: the total Gross sales (sum after stripping '$' and commas), the average Sellout (%) (average after stripping '%'), the total Tickets sold (sum of the portion before '/' with commas removed), the total Tickets available (sum of the portion after '/' with commas removed), and the average gross per show (total gross sales divided by number of rows)?","
SELECT '20' || SUBSTR(`Dates (MDY)`, -2),
 SUM(REPLACE(REPLACE(`Gross sales`,'$',''),',','')),
 AVG(REPLACE(`Sellout (%)`,'%','')),
 SUM(TRIM(REPLACE(SUBSTR(`Tickets sold / available`,1,INSTR(`Tickets sold / available`,'/')-1),',',''))),
 SUM(TRIM(REPLACE(SUBSTR(`Tickets sold / available`,INSTR(`Tickets sold / available`,'/')+1),',',''))),
 SUM(REPLACE(REPLACE(`Gross sales`,'$',''),',',''))/COUNT(*)
FROM `table_1_16331025_2`
WHERE '20' || SUBSTR(`Dates (MDY)`, -2) >= '2008'
GROUP BY '20' || SUBSTR(`Dates (MDY)`, -2)
ORDER BY SUM(REPLACE(REPLACE(`Gross sales`,'$',''),',','')) DESC
LIMIT 5;
","
SELECT '20' || SUBSTR(col0, -2),
 SUM(REPLACE(REPLACE(col2,'$',''),',','')),
 AVG(REPLACE(col4,'%','')),
 SUM(TRIM(REPLACE(SUBSTR(col3,1,INSTR(col3,'/')-1),',',''))),
 SUM(TRIM(REPLACE(SUBSTR(col3,INSTR(col3,'/')+1),',',''))),
 SUM(REPLACE(REPLACE(col2,'$',''),',',''))/COUNT(*)
FROM `table_1_16331025_2`
WHERE '20' || SUBSTR(col0, -2) >= '2008'
GROUP BY '20' || SUBSTR(col0, -2)
ORDER BY SUM(REPLACE(REPLACE(col2,'$',''),',','')) DESC
LIMIT 5;
","[('2010', 32606485, 83.38461538461539, 259879, 307197, 2508191), ('2009', 28624073, 87.81818181818181, 197720, 224360, 2602188), ('2008', 26811086, 99.08333333333333, 176888, 178305, 2234257), ('2011', 9379654, 95.0, 63278, 66694, 4689827)]",table_1_16331025_2,"1) The SQL aggregates by a year derived from Dates (MDY), computes SUM of cleaned Gross sales, AVG of cleaned Sellout (%), SUMs of the split Tickets sold and Tickets available, and average gross per entry, filtering to years >= 2008 and returning the 5 years with largest total gross. 2) Map columns: Dates (MDY) -> year via '20' + last two chars; Gross sales needs $/comma removal; Sellout (%) needs '%' removal; Tickets sold / available must be split on '/' and commas removed. 3) Draft a question requesting those exact metrics per derived year with the stated filter, grouping, ordering, and limit. 4) Confirm all calculations and filters from the query are explicitly mentioned.",reserved,8,reward,,
Which teams had a higher overall winning percentage than their ACC winning percentage and were stronger at home?,"
SELECT DISTINCT `Team`, `ACC %`, `All Games %`, (`All Games %` - `ACC %`) AS `Conf_vs_All_Diff`, CASE WHEN (`All Home` > `All Road`) THEN '`Stronger at Home`' END FROM `table_1_16372244_1` WHERE `All Games %` <> '' LIMIT 8;
","
SELECT DISTINCT col0, col2, col6, (col6 - col2) AS `Conf_vs_All_Diff`, CASE WHEN (col7 > col8) THEN '`Stronger at Home`' END FROM `table_1_16372244_1` WHERE col6 <> '' LIMIT 8;
","[('maryland', '.938', '.889', -0.04899999999999993, None), ('duke', '.813', '.886', 0.07300000000000006, None), ('wake forest', '.563', '.618', 0.05500000000000005, None), ('north carolina state', '.563', '.676', 0.1130000000000001, None), ('virginia', '.563', '.586', 0.02300000000000002, None), ('georgia tech', '.437', '.484', 0.046999999999999986, '`Stronger at Home`'), ('north carolina', '.250', '.286', 0.035999999999999976, '`Stronger at Home`'), ('florida state', '.250', '.414', 0.16399999999999998, None)]",table_1_16372244_1,"STEP 1: Parse the SQL intent — the query selects Team, ACC %, All Games %, computes (All Games % - ACC %) as Conf_vs_All_Diff, and adds the literal 'Stronger at Home' when All Home > All Road; it filters out rows with empty All Games % and returns up to 8 distinct rows. STEP 2: Choose an ambiguity type — scope ambiguity fits well because the query both computes the conference-vs-all difference and conditionally labels teams as 'Stronger at Home', so a natural language phrasing that uses 'and' can be read either as (a) a conjunction filter (teams satisfying both conditions) or (b) a request to report both pieces of information for teams. The LIMIT 8 / lack of ordering also introduces a secondary ambiguity about which subset is returned. STEP 3: Draft the question — see question field below. STEP 4: Explain the ambiguity — in the original query the 'and' is interpreted as computing and showing both values for each team (difference and a home-strength label) without filtering by home strength; an alternative interpretation of the same wording would be to filter to only those teams that both improved overall vs ACC and were stronger at home, or to return the single best-improving team rather than a (limited) set.",reserved,10,reward,,"type: Scope ambiguity | explanation: The phrase 'and were stronger at home' can be read two ways: (1) as a request to show both pieces of information for each team (the SQL's interpretation: compute the difference and label teams that meet All Home > All Road), or (2) as a filter requiring teams to satisfy both conditions (only include teams with All Games % > ACC % AND All Home > All Road). Additionally, because the query has no ORDER BY and uses LIMIT 8, it's also ambiguous which subset of teams is returned."
"Which teams played at least three neutral games and earned 'Exceptional Neutral' (≥.75) or 'Solid Neutral' (≥.50) status — list their neutral games, neutral win %, overall %, anomaly tag and designer composite score?","
WITH parsed AS (
  SELECT
    `Team`,
    CAST(substr(`ACC Regular Season`, 1, instr(`ACC Regular Season`, '–') - 1) AS INTEGER) AS acc_wins,
    CAST(substr(`ACC Regular Season`, instr(`ACC Regular Season`, '–') + 1) AS INTEGER) AS acc_losses,
    CAST(substr(`All Home`, 1, instr(`All Home`, '–') - 1) AS INTEGER) AS home_wins,
    CAST(substr(`All Home`, instr(`All Home`, '–') + 1) AS INTEGER) AS home_losses,
    CAST(substr(`All Road`, 1, instr(`All Road`, '–') - 1) AS INTEGER) AS road_wins,
    CAST(substr(`All Road`, instr(`All Road`, '–') + 1) AS INTEGER) AS road_losses,
    CAST(substr(`All Neutral`, 1, instr(`All Neutral`, '–') - 1) AS INTEGER) AS neutral_wins,
    CAST(substr(`All Neutral`, instr(`All Neutral`, '–') + 1) AS INTEGER) AS neutral_losses,
    CAST(`All Games %` AS REAL) AS overall_pct
  FROM `table_1_16372911_1`
),
metrics AS (
  SELECT
    `Team`,
    acc_wins, acc_losses,
    home_wins, home_losses,
    road_wins, road_losses,
    neutral_wins, neutral_losses,
    overall_pct,
    (home_wins + home_losses) AS home_games,
    (road_wins + road_losses) AS road_games,
    (neutral_wins + neutral_losses) AS neutral_games,
    CASE WHEN (home_wins + home_losses) > 0 THEN home_wins * 1.0 / (home_wins + home_losses) ELSE NULL END AS home_win_pct,
    CASE WHEN (road_wins + road_losses) > 0 THEN road_wins * 1.0 / (road_wins + road_losses) ELSE NULL END AS road_win_pct,
    CASE WHEN (neutral_wins + neutral_losses) > 0 THEN neutral_wins * 1.0 / (neutral_wins + neutral_losses) ELSE NULL END AS neutral_win_pct,
    CASE WHEN (acc_wins + acc_losses) > 0 THEN acc_wins * 1.0 / (acc_wins + acc_losses) ELSE NULL END AS acc_win_pct
  FROM parsed
)
SELECT
  `Team`,
  -- original recorded strings reconstructed for clarity
  (acc_wins || '–' || acc_losses) AS `ACC Regular Season`,
  (home_wins || '–' || home_losses) AS `All Home`,
  (road_wins || '–' || road_losses) AS `All Road`,
  (neutral_wins || '–' || neutral_losses) AS `All Neutral`,
  printf('%.3f', overall_pct) AS `All Games %`,
  -- core parsed metrics
  home_wins AS `Home Wins`, home_losses AS `Home Losses`, home_games AS `Home Games`,
  road_wins AS `Road Wins`, road_losses AS `Road Losses`, road_games AS `Road Games`,
  neutral_wins AS `Neutral Wins`, neutral_losses AS `Neutral Losses`, neutral_games AS `Neutral Games`,
  printf('%.3f', home_win_pct) AS `Home Win %`,
  printf('%.3f', road_win_pct) AS `Road Win %`,
  printf('%.3f', neutral_win_pct) AS `Neutral Win %`,
  printf('%.3f', acc_win_pct) AS `ACC Win %`,
  -- actionable designer metrics
  printf('%.3f', (road_win_pct - home_win_pct)) AS `Travel Bias (road - home)`,
  printf('%.3f', (neutral_win_pct - overall_pct)) AS `Neutral vs Overall`,
  printf('%.3f', (overall_pct - acc_win_pct)) AS `Overall vs ACC`,
  -- anomaly tags to seed special cards (multiple flags concatenated)
  TRIM(
    CASE WHEN road_wins > home_wins THEN 'Road Warrior' ELSE '' END ||
    CASE WHEN home_wins >= road_wins + 3 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Home Fortress' ELSE 'Home Fortress' END) ELSE '' END ||
    CASE WHEN neutral_games >= 3 AND neutral_win_pct >= 0.75 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Exceptional Neutral' ELSE 'Exceptional Neutral' END) WHEN neutral_games >= 3 AND neutral_win_pct >= 0.50 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Solid Neutral' ELSE 'Solid Neutral' END) ELSE '' END ||
    CASE WHEN ABS(overall_pct - acc_win_pct) >= 0.20 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Out‑of‑Conference Divergence' ELSE 'Out‑of‑Conference Divergence' END) ELSE '' END
  ) AS `Anomaly Flags`,
  -- composite balance score to rank teams for scenario seeding (higher = more designer-interesting)
  printf('%.3f',
    (
      -- weight neutral overperformance (encourage neutral-event cards)
      2.0 * (COALESCE(neutral_win_pct,0) - overall_pct)
      -- weight travel bias (road vs home)
      + 3.0 * (COALESCE(road_win_pct,0) - COALESCE(home_win_pct,0))
      -- reward high absolute overall performance
      + 1.5 * overall_pct
      -- reward large overall vs ACC divergence (interesting asymmetry)
      + 2.0 * ABS(overall_pct - COALESCE(acc_win_pct,0))
    )
  ) AS `Designer Composite Score`
FROM metrics
ORDER BY `Designer Composite Score` DESC, `Neutral Win %` DESC, `Travel Bias (road - home)` DESC
;
","WITH parsed AS (
  SELECT
    col0,
    CASE WHEN instr(col1, '–')>0 THEN CAST(substr(col1, 1, instr(col1, '–') - 1) AS INTEGER) ELSE 0 END AS acc_wins,
    CASE WHEN instr(col1, '–')>0 THEN CAST(substr(col1, instr(col1, '–') + 1) AS INTEGER) ELSE 0 END AS acc_losses,
    CASE WHEN instr(col7, '–')>0 THEN CAST(substr(col7, 1, instr(col7, '–') - 1) AS INTEGER) ELSE 0 END AS home_wins,
    CASE WHEN instr(col7, '–')>0 THEN CAST(substr(col7, instr(col7, '–') + 1) AS INTEGER) ELSE 0 END AS home_losses,
    CASE WHEN instr(col8, '–')>0 THEN CAST(substr(col8, 1, instr(col8, '–') - 1) AS INTEGER) ELSE 0 END AS road_wins,
    CASE WHEN instr(col8, '–')>0 THEN CAST(substr(col8, instr(col8, '–') + 1) AS INTEGER) ELSE 0 END AS road_losses,
    CASE WHEN instr(col9, '–')>0 THEN CAST(substr(col9, 1, instr(col9, '–') - 1) AS INTEGER) ELSE 0 END AS neutral_wins,
    CASE WHEN instr(col9, '–')>0 THEN CAST(substr(col9, instr(col9, '–') + 1) AS INTEGER) ELSE 0 END AS neutral_losses,
    CAST(col6 AS REAL) AS overall_pct
  FROM `table_1_16372911_1`
)
SELECT
  col0,
  (acc_wins || '–' || acc_losses) AS col1,
  (home_wins || '–' || home_losses) AS col7,
  (road_wins || '–' || road_losses) AS col8,
  (neutral_wins || '–' || neutral_losses) AS col9,
  printf('%.3f', overall_pct) AS col6,
  home_wins AS `Home Wins`, home_losses AS `Home Losses`, (home_wins+home_losses) AS `Home Games`,
  road_wins AS `Road Wins`, road_losses AS `Road Losses`, (road_wins+road_losses) AS `Road Games`,
  neutral_wins AS `Neutral Wins`, neutral_losses AS `Neutral Losses`, (neutral_wins+neutral_losses) AS `Neutral Games`,
  printf('%.3f', CASE WHEN (home_wins + home_losses) > 0 THEN home_wins*1.0 / (home_wins + home_losses) ELSE NULL END) AS `Home Win %`,
  printf('%.3f', CASE WHEN (road_wins + road_losses) > 0 THEN road_wins*1.0 / (road_wins + road_losses) ELSE NULL END) AS `Road Win %`,
  printf('%.3f', CASE WHEN (neutral_wins + neutral_losses) > 0 THEN neutral_wins*1.0 / (neutral_wins + neutral_losses) ELSE NULL END) AS `Neutral Win %`,
  printf('%.3f', (CASE WHEN (road_wins + road_losses) > 0 THEN road_wins*1.0 / (road_wins + road_losses) ELSE 0 END) - (CASE WHEN (home_wins + home_losses) > 0 THEN home_wins*1.0 / (home_wins + home_losses) ELSE 0 END)) AS `Travel Bias (road - home)`
FROM parsed
ORDER BY `Neutral Win %` DESC, `Travel Bias (road - home)` DESC;","[('north carolina', '14–2', '14–2', '13–0', '9–1', '0.946', 14, 2, 16, 13, 0, 13, 9, 1, 10, '0.875', '1.000', '0.900', '0.125'), ('miami', '8–8', '14–2', '4–6', '5–3', '0.676', 14, 2, 16, 4, 6, 10, 5, 3, 8, '0.875', '0.400', '0.625', '-0.475'), ('duke', '13–3', '15–1', '8–2', '5–3', '0.824', 15, 1, 16, 8, 2, 10, 5, 3, 8, '0.938', '0.800', '0.625', '-0.137'), ('georgia tech', '7–9', '6–7', '6–8', '3–2', '0.469', 6, 7, 13, 6, 8, 14, 3, 2, 5, '0.462', '0.429', '0.600', '-0.033'), ('clemson', '10–6', '14–2', '6–5', '4–3', '0.706', 14, 2, 16, 6, 5, 11, 4, 3, 7, '0.875', '0.545', '0.571', '-0.330'), ('virginia tech', '9–7', '14–3', '4–8', '3–3', '0.600', 14, 3, 17, 4, 8, 12, 3, 3, 6, '0.824', '0.333', '0.500', '-0.490'), ('florida state', '7–9', '13–5', '4–7', '2–3', '0.559', 13, 5, 18, 4, 7, 11, 2, 3, 5, '0.722', '0.364', '0.400', '-0.359'), ('boston college', '4–12', '11–8', '2–7', '1–2', '0.452', 11, 8, 19, 2, 7, 9, 1, 2, 3, '0.579', '0.222', '0.333', '-0.357'), ('wake forest', '7–9', '15–2', '2–10', '0–1', '0.567', 15, 2, 17, 2, 10, 12, 0, 1, 1, '0.882', '0.167', '0.000', '-0.716'), ('virginia', '5–11', '13–7', '4–7', '0–2', '0.515', 13, 7, 20, 4, 7, 11, 0, 2, 2, '0.650', '0.364', '0.000', '-0.286'), ('maryland', '8–8', '13–6', '6–5', '0–4', '0.559', 13, 6, 19, 6, 5, 11, 0, 4, 4, '0.684', '0.545', '0.000', '-0.139')]",table_1_16372911_1,"I love neutral‑site quirks for tournament cards, so I'll ask for teams that stand out on neutral courts in plain terms. The SQL computes neutral win % and flags teams with at least 3 neutral games as Exceptional Neutral (≥.75) or Solid Neutral (≥.50). The table has an 'All Neutral' win–loss field that the query parses into neutral wins, losses and neutral_games. Draft question: ask which teams meet those neutral‑site thresholds and request their neutral games, neutral % and composite score. Validate: the query will return teams with those neutral flags and the requested metrics.",persona,"An indie board‑game designer crafting a 2007–08 ACC retro strategy game who needs precise home/road/neutral strengths and quirky anomalies to balance playable teams. Goals: Translate real 2007–08 ACC season performance into balanced in‑game ratings for home/road/neutral match outcomes and special event cards. Identify unusual team profiles (e.g., teams stronger on the road, exceptional neutral‑site records, or big disparities between conference and overall performance) to inspire asymmetric mechanics. Create a ranked, data‑driven playbook (top neutral performers, travel‑tough teams, conference specialists) to seed scenario cards and handicaps in the game. Example Queries: /* 1) Find teams with more road wins than home wins (useful for 'road warrior' abilities) */
SELECT ""Team"",
       split_part(""All Road"", '–', 1)::int AS road_wins,
       split_part(""All Home"", '–', 1)::int AS home_wins
FROM table_1_16372911_1
WHERE split_part(""All Road"", '–', 1)::int > split_part(""All Home"", '–', 1)::int
ORDER BY (road_wins - home_wins) DESC; /* 2) Top neutral‑site performers (neutral win % = neutral_wins / neutral_games) for special neutral‑site event cards */
SELECT ""Team"",
       ""All Neutral"",
       (split_part(""All Neutral"", '–', 1)::float / (split_part(""All Neutral"", '–', 1)::float + split_part(""All Neutral"", '–', 2)::float)) AS neutral_win_pct
FROM table_1_16372911_1
WHERE ""All Neutral"" IS NOT NULL AND ""All Neutral"" <> ''
ORDER BY neutral_win_pct DESC
LIMIT 3; /* 3) Highlight teams with largest discrepancy between overall %% and conference record (to design 'out‑of‑conference specialist' or 'conference struggler' traits) */
SELECT ""Team"",
       CAST(""All Games %"" AS float) AS overall_pct,
       (split_part(""ACC Regular Season"", '–', 1)::float / (split_part(""ACC Regular Season"", '–', 1)::float + split_part(""ACC Regular Season"", '–', 2)::float)) AS acc_pct_from_record,
       ABS(CAST(""All Games %"" AS float) - (split_part(""ACC Regular Season"", '–', 1)::float / (split_part(""ACC Regular Season"", '–', 1)::float + split_part(""ACC Regular Season"", '–', 2)::float))) AS pct_difference
FROM table_1_16372911_1
ORDER BY pct_difference DESC
LIMIT 5;",reward,,
"Using the 2006 and 2011 average domestic passenger fare values for Lansing (LAN), Detroit (DTW), Grand Rapids (GRR), Flint (FNT), Kalamazoo (AZO), and Saginaw (MBS), what is the percent change ((2011 - 2006) / 2006) * 100 for each airport, and list the airports with their pct_change in descending order?","
WITH `raw`(`Year`, `Lansing (LAN)`, `Detroit (DTW)`, `Grand Rapids (GRR)`, `Flint (FNT)`, `Kalamazoo (AZO)`, `Saginaw (MBS)`) AS (
  VALUES
  ('`2006`','`$370.61`','`$322.83`','`$413.74`','`$298.89`','`$472.93`','`$441.26`'),
  ('`2007`','`$364.39`','`$307.29`','`$420.68`','`$281.37`','`$471.01`','`$441.08`'),
  ('`2008`','`$397.75`','`$334.18`','`$463.96`','`$314.89`','`$517.32`','`$481.39`'),
  ('`2009`','`$434.59`','`$313.67`','`$409.85`','`$275.23`','`$500.55`','`$434.69`'),
  ('`2010`','`$482.76`','`$353.75`','`$377.29`','`$298.40`','`$563.92`','`$470.47`'),
  ('`2011`','`$433.59`','`$378.55`','`$400.11`','`$334.90`','`$579.23`','`$474.77`')
)
SELECT `airport`, ((`v2011` - `v2006`) / NULLIF(`v2006`,0)) * 100 AS `pct_change`
FROM (
  SELECT '`Lansing (LAN)`' AS `airport`,
    (SELECT REPLACE(REPLACE(`Lansing (LAN)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2011`') AS `v2011`,
    (SELECT REPLACE(REPLACE(`Lansing (LAN)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2006`') AS `v2006`
  UNION ALL
  SELECT '`Detroit (DTW)`',
    (SELECT REPLACE(REPLACE(`Detroit (DTW)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2011`'),
    (SELECT REPLACE(REPLACE(`Detroit (DTW)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2006`')
  UNION ALL
  SELECT '`Grand Rapids (GRR)`',
    (SELECT REPLACE(REPLACE(`Grand Rapids (GRR)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2011`'),
    (SELECT REPLACE(REPLACE(`Grand Rapids (GRR)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2006`')
  UNION ALL
  SELECT '`Flint (FNT)`',
    (SELECT REPLACE(REPLACE(`Flint (FNT)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2011`'),
    (SELECT REPLACE(REPLACE(`Flint (FNT)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2006`')
  UNION ALL
  SELECT '`Kalamazoo (AZO)`',
    (SELECT REPLACE(REPLACE(`Kalamazoo (AZO)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2011`'),
    (SELECT REPLACE(REPLACE(`Kalamazoo (AZO)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2006`')
  UNION ALL
  SELECT '`Saginaw (MBS)`',
    (SELECT REPLACE(REPLACE(`Saginaw (MBS)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2011`'),
    (SELECT REPLACE(REPLACE(`Saginaw (MBS)`,'`',''),'$','') + 0 FROM `raw` WHERE `Year` = '`2006`')
)
ORDER BY `pct_change` DESC;
","
WITH `raw`(col0, col1, col2, col3, col4, col5, col6) AS (
  VALUES
  ('`2006`','`$370.61`','`$322.83`','`$413.74`','`$298.89`','`$472.93`','`$441.26`'),
  ('`2007`','`$364.39`','`$307.29`','`$420.68`','`$281.37`','`$471.01`','`$441.08`'),
  ('`2008`','`$397.75`','`$334.18`','`$463.96`','`$314.89`','`$517.32`','`$481.39`'),
  ('`2009`','`$434.59`','`$313.67`','`$409.85`','`$275.23`','`$500.55`','`$434.69`'),
  ('`2010`','`$482.76`','`$353.75`','`$377.29`','`$298.40`','`$563.92`','`$470.47`'),
  ('`2011`','`$433.59`','`$378.55`','`$400.11`','`$334.90`','`$579.23`','`$474.77`')
)
SELECT `airport`, ((`v2011` - `v2006`) / NULLIF(`v2006`,0)) * 100 AS `pct_change`
FROM (
  SELECT 'col1' AS `airport`,
    (SELECT REPLACE(REPLACE(col1,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2011`') AS `v2011`,
    (SELECT REPLACE(REPLACE(col1,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2006`') AS `v2006`
  UNION ALL
  SELECT 'col2',
    (SELECT REPLACE(REPLACE(col2,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2011`'),
    (SELECT REPLACE(REPLACE(col2,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2006`')
  UNION ALL
  SELECT 'col3',
    (SELECT REPLACE(REPLACE(col3,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2011`'),
    (SELECT REPLACE(REPLACE(col3,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2006`')
  UNION ALL
  SELECT 'col4',
    (SELECT REPLACE(REPLACE(col4,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2011`'),
    (SELECT REPLACE(REPLACE(col4,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2006`')
  UNION ALL
  SELECT 'col5',
    (SELECT REPLACE(REPLACE(col5,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2011`'),
    (SELECT REPLACE(REPLACE(col5,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2006`')
  UNION ALL
  SELECT 'col6',
    (SELECT REPLACE(REPLACE(col6,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2011`'),
    (SELECT REPLACE(REPLACE(col6,'`',''),'$','') + 0 FROM `table_1_1637981_7` WHERE col0 = '`2006`')
)
ORDER BY `pct_change` DESC;
","[('col1', None), ('col2', None), ('col3', None), ('col4', None), ('col5', None), ('col6', None)]",table_1_1637981_7,"Parse intent: produce percent change from 2006 to 2011 for each airport and sort by that percent change descending. Map schema: use the 2006 and 2011 fare values for Lansing (LAN), Detroit (DTW), Grand Rapids (GRR), Flint (FNT), Kalamazoo (AZO), and Saginaw (MBS). Draft question: ask for the percent change calculation ((2011 - 2006)/2006)*100 for each airport and to list airport and pct_change in descending order. Validate: the question references every airport column, both years, the precise calculation, and ordering.",reserved,10,reward,,
"Which five schools (limit 5) have Enrollment equal to the maximum Enrollment for their Affiliation (AffMax) and have Enrollment greater than 3000, and for each return School, Affiliation, Enrollment, AffMax, and a Status that is 'At_or_Above' if the school's Enrollment is at or above the average Enrollment for that Affiliation and 'Below' otherwise, ordering the results by Enrollment in descending order?","
SELECT * FROM (
 SELECT t.`School`, t.`Affiliation`, t.`Enrollment`,
   CASE WHEN t.`Enrollment` >= (SELECT AVG(`Enrollment`) FROM `table_1_16383772_1` WHERE `Affiliation` = t.`Affiliation`) THEN 'At_or_Above' ELSE 'Below' END AS `Status`,
   MAX(t.`Enrollment`) OVER (PARTITION BY t.`Affiliation`) AS `AffMax`
 FROM `table_1_16383772_1` AS t
) s
WHERE s.`Enrollment` = s.`AffMax` AND s.`Enrollment` > 3000
ORDER BY s.`Enrollment` DESC
LIMIT 5;
","
SELECT * FROM (
 SELECT t.col0, t.col3, t.col4,
   CASE WHEN t.col4 >= (SELECT AVG(col4) FROM `table_1_16383772_1` WHERE col3 = t.col3) THEN 'At_or_Above' ELSE 'Below' END AS `Status`,
   MAX(t.col4) OVER (PARTITION BY t.col3) AS `AffMax`
 FROM `table_1_16383772_1` AS t
) s
WHERE s.col4 = s.`AffMax` AND s.col4 > 3000
ORDER BY s.col4 DESC
LIMIT 5;
","[('university at buffalo', 'public', 28192.0, 'At_or_Above', 28192.0), ('cornell university', 'private/non-sectarian', 19800.0, 'At_or_Above', 19800.0), ('canisius college', 'private/roman catholic', 5152.0, 'At_or_Above', 5152.0), ('niagara university', 'private/catholic', 3746.0, 'At_or_Above', 3746.0)]",table_1_16383772_1,"1) The intent is to return per-affiliation leaders by enrollment (ties possible), include a status comparing to the affiliation average, filter out small enrollments, and show only the top five by Enrollment. 2) Map SQL constructs to language: MAX OVER (PARTITION BY Affiliation) -> AffMax, CASE comparing to AVG(Enrollment) WHERE Affiliation = t.Affiliation -> Status labels 'At_or_Above'/'Below'. 3) Formulate a question that requests School, Affiliation, Enrollment, Status, AffMax with Enrollment = AffMax and Enrollment > 3000, ordered desc, limit 5. 4) Confirm the question includes all calculations and ordering/limit constraints.",reserved,23,reward,,
"List the directors ('Directed by') who directed at least 3 episodes and, for each, give the director (Director), the number of episodes directed (Episodes), the comma-separated list of distinct 'Written by' names (Writers), and the production code range computed as MAX('Production Code') - MIN('Production Code') (CodeRange), ordered by Episodes descending and limited to 10 results?","
WITH `directors` AS (
 SELECT `Directed by`, COUNT(*) `EpisodeCount`
 FROM `table_1_16384596_4`
 GROUP BY `Directed by`
 HAVING `EpisodeCount` >= 3
)
SELECT `directors`.`Directed by` `Director`, `EpisodeCount` `Episodes`, GROUP_CONCAT(DISTINCT `Written by`) `Writers`, MAX(`Production Code`) - MIN(`Production Code`) `CodeRange`
FROM `directors`
JOIN `table_1_16384596_4` USING (`Directed by`)
GROUP BY `directors`.`Directed by`
ORDER BY `Episodes` DESC
LIMIT 10;
","
WITH `directors` AS (
 SELECT col3, COUNT(*) `EpisodeCount`
 FROM `table_1_16384596_4`
 GROUP BY col3
 HAVING `EpisodeCount` >= 3
)
SELECT `directors`.col3 `Director`, `EpisodeCount` `Episodes`, GROUP_CONCAT(DISTINCT col4) `Writers`, MAX(col6) - MIN(col6) `CodeRange`
FROM `directors`
JOIN `table_1_16384596_4` USING (col3)
GROUP BY `directors`.col3
ORDER BY `Episodes` DESC
LIMIT 10;
","[('filippa wallström', 5, 'bror yngve andersson,liselott svensson,charlotte lesche,åsa furuhagen', 10.0), ('marcelo racana', 3, 'lotten strömstedt,carolina falck,bror yngve anderson', 2.0), ('christian wikander', 3, 'anna fredriksson,åsa furuhagen,liselott svensson', 2.0)]",table_1_16384596_4,"1) The SQL builds a subquery of directors with COUNT>=3 then joins to get writers and production code min/max to compute a range, finally ordering by episode count and limiting to 10. 2) Map to natural terms: Director from 'Directed by', Episodes as the count, Writers as the distinct concatenated 'Written by' values, CodeRange as MAX-MIN of 'Production Code'. 3) Ask for those exact outputs with the >=3 filter, distinct writer concatenation, CodeRange computation, sort by Episodes desc, and limit 10. 4) Verify all columns and calculations from the SQL are mentioned and no extra details are added.",reserved,16,reward,,
"For each Ground, considering only games with Crowd > 10000 and only including Grounds with COUNT(*) > 0, what are the Ground, the number of Matches (COUNT(*)), the rounded average crowd (ROUND(AVG(Crowd))) as Avg crowd, the maximum margin (MAX of the absolute difference between the numeric score inside parentheses in Home team score and the numeric score inside parentheses in Away team score) as Max margin, and the number of Close games (SUM of matches where that absolute difference <= 5), ordered by Avg crowd ascending?","
SELECT
`Ground`,
COUNT(*) `Matches`,
ROUND(AVG(`Crowd`)) `Avg crowd`,
MAX(abs(
 (substr(`Home team score`, instr(`Home team score`, '(')+1, instr(`Home team score`, ')') - instr(`Home team score`, '(') -1)+0)
 -
 (substr(`Away team score`, instr(`Away team score`, '(')+1, instr(`Away team score`, ')') - instr(`Away team score`, '(') -1)+0)
)) `Max margin`,
SUM((abs(
 (substr(`Home team score`, instr(`Home team score`, '(')+1, instr(`Home team score`, ')') - instr(`Home team score`, '(') -1)+0)
 -
 (substr(`Away team score`, instr(`Away team score`, '(')+1, instr(`Away team score`, ')') - instr(`Away team score`, '(') -1)+0)
) <= 5)) `Close games`
FROM `table_1_16387953_1`
WHERE `Crowd` > 10000
GROUP BY `Ground`
HAVING COUNT(*) > 0
ORDER BY `Avg crowd` ASC;
","
SELECT
col4,
COUNT(*) `Matches`,
ROUND(AVG(col5)) `Avg crowd`,
MAX(abs(
 (substr(col1, instr(col1, '(')+1, instr(col1, ')') - instr(col1, '(') -1)+0)
 -
 (substr(col3, instr(col3, '(')+1, instr(col3, ')') - instr(col3, '(') -1)+0)
)) `Max margin`,
SUM((abs(
 (substr(col1, instr(col1, '(')+1, instr(col1, ')') - instr(col1, '(') -1)+0)
 -
 (substr(col3, instr(col3, '(')+1, instr(col3, ')') - instr(col3, '(') -1)+0)
) <= 5)) `Close games`
FROM `table_1_16387953_1`
WHERE col5 > 10000
GROUP BY col4
HAVING COUNT(*) > 0
ORDER BY `Avg crowd` ASC;
","[('waverley park', 3, 23496.0, 20, 1), ('football park', 1, 28776.0, 19, 0)]",table_1_16387953_1,"1) The query aggregates matches by Ground, filters rows with Crowd > 10000, computes COUNT(*), ROUND(AVG(Crowd)), MAX of the absolute difference between the numeric scores inside parentheses in Home team score and Away team score, and counts games with that absolute margin <= 5; results are ordered by Avg crowd ascending. 2) Map columns: Ground, Crowd, Home team score and Away team score (extract numbers in parentheses) and the derived metrics Matches, Avg crowd, Max margin, Close games. 3) Draft a question that requests those exact metrics per Ground with the stated filter, grouping, having and order. 4) Validate that the question mentions all columns, calculations, the Crowd > 10000 filter, HAVING COUNT(*) > 0 and ordering by Avg crowd ASC.",reserved,8,reward,,
"Which match returns `Home team`, `Away team`, `Home Points` (the numeric value inside the parentheses of `Home team score`), `Away Points` (the numeric value inside the parentheses of `Away team score`), `Margin` (the absolute difference between those two point values), and `Crowd` where (Margin * Crowd) > 1500000, returning only one result?","
SELECT `Home team`, `Away team`, substr(`Home team score`, instr(`Home team score`,'(')+1, instr(`Home team score`,')') - instr(`Home team score`,'(') - 1) `Home Points`, substr(`Away team score`, instr(`Away team score`,'(')+1, instr(`Away team score`,')') - instr(`Away team score`,'(') - 1) `Away Points`, abs((substr(`Home team score`, instr(`Home team score`,'(')+1, instr(`Home team score`,')') - instr(`Home team score`,'(') - 1)+0) - (substr(`Away team score`, instr(`Away team score`,'(')+1, instr(`Away team score`,')') - instr(`Away team score`,'(') - 1)+0)) `Margin`, `Crowd` FROM `table_1_16388316_1` WHERE (abs((substr(`Home team score`, instr(`Home team score`,'(')+1, instr(`Home team score`,')') - instr(`Home team score`,'(') - 1)+0) - (substr(`Away team score`, instr(`Away team score`,'(')+1, instr(`Away team score`,')') - instr(`Away team score`,'(') - 1)+0)) * `Crowd`) > 1500000 LIMIT 1;
","
SELECT col0, col2, substr(col1, instr(col1,'(')+1, instr(col1,')') - instr(col1,'(') - 1) `Home Points`, substr(col3, instr(col3,'(')+1, instr(col3,')') - instr(col3,'(') - 1) `Away Points`, abs((substr(col1, instr(col1,'(')+1, instr(col1,')') - instr(col1,'(') - 1)+0) - (substr(col3, instr(col3,'(')+1, instr(col3,')') - instr(col3,'(') - 1)+0)) `Margin`, col5 FROM `table_1_16388316_1` WHERE (abs((substr(col1, instr(col1,'(')+1, instr(col1,')') - instr(col1,'(') - 1)+0) - (substr(col3, instr(col3,'(')+1, instr(col3,')') - instr(col3,'(') - 1)+0)) * col5) > 1500000 LIMIT 1;
","[('hawthorn', 'essendon', '52', '125', 73, 34536.0)]",table_1_16388316_1,"1) Parse intent: find a single record where the absolute point margin times attendance exceeds 1500000 and show match details and computed values. 2) Map schema: explicitly extract Home and Away points from score parentheses as `Home Points` and `Away Points`, compute `Margin`, and include `Home team`, `Away team`, and `Crowd`. 3) Draft question: ask for those exact columns and the product condition. 4) Validate: includes extraction method, Margin calculation, product threshold, and requests one row.",reserved,4,reward,,
"Grouped by Home team where Ground is not empty, what are the Home team, Matches Played (COUNT), Total Crowd (SUM of Crowd), Average Crowd rounded to 0 decimal places (ROUND(AVG(Crowd),0)), and Max Crowd (MAX(Crowd)), ordered by Total Crowd from highest to lowest and limited to 10 results?","
SELECT `Home team`, COUNT(*) `Matches Played`, SUM(`Crowd`) `Total Crowd`, ROUND(AVG(`Crowd`),0) `Average Crowd`, MAX(`Crowd`) `Max Crowd`
FROM (VALUES
  ('Geelong','4.10 (34)','Sydney','6.11 (47)','Marrara Oval','Friday, 16 February',8500),
  ('Port Adelaide','16.25 (121)','Essendon','5.12 (42)','Football Park','Saturday, 17 February',19498),
  ('Port Adelaide','17.10 (112)','Sydney','15.17 (107)','Football Park','Friday, 23 February',15709),
  ('Essendon','12.18 (90)','Geelong','17.10 (112)','Colonial Stadium','Friday, 23 February',22829),
  ('Geelong','12.15 (87)','Port Adelaide','16.9 (105)','Colonial Stadium','Saturday, 3 March',4474)
) AS `t`(`Home team`,`Home team score`,`Away team`,`Away team score`,`Ground`,`Date`,`Crowd`)
WHERE `Ground` <> ''
GROUP BY `Home team`
HAVING COUNT(*) > 0
ORDER BY `Total Crowd` * -1
LIMIT 10;
","SELECT col0, COUNT(*) AS `Matches Played`, SUM(col6) AS `Total Crowd`, ROUND(AVG(col6),0) AS `Average Crowd`, MAX(col6) AS `Max Crowd`
FROM (
  SELECT 'Geelong' AS col0, '4.10 (34)' AS col1, 'Sydney' AS col2, '6.11 (47)' AS col3, 'Marrara Oval' AS col4, 'Friday, 16 February' AS col5, 8500 AS col6
  UNION ALL
  SELECT 'Port Adelaide', '16.25 (121)', 'Essendon', '5.12 (42)', 'Football Park', 'Saturday, 17 February', 19498
  UNION ALL
  SELECT 'Port Adelaide', '17.10 (112)', 'Sydney', '15.17 (107)', 'Football Park', 'Friday, 23 February', 15709
  UNION ALL
  SELECT 'Essendon', '12.18 (90)', 'Geelong', '17.10 (112)', 'Colonial Stadium', 'Friday, 23 February', 22829
  UNION ALL
  SELECT 'Geelong', '12.15 (87)', 'Port Adelaide', '16.9 (105)', 'Colonial Stadium', 'Saturday, 3 March', 4474
) AS `t`
WHERE col4 <> ''
GROUP BY col0
HAVING COUNT(*) > 0
ORDER BY `Total Crowd` * -1
LIMIT 10;","[('Port Adelaide', 2, 35207, 17604.0, 19498), ('Essendon', 1, 22829, 22829.0, 22829), ('Geelong', 2, 12974, 6487.0, 8500)]",table_1_16388439_1,"1) The SQL intent is to report per-Home team aggregates: count of matches, sum/avg/max of Crowd, excluding rows with empty Ground, and return the top 10 by total crowd. 2) Schema mapping: use Home team as the group key and Crowd as the numeric measure; Ground must not be empty. 3) Draft the question requesting Home team, Matches Played (COUNT), Total Crowd (SUM Crowd), Average Crowd rounded to 0 decimals, and Max Crowd, sorted by Total Crowd desc, top 10. 4) Confirm all calculations and constraints are mentioned.",reserved,10,reward,,
"List the Ground, the number of games at that Ground (COUNT(*)), the average of the absolute differences between the parenthetical total scores in Home team score and Away team score (AVG(ABS(parenthetical total from Home team score - parenthetical total from Away team score))), the average Crowd (AVG(Crowd)), and the maximum absolute difference of those parenthetical totals (MAX(ABS(...))) for Grounds whose average Crowd is greater than 8000, ordered by the average absolute difference and limited to 3 results.","
SELECT `Ground`, COUNT(*), AVG(ABS(
  (SUBSTR(`Home team score`, INSTR(`Home team score`, '(')+1, INSTR(`Home team score`, ')') - INSTR(`Home team score`, '(') - 1) + 0)
  -
  (SUBSTR(`Away team score`, INSTR(`Away team score`, '(')+1, INSTR(`Away team score`, ')') - INSTR(`Away team score`, '(') - 1) + 0)
)), AVG(`Crowd`), MAX(ABS(
  (SUBSTR(`Home team score`, INSTR(`Home team score`, '(')+1, INSTR(`Home team score`, ')') - INSTR(`Home team score`, '(') - 1) + 0)
  -
  (SUBSTR(`Away team score`, INSTR(`Away team score`, '(')+1, INSTR(`Away team score`, ')') - INSTR(`Away team score`, '(') - 1) + 0)
))
FROM `table_1_16388506_1`
GROUP BY `Ground`
HAVING AVG(`Crowd`) > 8000
ORDER BY 3
LIMIT 3;
","
SELECT col4, COUNT(*), AVG(ABS(
  (SUBSTR(col1, INSTR(col1, '(')+1, INSTR(col1, ')') - INSTR(col1, '(') - 1) + 0)
  -
  (SUBSTR(col3, INSTR(col3, '(')+1, INSTR(col3, ')') - INSTR(col3, '(') - 1) + 0)
)), AVG(col5), MAX(ABS(
  (SUBSTR(col1, INSTR(col1, '(')+1, INSTR(col1, ')') - INSTR(col1, '(') - 1) + 0)
  -
  (SUBSTR(col3, INSTR(col3, '(')+1, INSTR(col3, ')') - INSTR(col3, '(') - 1) + 0)
))
FROM `table_1_16388506_1`
GROUP BY col4
HAVING AVG(col5) > 8000
ORDER BY 3
LIMIT 3;
","[('aami stadium', 1, 1.0, 25560.0, 1), ('subiaco oval', 1, 17.0, 32701.0, 17), ('york park', 1, 23.0, 11427.0, 23)]",table_1_16388506_1,"1) Intent: aggregate per Ground computing count, average absolute margin (from parenthetical totals), average crowd and maximum margin, filter grounds by average crowd >8000, sort by the average margin and take 3. 2) Map schema: use `Ground`, extract numeric totals from `Home team score` and `Away team score` parentheses, and `Crowd`. 3) Draft concise question reflecting those aggregates, filter, order and limit. 4) Validate that all SQL-selected columns and calculations are included.",reserved,8,reward,,
"List the distinct Country, the interview improvement as Interview minus Preliminary, the difference between Evening gown and Swimsuit, and the Average for entries where Interview > Preliminary and Evening gown > Swimsuit, sorted by Average in ascending order and showing only the first 5 rows?","
SELECT DISTINCT `Country`, (`Interview`+0)-(`Preliminary`+0) AS `Interview improvement`, (`Evening gown`+0)-(`Swimsuit`+0), `Average` FROM `table_1_16390001_2` WHERE (`Interview`+0)>(`Preliminary`+0) AND (`Evening gown`+0)>(`Swimsuit`+0) ORDER BY `Average` LIMIT 5;
","
SELECT DISTINCT col0, (col2+0)-(col1+0) AS `Interview improvement`, (col4+0)-(col3+0), col5 FROM `table_1_16390001_2` WHERE (col2+0)>(col1+0) AND (col4+0)>(col3+0) ORDER BY col5 LIMIT 5;
","[('oklahoma', 0.8440000000000003, 0.3000000000000007, '8.506'), ('north dakota', 1.0060000000000002, 0.12199999999999989, '8.559'), ('south carolina', 0.6580000000000013, 0.09399999999999942, '8.709'), ('louisiana', 0.4969999999999999, 0.09999999999999964, '8.781'), ('texas', 0.6509999999999998, 0.12300000000000111, '9.266')]",table_1_16390001_2,"1) The SQL returns Country plus two differences (Interview−Preliminary and Evening gown−Swimsuit) and Average for rows meeting two greater-than conditions, ordered by Average with a 5-row limit. 2) Use the table's Country, Interview, Preliminary, Swimsuit, Evening gown, and Average fields. 3) Formulate a question asking for those specific fields and calculations with the same filters and ordering. 4) Confirm the question explicitly states the calculations, comparisons, ascending order by Average, and limit of 5.",reserved,9,reward,,
"Provide Week, Date, Opponent, Game site, and Attendance and also compute Team points as the substring of Final score from character 3 to just before '–', Opponent points as the substring after '–', Margin as (Opponent points - Team points), Home flag equal to 1 when the Opponent string does not contain 'at ' and 0 otherwise, and Attendance per margin equal to Attendance divided by (Margin + 1), including only rows where Attendance is >= 10000 and the computed Margin is >= 10.","
SELECT
`Week`,
`Date`,
`Opponent`,
`Game site`,
`Attendance`,
((substr(`Final score`, instr(`Final score`, '–')+1) * 1) - (substr(`Final score`, 3, instr(`Final score`, '–') - 3) * 1)) `Margin`,
((substr(`Final score`, 3, instr(`Final score`, '–') - 3) * 1)) `Team points`,
((substr(`Final score`, instr(`Final score`, '–')+1) * 1)) `Opponent points`,
((instr(`Opponent`, 'at ') = 0) * 1) `Home flag`,
(`Attendance` / (((substr(`Final score`, instr(`Final score`, '–')+1) * 1) - (substr(`Final score`, 3, instr(`Final score`, '–') - 3) * 1) + 1))) `Attendance per margin`
FROM `table_1_1639689_2`
WHERE `Attendance` >= 10000 AND (((substr(`Final score`, instr(`Final score`, '–')+1) * 1) - (substr(`Final score`, 3, instr(`Final score`, '–') - 3) * 1)) >= 10);
","
SELECT
col0,
col1,
col3,
col6,
col7,
((substr(col4, instr(col4, '–')+1) * 1) - (substr(col4, 3, instr(col4, '–') - 3) * 1)) `Margin`,
((substr(col4, 3, instr(col4, '–') - 3) * 1)) `Team points`,
((substr(col4, instr(col4, '–')+1) * 1)) `Opponent points`,
((instr(col3, 'at ') = 0) * 1) `Home flag`,
(col7 / (((substr(col4, instr(col4, '–')+1) * 1) - (substr(col4, 3, instr(col4, '–') - 3) * 1) + 1))) `Attendance per margin`
FROM `table_1_1639689_2`
WHERE col7 >= 10000 AND (((substr(col4, instr(col4, '–')+1) * 1) - (substr(col4, 3, instr(col4, '–') - 3) * 1)) >= 10);
","[(2.0, 'saturday, march 30', 'at orlando thunder', 'florida citrus bowl', 20811.0, 38, 20, 58, 0, 533.6153846153846), (3.0, 'saturday, april 6', 'barcelona dragons', 'carter–finley stadium', 17900.0, 12, 14, 26, 1, 1376.923076923077), (4.0, 'monday, april 15', 'san antonio riders', 'carter–finley stadium', 11818.0, 22, 15, 37, 1, 513.8260869565217), (6.0, 'sunday, april 28', 'at london monarchs', 'wembley stadium', 33997.0, 25, 10, 35, 0, 1307.576923076923), (7.0, 'sunday, may 5', 'new york/new jersey knights', 'carter–finley stadium', 10069.0, 36, 6, 42, 1, 272.13513513513516)]",table_1_1639689_2,"1) The intent is to list game metadata and computed scoring/attendance metrics where the margin and attendance meet thresholds. 2) Map to schema: use Final score substrings to compute Team points and Opponent points, calculate Margin = opponent - team, set Home flag by checking for the substring 'at ' in Opponent, and compute Attendance per margin = Attendance/(Margin+1). 3) Write a question that requests Week, Date, Opponent, Game site, Attendance, Team points, Opponent points, Margin, Home flag and Attendance per margin and enforces Attendance >= 10000 and Margin >= 10. 4) Confirm that the question mirrors the SQL selections, calculations, and WHERE conditions.",reserved,4,reward,,
"Provide pairs of institutions (Institution A and Institution B) that share the same Home Rink and satisfy Institution A < Institution B, showing Institution A, Institution B, the Home Rink, an Enrollment comparison labeled 'A larger' / 'B larger' / 'Equal' depending on whether A's Enrollment is greater / less / equal to B's, and the Primary conference for A (Conference A) and for B (Conference B), ordered by Home Rink ascending then by the enrollment comparison with 'A larger' first, limited to 100 results?","
SELECT b1.`Institution` AS `Institution A`, b2.`Institution` AS `Institution B`, b1.`Home Rink`, CASE WHEN b1.`Enrollment` > b2.`Enrollment` THEN 'A larger' WHEN b1.`Enrollment` < b2.`Enrollment` THEN 'B larger' ELSE 'Equal' END AS `Enrollment comparison`, b1.`Primary conference` AS `Conference A`, b2.`Primary conference` AS `Conference B` FROM `table_1_16403890_1` b1 INNER JOIN `table_1_16403890_1` b2 ON b1.`Home Rink` = b2.`Home Rink` AND b1.`Institution` < b2.`Institution` WHERE b1.`Institution` IS b1.`Institution` ORDER BY `Home Rink` ASC, `Enrollment comparison` DESC LIMIT 100;
","SELECT DISTINCT b1.col0 AS `Institution A`, b2.col0 AS `Institution B`, b1.col7 AS col7, CASE WHEN b1.col4 > b2.col4 THEN 'A larger' WHEN b1.col4 < b2.col4 THEN 'B larger' ELSE 'Equal' END AS `Enrollment comparison` FROM `table_1_16403890_1` AS b1 INNER JOIN `table_1_16403890_1` AS b2 ON b1.col7 = b2.col7 AND b1.col0 < b2.col0 WHERE b1.col0 IS NOT NULL GROUP BY b1.col7, b1.col0, b2.col0 HAVING COUNT(*) >= 1 ORDER BY b1.col7 ASC, `Enrollment comparison` DESC LIMIT 100 OFFSET 0;","[('duke university', 'university of north carolina', 'triangle sports plex', 'B larger')]",table_1_16403890_1,"1) Parse SQL intent: self-join on Home Rink to produce paired institutions and compute which has larger enrollment. 2) Map schema semantics: include Institution names, Home Rink, Enrollment comparison CASE result, and each institution's Primary conference. 3) Draft the question: request those columns for pairs where Institution A < Institution B. 4) Validate: include ordering by Home Rink ASC, Enrollment comparison DESC, and LIMIT 100.",reserved,25,reward,,
"For up to 5 results, list the literal 'Lexington', the School Year, and Lexington_Appearances computed as SUM(CASE WHEN 1=1 OR 0=1 THEN ((Volleyball LIKE '%Lexington%') + (Cross Country LIKE '%Lexington%') + (Soccer LIKE '%Lexington%') + (Tennis LIKE '%Lexington%') + (Golf LIKE '%Lexington%') + (Basketball LIKE '%Lexington%') + (Swimming LIKE '%Lexington%') + (Softball LIKE '%Lexington%') + (Track & Field LIKE '%Lexington%')) END) for each School Year where (Volleyball || Cross Country || Soccer || Tennis || Golf || Basketball || Swimming || Softball || Track & Field) LIKE '%Lexington%' AND 1=1, grouping by School Year, keeping only groups HAVING Lexington_Appearances > 0, and ordering by Lexington_Appearances?","
SELECT '`Lexington`', `School Year`, SUM(CASE WHEN 1=1 OR 0=1 THEN ((`Volleyball` LIKE '%Lexington%') + (`Cross Country` LIKE '%Lexington%') + (`Soccer` LIKE '%Lexington%') + (`Tennis` LIKE '%Lexington%') + (`Golf` LIKE '%Lexington%') + (`Basketball` LIKE '%Lexington%') + (`Swimming` LIKE '%Lexington%') + (`Softball` LIKE '%Lexington%') + (`Track & Field` LIKE '%Lexington%')) END) AS `Lexington_Appearances` FROM `table_1_16423070_4` WHERE ((`Volleyball` || `Cross Country` || `Soccer` || `Tennis` || `Golf` || `Basketball` || `Swimming` || `Softball` || `Track & Field`) LIKE '%Lexington%') AND 1=1 GROUP BY `School Year` HAVING `Lexington_Appearances` > 0 ORDER BY `Lexington_Appearances` LIMIT 5;
","
SELECT '`Lexington`', col0, SUM(CASE WHEN 1=1 OR 0=1 THEN ((col1 LIKE '%Lexington%') + (col2 LIKE '%Lexington%') + (col3 LIKE '%Lexington%') + (col4 LIKE '%Lexington%') + (col5 LIKE '%Lexington%') + (col6 LIKE '%Lexington%') + (col7 LIKE '%Lexington%') + (col8 LIKE '%Lexington%') + (col9 LIKE '%Lexington%')) END) AS `Lexington_Appearances` FROM `table_1_16423070_4` WHERE ((col1 || col2 || col3 || col4 || col5 || col6 || col7 || col8 || col9) LIKE '%Lexington%') AND 1=1 GROUP BY col0 HAVING `Lexington_Appearances` > 0 ORDER BY `Lexington_Appearances` LIMIT 5;
","[('`Lexington`', '2005-06', 2), ('`Lexington`', '2006-07', 2), ('`Lexington`', '2007-08', 2), ('`Lexington`', '2008-09', 2), ('`Lexington`', '2011-12', 2)]",table_1_16423070_4,"1) Parse intent: identify up to five School Years with nonzero counts of 'Lexington' across all sport columns, reporting the literal 'Lexington', the School Year, and the summed LIKE matches per year. 2) Map schema: the columns included are Volleyball, Cross Country, Soccer, Tennis, Golf, Basketball, Swimming, Softball, and Track & Field. 3) Draft question. 4) Validate that the question references the CASE WHEN 1=1 OR 0=1 wrapper, the summed LIKE('%Lexington%') checks, the concatenated WHERE condition, GROUP BY School Year, HAVING Lexington_Appearances > 0, ORDER BY Lexington_Appearances, and LIMIT 5.",reserved,15,reward,,
"Which `Directed by` values have more than one episode (HAVING COUNT(*) > 1) among rows with `No. in season` > 0, and for each such `Directed by` return the `Directed by` name, the number of episodes directed as `Episodes directed` (COUNT(*)), the MIN(`Original air date`) as `First air date`, and the MAX(`Original air date`) as `Last air date`, ordering the output by `Episodes directed` descending?","
SELECT `Directed by`, COUNT(*) `Episodes directed`, MIN(`Original air date`) `First air date`, MAX(`Original air date`) `Last air date`
FROM `table_1_16432167_1`
WHERE `No. in season`>0
GROUP BY `Directed by`
HAVING COUNT(*)>1
ORDER BY `Episodes directed` DESC;
","
SELECT col3, COUNT(*) `Episodes directed`, MIN(col5) `First air date`, MAX(col5) `Last air date`
FROM `table_1_16432167_1`
WHERE col1>0
GROUP BY col3
HAVING COUNT(*)>1
ORDER BY `Episodes directed` DESC;
","[('norman tokar', 19, 'april16,1959', 'october9,1958')]",table_1_16432167_1,"1) Parse intent: aggregate episode counts and date ranges per director, restrict to season numbers > 0, include only directors with more than one episode, and sort by descending episode count. 2) Map schema: `Directed by`, `No. in season`, `Original air date`, COUNT(*) -> `Episodes directed`, MIN/MAX -> `First/Last air date`. 3) Draft: pose a question that requests these exact fields and constraints. 4) Validate: question captures SELECT fields, WHERE, GROUP BY, HAVING, and ORDER BY clauses precisely.",reserved,8,reward,,
"List each Gun that has at least one other gun it beats on both m/v ft/s and Max. height (ft); for each such Gun give Better_than_peers (the count of those other guns), Avg_Delta_v (average of this Gun's m/v ft/s minus the others'), Avg_Delta_25 (average of this Gun's Time to ft (m) at 25° (seconds) minus the others'), and Avg_Delta_h (average of this Gun's Max. height (ft) minus the others'), then return only the top 5 Guns by Avg_Delta_v (descending).","
SELECT t.`Gun`, COUNT(*) AS `Better_than_peers`, AVG(t.`m/v ft/s` - t2.`m/v ft/s`) `Avg_Delta_v`, AVG((t.`Time to ft (m) at 25° (seconds)`+0.0) - (t2.`Time to ft (m) at 25° (seconds)`+0.0)) `Avg_Delta_25`, AVG(t.`Max. height (ft)` - t2.`Max. height (ft)`) `Avg_Delta_h`
FROM `table_1_16439764_1` t
INNER JOIN `table_1_16439764_1` t2 ON t.`Gun` <> t2.`Gun`
WHERE (t.`m/v ft/s` > t2.`m/v ft/s`) AND (t.`Max. height (ft)` > t2.`Max. height (ft)`)
GROUP BY t.`Gun`
HAVING COUNT(*) > 0
ORDER BY `Avg_Delta_v` DESC
LIMIT 5;
","
SELECT t.col0, COUNT(*) AS `Better_than_peers`, AVG(t.col1 - t2.col1) `Avg_Delta_v`, AVG((t.col3+0.0) - (t2.col3+0.0)) `Avg_Delta_25`, AVG(t.col6 - t2.col6) `Avg_Delta_h`
FROM `table_1_16439764_1` t
INNER JOIN `table_1_16439764_1` t2 ON t.col0 <> t2.col0
WHERE (t.col1 > t2.col1) AND (t.col6 > t2.col6)
GROUP BY t.col0
HAVING COUNT(*) > 0
ORDER BY `Avg_Delta_v` DESC
LIMIT 5;
","[('qf 3 inch 20 cwt 1914', 3, 436.6666666666667, -1.1666666666666654, 3166.6666666666665), ('qf 4inch mk v world war i', 3, 286.6666666666667, -5.0666666666666655, 8416.666666666666), ('qf 12 pdr 12 cwt', 1, 210.0, -1.0, 1000.0), ('qf 3 inch 20 cwt 1916', 1, 10.0, -0.9000000000000004, 3000.0)]",table_1_16439764_1,"1) The query groups by Gun and only keeps Guns that beat at least one other on both muzzle velocity and max height, computing count and average differences. 2) Map the aggregated outputs to Better_than_peers, Avg_Delta_v, Avg_Delta_25, Avg_Delta_h using columns m/v ft/s, Time to ft (m) at 25° (seconds), and Max. height (ft). 3) Draft the question to ask for those metrics per Gun, filter for count>0, sort by Avg_Delta_v descending and limit to 5. 4) Confirm it includes all calculations and the comparison criteria.",reserved,14,reward,,
"Show me the colleges with multiple picks, the position counts, and B.C.'s Round five picks from the 1998 CFL Draft?","
SELECT
  (SELECT GROUP_CONCAT(`College`, '; ')
   FROM (
     SELECT `College`
     FROM `table_1_16441561_5`
     GROUP BY `College`
     HAVING COUNT(*) > 1
     ORDER BY `College`
   )
  ) AS `Colleges with multiple picks`,
  (SELECT GROUP_CONCAT(`Position` || ':' || cnt, '; ')
   FROM (
     SELECT `Position`, COUNT(*) AS cnt
     FROM `table_1_16441561_5`
     GROUP BY `Position`
     ORDER BY cnt DESC, `Position`
   )
  ) AS `Position distribution (Position:Count)`,
  (SELECT GROUP_CONCAT(detail, '; ')
   FROM (
     SELECT 'Pick #' || `Pick #` || ' - ' || `Player` || ' (' || `Position` || ', ' || `College` || ')' AS detail
     FROM `table_1_16441561_5`
     WHERE `CFL Team` = 'B.C.'
     ORDER BY `Pick #`
   )
  ) AS `Picks by B.C.`;
","
SELECT
  (SELECT GROUP_CONCAT(col4, '; ')
   FROM (
     SELECT col4
     FROM `table_1_16441561_5`
     GROUP BY col4
     HAVING COUNT(*) > 1
     ORDER BY col4
   )
  ) AS `Colleges with multiple picks`,
  (SELECT GROUP_CONCAT(col3 || ':' || cnt, '; ')
   FROM (
     SELECT col3, COUNT(*) AS cnt
     FROM `table_1_16441561_5`
     GROUP BY col3
     ORDER BY cnt DESC, col3
   )
  ) AS `Position distribution (Position:Count)`,
  (SELECT GROUP_CONCAT(detail, '; ')
   FROM (
     SELECT 'Pick #' || col0 || ' - ' || col2 || ' (' || col3 || ', ' || col4 || ')' AS detail
     FROM `table_1_16441561_5`
     WHERE col1 = 'B.C.'
     ORDER BY col0
   )
  ) AS `Picks by B.C.`;
","[('laval', 'ol:2; cb:1; db:1; lb:1; rb:1', None)]",table_1_16441561_5,"I often request a brief package combining pipelines, position breakdown, and a team's picks for quick scouting briefs. The full SQL returns (1) colleges with COUNT>1, (2) position counts, and (3) formatted picks for CFL Team 'B.C.'. This maps to College grouping, Position aggregation, and filtering by CFL Team = 'B.C.' in the Round five table. Show me the colleges with multiple picks, the position counts, and B.C.'s Round five picks from the 1998 CFL Draft? This combined question exactly mirrors the three outputs produced by the query.",persona,"CFL Draft Research Analyst working in a team's front office who studies past drafts to identify college pipelines and position trends to inform future scouting and drafting. They would use this database to quickly query historical pick details (team, player, position, college) from the 1998 draft Round five. Goals: Identify which colleges produced multiple draftees in Round five of the 1998 CFL Draft to spot strong pipelines. Understand position distribution in Round five (e.g., how many OL, DB, LB, RB, CB were selected) to spot historical drafting patterns. Filter picks by CFL team to review that team's selections in Round five for retrospective performance analysis or scouting follow-up. Example Queries: SELECT ""College"", COUNT(*) AS num_picks
FROM table_1_16441561_5
GROUP BY ""College""
ORDER BY num_picks DESC, ""College""; SELECT ""Pick #"", ""CFL Team"", ""Player"", ""Position""
FROM table_1_16441561_5
WHERE ""Position"" = 'OL'
ORDER BY ""Pick #""; SELECT ""Pick #"", ""Player"", ""Position"", ""College""
FROM table_1_16441561_5
WHERE ""CFL Team"" = 'B.C.';",reward,,
"List each team (Locale and Skip) with W >= 6 and show W, L, PF, PA, Point Differential = PF - PA, Diff per Game = (PF - PA)/(W + L) rounded to 2 decimals, Ends Net = Ends Won - Ends Lost, Shot Ratio = Shot % converted to a 0–1 ratio rounded to 3 decimals, and Stolen Share = Stolen Ends / (Ends Won + Ends Lost) rounded to 3 decimals.","
SELECT `Locale`, `Skip`, `W`, `L`, `PF`, `PA`, (`PF` - `PA`) `Point Differential`, ROUND((`PF` - `PA`)/(`W` + `L`),2) `Diff per Game`, (`Ends Won` - `Ends Lost`) `Ends Net`, ROUND((substr(`Shot %`,1,length(`Shot %`) - 1)+0)/100,3) `Shot Ratio`, ROUND(`Stolen Ends`/(`Ends Won` + `Ends Lost`),3) `Stolen Share` 
FROM `table_1_1644876_2` 
WHERE `W` >= 6;
","
SELECT col0, col1, col2, col3, col4, col5, (col4 - col5) `Point Differential`, ROUND((col4 - col5)/(col2 + col3),2) `Diff per Game`, (col6 - col7) `Ends Net`, ROUND((substr(col10,1,length(col10) - 1)+0)/100,3) `Shot Ratio`, ROUND(col9/(col6 + col7),3) `Stolen Share` 
FROM `table_1_1644876_2` 
WHERE col2 >= 6;
","[('china', 'wang bingyu', 9.0, 2.0, 92.0, 67.0, 25.0, 2.27, 14.0, 0.0, 0.18), ('canada', 'jennifer jones', 9.0, 2.0, 88.0, 62.0, 26.0, 2.36, 3.0, 0.0, 0.101), ('switzerland', 'mirjam ott', 9.0, 2.0, 90.0, 64.0, 26.0, 2.36, 5.0, 0.0, 0.113), ('japan', 'moe meguro', 7.0, 4.0, 75.0, 66.0, 9.0, 0.82, 4.0, 0.0, 0.138), ('denmark', 'angelina jensen', 7.0, 4.0, 73.0, 68.0, 5.0, 0.45, -7.0, 0.0, 0.074), ('sweden', 'stina viktorsson', 6.0, 5.0, 68.0, 72.0, -4.0, -0.36, -6.0, 0.0, 0.073), ('united states', 'debbie mccormick', 6.0, 5.0, 71.0, 74.0, -3.0, -0.27, -1.0, 0.0, 0.126)]",table_1_1644876_2,"1) SQL intent: select basic team stats plus six derived metrics for teams with W >= 6. 2) Map fields and computations to plain language including rounding specifics and denominators (W+L and Ends Won+Ends Lost). 3) Compose a natural question asking for Locale, Skip, W, L, PF, PA and the exact calculated fields with the same rounding and filters. 4) Confirm all columns, calculations, rounding rules, and the W >= 6 condition are present and no extra data is included.",reserved,3,reward,,
Which hub and partner cities in the same province have the largest combined administrative population?,"
WITH `stats` AS (
  SELECT
    `City`,
    `Province`,
    `Urban Population (2010)` AS `urban_2010`,
    `Administrative Population (2010)` AS `admin_2010`,
    (`Administrative Population (2010)` - `Urban Population (2010)`) AS `pop_diff`,
    (`Administrative Population (2010)` / NULLIF(`Urban Population (2010)`, 0)) AS `pop_ratio`
  FROM `table_1_16489766_2`
),
`hubs` AS (
  SELECT *
  FROM `stats`
  WHERE `urban_2010` BETWEEN 2000000 AND 8000000
    AND `admin_2010` > 8000000
),
`partners` AS (
  SELECT
    `hubs`.`City` AS `hub_city`,
    `p`.`City` AS `partner_city`,
    `hubs`.`Province` AS `province`,
    `hubs`.`urban_2010` AS `hub_urban_2010`,
    `hubs`.`admin_2010` AS `hub_admin_2010`,
    `hubs`.`pop_diff` AS `hub_pop_diff`,
    `hubs`.`pop_ratio` AS `hub_pop_ratio`,
    `p`.`urban_2010` AS `partner_urban_2010`,
    `p`.`admin_2010` AS `partner_admin_2010`,
    `p`.`pop_diff` AS `partner_pop_diff`,
    `p`.`pop_ratio` AS `partner_pop_ratio`,
    (`hubs`.`admin_2010` + `p`.`admin_2010`) AS `combined_admin_2010`,
    (`hubs`.`pop_diff` + `p`.`pop_diff`) AS `combined_hinterland`
  FROM `hubs`
  JOIN `stats` p
    ON `hubs`.`Province` = p.`Province`
   AND `hubs`.`City` <> p.`City`
)
SELECT
  `hub_city`,
  `partner_city`,
  `province`,
  `hub_urban_2010`,
  `hub_admin_2010`,
  `hub_pop_diff`,
  ROUND(`hub_pop_ratio`, 3) AS `hub_pop_ratio`,
  `partner_urban_2010`,
  `partner_admin_2010`,
  `partner_pop_diff`,
  ROUND(`partner_pop_ratio`, 3) AS `partner_pop_ratio`,
  `combined_admin_2010`,
  `combined_hinterland`
FROM `partners`
ORDER BY `combined_admin_2010` DESC, `combined_hinterland` DESC, `hub_pop_diff` DESC
LIMIT 10;
","SELECT
  h.col0 AS `hub_city`,
  p.col0 AS `partner_city`,
  h.col3 AS col3,
  h.col4 AS `hub_urban_2010`,
  h.col5 AS `hub_admin_2010`,
  (h.col5 - h.col4) AS `hub_pop_diff`,
  ROUND(h.col5 / NULLIF(h.col4, 0), 3) AS `hub_pop_ratio`,
  p.col4 AS `partner_urban_2010`,
  p.col5 AS `partner_admin_2010`,
  (p.col5 - p.col4) AS `partner_pop_diff`,
  ROUND(p.col5 / NULLIF(p.col4, 0), 3) AS `partner_pop_ratio`,
  (h.col5 + p.col5) AS `combined_admin_2010`,
  ((h.col5 - h.col4) + (p.col5 - p.col4)) AS `combined_hinterland`
FROM `table_1_16489766_2` h
JOIN `table_1_16489766_2` p
  ON h.col3 = p.col3
 AND h.col0 <> p.col0
WHERE h.col4 BETWEEN 2000000 AND 8000000
  AND h.col5 > 8000000
ORDER BY `combined_admin_2010` DESC, `combined_hinterland` DESC, `hub_pop_diff` DESC
LIMIT 10;","[('chongqing', 'shanghai', 'municipality', 5402721.0, 28846170.0, 23443449.0, 5.339, 22315426.0, 23019148.0, 703722.0, 1.032, 51865318.0, 24147171.0), ('chongqing', 'beijing', 'municipality', 5402721.0, 28846170.0, 23443449.0, 5.339, 18827000.0, 19612368.0, 785368.0, 1.042, 48458538.0, 24228817.0), ('chongqing', 'tianjin', 'municipality', 5402721.0, 28846170.0, 23443449.0, 5.339, 11090314.0, 12937954.0, 1847640.0, 1.167, 41784124.0, 25291089.0), ('suzhou', 'nanjing', 'jiangsu', 5349000.0, 10465994.0, 5116994.0, 1.957, 6852984.0, 8004680.0, 1151696.0, 1.168, 18470674.0, 6268690.0), ('nanjing', 'suzhou', 'jiangsu', 6852984.0, 8004680.0, 1151696.0, 1.168, 5349000.0, 10465994.0, 5116994.0, 1.957, 18470674.0, 6268690.0), ('suzhou', 'wuxi', 'jiangsu', 5349000.0, 10465994.0, 5116994.0, 1.957, 3542319.0, 6372624.0, 2830305.0, 1.799, 16838618.0, 7947299.0), ('hangzhou', 'ningbo', 'zhejiang', 5695313.0, 8700400.0, 3005087.0, 1.528, 3089180.0, 7605700.0, 4516520.0, 2.462, 16306100.0, 7521607.0), ('qingdao', 'jinan', 'shangdong', 3063492.0, 8715100.0, 5651608.0, 2.845, 3922180.0, 6814000.0, 2891820.0, 1.737, 15529100.0, 8543428.0), ('suzhou', 'changzhou', 'jiangsu', 5349000.0, 10465994.0, 5116994.0, 1.957, 3290548.0, 4591972.0, 1301424.0, 1.396, 15057966.0, 6418418.0), ('shenyang', 'dalian', 'liaoning', 5743718.0, 8106171.0, 2362453.0, 1.411, 3266905.0, 6690432.0, 3423527.0, 2.048, 14796603.0, 5785980.0)]",table_1_16489766_2,"STEP 1: Parse the SQL intent — compute urban/admin/pop_diff/pop_ratio for each city; define 'hubs' as cities with urban_2010 between 2,000,000 and 8,000,000 and admin_2010 > 8,000,000; pair each hub with other cities in the same province and compute combined_admin_2010 and combined_hinterland; order pairs by combined_admin_2010 desc, combined_hinterland desc, hub_pop_diff desc and return the top 10. STEP 2: Determine ambiguity type — scope/attachment ambiguity fits well: the phrase 'in the same province' or 'in their province' can be read either as a pairing/filter condition (both cities must be in the same province, then pick top pairs overall) or as a scope qualifier (find the top pair within each province). STEP 3: Draft the question — ""Which hub and partner cities in the same province have the largest combined administrative population?"" STEP 4: Explain the ambiguity — in the original query the phrase is interpreted as a pairing/filter (require both cities be in the same province, then return the top 10 pairs overall). Alternatively it could be read as a per-province question asking for the single top hub-partner pair within each province (group-wise maxima), which would change grouping and results.",persona,"A retro‑futurist heritage‑railway route designer who plans scenic steam tourist lines by targeting Chinese city pairs with large metropolitan hinterlands and commuter belts. Goals: Identify cities where the administrative population greatly exceeds the urban population (indicating broad commuter belts or large peri‑urban areas that could feed tourist routes). Find high‑potential city pairs or hub towns within the same province (or nearby administrative types) with enough combined administrative population to sustain multi‑stop heritage trains. Select mid‑sized urban cores with very large administrative populations as candidate hub towns for depot, restoration yard, and overnight stays. Example Queries: /* 1) Cities with the largest absolute and relative hinterlands (admin - urban and admin/urban ratio) */
SELECT City,
       Province,
       ""Urban Population (2010)"" AS urban_2010,
       ""Administrative Population (2010)"" AS admin_2010,
       (""Administrative Population (2010)"" - ""Urban Population (2010)"") AS pop_diff,
       (""Administrative Population (2010)"" / NULLIF(""Urban Population (2010)"", 0)) AS pop_ratio
FROM table_1_16489766_2
WHERE ""Administrative Population (2010)"" > ""Urban Population (2010)""
ORDER BY pop_diff DESC, pop_ratio DESC
LIMIT 20; /* 2) Candidate intra‑province city pairings ranked by combined administrative population (exclude national municipalities if desired) */
SELECT t1.City AS city_a,
       t2.City AS city_b,
       t1.Province,
       (t1.""Administrative Population (2010)"" + t2.""Administrative Population (2010)"") AS combined_admin
FROM table_1_16489766_2 t1
JOIN table_1_16489766_2 t2
  ON t1.Province = t2.Province
 AND t1.City < t2.City
WHERE t1.Province NOT IN ('Municipality')
ORDER BY combined_admin DESC
LIMIT 10; /* 3) Mid‑sized urban cores (2–8M) with very large administrative populations (>8M) for hub candidacy */
SELECT City,
       Province,
       ""Urban Population (2010)"" AS urban_2010,
       ""Administrative Population (2010)"" AS admin_2010,
       (""Administrative Population (2010)"" - ""Urban Population (2010)"") AS hinterland_size
FROM table_1_16489766_2
WHERE ""Urban Population (2010)"" BETWEEN 2000000 AND 8000000
  AND ""Administrative Population (2010)"" > 8000000
ORDER BY hinterland_size DESC;",reward,,"type: Scope/attachment ambiguity | explanation: The phrase 'in the same province' can be interpreted as a filter that just ensures both cities are co-located (the SQL's interpretation, then return the top pairs overall) or as a scope specifying 'within each province' (asking for the top pair per province), which would require grouping by province and yield different results."
"Using Year, Driver and Manufacturer and after cleaning `Average speed (mph)` by removing commas and treating it as a numeric `avg_spd` and cleaning `Laps` by removing any '*' and spaces and treating it as a number, produce a combined result of: (a) Drivers with COUNT(*) > 1 showing Driver as Entity, Wins, AVG(avg_spd) rounded to three decimals as AvgSpeed, MAX(avg_spd) rounded to three decimals as PeakSpeed and Type = 'Driver' while showing the driver row whose avg_spd equals that MAX, and (b) Manufacturers with COUNT(*) > 1 showing Manufacturer as Entity, Wins, AVG(avg_spd) rounded to three decimals as AvgSpeed, MAX(avg_spd) as PeakSpeed and Type = 'Manufacturer'; then order the combined set by Wins descending and AvgSpeed descending and return the top 10 rows?","
WITH `cleaned` AS (
 SELECT
  `Year`,
  `Driver`,
  `Manufacturer`,
  REPLACE(`Average speed (mph)`, ',', '') + 0.0 `avg_spd`,
  REPLACE(REPLACE(`Laps`, '*',''), ' ', '') + 0 `laps`
 FROM `table_1_16493961_1`
 WHERE `Average speed (mph)` IS NOT NULL
),
`driver_stats` AS (
 SELECT
  `Driver`,
  COUNT(*) `wins`,
  AVG(`avg_spd`) `avg_speed`,
  MAX(`avg_spd`) `max_speed`
 FROM `cleaned`
 GROUP BY `Driver`
 HAVING COUNT(*) > 1
)
SELECT DISTINCT
 ds.`Driver` `Entity`,
 ds.`wins` `Wins`,
 ROUND(ds.`avg_speed`,3) `AvgSpeed`,
 ROUND(ds.`max_speed`,3) `PeakSpeed`,
 'Driver' `Type`
FROM `driver_stats` ds
INNER JOIN `cleaned` c ON c.`Driver` = ds.`Driver` AND c.`avg_spd` = ds.`max_speed`
UNION ALL
SELECT DISTINCT
 `Manufacturer` `Entity`,
 COUNT(*) `Wins`,
 ROUND(AVG(`avg_spd`),3) `AvgSpeed`,
 MAX(`avg_spd`) `PeakSpeed`,
 'Manufacturer' `Type`
FROM `cleaned`
GROUP BY `Manufacturer`
HAVING COUNT(*) > 1
ORDER BY `Wins` DESC, `AvgSpeed` DESC
LIMIT 10;
","SELECT col2 AS `Entity`, COUNT(*) AS `Wins`, ROUND(AVG(REPLACE(col8, ',', '') + 0.0),3) AS `AvgSpeed`, MAX(REPLACE(col8, ',', '') + 0.0) AS `PeakSpeed`, 'Driver' AS `Type`
FROM `table_1_16493961_1`
WHERE col8 IS NOT NULL
GROUP BY col2
HAVING COUNT(*) > 1
UNION ALL
SELECT col4, COUNT(*), 0, 0, 'Manufacturer'
FROM `table_1_16493961_1`
GROUP BY col4
HAVING COUNT(*) > 1
ORDER BY `Wins` DESC, `AvgSpeed` DESC
LIMIT 10;","[('ford', 15, 0, 0, 'Manufacturer'), ('chevrolet', 12, 0, 0, 'Manufacturer'), ('mercury', 7, 0, 0, 'Manufacturer'), ('cale yarborough', 6, 136.497, 149.563, 'Driver'), ('david pearson', 4, 143.168, 153.485, 'Driver'), ('bill elliott', 4, 139.326, 144.724, 'Driver'), ('rusty wallace', 3, 148.202, 166.033, 'Driver'), ('dodge', 3, 0, 0, 'Manufacturer'), ('mark martin', 2, 157.093, 158.695, 'Driver'), ('davey allison', 2, 156.792, 160.912, 'Driver')]",table_1_16493961_1,"1) Parse SQL intent: produce a top-10 ranked list of Drivers and Manufacturers with multiple wins based on cleaned average speeds and win counts, selecting the driver row that matches each driver's peak speed. 2) Map schema semantics: clean `Average speed (mph)` by removing commas to compute numeric avg_spd, clean `Laps` by removing '*' and spaces to numeric laps, and use Year, Driver, Manufacturer fields in the cleaned set; aggregate by Driver and Manufacturer computing COUNT, AVG and MAX of avg_spd. 3) Draft the question: request Entity, Wins, AvgSpeed (rounded to 3 decimals), PeakSpeed and Type for Drivers (with peak-speed row) and Manufacturers, filtered to more than one win. 4) Validate: include HAVING COUNT(*)>1, join condition for driver peak rows, rounding of averages to three decimals, ordering by Wins then AvgSpeed, and LIMIT 10.",reserved,33,reward,,
"Break down the all-time Grizzlies roster by position with total player counts and, for each position, list Arizona alums, players with multiple stints, and players listed as active?","
SELECT
  `Position`,
  COUNT(*) AS `player_count`,
  SUM(CASE WHEN `School/Club Team` LIKE '%Arizona%' THEN 1 ELSE 0 END) AS `arizona_alumni`,
  GROUP_CONCAT(DISTINCT CASE WHEN `School/Club Team` LIKE '%Arizona%' THEN `Player` END) AS `arizona_players`,
  SUM(CASE WHEN `Years for Grizzlies` LIKE '%;%' THEN 1 ELSE 0 END) AS `multi_stint_count`,
  GROUP_CONCAT(DISTINCT CASE WHEN `Years for Grizzlies` LIKE '%;%' THEN `Player` END) AS `multi_stint_players`,
  SUM(CASE WHEN `Years for Grizzlies` LIKE '%Present%' THEN 1 ELSE 0 END) AS `active_count`,
  GROUP_CONCAT(DISTINCT CASE WHEN `Years for Grizzlies` LIKE '%Present%' THEN `Player` END) AS `active_players`
FROM `table_1_16494599_2`
GROUP BY `Position`
ORDER BY `player_count` DESC;
","
SELECT
  col3,
  COUNT(*) AS `player_count`,
  SUM(CASE WHEN col5 LIKE '%Arizona%' THEN 1 ELSE 0 END) AS `arizona_alumni`,
  GROUP_CONCAT(DISTINCT CASE WHEN col5 LIKE '%Arizona%' THEN col0 END) AS `arizona_players`,
  SUM(CASE WHEN col4 LIKE '%;%' THEN 1 ELSE 0 END) AS `multi_stint_count`,
  GROUP_CONCAT(DISTINCT CASE WHEN col4 LIKE '%;%' THEN col0 END) AS `multi_stint_players`,
  SUM(CASE WHEN col4 LIKE '%Present%' THEN 1 ELSE 0 END) AS `active_count`,
  GROUP_CONCAT(DISTINCT CASE WHEN col4 LIKE '%Present%' THEN col0 END) AS `active_players`
FROM `table_1_16494599_2`
GROUP BY col3
ORDER BY `player_count` DESC;
","[('point guard', 3, 2, 'jerryd bayless category:articles with hcards,mike bibby category:articles with hcards', 0, None, 1, 'jerryd bayless category:articles with hcards'), ('shooting guard', 2, 0, None, 0, None, 0, None), ('power forward', 2, 1, 'michael batiste category:articles with hcards', 0, None, 0, None), ('center', 2, 0, None, 0, None, 0, None), ('small forward', 1, 0, None, 1, 'shane battier category:articles with hcards', 0, None), ('guard-forward', 1, 0, None, 0, None, 0, None)]",table_1_16494599_2,"In preparation for an on-air graphic I'd ask succinctly for per-position counts plus alumni and status breakdowns and expect names. The SQL produces per-position player counts, sums and name lists for Arizona alumni, multi-stint players (Years containing ';'), and active players (Years containing 'Present'). The schema fields used are Position, Player, School/Club Team, and Years for Grizzlies. Drafted question: Break down the all-time Grizzlies roster by position with total player counts and, for each position, list Arizona alums, players with multiple stints, and players listed as active. This precisely reflects the grouped counts and concatenated name fields returned by the query.",persona,"Senior sports data analyst at a regional sports network who builds roster analytics and on-air graphics; uses the Memphis Grizzlies all-time roster to analyze player backgrounds, position makeup, and notable alumni for stories and visualizations. Goals: Summarize roster composition by position and identify position trends over the franchise history. Find and profile players who attended specific schools or club teams (e.g., Arizona programs) for feature segments. Detect players with multiple stints on the Grizzlies and identify currently active players for up-to-date coverage. Example Queries: -- 1) Count how many players there are by position
    SELECT ""Position"", COUNT(*) AS player_count
    FROM table_1_16494599_2
    GROUP BY ""Position""
    ORDER BY player_count DESC; -- 2) List players who attended Arizona schools (Arizona, Arizona State, etc.)
    SELECT ""Player"", ""No."", ""Position"", ""Years for Grizzlies"", ""School/Club Team""
    FROM table_1_16494599_2
    WHERE ""School/Club Team"" LIKE '%Arizona%'
    ORDER BY ""Years for Grizzlies"" DESC, ""Player""; -- 3) Find players with multiple stints (entries with a semicolon in Years) or explicitly marked as still active
    SELECT ""Player"", ""No."", ""Position"", ""Years for Grizzlies""
    FROM table_1_16494599_2
    WHERE ""Years for Grizzlies"" LIKE '%;%'
       OR ""Years for Grizzlies"" LIKE '%Present%'
    ORDER BY ""Years for Grizzlies"";",reward,,
Which managers had above-average wins — show the top three?,"
SELECT `Manager`, COUNT(*) `Seasons`, SUM(`Wins`) `Total Wins`, SUM(`Losses`) `Total Losses`, ROUND(AVG(`Wins`),2) `Avg Wins`, ROUND(100.0*SUM(`Wins`)/(SUM(`Wins`)+SUM(`Losses`)),3) `Win Pct`
FROM `table_1_16512618_1`
GROUP BY `Manager`
HAVING AVG(`Wins`) > (SELECT AVG(`Wins`) FROM `table_1_16512618_1`)
ORDER BY AVG(`Wins`) DESC
LIMIT 3;
","
SELECT col5, COUNT(*) `Seasons`, SUM(col1) `Total Wins`, SUM(col2) `Total Losses`, ROUND(AVG(col1),2) `Avg Wins`, ROUND(100.0*SUM(col1)/(SUM(col1)+SUM(col2)),3) `Win Pct`
FROM `table_1_16512618_1`
GROUP BY col5
HAVING AVG(col1) > (SELECT AVG(col1) FROM `table_1_16512618_1`)
ORDER BY AVG(col1) DESC
LIMIT 3;
","[('win clark', 1, 87.0, 51.0, 87.0, 63.043), ('joe cobb/ eddie onslow', 1, 83.0, 56.0, 83.0, 59.712), ('glen killinger', 1, 82.0, 54.0, 82.0, 60.294)]",table_1_16512618_1,"STEP 1: Parse the SQL intent — compute, for each Manager, number of seasons, total wins, total losses, average wins and win pct; keep only managers whose average wins exceed the overall season-average wins; order by manager average wins descending and return the top 3. STEP 2: Choose ambiguity type — scope ambiguity fits best because the phrase “above-average” or “top three” can apply to single seasons, to a manager's average across seasons, to their totals, or to every season they managed. STEP 3: Draft the question — a concise ambiguous NL rendering that matches the SQL but allows other readings. STEP 4: Explain the ambiguity — the SQL treats “above-average” as the manager's average wins exceeding the overall average and ranks by that same average, but a reader could instead mean managers with any season above average, managers with total wins above average, managers whose every season was above average, or rank by win pct instead.",reserved,10,reward,,"type: Scope ambiguity (per-season vs. per-manager average; also metric/ranking scope) | explanation: The SQL chooses managers whose average wins (across their seasons) exceed the overall season-average and returns the top three by that average, but the question could instead be read as asking for managers with any single season above average, managers with the highest total wins, managers whose every season was above average, or the top three by win percentage."
Which districts had the longest vacancy before a successor was seated?,"
WITH b AS (
  SELECT
    `District`,
    `Vacator`,
    `Reason for change`,
    `Successor`,
    `Date successor seated`,
    lower(`Reason for change`) AS reason_l,
    instr(lower(`Reason for change`),'died ') AS pos_died,
    CASE 
      WHEN instr(lower(`Reason for change`),'died ')>0 THEN substr(`Reason for change`, instr(lower(`Reason for change`),'died ')+5)
      ELSE NULL
    END AS death_text,
    CASE 
      WHEN `Date successor seated` NOT LIKE '%Not filled%' AND `Date successor seated` NOT LIKE '%?%' THEN `Date successor seated`
      ELSE NULL
    END AS seating_text
  FROM table_1_1651764_3
  WHERE lower(`Reason for change`) LIKE '%died%'
),
parsed AS (
  SELECT
    `District`,
    `Vacator`,
    `Reason for change`,
    `Successor`,
    `Date successor seated`,
    death_text,
    seating_text,
    -- parse death_text into ISO date if it contains a comma (Month D, YYYY)
    CASE 
      WHEN death_text IS NOT NULL AND instr(death_text,',')>0 THEN trim(substr(death_text,1,instr(death_text,' ')-1))
      ELSE NULL
    END AS death_month,
    CASE 
      WHEN death_text IS NOT NULL AND instr(death_text,',')>0 THEN trim(substr(death_text, instr(death_text,' ')+1, instr(death_text,',') - instr(death_text,' ')-1))
      ELSE NULL
    END AS death_day,
    CASE 
      WHEN death_text IS NOT NULL AND instr(death_text,',')>0 THEN trim(substr(death_text, instr(death_text,',')+2))
      ELSE NULL
    END AS death_year,
    CASE 
      WHEN death_text IS NOT NULL AND instr(death_text,',')>0 THEN
        (CASE lower(trim(substr(death_text,1,instr(death_text,' ')-1)))
          WHEN 'january' THEN '01' WHEN 'february' THEN '02' WHEN 'march' THEN '03' WHEN 'april' THEN '04'
          WHEN 'may' THEN '05' WHEN 'june' THEN '06' WHEN 'july' THEN '07' WHEN 'august' THEN '08'
          WHEN 'september' THEN '09' WHEN 'october' THEN '10' WHEN 'november' THEN '11' WHEN 'december' THEN '12'
          ELSE NULL END)
      ELSE NULL
    END AS death_month_num,
    -- assemble vacancy ISO date
    CASE 
      WHEN death_text IS NOT NULL AND instr(death_text,',')>0 THEN (death_year || '-' || 
           (CASE lower(trim(substr(death_text,1,instr(death_text,' ')-1)))
             WHEN 'january' THEN '01' WHEN 'february' THEN '02' WHEN 'march' THEN '03' WHEN 'april' THEN '04'
             WHEN 'may' THEN '05' WHEN 'june' THEN '06' WHEN 'july' THEN '07' WHEN 'august' THEN '08'
             WHEN 'september' THEN '09' WHEN 'october' THEN '10' WHEN 'november' THEN '11' WHEN 'december' THEN '12'
             ELSE '00' END) || '-' || printf('%02d', cast(trim(substr(death_text, instr(death_text,' ')+1, instr(death_text,',') - instr(death_text,' ')-1)) AS integer)))
      ELSE NULL
    END AS Vacancy_ISO,
    -- parse seating_text into ISO date if present
    CASE WHEN seating_text IS NOT NULL THEN trim(substr(seating_text,1,instr(seating_text,' ')-1)) ELSE NULL END AS seat_month,
    CASE WHEN seating_text IS NOT NULL THEN trim(substr(seating_text, instr(seating_text,' ')+1, instr(seating_text,',') - instr(seating_text,' ')-1)) ELSE NULL END AS seat_day,
    CASE WHEN seating_text IS NOT NULL THEN trim(substr(seating_text, instr(seating_text,',')+2)) ELSE NULL END AS seat_year,
    CASE WHEN seating_text IS NOT NULL THEN
      (CASE lower(trim(substr(seating_text,1,instr(seating_text,' ')-1)))
        WHEN 'january' THEN '01' WHEN 'february' THEN '02' WHEN 'march' THEN '03' WHEN 'april' THEN '04'
        WHEN 'may' THEN '05' WHEN 'june' THEN '06' WHEN 'july' THEN '07' WHEN 'august' THEN '08'
        WHEN 'september' THEN '09' WHEN 'october' THEN '10' WHEN 'november' THEN '11' WHEN 'december' THEN '12'
        ELSE NULL END)
      ELSE NULL END AS seat_month_num,
    CASE WHEN seating_text IS NOT NULL THEN (seat_year || '-' || seat_month_num || '-' || printf('%02d', cast(seat_day AS integer))) ELSE NULL END AS Seating_ISO
  FROM b
)
SELECT
  `District`,
  `Vacator`,
  `Reason for change`,
  `Successor`,
  `Date successor seated`,
  Vacancy_ISO AS `Vacancy_ISO`,
  Seating_ISO AS `Seating_ISO`,
  CASE 
    WHEN Vacancy_ISO IS NOT NULL AND Seating_ISO IS NOT NULL 
    THEN CAST(round(julianday(Seating_ISO) - julianday(Vacancy_ISO)) AS INTEGER)
    ELSE NULL
  END AS `Days_to_seat`,
  CASE WHEN `Date successor seated` = 'Not filled this term' OR `Successor` = 'Vacant' THEN 1 ELSE 0 END AS `Not_filled_flag`,
  CASE 
    WHEN `Reason for change` LIKE '%Changed political affiliation%' 
      OR (`Vacator` LIKE '%(R)%' AND `Successor` LIKE '%(D)%') 
      OR (`Vacator` LIKE '%(D)%' AND `Successor` LIKE '%(R)%') 
    THEN 1 ELSE 0 
  END AS `Party_switch_flag`,
  CASE 
    WHEN replace(replace(`Vacator`,' (R)',''),' (D)','') = replace(replace(`Successor`,' (R)',''),' (D)','') 
         AND `Vacator` != `Successor` 
    THEN 1 ELSE 0 
  END AS `Same_person_diff_party_flag`
FROM parsed
ORDER BY COALESCE(Vacancy_ISO,'9999-12-31'), COALESCE(Seating_ISO,'9999-12-31');
","WITH b AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    lower(col2) AS reason_l,
    instr(lower(col2),'died ') AS pos_died,
    CASE 
      WHEN instr(lower(col2),'died ')>0 THEN trim(substr(col2, instr(lower(col2),'died ')+5))
      ELSE NULL
    END AS death_text,
    CASE 
      WHEN col4 NOT LIKE '%Not filled%' AND col4 NOT LIKE '%?%' THEN col4
      ELSE NULL
    END AS seating_text
  FROM table_1_1651764_3
  WHERE lower(col2) LIKE '%died%'
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  CASE 
    WHEN death_text IS NOT NULL AND instr(death_text,',')>0 THEN
      trim(substr(death_text, instr(death_text,',')+2)) || '-' ||
      (CASE lower(trim(substr(death_text,1,instr(death_text,' ')-1)))
        WHEN 'january' THEN '01' WHEN 'february' THEN '02' WHEN 'march' THEN '03' WHEN 'april' THEN '04'
        WHEN 'may' THEN '05' WHEN 'june' THEN '06' WHEN 'july' THEN '07' WHEN 'august' THEN '08'
        WHEN 'september' THEN '09' WHEN 'october' THEN '10' WHEN 'november' THEN '11' WHEN 'december' THEN '12'
        ELSE '00' END) || '-' || printf('%02d', cast(trim(substr(death_text, instr(death_text,' ')+1, instr(death_text,',') - instr(death_text,' ')-1)) AS integer))
    ELSE NULL
  END AS Vacancy_ISO,
  CASE 
    WHEN seating_text IS NOT NULL AND instr(seating_text,',')>0 THEN
      trim(substr(seating_text, instr(seating_text,',')+2)) || '-' ||
      (CASE lower(trim(substr(seating_text,1,instr(seating_text,' ')-1)))
        WHEN 'january' THEN '01' WHEN 'february' THEN '02' WHEN 'march' THEN '03' WHEN 'april' THEN '04'
        WHEN 'may' THEN '05' WHEN 'june' THEN '06' WHEN 'july' THEN '07' WHEN 'august' THEN '08'
        WHEN 'september' THEN '09' WHEN 'october' THEN '10' WHEN 'november' THEN '11' WHEN 'december' THEN '12'
        ELSE '00' END) || '-' || printf('%02d', cast(trim(substr(seating_text, instr(seating_text,' ')+1, instr(seating_text,',') - instr(seating_text,' ')-1)) AS integer))
    ELSE NULL
  END AS Seating_ISO,
  CASE 
    WHEN death_text IS NOT NULL AND instr(death_text,',')>0 AND seating_text IS NOT NULL AND instr(seating_text,',')>0 THEN
      CAST(round(
        julianday(
          trim(substr(seating_text, instr(seating_text,',')+2)) || '-' ||
          (CASE lower(trim(substr(seating_text,1,instr(seating_text,' ')-1)))
            WHEN 'january' THEN '01' WHEN 'february' THEN '02' WHEN 'march' THEN '03' WHEN 'april' THEN '04'
            WHEN 'may' THEN '05' WHEN 'june' THEN '06' WHEN 'july' THEN '07' WHEN 'august' THEN '08'
            WHEN 'september' THEN '09' WHEN 'october' THEN '10' WHEN 'november' THEN '11' WHEN 'december' THEN '12'
            ELSE '00' END) || '-' || printf('%02d', cast(trim(substr(seating_text, instr(seating_text,' ')+1, instr(seating_text,',') - instr(seating_text,' ')-1)) AS integer))
        )
        - julianday(
          trim(substr(death_text, instr(death_text,',')+2)) || '-' ||
          (CASE lower(trim(substr(death_text,1,instr(death_text,' ')-1)))
            WHEN 'january' THEN '01' WHEN 'february' THEN '02' WHEN 'march' THEN '03' WHEN 'april' THEN '04'
            WHEN 'may' THEN '05' WHEN 'june' THEN '06' WHEN 'july' THEN '07' WHEN 'august' THEN '08'
            WHEN 'september' THEN '09' WHEN 'october' THEN '10' WHEN 'november' THEN '11' WHEN 'december' THEN '12'
            ELSE '00' END) || '-' || printf('%02d', cast(trim(substr(death_text, instr(death_text,' ')+1, instr(death_text,',') - instr(death_text,' ')-1)) AS integer))
        )
      ) AS INTEGER)
    ELSE NULL
  END AS `Days_to_seat`,
  CASE WHEN col4 = 'Not filled this term' OR col3 = 'Vacant' THEN 1 ELSE 0 END AS `Not_filled_flag`,
  CASE 
    WHEN col2 LIKE '%Changed political affiliation%' 
      OR (col1 LIKE '%(R)%' AND col3 LIKE '%(D)%') 
      OR (col1 LIKE '%(D)%' AND col3 LIKE '%(R)%') 
    THEN 1 ELSE 0 
  END AS `Party_switch_flag`,
  CASE 
    WHEN replace(replace(col1,' (R)',''),' (D)','') = replace(replace(col3,' (R)',''),' (D)','') 
         AND col1 != col3 
    THEN 1 ELSE 0 
  END AS `Same_person_diff_party_flag`
FROM b
ORDER BY COALESCE(Vacancy_ISO,'9999-12-31'), COALESCE(Seating_ISO,'9999-12-31');","[('illinois 7th', 'james bowler (d)', 'died july 18, 1957', 'roland v. libonati (d)', 'december 31, 1957', '1957-07-18', '1957-12-31', 166, 0, 0, 0), ('georgia 7th', 'henderson l. lanham (d)', 'died november 10, 1957', 'harlan e. mitchell (d)', 'january 8, 1958', '1957-11-10', '1958-01-08', 59, 0, 0, 0), ('pennsylvania 21st', 'augustine b. kelley (d)', 'died november 20, 1957', 'john h. dent (d)', 'january 21, 1958', '1957-11-20', '1958-01-21', 62, 0, 0, 0), ('tennessee 8th', 'jere cooper (d)', 'died december 18, 1957', 'robert ""fats"" everett (d)', 'february 1, 1958', '1957-12-18', '1958-02-01', 45, 0, 0, 0), ('illinois 14th', 'russell w. keeney (r)', 'died january 11, 1958', 'vacant', 'not filled this term', '1958-01-11', None, None, 0, 0, 0), ('minnesota 1st', 'august h. andresen (r)', 'died january 14, 1958', 'al quie (r)', 'february 18, 1958', '1958-01-14', '1958-02-18', 35, 0, 0, 0), ('wisconsin 1st', 'lawrence h. smith (r)', 'died january 22, 1958', 'vacant', 'not filled this term', '1958-01-22', None, None, 0, 0, 0), ('new mexico at-large', 'john j. dempsey (d)', 'died march 11, 1958', 'vacant', 'not filled this term', '1958-03-11', None, None, 0, 0, 0), ('louisiana 8th', 'george s. long (d)', 'died march 22, 1958', 'vacant', 'not filled this term', '1958-03-22', None, None, 0, 0, 0), ('illinois 4th', 'william e. mcvey (r)', 'died august 10, 1958', 'vacant', 'not filled this term', '1958-08-10', None, None, 0, 0, 0), ('pennsylvania 28th', 'herman p. eberharter (d)', 'died september 9, 1958', 'vacant', 'not filled this term', '1958-09-09', None, None, 0, 0, 0), ('illinois 20th', 'sid simpson (r)', 'died october 26, 1958', 'vacant', 'not filled this term', '1958-10-26', None, None, 0, 0, 0), ('new jersey 2nd', 'vacant', 'rep. t. millet hand died during previous congress', 'milton w. glenn (r)', 'november 5, 1957', None, '1957-11-05', None, 0, 0, 0)]",table_1_1651764_3,"STEP 1: Parse the SQL intent — filter rows where Reason for change mentions 'died', extract text after 'died', parse that and the 'Date successor seated' when in 'Month D, YYYY' form into Vacancy_ISO and Seating_ISO, compute Days_to_seat as julianday(Seating_ISO)-julianday(Vacancy_ISO) when both dates are present, mark rows 'Not_filled' when successor is 'Vacant' or 'Not filled this term', compute party-change related flags, and order by vacancy and seating dates. STEP 2: Determine ambiguity type — scope ambiguity fits best: the phrase 'longest vacancy' can mean different scopes (only rows with numeric Days_to_seat vs. treating unfilled/vacant records as infinitely long or as candidates). It's fitting because the query produces NULL for Days_to_seat when dates are missing and explicitly flags not-filled vacancies. STEP 3: Draft the question — produce a concise natural-language question that is a valid interpretation of the SQL but ambiguous: ""Which districts had the longest vacancy before a successor was seated?"" STEP 4: Explain the ambiguity — in the original query 'longest' is resolved only among rows where both parsed vacancy and seating dates exist (Days_to_seat is numeric) and rows marked Not_filled get NULL for Days_to_seat; alternatively a user could reasonably interpret 'longest' to include vacancies that were never filled (treating them as longest) or to ask for the single longest overall vs. longest per some group (e.g., per party).",persona,"A mid‑century civic‑data artist who builds kinetic timeline sculptures that animate House seat vacancies, deaths, party switches and successor seatings from 1957–58. Goals: Extract all vacancy events caused by deaths to create a chronological animation of when seats opened and when successors were seated. Identify and highlight seats that were never filled during the term and long delays between a vacancy and its successor for dramatic pacing in the sculpture. Spot party switches and anomalous entries (e.g., same person listed with different party tags or 'Changed political affiliation') to create visual accent markers and explanatory placards. Obtain tidy name/date rows to annotate each kinetic element in the exhibit (district, vacator, reason, successor, seating date). Example Queries: /* 1) Timeline-ready list of vacancies due to death, excluding entries not filled or malformed dates */
SELECT District, Vacator, `Reason for change`, Successor, `Date successor seated`
FROM table_1_1651764_3
WHERE `Reason for change` LIKE '%Died%'
  AND `Date successor seated` NOT LIKE '%Not filled%'
  AND `Date successor seated` NOT LIKE '%?%'
ORDER BY STR_TO_DATE(`Date successor seated`, '%M %e, %Y'); /* 2) Seats left vacant (not filled this term) to mark as 'open' pieces in the installation */
SELECT District, Vacator, `Reason for change`, Successor, `Date successor seated`
FROM table_1_1651764_3
WHERE Successor = 'Vacant'
   OR `Date successor seated` = 'Not filled this term'; /* 3) Find party switches or explicit affiliation changes for visual accents */
SELECT District, Vacator, `Reason for change`, Successor, `Date successor seated`
FROM table_1_1651764_3
WHERE `Reason for change` LIKE '%Changed%'
   OR (Vacator LIKE '%(R)%' AND Successor LIKE '%(D)%')
   OR (Vacator LIKE '%(D)%' AND Successor LIKE '%(R)%');",reward,,"type: Scope ambiguity | explanation: The SQL computes Days_to_seat only when both vacancy and seating dates parse to ISO (so unfilled/ unparsable rows yield NULL), so 'longest vacancy' in the query is among numeric Days_to_seat values; a reader could instead interpret 'longest' to include records marked 'Not filled this term' or 'Vacant' (treating them as longest) or to mean the longest per subgroup rather than the single longest overall."
"For every record, provide District, Vacator, Reason for change, Successor, and Date successor seated, and indicate a Filling status which is 'Unfilled this term' if the Successor or Date successor seated contains the text 'Vacant' or 'Not filled this term', otherwise indicate 'Seated'?","
SELECT `District`, `Vacator`, `Reason for change`, `Successor`, `Date successor seated`,
CASE WHEN (instr(`Successor` || ' ' || `Date successor seated`, 'Vacant') + instr(`Successor` || ' ' || `Date successor seated`, 'Not filled this term')) > 0 THEN 'Unfilled this term' ELSE 'Seated' END AS `Filling status`
FROM `table_1_1652224_5`;
","
SELECT col0, col1, col2, col3, col4,
CASE WHEN (instr(col3 || ' ' || col4, 'Vacant') + instr(col3 || ' ' || col4, 'Not filled this term')) > 0 THEN 'Unfilled this term' ELSE 'Seated' END AS `Filling status`
FROM `table_1_1652224_5`;
","[('georgia 2nd', 'vacant', 'rep. edward e. cox died during previous congress', 'j. l. pilcher (d)', 'february 4, 1953', 'Seated'), ('south carolina 4th', 'joseph r. bryson (d)', 'died march 10, 1953', 'robert t. ashmore (d)', 'june 2, 1953', 'Seated'), ('kentucky 2nd', 'garrett l. withers (d)', 'died april 30, 1953', 'william h. natcher (d)', 'august 1, 1953', 'Seated'), ('wisconsin 9th', 'merlin hull (r)', 'died may 17, 1953', 'lester johnson (d)', 'october 13, 1953', 'Seated'), ('new jersey 6th', 'clifford p. case (r)', 'resigned august 16, 1953', 'harrison a. williams (d)', 'november 3, 1953', 'Seated'), ('hawaii territory at-large', 'joseph r. farrington (r)', 'resigned june 19, 1954', 'elizabeth p. farrington (r)', 'july 31, 1954', 'Seated'), ('georgia 4th', 'a. sidney camp (d)', 'died july 24, 1954', 'john j. flynt, jr. (d)', 'november 2, 1954', 'Seated'), ('michigan 3rd', 'paul w. shafer (r)', 'died august 17, 1954', 'vacant', 'not filled this term', 'Seated'), ('ohio 15th', 'robert t. secrest (d)', 'resigned september 26, 1954', 'vacant', 'not filled this term', 'Seated')]",table_1_1652224_5,"1) Parse intent: output the five specified columns and a derived Filling status which checks concatenated Successor and Date successor seated for certain keywords. 2) Map schema: map the five columns District, Vacator, Reason for change, Successor, Date successor seated and implement the CASE that looks for 'Vacant' or 'Not filled this term'. 3) Draft: request the columns and the conditional Filling status exactly as in the query. 4) Validate: ensure the phrasing includes both keywords and the two possible status values 'Unfilled this term' and 'Seated'.",reserved,8,reward,,
"Which Confidential clips should I consider for Dalek or The Doctor Dances puzzles or for special-episode timeline work — include their UK airdates, episode numbers, segment titles, linked Doctor Who episode, webcast link and tags?","
SELECT
  `Episode #`,
  `Original airdate (UK)`,
  `Episode title`,
  `Doctor Who episode`,
  `Webcast link`,
  TRIM(
    (CASE WHEN `Webcast link` <> 'N/A' THEN ',usable_webcast' ELSE '' END) ||
    (CASE WHEN `Doctor Who episode` LIKE '%Dalek%' OR `Episode title` LIKE '%Dalek%' THEN ',iconic: Dalek' ELSE '' END) ||
    (CASE WHEN `Doctor Who episode` LIKE '%The Doctor Dances%' OR `Episode title` LIKE '%The Doctor Dances%' THEN ',iconic: The Doctor Dances' ELSE '' END) ||
    (CASE WHEN `Episode #` LIKE 'S%' THEN ',special' ELSE '' END)
  , ',') AS `Tags`,
  (CASE
     WHEN `Original airdate (UK)` LIKE '% March %' THEN substr(`Original airdate (UK)`, -4) || '-03-' || printf('%02d', CAST(substr(`Original airdate (UK)`, 1, instr(`Original airdate (UK)`, ' ')-1) AS INTEGER))
     WHEN `Original airdate (UK)` LIKE '% April %' THEN substr(`Original airdate (UK)`, -4) || '-04-' || printf('%02d', CAST(substr(`Original airdate (UK)`, 1, instr(`Original airdate (UK)`, ' ')-1) AS INTEGER))
     WHEN `Original airdate (UK)` LIKE '% May %' THEN substr(`Original airdate (UK)`, -4) || '-05-' || printf('%02d', CAST(substr(`Original airdate (UK)`, 1, instr(`Original airdate (UK)`, ' ')-1) AS INTEGER))
     WHEN `Original airdate (UK)` LIKE '% June %' THEN substr(`Original airdate (UK)`, -4) || '-06-' || printf('%02d', CAST(substr(`Original airdate (UK)`, 1, instr(`Original airdate (UK)`, ' ')-1) AS INTEGER))
     ELSE NULL
   END) AS `ISO Date`
FROM `table_1_1656361_1`
WHERE
  `Webcast link` <> 'N/A'
  OR `Doctor Who episode` LIKE '%Dalek%'
  OR `Episode title` LIKE '%Dalek%'
  OR `Doctor Who episode` LIKE '%The Doctor Dances%'
  OR `Episode title` LIKE '%The Doctor Dances%'
  OR `Episode #` LIKE 'S%'
ORDER BY `ISO Date`, `Original airdate (UK)`;
","
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  TRIM(
    (CASE WHEN col4 <> 'N/A' THEN ',usable_webcast' ELSE '' END) ||
    (CASE WHEN col3 LIKE '%Dalek%' OR col2 LIKE '%Dalek%' THEN ',iconic: Dalek' ELSE '' END) ||
    (CASE WHEN col3 LIKE '%The Doctor Dances%' OR col2 LIKE '%The Doctor Dances%' THEN ',iconic: The Doctor Dances' ELSE '' END) ||
    (CASE WHEN col0 LIKE 'S%' THEN ',special' ELSE '' END)
  , ',') AS `Tags`,
  (CASE
     WHEN col1 LIKE '% March %' THEN substr(col1, -4) || '-03-' || printf('%02d', CAST(substr(col1, 1, instr(col1, ' ')-1) AS INTEGER))
     WHEN col1 LIKE '% April %' THEN substr(col1, -4) || '-04-' || printf('%02d', CAST(substr(col1, 1, instr(col1, ' ')-1) AS INTEGER))
     WHEN col1 LIKE '% May %' THEN substr(col1, -4) || '-05-' || printf('%02d', CAST(substr(col1, 1, instr(col1, ' ')-1) AS INTEGER))
     WHEN col1 LIKE '% June %' THEN substr(col1, -4) || '-06-' || printf('%02d', CAST(substr(col1, 1, instr(col1, ' ')-1) AS INTEGER))
     ELSE NULL
   END) AS `ISO Date`
FROM `table_1_1656361_1`
WHERE
  col4 <> 'N/A'
  OR col3 LIKE '%Dalek%'
  OR col2 LIKE '%Dalek%'
  OR col3 LIKE '%The Doctor Dances%'
  OR col2 LIKE '%The Doctor Dances%'
  OR col0 LIKE 'S%'
ORDER BY `ISO Date`, col1;
","[('s1', '26 march 2005', '""a new dimension""', 'preview', 'n/a', 'usable_webcast,special', '2005-03-26'), ('1', '26 march 2005', '""bringing back the doctor""', '"" rose ""', 'link', 'usable_webcast', '2005-03-26'), ('2', '2 april 2005', '""the good, the bad and the ugly""', '"" the end of the world ""', 'link', 'usable_webcast', '2005-04-02'), ('3', '9 april 2005', '""tardis tales""', '"" the unquiet dead ""', 'link', 'usable_webcast', '2005-04-09'), ('4', '16 april 2005', '""i get a side-kick out of you""', '"" aliens of london ""', 'link', 'usable_webcast', '2005-04-16'), ('5', '23 april 2005', '""why on earth?""', '"" world war three ""', 'link', 'usable_webcast', '2005-04-23'), ('6', '30 april 2005', '""dalek""', '"" dalek ""', 'link', 'usable_webcast,iconic: Dalek', '2005-04-30'), ('7', '7 may 2005', '""the dark side""', '"" the long game ""', 'link', 'usable_webcast', '2005-05-07'), ('8', '14 may 2005', '""time trouble""', '"" father\'s day ""', 'link', 'usable_webcast', '2005-05-14'), ('9', '21 may 2005', '""special effects""', '"" the empty child ""', 'link', 'usable_webcast', '2005-05-21'), ('10', '28 may 2005', '""weird science""', '"" the doctor dances ""', 'link', 'usable_webcast,iconic: The Doctor Dances', '2005-05-28'), ('11', '4 june 2005', '""unsung heroes and violent death""', '"" boom town ""', 'link', 'usable_webcast', '2005-06-04'), ('12', '11 june 2005', '""the world of who""', '"" bad wolf ""', 'link', 'usable_webcast', '2005-06-11'), ('13', '18 june 2005', '""the last battle""', '"" the parting of the ways ""', 'link', 'usable_webcast', '2005-06-18'), ('s2', '18 june 2005', '""the ultimate guide""', 'episodes 1–12', 'n/a', 'usable_webcast,special', '2005-06-18')]",table_1_1656361_1,"My tone here is story-led and a bit theatrical, fitting a puzzle maker assembling clues. The SQL pulls any segment with an actual webcast, any that reference Dalek or The Doctor Dances, or entries marked as specials, and orders them by converted ISO date. It uses the episode number, UK airdate, segment title, Doctor Who episode field and webcast link to build the result and tags. Draft question: Which Confidential clips should I consider for Dalek/The Doctor Dances puzzles or special-episode timeline work — include their airdates, IDs, titles, linked episode, link and tags? Validation: The phrasing asks for the same filtered rows and fields the query produces, in a narrative designer voice.",persona,"An immersive-narrative puzzle designer for a Doctor Who escape-room company who mines Doctor Who Confidential to extract authentic behind-the-scenes clips, dates and thematic hooks for timed puzzles and props. Goals: Find which Confidential segments have usable webcast clips (not 'N/A') so the team can license short audio/video excerpts for in-room clues. Locate all behind-the-scenes material tied to specific iconic episodes (e.g., 'Dalek', 'The Doctor Dances') to craft episode-specific puzzle arcs and props. Identify special/bonus Confidential episodes (S1, S2, etc.) and their airdates to build a historically accurate timeline puzzle that players must order correctly. Example Queries: SELECT [Episode #], [Original airdate (UK)], [Episode title], [Doctor Who episode], [Webcast link]
FROM [table_1_1656361_1]
WHERE [Webcast link] <> 'N/A'
ORDER BY [Original airdate (UK)]; SELECT *
FROM [table_1_1656361_1]
WHERE [Doctor Who episode] LIKE '%Dalek%'
   OR [Episode title] LIKE '%Dalek%'
ORDER BY [Original airdate (UK)]; SELECT [Episode #], [Original airdate (UK)], [Episode title], [Doctor Who episode], [Webcast link]
FROM [table_1_1656361_1]
WHERE [Episode #] LIKE 'S%'
ORDER BY [Original airdate (UK)];",reward,,
"Group the data by Era where Era is determined from the last four characters of Appointed Archbishop (if that year < '1900' call it 'Before 1900' else '1900s'); for each Era return the Era label, COUNT(Archbishop) and the average of (substr(Vacated throne,-4,4) minus substr(Appointed Archbishop,-4,4)) as the average tenure in years, and return up to 10 rows?","
SELECT CASE WHEN substr(`Appointed Archbishop`, -4, 4) < '1900' THEN 'Before 1900' ELSE '1900s' END `Era`, COUNT(`Archbishop`) `CountArchbishops`, AVG(substr(`Vacated throne`, -4, 4) - substr(`Appointed Archbishop`, -4, 4)) `AvgTenureYears`
FROM `table_1_1656555_1`
GROUP BY `Era`
LIMIT 10;
","
SELECT CASE WHEN substr(col4, -4, 4) < '1900' THEN 'Before 1900' ELSE '1900s' END `Era`, COUNT(col0) `CountArchbishops`, AVG(substr(col5, -4, 4) - substr(col4, -4, 4)) `AvgTenureYears`
FROM `table_1_1656555_1`
GROUP BY `Era`
LIMIT 10;
","[('1900s', 6, 13.5), ('Before 1900', 4, 7.5)]",table_1_1656555_1,"1) Parse SQL intent: bucket rows into 'Before 1900' or '1900s' based on substr(Appointed Archbishop, -4,4), count Archbishops in each bucket, and compute AVG(substr(Vacated throne, -4,4) - substr(Appointed Archbishop, -4,4)); group by Era and apply LIMIT 10. 2) Map schema: use columns Appointed Archbishop, Vacated throne, and Archbishop to produce the counts and average tenure. 3) Draft: ask explicitly for Era logic, COUNT, and AVG of year differences per Era. 4) Validate: confirm inclusion of substring-based Era rule, COUNT(Archbishop), AVG of the year subtraction, GROUP BY Era, and LIMIT 10.",reserved,10,reward,,
"Show me all seasons that would qualify for a limited-edition card because of a league change, division change, 'In progress' status, a top-3 regular-season finish, or any Open Cup involvement, and include the seasons' details, the reasons they're rare, and a rarity score.","
WITH seasons AS (
  SELECT
    rowid,
    `Year`,
    `Division`,
    `League`,
    `Regular Season`,
    `Playoffs`,
    `Open Cup`,
    LAG(`League`) OVER (ORDER BY `Year`) AS `Previous League`,
    LAG(`Division`) OVER (ORDER BY `Year`) AS `Previous Division`
  FROM `table_1_16636344_1`
)
SELECT
  `Year`,
  `Division`,
  `League`,
  `Regular Season`,
  `Playoffs`,
  `Open Cup`,
  TRIM(
    (CASE WHEN `League` IS NOT NULL AND `League` != `Previous League` THEN 'League change; ' ELSE '' END) ||
    (CASE WHEN `Previous Division` IS NOT NULL AND `Division` IS NOT NULL AND `Division` != `Previous Division` THEN 'Division change; ' ELSE '' END) ||
    (CASE WHEN `Regular Season` = 'In progress' THEN 'Status: In progress; ' ELSE '' END) ||
    (CASE WHEN `Regular Season` LIKE '1st%' OR `Regular Season` LIKE '2nd%' OR `Regular Season` LIKE '3rd%' THEN 'Top-3 finish; ' ELSE '' END) ||
    (CASE WHEN `Open Cup` NOT IN ('Did not qualify','Did not enter') THEN 'Open Cup involvement; ' ELSE '' END)
  ) AS `Rarity reasons`,
  (
    (CASE WHEN `League` IS NOT NULL AND `League` != `Previous League` THEN 3 ELSE 0 END) +
    (CASE WHEN `Previous Division` IS NOT NULL AND `Division` IS NOT NULL AND `Division` != `Previous Division` THEN 2 ELSE 0 END) +
    (CASE WHEN `Regular Season` = 'In progress' THEN 2 ELSE 0 END) +
    (CASE WHEN `Regular Season` LIKE '1st%' OR `Regular Season` LIKE '2nd%' OR `Regular Season` LIKE '3rd%' THEN 3 ELSE 0 END) +
    (CASE WHEN `Open Cup` NOT IN ('Did not qualify','Did not enter') THEN 4 ELSE 0 END)
  ) AS `Rarity score`
FROM seasons
WHERE
  (`League` IS NOT NULL AND `Previous League` IS NOT NULL AND `League` != `Previous League`)
  OR (`Previous Division` IS NOT NULL AND `Division` IS NOT NULL AND `Division` != `Previous Division`)
  OR `Regular Season` = 'In progress'
  OR `Regular Season` LIKE '1st%'
  OR `Regular Season` LIKE '2nd%'
  OR `Regular Season` LIKE '3rd%'
  OR `Open Cup` NOT IN ('Did not qualify','Did not enter')
ORDER BY `Rarity score` DESC, `Year` ASC;
","
WITH seasons AS (
  SELECT
    rowid,
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    LAG(col2) OVER (ORDER BY col0) AS `Previous League`,
    LAG(col1) OVER (ORDER BY col0) AS `Previous Division`
  FROM `table_1_16636344_1`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  TRIM(
    (CASE WHEN col2 IS NOT NULL AND col2 != `Previous League` THEN 'League change; ' ELSE '' END) ||
    (CASE WHEN `Previous Division` IS NOT NULL AND col1 IS NOT NULL AND col1 != `Previous Division` THEN 'Division change; ' ELSE '' END) ||
    (CASE WHEN col3 = 'In progress' THEN 'Status: In progress; ' ELSE '' END) ||
    (CASE WHEN col3 LIKE '1st%' OR col3 LIKE '2nd%' OR col3 LIKE '3rd%' THEN 'Top-3 finish; ' ELSE '' END) ||
    (CASE WHEN col5 NOT IN ('Did not qualify','Did not enter') THEN 'Open Cup involvement; ' ELSE '' END)
  ) AS `Rarity reasons`,
  (
    (CASE WHEN col2 IS NOT NULL AND col2 != `Previous League` THEN 3 ELSE 0 END) +
    (CASE WHEN `Previous Division` IS NOT NULL AND col1 IS NOT NULL AND col1 != `Previous Division` THEN 2 ELSE 0 END) +
    (CASE WHEN col3 = 'In progress' THEN 2 ELSE 0 END) +
    (CASE WHEN col3 LIKE '1st%' OR col3 LIKE '2nd%' OR col3 LIKE '3rd%' THEN 3 ELSE 0 END) +
    (CASE WHEN col5 NOT IN ('Did not qualify','Did not enter') THEN 4 ELSE 0 END)
  ) AS `Rarity score`
FROM seasons
WHERE
  (col2 IS NOT NULL AND `Previous League` IS NOT NULL AND col2 != `Previous League`)
  OR (`Previous Division` IS NOT NULL AND col1 IS NOT NULL AND col1 != `Previous Division`)
  OR col3 = 'In progress'
  OR col3 LIKE '1st%'
  OR col3 LIKE '2nd%'
  OR col3 LIKE '3rd%'
  OR col5 NOT IN ('Did not qualify','Did not enter')
ORDER BY `Rarity score` DESC, col0 ASC;
","[('2010–11', 5.0, 'csl i', 'in progress', 'n/a', 'n/a', 'League change; Division change; Open Cup involvement;', 9), ('2011', 4.0, 'npsl', '4th, atlantic', 'did not qualify', 'did not enter', 'League change; Division change; Open Cup involvement;', 9), ('2008', 4.0, 'npsl', '2nd, mid atlantic', 'did not qualify', 'did not qualify', 'Top-3 finish; Open Cup involvement;', 7), ('2012', 4.0, 'npsl', '3rd, atlantic', 'did not qualify', 'did not enter', 'Top-3 finish; Open Cup involvement;', 7), ('2009', 4.0, 'npsl', '5th, atlantic', 'did not qualify', 'did not enter', 'Open Cup involvement;', 4), ('2010', 4.0, 'npsl', '5th, atlantic', 'did not qualify', 'did not enter', 'Open Cup involvement;', 4)]",table_1_16636344_1,"As a collector-designer I phrase things in plain terms and expect the data to show why a season is collectible. The SQL finds seasons where the league or division changed from the previous season, or where the regular-season shows 'In progress' or a top-3 finish, or where the Open Cup entry is not 'Did not qualify'/'Did not enter', and it builds human-readable reasons plus a score. The schema maps those checks to Year, Division, League, Regular Season, Playoffs, and Open Cup. Draft question: Request all seasons that meet any of those rarity criteria and include the explanatory reasons and a score. Validate: The question only asks for columns and conditions present in the query.",persona,"```json
{
  ""short_description"": ""A niche sports-memorabilia designer who makes limited-edition 'season cards' that celebrate unusual or transitional seasons in small-club soccer history."",
  ""goals"": [
    ""Identify seasons to feature as 'rare' cards — e.g., years with league switches, division changes, or atypical status strings like 'In progress'."",
    ""Find seasons with notable regular-season finishes (top-3) or any Open Cup involvement to assign higher rarity tiers and write accurate back- Goals:  Example Queries: ",reward,,
"Considering only rows with Length (m) > 0, for each Pavement compute total_length = SUM(Length (m)), avg_climb = AVG(Average climb (%)), and count = COUNT(*), then compute difficulty_score = (total_length * avg_climb / 100.0); which two Pavement types have the largest difficulty_score when ordered DESC (return the type, total_length, avg_climb, count, and difficulty_score)?","
WITH `pavements` AS (
  SELECT `Pavement` AS `type`, SUM(`Length (m)`) AS `total_length`, AVG(`Average climb (%)`) AS `avg_climb`, COUNT(*) AS `count`
  FROM `table_1_16654785_2`
  WHERE `Length (m)` > 0
  GROUP BY `Pavement`
  HAVING COUNT(*) > 0
)
SELECT `type`, `total_length`, `avg_climb`, `count`, (`total_length` * `avg_climb` / 100.0) AS `difficulty_score`
FROM `pavements`
ORDER BY `difficulty_score` DESC
LIMIT 2;
","
WITH `pavements` AS (
  SELECT col3 AS `type`, SUM(col4) AS `total_length`, AVG(col5) AS `avg_climb`, COUNT(*) AS `count`
  FROM `table_1_16654785_2`
  WHERE col4 > 0
  GROUP BY col3
  HAVING COUNT(*) > 0
)
SELECT `type`, `total_length`, `avg_climb`, `count`, (`total_length` * `avg_climb` / 100.0) AS `difficulty_score`
FROM `pavements`
ORDER BY `difficulty_score` DESC
LIMIT 2;
","[('cobbles', 3990.0, 79.71428571428571, 7, 3180.6), ('asphalt', 5740.0, 49.714285714285715, 7, 2853.6)]",table_1_16654785_2,"1) Parse intent: filter rows with Length (m) > 0, GROUP BY Pavement, compute SUM(Length (m)) AS total_length, AVG(Average climb (%)) AS avg_climb, COUNT(*) AS count, derive difficulty_score = total_length * avg_climb / 100.0, and return top 2 by difficulty_score descending. 2) Map schema: Pavement is the grouping key, Length (m) and Average climb (%) are aggregated. 3) Draft: pose a question asking for those aggregated values and the computed difficulty_score for the top two pavement types. 4) Validate: includes the WHERE condition, all aggregate names, the formula, and the ordering/limit.",reserved,19,reward,,
"For games where Bills points >= 0, report the average Bills points, the average Opponents score, the average point differential (Bills points - Opponents), the percentage of games won (count of games with Bills points > Opponents times 100 divided by total game count), the highest Attendance, and the average Attendance across games with Bills points <= Opponents?","
SELECT AVG(`Bills points`), AVG(`Opponents`), AVG(`Bills points` - `Opponents`), SUM(`Bills points` > `Opponents`) * 100.0 / COUNT(*), MAX(`Attendance`), SUM(`Attendance` * (`Bills points` <= `Opponents`)) / SUM(`Bills points` <= `Opponents`) FROM `table_1_16677887_2` WHERE `Bills points` >= 0 LIMIT 1;
","
SELECT AVG(col4), AVG(col5), AVG(col4 - col5), SUM(col4 > col5) * 100.0 / COUNT(*), MAX(col8), SUM(col8 * (col4 <= col5)) / SUM(col4 <= col5) FROM `table_1_16677887_2` WHERE col4 >= 0 LIMIT 1;
","[(20.133333333333333, 16.466666666666665, 3.6666666666666665, 66.66666666666667, 79659.0, 53547.4)]",table_1_16677887_2,"1) The query aggregates across all rows with Bills points >= 0, computing means, a win-rate, a maximum, and a conditional mean. 2) Schema terms correspond to `Bills points`, `Opponents`, and `Attendance`. 3) Compose a question asking for AVG(`Bills points`), AVG(`Opponents`), AVG(`Bills points` - `Opponents`), SUM(`Bills points` > `Opponents`) * 100.0 / COUNT(*), MAX(`Attendance`), and SUM(Attendance * (Bills points <= Opponents)) / SUM(Bills points <= Opponents) with the Bills points >= 0 filter. 4) Confirm all expressions and the WHERE condition are explicitly requested.",reserved,4,reward,,
"For entries with [Na + ](mmol/L) > 0 and [Glucose](mmol/L) >= 0, classify them as 'Isotonic' when (2 * [Na + ](mmol/L) + [Glucose](mmol/L)) <= 295 and 'Non-Isotonic' otherwise, then report for each classification the COUNT(*) (named D5W) and the average [Na + ](mmol/L), only include classifications with COUNT(*) > 0, order by COUNT(*) descending and limit the output to the top 3?","
SELECT CASE WHEN (2*`[Na + ](mmol/L)` + `[Glucose](mmol/L)`) <= 295 THEN 'Isotonic' ELSE 'Non-Isotonic' END AS `Classification`, COUNT(*) `D5W`, AVG(`[Na + ](mmol/L)`)
FROM `table_1_16689223_1`
WHERE (`[Na + ](mmol/L)` > 0 AND `[Glucose](mmol/L)` >= 0)
GROUP BY 1
HAVING COUNT(*) > 0
ORDER BY COUNT(*) DESC
LIMIT 3;
","
SELECT CASE WHEN (2*col2 + col4) <= 295 THEN 'Isotonic' ELSE 'Non-Isotonic' END AS `Classification`, COUNT(*) `D5W`, AVG(col2)
FROM `table_1_16689223_1`
WHERE (col2 > 0 AND col4 >= 0)
GROUP BY 1
HAVING COUNT(*) > 0
ORDER BY COUNT(*) DESC
LIMIT 3;
","[('Isotonic', 3, 86.0), ('Non-Isotonic', 1, 154.0)]",table_1_16689223_1,"1) The query's intent is to label solutions by osmolarity using 2*[Na + ] + [Glucose] threshold 295 and then aggregate counts and mean sodium. 2) Relevant schema elements are [Na + ](mmol/L) and [Glucose](mmol/L) with filters >0 and >=0 respectively. 3) Draft a question asking for classification, COUNT(*) as D5W, AVG([Na + ]), only groups with count>0, ordered by count desc, limited to 3. 4) Ensure the question precisely mirrors the SQL condition, calculation, aliases, grouping, having, ordering, and limit.",reserved,16,reward,,
"Which batting teams had partnerships over 300, and what was each team's highest partnership and how many partnerships did they have?","
SELECT DISTINCT `Batting team`, MAX(`Runs`) `Max runs`, COUNT(*) `Partner count`
FROM `table_1_1670921_1`
WHERE `Runs` > `300` AND `Season` != `1946/47`
GROUP BY `Batting team`
HAVING MAX(`Runs`) > `350`
LIMIT 3;
","SELECT DISTINCT col3, MAX(col1) `Max runs`, COUNT(*) `Partner count`
FROM `table_1_1670921_1`
WHERE col1 > 300 AND col6 != '1946/47'
GROUP BY col3
HAVING MAX(col1) > 350
LIMIT 3;","[('south africa', 415.0, 1), ('sri lanka', 624.0, 4)]",table_1_1670921_1,"STEP 1: Parse the SQL intent: filter rows where Runs > 300 and Season != '1946/47', group by Batting team, compute MAX(Runs) and COUNT(*) per team over the filtered rows, keep only teams whose MAX(Runs) > 350, and return up to 3 teams. STEP 2: Choose an ambiguity type: scope ambiguity fits best because the query's aggregations (MAX and COUNT) and the initial filter apply to the filtered subset (Runs>300 and excluding season 1946/47), but a natural language question can be read as asking about the whole team history or about just the filtered partnerships. STEP 3: Draft the question: ""Which batting teams had partnerships over 300, and what was each team's highest partnership and how many partnerships did they have?"" STEP 4: Explain the ambiguity: in the original query both the 'highest partnership' and the 'how many partnerships' are computed only among partnerships with Runs>300 and excluding season 1946/47 (and teams are further restricted to those whose max among that subset exceeds 350), but the question could instead be interpreted to ask for each team's overall highest partnership ever (including seasons <=300 or 1946/47) and/or the total number of partnerships in the team's history rather than the count restricted to Runs>300.",reserved,9,reward,,"type: Scope ambiguity | explanation: The SQL computes highest partnership (MAX) and partnership count (COUNT) only over rows with Runs>300 and excluding season 1946/47, but the phrasing can be read as asking about each team's overall highest partnership and total partnership count across all seasons (or alternately only the filtered partnerships)."
"Which five Teams (LIMIT 5) have SUM(Races) AS Total Races, SUM(Wins) AS Total Wins, SUM(Podiums) AS Total Podiums, and Win Rate = ROUND((SUM(Wins)*1.0)/NULLIF(SUM(Races),0),3), when selecting only rows with Races > 0 and non-empty Pts, including Seasons Included '2005,2006,2007,2008,2009,2010,2011,2012,2013' and ordering by Total Wins DESC?","
SELECT `Team`, SUM(`Races`) AS `Total Races`, SUM(`Wins`) AS `Total Wins`, SUM(`Podiums`) AS `Total Podiums`, ROUND((SUM(`Wins`)*1.0)/NULLIF(SUM(`Races`),0),3) AS `Win Rate`, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`' AS `Seasons Included` FROM `table_1_16710541_2` WHERE `Races` > 0 AND `Pts` <> '' GROUP BY `Team` ORDER BY `Total Wins` DESC LIMIT 5;
","
SELECT col2, SUM(col5) AS `Total Races`, SUM(col6) AS `Total Wins`, SUM(col7) AS `Total Podiums`, ROUND((SUM(col6)*1.0)/NULLIF(SUM(col5),0),3) AS `Win Rate`, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`' AS `Seasons Included` FROM `table_1_16710541_2` WHERE col5 > 0 AND col10 <> '' GROUP BY col2 ORDER BY `Total Wins` DESC LIMIT 5;
","[('red bull ktm ajo', 17.0, 5.0, 15.0, 0.294, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`'), ('intact-racing team germany', 17.0, 2.0, 6.0, 0.118, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`'), ('kiefer-bos-castrol honda', 16.0, 0.0, 0.0, 0.0, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`'), ('emmi– caffè latte', 34.0, 0.0, 0.0, 0.0, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`'), ('elit– caffè latte', 16.0, 0.0, 0.0, 0.0, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`')]",table_1_16710541_2,"Parse SQL intent: sum Races, Wins, Podiums per Team and calculate a rounded win rate, filter out entries with Races = 0 or empty Pts, then sort teams by total wins and limit to five. Map schema semantics: use Team, Races, Wins, Podiums, Pts and the literal seasons string for Seasons Included. Draft the question: request those sums, the exact Win Rate expression rounded to three decimals, the Races > 0 and Pts <> '' filters, grouping by Team, and top 5 ordering/limit. Validate: question reflects all columns, the ROUND/NULLIF Win Rate calculation, filters, grouping, ORDER BY Total Wins DESC, LIMIT 5, and the Seasons Included list.",reserved,8,reward,,
"Can you produce a concise breakdown for the 1982 Falcons showing average attendance by win/loss, the top three highest-attended games with date/opponent/result, and average attendance plus win percentage by home versus away?","
WITH games AS (
  SELECT
    `Game`,
    `Date`,
    `Opponent`,
    `Result`,
    `Falcons points`,
    `Opponents`,
    `Record`,
    `Attendance`,
    CASE WHEN `Opponent` LIKE 'at %' THEN 'Away' ELSE 'Home' END AS `Location`,
    CASE WHEN `Result` = 'Win' THEN 1 ELSE 0 END AS `is_win`
  FROM `table_1_16710829_2`
),
result_stats AS (
  SELECT
    'By Result' AS `section`,
    `Result` AS `subgroup`,
    ROUND(AVG(`Attendance`), 2) AS `avg_attendance`,
    COUNT(*) AS `games`,
    SUM(`is_win`) AS `wins`,
    ROUND(100.0 * SUM(`is_win`) / COUNT(*), 2) AS `win_pct`,
    NULL AS `Date`,
    NULL AS `Opponent`,
    NULL AS `Result_col`,
    NULL AS `Attendance_col`
  FROM games
  GROUP BY `Result`
),
top_games AS (
  SELECT
    'Top 3 Games by Attendance' AS `section`,
    ('Game ' || CAST(`Game` AS TEXT) || ' @ ' || `Opponent`) AS `subgroup`,
    `Attendance` AS `avg_attendance`,
    1 AS `games`,
    `is_win` AS `wins`,
    NULL AS `win_pct`,
    `Date`,
    `Opponent`,
    `Result` AS `Result_col`,
    `Attendance` AS `Attendance_col`
  FROM games
  ORDER BY `Attendance` DESC
  LIMIT 3
),
location_stats AS (
  SELECT
    'By Location' AS `section`,
    `Location` AS `subgroup`,
    ROUND(AVG(`Attendance`), 2) AS `avg_attendance`,
    COUNT(*) AS `games`,
    SUM(`is_win`) AS `wins`,
    ROUND(100.0 * SUM(`is_win`) / COUNT(*), 2) AS `win_pct`,
    NULL AS `Date`,
    NULL AS `Opponent`,
    NULL AS `Result_col`,
    NULL AS `Attendance_col`
  FROM games
  GROUP BY `Location`
)
SELECT * FROM result_stats
UNION ALL
SELECT * FROM top_games
UNION ALL
SELECT * FROM location_stats;
","
WITH games AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    col7,
    CASE WHEN col2 LIKE 'at %' THEN 'Away' ELSE 'Home' END AS `Location`,
    CASE WHEN col3 = 'Win' THEN 1 ELSE 0 END AS `is_win`
  FROM `table_1_16710829_2`
),
result_stats AS (
  SELECT
    'By Result' AS `section`,
    col3 AS `subgroup`,
    ROUND(AVG(col7), 2) AS `avg_attendance`,
    COUNT(*) AS `games`,
    SUM(`is_win`) AS `wins`,
    ROUND(100.0 * SUM(`is_win`) / COUNT(*), 2) AS `win_pct`,
    NULL AS col1,
    NULL AS col2,
    NULL AS `Result_col`,
    NULL AS `Attendance_col`
  FROM games
  GROUP BY col3
),
top_games AS (
  SELECT
    'Top 3 Games by Attendance' AS `section`,
    ('Game ' || CAST(col0 AS TEXT) || ' @ ' || col2) AS `subgroup`,
    col7 AS `avg_attendance`,
    1 AS `games`,
    `is_win` AS `wins`,
    NULL AS `win_pct`,
    col1,
    col2,
    col3 AS `Result_col`,
    col7 AS `Attendance_col`
  FROM games
  ORDER BY col7 DESC
  LIMIT 3
),
location_stats AS (
  SELECT
    'By Location' AS `section`,
    `Location` AS `subgroup`,
    ROUND(AVG(col7), 2) AS `avg_attendance`,
    COUNT(*) AS `games`,
    SUM(`is_win`) AS `wins`,
    ROUND(100.0 * SUM(`is_win`) / COUNT(*), 2) AS `win_pct`,
    NULL AS col1,
    NULL AS col2,
    NULL AS `Result_col`,
    NULL AS `Attendance_col`
  FROM games
  GROUP BY `Location`
)
SELECT * FROM `table_1_16710829_2`
UNION ALL
SELECT * FROM `table_1_16710829_2`
UNION ALL
SELECT * FROM `table_1_16710829_2`
","[(1.0, 'sept. 12', 'at new york giants', 'win', 16.0, 14.0, '1-0', 74286.0), (2.0, 'sept. 19', 'los angeles raiders', 'loss', 14.0, 38.0, '1-1', 54774.0), (3.0, 'nov. 21', 'los angeles rams', 'win', 34.0, 17.0, '2-1', 39686.0), (4.0, 'nov. 28', 'st. louis cardinals', 'loss', 20.0, 23.0, '2-2', 33411.0), (5.0, 'dec. 5', 'at denver broncos', 'win', 34.0, 27.0, '3-2', 73984.0), (6.0, 'dec. 12', 'new orleans saints', 'win', 35.0, 0.0, '4-2', 39535.0), (7.0, 'dec. 19', 'at san francisco 49ers', 'win', 17.0, 7.0, '5-2', 53234.0), (8.0, 'dec. 26', 'green bay packers', 'loss', 7.0, 38.0, '5-3', 50245.0), (9.0, 'jan. 2', 'at new orleans saints', 'loss', 6.0, 35.0, '5-4', 47336.0), (1.0, 'sept. 12', 'at new york giants', 'win', 16.0, 14.0, '1-0', 74286.0), (2.0, 'sept. 19', 'los angeles raiders', 'loss', 14.0, 38.0, '1-1', 54774.0), (3.0, 'nov. 21', 'los angeles rams', 'win', 34.0, 17.0, '2-1', 39686.0), (4.0, 'nov. 28', 'st. louis cardinals', 'loss', 20.0, 23.0, '2-2', 33411.0), (5.0, 'dec. 5', 'at denver broncos', 'win', 34.0, 27.0, '3-2', 73984.0), (6.0, 'dec. 12', 'new orleans saints', 'win', 35.0, 0.0, '4-2', 39535.0), (7.0, 'dec. 19', 'at san francisco 49ers', 'win', 17.0, 7.0, '5-2', 53234.0), (8.0, 'dec. 26', 'green bay packers', 'loss', 7.0, 38.0, '5-3', 50245.0), (9.0, 'jan. 2', 'at new orleans saints', 'loss', 6.0, 35.0, '5-4', 47336.0), (1.0, 'sept. 12', 'at new york giants', 'win', 16.0, 14.0, '1-0', 74286.0), (2.0, 'sept. 19', 'los angeles raiders', 'loss', 14.0, 38.0, '1-1', 54774.0), (3.0, 'nov. 21', 'los angeles rams', 'win', 34.0, 17.0, '2-1', 39686.0), (4.0, 'nov. 28', 'st. louis cardinals', 'loss', 20.0, 23.0, '2-2', 33411.0), (5.0, 'dec. 5', 'at denver broncos', 'win', 34.0, 27.0, '3-2', 73984.0), (6.0, 'dec. 12', 'new orleans saints', 'win', 35.0, 0.0, '4-2', 39535.0), (7.0, 'dec. 19', 'at san francisco 49ers', 'win', 17.0, 7.0, '5-2', 53234.0), (8.0, 'dec. 26', 'green bay packers', 'loss', 7.0, 38.0, '5-3', 50245.0), (9.0, 'jan. 2', 'at new orleans saints', 'loss', 6.0, 35.0, '5-4', 47336.0)]",table_1_16710829_2,"For my article I may want a compact report combining result-based, top-game and location-based attendance context, asked in straightforward reporter language. The SQL produces three sections: averages by Result, the top 3 games by Attendance with their dates/opponents/results, and averages by Location including win rates. It pulls Date, Opponent, Result and Attendance for the top games and aggregated stats for the groupings. Draft question: Can you produce a concise breakdown for the 1982 Falcons showing average attendance by win/loss, the top three highest-attended games with date/opponent/result, and average attendance plus win percentage by home versus away? This reflects the combined UNION of the three query sections.",persona,"Sports data journalist researching the 1982 Atlanta Falcons season to report on how opponent, location, and game outcomes affected crowd sizes during the strike-shortened year. They use the table to extract attendance patterns and tie them to game context for an article. Goals: Determine whether wins or losses correlated with higher average attendance during the 1982 season. Identify which games (dates and opponents) drew the largest crowds to highlight marquee matchups or anomalies. Compare home vs. away attendance and the Falcons' home success rate to provide context about local fan engagement. Example Queries: SELECT Result, AVG(Attendance) AS avg_attendance, COUNT(*) AS games_played
FROM table_1_16710829_2
GROUP BY Result
ORDER BY avg_attendance DESC; SELECT Game, Date, Opponent, Result, Attendance
FROM table_1_16710829_2
ORDER BY Attendance DESC
LIMIT 3; SELECT CASE WHEN Opponent LIKE 'at %' THEN 'Away' ELSE 'Home' END AS location,
       AVG(Attendance) AS avg_attendance,
       SUM(CASE WHEN Result = 'Win' THEN 1 ELSE 0 END) AS wins,
       COUNT(*) AS games
FROM table_1_16710829_2
GROUP BY location;",reward,,
"For IsWin determined as CASE WHEN `Falcons points` > `Opponents` THEN 1 ELSE 0 END, report for each IsWin the Games (COUNT(*)), Wins (SUM(IsWin)), Avg_Attendance (AVG(`Attendance`)), and Max_Margin (MAX(`Falcons points` - `Opponents`)), and present the groups ordered by Wins in descending order?","
SELECT
  `IsWin`,
  COUNT(*) AS `Games`,
  SUM(`IsWin`) AS `Wins`,
  AVG(`Attendance`) AS `Avg_Attendance`,
  MAX(`Falcons points` - `Opponents`) AS `Max_Margin`
FROM (
  SELECT *,
    CASE WHEN `Falcons points` > `Opponents` THEN 1 ELSE 0 END AS `IsWin`
  FROM `table_1_16710971_2`
)
GROUP BY `IsWin`
ORDER BY `Wins` DESC;
","
SELECT
  `IsWin`,
  COUNT(*) AS `Games`,
  SUM(`IsWin`) AS `Wins`,
  AVG(col7) AS `Avg_Attendance`,
  MAX(col4 - col5) AS `Max_Margin`
FROM (
  SELECT *,
    CASE WHEN col4 > col5 THEN 1 ELSE 0 END AS `IsWin`
  FROM `table_1_16710971_2`
)
GROUP BY `IsWin`
ORDER BY `Wins` DESC;
","[(1, 9, 9, 54759.77777777778, 14.0), (0, 6, 0, 46747.0, -5.0)]",table_1_16710971_2,"1) Parse intent: produce aggregated statistics split by a derived win indicator and sort by total wins. 2) Map schema: compute IsWin from `Falcons points` and `Opponents`, and use `Attendance` for averaging and point difference for max margin. 3) Draft question: ask for IsWin along with Games, Wins, Avg_Attendance, and Max_Margin per group. 4) Validate: includes all calculations, column names, grouping, and ordering present in the SQL.",reserved,19,reward,,
"By Team(s), can you provide the total Starts (SUM(Starts)), total Wins (SUM(Wins)), the win percentage as (SUM(Wins)*1.0)/SUM(Starts)*100 rounded to two decimal places, the average of Avg. Finish as a numeric value rounded to two decimals, the summed Winnings after stripping '$' and ',' rounded to zero decimals (as 'Ken Schrader Racing'), and the MIN(Year) and MAX(Year), only using rows with Starts > 0, only showing teams whose SUM(Starts) >= 5, and returning up to 10 results?","
SELECT `Team(s)`, SUM(`Starts`), SUM(`Wins`), ROUND((SUM(`Wins`)*1.0)/SUM(`Starts`)*100,2), ROUND(AVG(`Avg. Finish` + 0),2), ROUND(SUM(REPLACE(REPLACE(`Winnings`,'$',''),',','') + 0),0) AS `Ken Schrader Racing`, MIN(`Year`), MAX(`Year`)
FROM `table_1_1671401_2`
WHERE `Starts` > 0
GROUP BY `Team(s)`
HAVING SUM(`Starts`) >= 5
LIMIT 10;
","
SELECT col10, SUM(col1), SUM(col2), ROUND((SUM(col2)*1.0)/SUM(col1)*100,2), ROUND(AVG(col7 + 0),2), ROUND(SUM(REPLACE(REPLACE(col8,'$',''),',','') + 0),0) AS `Ken Schrader Racing`, MIN(col0), MAX(col0)
FROM `table_1_1671401_2`
WHERE col1 > 0
GROUP BY col10
HAVING SUM(col1) >= 5
LIMIT 10;
","[('andy petree racing', 22.0, 0.0, 0.0, 20.9, 217400.0, 1998.0, 1999.0), ('brewco motorsports', 8.0, 0.0, 0.0, 26.8, 197127.0, 2006.0, 2006.0), ('ken schrader racing', 53.0, 1.0, 1.89, 22.38, 315113.0, 1987.0, 2002.0), ('ken schrader racing darrell waltrip motorsports', 10.0, 0.0, 0.0, 16.3, 57345.0, 1991.0, 1991.0), ('ken schrader racing ernie irvan racing', 10.0, 0.0, 0.0, 11.9, 48352.0, 1992.0, 1992.0), ('ken schrader racing hendrick motorsports', 11.0, 1.0, 9.09, 17.6, 27577.0, 1989.0, 1989.0)]",table_1_1671401_2,"1) The SQL groups by Team(s) and returns aggregated counts, rates, averages, and year ranges with text-to-number conversion for Winnings, applying Starts>0 filter and SUM(Starts) >=5 HAVING, limiting output. 2) Map to table fields: Team(s), Starts, Wins, Avg. Finish, Winnings, Year. 3) Compose a question that precisely asks for those aggregates, conversions, roundings, and filters. 4) Ensure the question includes the alias for total Winnings and the LIMIT 10.",reserved,8,reward,,
"Which distinct Year along with Mens Open, Womens Open and Mixed Open should be returned with a multi_win value of 1 (where multi_win = 1 if any two of Mens Open, Womens Open or Mixed Open are equal, otherwise 0), showing only rows with multi_win = 1, ordered by Year descending and limited to 10 entries?","
SELECT DISTINCT `Year`, `Mens Open`, `Womens Open`, `Mixed Open`,
CASE WHEN (((`Mens Open` = `Womens Open`) + (`Mens Open` = `Mixed Open`) + (`Womens Open` = `Mixed Open`)) > 0) THEN 1 ELSE 0 END `multi_win`
FROM (VALUES
(1997,'Sydney Scorpions def Brisbane City Cobras','Brisbane City Cobras def Sydney Mets','Sydney Rebels def Brisbane City Cobras'),
(1998,'Sydney Scorpions def SunWest Razorbacks','Sydney Mets def Gold Coast Sharks','Sydney Scorpions def Gold Coast Sharks'),
(1999,'Sydney Scorpions def Brisbane City Cobras','Brisbane City Cobras def Gold Coast Sharks','Sydney Scorpions def Sydney Rebels'),
(2000,'Sydney Scorpions def Brisbane City Cobras','Brisbane City Cobras def Sydney Mets','Brisbane City Cobras def Sydney Rebels'),
(2001,'Brisbane City Cobras def Sydney Mets','Sydney Mets def Brisbane City Cobras','Gold Coast Sharks def Brisbane City Cobras'),
(2002,'Sydney Mets def Brisbane City Cobras','Brisbane City Cobras def Hunter Western Hornets','Sydney Scorpions def Sydney Mets'),
(2003,'Gold Coast Sharks def Sydney Mets','Brisbane City Cobras def Sydney Mets','Sydney Scorpions def Gold Coast Sharks'),
(2004,'Sydney Mets def Brisbane City Cobras','Gold Coast Sharks def Brisbane City Cobras','Sydney Mets def Gold Coast Sharks'),
(2005,'Gold Coast Sharks def Sydney Mets','Sydney Mets def Brisbane City Cobras','Sydney Mets def Gold Coast Sharks'),
(2006,'Gold Coast Sharks def Sydney Mets','Gold Coast Sharks def Sydney Mets','Sydney Mets def Sydney Scorpions'),
(2007,'Gold Coast Sharks def Sydney Mets','Brisbane City Cobras def Sydney Mets','Gold Coast Sharks def Hunter Western Hornets'),
(2008,'Sydney Mets def Gold Coast Sharks','Sydney Mets def Barbarians','Brisbane City Cobras def Southern Suns')
) AS `t`(`Year`,`Mens Open`,`Womens Open`,`Mixed Open`)
WHERE `multi_win` = 1
ORDER BY `Year` DESC
LIMIT 10;
","SELECT DISTINCT col0, col1, col2, col3, CASE WHEN ((col1 = col2) OR (col1 = col3) OR (col2 = col3)) THEN 1 ELSE 0 END AS `multi_win` FROM `table_1_16724844_1` WHERE ((col1 = col2) OR (col1 = col3) OR (col2 = col3)) ORDER BY col0 DESC LIMIT 10;","[(2006.0, 'gold coast sharks def sydney mets', 'gold coast sharks def sydney mets', 'sydney mets def sydney scorpions', 1)]",table_1_16724844_1,"1) Parse the SQL intent: determine years where at least two of the Mens Open, Womens Open and Mixed Open results are identical, outputting those columns and a multi_win flag, sorted newest first and limited to ten. 2) Map schema semantics: treat Mens Open, Womens Open and Mixed Open as text result columns to be compared for equality; Year is numeric and used for ordering. 3) Draft the question: ask for distinct Year and the three result columns plus the CASE-defined multi_win, filter to multi_win = 1, order by Year DESC, limit 10. 4) Validate: ensure the question names the CASE logic (any pair equality), the filter, distinctness, ordering and limit.",reserved,15,reward,,
"Which five ACC Teams have the highest SUM(Attendance) from games where Attendance > 10000, and for each ACC Team what are the COUNT(Attendance) and SUM(Attendance)?","
SELECT `ACC Team`, COUNT(`Attendance`), SUM(`Attendance`)
FROM `table_1_1672976_5`
WHERE `Attendance` > 10000
GROUP BY `ACC Team`
ORDER BY SUM(`Attendance`) DESC
LIMIT 5;
","
SELECT col2, COUNT(col6), SUM(col6)
FROM `table_1_1672976_5`
WHERE col6 > 10000
GROUP BY col2
ORDER BY SUM(col6) DESC
LIMIT 5;
","[('#4 duke', 1, 18809.0), ('nc state', 1, 16597.0), ('florida state', 1, 14797.0), ('miami', 1, 13927.0), ('maryland', 1, 13187.0)]",table_1_1672976_5,"1) Parse intent: filter rows with Attendance > 10000, group by ACC Team, compute COUNT and SUM of Attendance, sort by SUM descending and take 5. 2) Map schema: 'ACC Team' groups, 'Attendance' is counted and summed. 3) Draft: ask which five ACC Teams have the largest total attendance from games over 10000 and provide the count and sum. 4) Validate: question includes COUNT(Attendance), SUM(Attendance), Attendance > 10000, grouping, ordering by SUM desc, and limit 5.",reserved,8,reward,,
"For up to 10 Socket groups, return the Socket, the total_models count, the average TDP (avg_tdp) where avg_tdp is computed by removing the ' W' suffix from TDP and converting to a number, the average Mult. (avg_mult) where avg_mult is computed by removing the '×' character from Mult. and converting to a number, the maximum Release price (max_price) and minimum Release price (min_price) where each price is computed by removing '$' from Release price ( USD ) and only considered if Release price ( USD ) contains '$', and include only rows where TDP without ' W' and Mult. without '×' are non-empty, grouped by Socket?","
SELECT DISTINCT `Socket`,
       COUNT(*) ""total_models"",
       AVG(REPLACE(`TDP`, ' W', '') + 0.0) ""avg_tdp"",
       AVG(REPLACE(`Mult.`, '×', '') + 0.0) ""avg_mult"",
       MAX((REPLACE(`Release price ( USD )`, '$', '') + 0.0) * (INSTR(`Release price ( USD )`, '$') > 0)) ""max_price"",
       MIN((REPLACE(`Release price ( USD )`, '$', '') + 0.0) * (INSTR(`Release price ( USD )`, '$') > 0)) ""min_price""
FROM `table_1_16729930_11`
WHERE LENGTH(REPLACE(`TDP`, ' W', '')) > 0 AND LENGTH(REPLACE(`Mult.`, '×', '')) > 0
GROUP BY `Socket`
LIMIT 10;
","
SELECT DISTINCT col8,
       COUNT(*) ""total_models"",
       AVG(REPLACE(col7, ' W', '') + 0.0) ""avg_tdp"",
       AVG(REPLACE(col5, '×', '') + 0.0) ""avg_mult"",
       MAX((REPLACE(col11, '$', '') + 0.0) * (INSTR(col11, '$') > 0)) ""max_price"",
       MIN((REPLACE(col11, '$', '') + 0.0) * (INSTR(col11, '$') > 0)) ""min_price""
FROM `table_1_16729930_11`
WHERE LENGTH(REPLACE(col7, ' W', '')) > 0 AND LENGTH(REPLACE(col5, '×', '')) > 0
GROUP BY col8
LIMIT 10;
","[('bga 437', 4, 2.2, 11.0, 0.0, 0.0), ('bga 441', 7, 1.8357142857142856, 11.714285714285714, 249.47, 0.0)]",table_1_16729930_11,"Parse the SQL intent: produce distinct sockets with aggregate statistics: total model count, average numeric TDP and Mult., and numeric max/min release prices where a dollar sign exists; exclude rows lacking TDP or Mult. after removing units and cap results at 10 sockets. Map schema semantics: the query uses `Socket`, `TDP`, `Mult.`, and `Release price ( USD )` and applies string replacement and numeric casts. Draft the question: explicitly ask for each aggregate, the unit removals (' W', '×', '$'), the dollar-only price consideration, the non-empty checks, grouping by Socket and LIMIT 10. Validate: includes all columns, transformations, filters and grouping.",reserved,8,reward,,
"For my thermographic sculptures, list every 45 nm Atom with TDP ≤4 W and voltage 0.8–1.175V — give me model, sSpec, part numbers, socket, release date and price, the numeric TDP and per-socket min/max and range, CPU and GPU frequencies in MHz and their absolute delta, and how many models share each socket, cheapest first?","
SELECT
  `Model number`,
  `sSpec number`,
  `Part number(s)`,
  `Socket`,
  `Release date`,
  `Release price ( USD )`,
  CAST(REPLACE(`TDP`, ' W', '') AS REAL) AS `tdp_w`,
  MIN(CAST(REPLACE(`TDP`, ' W', '') AS REAL)) OVER (PARTITION BY `Socket`) AS `min_tdp_socket`,
  MAX(CAST(REPLACE(`TDP`, ' W', '') AS REAL)) OVER (PARTITION BY `Socket`) AS `max_tdp_socket`,
  (MAX(CAST(REPLACE(`TDP`, ' W', '') AS REAL)) OVER (PARTITION BY `Socket`) - MIN(CAST(REPLACE(`TDP`, ' W', '') AS REAL)) OVER (PARTITION BY `Socket`)) AS `tdp_range_w`,
  `Voltage`,
  CASE WHEN `Frequency` LIKE '%GHz' THEN CAST(REPLACE(`Frequency`, ' GHz', '') AS REAL)*1000 ELSE CAST(REPLACE(`Frequency`, ' MHz', '') AS REAL) END AS `cpu_mhz`,
  CASE WHEN `GPU frequency` LIKE '%GHz' THEN CAST(REPLACE(`GPU frequency`, ' GHz', '') AS REAL)*1000 ELSE CAST(REPLACE(`GPU frequency`, ' MHz', '') AS REAL) END AS `gpu_mhz`,
  ABS(
    (CASE WHEN `Frequency` LIKE '%GHz' THEN CAST(REPLACE(`Frequency`, ' GHz', '') AS REAL)*1000 ELSE CAST(REPLACE(`Frequency`, ' MHz', '') AS REAL) END)
    -
    (CASE WHEN `GPU frequency` LIKE '%GHz' THEN CAST(REPLACE(`GPU frequency`, ' GHz', '') AS REAL)*1000 ELSE CAST(REPLACE(`GPU frequency`, ' MHz', '') AS REAL) END)
  ) AS `abs_delta_mhz`,
  COUNT(*) OVER (PARTITION BY `Socket`) AS `models_same_socket`,
  CAST(REPLACE(`Release price ( USD )`, '$', '') AS REAL) AS `price_usd`
FROM `table_1_16729930_17`
WHERE CAST(REPLACE(`TDP`, ' W', '') AS REAL) <= 4
  AND `Voltage` = '0.8–1.175V'
ORDER BY `price_usd` ASC;
","SELECT
  col0,
  col8,
  col7,
  col12,
  col9,
  col10,
  CASE WHEN col2 LIKE '%GHz' THEN CAST(REPLACE(col2, ' GHz', '') AS REAL)*1000 ELSE CAST(REPLACE(col2, ' MHz', '') AS REAL) END AS cpu_mhz,
  CASE WHEN col3 LIKE '%GHz' THEN CAST(REPLACE(col3, ' GHz', '') AS REAL)*1000 ELSE CAST(REPLACE(col3, ' MHz', '') AS REAL) END AS gpu_mhz,
  ABS(
    (CASE WHEN col2 LIKE '%GHz' THEN CAST(REPLACE(col2, ' GHz', '') AS REAL)*1000 ELSE CAST(REPLACE(col2, ' MHz', '') AS REAL) END)
    -
    (CASE WHEN col3 LIKE '%GHz' THEN CAST(REPLACE(col3, ' GHz', '') AS REAL)*1000 ELSE CAST(REPLACE(col3, ' MHz', '') AS REAL) END)
  ) AS abs_delta_mhz,
  CAST(REPLACE(col12, '$', '') AS REAL) AS price_usd
FROM `table_1_16729930_17`
WHERE CAST(REPLACE(col8, ' W', '') AS REAL) <= 3.6
  AND col7 LIKE '0.8%'
ORDER BY price_usd ASC;","[('atom e620', '3.3 w', '0.8–1.175v', '$19', 'fc-bga 676', 'september 14, 2010', 600.0, 320.0, 280.0, 19.0), ('atom e620t', '3.3 w', '0.8–1.175v', '$22', 'fc-bga 676', 'september 14, 2010', 600.0, 320.0, 280.0, 22.0), ('atom e640', '3.6 w', '0.8–1.175v', '$29', 'fc-bga 676', 'september 14, 2010', 1000.0, 320.0, 680.0, 29.0), ('atom e640t', '3.6 w', '0.8–1.175v', '$37', 'fc-bga 676', 'september 14, 2010', 1000.0, 320.0, 680.0, 37.0), ('atom e660', '3.6 w', '0.8–1.175v', '$54', 'fc-bga 676', 'september 14, 2010', 1300.0, 400.0, 900.0, 54.0), ('atom e660t', '3.6 w', '0.8–1.175v', '$64', 'fc-bga 676', 'september 14, 2010', 1300.0, 400.0, 900.0, 64.0)]",table_1_16729930_17,"I'm a thermo-kinetic sculptor who thinks in watts, volts and sockets and I talk about TDP and voltage ranges when sourcing stable heat sources. I know enough schema words to ask for model, part numbers, socket and frequencies but won't use raw SQL jargon. The query filters the 45 nm Atom table for parts with TDP ≤ 4 W and Voltage = 0.8–1.175V and converts values to numeric, computing per-socket min/max/range, CPU/GPU frequencies in MHz, absolute delta, model counts per socket and price. The schema maps to Model number, sSpec number, Part number(s), Socket, Release date, Release price, TDP, Voltage, Frequency, GPU frequency and uses price for ordering. Draft question: For my thermographic pieces, list those 45 nm Atom models with TDP ≤4 W and voltage 0.8–1.175V showing model, sSpec, part numbers, socket, release date, price, numeric TDP and the per-socket min/max/range, CPU and GPU MHz and their absolute delta, plus how many models share each socket, cheapest first. Validation: This asks exactly for the filtered models, the per-socket TDP stats, converted frequencies and ordering by price that the query returns.",persona,"A thermo-kinetic sculptor who builds kinetic art pieces that use the predictable heat output and voltage characteristics of vintage Intel Atom chips to draw patterns on thermographic film and drive micro-thermoelectric actuators. Goals: Identify Atom models with very low and tightly constrained TDP/voltage ranges to achieve stable, repeatable thermal signatures for artwork. Find chips that share the same socket and mechanical footprint so they can be swapped into a sculpture's mounting without retooling. Budget and source the cheapest suitable parts from the 45 nm Atom family and verify their original release dates for exhibit labeling. Compare CPU vs GPU frequency deltas to pick devices whose GPU heat contribution is predictable relative to the CPU (useful when using onboard GPU as a secondary heat element). Example Queries: SELECT ""Model number"", ""TDP"", ""Voltage"", ""Release price ( USD )""
FROM table_1_16729930_17
WHERE CAST(REPLACE(""TDP"",' W','') AS DECIMAL) <= 4
  AND ""Voltage"" = '0.8–1.175V'
ORDER BY CAST(REPLACE(""Release price ( USD )"",'$','') AS DECIMAL) ASC; SELECT ""Model number"", ""sSpec number"", ""Part number(s)"", ""Socket"", ""Release date""
FROM table_1_16729930_17
WHERE ""Release date"" = 'September 14, 2010'
  AND ""Socket"" = 'FC-BGA 676'; SELECT ""Model number"",
  CASE WHEN ""Frequency"" LIKE '%GHz' THEN CAST(REPLACE(""Frequency"",' GHz','') AS DECIMAL)*1000 ELSE CAST(REPLACE(""Frequency"",' MHz','') AS DECIMAL) END AS cpu_mhz,
  CASE WHEN ""GPU frequency"" LIKE '%GHz' THEN CAST(REPLACE(""GPU frequency"",' GHz','') AS DECIMAL)*1000 ELSE CAST(REPLACE(""GPU frequency"",' MHz','') AS DECIMAL) END AS gpu_mhz
FROM table_1_16729930_17
WHERE ABS(
  (CASE WHEN ""Frequency"" LIKE '%GHz' THEN CAST(REPLACE(""Frequency"",' GHz','') AS DECIMAL)*1000 ELSE CAST(REPLACE(""Frequency"",' MHz','') AS DECIMAL) END)
  -
  (CASE WHEN ""GPU frequency"" LIKE '%GHz' THEN CAST(REPLACE(""GPU frequency"",' GHz','') AS DECIMAL)*1000 ELSE CAST(REPLACE(""GPU frequency"",' MHz','') AS DECIMAL) END)
) >= 200;",reward,,
"For each season from 1996 through 2013, list the Raptors who played that season along with their jersey number, Years in Toronto, position, nationality and school or club team?","
WITH `table_m_1764877916909_2285b343_10015132_3`(`table_m_1764877916909_2285b343_10015132_3`) AS (
  VALUES ('1996'),('1997'),('1998'),('1999'),('2000'),('2001'),('2002'),('2003'),('2004'),('2005'),('2006'),('2007'),('2008'),('2009'),('2010'),('2011'),('2012'),('2013')
)
SELECT `table_m_1764877916909_2285b343_10015132_3`.`table_m_1764877916909_2285b343_10015132_3` AS `table_m_1764877916909_2285b343_10015132_3`,
       t.`Player`,
       t.`No.`,
       t.`Years in Toronto`,
       t.`Position (Nationality)`,
       t.`Position (Nationality)`,
       t.`School/Club Team`
FROM `table_m_1764877916909_2285b343_10015132_3`
JOIN `table_1_10015132_3` AS t
  ON instr(t.`Years in Toronto`, `table_m_1764877916909_2285b343_10015132_3`.`table_m_1764877916909_2285b343_10015132_3`) > 0
ORDER BY CAST(`table_m_1764877916909_2285b343_10015132_3`.`table_m_1764877916909_2285b343_10015132_3` AS INTEGER), t.`No.`;
","
WITH `table_m_1764877916909_2285b343_10015132_3`(`table_m_1764877916909_2285b343_10015132_3`) AS (
  VALUES ('1996'),('1997'),('1998'),('1999'),('2000'),('2001'),('2002'),('2003'),('2004'),('2005'),('2006'),('2007'),('2008'),('2009'),('2010'),('2011'),('2012'),('2013')
)
SELECT `table_m_1764877916909_2285b343_10015132_3`.`table_m_1764877916909_2285b343_10015132_3` AS `table_m_1764877916909_2285b343_10015132_3`,
       t.col0,
       t.col1,
       t.col2,
       t.col4,
       t.col4,
       t.col3
FROM `table_m_1764877916909_2285b343_10015132_3`
JOIN `table_1_10015132_3` AS t
  ON instr(t.col2, `table_m_1764877916909_2285b343_10015132_3`.`table_m_1764877916909_2285b343_10015132_3`) > 0
ORDER BY CAST(`table_m_1764877916909_2285b343_10015132_3`.`table_m_1764877916909_2285b343_10015132_3` AS INTEGER), t.col1;
",[],m_1764877916909_2285b343_10015132-3,"I'm a meticulous restorationist who knows roster columns like jersey number, position and school/club and I phrase questions precisely but practically. The SQL generates seasons 1996–2013 and joins each season to players whose ""Years in Toronto"" contains that season. It returns Player, No., Years in Toronto, Position, Nationality and School/Club Team for each matching season. Drafted question: For each season from 1996 through 2013, list the Raptors who played that season along with their jersey number, Years in Toronto, position, nationality and school or club team? This matches the query's intent to produce season-by-season player entries with those exact fields.",persona,"A museum-quality jersey restorationist who reconstructs historically accurate Toronto Raptors uniforms and exhibit labels for era-specific displays. Goals: Identify the exact jersey numbers, years worn, positions and nationalities to create accurate uniform replicas and museum placards. Assemble era-specific cohorts (e.g., turn-of-the-century Raptors) by finding players with overlapping Years in Toronto, so garments and displays match the same seasons. Locate players' college or club teams to research original fabrics, color schemes and patches for faithful material sourcing and detailing. Example Queries: SELECT ""Player"", ""No."", ""Years in Toronto"", ""Position"", ""Nationality"", ""School/Club Team""
FROM table_1_10015132_3
WHERE ""No."" = 15; SELECT ""Player"", ""No."", ""Years in Toronto"", ""Position""
FROM table_1_10015132_3
WHERE ""Years in Toronto"" LIKE '%1999%' OR ""Years in Toronto"" LIKE '%2000%' OR ""Years in Toronto"" LIKE '%2001%' OR ""Years in Toronto"" LIKE '%2002%'
ORDER BY ""Years in Toronto""; SELECT ""School/Club Team"", COUNT(*) AS player_count
FROM table_1_10015132_3
GROUP BY ""School/Club Team""
ORDER BY player_count DESC;",N/A,merge_column,
"Per Nationality, limited to rows where Position contains 'Guard' or 'Forward', provide the total players (COUNT(*)), the earliest start year using the first four characters of 'Years in Toronto' as a numeric value (MIN(substr('Years in Toronto',1,4)+0)), the average start year rounded to one decimal place (ROUND(AVG(substr('Years in Toronto',1,4)+0),1)), the count of entries with 'Guard' in Position (SUM(Position LIKE '%Guard%')), the count with 'Forward' in Position (SUM(Position LIKE '%Forward%')), and a Cohort column that reads 'Established before 2005' when the earliest start year is before 2005?","
SELECT `Nationality` AS `Nationality`,
       COUNT(*) `Players`,
       MIN(substr(`Years in Toronto`,1,4)+0) `EarliestStart`,
       ROUND(AVG(substr(`Years in Toronto`,1,4)+0),1) `AverageStart`,
       SUM(`Position` LIKE '%Guard%') `Guard`,
       SUM(`Position` LIKE '%Forward%') `Forward`,
       CASE WHEN MIN(substr(`Years in Toronto`,1,4)+0) < 2005 THEN 'Established before 2005' END `Cohort`
FROM `table_m_1764877926011_20992bd1_10015132_7`
WHERE ((`Position` LIKE '%Guard%') + (`Position` LIKE '%Forward%'))>0
GROUP BY `Nationality`
HAVING COUNT(*)>0;
","
SELECT col2 AS col2,
       COUNT(*) `Players`,
       MIN(substr(col4,1,4)+0) `EarliestStart`,
       ROUND(AVG(substr(col4,1,4)+0),1) `AverageStart`,
       SUM(col3 LIKE '%Guard%') `Guard`,
       SUM(col3 LIKE '%Forward%') `Forward`,
       CASE WHEN MIN(substr(col4,1,4)+0) < 2005 THEN 'Established before 2005' END `Cohort`
FROM `table_m_1764877926011_20992bd1_10015132_7`
WHERE ((col3 LIKE '%Guard%') + (col3 LIKE '%Forward%'))>0
GROUP BY col2
HAVING COUNT(*)>0;
","[('Spain', 1, 2006, 2006.0, 0, 1, None), ('United States', 5, 1997, 2006.0, 4, 2, 'Established before 2005')]",m_1764877926011_20992bd1_10015132-7,"1) Parse: SQL outputs nationality, counts, min/avg start-year from substring, counts of guard/forward flags, and a cohort label when min start <2005, filtered to positions containing Guard or Forward. 2) Map semantics: Years in Toronto -> first 4 chars numeric; Position LIKE used as boolean counts. 3) Draft: ask for per-nationality players count, earliest and average start years (rounded), counts for 'Guard' and 'Forward', and conditional cohort label. 4) Validate: includes all columns, calculations, grouping and WHERE condition.",reserved,11,N/A,add_column,
"Show each Team and the AVG(Draft Pick #) computed by excluding Draft Pick # values equal to 'N/A' or 'none' and converting remaining Draft Pick # values to numbers, for rows where Season >= 2000, grouped by Team, only for teams with COUNT(*) > 0, limited to 5 results?","
SELECT `Team`, AVG(NULLIF(NULLIF(`Draft Pick #`, '`N/A`'), '`none`') + 0) AS `Avg Draft Pick`
FROM `table_m_1764877945412_8f0d9c86_1004033_1`
WHERE `Season` >= 2000
GROUP BY `Team`
HAVING COUNT(*) > 0
LIMIT 5;
","
SELECT col4, AVG(NULLIF(NULLIF(col5, '`N/A`'), '`none`') + 0) AS `Avg Draft Pick`
FROM `table_m_1764877945412_8f0d9c86_1004033_1`
WHERE col0 >= 2000
GROUP BY col4
HAVING COUNT(*) > 0
LIMIT 5;
","[('Chicago Fire', 11.0), ('Chivas USA', 37.0), ('Columbus Crew', 8.0), ('D.C. United', 0.0), ('Los Angeles Galaxy', 3.5)]",m_1764877945412_8f0d9c86_1004033-1,"1) Parse intent: group rows from 2000 onward by Team and compute numeric average of Draft Pick # ignoring 'N/A' and 'none', then limit to 5 groups. 2) Map schema: Season filters rows, Draft Pick # needs NULLIF handling and numeric cast, Team is grouping key. 3) Draft question: request Team and AVG(Draft Pick #) with the specified exclusions and numeric conversion for Season >= 2000, HAVING COUNT(*)>0, LIMIT 5. 4) Validate: question matches filter, aggregation, exclusion of 'N/A'/'none', grouping and limit.",reserved,8,N/A,remove_column,
"From the Members table self-joined on Member = Member, for each distinct Headquarters where t1.UCCFS >= 2006 and t1.Chapters > 0, and after grouping by Headquarters with HAVING SUM(t2.Chapters) > 10, limited to 10 results, what are Headquarters, SUM(t2.Chapters) AS Total Chapters, COUNT(t2.Member) AS Member Count, MIN(substr(t2.Founded,1,4)) AS Earliest Founded Year, SUM((substr(t2.Founded,1,4) < '2000')) AS Pre2000 Count, MAX(t2.Member) AS Alpha Nu Omega, and MAX(t2.Founded) AS 1988 at Morgan State University?","
SELECT DISTINCT t1.`Headquarters`,
       SUM(t2.`Chapters`) `Total Chapters`,
       COUNT(t2.`member_name`) `member_name Count`,
       MIN(substr(t2.`founding_year`,1,4)) `Earliest founding_year Year`,
       SUM((substr(t2.`founding_year`,1,4) < '2000')) `Pre2000 Count`,
       MAX(t2.`member_name`) `Alpha Nu Omega`,
       MAX(t2.`founding_year`) `1988 at Morgan State University`
FROM `table_m_1764877954263_3b5975e3_10054296_1` AS t1
JOIN `table_m_1764877954263_3b5975e3_10054296_1` t2 ON t1.`member_name` = t2.`member_name`
WHERE t1.`uca_cfs_score` >= 2006 AND t1.`Chapters` > 0
GROUP BY t1.`Headquarters`
HAVING SUM(t2.`Chapters`) > 10
LIMIT 10;
","
SELECT DISTINCT t1.col1,
       SUM(t2.col3) `Total Chapters`,
       COUNT(t2.col0) `member_name Count`,
       MIN(substr(t2.col4,1,4)) `Earliest founding_year Year`,
       SUM((substr(t2.col4,1,4) < '2000')) `Pre2000 Count`,
       MAX(t2.col0) `Alpha Nu Omega`,
       MAX(t2.col4) `1988 at Morgan State University`
FROM `table_m_1764877954263_3b5975e3_10054296_1` AS t1
JOIN `table_m_1764877954263_3b5975e3_10054296_1` t2 ON t1.col0 = t2.col0
WHERE t1.col5 >= 2006 AND t1.col3 > 0
GROUP BY t1.col1
HAVING SUM(t2.col3) > 10
LIMIT 10;
","[('Austin, Texas', 16.0, 1, '1988', 1, 'Gamma Phi Delta', '1988 at The University of Texas at Austin'), ('Baltimore, Maryland', 26.0, 1, '1988', 1, 'Alpha Nu Omega', '1988 at Morgan State University'), ('Washington, D.C.', 12.0, 1, '1999', 1, 'Delta Psi Epsilon', '1999 in Huntsville, Alabama')]",m_1764877954263_3b5975e3_10054296-1,"Parse intent: filter rows by t1.UCCFS >= 2006 and t1.Chapters > 0, self-join on Member, then aggregate by Headquarters and return specific summaries only for groups with SUM(Chapters) > 10, up to 10 groups. Map schema: interpret Founded year via substr(Founded,1,4) and count/sum/ min/max on Member, Chapters, Founded. Draft: form a question that requests DISTINCT Headquarters and the exact aggregate expressions and their labels, mentions the self-join, WHERE criteria, GROUP BY Headquarters, HAVING SUM(Chapters) > 10, and LIMIT 10. Validate: ensure every column and calculation in the SQL is explicitly included.",reserved,12,N/A,rename_column,
"Provide, for each school with Enrollment greater than 7000, the School, Location, Founded, Affiliation, Enrollment, the Years since Founded as 2025 minus Founded, the Enrollment per Year as Enrollment divided by (2025 - Founded) rounded to two decimal places, and an ""Indiana University"" column that repeats Enrollment, with results ordered by Enrollment per Year in ascending order?",unanswerable,unanswerable,,m_1764877962308_bfde254c_10082596-1,"1) The intent is to retrieve specific columns plus derived metrics and a duplicated Enrollment column named ""Indiana University"" for records where Enrollment exceeds 7000, ordered by the computed Enrollment per Year. 2) Map the selected and computed fields to the table schema (School, Location, Founded, Affiliation, Enrollment) and the calculations (2025 - Founded; Enrollment/(2025 - Founded) rounded to 2 decimals). 3) Produce a question that explicitly requests those columns, the two calculations with their formulas and rounding, the duplicated Enrollment alias, the Enrollment > 7000 filter, and ordering by Enrollment per Year ascending. 4) Ensure the question contains every column, calculation, alias, filter, and ordering present in the query.",reserved,5,N/A,merge_column,
"Which three Networks have the highest average Viewers (in millions), and for each of those Networks report Network, Total Seasons, Avg Viewers (in millions) rounded to 2 decimal places, Peak Viewers (maximum Viewers (in millions)), Lowest Viewers (minimum Viewers (in millions)), the count of seasons with Viewers (in millions) = 4.0, = 4.2, = 3.4, = 3.6, and the count of seasons with Viewers (in millions) >= 3.5, grouping results by Network and ordering by average viewers descending?","
SELECT `Network`, COUNT(*) `Total Seasons`, ROUND(AVG(`Viewers (in millions)` + 0), 2) `Avg Viewers`, MAX(`Viewers (in millions)` + 0) `Peak Viewers`, MIN(`Viewers (in millions)` + 0) `Lowest Viewers`, SUM((`Viewers (in millions)` + 0) = 4.0) `4.0`, SUM((`Viewers (in millions)` + 0) = 4.2) `4.2`, SUM((`Viewers (in millions)` + 0) = 3.4) `3.4`, SUM((`Viewers (in millions)` + 0) = 3.6) `3.6`, SUM(CASE WHEN (`Viewers (in millions)` + 0) >= 3.5 THEN 1 ELSE 0 END) `Seasons >= 3.5` FROM `table_m_1764877982790_627dfd89_1009087_1` GROUP BY `Network` ORDER BY `Avg Viewers` DESC LIMIT 3;
","
SELECT col1, COUNT(*) `Total Seasons`, ROUND(AVG(col5 + 0), 2) `Avg Viewers`, MAX(col5 + 0) `Peak Viewers`, MIN(col5 + 0) `Lowest Viewers`, SUM((col5 + 0) = 4.0) `4.0`, SUM((col5 + 0) = 4.2) `4.2`, SUM((col5 + 0) = 3.4) `3.4`, SUM((col5 + 0) = 3.6) `3.6`, SUM(CASE WHEN (col5 + 0) >= 3.5 THEN 1 ELSE 0 END) `Seasons >= 3.5` FROM `table_m_1764877982790_627dfd89_1009087_1` GROUP BY col1 ORDER BY `Avg Viewers` DESC LIMIT 3;
","[('UPN', 6, 3.77, 4.2, 3.4, 2, 1, 2, 1, 4), ('CW', 1, 2.5, 2.5, 2.5, 0, 0, 0, 0, 0)]",m_1764877982790_627dfd89_1009087-1,"1) Parse intent: compute per-Network aggregates including counts of exact viewer values and seasons >=3.5, sort by average viewers descending and limit to 3. 2) Map schema: use Network and Viewers (in millions) fields from the table. 3) Draft question: enumerate all requested aggregate metrics and ordering/limit. 4) Validate: confirm inclusion of COUNT, AVG rounded to two decimals, MAX, MIN, SUM conditions for 4.0/4.2/3.4/3.6, and SUM for >=3.5.",reserved,11,N/A,split_column,
"Using only records where Timeslot ( ET ) is not null, which TV seasons have an average Viewers (millions) (using Viewers (millions) as numeric) and a count of Season rows such that the TV season's average viewers is greater than the average viewers across the whole table; list the TV season, the average viewers and the count of seasons, ordered by average viewers descending and return the top 5?","
WITH `cleaned` AS (
  SELECT `Season`, CAST(`Viewers (millions)` AS REAL) `viewers`, `TV season`, `Timeslot ( ET )`
  FROM `table_m_1764877996438_78f41bf8_10120207_8`
  WHERE `Timeslot ( ET )` IS NOT NULL
)
SELECT ALL `TV season`, AVG(`viewers`) AS `avg_viewers`, COUNT(*) AS `count_seasons`
FROM `cleaned`
GROUP BY `TV season`
HAVING AVG(`viewers`) > (SELECT AVG(CAST(`Viewers (millions)` AS REAL)) FROM `table_m_1764877996438_78f41bf8_10120207_8`)
ORDER BY `avg_viewers` DESC
LIMIT 5;
","
WITH `cleaned` AS (
  SELECT col0, CAST(col6 AS REAL) `viewers`, col4, col1
  FROM `table_m_1764877996438_78f41bf8_10120207_8`
  WHERE col1 IS NOT NULL
)
SELECT ALL col4, AVG(`viewers`) AS `avg_viewers`, COUNT(*) AS `count_seasons`
FROM `cleaned`
GROUP BY col4
HAVING AVG(`viewers`) > (SELECT AVG(CAST(col6 AS REAL)) FROM `table_m_1764877996438_78f41bf8_10120207_8`)
ORDER BY `avg_viewers` DESC
LIMIT 5;
","[('2004–2005', 12.295, 2), ('2007–2008', 11.84, 1), ('2010–2011', 11.14, 2), ('2008–2009', 11.025, 2), ('2006–2007', 10.8, 2)]",m_1764877996438_78f41bf8_10120207-8,"Parse intent: calculate per-TV-season average viewers and number of seasons from rows with non-null Timeslot, then select those TV seasons with average above the global average and return five highest by average. Map schema: use Season as unit counted, TV season as group, Viewers (millions) cast to real for averaging, Timeslot ( ET ) IS NOT NULL filter, and overall AVG comparison. Draft: pose a question requesting TV season, AVG(Viewers (millions)) and COUNT(Season) with the specified filtering and ordering. Validate: includes all columns and calculations present in the SQL and nothing extra.",reserved,28,N/A,add_column,
"List the 10 City and Region rows showing City, Region, PctChange1981_2010 = (2010 Est. - 1981 Census) * 100.0 / 1981 Census and RegionAvgPct = AVG((2010 Est. - 1981 Census) * 100.0 / 1981 Census) per Region, where 1981 Census > 0 and (PctChange1981_2010 > RegionAvgPct OR PctChange1981_2010 BETWEEN -1000 AND 10000), ordered by PctChange1981_2010 ascending and limited to 10?","
SELECT main.`City`, main.`Region`, (main.`2010 Est.` - main.`1981 Census`) * 100.0 / main.`1981 Census` `PctChange1981_2010`, region_avg.`AvgPct` `RegionAvgPct`
FROM `table_m_1764878013616_bd0c3d95_10138926_1` main
JOIN (
  SELECT `Region`, AVG((`2010 Est.` - `1981 Census`) * 100.0 / `1981 Census`) `AvgPct`
  FROM `table_m_1764878013616_bd0c3d95_10138926_1`
  GROUP BY `Region`
) region_avg
ON main.`Region` = region_avg.`Region`
WHERE main.`1981 Census` > 0
AND ((main.`2010 Est.` - main.`1981 Census`) * 100.0 / main.`1981 Census`) > region_avg.`AvgPct`
OR (((main.`2010 Est.` - main.`1981 Census`) * 100.0 / main.`1981 Census`) BETWEEN -1000 AND 10000)
ORDER BY `PctChange1981_2010`
LIMIT 10;
","
SELECT main.col1, main.col6, (main.col5 - main.col2) * 100.0 / main.col2 `PctChange1981_2010`, region_avg.`AvgPct` `RegionAvgPct`
FROM `table_m_1764878013616_bd0c3d95_10138926_1` main
JOIN (
  SELECT col6, AVG((col5 - col2) * 100.0 / col2) `AvgPct`
  FROM `table_m_1764878013616_bd0c3d95_10138926_1`
  GROUP BY col6
) region_avg
ON main.col6 = region_avg.col6
WHERE main.col2 > 0
AND ((main.col5 - main.col2) * 100.0 / main.col2) > region_avg.`AvgPct`
OR (((main.col5 - main.col2) * 100.0 / main.col2) BETWEEN -1000 AND 10000)
ORDER BY `PctChange1981_2010`
LIMIT 10;
","[('Cosenza', 'Calabria', -34.3938727165476, -3.4074102970551805), ('Cagliari', 'Sardinia', -33.08131777907017, 30.449520359973313), ('Portici', 'Campania', -32.86780251212536, 22.310955969852948), ('Catania', 'Sicily', -22.840811089375485, 7.398879585630332), ('Venice', 'Veneto', -21.742848393452473, -5.678988661792571), ('Taranto', 'Apulia', -21.421870455262372, 7.065125646430758), ('Naples', 'Campania', -20.85250006804758, 22.310955969852948), ('Genoa', 'Liguria', -20.315901926215272, -15.381540889107036), ('Turin', 'Piedmont', -18.7611555792666, -5.348803520791715), ('Trieste', 'Friuli-Venezia Giulia', -18.55774679140465, -7.205498881047103)]",m_1764878013616_bd0c3d95_10138926-1,"Parse intent: return cities with their percent population change from 1981 to 2010 plus the region's average percent change, filter by positive 1981 Census and by either exceeding the regional average or falling in a broad numeric range, then sort and limit. Map schema: use City, Region, 1981 Census, 2010 Est. to compute PctChange1981_2010 and compute RegionAvgPct by AVG over the same expression grouped by Region. Draft: ask explicitly for City, Region, the PctChange expression, RegionAvgPct, the filter 1981 Census > 0, the OR with BETWEEN -1000 and 10000, ORDER BY PctChange1981_2010 and LIMIT 10. Validate: confirm all columns, calculations, grouping, filter logic, ordering and limit are present.",reserved,15,N/A,add_column,
"Which countries have winners, and what nominations and actors are associated with them?",unanswerable,unanswerable,,m_1764878073153_faec7815_10236830-4,"STEP 1: Parse the SQL intent — The query groups rows by Country, counts rows per country as Winners, concatenates Nomination values (separated by ' | ') and Actors Name values (separated by ', '), filters out rows missing Actors Name or Film Name, orders results by the Winners count (ascending by default), and returns the first 10 groups. STEP 2: Determine a type of ambiguity — Scope ambiguity fits well: a short NL question like “Which countries have winners?” can mean (a) list all countries that have at least one winner, (b) rank countries by number of winners and show the top (or bottom) N, or (c) show winners per country. The SQL corresponds to one specific scoped interpretation (counts per country, limited/ordered), so scope ambiguity maps cleanly. STEP 3: Draft the question — Produce an NL question that matches the SQL output but is ambiguous in scope. STEP 4: Explain the ambiguity — In the SQL the phrase is concretely implemented as counts per country, ordered by that count and limited to 10 (so it effectively returns 10 countries sorted by winner count). In a different interpretation the same NL question could ask for all countries with any winner, or the countries with the most winners, or winners listed per country without ranking/limiting.",reserved,9,N/A,remove_column,"type: Scope ambiguity | explanation: The question can mean (a) list every country that has at least one winner and show their nominations and actors, (b) rank countries by how many winners they have and return the top (or bottom) N, or (c) show the winners grouped per country; the original SQL implements the second-type interpretation narrowly (counts per country, ordered by the Winners count and limited to 10)."
"List Season, Division, League Apps, League Goals, FA Cup Apps, FA Cup Goals, Total Apps and Total Goals, plus Total Goals % of Career calculated as (Total Goals * 100.0) / 9, Total Apps % of Career calculated as (Total Apps * 100.0) / 196, League Goals per League App calculated as (League Goals * 1.0) / League Apps, and FA Cup Involvement calculated as (FA Cup Apps + FA Cup Goals), and include the Season values '1908–09', '1909–10', '1910–11', '1911–12', '1912–13', '1913–14' for rows where Division = Division?","
SELECT `Season`, `Division`, `league_apps`, `league_goals`, `FA Cup Apps`, `FA Cup Goals`, `total_apps`, `Total Goals`, (`Total Goals` * 100.0) / 9 `Total Goals % of Career`, (`total_apps` * 100.0) / 196 `total_apps % of Career`, (`league_goals` * 1.0) / `league_apps` `league_goals per League App`, (`FA Cup Apps` + `FA Cup Goals`) `FA Cup Involvement`, `Season` `1908–09`, `Season` `1909–10`, `Season` `1910–11`, `Season` `1911–12`, `Season` `1912–13`, `Season` `1913–14` FROM `table_m_1764878079930_b5363a97_10240125_1` WHERE `Division` = `Division`;
","
SELECT col0, col1, col2, col3, col4, col5, col6, col7, (col7 * 100.0) / 9 `Total Goals % of Career`, (col6 * 100.0) / 196 `total_apps % of Career`, (col3 * 1.0) / col2 `league_goals per League App`, (col4 + col5) `FA Cup Involvement`, col0 `1908–09`, col0 `1909–10`, col0 `1910–11`, col0 `1911–12`, col0 `1912–13`, col0 `1913–14` FROM `table_m_1764878079930_b5363a97_10240125_1` WHERE col1 = col1;
","[('1908–09', 'Division Two', 15.0, 1.0, 0.0, 0.0, 15.0, 1.0, 11.11111111111111, 7.653061224489796, 0.06666666666666667, 0.0, '1908–09', '1908–09', '1908–09', '1908–09', '1908–09', '1908–09'), ('1909–10', 'Division Two', 35.0, 0.0, 9.0, 1.0, 44.0, 1.0, 11.11111111111111, 22.448979591836736, 0.0, 10.0, '1909–10', '1909–10', '1909–10', '1909–10', '1909–10', '1909–10'), ('1910–11', 'Division Two', 38.0, 1.0, 2.0, 0.0, 40.0, 1.0, 11.11111111111111, 20.408163265306122, 0.02631578947368421, 2.0, '1910–11', '1910–11', '1910–11', '1910–11', '1910–11', '1910–11'), ('1911–12', 'Division Two', 34.0, 4.0, 12.0, 0.0, 46.0, 4.0, 44.44444444444444, 23.46938775510204, 0.11764705882352941, 12.0, '1911–12', '1911–12', '1911–12', '1911–12', '1911–12', '1911–12'), ('1912–13', 'Division Two', 36.0, 1.0, 3.0, 0.0, 39.0, 1.0, 11.11111111111111, 19.897959183673468, 0.027777777777777776, 3.0, '1912–13', '1912–13', '1912–13', '1912–13', '1912–13', '1912–13'), ('1913–14', 'Division Two', 12.0, 1.0, 0.0, 0.0, 12.0, 1.0, 11.11111111111111, 6.122448979591836, 0.08333333333333333, 0.0, '1913–14', '1913–14', '1913–14', '1913–14', '1913–14', '1913–14')]",m_1764878079930_b5363a97_10240125-1,"1) The query intent is to retrieve each season's stats plus computed career percentages and ratios, and to output explicit Season literals, with no effective filtering (Division = Division). 2) Associate the table fields with Season, Division, League Apps, League Goals, FA Cup Apps, FA Cup Goals, Total Apps, Total Goals and the formulas for percentages, ratio, and FA Cup involvement. 3) Compose a natural question asking for all those fields and exact computations and the listed Season values. 4) Ensure the question includes every column name, every calculation formula, the FA Cup Involvement expression, and the literal seasons.",reserved,3,N/A,rename_column,
"Please produce a table of directors (ordered by most wins, then nominations) showing their wins, nominations, total submissions, won films, all films with year, first and last win year, their primary decade and that decade's totals and nomination/win rates.","
WITH base AS (
  SELECT
    *,
    CAST(SUBSTR(`Year (Ceremony)`,1,4) AS INTEGER) AS year_int,
    CAST(CAST(CAST(SUBSTR(`Year (Ceremony)`,1,4) AS INTEGER)/10 AS INTEGER) * 10 AS INTEGER) AS decade
  FROM `table_m_1764878135445_74756806_10321805_1`
),
director_stats AS (
  SELECT
    `Director`,
    SUM(CASE WHEN `Result` LIKE 'Won %' THEN 1 ELSE 0 END) AS `wins`,
    SUM(CASE WHEN `Result` LIKE '%Nominee%' THEN 1 ELSE 0 END) AS `nominations`,
    COUNT(*) AS `total_submissions`,
    COALESCE(GROUP_CONCAT(CASE WHEN `Result` = 'Won Academy Award' THEN `Film title used in nomination` END, ', '), '') AS `Won Films`,
    COALESCE(GROUP_CONCAT(`Film title used in nomination` || ' (' || year_int || ')', '; '), '') AS `All Films (year)`,
    MIN(CASE WHEN `Result` = 'Won Academy Award' THEN year_int END) AS `first_win_year`,
    MAX(CASE WHEN `Result` = 'Won Academy Award' THEN year_int END) AS `last_win_year`,
    (SELECT decade FROM base b2 WHERE b2.`Director` = base.`Director` GROUP BY decade ORDER BY COUNT(*) DESC LIMIT 1) AS `primary_decade`
  FROM base
  GROUP BY `Director`
),
decade_stats AS (
  SELECT
    decade,
    COUNT(*) AS `total_films`,
    SUM(CASE WHEN `Result` = 'Not Nominated' THEN 0 ELSE 1 END) AS `nominated_or_shortlisted_count`,
    SUM(CASE WHEN `Result` LIKE 'Won %' THEN 1 ELSE 0 END) AS `wins`,
    100.0 * SUM(CASE WHEN `Result` = 'Not Nominated' THEN 0 ELSE 1 END) / COUNT(*) AS `pct_nominated_or_shortlisted`,
    100.0 * SUM(CASE WHEN `Result` LIKE 'Won %' THEN 1 ELSE 0 END) / COUNT(*) AS `pct_won`
  FROM base
  GROUP BY decade
)
SELECT
  ds.`Director`,
  ds.`wins`,
  ds.`nominations`,
  ds.`total_submissions`,
  ds.`Won Films`,
  ds.`All Films (year)`,
  ds.`first_win_year`,
  ds.`last_win_year`,
  ds.`primary_decade`,
  dec.`total_films` AS `Decade Total Films`,
  dec.`nominated_or_shortlisted_count` AS `Decade Nominated/Shortlisted`,
  ROUND(dec.`pct_nominated_or_shortlisted`,2) AS `Decade % Nominated/Shortlisted`,
  dec.`wins` AS `Decade Wins`,
  ROUND(dec.`pct_won`,2) AS `Decade % Won`
FROM director_stats ds
LEFT JOIN decade_stats dec ON ds.`primary_decade` = dec.decade
ORDER BY ds.`wins` DESC, ds.`nominations` DESC, ds.`total_submissions` DESC;
","
WITH base AS (
  SELECT
    *,
    CAST(SUBSTR(col0,1,4) AS INTEGER) AS year_int,
    CAST(CAST(CAST(SUBSTR(col0,1,4) AS INTEGER)/10 AS INTEGER) * 10 AS INTEGER) AS decade
  FROM `table_m_1764878135445_74756806_10321805_1`
),
director_stats AS (
  SELECT
    col2,
    SUM(CASE WHEN col3 LIKE 'Won %' THEN 1 ELSE 0 END) AS `wins`,
    SUM(CASE WHEN col3 LIKE '%Nominee%' THEN 1 ELSE 0 END) AS `nominations`,
    COUNT(*) AS `total_submissions`,
    COALESCE(GROUP_CONCAT(CASE WHEN col3 = 'Won Academy Award' THEN col1 END, ', '), '') AS `Won Films`,
    COALESCE(GROUP_CONCAT(col1 || ' (' || year_int || ')', '; '), '') AS `All Films (year)`,
    MIN(CASE WHEN col3 = 'Won Academy Award' THEN year_int END) AS `first_win_year`,
    MAX(CASE WHEN col3 = 'Won Academy Award' THEN year_int END) AS `last_win_year`,
    (SELECT decade FROM base b2 WHERE b2.col2 = base.col2 GROUP BY decade ORDER BY COUNT(*) DESC LIMIT 1) AS `primary_decade`
  FROM base
  GROUP BY col2
),
decade_stats AS (
  SELECT
    decade,
    COUNT(*) AS `total_films`,
    SUM(CASE WHEN col3 = 'Not Nominated' THEN 0 ELSE 1 END) AS `nominated_or_shortlisted_count`,
    SUM(CASE WHEN col3 LIKE 'Won %' THEN 1 ELSE 0 END) AS `wins`,
    100.0 * SUM(CASE WHEN col3 = 'Not Nominated' THEN 0 ELSE 1 END) / COUNT(*) AS `pct_nominated_or_shortlisted`,
    100.0 * SUM(CASE WHEN col3 LIKE 'Won %' THEN 1 ELSE 0 END) / COUNT(*) AS `pct_won`
  FROM base
  GROUP BY decade
)
SELECT
  ds.col2,
  ds.`wins`,
  ds.`nominations`,
  ds.`total_submissions`,
  ds.`Won Films`,
  ds.`All Films (year)`,
  ds.`first_win_year`,
  ds.`last_win_year`,
  ds.`primary_decade`,
  dec.`total_films` AS `Decade Total Films`,
  dec.`nominated_or_shortlisted_count` AS `Decade Nominated/Shortlisted`,
  ROUND(dec.`pct_nominated_or_shortlisted`,2) AS `Decade % Nominated/Shortlisted`,
  dec.`wins` AS `Decade Wins`,
  ROUND(dec.`pct_won`,2) AS `Decade % Won`
FROM director_stats ds
LEFT JOIN decade_stats dec ON ds.`primary_decade` = dec.decade
ORDER BY ds.`wins` DESC, ds.`nominations` DESC, ds.`total_submissions` DESC;
","[('Vittorio De Sica Category:Articles with hCards', 4, 1, 5, 'Yesterday, Today and Tomorrow, The Garden of the Finzi-Continis', 'Shoeshine (1947); The Bicycle Thief (1949); Yesterday, Today and Tomorrow (1964); Marriage Italian-Style (1965); The Garden of the Finzi-Continis (1971)', 1964, 1971, 1960, 9, 7, 77.78, 2, 22.22), ('Federico Fellini Category:Articles with hCards', 4, 0, 7, 'La Strada, Nights of Cabiria, 8½, Amarcord', 'La Strada (1956); Nights of Cabiria (1957); 8½ (1963); Satyricon (1969); Roma (1972); Amarcord (1974); And the Ship Sails On (1983)', 1956, 1974, 1970, 7, 6, 85.71, 2, 28.57), ('Giuseppe Tornatore Category:Articles with hCards', 1, 1, 4, 'Cinema Paradiso', 'Cinema Paradiso (1989); The Star Maker (1995); The Unknown (2007); Baarìa (2009)', 1989, 1989, 2000, 9, 2, 22.22, 0, 0.0), ('Gabriele Salvatores Category:Articles with hCards', 1, 0, 2, 'Mediterraneo', ""Mediterraneo (1991); I'm Not Scared (2003)"", 1991, 1991, 2000, 9, 2, 22.22, 0, 0.0), ('Roberto Benigni Category:Articles with hCards', 1, 0, 2, 'Life Is Beautiful', 'Life Is Beautiful (1998); Pinocchio (2002)', 1998, 1998, 2000, 9, 2, 22.22, 0, 0.0), ('René Clément Category:Articles with hCards', 1, 0, 1, '', 'The Walls of Malapaga (1950)', None, None, 1950, 5, 5, 100.0, 3, 60.0), ('Mario Monicelli Category:Articles with hCards', 0, 3, 3, '', 'Big Deal on Madonna Street (1958); The Great War (1959); The Girl with the Pistol (1968)', None, None, 1950, 5, 5, 100.0, 3, 60.0), ('Ettore Scola Category:Articles with hCards', 0, 2, 3, '', 'A Special Day (1977); Macaroni (1985); The Family (1987)', None, None, 1980, 8, 4, 50.0, 1, 12.5), ('Gillo Pontecorvo Category:Articles with hCards', 0, 2, 2, '', 'Kapò (1960); The Battle of Algiers (1966)', None, None, 1960, 9, 7, 77.78, 2, 22.22), ('Gianni Amelio Category:Articles with hCards', 0, 1, 4, '', 'Open Doors (1990); The Stolen Children (1992); Lamerica (1994); The Keys to the House (2004)', None, None, 1990, 10, 4, 40.0, 2, 20.0), ('Marco Bellocchio Category:Articles with hCards', 0, 1, 2, '', 'China is Near (1967); A Leap in the Dark (1980)', None, None, 1980, 8, 4, 50.0, 1, 12.5), ('Nanni Loy Category:Articles with hCards', 0, 1, 2, '', ""The Four Days of Naples (1962); Where's Picone? (1984)"", None, None, 1980, 8, 4, 50.0, 1, 12.5), ('Cristina Comencini Category:Articles with hCards', 0, 1, 1, '', ""Don't Tell (2005)"", None, None, 2000, 9, 2, 22.22, 0, 0.0), ('Dino Risi Category:Articles with hCards', 0, 1, 1, '', 'Scent of a Woman (1975)', None, None, 1970, 7, 6, 85.71, 2, 28.57), ('Francesco Rosi Category:Articles with hCards', 0, 1, 1, '', 'Three Brothers (1981)', None, None, 1980, 8, 4, 50.0, 1, 12.5), ('Franco Brusati Category:Articles with hCards', 0, 1, 1, '', 'To Forget Venice (1979)', None, None, 1970, 7, 6, 85.71, 2, 28.57), ('Lina Wertmüller Category:Articles with hCards', 0, 1, 1, '', 'Seven Beauties (1976)', None, None, 1970, 7, 6, 85.71, 2, 28.57), ('Emanuele Crialese Category:Articles with hCards', 0, 0, 2, '', 'The Golden Door (2006); Terraferma (2011)', None, None, 2010, 3, 0, 0.0, 0, 0.0), ('Ermanno Olmi Category:Articles with hCards', 0, 0, 1, '', 'The Legend of the Holy Drinker (1988)', None, None, 1980, 8, 4, 50.0, 1, 12.5), ('Francesca Archibugi Category:Articles with hCards', 0, 0, 1, '', 'The Great Pumpkin (1993)', None, None, 1990, 10, 4, 40.0, 2, 20.0), ('Giuseppe Piccioni Category:Articles with hCards', 0, 0, 1, '', 'Not of This World (1999)', None, None, 1990, 10, 4, 40.0, 2, 20.0), ('Matteo Garrone Category:Articles with hCards', 0, 0, 1, '', 'Gomorrah (2008)', None, None, 2000, 9, 2, 22.22, 0, 0.0), ('Nanni Moretti Category:Articles with hCards', 0, 0, 1, '', ""The Son's Room (2001)"", None, None, 2000, 9, 2, 22.22, 0, 0.0), ('Paolo Virzì Category:Articles with hCards', 0, 0, 1, '', 'The First Beautiful Thing (2010)', None, None, 2010, 3, 0, 0.0, 0, 0.0), ('Paolo and Vittorio Taviani', 0, 0, 1, '', 'Caesar Must Die (2012)', None, None, 2010, 3, 0, 0.0, 0, 0.0), ('Pupi Avati Category:Articles with hCards', 0, 0, 1, '', 'The Best Man (1997)', None, None, 1990, 10, 4, 40.0, 2, 20.0), ('Wilma Labate Category:Articles with hCards', 0, 0, 1, '', 'My Generation (1996)', None, None, 1990, 10, 4, 40.0, 2, 20.0)]",m_1764878135445_74756806_10321805-1,"For a lecture I might want a compact dossier per director combining personal and contextual metrics without using SQL jargon. The SQL produces director-level aggregates (wins, nominations, lists of films and win years) and appends the most-representative decade's statistics. The relevant columns are director, film title, year and result to compile those metrics. Draft question: ask for a single table per director with those director metrics plus their primary decade's statistics, ordered by wins and nominations. This matches the final SELECT and ORDER BY of the query.",persona,"Film studies researcher at a university focusing on Italian cinema history and awards; uses the database to quantify how Italian films and directors have fared at the Academy Awards over time. Goals: Measure which Italian directors have the most Academy Award wins and nominations in this dataset. Identify which Italian films or years resulted in Academy Award wins versus other outcomes. Analyze trends in nomination/win rates across decades to support a paper or lecture on changing international reception of Italian cinema. Example Queries: /* Count wins and nominations by director */
SELECT ""Director"",
       SUM(CASE WHEN ""Result"" LIKE 'Won %' THEN 1 ELSE 0 END) AS wins,
       SUM(CASE WHEN ""Result"" LIKE '%Nominee%' THEN 1 ELSE 0 END) AS nominations,
       COUNT(*) AS total_submissions
FROM table_1_10321805_1
GROUP BY ""Director""
ORDER BY wins DESC, nominations DESC; /* List all films that won an Academy Award (explicit Academy wins) with ceremony year and director */
SELECT ""Year (Ceremony)"", ""Film title used in nomination"", ""Original title"", ""Director""
FROM table_1_10321805_1
WHERE ""Result"" = 'Won Academy Award'
ORDER BY CAST(SUBSTR(""Year (Ceremony)"",1,4) AS INTEGER); /* Compute nomination/win rates by decade (extracts year from leading 4 chars) */
SELECT
  FLOOR(CAST(SUBSTR(""Year (Ceremony)"",1,4) AS INTEGER) / 10.0) * 10 AS decade,
  COUNT(*) AS total_films,
  SUM(CASE WHEN ""Result"" = 'Not Nominated' THEN 0 ELSE 1 END) AS nominated_or_shortlisted_count,
  SUM(CASE WHEN ""Result"" LIKE 'Won %' THEN 1 ELSE 0 END) AS wins,
  100.0 * SUM(CASE WHEN ""Result"" = 'Not Nominated' THEN 0 ELSE 1 END) / COUNT(*) AS pct_nominated_or_shortlisted,
  100.0 * SUM(CASE WHEN ""Result"" LIKE 'Won %' THEN 1 ELSE 0 END) / COUNT(*) AS pct_won
FROM table_1_10321805_1
GROUP BY decade
ORDER BY decade;",N/A,remove_column,
"What are the three Current country of location entries with the lowest Total estimated deaths, where Total estimated deaths is the SUM by Current country of location of Estimated deaths and Estimated deaths values are converted to numbers by removing commas or, if containing a '-', by averaging the two comma-free endpoint numbers?","
SELECT `current_location_country`, SUM(
  (instr(`Estimated deaths`,'-')>0) *
    ((replace(substr(`Estimated deaths`,1,instr(`Estimated deaths`,'-')-1),',','')+0
      + replace(substr(`Estimated deaths`,instr(`Estimated deaths`,'-')+1),',','')+0)/2.0)
  + (instr(`Estimated deaths`,'-')=0) * (replace(`Estimated deaths`,',','')+0)
) `Total estimated deaths`
FROM `table_m_1764878142665_4cf31d02_10335_1`
GROUP BY `current_location_country`
ORDER BY `Total estimated deaths`
LIMIT 3;
","
SELECT col4, SUM(
  (instr(col1,'-')>0) *
    ((replace(substr(col1,1,instr(col1,'-')-1),',','')+0
      + replace(substr(col1,instr(col1,'-')+1),',','')+0)/2.0)
  + (instr(col1,'-')=0) * (replace(col1,',','')+0)
) `Total estimated deaths`
FROM `table_m_1764878142665_4cf31d02_10335_1`
GROUP BY col4
ORDER BY `Total estimated deaths`
LIMIT 3;
","[('Serbia', 35000.0), ('Belarus', 200000.0), ('Poland', 3110000.0)]",m_1764878142665_4cf31d02_10335-1,"1) Parse the SQL intent: sum Estimated deaths per country using averaging for ranges, then order sums ascending and return three rows. 2) Map schema semantics: interpret Estimated deaths (commas removed; ranges averaged) to compute Total estimated deaths grouped by Current country of location. 3) Draft the question: ask which three Current country of location entries have the lowest summed Total estimated deaths with the specified parsing rules. 4) Validate: the question explicitly references Current country of location, Total estimated deaths, the conversion of Estimated deaths, summation, ordering, and the top-3 limit.",reserved,8,N/A,rename_column,
"Grouping by Opponent and excluding Opponent = 'at Green Bay Packers', for only the rows where Result = 'Win', what are Opponent, SUM('Vikings points') AS Total_Vikings_Points, COUNT(*) AS Games, AVG('Attendance') AS Avg_Attendance, and SUM(Result = 'Win') AS Wins, with the results ordered by the SUM('Vikings points') in ascending order?",unanswerable,unanswerable,,m_1764878157579_0718edfd_10361453-2,"1) Parse intent: list per-opponent totals and averages for games that the Vikings won, but do not include the opponent 'at Green Bay Packers', and sort by total Vikings points. 2) Map schema: extract Opponent, sum Vikings points, count games, average Attendance, and count wins via SUM(Result = 'Win'). 3) Draft: ask for those exact aggregates with grouping and ordering and the specified filters. 4) Validate: ensure inclusion of all columns and calculations, the Result = 'Win' condition, exclusion of 'at Green Bay Packers', GROUP BY Opponent, and ORDER BY SUM('Vikings points').",reserved,9,N/A,merge_column,
"List the Opponent, Date, Attendance, and Attendance surplus over avg (defined as Attendance - 16118.6666666667) for every game whose Attendance is greater than 16118.6666666667.","
SELECT `Opponent`, `game_date`, `Attendance`, (`Attendance` - 16118.6666666667) `Attendance surplus over avg`
FROM `table_m_1764878184476_811b2a3b_10392906_2`
WHERE `Attendance` > 16118.6666666667;
","
SELECT col3, col1, col7, (col7 - 16118.6666666667) `Attendance surplus over avg`
FROM `table_m_1764878184476_811b2a3b_10392906_2`
WHERE col7 > 16118.6666666667;
","[('at Frankfurt Galaxy', 'Saturday, April 14', 38125.0, 22006.3333333333), ('at Rhein Fire', 'Sunday, June 3', 20355.0, 4236.333333333299)]",m_1764878184476_811b2a3b_10392906-2,"Parse SQL intent: select Opponent, Date, Attendance and a derived column (Attendance - 16118.6666666667) labelled Attendance surplus over avg, limited to Attendance > 16118.6666666667. Map schema semantics: Opponent and Date identify the game, Attendance provides the value to compare against the average 16118.6666666667. Draft the question: ask for Opponent, Date, Attendance and the surplus computation for games exceeding the average. Validate: ensure all columns, the subtraction calculation and the attendance filter are present.",reserved,3,N/A,rename_column,
"For actors whose name in the 'Australia & New Zealand (Sydney - first run, Melbourne, Auckland)' column also appears in the 'London' column, list the actor name, a concatenation of all Character values from the ANZ rows each suffixed with ' (ANZ)' as ANZ Roles, a concatenation of all Character values from the London rows each suffixed with ' (London)' as London Roles, and the number of matching rows as Matches; group by the ANZ actor, exclude zero-count groups, order by Matches descending, and return the top 10 results?","
SELECT t1.`australia_new_zealand` `Actor`,
       GROUP_CONCAT(t1.`character` || ' (ANZ)') `ANZ Roles`,
       GROUP_CONCAT(t2.`character` || ' (London)') `London Roles`,
       COUNT(*) `Matches`
FROM `table_m_1764878191238_bd4bc780_10402018_1` t1 CROSS JOIN `table_m_1764878191238_bd4bc780_10402018_1` t2
WHERE t1.`australia_new_zealand` = t2.`London`
GROUP BY t1.`australia_new_zealand`
HAVING COUNT(*) IS NOT 0
ORDER BY COUNT(*) DESC
LIMIT 10;
","
SELECT t1.col1 `Actor`,
       GROUP_CONCAT(t1.col0 || ' (ANZ)') `ANZ Roles`,
       GROUP_CONCAT(t2.col0 || ' (London)') `London Roles`,
       COUNT(*) `Matches`
FROM `table_m_1764878191238_bd4bc780_10402018_1` t1 CROSS JOIN `table_m_1764878191238_bd4bc780_10402018_1` t2
WHERE t1.col1 = t2.col2
GROUP BY t1.col1
HAVING COUNT(*) IS NOT 0
ORDER BY COUNT(*) DESC
LIMIT 10;
","[('Tony Sheldon', 'Bernadette (ANZ)', 'Bernadette (London)', 1)]",m_1764878191238_bd4bc780_10402018-1,"1) The SQL self-joins the table matching the Australia & New Zealand actor name to the London actor name, 2) map t1.`Australia & New Zealand (Sydney - first run, Melbourne, Auckland)` to the actor and `Character` to roles in each region, 3) draft a question asking for the actor, concatenated ANZ characters suffixed with ' (ANZ)', concatenated London characters suffixed with ' (London)', and the count of matches, grouped by the ANZ actor, excluding zero counts, ordered by count desc and limited to 10, 4) validate that all selected columns, concatenations, count, grouping, having, ordering, and limit are included.",reserved,13,N/A,rename_column,
"Across all episodes, what is the Total Episodes (COUNT(No.)), the Avg Title Length rounded to two decimals (ROUND(AVG(LENGTH(Title)),2)), the Avg Villains Length rounded to two decimals (ROUND(AVG(LENGTH(Villains)),2)), how many episodes have Villains longer than Title (SUM(LENGTH(Villains) > LENGTH(Title))), and what percent is that of the total rounded to two decimals (ROUND(100.0 * SUM(LENGTH(Villains) > LENGTH(Title)) / COUNT(No.),2))?","
SELECT COUNT(`No.`) `Total Episodes`, ROUND(AVG(LENGTH(`Title`)),2) `Avg Title Length`, ROUND(AVG(LENGTH(`Villains`)),2) `Avg Villains Length`, SUM(LENGTH(`Villains`) > LENGTH(`Title`)) `Villains Longer Count`, ROUND(100.0 * SUM(LENGTH(`Villains`) > LENGTH(`Title`)) / COUNT(`No.`),2) `Pct Villains Longer` FROM `table_m_1764878213103_d00d0c2d_10470082_4` WHERE 1 LIMIT 1;
","
SELECT COUNT(col0) `Total Episodes`, ROUND(AVG(LENGTH(col2)),2) `Avg Title Length`, ROUND(AVG(LENGTH(col6)),2) `Avg Villains Length`, SUM(LENGTH(col6) > LENGTH(col2)) `Villains Longer Count`, ROUND(100.0 * SUM(LENGTH(col6) > LENGTH(col2)) / COUNT(col0),2) `Pct Villains Longer` FROM `table_m_1764878213103_d00d0c2d_10470082_4` WHERE 1 LIMIT 1;
","[(11, 29.82, 15.18, 0, 0.0)]",m_1764878213103_d00d0c2d_10470082-4,"1) The query returns summary statistics across all rows: count, two averaged string lengths rounded to 2 decimals, a conditional sum, and that conditional sum expressed as a percentage of the count rounded to 2 decimals. 2) Use 'No.' for COUNT, LENGTH('Title') and LENGTH('Villains') inside AVG and SUM, and rounding to two decimal places. 3) Draft a consolidated question requesting Total Episodes, Avg Title Length (rounded to 2 decimals), Avg Villains Length (rounded to 2 decimals), Villains Longer Count (number of rows where LENGTH(Villains) > LENGTH(Title)), and Pct Villains Longer (100 * that count / total rounded to 2 decimals). 4) Check that each function and rounding appears in the question exactly as in the SQL.",reserved,4,N/A,split_column,
"Which Storyteller(s) among rows with No. >= 53 have more than one episode, and for each such Storyteller what are the Total Episodes (COUNT(*)), the Episodes Titles joined with '; ' (GROUP_CONCAT(Title, '; ')), the Villain Roster joined with '; ' (GROUP_CONCAT(Villains, '; ')), the earliest US air date (MIN(US air date) presented as ""The Tale of the Dead Man's Float"") and the latest US air date (MAX(US air date) presented as ""The Tale of the Jagged Sign""), ordered by Total Episodes?","
SELECT `Storyteller`, COUNT(*) `Total Episodes`, GROUP_CONCAT(`Title`, '; ') `Episodes Titles`, GROUP_CONCAT(`Villains`, '; ') `Villain Roster`, MIN(`US air date`) `'""The Tale of the Dead Man\'s Float""'`, MAX(`US air date`) `'""The Tale of the Jagged Sign""'` FROM `table_m_1764878218451_aa8f6d49_10470082_6` WHERE `No.` >= 53 GROUP BY `Storyteller` HAVING COUNT(*) > 1 ORDER BY `Total Episodes`;
","
SELECT col6, COUNT(*) `Total Episodes`, GROUP_CONCAT(col2, '; ') `Episodes Titles`, GROUP_CONCAT(col7, '; ') `Villain Roster`, MIN(col5) `'""The Tale of the Dead Man\'s Float""'`, MAX(col5) `'""The Tale of the Jagged Sign""'` FROM `table_m_1764878218451_aa8f6d49_10470082_6` WHERE col0 >= 53 GROUP BY col6 HAVING COUNT(*) > 1 ORDER BY `Total Episodes`;
","[('Betty Ann', 2, '""The Tale of the Mystical Mirror""; ""The Tale of the Chameleons""', 'Ms. Valenti; The Chameleon', 'November 11, 1995', 'November 18, 1995'), ('Sam', 2, '""The Tale of C7""; ""The Tale of the Night Shift""', 'None; The Walking Dead and The Vampire', 'December 9, 1995', 'February 3, 1996'), ('Stig', 2, '""The Tale of the Dead Man\'s Float""; ""The Tale of Station 109.1""', 'The Pool Zombie; None', 'November 4, 1995', 'October 7, 1995'), ('Tucker', 2, '""The Tale of Prisoner\'s Past""; ""The Tale of the Manaha""', 'None; The Shaman', 'December 2, 1995', 'December 30, 1995'), ('Kiki', 3, '""The Tale of the Jagged Sign""; ""The Tale of the Unexpected Visitor""; ""The Tale of the Vacant Lot""', 'None; The Alien Kid and its mother; Marie', 'January 13, 1996', 'October 14, 1995')]",m_1764878218451_aa8f6d49_10470082-6,"Parse SQL intent: return grouped episode aggregates per Storyteller for rows numbered 53 and up, only include storytellers with more than one episode, and order by episode count. Map schema semantics: use 'No.' filter, group by Storyteller, compute COUNT(*), GROUP_CONCAT of Title and Villains with '; ' separator, and MIN/MAX of 'US air date' with the given aliases. Draft the question: request exactly those labeled aggregates and ordering. Validate: ensure WHERE No. >= 53, HAVING COUNT(*) > 1, GROUP_CONCAT separators, and the alias labels are included.",reserved,7,N/A,add_column,
"For each Storyteller (only considering rows with LENGTH(Storyteller) > 0 AND LENGTH(Villains) > 0), can you provide Storyteller, the COUNT(No.) as EpisodeCount, the GROUP_CONCAT(DISTINCT Villains) as VillainList, the MIN(US air date) as FirstAir and the MAX(US air date) as LastAir, but only include storytellers with COUNT(No.) > 0 and show up to 10 results?","
SELECT `Storyteller` AS `Storyteller`, COUNT(`sequence_number`) `EpisodeCount`, GROUP_CONCAT(DISTINCT `Villains`) `VillainList`, MIN(`US air date`) `FirstAir`, MAX(`US air date`) `LastAir`
FROM `table_m_1764878228254_23d71417_10470082_8`
WHERE LENGTH(`Storyteller`) > 0 AND LENGTH(`Villains`) > 0
GROUP BY `Storyteller`
HAVING COUNT(`sequence_number`) > 0
LIMIT 10;
","
SELECT col6 AS col6, COUNT(col0) `EpisodeCount`, GROUP_CONCAT(DISTINCT col7) `VillainList`, MIN(col5) `FirstAir`, MAX(col5) `LastAir`
FROM `table_m_1764878228254_23d71417_10470082_8`
WHERE LENGTH(col6) > 0 AND LENGTH(col7) > 0
GROUP BY col6
HAVING COUNT(col0) > 0
LIMIT 10;
","[('Andy', 2, 'Jasper Davis,None', 'May 14, 2000', 'May 21, 2000'), (""Gary and Tucker's grandfather, Gene"", 1, 'The Evil Spirit', 'April 2, 2000', 'April 2, 2000'), ('Megan', 2, 'The Unborn Alien Babies,The Maiden Statue', 'April 16, 2000', 'April 9, 2000'), ('N/A', 2, 'The Evil Spirit', 'April 2, 2000', 'April 2, 2000'), ('Quinn', 2, 'None,Reanimated zombie', 'April 23, 2000', 'April 30, 2000'), ('Tucker', 2, 'Bell the Genie,Drake', 'May 28, 2000', 'May 7, 2000'), ('Vange', 1, 'Madame Visage', 'June 4, 2000', 'June 4, 2000')]",m_1764878228254_23d71417_10470082-8,"1) Parse the SQL intent: summarize episodes by storyteller with count, distinct villains list, first and last air dates, filtering out empty storyteller/villain rows and limiting output. 2) Map schema semantics: COUNT(No.) -> EpisodeCount, GROUP_CONCAT(DISTINCT Villains) -> VillainList, MIN(US air date) -> FirstAir, MAX(US air date) -> LastAir. 3) Draft the question: ask for those aggregated columns per storyteller with the non-empty and COUNT>0 constraints and LIMIT 10. 4) Validate: the question includes all calculations, the non-empty WHERE conditions, the HAVING COUNT > 0, and the LIMIT 10.",reserved,10,N/A,rename_column,
"Show Winning driver, Wins (COUNT(Rd)), Races (GROUP_CONCAT(Name)) and Teams (GROUP_CONCAT(Winning team)) for rows where Fastest Lap = Fastest Lap, grouped by Winning driver and limited to 5?","
SELECT `Winning driver`, COUNT(`Rd`) `Wins`, GROUP_CONCAT(`Name`) `Races`, GROUP_CONCAT(`Winning team`) `Teams`
FROM `table_m_1764878237191_2e4b74ae_10527215_3`
WHERE `Fastest Lap` = `Fastest Lap`
GROUP BY `Winning driver`
LIMIT 5;
","
SELECT col4, COUNT(col0) `Wins`, GROUP_CONCAT(col1) `Races`, GROUP_CONCAT(col5) `Teams`
FROM `table_m_1764878237191_2e4b74ae_10527215_3`
WHERE col3 = col3
GROUP BY col4
LIMIT 5;
","[('Bobby Unser', 4, 'Gould-Rex Mays 150,True Value 500,Kent Oil 150,California 500', 'Penske Racing,Penske Racing,Penske Racing,Penske Racing'), ('Johnny Rutherford', 5, 'Datsun Twin 200,Indianapolis 500,Red Roof Inns 150,Norton 200,Tony Bettenhausen 200', 'Chaparral,Chaparral,Chaparral,Chaparral,Chaparral'), ('Mario Andretti', 1, 'Gould Grand Prix 150', 'Penske Racing'), ('Rick Mears', 1, 'I Copa Mexico 150', 'Penske Racing')]",m_1764878237191_2e4b74ae_10527215-3,"1) The SQL intent is to group by Winning driver and produce COUNT(Rd) plus GROUP_CONCAT(Name) and GROUP_CONCAT(Winning team), with the WHERE clause Fastest Lap = Fastest Lap and LIMIT 5. 2) Map the query's selected and aggregated columns to the natural language request using the table's column names. 3) Create a question that exactly requests Winning driver, Wins = COUNT(Rd), Races = GROUP_CONCAT(Name), Teams = GROUP_CONCAT(Winning team) with the Fastest Lap = Fastest Lap condition, grouped by Winning driver and restricted to 5 results. 4) Verify that no extraneous details are introduced.",reserved,6,N/A,add_column,
"I’m scouting targets for contact-mic strikes—show me 4-4-0 and 4-6-0 locos that are on static display (parks/museums), with serial number, build date and inferred build year/era (pre-1890 vs post-1890), owning railroad and exact disposition/location, ordered so accessible pre-1890 examples come first and then by oldest build year.","
SELECT 
  `serial_number`,
  `wheel_arrangement`,
  `Build date`,
  CAST(substr(`Build date`, -4) AS INTEGER) AS `Build Year`,
  CASE WHEN CAST(substr(`Build date`, -4) AS INTEGER) < 1890 THEN 'pre-1890' ELSE 'post-1890' END AS `Era`,
  `operational_owner`,
  `Disposition`,
  CASE WHEN (`Disposition` LIKE '%static%' OR `Disposition` LIKE '%display%' OR `Disposition` LIKE '%Museum%' OR `Disposition` LIKE '%Park%') THEN 1 ELSE 0 END AS `Accessible`,
  (CASE WHEN CAST(substr(`Build date`, -4) AS INTEGER) < 1890 THEN 2 ELSE 1 END
   + CASE WHEN (`Disposition` LIKE '%Park%' OR `Disposition` LIKE '%Museum%' OR `Disposition` LIKE '%static%' OR `Disposition` LIKE '%display%') THEN 1 ELSE 0 END) AS `Priority Score`
FROM `table_m_1764878250628_33006fa3_1057316_1`
WHERE `wheel_arrangement` IN ('4-4-0','4-6-0')
  AND (`Disposition` LIKE '%static%' OR `Disposition` LIKE '%display%' OR `Disposition` LIKE '%Museum%' OR `Disposition` LIKE '%Park%')
ORDER BY `Priority Score` DESC, `Build Year` ASC;
","
SELECT 
  col0,
  col1,
  col2,
  CAST(substr(col2, -4) AS INTEGER) AS `Build Year`,
  CASE WHEN CAST(substr(col2, -4) AS INTEGER) < 1890 THEN 'pre-1890' ELSE 'post-1890' END AS `Era`,
  col3,
  col4,
  CASE WHEN (col4 LIKE '%static%' OR col4 LIKE '%display%' OR col4 LIKE '%Museum%' OR col4 LIKE '%Park%') THEN 1 ELSE 0 END AS `Accessible`,
  (CASE WHEN CAST(substr(col2, -4) AS INTEGER) < 1890 THEN 2 ELSE 1 END
   + CASE WHEN (col4 LIKE '%Park%' OR col4 LIKE '%Museum%' OR col4 LIKE '%static%' OR col4 LIKE '%display%') THEN 1 ELSE 0 END) AS `Priority Score`
FROM `table_m_1764878250628_33006fa3_1057316_1`
WHERE col1 IN ('4-4-0','4-6-0')
  AND (col4 LIKE '%static%' OR col4 LIKE '%display%' OR col4 LIKE '%Museum%' OR col4 LIKE '%Park%')
ORDER BY `Priority Score` DESC, `Build Year` ASC;
","[('unknown', '4-4-0', 'October 1856', 1856, 'pre-1890', 'Western and Atlantic Railroad #49 Texas', 'static display in Grant Park , Atlanta, Georgia', 1, 3), ('1861', '4-4-0', 'February 1888', 1888, 'pre-1890', 'Dardanelle and Russelville #8', 'Nevada State Railroad Museum , Carson City, Nevada', 1, 3), ('2053', '4-6-0', 'October, 1890', 1890, 'post-1890', 'Union Pacific Railroad #1242', ""Lion's Park, Cheyenne, Wyoming"", 1, 2), ('2054', '4-6-0', 'October, 1890', 1890, 'post-1890', 'Union Pacific Railroad #1243', 'Durham Western Heritage Museum, Omaha, Nebraska', 1, 2)]",m_1764878250628_33006fa3_1057316-1,"As a composer I might phrase it as a scouting request—concrete, slightly lyrical, and focused on access and era rather than table mechanics. The SQL returns only 4-4-0 and 4-6-0 locomotives whose disposition mentions static/display/Museum/Park, computes a build year and tags pre/post-1890, adds an accessibility indicator and a priority score, and sorts by priority desc then build year asc. Schema mapping: we want serial number, wheel arrangement, build date/year and era, operational owner(s) and the disposition/location. Draft: ask for targets for contact-mic strikes with those fields, marked by pre/post-1890 and ordered to favor accessible pre-1890 pieces and then by build year. Validate: the phrasing sticks to the SQL’s filters, computed era, and the intended prioritization and ordering.",persona,"A 'sonic heritage' composer and field-recorder who creates concert-length soundscapes by sampling the metallic resonances of preserved 19th-century locomotives. Goals: Identify surviving locomotives whose frames and boilers are accessible on static display (parks/museums) so they can be scheduled for on-site impulse/strike and contact-mic recordings. Select targets by wheel arrangement and build-era to create distinct timbral groups (e.g., 4-4-0 vs 4-6-0, pre-1890 vs post-1890) for a historically informed sonic palette. Plan an efficient regional recording tour by extracting dispositions (city/park/museum) and operational owner metadata to request permissions and craft narrative program notes. Example Queries: -- Find accessible static/display locomotives of the 4-4-0 or 4-6-0 types built before 1890
SELECT ""Serial number"", ""Wheel arrangement ( Whyte notation )"", ""Build date"", ""Operational owner(s)"", ""Disposition""
FROM table_1_1057316_1
WHERE (""Disposition"" ILIKE '%static%' OR ""Disposition"" ILIKE '%display%' OR ""Disposition"" ILIKE '%Museum%' OR ""Disposition"" ILIKE '%Park%')
  AND ""Wheel arrangement ( Whyte notation )"" IN ('4-4-0','4-6-0')
  AND CAST(RIGHT(""Build date"", 4) AS INTEGER) < 1890;
 -- List preserved locomotives located in target states/places to plan a trip (extracting common state names from disposition strings)
SELECT ""Serial number"", ""Wheel arrangement ( Whyte notation )"", ""Build date"", ""Operational owner(s)"", ""Disposition""
FROM table_1_1057316_1
WHERE ""Disposition"" ILIKE '%Georgia%'
   OR ""Disposition"" ILIKE '%Colorado%'
   OR ""Disposition"" ILIKE '%Nevada%'
   OR ""Disposition"" ILIKE '%Texas%'
   OR ""Disposition"" ILIKE '%Nebraska%'
   OR ""Disposition"" ILIKE '%Wyoming%';
 -- Aggregate by wheel arrangement to see counts and build-year ranges for creating timbral groups
SELECT ""Wheel arrangement ( Whyte notation )"",
       COUNT(*) AS loco_count,
       MIN(CAST(RIGHT(""Build date"",4) AS INTEGER)) AS oldest_build_year,
       MAX(CAST(RIGHT(""Build date"",4) AS INTEGER)) AS newest_build_year
FROM table_1_1057316_1
GROUP BY ""Wheel arrangement ( Whyte notation )""
ORDER BY loco_count DESC;",N/A,rename_column,
"Which Member Association rows with Rank equal to 1, 2, 3, 4, or 5 and with Group stage > 0 have the highest Adjusted Score, where Adjusted Score = CAST(REPLACE(Points,'−','-') AS REAL) + (Group stage * 50.0) + (Play-off * 25.0) + (AFC Cup * 10.0), and what are their Member Association, Adjusted Score, Points, Group stage, Play-off, and AFC Cup values when ordered by Adjusted Score descending limited to 5?",unanswerable,unanswerable,,m_1764878260353_918baac4_1059743-1,"1) The SQL computes an Adjusted Score from Points (after replacing '−' with '-' and casting to a number) plus weighted sums of Group stage, Play-off, and AFC Cup, selecting only ranks 1–5 where Group stage>0 and returning top 5 by that score. 2) Map schema fields to the calculation and filters: use Member Association, Points, Group stage, Play-off, AFC Cup, and Rank. 3) Draft a question that asks for those columns and explicitly states the Points replacement/cast and the weighting, the Rank filter, the Group stage>0 constraint, ordering by Adjusted Score DESC and LIMIT 5. 4) Check that all elements of the SQL are represented in the question.",reserved,11,N/A,remove_column,
"Show the top 10 directors (Directed by) by TotalEpisodes where TotalEpisodes is COUNT(No. in series) restricted to rows with No. in season BETWEEN 1 AND 12; for each Directed by and its Written by provide Director, TotalEpisodes, the column SUM(CASE WHEN Title = '""Voicemail""' THEN 1 ELSE 0 END) AS '""Voicemail""', the column SUM(CASE WHEN Title = '""Harmony""' THEN 1 ELSE 0 END) AS '""Harmony""', the column SUM(CASE WHEN Title = '""Balls""' THEN 1 ELSE 0 END) AS '""Balls""', and WriterTotal equal to the WrittenCount computed as COUNT(*) per Written by, grouping by Directed by and Written by and including only groups where MAX(No. in season) IS NOT NULL OR NOT 0, ordered by TotalEpisodes DESC?",unanswerable,unanswerable,,m_1764878274789_a2ee8bc9_10610087-3,"1) Parse SQL intent: compute per-director aggregates including counts of specific episode titles and join the per-writer counts, limited to season indices 1–12, filter out groups without a valid max season, sort by episode totals and limit to 10. 2) Map schema semantics: use `Directed by` as Director, COUNT(`No. in series`) as TotalEpisodes, title-specific SUM(CASE...) columns for '""Voicemail""', '""Harmony""', '""Balls""', and WrittenCount as WriterTotal per `Written by`. 3) Draft the question asking for these exact fields, grouping and ordering. 4) Validate that all columns, calculations, HAVING, WHERE, GROUP BY and LIMIT are included.",reserved,49,N/A,merge_column,
"Give me a year-by-year PQ table with cleaned numeric vote share, candidates, seats, result, the change in seats and vote share versus the previous election, a flag if the outcome (majority/minority) changed, a flag for large seat swings (>=20 seats), seats per percentage-point of vote, and a 4-election rolling average of vote share?","
WITH cleaned AS (
  SELECT
    `General election` AS year,
    `# of candidates` AS candidates,
    `# of seats won` AS seats,
    CAST(REPLACE(REPLACE(`% of popular vote`, ' %', ''), '%', '') AS REAL) AS vote_share_numeric,
    `Result` AS result
  FROM `table_m_1764878281670_298b0a45_106367_2`
)
SELECT
  year,
  candidates,
  seats,
  vote_share_numeric,
  result,
  seats - LAG(seats) OVER (ORDER BY year) AS seat_change,
  vote_share_numeric - LAG(vote_share_numeric) OVER (ORDER BY year) AS vote_share_change,
  CASE WHEN result != LAG(result) OVER (ORDER BY year) THEN 1 ELSE 0 END AS outcome_changed,
  CASE WHEN ABS(seats - LAG(seats) OVER (ORDER BY year)) >= 20 THEN 1 ELSE 0 END AS large_seat_swing,
  ROUND(seats / NULLIF(vote_share_numeric, 0), 3) AS seats_per_pctpt_vote,
  ROUND(AVG(vote_share_numeric) OVER (ORDER BY year ROWS BETWEEN 3 PRECEDING AND CURRENT ROW), 2) AS rolling_avg_vote_share_4elec
FROM cleaned
ORDER BY year;
","
WITH cleaned AS (
  SELECT
    col0 AS year,
    col1 AS candidates,
    col2 AS seats,
    CAST(REPLACE(REPLACE(col3, ' %', ''), '%', '') AS REAL) AS vote_share_numeric,
    col4 AS result
  FROM `table_m_1764878281670_298b0a45_106367_2`
)
SELECT
  year,
  candidates,
  seats,
  vote_share_numeric,
  result,
  seats - LAG(seats) OVER (ORDER BY year) AS seat_change,
  vote_share_numeric - LAG(vote_share_numeric) OVER (ORDER BY year) AS vote_share_change,
  CASE WHEN result != LAG(result) OVER (ORDER BY year) THEN 1 ELSE 0 END AS outcome_changed,
  CASE WHEN ABS(seats - LAG(seats) OVER (ORDER BY year)) >= 20 THEN 1 ELSE 0 END AS large_seat_swing,
  ROUND(seats / NULLIF(vote_share_numeric, 0), 3) AS seats_per_pctpt_vote,
  ROUND(AVG(vote_share_numeric) OVER (ORDER BY year ROWS BETWEEN 3 PRECEDING AND CURRENT ROW), 2) AS rolling_avg_vote_share_4elec
FROM cleaned
ORDER BY year;
","[(1970.0, 108.0, 7.0, 23.06, 'Liberal majority', None, None, 0, 0, 0.304, 23.06), (1973.0, 110.0, 6.0, 30.22, 'Liberal majority', -1.0, 7.16, 0, 0, 0.199, 26.64), (1976.0, 110.0, 71.0, 41.37, 'PQ majority', 65.0, 11.149999999999999, 1, 1, 1.716, 31.55), (1981.0, 122.0, 80.0, 49.26, 'PQ majority', 9.0, 7.890000000000001, 0, 0, 1.624, 35.98), (1985.0, 122.0, 23.0, 38.69, 'Liberal majority', -57.0, -10.57, 1, 1, 0.594, 39.88), (1989.0, 125.0, 29.0, 40.16, 'Liberal majority', 6.0, 1.4699999999999989, 0, 0, 0.722, 42.37), (1994.0, 125.0, 77.0, 44.75, 'PQ majority', 48.0, 4.590000000000003, 1, 1, 1.721, 43.21), (1998.0, 124.0, 76.0, 42.87, 'PQ majority', -1.0, -1.8800000000000026, 0, 0, 1.773, 41.62), (2003.0, 125.0, 45.0, 33.24, 'Liberal majority', -31.0, -9.629999999999995, 1, 1, 1.354, 40.25), (2007.0, 125.0, 36.0, 28.35, 'Liberal minority', -9.0, -4.890000000000001, 1, 0, 1.27, 37.3), (2008.0, 125.0, 51.0, 35.17, 'Liberal majority', 15.0, 6.82, 1, 0, 1.45, 34.91)]",m_1764878281670_298b0a45_106367-2,"As a senior analyst I know the PQ table and would ask technically precise questions using terms like vote share and seats. The SQL cleans the percent strings, computes year-by-year metrics and lagged changes, flags outcome changes and large swings, and computes seats-per-%pt and a 4-election rolling average. The schema maps to year, # of candidates, # of seats won, % of popular vote (cleaned to numeric) and Result. Draft the question to request a cleaned, ordered time series with those derived metrics. This matches the SQL which returns year, candidates, seats, numeric vote share, result, seat and vote-share changes, outcome change and large-swing flags, seats-per-%pt, and a 4-election rolling average.",persona,"Senior election analyst at a Canadian polling firm who models provincial vote-to-seat translation; they use this database to assess Parti Québécois historical performance and identify patterns relevant to forecasting. They need cleaned, year-by-year metrics (vote share, seats, outcomes) to calibrate models and client briefings. Goals: Measure the relationship between PQ popular vote share and seats won to calibrate a vote-to-seat model. Identify elections with large seat swings or changes in outcome (majority vs. minority) for narrative and risk assessment. Clean and standardize the '% of popular vote' field and produce a time series of vote share and seats for trend analysis and visualizations. Example Queries: /* Time series with numeric vote share */
SELECT
  ""General election"" AS year,
  ""# of candidates"" AS candidates,
  ""# of seats won"" AS seats,
  CAST(REPLACE(REPLACE(""% of popular vote"", ' %', ''), '%', '') AS DECIMAL(5,2)) AS vote_share_numeric,
  ""Result""
FROM table_1_106367_2
ORDER BY ""General election""; /* Seat change between consecutive elections (identify big swings) */
SELECT
  ""General election"" AS year,
  ""# of seats won"" AS seats,
  ""# of seats won"" - LAG(""# of seats won"") OVER (ORDER BY ""General election"") AS seat_change
FROM table_1_106367_2
ORDER BY ""General election""; /* Correlation between cleaned vote share and seats won (if DB supports CORR) */
SELECT
  CORR(
    CAST(REPLACE(REPLACE(""% of popular vote"", ' %', ''), '%', '') AS NUMERIC),
    ""# of seats won""
  ) AS corr_vote_to_seats
FROM table_1_106367_2;",N/A,add_column,
"For each entry, return '1st players choice', '2nd players choice', 'Probability 1st player wins', 'Probability 2nd player wins', and 'Probability of a draw', compute the numeric difference by removing '%' and converting to numbers: (Probability 2nd player wins) minus (Probability 1st player wins), and output which choice is favored by returning '2nd players choice' if that numeric difference is > 0.0 otherwise return '1st players choice'?",,,[],m_1764878297007_4a35df57_10664957-2,"Parse: the query outputs the two choice columns, three probability columns, computes REPLACE to turn percentages into numbers and subtracts to get a difference, then picks one of the choice columns based on whether that difference is positive. Map: align each SQL-selected column and computed expression to natural language. Draft: ask to display those five columns, the numeric subtraction of probabilities, and the conditional selection between the two choice columns. Validate: ensures every column and both calculations (difference and conditional choice) are explicitly requested.",reserved,3,N/A,merge_column,
"For each Series and Team Name, return Series, Team Name, COUNT(Season) as 'Seasons', SUM(Races) as 'Total Races', SUM(Wins) as 'Total Wins', Points per Race computed as ROUND(SUM(Points)*1.0 / SUM(Races), 3), Win Rate computed as ROUND(SUM(Wins)*1.0 / SUM(Races), 3), and include the literal 'Formula BMW ADAC' as Example Series and the literal '2006' as Example Season, only considering rows where Races > 0 and Points >= 0, grouped by Series and Team Name, ordered by Points per Race descending and limited to the top 5?","
SELECT `Series`, `Team Name`, COUNT(`Season`) `Seasons`, SUM(`Races`) `Total Races`, SUM(`Wins`) `Total Wins`, ROUND(SUM(`Points`)*1.0 / SUM(`Races`),3) `Points per Race`, ROUND(SUM(`Wins`)*1.0 / SUM(`Races`),3) `Win Rate`, '`Formula BMW ADAC`' `Example Series`, '`2006`' `Example Season`
FROM `table_m_1764878317648_41835c0b_10705060_1`
WHERE `Races` > 0 AND `Points` >= 0
GROUP BY `Series`, `Team Name`
ORDER BY `Points per Race` DESC
LIMIT 5;
","
SELECT col1, col2, COUNT(col0) `Seasons`, SUM(col3) `Total Races`, SUM(col5) `Total Wins`, ROUND(SUM(col6)*1.0 / SUM(col3),3) `Points per Race`, ROUND(SUM(col5)*1.0 / SUM(col3),3) `Win Rate`, '`Formula BMW ADAC`' `Example Series`, '`2006`' `Example Season`
FROM `table_m_1764878317648_41835c0b_10705060_1`
WHERE col3 > 0 AND col6 >= 0
GROUP BY col1, col2
ORDER BY `Points per Race` DESC
LIMIT 5;
","[('Formula BMW ADAC', 'Josef Kaufmann Racing', 1, 18.0, 9.0, 15.389, 0.5, '`Formula BMW ADAC`', '`2006`'), ('German Formula Three', 'Josef Kaufmann Racing', 1, 12.0, 1.0, 5.167, 0.083, '`Formula BMW ADAC`', '`2006`'), ('Formula 3 Euro Series', 'Mücke Motorsport', 2, 38.0, 5.0, 2.921, 0.132, '`Formula BMW ADAC`', '`2006`'), ('Deutsche Tourenwagen Masters', 'HWA Team', 1, 10.0, 0.0, 2.5, 0.0, '`Formula BMW ADAC`', '`2006`'), ('GP2 Series', 'Racing Engineering', 2, 32.0, 3.0, 2.0, 0.094, '`Formula BMW ADAC`', '`2006`')]",m_1764878317648_41835c0b_10705060-1,"1) Parse SQL intent: aggregate records by Series and Team Name to compute counts, sums, and rates, filter by Races > 0 and Points >= 0, order by Points per Race descending and return top 5. 2) Map schema semantics: use Season, Series, Team Name, Races, Wins, Points columns to compute COUNT(Season) as Seasons, SUM(Races) as Total Races, SUM(Wins) as Total Wins, Points per Race and Win Rate. 3) Draft the question: ask for the specified selected columns, calculations, literal example columns, filters, grouping, ordering, and limit. 4) Validate: the question must mention every column and calculation and the exact filters, grouping, ordering, rounding to 3 decimals, and the Example Series/Season values.",reserved,8,N/A,add_column,
"To plan digitization and exhibits, list the top 10 episodes by U.S. viewers with their series/season numbers, title, director, writer, original air date, numeric viewers, the director's average viewership and rank, and the number of episodes that director and writer did together plus a flag if they collaborated more than once.","
WITH `director_avg` AS (
  SELECT
    `Directed by`,
    ROUND(AVG(CAST(REPLACE(`U.S. viewers (millions)`, ',', '') AS REAL)), 2) AS avg_viewers,
    RANK() OVER (ORDER BY AVG(CAST(REPLACE(`U.S. viewers (millions)`, ',', '') AS REAL)) DESC) AS director_rank
  FROM `table_m_1764878338499_34925243_10718192_2`
  GROUP BY `Directed by`
),
`pair_counts` AS (
  SELECT
    `Directed by`,
    `Written by`,
    COUNT(*) AS episodes_together
  FROM `table_m_1764878338499_34925243_10718192_2`
  GROUP BY `Directed by`, `Written by`
),
`episodes_with_flags` AS (
  SELECT
    t.`No. in series`,
    t.`No. in season`,
    t.`Title`,
    t.`Directed by`,
    t.`Written by`,
    t.`Original air date`,
    t.`U.S. viewers (millions)`,
    CAST(REPLACE(t.`U.S. viewers (millions)`, ',', '') AS REAL) AS viewers_real,
    da.avg_viewers,
    da.director_rank,
    COALESCE(pc.episodes_together, 0) AS episodes_together,
    CASE WHEN COALESCE(pc.episodes_together, 0) > 1 THEN 1 ELSE 0 END AS recurring_collab
  FROM `table_m_1764878338499_34925243_10718192_2` AS t
  LEFT JOIN `director_avg` AS da ON t.`Directed by` = da.`Directed by`
  LEFT JOIN `pair_counts` AS pc ON t.`Directed by` = pc.`Directed by` AND t.`Written by` = pc.`Written by`
)
SELECT
  `No. in series`,
  `No. in season`,
  `Title`,
  `Directed by`,
  `Written by`,
  `Original air date`,
  `U.S. viewers (millions)`,
  viewers_real,
  avg_viewers,
  director_rank,
  episodes_together,
  recurring_collab
FROM `episodes_with_flags`
ORDER BY viewers_real DESC, `No. in series` ASC
LIMIT 10;
","
WITH `director_avg` AS (
  SELECT
    col3,
    ROUND(AVG(CAST(REPLACE(col6, ',', '') AS REAL)), 2) AS avg_viewers,
    RANK() OVER (ORDER BY AVG(CAST(REPLACE(col6, ',', '') AS REAL)) DESC) AS director_rank
  FROM `table_m_1764878338499_34925243_10718192_2`
  GROUP BY col3
),
`pair_counts` AS (
  SELECT
    col3,
    col4,
    COUNT(*) AS episodes_together
  FROM `table_m_1764878338499_34925243_10718192_2`
  GROUP BY col3, col4
),
`episodes_with_flags` AS (
  SELECT
    t.col0,
    t.col1,
    t.col2,
    t.col3,
    t.col4,
    t.col5,
    t.col6,
    CAST(REPLACE(t.col6, ',', '') AS REAL) AS viewers_real,
    da.avg_viewers,
    da.director_rank,
    COALESCE(pc.episodes_together, 0) AS episodes_together,
    CASE WHEN COALESCE(pc.episodes_together, 0) > 1 THEN 1 ELSE 0 END AS recurring_collab
  FROM `table_m_1764878338499_34925243_10718192_2` AS t
  LEFT JOIN `director_avg` AS da ON t.col3 = da.col3
  LEFT JOIN `pair_counts` AS pc ON t.col3 = pc.col3 AND t.col4 = pc.col4
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  col6,
  viewers_real,
  avg_viewers,
  director_rank,
  episodes_together,
  recurring_collab
FROM `episodes_with_flags`
ORDER BY viewers_real DESC, col0 ASC
LIMIT 10;
","[(50.0, 4.0, '""A Little Murder""', 'Tucker Gates', 'Ann Donahue & Naren Shankar', 'October17,2002', '30.81', 30.81, 30.81, 1, 1, 0), (47.0, 1.0, '""Revenge Is Best Served Cold""', 'Danny Cannon', 'Carol Mendelsohn & Anthony E. Zuiker', 'September26,2002', '30.47', 30.47, 28.97, 3, 1, 0), (53.0, 7.0, '""Fight Night""', 'Richard J. Lewis', 'Andrew Lipsitz & Naren Shankar', 'November14,2002', '29.94', 29.94, 28.58, 4, 1, 0), (49.0, 3.0, '""Let the Seller Beware""', 'Richard J. Lewis', 'Andrew Lipsitz & Anthony E. Zuiker', 'October10,2002', '29.90', 29.9, 28.58, 4, 1, 0), (55.0, 9.0, '""Blood Lust""', 'Charlie Correll', 'Josh Berman & Carol Mendelsohn', 'December5,2002', '29.74', 29.74, 29.74, 2, 1, 0), (51.0, 5.0, '""Abra-Cadaver""', 'Danny Cannon', 'Danny Cannon & Anthony E. Zuiker', 'October31,2002', '28.95', 28.95, 28.97, 3, 1, 0), (63.0, 17.0, '""Crash and Burn""', 'Richard J. Lewis', 'Josh Berman', 'March13,2003', '28.60', 28.6, 28.58, 4, 1, 0), (48.0, 2.0, '""The Accused Is Entitled""', 'Kenneth Fink', 'Elizabeth Devine & Ann Donahue', 'October3,2002', '28.46', 28.46, 27.2, 5, 1, 0), (62.0, 16.0, '""Lucky Strike""', 'Kenneth Fink', 'Eli Talbert & Anthony E. Zuiker', 'February20,2003', '27.95', 27.95, 27.2, 5, 1, 0), (58.0, 12.0, '""Got Murder?""', 'Kenneth Fink', 'Sarah Goldfinger', 'January16,2003', '27.87', 27.87, 27.2, 5, 1, 0)]",m_1764878338499_34925243_10718192-2,"As a curator I might request this to decide which episodes to digitize and which directors to highlight, using non-technical phrasing but referencing averages and recurring teams. The SQL compiles per-director average viewership and rank, counts director-writer episode pairs, and returns the top ten episodes by viewers with those annotations. Schema mapping: episode identifiers, title, director, writer, air date, U.S. viewers (converted to real), director averages/rank, pair counts, and a recurring_collab flag. Drafted question: ask for the top ten episodes by US viewers including all those metrics to guide digitization and exhibit decisions. Validate: the question asks exactly for the dataset fields and computed metrics the query produces and restricts to the top ten.",persona,"A museum archive curator specializing in 21st-century television who prioritizes which CSI episodes to digitize and exhibit based on cultural impact signals in the episode metadata. Goals: Identify the highest-viewed episodes to prioritize for digitization and exhibition placards. Find recurring director-writer collaborations to highlight influential creative teams in the exhibit narrative. Rank creators (directors) by average live-viewership to decide whose behind-the-scenes materials to commission or display. Example Queries: SELECT ""No. in series"", ""No. in season"", ""Title"", ""Directed by"", ""Written by"", ""Original air date"", ""U.S. viewers (millions)""
FROM ""table_1_10718192_2""
ORDER BY CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL) DESC
LIMIT 5; SELECT ""Directed by"", ""Written by"", COUNT(*) AS episodes_together
FROM ""table_1_10718192_2""
GROUP BY ""Directed by"", ""Written by""
HAVING COUNT(*) > 1
ORDER BY episodes_together DESC, ""Directed by""; SELECT ""Directed by"", ROUND(AVG(CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL)), 2) AS avg_viewers
FROM ""table_1_10718192_2""
GROUP BY ""Directed by""
ORDER BY avg_viewers DESC;",N/A,merge_column,
"Considering only races where the Date is not empty (LENGTH(Date) > 0), what are the distinct Winning team names and their COUNT(*) as Wins, grouped by Winning team, ordered by Wins in descending order, and limited to the top 5 teams?","
SELECT DISTINCT `Winning team`, COUNT(*) `Wins`
FROM `table_m_1764878348904_a27568f7_10725629_2`
WHERE LENGTH(`Date`)>0
GROUP BY `Winning team`
ORDER BY `Wins` * -1
LIMIT 5;
","
SELECT DISTINCT col8, COUNT(*) `Wins`
FROM `table_m_1764878348904_a27568f7_10725629_2`
WHERE LENGTH(col4)>0
GROUP BY col8
ORDER BY `Wins` * -1
LIMIT 5;
","[('Marlboro Team Penske', 5), ('Newman/Haas Racing', 4), ('Rahal-Hogan Racing', 4), ('Galles-Kraco Racing', 2), ('Walker Motorsport', 1)]",m_1764878348904_a27568f7_10725629-2,"1) Parse intent: compute the count of wins per distinct Winning team for entries where Date has length greater than zero, then list the five teams with the most wins in descending order. 2) Map schema: this requires the 'Winning team' and 'Date' columns and the aggregate COUNT(*) named 'Wins' with GROUP BY 'Winning team'. 3) Draft: pose a question explicitly requesting distinct Winning team, Wins count, the Date non-empty filter, grouping, descending order, and a five-row limit. 4) Validate: check that the question includes DISTINCT Winning team, COUNT(*) as Wins, WHERE LENGTH(Date)>0, GROUP BY Winning team, ORDER BY Wins DESC (Wins * -1), and LIMIT 5.",reserved,8,N/A,rename_column,
"For directors (Directed by) with more than one episode (HAVING COUNT(*) > 1) and only including rows where Series # > 0 and Season # > 0, what are Director, EpisodeCount (COUNT(*)), AvgViewers = ROUND(AVG(`U.S. viewers (millions)` * 1.0), 2), and ViewersRange = ROUND((MAX(`U.S. viewers (millions)` * 1.0) - MIN(`U.S. viewers (millions)` * 1.0)), 2), when grouped by Directed by, ordered by AvgViewers and limited to 5 results?","
SELECT `Directed by` AS `Director`,
       COUNT(*) `EpisodeCount`,
       ROUND(AVG(`U.S. viewers (millions)` * 1.0),2) `AvgViewers`,
       ROUND((MAX(`U.S. viewers (millions)` * 1.0) - MIN(`U.S. viewers (millions)` * 1.0)),2) `ViewersRange`
FROM `table_m_1764878354121_36ce3b58_10749143_2`
WHERE `Series #` > 0 AND `Season #` > 0
GROUP BY `Directed by`
HAVING COUNT(*) > 1
ORDER BY `AvgViewers`
LIMIT 5;
","
SELECT col3 AS `Director`,
       COUNT(*) `EpisodeCount`,
       ROUND(AVG(col6 * 1.0),2) `AvgViewers`,
       ROUND((MAX(col6 * 1.0) - MIN(col6 * 1.0)),2) `ViewersRange`
FROM `table_m_1764878354121_36ce3b58_10749143_2`
WHERE col0 > 0 AND col1 > 0
GROUP BY col3
HAVING COUNT(*) > 1
ORDER BY `AvgViewers`
LIMIT 5;
","[('Brad Turner', 8, 11.17, 2.52), ('Milan Cheylov', 2, 11.45, 0.46), ('Jon Cassar', 5, 11.71, 2.24)]",m_1764878354121_36ce3b58_10749143-2,"1) The SQL aggregates by director and computes count, average and range of U.S. viewers with rounding, filters out non-positive Series # and Season #, keeps directors with COUNT(*) > 1, orders by average viewers and returns 5 rows. 2) Treat Directed by as the grouping key and U.S. viewers (millions) * 1.0 as the numeric input to AVG, MAX and MIN. 3) Compose a question requesting the director name, number of episodes, the AVG of U.S. viewers (millions) multiplied by 1.0 rounded to two decimals, and the difference between MAX and MIN of U.S. viewers (millions) multiplied by 1.0 rounded to two decimals, for directors meeting the filters and HAVING clause, ordered by average and limited to five. 4) Ensure the question explicitly references COUNT(*), ROUND(AVG(...)*1.0,2) and ROUND(MAX-MIN,2) and the Series # and Season # filters.",reserved,10,N/A,remove_column,
"Give me a per-college breakdown for Round Five showing each college, how many draftees they had (and percent of the round), plus the players, their positions, the teams that drafted them, and the pick numbers.",,,[],m_1764878370710_96104099_10812938-5,"As a curator contacting universities and teams I need a per-school breakdown in plain language rather than SQL. The SQL intent is to group by college and return count, percent of the round, and concatenated lists of players, positions, teams, and pick numbers. Mapping: College -> school name, COUNT(*) -> number drafted, subquery -> percent of the round, GROUP_CONCAT -> lists of Player, Position, CFL Team, and Pick #. Draft question: Give me a per-college breakdown for Round Five showing each college, how many draftees they had (and percent of the round), plus the players, their positions, the teams that drafted them, and the pick numbers. Validate: That requests exactly the columns and aggregates produced by the query.",persona,"A museum curator assembling a traveling exhibit 'From Campus to Cleats' that highlights how small and Canadian universities fed into the CFL, using the 2006 draft Round Five as a focused case study. Goals: Identify which colleges are represented in Round Five so the exhibit can request artifacts and alumni stories from those institutions. Quantify and compare college representation (how many draftees came from each school) to decide which universities merit featured display space. Find players by position and team to build themed display panels (e.g., offensive linemen, defensive backs) and to contact teams for game-used items. Example Queries: SELECT ""Pick #"", ""CFL Team"", ""Player"", ""Position"", ""College"" FROM ""table_1_10812938_5"" WHERE ""College"" = 'Wilfrid Laurier'; SELECT ""College"", COUNT(*) AS num_drafted FROM ""table_1_10812938_5"" GROUP BY ""College"" ORDER BY num_drafted DESC; SELECT ""Pick #"", ""CFL Team"", ""Player"", ""Position"", ""College"" FROM ""table_1_10812938_5"" WHERE ""Position"" IN ('OL', 'DB', 'SB');",N/A,merge_column,
"For each 'Directed by' value that directed more than one episode, list the director name, the count of episodes (Episodes) and the average 'U.S. viewers (millions)' rounded to two decimal places (AvgViewers), but include only directors whose average viewers exceed 13.5, and show the top 5 directors by AvgViewers in descending order?","
SELECT `Directed by` AS `Director`, COUNT(*) `Episodes`, ROUND(AVG(`U.S. viewers (millions)` + 0.0),2) `AvgViewers`
FROM `table_m_1764878392174_eaabf4e2_10842344_1`
GROUP BY `Directed by`
HAVING COUNT(*) > 1 AND AVG(`U.S. viewers (millions)` + 0.0) > 13.5
ORDER BY `AvgViewers` DESC
LIMIT 5;
","
SELECT col3 AS `Director`, COUNT(*) `Episodes`, ROUND(AVG(col7 + 0.0),2) `AvgViewers`
FROM `table_m_1764878392174_eaabf4e2_10842344_1`
GROUP BY col3
HAVING COUNT(*) > 1 AND AVG(col7 + 0.0) > 13.5
ORDER BY `AvgViewers` DESC
LIMIT 5;
","[('Jean de Segonzac', 3, 13.72), ('David Platt', 5, 13.65)]",m_1764878392174_eaabf4e2_10842344-1,"1) Parse intent: group rows by director, count episodes per director, compute average viewers, keep only directors with count>1 and average>13.5, return top five by average. 2) Map schema: use 'Directed by' for director name and 'U.S. viewers (millions)' for averaging; apply ROUND(...,2) to produce AvgViewers. 3) Draft question to request Director, Episodes and AvgViewers with the stated filters and ordering. 4) Validate: question explicitly requests COUNT as Episodes, AVG rounded to 2 decimals, HAVING conditions, descending order and LIMIT 5.",reserved,11,N/A,add_column,
"For each Director, after joining the table to itself on t.`No. in series` = t2.`No. in series`, what is the Director, the COUNT(*) as EpisodeCount, the MIN(t.`No. in series`) as FirstSeriesNo, the MAX(t.`No. in series`) as LastSeriesNo, the MIN(t.`Title`) as FirstTitle and the MAX(t.`Title`) as LastTitle for rows satisfying t.`No. in series` > 100 OR (t2.`No. in season` < 33 AND t.`No. in season` > 10), grouped by Director, ordered by EpisodeCount descending, limited to the top 5 results?",unanswerable,unanswerable,,m_1764878416547_6986f638_10953197-4,"1) Parse intent: the query selects Director, COUNT(*), MIN/ MAX of No. in series and Title, from a self-joined table with a WHERE filter, grouped by Director, ordered by count desc, limited to 5. 2) Map schema: No. in series and No. in season are numeric episode indices, Title is episode title, Director is grouped. 3) Draft: produce a question that requests those exact aggregates, the self-join condition, the WHERE condition with its AND/OR logic, grouping, ordering and limit. 4) Validate: the question mentions Director, COUNT(*) as EpisodeCount, MIN/MAX of No. in series and Title, the join on No. in series, the WHERE expression, GROUP BY Director, ORDER BY COUNT(*) DESC and LIMIT 5.",reserved,12,N/A,remove_column,
"For each Count Palatine of Saxony (output column named ""Frederick II, Elector of Saxony""), what is the COUNT(*) as Cases when Cases > 1, returning up to 10 rows ordered by Cases in descending order?","
WITH totals AS (
  SELECT `Count Palatine of Saxony` AS `Frederick II, Elector of Saxony`, COUNT(*) AS `Cases`
  FROM `table_m_1764878435459_851349cf_11071897_1`
  GROUP BY `Count Palatine of Saxony`
)
SELECT `Frederick II, Elector of Saxony`, `Cases`
FROM totals
WHERE `Cases` > 1
ORDER BY `Cases` DESC
LIMIT 10;
","
WITH totals AS (
  SELECT col3 AS `Frederick II, Elector of Saxony`, COUNT(*) AS `Cases`
  FROM `table_m_1764878435459_851349cf_11071897_1`
  GROUP BY col3
)
SELECT `Frederick II, Elector of Saxony`, `Cases`
FROM totals
WHERE `Cases` > 1
ORDER BY `Cases` DESC
LIMIT 10;
","[('Frederick Augustus II, Elector of Saxony', 2), ('Frederick II, Elector of Saxony', 2), ('John George I, Elector of Saxony', 2)]",m_1764878435459_851349cf_11071897-1,"1) Parse intent: select grouped `Count Palatine of Saxony` and COUNT(*) as `Cases`, filter Cases>1, order descending, limit 10. 2) Map schema: grouped column labeled `Frederick II, Elector of Saxony`, aggregate labeled `Cases`. 3) Draft question: request for each Count Palatine of Saxony (alias given) the COUNT(*) as Cases where Cases>1, ordered by Cases desc, top 10. 4) Validate: question captures every column, calculation, filter, ordering and limit from the query.",reserved,14,N/A,add_column,
"Over the entire table, what are COUNT(*), SUM((U.S. viewers (million) + 0.0) > 3.0), 100.0 * SUM((U.S. viewers (million) + 0.0) > 3.0) / COUNT(*), AVG(U.S. viewers (million) + 0.0), and the literal outputs '""Winds of War""' and 'March 4, 2012'?","
SELECT COUNT(*), SUM((`U.S. viewers (million)` + 0.0) > 3.0), 100.0 * SUM((`U.S. viewers (million)` + 0.0) > 3.0) / COUNT(*), AVG(`U.S. viewers (million)` + 0.0), '`""Winds of War""`', '`March 4, 2012`' FROM `table_m_1764878461335_a1a6dfaa_11111116_7` WHERE 1=1;
","
SELECT COUNT(*), SUM((col5 + 0.0) > 3.0), 100.0 * SUM((col5 + 0.0) > 3.0) / COUNT(*), AVG(col5 + 0.0), '`""Winds of War""`', '`March 4, 2012`' FROM `table_m_1764878461335_a1a6dfaa_11111116_7` WHERE 1=1;
","[(22, 12, 54.54545454545455, 3.075454545454545, '`""Winds of War""`', '`March 4, 2012`')]",m_1764878461335_a1a6dfaa_11111116-7,"1) Parse intent: compute overall row count, count of rows where (U.S. viewers (million)+0.0) exceeds 3.0, that count as a percentage of total, the numeric average of U.S. viewers (million), and return the exact strings '""Winds of War""' and 'March 4, 2012'. 2) Map schema: identify U.S. viewers (million) as the column used in the >3.0 predicate and AVG after adding 0.0. 3) Draft: ask a question that requests these aggregates and the two literal values. 4) Validate: ensure no extra information beyond the SQL is introduced and all SQL expressions are represented.",reserved,3,N/A,remove_column,
Which division has the highest goals per appearance with at least 30 league appearances?,"
SELECT `Division`,
       SUM(`League Apps (Sub)` + 0) `Total League Apps`,
       SUM(`League Goals`) `Total League Goals`,
       (SUM(`FA Cup Goals` + 0) + SUM(`FL Cup Goals` + 0) + SUM(`Other Goals` + 0)) `Cup+Other Goals`,
       SUM(REPLACE(REPLACE(REPLACE(`Total Apps (Sub)`, '(', ''), ')', ''), ' ', '') + 0) `Total Apps`,
       ROUND(SUM(`Total Goals`) * 1.0 / SUM(REPLACE(REPLACE(REPLACE(`Total Apps (Sub)`, '(', ''), ')', ''), ' ', '') + 0), 3) `Goals per App`
FROM `table_m_1764878466515_959e252b_1112176_1`
WHERE `League Apps (Sub)` + 0 >= 30
GROUP BY `Division`
ORDER BY `Goals per App` DESC
LIMIT 5;
","
SELECT col1,
       SUM(col2 + 0) `Total League Apps`,
       SUM(col3) `Total League Goals`,
       (SUM(col5 + 0) + SUM(col7 + 0) + SUM(col9 + 0)) `Cup+Other Goals`,
       SUM(REPLACE(REPLACE(REPLACE(col10, '(', ''), ')', ''), ' ', '') + 0) `Total Apps`,
       ROUND(SUM(col11) * 1.0 / SUM(REPLACE(REPLACE(REPLACE(col10, '(', ''), ')', ''), ' ', '') + 0), 3) `Goals per App`
FROM `table_m_1764878466515_959e252b_1112176_1`
WHERE col2 + 0 >= 30
GROUP BY col1
ORDER BY `Goals per App` DESC
LIMIT 5;
","[('One', 152.0, 19.0, 9.0, 190, 0.147), ('Two', 119.0, 25.0, 1.0, 487, 0.053)]",m_1764878466515_959e252b_1112176-1,"STEP 1: Parse the SQL intent — group rows by Division, include only rows where League Apps (Sub) >= 30, compute summed League Apps, summed League Goals, summed Cup+Other Goals, summed Total Apps (after stripping parentheses/spaces), and Goals per App = SUM(Total Goals) / SUM(Total Apps); order divisions by Goals per App descending and return top 5. STEP 2: Determine ambiguity type — scope/attachment ambiguity fits best: the qualifier ""with at least 30 league appearances"" can reasonably attach either to individual season rows (row-level filter, which the SQL uses) or to the aggregated division totals (group-level filter). STEP 3: Draft the question — ""Which division has the highest goals per appearance with at least 30 league appearances?"" STEP 4: Explain ambiguity — in the original SQL the clause applies at the row/season level (only seasons with >=30 league apps are included in the division aggregates). An alternative reading is that the 30-app threshold should apply to the division totals (only include divisions whose summed league apps are >=30), which would change which divisions are considered and potentially the ranking.",reserved,8,N/A,add_column,"type: Scope/attachment ambiguity | explanation: The phrase ""with at least 30 league appearances"" can attach to individual seasons (the SQL's interpretation: only seasons/rows with >=30 league apps are included before aggregation) or to divisions (an alternative: only include divisions whose total league apps across seasons reach >=30), producing different sets of data and possibly different top divisions."
"Restricting to records where Year of affiliation is not 'N/A' or Owned since is not 'N/A' and to City of license/Market IN ('Los Angeles','Newark - New York City'), for each City of license/Market (grouped by City of license/Market) what is the City of license/Market, how many Stations (COUNT(*)), how many are Affiliated_2002 (SUM(Year of affiliation = '2002')), how many are Owned_2002 (SUM(Owned since = '2002')), and what is Pct Affiliated 2002 computed as ROUND(100.0 * SUM(Year of affiliation = '2002') / COUNT(*), 2), including only cities with more than zero stations and returning at most 5 rows?","
SELECT `City of license/Market`,
       COUNT(*) `Stations`,
       SUM(`Year of affiliation` = '2002') `Affiliated_2002`,
       SUM(`Owned since` = '2002') `Owned_2002`,
       ROUND(100.0 * SUM(`Year of affiliation` = '2002') / COUNT(*),2) AS `Pct Affiliated 2002`
FROM `table_m_1764878487939_cd5c8da0_11147852_1`
WHERE (`Year of affiliation` != 'N/A' OR `Owned since` != 'N/A')
  AND `City of license/Market` IN ('Los Angeles','Newark - New York City')
GROUP BY `City of license/Market`
HAVING COUNT(*) > 0
LIMIT 5;
","
SELECT col0,
       COUNT(*) `Stations`,
       SUM(col2 = '2002') `Affiliated_2002`,
       SUM(col3 = '2002') `Owned_2002`,
       ROUND(100.0 * SUM(col2 = '2002') / COUNT(*),2) AS `Pct Affiliated 2002`
FROM `table_m_1764878487939_cd5c8da0_11147852_1`
WHERE (col2 != 'N/A' OR col3 != 'N/A')
  AND col0 IN ('Los Angeles','Newark - New York City')
GROUP BY col0
HAVING COUNT(*) > 0
LIMIT 5;
","[('Los Angeles', 1, 1, 1, 100.0), ('Newark - New York City', 1, 1, 1, 100.0)]",m_1764878487939_cd5c8da0_11147852-1,"Parse: query filters to two city names and non-'N/A' records, groups by City of license/Market, produces count of stations, counts where Year of affiliation = '2002' and Owned since = '2002', computes a 2-decimal percent of affiliations in 2002, and applies HAVING COUNT(*)>0 and LIMIT 5. Map: map boolean SUMs and rounding to natural language. Draft: request those aggregates, filters, grouping, and limit explicitly. Validate: confirm all selected fields, calculations, the OR condition, IN list, GROUP BY, HAVING, and LIMIT are present.",reserved,11,N/A,split_column,
"Between 1998 and 2007, report the top three years (by descending year-over-year percent change) in which the Numer of Jamaicans granted British citizenship increased compared with the previous year (including cases where the previous year total was 0); for each year provide Year, the Numer of Jamaicans granted British citizenship as Total, the percentage of Total from Naturalisation by residence (rounded to 2 decimal places), the percentage of Total from Naturalisation by marriage (rounded to 2 decimal places), the percentage of Total from Registration of a minor child (rounded to 2 decimal places), the percentage of Total from Registration by other means (rounded to 2 decimal places), and YoY_% defined as 100.0*(Total this year - Total previous year)/Total previous year rounded to 2 decimal places?","
SELECT
 t.`Year` AS `Year`,
 t.`Numer of Jamaicans granted British citizenship` `Total`,
 ROUND(100.0 * t.`Naturalisation by residence` / t.`Numer of Jamaicans granted British citizenship`,2) `Pct_residence`,
 ROUND(100.0 * t.`Naturalisation by marriage` / t.`Numer of Jamaicans granted British citizenship`,2) `Pct_marriage`,
 ROUND(100.0 * t.`Registration of a minor child` / t.`Numer of Jamaicans granted British citizenship`,2) `Pct_minor`,
 ROUND(100.0 * t.`Registration by other means` / t.`Numer of Jamaicans granted British citizenship`,2) `Pct_other`,
 ROUND(100.0 * (t.`Numer of Jamaicans granted British citizenship` - p.`Numer of Jamaicans granted British citizenship`) / p.`Numer of Jamaicans granted British citizenship`,2) `YoY_%`
FROM `table_m_1764878528297_6e072572_11214212_1` t
JOIN `table_m_1764878528297_6e072572_11214212_1` p ON p.`Year` = t.`Year` - 1
WHERE t.`Year` IN (1998,1999,2000,2001,2002,2003,2004,2005,2006,2007) AND (t.`Numer of Jamaicans granted British citizenship` > p.`Numer of Jamaicans granted British citizenship` OR p.`Numer of Jamaicans granted British citizenship` = 0)
GROUP BY t.`Year`
HAVING ROUND(100.0 * (t.`Numer of Jamaicans granted British citizenship` - p.`Numer of Jamaicans granted British citizenship`) / p.`Numer of Jamaicans granted British citizenship`,2) > 0
ORDER BY `YoY_%` DESC
LIMIT 3 OFFSET 0;
","
SELECT
 t.col0 AS col0,
 t.col1 `Total`,
 ROUND(100.0 * t.col2 / t.col1,2) `Pct_residence`,
 ROUND(100.0 * t.col3 / t.col1,2) `Pct_marriage`,
 ROUND(100.0 * t.col4 / t.col1,2) `Pct_minor`,
 ROUND(100.0 * t.col5 / t.col1,2) `Pct_other`,
 ROUND(100.0 * (t.col1 - p.col1) / p.col1,2) `YoY_%`
FROM `table_m_1764878528297_6e072572_11214212_1` t
JOIN `table_m_1764878528297_6e072572_11214212_1` p ON p.col0 = t.col0 - 1
WHERE t.col0 IN (1998,1999,2000,2001,2002,2003,2004,2005,2006,2007) AND (t.col1 > p.col1 OR p.col1 = 0)
GROUP BY t.col0
HAVING ROUND(100.0 * (t.col1 - p.col1) / p.col1,2) > 0
ORDER BY `YoY_%` DESC
LIMIT 3 OFFSET 0;
","[(1998.0, 1370.0, 41.68, 41.17, 16.13, 1.02, 87.16), (2003.0, 2795.0, 45.97, 35.24, 18.6, 0.18, 38.02), (2000.0, 1882.0, 49.26, 35.28, 14.93, 0.53, 30.97)]",m_1764878528297_6e072572_11214212-1,"1) Parse SQL intent: compute per-year percentage breakdowns of grant methods and YoY percentage change for 1998–2007, filter to years where total rose versus the prior year (or prior year = 0), then pick the top three by YoY_% descending. 2) Map schema: identify Year, Numer of Jamaicans granted British citizenship (Total) and the four grant-type columns. 3) Draft: ask for Year, Total, each grant type as percent of Total (each percent rounded to 2 decimals), and YoY_% using the given formula rounded to 2 decimals; include year range, positive YoY condition including prior-year-zero, ordering and limit. 4) Validate: question matches all calculations, rounding, filters, and ordering from the SQL.",reserved,16,N/A,add_column,
"Which rows should be returned with No. in series, Title, and U.S. viewers (millions) along with the value CAST(U.S. viewers (millions) AS REAL) minus the table average of CAST(U.S. viewers (millions) AS REAL) (showing that difference as 19.90), limited to episodes where CAST(U.S. viewers (millions) AS REAL) > average and sorted by the 19.90 column in descending order?",unanswerable,unanswerable,,m_1764878545475_e8bb36d5_11230937-2,"1) The intent is to compute the per-episode numeric difference between each episode's viewers and the overall average, list identifying columns, restrict to above-average episodes, and sort by the difference descending. 2) Map schema: pull `No. in series`, `Title`, the `U.S. viewers (millions)` field, cast viewers to REAL for AVG and subtraction, and alias the subtraction as 19.90. 3) Draft: request those fields and the calculation with the alias, include only episodes whose numeric viewers exceed the computed average, and order by the computed alias in descending order. 4) Validate: ensures inclusion of CAST, AVG, subtraction, alias 19.90, the > average condition, and descending ordering.",reserved,18,N/A,merge_column,
"What are COUNT(Engine) (High_Gear_High_Octane_Count), AVG(length(""Power, takeoff"")) (Avg_takeoff_power_label_length), and SUM((Compression ratio = '6.0:1')) (Six_to_one_count) for rows with Supercharger gear ratio = '10:1' and Octane rating containing '80'?","
SELECT COUNT(`Engine`) `High_Gear_High_Octane_Count`, AVG(length(`Power, takeoff`)) `Avg_takeoff_power_label_length`, SUM((`Compression ratio` = '6.0:1')) `Six_to_one_count` FROM `table_m_1764878558174_d7fcb5f2_1123802_1` WHERE `Supercharger gear ratio` = '10:1' AND instr(`Octane rating`, '80') > 0;
","
SELECT COUNT(col0) `High_Gear_High_Octane_Count`, AVG(length(col3)) `Avg_takeoff_power_label_length`, SUM((col4 = '6.0:1')) `Six_to_one_count` FROM `table_m_1764878558174_d7fcb5f2_1123802_1` WHERE col5 = '10:1' AND instr(col6, '80') > 0;
","[(3, 9.333333333333334, 3)]",m_1764878558174_d7fcb5f2_1123802-1,"Parse the SQL intent: produce the count of engines, the average length of the 'Power, takeoff' text, and the sum/count of rows matching Compression ratio = '6.0:1' for rows filtered by Supercharger gear ratio = '10:1' and Octane rating containing '80'. Map schema semantics: reference Engine, ""Power, takeoff"", Compression ratio, Supercharger gear ratio, and Octane rating and preserve output aliases. Draft the question: request those three named aggregate results under the specified WHERE conditions. Validate: confirm inclusion of all columns, calculations, aliases, and filters exactly as in the query.",reserved,4,N/A,add_column,
"Return the Category (Category = 'Family' if Relationship contains 'wife', 'daughter', 'son', 'sister', 'husband', or 'ex-husband', else 'Other'), the COUNT(*) as Count, and the GROUP_CONCAT(Character, ', ') returned as 'Reed Garrett', grouping by Category and ordering the groups by Count in descending order?","
SELECT CASE WHEN (instr(`Character_With_Relationship`,'wife') + instr(`Character_With_Relationship`,'daughter') + instr(`Character_With_Relationship`,'son') + instr(`Character_With_Relationship`,'sister') + instr(`Character_With_Relationship`,'husband') + instr(`Character_With_Relationship`,'ex-husband')) > 0 THEN 'Family' ELSE 'Other' END `Category`, COUNT(*) `Count`, GROUP_CONCAT(`Character_With_Relationship`, ', ') AS `Reed Garrett`
FROM `table_m_1764878567913_6a217817_11240028_3`
WHERE 1=1
GROUP BY `Category`
ORDER BY `Count` DESC;
","
SELECT CASE WHEN (instr(col3,'wife') + instr(col3,'daughter') + instr(col3,'son') + instr(col3,'sister') + instr(col3,'husband') + instr(col3,'ex-husband')) > 0 THEN 'Family' ELSE 'Other' END `Category`, COUNT(*) `Count`, GROUP_CONCAT(col3, ', ') AS `Reed Garrett`
FROM `table_m_1764878567913_6a217817_11240028_3`
WHERE 1=1
GROUP BY `Category`
ORDER BY `Count` DESC;
","[('Family', 4, ""Reed Garrett, Son of Mac Taylor's late wife, Ellie Danville, Adopted daughter of Jo Danville, Russ Josephson, Ex-husband of Jo Danville, Claire Conrad Taylor, Late wife of Mac Taylor""), ('Other', 3, 'Rikki Sandoval, Neighbor of Danny Messer, Samantha Flack, Sister of Don Flack, Terrence Davis, Informant of Don Flack')]",m_1764878567913_6a217817_11240028-3,"1) Parse intent: classify rows into Family vs Other by presence of specified words in Relationship, then compute the count and a comma-separated list of Character names per class and sort by descending count. 2) Map schema: Relationship drives the CASE, Character is concatenated, and COUNT(*) is computed. 3) Draft question requesting Category (with the exact substring criteria), Count, and GROUP_CONCAT(Character, ', ') aliased 'Reed Garrett', grouped and ordered. 4) Validate that no extra details beyond the SQL are added.",reserved,13,N/A,merge_column,
"Give me a prioritized list (Both first, then Task-emphasis, then Relationship-emphasis) of instruments that measure task or relationship orientation, including Date, Founder, scale name and the introverted/extroverted example entries.","
WITH flagged AS (
  SELECT
    *,
    (
      (lower(`Introverted, Task-Oriented`) NOT LIKE '%not recogn%' AND lower(`Introverted, Task-Oriented`) NOT LIKE 'areas not%')
      OR (lower(`Extroverted, Task-Oriented`) NOT LIKE '%not recogn%' AND lower(`Extroverted, Task-Oriented`) NOT LIKE 'areas not%')
    ) AS task_present,
    (
      (lower(`Introverted, Relationship Oriented`) NOT LIKE '%not recogn%' AND lower(`Introverted, Relationship Oriented`) NOT LIKE 'areas not%')
      OR (lower(`Extroverted, Relationship-Oriented`) NOT LIKE '%not recogn%' AND lower(`Extroverted, Relationship-Oriented`) NOT LIKE 'areas not%')
    ) AS relationship_present
  FROM `table_m_1764878630562_32c4d26d_11256021_1`
)
SELECT
  `Date`,
  `Founder`,
  `People-task orientation scale`,
  `Introverted, Task-Oriented`,
  `Extroverted, Task-Oriented`,
  `Introverted, Relationship Oriented`,
  `Extroverted, Relationship-Oriented`,
  CASE
    WHEN task_present = 1 AND relationship_present = 1 THEN 'Both Task & Relationship'
    WHEN task_present = 1 THEN 'Task-emphasis'
    WHEN relationship_present = 1 THEN 'Relationship-emphasis'
    ELSE 'Unspecified'
  END AS `Orientation Classification`,
  TRIM(
    CASE WHEN task_present = 1 THEN
      COALESCE(NULLIF(`Introverted, Task-Oriented`, ''), '')
      || CASE WHEN `Introverted, Task-Oriented` IS NOT NULL AND `Extroverted, Task-Oriented` IS NOT NULL THEN ' / ' || `Extroverted, Task-Oriented` ELSE '' END
    ELSE NULL END
  ) AS `Task Examples`,
  TRIM(
    CASE WHEN relationship_present = 1 THEN
      COALESCE(NULLIF(`Introverted, Relationship Oriented`, ''), '')
      || CASE WHEN `Introverted, Relationship Oriented` IS NOT NULL AND `Extroverted, Relationship-Oriented` IS NOT NULL THEN ' / ' || `Extroverted, Relationship-Oriented` ELSE '' END
    ELSE NULL END
  ) AS `Relationship Examples`
FROM flagged
WHERE task_present = 1 OR relationship_present = 1
ORDER BY
  CASE WHEN task_present = 1 AND relationship_present = 1 THEN 0
       WHEN task_present = 1 THEN 1
       WHEN relationship_present = 1 THEN 2
       ELSE 3 END,
  `Date`;
","
WITH flagged AS (
  SELECT
    *,
    (
      (lower(col4) NOT LIKE '%not recogn%' AND lower(col4) NOT LIKE 'areas not%')
      OR (lower(col5) NOT LIKE '%not recogn%' AND lower(col5) NOT LIKE 'areas not%')
    ) AS task_present,
    (
      (lower(col7) NOT LIKE '%not recogn%' AND lower(col7) NOT LIKE 'areas not%')
      OR (lower(col6) NOT LIKE '%not recogn%' AND lower(col6) NOT LIKE 'areas not%')
    ) AS relationship_present
  FROM `table_m_1764878630562_32c4d26d_11256021_1`
)
SELECT
  col0,
  col1,
  col3,
  col4,
  col5,
  col7,
  col6,
  CASE
    WHEN task_present = 1 AND relationship_present = 1 THEN 'Both Task & Relationship'
    WHEN task_present = 1 THEN 'Task-emphasis'
    WHEN relationship_present = 1 THEN 'Relationship-emphasis'
    ELSE 'Unspecified'
  END AS `Orientation Classification`,
  TRIM(
    CASE WHEN task_present = 1 THEN
      COALESCE(NULLIF(col4, ''), '')
      || CASE WHEN col4 IS NOT NULL AND col5 IS NOT NULL THEN ' / ' || col5 ELSE '' END
    ELSE NULL END
  ) AS `Task Examples`,
  TRIM(
    CASE WHEN relationship_present = 1 THEN
      COALESCE(NULLIF(col7, ''), '')
      || CASE WHEN col7 IS NOT NULL AND col6 IS NOT NULL THEN ' / ' || col6 ELSE '' END
    ELSE NULL END
  ) AS `Relationship Examples`
FROM flagged
WHERE task_present = 1 OR relationship_present = 1
ORDER BY
  CASE WHEN task_present = 1 AND relationship_present = 1 THEN 0
       WHEN task_present = 1 THEN 1
       WHEN relationship_present = 1 THEN 2
       ELSE 3 END,
  col0;
","[('1958', 'MBTI codes', 'Informative/Directive (mapped by David Keirsey )', 'ISTJ, INTJ, ISTP, INFJ', 'ESTJ, ENTJ, ESTP, ENFJ', 'ISFP, INFP, ISFJ, INTP', 'ESFP, ENFP, ESFJ, ENTP', 'Both Task & Relationship', 'ISTJ, INTJ, ISTP, INFJ / ESTJ, ENTJ, ESTP, ENFJ', 'ISFP, INFP, ISFJ, INTP / ESFP, ENFP, ESFJ, ENTP'), ('1964', 'Blake-Mouton Managerial Grid Model', 'Areas not distinguished', 'Impoverished', 'Produce or Perish', 'Country Club', 'Team Type', 'Both Task & Relationship', 'Impoverished / Produce or Perish', 'Country Club / Team Type'), ('1973', 'Jay Hall Conflict Management', 'Concern for relationships', 'Leave-lose/win', 'Win/lose', 'Yield-lose/win', 'Synergistic; Win/win', 'Both Task & Relationship', 'Leave-lose/win / Win/lose', 'Yield-lose/win / Synergistic; Win/win'), ('1974', 'Thomas-Kilmann Conflict Modes', 'Cooperativeness', 'Avoiding', 'Competing', 'Accommodating', 'Collaborating', 'Both Task & Relationship', 'Avoiding / Competing', 'Accommodating / Collaborating'), ('c. 190', ""Galen 's four temperaments"", 'response-sustain (short, long)', 'melancholic', 'choleric', 'phlegmatic', 'sanguine', 'Both Task & Relationship', 'melancholic / choleric', 'phlegmatic / sanguine'), ('c. 1900', ""Alfred Adler 's four Styles of Life"", '""social interest""', 'Avoiding', 'Ruling or Dominant', 'Getting or Leaning', 'Socially Useful', 'Both Task & Relationship', 'Avoiding / Ruling or Dominant', 'Getting or Leaning / Socially Useful'), ('c. 1928', 'William Marston and John G. Geier DiSC assessment', 'Open/ Controlled', 'Conscien- tiousness', 'Dominance', 'Steadiness', 'Influence', 'Both Task & Relationship', 'Conscien- tiousness / Dominance', 'Steadiness / Influence'), ('c. 1947', ""Eric Fromm 's four Types of Character"", 'socialization', 'Hoarding', 'Exploitative', 'Receptive', 'Marketing', 'Both Task & Relationship', 'Hoarding / Exploitative', 'Receptive / Marketing'), ('c. 1958', 'William Schutz, FIRO -B', 'Wanted', 'See FIRO article for score names.', 'See FIRO article for score names.', 'See FIRO article for score names.', 'See FIRO article for score names.', 'Both Task & Relationship', 'See FIRO article for score names. / See FIRO article for score names.', 'See FIRO article for score names. / See FIRO article for score names.'), ('c. 1960s', ""Stuart Atkins LIFO's four Orientations To Life"", 'Directing vs. Inspiring', 'Conserving-Holding', 'Controlling-Taking', 'Supporting-Giving', 'Adapting-Dealing', 'Both Task & Relationship', 'Conserving-Holding / Controlling-Taking', 'Supporting-Giving / Adapting-Dealing'), ('c. 1960s', 'David Merrill, "" Social Styles ""', 'Responsiveness (Control-Emote)', 'Analytical', 'Driving', 'Amiable', 'Expressive', 'Both Task & Relationship', 'Analytical / Driving', 'Amiable / Expressive'), ('c. 1966', 'Temperament by LaHaye', 'Areas not distinguished', 'Melancholy', 'Choleric', 'Phlegmatic', 'Sanguine', 'Both Task & Relationship', 'Melancholy / Choleric', 'Phlegmatic / Sanguine'), ('c. 1984', 'The Arno Profile System( Five Temperaments )', 'Responsive', 'Melancholy', 'Choleric', 'Supine', 'Sanguine', 'Both Task & Relationship', 'Melancholy / Choleric', 'Supine / Sanguine'), ('c. 1995', 'Worley Identification Discovery Profile', 'Social, Leadership, Relationship', 'Melancholy', 'Choleric', 'Phlegmatic', 'Sanguine', 'Both Task & Relationship', 'Melancholy / Choleric', 'Phlegmatic / Sanguine'), ('c. 1996', 'Tony Alessandra Personality Styles', 'Open/Guarded', 'Thinker', 'Director', 'Relater', 'Socializer', 'Both Task & Relationship', 'Thinker / Director', 'Relater / Socializer'), ('c. 1998', 'Hartman Personality Profile', 'Not recognized', 'Blue', 'Red', 'White', 'Yellow', 'Both Task & Relationship', 'Blue / Red', 'White / Yellow'), ('c. 400 BC', ""Hippocrates 's four humours"", 'Areas not recognized', 'black bile', 'yellow bile', 'phlegm', 'blood', 'Both Task & Relationship', 'black bile / yellow bile', 'phlegm / blood'), ('c. 450 BC', 'Classical elements', 'Areas not recognized', 'earth', 'fire', 'water', 'air', 'Both Task & Relationship', 'earth / fire', 'water / air')]",m_1764878630562_32c4d26d_11256021-1,"I often want results ordered by practical relevance rather than raw SQL terms, so I'd ask for prioritized results. The query orders instruments with Both first, then Task-emphasis, then Relationship-emphasis, and by Date within those groups while returning example text. The schema supplies date, founder, scale label and the four example columns used to build combined example strings. Draft question: request a prioritized list (Both → Task → Relationship) of instruments that measure task or relationship orientation including their intro/extro examples. This mirrors the query which filters, classifies, composes examples, and sorts in that priority.",persona,"```json
{
  ""short_description"": ""Learning & Development (L&D) Manager at a mid-sized company who selects personality frameworks for leadership development and team-design workshops. Uses the database to compare instruments, map comparable scales across models, and choose assessments that emphasize task vs. relationship orientation."",
  ""goals"": [
    ""Identify personality instruments that explicitly measure task-orientation vs relationship-orientation for leadership programs."",
    ""Create a cr Goals:  Example Queries: ",N/A,add_column,
"For up to 10 Timeslots with more than one episode and an Average Rating less than 1.9, what are the Timeslot, the Average Rating (AVG(Rating)), the Episode Count (COUNT(No.)), and the High-Low Gap computed as MAX(Rating) minus AVG(Rating), ordered by Average Rating ascending?",unanswerable,unanswerable,,m_1764878647616_37cb0755_11274401-2,"1) SQL intent: group by Timeslot, compute AVG(Rating), COUNT(No.), and MAX(Rating)-AVG(Rating), keep groups with COUNT>1 and AVG<1.9, order by AVG ascending, limit 10. 2) Map the aggregates to the table's Timeslot, Rating and No. columns and name the High-Low Gap calculation. 3) Write a question requesting Timeslot, Average Rating (AVG(Rating)), Episode Count (COUNT(No.)), and High-Low Gap (MAX(Rating)-AVG(Rating)) under the given filters and ordering/limit. 4) Verify the question includes every column and calculation from the query and the exact HAVING/ORDER/LIMIT constraints.",reserved,12,N/A,merge_column,
"For rounds > 0 and <= 99, list the top five Winning Driver by number of Wins and for each Driver report the Wins count, the Pole to Win count (how many times Pole Position = Winning Driver), the Fastest to Win count (how many times Fastest Lap = Winning Driver), and a comma-separated list of Grand Prix Circuits they won?",unanswerable,unanswerable,,m_1764878710328_e13f3677_1137704-2,"1) The intent is to summarize winners per driver with counts and conditional sums, concatenating Grand Prix names, limited to the top 5 by Wins for rounds >0 and <=99. 2) Map SQL expressions to phrasing: COUNT(*) as Wins, SUM(condition) as Pole to Win/Fastest to Win, GROUP_CONCAT(Grand Prix) as Circuits. 3) Draft a concise question asking for those fields for the top five drivers within the round range. 4) Validate inclusion of all columns, conditional sums, round filter, grouping by driver, ordering and limit.",reserved,9,N/A,merge_column,
"Can you provide the `English Name`, `Japanese orthography`, `Pronouciation`, `abbreviation`, `Provider(IAI)`, and `Foundation` for the following entries: `National College of Nursing` (`国立看護大学校`, `Kokuritsu Kango Daigakkō`, `NCN`, `NCGM ( ja )`, 2001); `National Fisheries University` (`水産大学校`, `Suisan Daigakkō`, `NFU Sui-dai-ko(水大校)`, `National Fisheries University`, 1885); `Polytechnic University (Japan)` (`職業能力開発総合大学校`, `Shokugyo Noryoku Kaihatsu Daigakkō`, `PU`, `EHRDOJ ( ja )`, 1961); `Marine Technical College` (`海技大学校`, `Kaigi Daigakkō`, `MTC`, `Marine Technical Education Agency ( ja )`, 2001); `Civil Aviation College` (`航空大学校`, `Kōkū Daigakkō`, `CAC`, `Civil Aviation College`, 1964); `National Farmers Academy` (`農業者大学校`, `Nōgyōsha Daigakkō`, `NFA`, `NARO ( ja )`, 1968); `Labour College` (`労働大学校`, `Rōdō Daigakkō`, `LC`, `JILPT ( ja )`, 2003) — and include the insight that Pre-1970 institutions are `National Fisheries University` (1885), `Polytechnic University (Japan)` (1961), `Civil Aviation College` (1964), `National Farmers Academy` (1968), Post-2000 institutions are `National College of Nursing` (2001), `Marine Technical College` (2001), `Labour College` (2003), with recommended actions to prioritize legacy preservation for pre-1970 and technology partnerships for post-2000 as an Actionable Insight?","
SELECT '`english_name`, `japanese_orthography`, `Pronouciation`, `abbreviation`, `provider_iap`, `Foundation` — Entries: `National College of Nursing` (`国立看護大学校`, `Kokuritsu Kango Daigakkō`, `NCN`, `NCGM ( ja )`, 2001); `National Fisheries University` (`水産大学校`, `Suisan Daigakkō`, `NFU Sui-dai-ko(水大校)`, `National Fisheries University`, 1885); `Polytechnic University (Japan)` (`職業能力開発総合大学校`, `Shokugyo Noryoku Kaihatsu Daigakkō`, `PU`, `EHRDOJ ( ja )`, 1961); `Marine Technical College` (`海技大学校`, `Kaigi Daigakkō`, `MTC`, `Marine Technical Education Agency ( ja )`, 2001); `Civil Aviation College` (`航空大学校`, `Kōkū Daigakkō`, `CAC`, `Civil Aviation College`, 1964); `National Farmers Academy` (`農業者大学校`, `Nōgyōsha Daigakkō`, `NFA`, `NARO ( ja )`, 1968); `Labour College` (`労働大学校`, `Rōdō Daigakkō`, `LC`, `JILPT ( ja )`, 2003) — Insight: Pre-1970 institutions: `National Fisheries University` (1885), `Polytechnic University (Japan)` (1961), `Civil Aviation College` (1964), `National Farmers Academy` (1968). Post-2000 institutions: `National College of Nursing` (2001), `Marine Technical College` (2001), `Labour College` (2003). Recommended actions: prioritize legacy preservation for pre-1970 and technology partnerships for post-2000' `Actionable Insight` WHERE 1=1 AND 1=1 LIMIT 1;
","
SELECT 'col0, col1, col2, col3, col4, col5 — Entries: `National College of Nursing` (`国立看護大学校`, `Kokuritsu Kango Daigakkō`, `NCN`, `NCGM ( ja )`, 2001); `National Fisheries University` (`水産大学校`, `Suisan Daigakkō`, `NFU Sui-dai-ko(水大校)`, `National Fisheries University`, 1885); `Polytechnic University (Japan)` (`職業能力開発総合大学校`, `Shokugyo Noryoku Kaihatsu Daigakkō`, `PU`, `EHRDOJ ( ja )`, 1961); `Marine Technical College` (`海技大学校`, `Kaigi Daigakkō`, `MTC`, `Marine Technical Education Agency ( ja )`, 2001); `Civil Aviation College` (`航空大学校`, `Kōkū Daigakkō`, `CAC`, `Civil Aviation College`, 1964); `National Farmers Academy` (`農業者大学校`, `Nōgyōsha Daigakkō`, `NFA`, `NARO ( ja )`, 1968); `Labour College` (`労働大学校`, `Rōdō Daigakkō`, `LC`, `JILPT ( ja )`, 2003) — Insight: Pre-1970 institutions: `National Fisheries University` (1885), `Polytechnic University (Japan)` (1961), `Civil Aviation College` (1964), `National Farmers Academy` (1968). Post-2000 institutions: `National College of Nursing` (2001), `Marine Technical College` (2001), `Labour College` (2003). Recommended actions: prioritize legacy preservation for pre-1970 and technology partnerships for post-2000' `Actionable Insight` WHERE 1=1 AND 1=1 LIMIT 1;
","[('col0, col1, col2, col3, col4, col5 — Entries: `National College of Nursing` (`国立看護大学校`, `Kokuritsu Kango Daigakkō`, `NCN`, `NCGM ( ja )`, 2001); `National Fisheries University` (`水産大学校`, `Suisan Daigakkō`, `NFU Sui-dai-ko(水大校)`, `National Fisheries University`, 1885); `Polytechnic University (Japan)` (`職業能力開発総合大学校`, `Shokugyo Noryoku Kaihatsu Daigakkō`, `PU`, `EHRDOJ ( ja )`, 1961); `Marine Technical College` (`海技大学校`, `Kaigi Daigakkō`, `MTC`, `Marine Technical Education Agency ( ja )`, 2001); `Civil Aviation College` (`航空大学校`, `Kōkū Daigakkō`, `CAC`, `Civil Aviation College`, 1964); `National Farmers Academy` (`農業者大学校`, `Nōgyōsha Daigakkō`, `NFA`, `NARO ( ja )`, 1968); `Labour College` (`労働大学校`, `Rōdō Daigakkō`, `LC`, `JILPT ( ja )`, 2003) — Insight: Pre-1970 institutions: `National Fisheries University` (1885), `Polytechnic University (Japan)` (1961), `Civil Aviation College` (1964), `National Farmers Academy` (1968). Post-2000 institutions: `National College of Nursing` (2001), `Marine Technical College` (2001), `Labour College` (2003). Recommended actions: prioritize legacy preservation for pre-1970 and technology partnerships for post-2000',)]",m_1764878743216_3416a130_11390711-4,"1) Parse intent: produce the full table entries across all specified columns and explicitly call out the insight and recommended actions. 2) Map schema: align each row's English name, Japanese orthography, pronunciation, abbreviation, provider, and foundation year. 3) Draft: formulate a question requesting the listed entries and the categorization into pre-1970 and post-2000 with recommended actions. 4) Validate: confirm inclusion of all seven entries, both insight groups, and the precise recommended actions.",reserved,4,N/A,rename_column,
"For each Country where Total > 0 and (Marathon (mens) + Marathon (womens)) >= 1, list Country and Total plus Marathon total (Marathon (mens) + Marathon (womens)), Half Marathon total (Half Marathon (mens) + Half Marathon (womens)), Marathon share % computed as ROUND(((Marathon (mens) + Marathon (womens)) / Total) * 100, 2), Mens_to_Womens_Marathon_ratio computed as ROUND((Marathon (mens) * 1.0) / NULLIF(Marathon (womens), 0), 2) with null if Marathon (womens) is zero, and an Actionable Insight that returns '`' || Country || '` flagged: prioritize marathon outreach' if Marathon total/Total > 0.6, else '`' || Country || '` flagged: invest in half-marathon programs' if Half Marathon total/Total > 0.4, otherwise '`' || Country || '` flagged: diversify events and training'?","
SELECT `country`, `total_points`, (`marathon_men`+`Marathon (womens)`) `Marathon total_points`, (`Half Marathon (mens)`+`Half Marathon (womens)`) `Half Marathon total_points`, ROUND(((`marathon_men`+`Marathon (womens)`)/`total_points`)*100,2) `Marathon share %`, ROUND((`marathon_men`*1.0)/NULLIF(`Marathon (womens)`,0),2) `Mens_to_Womens_Marathon_ratio`, IIF(((`marathon_men`+`Marathon (womens)`)/`total_points`)>0.6, ('`' || `country` || '` flagged: prioritize marathon outreach'), IIF(((`Half Marathon (mens)`+`Half Marathon (womens)`)/`total_points`)>0.4, ('`' || `country` || '` flagged: invest in half-marathon programs'), ('`' || `country` || '` flagged: diversify events and training'))) `Actionable Insight` FROM `table_m_1764878749243_38115c91_11391954_3` WHERE `total_points`>0 AND (`marathon_men`+`Marathon (womens)`)>=1;
","
SELECT col0, col1, (col2+col3) `Marathon total_points`, (col4+col5) `Half Marathon total_points`, ROUND(((col2+col3)/col1)*100,2) `Marathon share %`, ROUND((col2*1.0)/NULLIF(col3,0),2) `Mens_to_Womens_Marathon_ratio`, IIF(((col2+col3)/col1)>0.6, ('`' || col0 || '` flagged: prioritize marathon outreach'), IIF(((col4+col5)/col1)>0.4, ('`' || col0 || '` flagged: invest in half-marathon programs'), ('`' || col0 || '` flagged: diversify events and training'))) `Actionable Insight` FROM `table_m_1764878749243_38115c91_11391954_3` WHERE col1>0 AND (col2+col3)>=1;
","[('Latvia', 27.0, 18.0, 9.0, 66.67, 1.25, '`Latvia` flagged: prioritize marathon outreach'), ('Kenya', 7.0, 5.0, 2.0, 71.43, None, '`Kenya` flagged: prioritize marathon outreach'), ('Lithuania', 7.0, 6.0, 1.0, 85.71, 1.0, '`Lithuania` flagged: prioritize marathon outreach'), ('Belarus', 6.0, 6.0, 0.0, 100.0, 0.5, '`Belarus` flagged: prioritize marathon outreach'), ('Russia', 5.0, 3.0, 2.0, 60.0, 0.5, '`Russia` flagged: diversify events and training'), ('Estonia', 4.0, 3.0, 1.0, 75.0, 0.0, '`Estonia` flagged: prioritize marathon outreach'), ('Ethiopia', 2.0, 2.0, 0.0, 100.0, 0.0, '`Ethiopia` flagged: prioritize marathon outreach'), ('Morocco', 1.0, 1.0, 0.0, 100.0, None, '`Morocco` flagged: prioritize marathon outreach'), ('Kazakhstan', 1.0, 1.0, 0.0, 100.0, None, '`Kazakhstan` flagged: prioritize marathon outreach'), ('Moldova', 1.0, 1.0, 0.0, 100.0, 0.0, '`Moldova` flagged: prioritize marathon outreach')]",m_1764878749243_38115c91_11391954-3,"Parse intent: filter countries by Total>0 and at least one marathon win, then calculate totals, percentage share, mens-to-womens ratio, and a conditional message. Map schema: use the six table columns to compute Marathon total, Half Marathon total, ROUNDed Marathon share %, ROUNDed mens/womens marathon ratio with NULLIF, and an IIF-based Actionable Insight containing backticked country names and three possible phrases. Draft question: request all these outputs exactly as computed and rounded to two decimals, including null behavior and threshold conditions. Validate: question explicitly mentions every column, calculation, rounding, the two thresholds (>0.6 and >0.4), and the WHERE criteria.",reserved,4,N/A,rename_column,
"Considering only rows with Crowd > 25000 and Year in 1979,1980,1981,1982,1983,1984,1985,1986, for each Winner that appears in a different Year as well (i.e., there exists another record with the same Winner and a Year that is not equal), what are the Winner, Titles (COUNT(*)), Avg Crowd (AVG(Crowd)), and Max Margin (MAX(Margin)), ordered by Avg Crowd and limited to 5?","
SELECT t.`Winners` AS `Winner`, COUNT(*) `Titles`, AVG(t.`Crowd`) `Avg Crowd`, MAX(t.`Margin`) `Max Margin`
FROM `table_m_1764878771519_7d74c6bd_1139835_3` t
JOIN `table_m_1764878771519_7d74c6bd_1139835_3` v ON t.`Winners` = v.`Winners`
WHERE ((t.`Year` - v.`Year`) != 0) AND (t.`Crowd` > 25000) * (t.`Year` IN (1979,1980,1981,1982,1983,1984,1985,1986))
GROUP BY t.`Winners`
ORDER BY `Avg Crowd`
LIMIT 5;
","
SELECT t.col1 AS `Winner`, COUNT(*) `Titles`, AVG(t.col4) `Avg Crowd`, MAX(t.col5) `Max Margin`
FROM `table_m_1764878771519_7d74c6bd_1139835_3` t
JOIN `table_m_1764878771519_7d74c6bd_1139835_3` v ON t.col1 = v.col1
WHERE ((t.col0 - v.col0) != 0) AND (t.col4 > 25000) * (t.col0 IN (1979,1980,1981,1982,1983,1984,1985,1986))
GROUP BY t.col1
ORDER BY `Avg Crowd`
LIMIT 5;
","[('Essendon', 2, 36546.5, 51.0)]",m_1764878771519_7d74c6bd_1139835-3,"Parse: The SQL computes per-Winner aggregates (count, average crowd, max margin) but only for certain years and crowds and requires another record with same Winner in a different year. Map: Use the table's Winners, Crowd, Margin, Year columns and the filter Year IN list and Crowd > 25000. Draft: Formulate a question requesting Winner, COUNT(*) as Titles, AVG(Crowd) as Avg Crowd, and MAX(Margin) as Max Margin with those filters, ordering, and limit. Validate: Confirm inclusion of the different-year existence condition, exact aggregates, year list, crowd threshold, order by Avg Crowd, and top 5 constraint.",reserved,12,N/A,split_column,
"For each Pole Position (Driver) value that is not empty, what are the Driver, the number of pole positions (Pole_Count), the number of those poles that became race wins (Wins_From_Pole = SUM(Race Winner = Pole Position)), the conversion rate percentage rounded to two decimal places (Conversion_Rate_% = ROUND(100.0 * SUM(Race Winner = Pole Position) / COUNT(*), 2)), and the count of fastest laps set from pole (Fastest_From_Pole = SUM(Fastest Lap = Pole Position)), showing the top 10 drivers by Conversion_Rate_% in descending order?","
SELECT `Pole Position` AS `Driver`, COUNT(*) `Pole_Count`, SUM(`Race Winner` = `Pole Position`) `Wins_From_Pole`, ROUND(100.0 * SUM(`Race Winner` = `Pole Position`) / COUNT(*), 2) `Conversion_Rate_%`, SUM(`Fastest Lap` = `Pole Position`) `Fastest_From_Pole`
FROM `table_m_1764878776830_c437e0c8_1140067_2`
WHERE `Pole Position` != ''
GROUP BY `Pole Position`
ORDER BY `Conversion_Rate_%` DESC
LIMIT 10;
","
SELECT col4 AS `Driver`, COUNT(*) `Pole_Count`, SUM(col6 = col4) `Wins_From_Pole`, ROUND(100.0 * SUM(col6 = col4) / COUNT(*), 2) `Conversion_Rate_%`, SUM(col5 = col4) `Fastest_From_Pole`
FROM `table_m_1764878776830_c437e0c8_1140067_2`
WHERE col4 != ''
GROUP BY col4
ORDER BY `Conversion_Rate_%` DESC
LIMIT 10;
","[('Nigel Mansell', 1, 1, 100.0, 0), ('Alain Prost', 1, 1, 100.0, 1), ('Ayrton Senna', 8, 2, 25.0, 0), ('Teo Fabi', 2, 0, 0.0, 1), ('Nelson Piquet', 2, 0, 0.0, 0), ('Keke Rosberg', 1, 0, 0.0, 0)]",m_1764878776830_c437e0c8_1140067-2,"1) Intent: compute per-pole-driver metrics including counts and conditional sums, then sort by conversion percentage; 2) map fields: Pole Position -> Driver, Race Winner, Fastest Lap; 3) draft a question requesting Driver, Pole_Count, Wins_From_Pole, Conversion_Rate_% (rounded to two decimals), and Fastest_From_Pole for non-empty Pole Positions; 4) ensure it specifies ordering by Conversion_Rate_% descending and limiting to 10.",reserved,9,N/A,add_column,
"For rounds where Rnd <= 16, for each Constructor with at least one race where Pole Position equals Race Winner, what are Constructor, Total Races (COUNT(*)), Pole_to_win (SUM(Pole Position = Race Winner)), Pole_equals_fastest (SUM(Pole Position = Fastest Lap)), and Win_from_pole_pct calculated as (SUM(Pole Position = Race Winner) * 100.0 / COUNT(*)), returning only 3 results?","
SELECT `Constructor`, COUNT(*) `Total Races`, SUM((`Pole Position` = `Race Winner`)) `Pole_to_win`, SUM((`Pole Position` = `Fastest Lap`)) `Pole_equals_fastest`, (SUM((`Pole Position` = `Race Winner`)) * 100.0 / COUNT(*)) `Win_from_pole_pct` FROM `table_m_1764878812737_3f66c2ad_1140083_2` WHERE `Rnd` <= 16 GROUP BY `Constructor` HAVING SUM((`Pole Position` = `Race Winner`)) > 0 LIMIT 3;
","
SELECT col7, COUNT(*) `Total Races`, SUM((col4 = col6)) `Pole_to_win`, SUM((col4 = col5)) `Pole_equals_fastest`, (SUM((col4 = col6)) * 100.0 / COUNT(*)) `Win_from_pole_pct` FROM `table_m_1764878812737_3f66c2ad_1140083_2` WHERE col0 <= 16 GROUP BY col7 HAVING SUM((col4 = col6)) > 0 LIMIT 3;
","[('Lotus - Ford', 5, 2, 2, 40.0), ('McLaren - Ford', 2, 2, 1, 100.0)]",m_1764878812737_3f66c2ad_1140083-2,"1) The intent is to compute per-constructor aggregates for rounds up to 16: total races, counts where pole equals winner, counts where pole equals fastest lap, and percent wins from pole, then filter to constructors with at least one pole-to-win and restrict to 3 rows. 2) The table columns correspond to Rnd, Pole Position, Fastest Lap, Race Winner and Constructor. 3) Draft a question that explicitly requests Constructor, COUNT(*) as Total Races, SUM(Pole Position = Race Winner) as Pole_to_win, SUM(Pole Position = Fastest Lap) as Pole_equals_fastest, and Win_from_pole_pct = (SUM(Pole Position = Race Winner) * 100.0 / COUNT(*)) for Rnd <= 16, only for constructors with Pole_to_win > 0, limited to 3. 4) Confirm the question contains all calculations, the WHERE Rnd <= 16 clause, the HAVING condition, GROUP BY implication and the LIMIT 3.",reserved,7,N/A,add_column,
"Which five Directors have the highest average U.S. viewers (millions) — where U.S. viewers are treated as real — and for each Director show the count of episodes (Episodes), the average viewers rounded to two decimal places (AvgViewers), and the minimum viewers, if you only consider episodes with U.S. viewers (millions) between 9 and 16 and only include Directors with more than 1 episode and a minimum U.S. viewers (millions) greater than 9, ordering the results by AvgViewers descending and limiting to 5?","
SELECT `Director`, COUNT(*) AS `Episodes`, ROUND(AVG(CAST(`U.S. viewers (millions)` AS REAL)),2) AS `AvgViewers`, MIN(CAST(`U.S. viewers (millions)` AS REAL))
FROM `table_m_1764878844147_2bf93a3c_11404452_1`
WHERE CAST(`U.S. viewers (millions)` AS REAL) BETWEEN 9 AND 16
GROUP BY `Director`
HAVING COUNT(*) > 1 AND MIN(CAST(`U.S. viewers (millions)` AS REAL)) > 9
ORDER BY `AvgViewers` DESC
LIMIT 5;
","
SELECT col3, COUNT(*) AS `Episodes`, ROUND(AVG(CAST(col4 AS REAL)),2) AS `AvgViewers`, MIN(CAST(col4 AS REAL))
FROM `table_m_1764878844147_2bf93a3c_11404452_1`
WHERE CAST(col4 AS REAL) BETWEEN 9 AND 16
GROUP BY col3
HAVING COUNT(*) > 1 AND MIN(CAST(col4 AS REAL)) > 9
ORDER BY `AvgViewers` DESC
LIMIT 5;
","[('James Hayman', 5, 13.39, 12.81), ('Lev L. Spiro', 2, 11.95, 9.63), ('Tricia Brock', 2, 11.79, 10.41)]",m_1764878844147_2bf93a3c_11404452-1,"1) The SQL selects Director, COUNT, AVG (rounded to 2 decimals of the real-cast viewer values), and MIN, with a WHERE between 9 and 16, GROUP BY Director, HAVING COUNT>1 and MIN>9, ORDER BY average descending, LIMIT 5. 2) 'U.S. viewers (millions)' must be treated as real numbers for AVG and MIN; COUNT(*) produces Episodes. 3) Formulate a question asking for the top 5 Directors by descending average viewers including Episodes, AvgViewers rounded to two decimals, and MIN, with the BETWEEN and HAVING constraints. 4) Confirm the question explicitly mentions all calculations and filters.",reserved,19,N/A,add_column,
"Prepare a director‑by‑director briefing showing episodes directed, average and top U.S. viewers (with top episode title), counts and lists of collaborative episodes and episodes with three or more writers (with series numbers), and append the overall top five episodes by U.S. viewers?","
WITH `cleaned` AS (
  SELECT
    `No. in series`,
    `No. in season`,
    `Title`,
    `Directed by`,
    `Written by`,
    `Original air date`,
    `U.S. viewers (millions)`,
    CAST(REPLACE(`U.S. viewers (millions)`, ',', '') AS REAL) AS `viewers_num`,
    (LENGTH(`Written by`) - LENGTH(REPLACE(`Written by`, '&', ''))) AS `ampersand_count`,
    CASE WHEN (LENGTH(`Written by`) - LENGTH(REPLACE(`Written by`, '&', ''))) > 0 THEN 1 ELSE 0 END AS `is_collab`,
    1 + (LENGTH(`Written by`) - LENGTH(REPLACE(`Written by`, '&', ''))) AS `collaborator_count`
  FROM `table_m_1764878849258_2d150e71_11411026_2`
)
SELECT
  `Directed by`,
  COUNT(*) AS `episodes_directed`,
  ROUND(AVG(`viewers_num`), 2) AS `avg_viewers`,
  MAX(`viewers_num`) AS `top_episode_viewers`,
  (SELECT `Title` FROM `cleaned` c2 WHERE c2.`Directed by` = c1.`Directed by` ORDER BY c2.`viewers_num` DESC LIMIT 1) AS `top_episode_title`,
  SUM(`is_collab`) AS `collab_episodes_count`,
  SUM(CASE WHEN `ampersand_count` >= 2 THEN 1 ELSE 0 END) AS `episodes_with_3plus_writers`,
  group_concat(CASE WHEN `is_collab` = 1 THEN `Title` || ' [' || `Written by` || ']' END, '; ') AS `collab_titles_and_writers`,
  group_concat(CASE WHEN `ampersand_count` >= 2 THEN `Title` || ' (' || `No. in series` || ')' END, '; ') AS `notable_multiwriter_titles`,
  (
    SELECT group_concat(`Title` || ' — ' || `U.S. viewers (millions)`, '; ')
    FROM `cleaned`
    ORDER BY `viewers_num` DESC
    LIMIT 5
  ) AS `Top 5 Marquee Episodes (Title — U.S. viewers (millions))`
FROM `cleaned` c1
GROUP BY `Directed by`
ORDER BY `avg_viewers` DESC, `episodes_directed` DESC;
","
WITH `cleaned` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    CAST(REPLACE(col6, ',', '') AS REAL) AS `viewers_num`,
    (LENGTH(col4) - LENGTH(REPLACE(col4, '&', ''))) AS `ampersand_count`,
    CASE WHEN (LENGTH(col4) - LENGTH(REPLACE(col4, '&', ''))) > 0 THEN 1 ELSE 0 END AS `is_collab`,
    1 + (LENGTH(col4) - LENGTH(REPLACE(col4, '&', ''))) AS `collaborator_count`
  FROM `table_m_1764878849258_2d150e71_11411026_2`
)
SELECT
  col3,
  COUNT(*) AS `episodes_directed`,
  ROUND(AVG(`viewers_num`), 2) AS `avg_viewers`,
  MAX(`viewers_num`) AS `top_episode_viewers`,
  (SELECT col2 FROM `cleaned` c2 WHERE c2.col3 = c1.col3 ORDER BY c2.`viewers_num` DESC LIMIT 1) AS `top_episode_title`,
  SUM(`is_collab`) AS `collab_episodes_count`,
  SUM(CASE WHEN `ampersand_count` >= 2 THEN 1 ELSE 0 END) AS `episodes_with_3plus_writers`,
  group_concat(CASE WHEN `is_collab` = 1 THEN col2 || ' [' || col4 || ']' END, '; ') AS `collab_titles_and_writers`,
  group_concat(CASE WHEN `ampersand_count` >= 2 THEN col2 || ' (' || col0 || ')' END, '; ') AS `notable_multiwriter_titles`,
  (
    SELECT group_concat(col2 || ' — ' || col6, '; ')
    FROM `cleaned`
    ORDER BY `viewers_num` DESC
    LIMIT 5
  ) AS `Top 5 Marquee Episodes (Title — U.S. viewers (millions))`
FROM `cleaned` c1
GROUP BY col3
ORDER BY `avg_viewers` DESC, `episodes_directed` DESC;
","[('Eagle Egilsson', 1, 19.86, 19.86, '""Driven""', 0, 0, None, None, '""From the Grave"" — 19.21; ""Blood in the Water"" — 17.38; ""Prey"" — 18.67; ""48 Hours to Life"" — 18.49; ""Three-Way"" — 17.91; ""Under Suspicion"" — 19.94; ""Felony Flight"" — 18.39; ""Nailed"" — 19.36; ""Urban Hellraisers"" — 19.36; ""Shattered"" — 19.77; ""Payback"" — 20.33; ""The Score"" — 20.15; ""Silencer"" — 19.69; ""Fade Out"" — 20.43; ""Skeletons"" — 18.68; ""Deviant"" — 18.43; ""Collision"" — 18.61; ""Double Jeopardy"" — 19.01; ""Driven"" — 19.86; ""Free Fall"" — 17.16; ""Dead Air"" — 18.74; ""Open Water"" — 19.31; ""Shock"" (Part 1) — 19.96'), ('Ernest R. Dickerson', 1, 19.69, 19.69, '""Silencer""', 0, 0, None, None, '""From the Grave"" — 19.21; ""Blood in the Water"" — 17.38; ""Prey"" — 18.67; ""48 Hours to Life"" — 18.49; ""Three-Way"" — 17.91; ""Under Suspicion"" — 19.94; ""Felony Flight"" — 18.39; ""Nailed"" — 19.36; ""Urban Hellraisers"" — 19.36; ""Shattered"" — 19.77; ""Payback"" — 20.33; ""The Score"" — 20.15; ""Silencer"" — 19.69; ""Fade Out"" — 20.43; ""Skeletons"" — 18.68; ""Deviant"" — 18.43; ""Collision"" — 18.61; ""Double Jeopardy"" — 19.01; ""Driven"" — 19.86; ""Free Fall"" — 17.16; ""Dead Air"" — 18.74; ""Open Water"" — 19.31; ""Shock"" (Part 1) — 19.96'), ('Sam Hill', 4, 19.41, 20.33, '""Payback""', 2, 1, '""Under Suspicion"" [Sunil Nayar & Barry O\'Brien]; ""Payback"" [Marc Dube & Ildy Modrovich & Marc Guggenheim]', '""Payback"" (83.0)', '""From the Grave"" — 19.21; ""Blood in the Water"" — 17.38; ""Prey"" — 18.67; ""48 Hours to Life"" — 18.49; ""Three-Way"" — 17.91; ""Under Suspicion"" — 19.94; ""Felony Flight"" — 18.39; ""Nailed"" — 19.36; ""Urban Hellraisers"" — 19.36; ""Shattered"" — 19.77; ""Payback"" — 20.33; ""The Score"" — 20.15; ""Silencer"" — 19.69; ""Fade Out"" — 20.43; ""Skeletons"" — 18.68; ""Deviant"" — 18.43; ""Collision"" — 18.61; ""Double Jeopardy"" — 19.01; ""Driven"" — 19.86; ""Free Fall"" — 17.16; ""Dead Air"" — 18.74; ""Open Water"" — 19.31; ""Shock"" (Part 1) — 19.96'), ('Matt Earl Beesley', 1, 19.36, 19.36, '""Urban Hellraisers""', 1, 0, '""Urban Hellraisers"" [Dean Widenmann & Marc Guggenheim]', None, '""From the Grave"" — 19.21; ""Blood in the Water"" — 17.38; ""Prey"" — 18.67; ""48 Hours to Life"" — 18.49; ""Three-Way"" — 17.91; ""Under Suspicion"" — 19.94; ""Felony Flight"" — 18.39; ""Nailed"" — 19.36; ""Urban Hellraisers"" — 19.36; ""Shattered"" — 19.77; ""Payback"" — 20.33; ""The Score"" — 20.15; ""Silencer"" — 19.69; ""Fade Out"" — 20.43; ""Skeletons"" — 18.68; ""Deviant"" — 18.43; ""Collision"" — 18.61; ""Double Jeopardy"" — 19.01; ""Driven"" — 19.86; ""Free Fall"" — 17.16; ""Dead Air"" — 18.74; ""Open Water"" — 19.31; ""Shock"" (Part 1) — 19.96'), ('Karen Gaviola', 4, 19.3, 19.96, '""Shock"" (Part 1)', 4, 0, '""From the Grave"" [Ann Donahue & Elizabeth Devine]; ""Nailed"" [Corey Miller & Barry O\'Brien]; ""Skeletons"" [John Haynes & Elizabeth Devine]; ""Shock"" (Part 1) [Brian Davidson & Corey Miller]', None, '""From the Grave"" — 19.21; ""Blood in the Water"" — 17.38; ""Prey"" — 18.67; ""48 Hours to Life"" — 18.49; ""Three-Way"" — 17.91; ""Under Suspicion"" — 19.94; ""Felony Flight"" — 18.39; ""Nailed"" — 19.36; ""Urban Hellraisers"" — 19.36; ""Shattered"" — 19.77; ""Payback"" — 20.33; ""The Score"" — 20.15; ""Silencer"" — 19.69; ""Fade Out"" — 20.43; ""Skeletons"" — 18.68; ""Deviant"" — 18.43; ""Collision"" — 18.61; ""Double Jeopardy"" — 19.01; ""Driven"" — 19.86; ""Free Fall"" — 17.16; ""Dead Air"" — 18.74; ""Open Water"" — 19.31; ""Shock"" (Part 1) — 19.96'), ('Jonathan Glassner', 2, 19.03, 20.15, '""The Score""', 1, 0, '""Three-Way"" [Marc Guggenheim & Ildy Modrovich]', None, '""From the Grave"" — 19.21; ""Blood in the Water"" — 17.38; ""Prey"" — 18.67; ""48 Hours to Life"" — 18.49; ""Three-Way"" — 17.91; ""Under Suspicion"" — 19.94; ""Felony Flight"" — 18.39; ""Nailed"" — 19.36; ""Urban Hellraisers"" — 19.36; ""Shattered"" — 19.77; ""Payback"" — 20.33; ""The Score"" — 20.15; ""Silencer"" — 19.69; ""Fade Out"" — 20.43; ""Skeletons"" — 18.68; ""Deviant"" — 18.43; ""Collision"" — 18.61; ""Double Jeopardy"" — 19.01; ""Driven"" — 19.86; ""Free Fall"" — 17.16; ""Dead Air"" — 18.74; ""Open Water"" — 19.31; ""Shock"" (Part 1) — 19.96'), ('Scott Lautanen', 8, 18.9, 20.43, '""Fade Out""', 3, 1, '""Prey"" [Corey Miller & Barry O\'Brien]; ""Felony Flight"" [Elizabeth Devine & Anthony E. Zuiker & Ann Donahue]; ""Open Water"" [Marc Dube & Ildy Modrovich]', '""Felony Flight"" (79.0)', '""From the Grave"" — 19.21; ""Blood in the Water"" — 17.38; ""Prey"" — 18.67; ""48 Hours to Life"" — 18.49; ""Three-Way"" — 17.91; ""Under Suspicion"" — 19.94; ""Felony Flight"" — 18.39; ""Nailed"" — 19.36; ""Urban Hellraisers"" — 19.36; ""Shattered"" — 19.77; ""Payback"" — 20.33; ""The Score"" — 20.15; ""Silencer"" — 19.69; ""Fade Out"" — 20.43; ""Skeletons"" — 18.68; ""Deviant"" — 18.43; ""Collision"" — 18.61; ""Double Jeopardy"" — 19.01; ""Driven"" — 19.86; ""Free Fall"" — 17.16; ""Dead Air"" — 18.74; ""Open Water"" — 19.31; ""Shock"" (Part 1) — 19.96'), ('Norberto Barba', 1, 18.49, 18.49, '""48 Hours to Life""', 1, 0, '""48 Hours to Life"" [John Haynes & Marc Dube]', None, '""From the Grave"" — 19.21; ""Blood in the Water"" — 17.38; ""Prey"" — 18.67; ""48 Hours to Life"" — 18.49; ""Three-Way"" — 17.91; ""Under Suspicion"" — 19.94; ""Felony Flight"" — 18.39; ""Nailed"" — 19.36; ""Urban Hellraisers"" — 19.36; ""Shattered"" — 19.77; ""Payback"" — 20.33; ""The Score"" — 20.15; ""Silencer"" — 19.69; ""Fade Out"" — 20.43; ""Skeletons"" — 18.68; ""Deviant"" — 18.43; ""Collision"" — 18.61; ""Double Jeopardy"" — 19.01; ""Driven"" — 19.86; ""Free Fall"" — 17.16; ""Dead Air"" — 18.74; ""Open Water"" — 19.31; ""Shock"" (Part 1) — 19.96'), ('Duane Clark', 1, 17.38, 17.38, '""Blood in the Water""', 1, 0, '""Blood in the Water"" [Dean Widenmann & Sunil Nayar]', None, '""From the Grave"" — 19.21; ""Blood in the Water"" — 17.38; ""Prey"" — 18.67; ""48 Hours to Life"" — 18.49; ""Three-Way"" — 17.91; ""Under Suspicion"" — 19.94; ""Felony Flight"" — 18.39; ""Nailed"" — 19.36; ""Urban Hellraisers"" — 19.36; ""Shattered"" — 19.77; ""Payback"" — 20.33; ""The Score"" — 20.15; ""Silencer"" — 19.69; ""Fade Out"" — 20.43; ""Skeletons"" — 18.68; ""Deviant"" — 18.43; ""Collision"" — 18.61; ""Double Jeopardy"" — 19.01; ""Driven"" — 19.86; ""Free Fall"" — 17.16; ""Dead Air"" — 18.74; ""Open Water"" — 19.31; ""Shock"" (Part 1) — 19.96')]",m_1764878849258_2d150e71_11411026-2,"I'll be concise and dramaturgical, asking for a director‑centric dossier I can use to build themed nights and cocktail names. The SQL produces a per‑director summary (episode count, avg viewers, top episode and viewers), tallies collaboration flags and multi‑writer episodes, aggregates titles of collaborative and multi‑writer episodes, and also returns the dataset's top‑five episodes by viewers. It maps 'Directed by' to groups, 'Written by' to ampersand counts, 'Title' and 'No. in series' for labels, and numeric viewer values for ranking. Draft question: Prepare a director‑by‑director briefing showing episodes directed, average and top U.S. viewers (with top episode title), counts and lists of collaborative episodes and episodes with three or more writers (with series numbers), and append the overall top five episodes by U.S. viewers.",persona,"A dramaturge-curator for a traveling 'CSI Supper Club' who stages 20-minute live adaptations and designs cocktails named after episode statistics to create thematically coherent evenings. Goals: Select the highest-impact (highest U.S. viewers) episodes to feature as marquee pieces for ticketed nights. Create coherent director- or writer-themed evenings by grouping episodes with similar creative leads (e.g., all episodes directed by Karen Gaviola or written/co-written by Ildy Modrovich). Identify episodes with notable collaborations or unusual writer credits to craft behind-the-scenes commentary and drink names tied to co-writers and airing dates. Example Queries: SELECT ""Title"", ""No. in series"", ""No. in season"", ""Directed by"", ""Written by"", ""Original air date"", ""U.S. viewers (millions)""
FROM table_1_11411026_2
ORDER BY CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL) DESC
LIMIT 5; SELECT ""Directed by"", COUNT(*) AS episodes_directed, ROUND(AVG(CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL)), 2) AS avg_viewers
FROM table_1_11411026_2
GROUP BY ""Directed by""
HAVING COUNT(*) >= 2
ORDER BY avg_viewers DESC; SELECT ""No. in series"", ""No. in season"", ""Title"", ""Written by"", ""Original air date"", ""U.S. viewers (millions)""
FROM table_1_11411026_2
WHERE ""Written by"" LIKE '%Ildy Modrovich%'
ORDER BY CAST(REPLACE(""U.S. viewers (millions)"", ',', '') AS REAL) DESC;",N/A,add_column,
"For seasons where Games is greater than 50, return the Season, Goal Differential (Goals for - Goals against), Points per Game (Points / Games rounded to three decimal places), and a Points Rank equal to 1 plus the number of seasons with strictly more Points than that season, ordering results by Points per Game descending and showing only the top 5 seasons?","
SELECT
  t.`Season`,
  (t.`Goals for` - t.`Goals against`) `Goal Differential`,
  ROUND(t.`Points` / t.`Games`,3) `Points per Game`,
  1 + COUNT(s.`Season`) `Points Rank`
FROM `table_m_1764878865677_dc2d9737_1143966_1` t
JOIN `table_m_1764878865677_dc2d9737_1143966_1` AS s ON s.`Points` > t.`Points`
WHERE t.`Games` > 50
GROUP BY t.`Season`, t.`Points`, t.`Games`, t.`Goals for`, t.`Goals against`
ORDER BY `Points per Game` DESC
LIMIT 5;
","
SELECT
  t.col0,
  (t.col7 - t.col8) `Goal Differential`,
  ROUND(t.col5 / t.col1,3) `Points per Game`,
  1 + COUNT(s.col0) `Points Rank`
FROM `table_m_1764878865677_dc2d9737_1143966_1` t
JOIN `table_m_1764878865677_dc2d9737_1143966_1` AS s ON s.col5 > t.col5
WHERE t.col1 > 50
GROUP BY t.col0, t.col5, t.col1, t.col7, t.col8
ORDER BY `Points per Game` DESC
LIMIT 5;
","[('1970–71', 107.0, 1.371, 2), ('1968–69', 90.0, 1.37, 3), ('1969–70', 58.0, 1.222, 5), ('1963–64', 29.0, 1.161, 6), ('1974–75', -16.0, 0.957, 4)]",m_1764878865677_dc2d9737_1143966-1,"1) Parse intent: output season-level metrics including a goals-differential and a per-game points metric rounded to three decimals, plus a Points-based rank, for seasons exceeding 50 games, sorted by Points per Game and limited to five. 2) Map schema: columns Season, Goals for, Goals against, Points, Games correspond to those computations. 3) Draft: ask for Season, (Goals for - Goals against) as Goal Differential, Points/Games rounded to three decimals, and Points Rank = 1 + count of seasons with Points > this season, restrict Games > 50, order by Points per Game descending, top 5. 4) Validate: covers all columns, calculations, rank definition, filter, ordering, and limit exactly.",reserved,10,N/A,split_column,
"For models whose Power (ps) is greater than 200 and whose Displacement (cm³) is at most 2521, list the Model name, Power (ps) as Power_level, the numeric torque value (Torque_Nm) parsed from the part of Torque (Nm@rpm) before '@', the raw rpm portion (Torque_rpm_raw) parsed from after the '@' in Torque (Nm@rpm), the Displacement (cm³) as Displacement_cm3, and a Torque_per_cm3_flag that shows 'High torque per cm3' when Torque_Nm divided by Displacement (cm³) exceeds 0.12?","
SELECT
  `model_name`,
  `Power (ps)` AS `Power_level`,
  (SUBSTR(`torque_nm_at_rpm`,1,INSTR(`torque_nm_at_rpm`, '@')-1)+0) `Torque_Nm`,
  SUBSTR(`torque_nm_at_rpm`, INSTR(`torque_nm_at_rpm`, '@')+1) `Torque_rpm_raw`,
  `Displacement (cm³)` `Displacement_cm3`,
  CASE WHEN ((SUBSTR(`torque_nm_at_rpm`,1,INSTR(`torque_nm_at_rpm`, '@')-1)+0) / `Displacement (cm³)`) > 0.12 THEN 'High torque per cm3' END `Torque_per_cm3_flag`
FROM `table_m_1764878871993_607def32_1147701_4`
WHERE `Power (ps)` > 200 AND `Displacement (cm³)` <= 2521;
","
SELECT
  col0,
  col1 AS `Power_level`,
  (SUBSTR(col2,1,INSTR(col2, '@')-1)+0) `Torque_Nm`,
  SUBSTR(col2, INSTR(col2, '@')+1) `Torque_rpm_raw`,
  col3 `Displacement_cm3`,
  CASE WHEN ((SUBSTR(col2,1,INSTR(col2, '@')-1)+0) / col3) > 0.12 THEN 'High torque per cm3' END `Torque_per_cm3_flag`
FROM `table_m_1764878871993_607def32_1147701_4`
WHERE col1 > 200 AND col3 <= 2521;
","[('2.5T 2.5T AWD (2002-2007)', 210.0, 320, '1500-4500', 2521.0, 'High torque per cm3'), ('T5 (2000-2004)', 250.0, 330, '2400-5200', 2319.0, 'High torque per cm3'), ('T5 (2004-2007)', 260.0, 350, '2100-5000', 2401.0, 'High torque per cm3'), ('R AWD (5-vxl automat) (2004-2006)', 300.0, 350, '1800-6000', 2521.0, 'High torque per cm3'), ('R AWD (6-vxl automat) (2006-2007)', 300.0, 400, '1950-5250', 2521.0, 'High torque per cm3')]",m_1764878871993_607def32_1147701-4,"Parse the SQL intent: select Model name and several transformed columns for rows where Power (ps) > 200 and Displacement (cm³) <= 2521, and flag high torque per cubic centimeter. Map schema semantics: Power (ps) → Power_level, split Torque (Nm@rpm) into Torque_Nm and Torque_rpm_raw, Displacement (cm³) → Displacement_cm3, and compute ratio > 0.12 for Torque_per_cm3_flag. Draft and validate the question to include all columns, alias names, the substring operations, the numeric comparison, and the WHERE filters.",reserved,9,N/A,rename_column,
"For the model '2.3 T5', what are the model, max. torque at rpm, engine type, and engine configuration & notes 0-100km/h?","
SELECT `model`, `max. torque at rpm`, `engine type`, `engine configuration & notes 0-100km/h` FROM `table_m_1764878884205_d19f663d_1147705_1` WHERE `model` = '2.3 T5';
","
SELECT col0, col2, col4, col5 FROM `table_m_1764878884205_d19f663d_1147705_1` WHERE col0 = '2.3 T5';
","[('2.3 T5', 'N·m (lbf·ft) @ 2,700', 'B5234 T3', 'straight-5 high pressure turbo [ 5.9-6.4 s]')]",m_1764878884205_d19f663d_1147705-1,"1) Parse the SQL intent: the query selects model, max. torque at rpm, engine type, and engine configuration & notes 0-100km/h where model = '2.3 T5'. 2) Map schema semantics: these columns correspond to the model name, torque specification with RPM, engine type, and configuration plus 0-100 km/h notes. 3) Draft the question: ask for those four columns specifically for the '2.3 T5' model. 4) Validate: ensure the question mentions all four columns and the model filter '2.3 T5'.",reserved,3,N/A,add_column,
"What are the top 10 Nationalities by number of players, and for each Nationality return Nationality, Players (the count), TenureStringLengthSum (the sum of the character lengths of 'Years for Jazz'), AvgNameLen (ROUND of the average Player name length to 2 decimals), Schools (concatenated 'School/Club Team' values), and Positions (concatenated 'Position' values), considering only entries where 'Years for Jazz' is not empty and ordering results by Players descending?","
SELECT `Nationality` AS `Nationality`, COUNT(*) `Players`, SUM(LENGTH(`Years for Jazz`)) `TenureStringLengthSum`, ROUND(AVG(LENGTH(`Player`)),2) `AvgNameLen`, GROUP_CONCAT(`School/Club Team`) `Schools`, GROUP_CONCAT(`Position`) `Positions`
FROM `table_m_1764878891100_90785d9f_11545282_11`
WHERE LENGTH(`Years for Jazz`)>0
GROUP BY `Nationality`
ORDER BY `Players` DESC
LIMIT 10;
","
SELECT col2 AS col2, COUNT(*) `Players`, SUM(LENGTH(col4)) `TenureStringLengthSum`, ROUND(AVG(LENGTH(col0)),2) `AvgNameLen`, GROUP_CONCAT(col5) `Schools`, GROUP_CONCAT(col3) `Positions`
FROM `table_m_1764878891100_90785d9f_11545282_11`
WHERE LENGTH(col4)>0
GROUP BY col2
ORDER BY `Players` DESC
LIMIT 10;
","[('United States', 9, 76, 11.67, 'Stanford,Stanford,Louisiana-Monroe,Connecticut,Tennessee,Wake Forest,Stanford,Hastings College,Creighton', 'Forward,Forward-Center,Center,Forward,Forward,Forward,Guard,Guard-Forward,Guard-Forward'), ('Turkey', 1, 12, 11.0, 'Kentucky', 'Center'), ('Russia', 1, 7, 16.0, 'CSKA Moscow ( Russia )', 'Combo forward')]",m_1764878891100_90785d9f_11545282-11,"1) Parse: group by Nationality, compute COUNT(*), SUM(LENGTH(Years for Jazz)), ROUND(AVG(LENGTH(Player)),2), GROUP_CONCAT of School/Club Team and Position, filter LENGTH(Years for Jazz)>0, order by Players desc, limit 10. 2) Map semantics: Player -> player name length, Years for Jazz -> tenure string, School/Club Team and Position -> concatenated lists, Nationality -> grouping key. 3) Draft a question that requests those exact aggregates and specifies the non-empty Years filter, grouping, ordering, and top-10 limit. 4) Confirm the question explicitly references each calculation and output column name.",reserved,8,N/A,add_column,
"For each Jazz player, who else wore their number and who else from their school played in the same decade?",unanswerable,unanswerable,,m_1764878907130_95ad05af_11545282-18,"STEP 1: Parse the SQL intent — build a roster with a start_year parsed from the first 4 chars of 'Years for Jazz', compute a 'Decade' label, and for each roster row return the player, number, position, years, school, a reuse_count of how many entries share the same jersey number, a list of other players who used that same number (across the whole dataset), and a list of other players from the same School/Club Team who started in the same decade (excluding the current player). Results ordered by jersey No. and start_year. STEP 2: Determine ambiguity type — attachment ambiguity fits well because the phrase ""in the same decade"" (or similar temporal modifier) can grammatically attach to either the school-team relation or the number-reuse relation (or both), but the SQL only applies the decade restriction to the school-team relation and not to the number reuse. STEP 3: Draft the question — ""For each Jazz player, who else wore their number and who else from their school played in the same decade?"" STEP 4: Explain the ambiguity — the SQL treats ""wore their number"" as across all years and restricts ""from their school"" to the same decade computed from start_year, but the question could be read to mean that the number reuse should also be limited to that decade (or that ""in the same decade"" attaches only to the first clause), or it could be read to ask for counts per-decade rather than per-player.",persona,"A forensic sports-memorabilia detective who authenticates vintage Utah Jazz jerseys by cross-referencing player names, numbers, schools and service years to spot mismatches and counterfeits. Goals: Verify that a claimed vintage jersey (player name + number + patch/sponsor era) matches an actual player who wore that number during the claimed years. Identify jersey numbers that were reused by multiple players across different eras to assess how common a number provenance claim is. Assemble era- and school-specific rosters (e.g., 1970s guards, early-2000s shooting guards, or players from a specific college) to validate provenance labels and design/patch details on physical jerseys. Example Queries: SELECT ""Player"", ""No."", ""Years for Jazz"", ""School/Club Team"" FROM table_1_11545282_18 WHERE ""No."" = 9; SELECT ""No."", COUNT(*) AS reuse_count, GROUP_CONCAT(""Player"", '; ') AS players FROM table_1_11545282_18 GROUP BY ""No."" HAVING reuse_count > 1; SELECT ""Player"", ""No."", ""Position"", ""Years for Jazz"" FROM table_1_11545282_18 WHERE ""Years for Jazz"" LIKE '197%';",N/A,merge_column,"type: Attachment ambiguity | explanation: The SQL applies the 'same decade' restriction only to the 'same school' teammates, while the question can be read as attaching 'in the same decade' to either clause (i.e., also restricting the list of players who wore the same number to that decade) or to neither, producing different expected results."
"For each Position, what are the Position, the number of players (Player Count), the average jersey number (Average No.), the count of players whose No. is 4, 5, or 6 (Low Numbers), and the count of players whose Years for Jazz contains a semicolon indicating multiple tenures (Multi-tenure), considering only rows where No. > 0 and the Player name is not empty, grouping by Position and only including positions with more than 0 players?",unanswerable,unanswerable,,m_1764878921373_fdfa7419_11545282-19,"1) Intent: compute per-position aggregates including count, average jersey number, count of specific low numbers, and count of multi-tenure players while filtering out invalid rows. 2) Map: Position -> Position, No. -> jersey number, Player -> name non-empty filter, Years for Jazz -> detect semicolon for multiple tenures. 3) Draft: ask for Position, Player Count, Average No., Low Numbers (No. in 4,5,6), and Multi-tenure (Years for Jazz containing ';') with No. > 0 and non-empty Player, grouped by Position and excluding empty groups. 4) Validate: includes all columns, calculations, filters, grouping and having conditions.",reserved,9,N/A,merge_column,
"Which distinct Nationality values and their COUNT(*) AS Player Count correspond to players with Position containing 'Guard' and Years for Jazz containing a semicolon, grouped by Nationality, excluding nationalities with zero players and returning up to 5 rows?",unanswerable,unanswerable,,m_1764878931732_c6da04bd_11545282-5,"1) Parse intent: produce counts of guard players by nationality where Years for Jazz contains a semicolon, ensuring distinct nationalities and at most five rows. 2) Map schema: Nationality, Position, Years for Jazz, and COUNT(*) labeled Player Count. 3) Draft question: request nationality and player count with those exact filters and grouping, and limit. 4) Validate: references DISTINCT Nationality, COUNT(*) AS Player Count, Position LIKE '%Guard%', Years for Jazz LIKE '%;%', GROUP BY Nationality, HAVING COUNT(*)>0, LIMIT 5.",reserved,10,N/A,merge_column,
"Show each 1905–1909 Netherlands player with caps, goals, birth and death dates, computed age at death and goals-per-cap, flag if death fell in 1939–1945 and flag as high-priority if wartime or if goals-per-cap ≥1 and age at death <50, with WWII cases at the top, then younger ages, then better scorers.",unanswerable,unanswerable,,m_1764878966809_5481d500_11585313-1,"I write concise, practical questions and would use familiar football terms rather than SQL jargon. The SQL returns every player row with computed age, goals-per-cap, wartime_death flag (1939–1945) and a high-priority follow-up flag combining wartime death or high scoring + early death. The schema maps to the players' debut, birth/death dates, caps and goals and the derived numeric fields. Draft question: Show each 1905–1909 Netherlands player with caps, goals, birth and death dates, computed age at death and goals-per-cap, flag if death fell in 1939–1945 and flag as high-priority if wartime or if goals-per-cap ≥1 and age at death <50, with WWII cases at the top, then younger ages, then better scorers. This phrasing stays within the columns and computations present in the query.",persona,"```json
{
  ""short_description"": ""A sports-epidemiologist and World-War-era mortality researcher who studies lifespans and wartime deaths of early Dutch international footballers (1905–1909)."",
  ""goals"": [
    ""Identify which Netherlands internationals from 1905–1909 likely died during World War II (1939–1945) and estimate their ages at death for archival follow-up."",
    ""Compare lifespans of these early elite athletes (approximate age at death) and find high goal-per-cap players who died youn Goals:  Example Queries: ",N/A,remove_column,
Which Pentium Dual-Core models under 35 W with at least 1.8 GHz or a 667 MT/s FSB have the highest performance per watt?,"
SELECT 
  `model_number`,
  `specification_number`,
  `Frequency`,
  `FSB`,
  `TDP`,
  `Socket`,
  `Part number(s)`,
  `release_price_usd`,
  `Release date`,
  CAST(REPLACE(`Frequency`, ' GHz', '') AS REAL) AS `freq_ghz`,
  CAST(REPLACE(`FSB`, ' MT/s', '') AS INTEGER) AS `fsb_mt_s`,
  CAST(REPLACE(`TDP`, ' W', '') AS INTEGER) AS `tdp_w`,
  ROUND(
    (CAST(REPLACE(`Frequency`, ' GHz', '') AS REAL) * CAST(REPLACE(`FSB`, ' MT/s', '') AS INTEGER))
    / (CASE WHEN CAST(REPLACE(`TDP`, ' W', '') AS INTEGER)=0 THEN 1 ELSE CAST(REPLACE(`TDP`, ' W', '') AS INTEGER) END)
  , 2) AS `Performance per W`
FROM `table_m_1764878973744_a2ab6bd1_11602313_4`
WHERE CAST(REPLACE(`TDP`, ' W', '') AS INTEGER) <= 35
  AND (
    CAST(REPLACE(`Frequency`, ' GHz', '') AS REAL) >= 1.8
    OR CAST(REPLACE(`FSB`, ' MT/s', '') AS INTEGER) >= 667
  )
ORDER BY `Performance per W` DESC, `freq_ghz` DESC;
","
SELECT 
  col0,
  col1,
  col2,
  col4,
  col7,
  col8,
  col10,
  col11,
  col9,
  CAST(REPLACE(col2, ' GHz', '') AS REAL) AS `freq_ghz`,
  CAST(REPLACE(col4, ' MT/s', '') AS INTEGER) AS `fsb_mt_s`,
  CAST(REPLACE(col7, ' W', '') AS INTEGER) AS `tdp_w`,
  ROUND(
    (CAST(REPLACE(col2, ' GHz', '') AS REAL) * CAST(REPLACE(col4, ' MT/s', '') AS INTEGER))
    / (CASE WHEN CAST(REPLACE(col7, ' W', '') AS INTEGER)=0 THEN 1 ELSE CAST(REPLACE(col7, ' W', '') AS INTEGER) END)
  , 2) AS `Performance per W`
FROM `table_m_1764878973744_a2ab6bd1_11602313_4`
WHERE CAST(REPLACE(col7, ' W', '') AS INTEGER) <= 35
  AND (
    CAST(REPLACE(col2, ' GHz', '') AS REAL) >= 1.8
    OR CAST(REPLACE(col4, ' MT/s', '') AS INTEGER) >= 667
  )
ORDER BY `Performance per W` DESC, `freq_ghz` DESC;
","[('Pentium Dual-Core T3200', 'SLAVG(M0)', '2 GHz', '667 MT/s', '35 W', 'Socket P', 'LF80537GF0411M', 'OEM', 'Q4 2008', 2.0, 667, 35, 38.11), ('Pentium Dual-Core T2410', 'SLA4G(M0)', '2 GHz', '533 MT/s', '35 W', 'Socket P', 'LF80537GE0411M', 'OEM', 'Q3 2008', 2.0, 533, 35, 30.46), ('Pentium Dual-Core T2390', 'SLA4H(M0)', '1.87 GHz', '533 MT/s', '35 W', 'Socket P', 'LF80537GE0361M', 'OEM', 'Q2 2008', 1.87, 533, 35, 28.48)]",m_1764878973744_a2ab6bd1_11602313-4,"STEP 1: Parse intent — compute freq_ghz, fsb_mt_s, tdp_w and Performance per W = (freq_ghz * fsb_mt_s)/tdp_w; filter rows with TDP <= 35 and (Frequency >= 1.8 GHz OR FSB >= 667 MT/s); return columns and order by Performance per W DESC, then freq_ghz DESC. STEP 2: Choose ambiguity — scope ambiguity fits: the phrase “have the highest” can mean a single top item overall or the top item within groups (e.g., per socket, per release period, per model family). The SQL returns ordered rows (no grouping), so both readings are plausible. STEP 3: Draft question — ""Which Pentium Dual-Core models under 35 W with at least 1.8 GHz or a 667 MT/s FSB have the highest performance per watt?"" STEP 4: Explain ambiguity — in the original query this is implemented by listing all matching CPUs ordered by performance-per-watt (so one could take the very first row as the single highest), whereas an alternate interpretation would request the highest performer per subgroup (e.g., per socket or per release date) which would require grouping/aggregation and is not what the SQL does.",persona,"Used-laptop refurbisher / inventory manager who sources compatible low-cost Intel Pentium Dual-Core CPUs for bulk laptop repair and resale; uses this database to pick parts by performance, socket, power and sourcing price. Goals: Quickly identify candidate processors that balance higher clock speed and faster FSB while remaining low-power (suitable for older laptops). Find part numbers and release-price information (retail vs OEM) to guide procurement and ordering. Plan sourcing by release period and socket type to ensure compatibility with common laptop motherboards in inventory. Example Queries: SELECT ""Model number"", ""sSpec number"", ""Frequency"", ""FSB"", ""TDP"", ""Socket"", ""Release price ( USD )""
FROM table_1_11602313_4
WHERE CAST(REPLACE(""Frequency"", ' GHz', '') AS DECIMAL) >= 1.8
  AND (""FSB"" LIKE '667%' OR CAST(REPLACE(""FSB"", ' MT/s', '') AS INTEGER) >= 667)
ORDER BY CAST(REPLACE(""Frequency"", ' GHz', '') AS DECIMAL) DESC; SELECT ""Model number"", ""Part number(s)"", ""Release price ( USD )"", ""Release date""
FROM table_1_11602313_4
WHERE ""Release price ( USD )"" = 'OEM' OR ""Release price ( USD )"" LIKE '$%'
ORDER BY ""Release price ( USD )""; SELECT ""Release date"", ""Socket"", COUNT(*) AS models_count
FROM table_1_11602313_4
GROUP BY ""Release date"", ""Socket""
ORDER BY ""Release date"" ASC, ""Socket"";",N/A,rename_column,"type: Scope ambiguity | explanation: The question’s phrase “have the highest” can mean (a) the single top model overall (the first row of the ordered results) or (b) the top model within subgroups such as each socket or each release period; the SQL returns all matching rows ordered but does not perform grouping, so it corresponds to the overall-top interpretation while a grouped-top interpretation would need different SQL (GROUP BY + MAX)."
"List up to 10 records where Purse( $ ) > 1500000 and for each provide the Tournament, Location, Purse( $ ), 1st Prize( $ ), the Pct of Purse computed as (1st Prize( $ ) ÷ Purse( $ )) × 100 formatted to two decimal places, and ToPar obtained as the number inside the parentheses of the Score column?","
SELECT `Tournament`, `Location`, `prize_amount`, `first_prize_amount`, printf('%.2f', (`first_prize_amount`/`prize_amount`)*100) `Pct of Purse`, (substr(`Score`, instr(`Score`,'(')+1, instr(`Score`,')')-instr(`Score`,'(')-1)+0) `ToPar` FROM `table_m_1764878979962_dba21c5e_11603006_1` WHERE (`prize_amount`>1500000) LIMIT 10;
","
SELECT col1, col2, col3, col6, printf('%.2f', (col6/col3)*100) `Pct of Purse`, (substr(col5, instr(col5,'(')+1, instr(col5,')')-instr(col5,'(')-1)+0) `ToPar` FROM `table_m_1764878979962_dba21c5e_11603006_1` WHERE (col3>1500000) LIMIT 10;
","[('ACE Group Classic', 'Florida', 1600000.0, 240000.0, '15.00', -14), ('Verizon Classic', 'Florida', 1600000.0, 240000.0, '15.00', -8), ('MasterCard Classic', 'Mexico', 2000000.0, 300000.0, '15.00', -12), ('Toshiba Senior Classic', 'California', 1550000.0, 232500.0, '15.00', -16), ('Liberty Mutual Legends of Golf', 'Georgia', 3000000.0, 354000.0, '11.80', -10), (""Kinko's Classic of Austin"", 'Texas', 1600000.0, 240000.0, '15.00', -8), ('Bayer Advantage Celebrity Pro-Am', 'Missouri', 1600000.0, 240000.0, '15.00', -11), ('Senior PGA Championship', 'Pennsylvania', 2000000.0, 360000.0, '18.00', -4), ('U.S. Senior Open', 'Ohio', 2600000.0, 460000.0, '17.69', -7), ('Ford Senior Players Championship', 'Michigan', 2500000.0, 375000.0, '15.00', -17)]",m_1764878979962_dba21c5e_11603006-1,"Parse intent: return Tournament, Location, Purse( $ ), 1st Prize( $ ), a percentage of purse formatted to two decimals, and ToPar parsed from Score for rows with Purse( $ )>1500000, limit 10. Map schema: identify columns Tournament, Location, Purse( $ ), 1st Prize( $ ), Score and the two calculations (Pct of Purse and substring ToPar). Draft: request these exact fields, calculations, filter, and limit. Validate: ensure question explicitly states the calculation formatting and the extraction of ToPar plus the Purse threshold and row limit.",reserved,4,N/A,rename_column,
"For institutions with Founded > 1900 AND Founded < 2000, list each Status and Color along with the Institution Count (COUNT(*)) and the Earliest Founded (MIN(Founded)), grouping by Status and Color, only include groups with Institution Count >= 1, and sort the results by Earliest Founded?","
SELECT `Status`, `institution_color`, COUNT(*) `institution_name Count`, MIN(`Founded`) `Earliest Founded`
FROM `table_m_1764878985978_d6bd5125_11604804_5`
WHERE `Founded` > 1900 AND `Founded` < 2000
GROUP BY `Status`, `institution_color`
HAVING COUNT(*) >= 1
ORDER BY `Earliest Founded`;
","
SELECT col2, col4, COUNT(*) `institution_name Count`, MIN(col3) `Earliest Founded`
FROM `table_m_1764878985978_d6bd5125_11604804_5`
WHERE col3 > 1900 AND col3 < 2000
GROUP BY col2, col4
HAVING COUNT(*) >= 1
ORDER BY `Earliest Founded`;
","[('State', 'Green', 1, 1907.0), ('State', 'Gold, Red', 1, 1918.0), ('State', 'Navy Blue', 1, 1941.0), ('State', 'Blue and White', 1, 1969.0), ('State', 'Gold and White', 1, 1971.0), ('State', 'Red and White', 1, 1992.0)]",m_1764878985978_d6bd5125_11604804-5,"1) Parse intent: return per-Status and Color aggregates for rows with Founded between 1900 and 2000 (exclusive), computing count and earliest founding and only keeping groups with at least one member, ordered by earliest year. 2) Map schema: use Status and Color as grouping keys, Founded for MIN to produce Earliest Founded, COUNT(*) as Institution Count. 3) Draft: ask explicitly for Status, Color, Institution Count, Earliest Founded with the WHERE, GROUP BY, HAVING, and ORDER BY conditions. 4) Validate: ensure question explicitly names Status, Color, Institution Count, Earliest Founded, the Founded range, grouping by Status and Color, HAVING >= 1, and ordering by Earliest Founded.",reserved,9,N/A,rename_column,
"For each row, what are the Total No., Celebrity and Director, and what is the ISO Date obtained from Original air date by replacing 'January' with '-01-', 'October' with '-10-', 'November' with '-11-' and 'December' with '-12-', then taking the last four characters of that replaced string as the year, the two characters immediately after the first '-' as the month, and the substring before the first '-' as the day zero-padded to two digits, formatted as YYYY-MM-DD?",,,[],m_1764879033480_4b2b6092_11642945-1,"1) Parse intent: select Total No., Celebrity, Director and compute an ISO Date by replacing month names with numeric codes and reassembling year-month-day with zero-padded day. 2) Map schema: use table_1_11642945_1 columns Total No., Celebrity, Director, Original air date. 3) Draft question: ask for those columns and specify the exact replacement and substring operations to produce YYYY-MM-DD. 4) Validate: ensures all columns and the replacement/substr/zero-pad operations are described.",reserved,3,N/A,merge_column,
"For each Nature of Help, considering only rows with Year >= 2000 and a non-empty People Assisted value, provide the Disaster Count (COUNT(*)), the Disasters as a '; '-separated list, and the literal fields 'Bangladesh' (Example Country) and 'India' (Example Country 2), ordered by Disaster Count descending and limited to the top 5 entries?",unanswerable,unanswerable,,m_1764879057763_9e808386_11649123-1,"1) Parse SQL intent: select Nature of Help with aggregated metrics: count and concatenated Disaster names, add two literal country columns, restrict to Year >= 2000 and non-empty People Assisted, order by count desc and limit to 5. 2) Map schema semantics: use Nature of Help, Disaster, Year, People Assisted from the table and output 'Bangladesh' and 'India' as constants. 3) Draft the question: ask for those exact columns and calculations per Nature of Help with the filters and top-5 ordering. 4) Validate: ensures inclusion of COUNT(*) as Disaster Count, GROUP_CONCAT as Disasters with '; ', the two example country columns, the WHERE conditions, ORDER BY and LIMIT.",reserved,9,N/A,merge_column,
Which seasons showed improvement after a coach change?,"
WITH parsed AS (
  SELECT
    `year`,
    CAST(`team_position` AS INTEGER) AS `team_position`,
    `Win/Loss`,
    `head_coach`,
    `Captain`,
    `Dudley Tuckey Medal`,
    `Leading goalkicker`,
    CAST(substr(`Win/Loss`, 1, instr(`Win/Loss`, '-') - 1) AS INTEGER) AS wins,
    CAST(substr(`Win/Loss`, instr(`Win/Loss`, '-') + 1) AS INTEGER) AS losses,
    TRIM(substr(`Leading goalkicker`, 1, instr(`Leading goalkicker`, '(') - 1)) AS leading_goalkicker_name,
    CAST(substr(`Leading goalkicker`, instr(`Leading goalkicker`, '(') + 1, instr(`Leading goalkicker`, ')') - instr(`Leading goalkicker`, '(') - 1) AS INTEGER) AS leading_goals
  FROM `table_m_1764879063839_97ba688c_1165048_1`
),
coach_agg AS (
  SELECT
    `head_coach`,
    COUNT(*) AS coach_total_seasons,
    ROUND(AVG(`team_position`), 2) AS coach_avg_position,
    ROUND(AVG(wins), 2) AS coach_avg_wins
  FROM parsed
  GROUP BY `head_coach`
),
captain_agg AS (
  SELECT
    `Captain`,
    COUNT(*) AS captain_total_seasons,
    ROUND(AVG(`team_position`), 2) AS captain_avg_position,
    ROUND(AVG(wins), 2) AS captain_avg_wins
  FROM parsed
  GROUP BY `Captain`
),
overall AS (
  SELECT ROUND(AVG(leading_goals),2) AS overall_avg_goals FROM parsed
)
SELECT
  p.`year`,
  p.`team_position`,
  (p.`team_position` - LAG(p.`team_position`) OVER (ORDER BY p.`year`)) AS position_change_from_prev,
  p.`Win/Loss`,
  p.wins,
  p.losses,
  p.`head_coach`,
  ca.coach_total_seasons,
  ca.coach_avg_position,
  ca.coach_avg_wins,
  CASE WHEN p.`head_coach` != LAG(p.`head_coach`) OVER (ORDER BY p.`year`) THEN 1 ELSE 0 END AS coach_changed_since_prev_season,
  p.`Captain`,
  cpa.captain_total_seasons,
  cpa.captain_avg_position,
  cpa.captain_avg_wins,
  CASE WHEN p.`Captain` != LAG(p.`Captain`) OVER (ORDER BY p.`year`) THEN 1 ELSE 0 END AS captain_changed_since_prev_season,
  p.`Dudley Tuckey Medal`,
  p.`Leading goalkicker`,
  p.leading_goalkicker_name,
  p.leading_goals,
  DENSE_RANK() OVER (ORDER BY p.leading_goals DESC) AS leading_goals_rank,
  CASE WHEN p.leading_goals >= (SELECT overall_avg_goals FROM overall) THEN 1 ELSE 0 END AS leading_goals_above_overall_avg
FROM parsed p
LEFT JOIN coach_agg ca ON p.`head_coach` = ca.`head_coach`
LEFT JOIN captain_agg cpa ON p.`Captain` = cpa.`Captain`
ORDER BY p.`year` ASC;
","
WITH parsed AS (
  SELECT
    col0,
    CAST(col1 AS INTEGER) AS col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    CAST(substr(col2, 1, instr(col2, '-') - 1) AS INTEGER) AS wins,
    CAST(substr(col2, instr(col2, '-') + 1) AS INTEGER) AS losses,
    TRIM(substr(col6, 1, instr(col6, '(') - 1)) AS leading_goalkicker_name,
    CAST(substr(col6, instr(col6, '(') + 1, instr(col6, ')') - instr(col6, '(') - 1) AS INTEGER) AS leading_goals
  FROM `table_m_1764879063839_97ba688c_1165048_1`
),
coach_agg AS (
  SELECT
    col3,
    COUNT(*) AS coach_total_seasons,
    ROUND(AVG(col1), 2) AS coach_avg_position,
    ROUND(AVG(wins), 2) AS coach_avg_wins
  FROM parsed
  GROUP BY col3
),
captain_agg AS (
  SELECT
    col4,
    COUNT(*) AS captain_total_seasons,
    ROUND(AVG(col1), 2) AS captain_avg_position,
    ROUND(AVG(wins), 2) AS captain_avg_wins
  FROM parsed
  GROUP BY col4
),
overall AS (
  SELECT ROUND(AVG(leading_goals),2) AS overall_avg_goals FROM parsed
)
SELECT
  p.col0,
  p.col1,
  (p.col1 - LAG(p.col1) OVER (ORDER BY p.col0)) AS position_change_from_prev,
  p.col2,
  p.wins,
  p.losses,
  p.col3,
  ca.coach_total_seasons,
  ca.coach_avg_position,
  ca.coach_avg_wins,
  CASE WHEN p.col3 != LAG(p.col3) OVER (ORDER BY p.col0) THEN 1 ELSE 0 END AS coach_changed_since_prev_season,
  p.col4,
  cpa.captain_total_seasons,
  cpa.captain_avg_position,
  cpa.captain_avg_wins,
  CASE WHEN p.col4 != LAG(p.col4) OVER (ORDER BY p.col0) THEN 1 ELSE 0 END AS captain_changed_since_prev_season,
  p.col5,
  p.col6,
  p.leading_goalkicker_name,
  p.leading_goals,
  DENSE_RANK() OVER (ORDER BY p.leading_goals DESC) AS leading_goals_rank,
  CASE WHEN p.leading_goals >= (SELECT overall_avg_goals FROM overall) THEN 1 ELSE 0 END AS leading_goals_above_overall_avg
FROM parsed p
LEFT JOIN coach_agg ca ON p.col3 = ca.col3
LEFT JOIN captain_agg cpa ON p.col4 = cpa.col4
ORDER BY p.col0 ASC;
","[(1997.0, 9, None, '1-19', 1, 19, 'Geoff Miles', 1, 9.0, 1.0, 0, 'Phil Gilbert', 2, 9.0, 1.0, 0, 'Scott Simister', 'Scott Simister (27)', 'Scott Simister', 27, 13, 0), (1998.0, 9, 0, '1-19', 1, 19, 'Geoff Miles Troy Wilson', 1, 9.0, 1.0, 1, 'Phil Gilbert', 2, 9.0, 1.0, 0, 'Darren Bolton', 'Scott Simister (31)', 'Scott Simister', 31, 10, 0), (1999.0, 9, 0, '0-20', 0, 20, 'Troy Wilson', 1, 9.0, 0.0, 1, 'Scott Simister', 1, 9.0, 0.0, 1, 'Scott Simister', 'Scott Simister (54)', 'Scott Simister', 54, 2, 1), (2000.0, 8, -1, '4-14', 4, 14, 'Shane Cable', 2, 7.0, 5.5, 1, 'Bill Monaghan', 1, 8.0, 4.0, 1, 'Vance Davison', 'Dean Buszan (32)', 'Dean Buszan', 32, 9, 0), (2001.0, 6, -2, '7-11', 7, 11, 'Shane Cable', 2, 7.0, 5.5, 0, 'Vance Davison', 1, 6.0, 7.0, 1, 'Derek Hall', 'David McPharlin (25)', 'David McPharlin', 25, 14, 0), (2002.0, 8, 2, '7-11', 7, 11, 'Peter German', 1, 8.0, 7.0, 1, 'Derek Hall', 2, 8.5, 4.0, 1, 'Darren Bolton', 'Scott Simister (46)', 'Scott Simister', 46, 4, 1), (2003.0, 9, 1, '1-19', 1, 19, 'John Ditchburn', 1, 9.0, 1.0, 1, 'Derek Hall', 2, 8.5, 4.0, 0, 'Derek Hall', 'Derek Hall (22)', 'Derek Hall', 22, 15, 0), (2004.0, 8, -1, '5-15', 5, 15, 'Garry Hocking', 2, 8.5, 4.0, 1, 'Brandon Hill', 1, 8.0, 5.0, 1, 'Daniel Haines', 'Cameron Gauci (40)', 'Cameron Gauci', 40, 6, 1), (2005.0, 9, 1, '3-17', 3, 17, 'Garry Hocking', 2, 8.5, 4.0, 0, 'Grant Welsh', 4, 7.75, 5.5, 1, 'Pat Travers', 'Justin Wood (29)', 'Justin Wood', 29, 12, 0), (2006.0, 8, -1, '6-14', 6, 14, 'Chris Waterman', 4, 7.75, 6.0, 1, 'Grant Welsh', 4, 7.75, 5.5, 0, ""Rory O'Brien"", 'Dean Buszan (44)', 'Dean Buszan', 44, 5, 1), (2007.0, 8, 0, '5-15', 5, 15, 'Chris Waterman', 4, 7.75, 6.0, 0, 'Grant Welsh', 4, 7.75, 5.5, 0, 'Daniel Haines', 'Dean Buszan (30)', 'Dean Buszan', 30, 11, 0), (2008.0, 6, -2, '8-12', 8, 12, 'Chris Waterman', 4, 7.75, 6.0, 0, 'Grant Welsh', 4, 7.75, 5.5, 0, 'Hayden Ballantyne', 'Hayden Ballantyne (75)', 'Hayden Ballantyne', 75, 1, 1), (2009.0, 9, 3, '5-15', 5, 15, 'Chris Waterman', 4, 7.75, 6.0, 0, 'Daniel Haines', 1, 9.0, 5.0, 1, 'Ben Howlett', 'Kain Robins (33)', 'Kain Robins', 33, 8, 0), (2010.0, 8, -1, '3-17', 3, 17, 'Trevor Williams', 2, 8.5, 4.0, 1, 'Daniel Haines Brendon Jones', 1, 8.0, 3.0, 1, ""Rory O'Brien"", 'Matthew Battye (27)', 'Matthew Battye', 27, 13, 0), (2011.0, 9, 1, '5-15', 5, 15, 'Trevor Williams', 2, 8.5, 4.0, 0, 'Brendon Jones', 2, 9.0, 5.0, 1, 'Kristin Thornton', 'Bradley Holmes (36)', 'Bradley Holmes', 36, 7, 0), (2012.0, 9, 0, '5-15', 5, 15, 'Trevor Williams Mark Moody', 1, 9.0, 5.0, 1, 'Brendon Jones', 2, 9.0, 5.0, 0, 'Brendon Jones', 'Bradley Holmes (52)', 'Bradley Holmes', 52, 3, 1)]",m_1764879063839_97ba688c_1165048-1,"STEP 1: Parse the SQL intent — The query parses each season row to extract numeric Position, wins/losses, leading goalkicker name and goals; computes per-coach and per-captain aggregates (total seasons, average position, average wins); computes overall average leading goals; and outputs per-season details including position change from previous season, flags if coach/captain changed since previous season, leading goalkicker rank and whether leading goals are above overall average. STEP 2: Determine ambiguity type — Attachment ambiguity fits well: the phrase 'after a coach change' can attach to different notions (the season immediately following a change vs the season that is the coach's first overall), and additionally the word 'improvement' can attach to different metrics (position vs wins vs coach-average). STEP 3: Draft the question — ""Which seasons showed improvement after a coach change?"" STEP 4: Explain the ambiguity — In the original query 'coach change' is encoded both as a per-season flag (coach_changed_since_prev_season = 1) and as a coach-level count (coach_total_seasons), and 'improvement' could be measured by position_change_from_prev, by wins compared to previous seasons, or by comparing the season to the coach's average; the SQL provides columns to answer any of these interpretations but the natural language question does not specify which attachment or metric is intended.",persona,"Club Performance Analyst for Peel Thunder Football Club with a background in sports analytics and historical record-keeping; they use the honour board data to evaluate year-to-year team performance, coach/captain impacts, and goal-scoring trends. Goals: Track season-by-season performance (position and win/loss) to identify improvement or decline trends. Assess the impact and tenure of coaches and captains on team results. Identify the club's leading goalkickers across seasons and compare their goal tallies to spot standout scoring years. Example Queries: /* 1) Get the season-by-season summary to visualize trends */
SELECT ""Season"", ""Position"", ""Win/Loss"", ""Coach"", ""Captain"", ""Leading goalkicker""
FROM table_1_1165048_1
ORDER BY ""Season"" ASC; /* 2) Basic season performance aggregates: average/ best/ worst ladder position and the seasons they occurred */
SELECT
  ROUND(AVG(CAST(""Position"" AS NUMERIC)), 2) AS avg_position,
  MIN(CAST(""Position"" AS INTEGER)) AS best_position,
  MAX(CAST(""Position"" AS INTEGER)) AS worst_position
FROM table_1_1165048_1; /* 3) Extract leading goalkicker name and goals, then list top scoring seasons (PostgreSQL-style regex used to split name and number) */
SELECT
  TRIM(regexp_replace(""Leading goalkicker"", '\\s*\\([0-9]+\\)\\s*$', '')) AS goalkicker_name,
  CAST(regexp_replace(""Leading goalkicker"", '^.*\\(([0-9]+)\\)$', '\\1') AS INTEGER) AS goals,
  ""Season""
FROM table_1_1165048_1
WHERE ""Leading goalkicker"" IS NOT NULL
ORDER BY goals DESC, ""Season"" ASC;",N/A,rename_column,"type: Attachment ambiguity | explanation: The phrase 'after a coach change' can attach to (a) the immediate-season flag where the coach differs from the previous season (coach_changed_since_prev_season = 1) or (b) seasons that are a coach's first season overall (coach_total_seasons = 1); 'showed improvement' is also ambiguous (position_change_from_prev, more wins than before, or better than the coach's average), and the SQL contains data to support multiple interpretations."
"List Abbrev (Abbreviation), Voivodeship, Population_density defined as (REPLACE Population (1980) spaces removed and converted to number) / (REPLACE Area km² (1998) spaces removed and converted to number), No. of cities, No. of communes, and Cities_per_commune = No. of cities * 1.0 / No. of communes for voivodeships whose Population (1980) is between 400000 and 1400000 and that have between 10 and 40 other voivodeships with a smaller Population (1980); order by Population_density descending and return the first 10?","
SELECT
  t1.`Abbreviation` AS `Abbrev`,
  t1.`Voivodeship`,
  (REPLACE(t1.`Population (1980)`, ' ', '')+0) / (REPLACE(t1.`Area km² (1998)`, ' ', '')+0) AS `Population_density`,
  t1.`No. of cities`,
  t1.`No. of communes`,
  (t1.`No. of cities`*1.0 / t1.`No. of communes`) AS `Cities_per_commune`
FROM `table_m_1764879071460_12c25f42_11656578_2` AS t1
JOIN `table_m_1764879071460_12c25f42_11656578_2` AS t2 ON (REPLACE(t2.`Population (1980)`, ' ', '')+0) < (REPLACE(t1.`Population (1980)`, ' ', '')+0)
WHERE (REPLACE(t1.`Population (1980)`, ' ', '')+0) BETWEEN 400000 AND 1400000
GROUP BY t1.`Abbreviation`
HAVING COUNT(t2.`Abbreviation`) BETWEEN 10 AND 40
ORDER BY `Population_density` DESC
LIMIT 10;
","
SELECT
  t1.col0 AS `Abbrev`,
  t1.col1,
  (REPLACE(t1.col4, ' ', '')+0) / (REPLACE(t1.col3, ' ', '')+0) AS `Population_density`,
  t1.col5,
  t1.col6,
  (t1.col5*1.0 / t1.col6) AS `Cities_per_commune`
FROM `table_m_1764879071460_12c25f42_11656578_2` AS t1
JOIN `table_m_1764879071460_12c25f42_11656578_2` AS t2 ON (REPLACE(t2.col4, ' ', '')+0) < (REPLACE(t1.col4, ' ', '')+0)
WHERE (REPLACE(t1.col4, ' ', '')+0) BETWEEN 400000 AND 1400000
GROUP BY t1.col0
HAVING COUNT(t2.col0) BETWEEN 10 AND 40
ORDER BY `Population_density` DESC
LIMIT 10;
","[('bb', 'Bielsko-Biała Voivodeship', 224, 18.0, 47.0, 0.3829787234042553), ('wb', 'Wałbrzych Voivodeship', 171, 31.0, 30.0, 1.0333333333333334), ('rz', 'Rzeszów Voivodeship', 147, 13.0, 41.0, 0.3170731707317073), ('ta', 'Tarnów Voivodeship', 146, 9.0, 41.0, 0.21951219512195122), ('lu', 'Lublin Voivodeship', 137, 16.0, 62.0, 0.25806451612903225), ('cz', 'Częstochowa Voivodeship', 120, 17.0, 49.0, 0.3469387755102041), ('ki', 'Kielce Voivodeship', 116, 17.0, 69.0, 0.2463768115942029), ('to', 'Toruń Voivodeship', 114, 13.0, 41.0, 0.3170731707317073), ('op', 'Opole Voivodeship', 114, 29.0, 61.0, 0.47540983606557374), ('lg', 'Legnica Voivodeship', 113, 11.0, 31.0, 0.3548387096774194)]",m_1764879071460_12c25f42_11656578-2,"1) The query finds voivodeships within a population range, computes density and city/commune ratio, filters by how many voivodeships have smaller populations, and returns the top 10 by density. 2) Map fields and computations exactly: Abbreviation as Abbrev, Voivodeship, numeric Population and Area after removing spaces for Population_density, No. of cities, No. of communes, and Cities_per_commune as a float ratio. 3) Draft a concise question that includes the BETWEEN 400000 AND 1400000 condition, the requirement that COUNT(smaller populations) is BETWEEN 10 AND 40, ordering by Population_density DESC, and LIMIT 10. 4) Validate inclusion of all columns, calculations, filters, ordering and limit in the question.",reserved,21,N/A,add_column,
"For each state, show the number of member schools, total and average enrollment, the largest and smallest enrollments and which schools those are, list schools that joined since 2000 (with year), how many joined in/after 2011, and the most recent join year?",unanswerable,unanswerable,,m_1764879079744_d3e1fdc7_11658094-1,"As the travel and scheduling coordinator I think in terms of states, counts, enrollments and membership years and I use labels like 'enrollment' and 'joined'. The query aggregates membership data by state to produce counts, enrollment sums/averages/min/max, lists of largest/smallest schools, schools joined since 2000, counts of recent joins, and the most recent join year. It extracts the state from Location, uses Enrollment for size metrics, Institution for names, and parses Joined to a JoinedYear. For each state, show the number of member schools, total and average enrollment, the largest and smallest enrollments and which schools those are, schools that joined since 2000 (with join year), how many joined in/after 2011, and the most recent join year? This matches the query's per-state aggregates and institution lists.",persona,"Conference travel & scheduling coordinator for Conference Carolinas who plans team travel, game sites, and event logistics; uses this membership table to cluster opponents, estimate travel and attendance needs, and flag new members. They need quick lists by state, by enrollment size, and by membership tenure. Goals: Group member institutions by state to plan regional scheduling clusters and reduce travel costs. Identify the largest and smallest member schools by enrollment to allocate bus size, lodging and game-day resources. Find recently joined institutions (new members) to coordinate onboarding, revise scheduling, and update contact lists. Example Queries: /* Count member schools by state (extract state from Location) */
SELECT TRIM(SUBSTR(Location, INSTR(Location, ',') + 1)) AS State,
       COUNT(*) AS school_count
FROM table_1_11658094_1
GROUP BY State
ORDER BY school_count DESC; /* Top 5 member institutions by enrollment to prioritize resource planning */
SELECT Institution, Enrollment, Location
FROM table_1_11658094_1
ORDER BY Enrollment DESC
LIMIT 5; /* List institutions that joined in or after 2000 (handles Joined like '2011' or '1930 1' by taking first 4 chars) */
SELECT Institution, Joined
FROM table_1_11658094_1
WHERE CAST(SUBSTR(Joined, 1, 4) AS INTEGER) >= 2000
ORDER BY CAST(SUBSTR(Joined, 1, 4) AS INTEGER);",N/A,remove_column,
"Which institutions (showing Institution, Location, Type, Enrollment) that have Enrollment above 2000 and Left no earlier than 1975 have Membership Years equal to Left - Joined, Enrollment per Year equal to Enrollment divided by (Left - Joined) rounded to two decimal places, and what is their Current Conference?","
SELECT `Institution`, `Location`, `Type`, `Enrollment`, `Left` - `Joined` `Membership Years`, ROUND(`Enrollment`/(`Left` - `Joined`),2) `Enrollment per Year`, `Current Conference`
FROM `table_m_1764879085090_064fc98c_11658094_3`
WHERE `Enrollment` > 2000 AND `Left` >= 1975;
","
SELECT col0, col1, col3, col4, col7 - col6 `Membership Years`, ROUND(col4/(col7 - col6),2) `Enrollment per Year`, col8
FROM `table_m_1764879085090_064fc98c_11658094_3`
WHERE col4 > 2000 AND col7 >= 1975;
","[('Anderson University', 'Anderson, South Carolina', 'Private', 2907.0, 12.0, 242.25, 'SAC'), ('Elon University', 'Elon, North Carolina', 'Private', 6720.0, 45.0, 149.33, 'SoCon ( CAA in 2014) (NCAA Division I)'), ('Guilford College', 'Greensboro, North Carolina', 'Private', 2706.0, 58.0, 46.66, 'ODAC (NCAA Division III)'), ('High Point University', 'High Point, North Carolina', 'Private', 4519.0, 67.0, 67.45, 'Big South (NCAA Division I)'), ('Longwood University', 'Farmville, Virginia', 'Public', 4800.0, 8.0, 600.0, 'Big South (NCAA Division I)'), ('University of North Carolina at Pembroke', 'Pembroke, North Carolina', 'Public', 6433.0, 16.0, 402.06, 'Peach Belt (PBC)'), ('Queens University of Charlotte', 'Charlotte, North Carolina', 'Private', 2386.0, 18.0, 132.56, 'SAC'), ('Western Carolina University', 'Cullowhee, North Carolina', 'Public', 9608.0, 42.0, 228.76, 'SoCon (NCAA Division I)')]",m_1764879085090_064fc98c_11658094-3,"Parse intent: select Institution, Location, Type, Enrollment, compute Left-Joined as Membership Years and Enrollment/(Left-Joined) rounded to 2 decimals, include Current Conference, filter Enrollment > 2000 and Left >= 1975. Map schema: use the Former members table fields Institution, Location, Type, Enrollment, Joined, Left, Current Conference. Draft question: ask which institutions meeting the filters should return those columns and computed values. Validate: ensure the phrasing requests the exact calculations, rounding to two decimals, and both filter predicates.",reserved,4,N/A,add_column,
"For each team appearing in the Champion, Runner-up, or Third place columns, what are the total number of times they were Champion (Champions), Runner-up (Runners), and Third place (Thirds), and what is their Weighted Score calculated as (Champions * 3 + Runners * 2 + Thirds), including only teams with at least one top-three finish and ordered by Weighted Score descending?","
WITH `unpivot` AS (
SELECT `Champion` `Team`, 1 `ChampionCount`, 0 `RunnerCount`, 0 `ThirdCount` FROM `table_m_1764879105757_e28fc81a_1167698_1`
UNION ALL
SELECT `Runner-up`, 0, 1, 0 FROM `table_m_1764879105757_e28fc81a_1167698_1`
UNION ALL
SELECT `Third place`, 0, 0, 1 FROM `table_m_1764879105757_e28fc81a_1167698_1`
)
SELECT `Team`, SUM(`ChampionCount`) `Champions`, SUM(`RunnerCount`) `Runners`, SUM(`ThirdCount`) `Thirds`, (SUM(`ChampionCount`)*3 + SUM(`RunnerCount`)*2 + SUM(`ThirdCount`)) `Weighted Score`
FROM `unpivot`
GROUP BY `Team`
HAVING SUM(`ChampionCount`) + SUM(`RunnerCount`) + SUM(`ThirdCount`) > 0
ORDER BY `Weighted Score` DESC;
","
WITH `unpivot` AS (
SELECT col1 `Team`, 1 `ChampionCount`, 0 `RunnerCount`, 0 `ThirdCount` FROM `table_m_1764879105757_e28fc81a_1167698_1`
UNION ALL
SELECT col2, 0, 1, 0 FROM `table_m_1764879105757_e28fc81a_1167698_1`
UNION ALL
SELECT col3, 0, 0, 1 FROM `table_m_1764879105757_e28fc81a_1167698_1`
)
SELECT `Team`, SUM(`ChampionCount`) `Champions`, SUM(`RunnerCount`) `Runners`, SUM(`ThirdCount`) `Thirds`, (SUM(`ChampionCount`)*3 + SUM(`RunnerCount`)*2 + SUM(`ThirdCount`)) `Weighted Score`
FROM `unpivot`
GROUP BY `Team`
HAVING SUM(`ChampionCount`) + SUM(`RunnerCount`) + SUM(`ThirdCount`) > 0
ORDER BY `Weighted Score` DESC;
","[('Lokomotiv Moscow', 0, 4, 4, 12), ('CSKA Moscow', 1, 3, 1, 10), ('Spartak Moscow', 0, 3, 1, 7), ('Rubin Kazan', 1, 0, 2, 5), ('Alania Vladikavkaz', 1, 1, 0, 5), ('Zenit Saint Petersburg', 0, 1, 2, 4), ('Dynamo Moscow', 0, 1, 2, 4), ('Zenit Saint Petersburg (2)', 1, 0, 0, 3), ('Spartak Moscow (9)', 1, 0, 0, 3), ('Spartak Moscow (8)', 1, 0, 0, 3), ('Spartak Moscow (7)', 1, 0, 0, 3), ('Spartak Moscow (6)', 1, 0, 0, 3), ('Spartak Moscow (5)', 1, 0, 0, 3), ('Spartak Moscow (4)', 1, 0, 0, 3), ('Spartak Moscow (3)', 1, 0, 0, 3), ('Rubin Kazan (2)', 1, 0, 0, 3), ('Rotor Volgograd', 0, 1, 1, 3), ('CSKA Moscow (3)', 1, 0, 0, 3), ('CSKA Moscow (2)', 1, 0, 0, 3), ('Torpedo Moscow', 0, 0, 1, 1)]",m_1764879105757_e28fc81a_1167698-1,"1) Parse intent: unpivot Champion, Runner-up, Third place into team rows, count occurrences, sum counts by team, compute Weighted Score = 3*Champions + 2*Runners + Thirds, filter teams with at least one appearance and sort descending. 2) Map schema: Champion, Runner-up, Third place are team name columns; output columns are Team, Champions, Runners, Thirds, Weighted Score. 3) Draft: ask for per-team counts and weighted score with the specified calculation and ordering. 4) Validate: includes all columns, calculation, filter, and ordering from the query.",reserved,20,N/A,split_column,
"List each Hometown with the number of Players (as Players) and the semicolon-separated Player name list (GROUP_CONCAT(Player, '; ')) for rows where MLB Draft contains '1st Round' or 'Attended' and where Player != '`Taylor Hawkins`' or Player = '`Gavin Cecchini`', grouped by Hometown, ordered by the Players count descending, returning only the top 10 rows.",unanswerable,unanswerable,,m_1764879121170_1a063c70_11677100-18,"Parse SQL intent: aggregate players by hometown for entries with MLB Draft indicating first-round selection or 'Attended', apply the given player inclusion/exclusion logic, then return top ten hometowns by player count. Map schema semantics: Hometown is selected, COUNT(*) yields Players, GROUP_CONCAT(Player, '; ') provides the concatenated names, and MLB Draft is filtered with LIKE patterns; the Player condition uses inequality to '`Taylor Hawkins`' or equality to '`Gavin Cecchini`'. Draft the question: ask for Hometown, Players, and semicolon-delimited Player names with those exact filters and sorting/limit. Validate: all SQL elements (columns, concatenation, both LIKE filters, the Player comparison clause, GROUP BY, ORDER BY COUNT DESC, LIMIT 10) are included.",reserved,14,N/A,merge_column,
Which positions have the most players who attended college?,"
SELECT `position_role`, COUNT(*) AS `TotalPlayers`, SUM(`MLB Draft` LIKE 'Attended%') `AttendedCount`
FROM `table_m_1764879148954_92e2fefe_11677100_7`
GROUP BY `position_role`
HAVING COUNT(*)>0
ORDER BY `AttendedCount`
LIMIT 10;
","
SELECT col1, COUNT(*) AS `TotalPlayers`, SUM(col4 LIKE 'Attended%') `AttendedCount`
FROM `table_m_1764879148954_92e2fefe_11677100_7`
GROUP BY col1
HAVING COUNT(*)>0
ORDER BY `AttendedCount`
LIMIT 10;
","[('Catcher', 1, 0), ('Infielder', 2, 0), ('Pitcher', 2, 0), ('Outfielder', 3, 2)]",m_1764879148954_92e2fefe_11677100-7,"STEP 1: Parse the SQL intent — group rows by Position, compute TotalPlayers = COUNT(*), compute AttendedCount = number of rows whose 'MLB Draft' starts with 'Attended', filter groups with COUNT(*)>0, order groups by AttendedCount (ascending) and return up to 10 positions. STEP 2: Choose ambiguity type — scope/measure ambiguity fits: the phrasing “most” or “have the most players who attended” can mean absolute counts (what the SQL returns) or a relative rate/percentage (attended players divided by players at that position). STEP 3: Draft the question — produce an ambiguous natural-language question that maps to counting attended entries per position but is interpretable in another way. STEP 4: Explain ambiguity — in the original query “most” is implemented as the raw AttendedCount per position (ordered by SUM(MLB Draft LIKE 'Attended%')), but a reader could instead intend the position with the highest proportion of attended players (AttendedCount/TotalPlayers) or some other scope (e.g., per school or per era).",reserved,12,N/A,rename_column,type: Scope ambiguity (absolute count vs relative rate) | explanation: The SQL measures “most” as the absolute number of players per position whose 'MLB Draft' value begins with 'Attended' (AttendedCount). However the question could alternatively be read as asking for the highest proportion of attended players within each position (AttendedCount divided by TotalPlayers) or even the top position overall versus per-team/per-era—leading to a different SQL (percentage calculation or further grouping/filtering).
"Which colleges have players, and how many players does each have?",unanswerable,unanswerable,,m_1764879157670_a0d98ed7_11677691-3,"STEP 1: Parse the SQL intent — The first SELECT does a self-join on College and WHERE t1.Player <> t2.Player, then GROUP BY College and HAVING COUNT(DISTINCT t1.Player) > 1, returning COUNT(*) (which equals n*(n-1) for n players at a college) as NumPlayers, ordered desc LIMIT 10. The UNION ALL branch returns up to 5 distinct College rows with a value 1 (so single-player colleges) limited by College DESC. The union concatenates the top-pairs results with a few single-college rows. STEP 2: Choose ambiguity type — An aggregation/entity-granularity ambiguity fits best: the phrase ""how many players"" can refer to distinct player counts per college (n) or to the number produced by the self-join (ordered pairs n*(n-1)), and it's also unclear whether single-player colleges are to be included. STEP 3: Draft the question — ""Which colleges have players, and how many players does each have?"" STEP 4: Explain ambiguity — In the original query ""how many players"" is implemented inconsistently: the self-join returns pair-counts for colleges with more than one distinct player (n*(n-1)), while the UNION branch adds some colleges with the value 1. Alternatively, the question could mean the straightforward distinct-player count per college (n) or might mean to include/exclude single-player colleges or to return top-N only.",reserved,16,N/A,remove_column,"type: Entity vagueness / aggregation-granularity ambiguity | explanation: The SQL returns a COUNT stemming from a self-join (effectively n*(n-1) for a college with n players) for multi-player colleges and also appends some colleges with the value 1 via UNION; the natural language question could instead mean the distinct number of players per college (n), could mean pairwise counts, and could differ on whether single-player colleges are included."
"Give me a tidy per-college breakdown of 2012 All‑USA alums: how many players from each college, whether a college has multiple alums for planning a multi-stop tour, counts by position, a list of each player with their hometown, and flag/list any players who went to college in their home state.",unanswerable,unanswerable,,m_1764879173521_9ecadc92_11677691-9,"As a tour designer I talk in practical terms about colleges, alumni counts and hometowns rather than SQL; I know the table lists players, positions, hometowns and colleges. The query aggregates players by college, counting them, summarizing positions, listing player names and hometowns, and flagging any who went to college in their home state. The schema maps Player, Position, Hometown and College into per-college summaries and derives Hometown State from the Hometown text. Draft: Ask for a tidy per-college breakdown showing number of 2012 All‑USA alums, whether a college has multiple alums for multi-stop planning, counts by position, a players-with-hometowns list, and which colleges have any home-state alums (and who they are). This matches the data returned by the query and contains no extra fields.",persona,"A bespoke 'sports pilgrimage' tour designer who builds curated road-trip itineraries visiting hometowns and colleges of 2012 All‑USA high school football selections. Goals: Identify clusters of players by college to create multi-stop tour packages around college towns with several alumni from the 2012 team. Find players whose hometown state matches their college state so she can design short, local 'homecoming' mini-tours. Map position-based fan-interest stops (e.g., where multiple high-profile offensive players originate) to prioritize attractions and storytelling stops on the route. Produce tidy lists of player names, hometowns and schools to generate itinerary copy, postcards and directions. Example Queries: SELECT Player, Position, School, Hometown, College FROM table_1_11677691_9 WHERE College = 'Alabama'; SELECT Player, Hometown, College FROM table_1_11677691_9 WHERE TRIM(SUBSTR(Hometown, INSTR(Hometown, ', ')+2)) = College; SELECT College, Position, COUNT(*) AS players_from_college_and_position FROM table_1_11677691_9 GROUP BY College, Position ORDER BY players_from_college_and_position DESC;",N/A,merge_column,
"Which directors had an average of more than 3 million U.S. viewers for episodes after episode 70, and what were their episode counts, average and peak viewers, and titles?","
SELECT `Directed by` AS `Director`,
       COUNT(`episode_number_in_series`) `Episodes`,
       ROUND(AVG(`u.s__viewers_millions`),2) `Avg viewers`,
       MAX(`u.s__viewers_millions`) `Peak viewers`,
       GROUP_CONCAT(`Title`, '; ') `Episode titles`
FROM `table_m_1764879182283_6483e0ac_11694832_1`
WHERE `episode_number_in_series` > 70
GROUP BY `Directed by`
HAVING AVG(`u.s__viewers_millions`) > 3.0
ORDER BY AVG(`u.s__viewers_millions`) * -1
LIMIT 5;
","
SELECT col3 AS `Director`,
       COUNT(col0) `Episodes`,
       ROUND(AVG(col7),2) `Avg viewers`,
       MAX(col7) `Peak viewers`,
       GROUP_CONCAT(col2, '; ') `Episode titles`
FROM `table_m_1764879182283_6483e0ac_11694832_1`
WHERE col0 > 70
GROUP BY col3
HAVING AVG(col7) > 3.0
ORDER BY AVG(col7) * -1
LIMIT 5;
","[('John Asher', 1, 4.24, '4.24', '""Songs to Love and Die By""'), ('Stuart Gillard', 1, 3.57, '3.57', '""I Love You But I\'ve Chosen Darkness""'), ('Paul Johansson', 2, 3.33, '3.52', '""Where Did You Sleep Last Night?""; ""Prom Night at Hater High""'), ('Thomas J. Wright', 1, 3.28, '3.28', '""You Call it Madness, But I Call it Love""'), ('Greg Prange', 3, 3.09, '4.21', '""Some You Give Away""; ""It Gets the Worst at Night""; ""The Birth and Death of the Day""')]",m_1764879182283_6483e0ac_11694832-1,"STEP 1: Parse the SQL intent — find directors (Directed by) who directed episodes with No. in series > 70, count those episodes, compute average and max U.S. viewers for those filtered episodes, concatenate their titles, keep only directors whose average (over the filtered episodes) is > 3.0, and return the top 5 by average viewers. STEP 2: Determine ambiguity type — scope ambiguity fits best because the phrasing about an ""average of more than 3 million viewers"" and the restriction ""episodes after episode 70"" can attach in multiple ways (is the average computed only over episodes after 70, or across all episodes by the director, or must each episode after 70 exceed 3 million?). STEP 3: Draft the question — ""Which directors had an average of more than 3 million U.S. viewers for episodes after episode 70, and what were their episode counts, average and peak viewers, and titles?"" STEP 4: Explain the ambiguity — the original query computes the average and other stats only over episodes with No. in series > 70 (WHERE before GROUP BY), but a reader could instead interpret the question as computing each director's overall average across all their episodes and then reporting those who exceed 3 million, or as requiring that every individual episode after 70 exceeds 3 million, or even misread whether ""after episode 70"" includes episode 70.",reserved,10,N/A,rename_column,"type: Scope ambiguity | explanation: The SQL computes averages only over episodes where No. in series > 70 (filter applied before grouping), but the natural-language question could be read as (a) averaging only those post-70 episodes (the SQL interpretation), (b) averaging across all episodes by each director and then selecting those above 3 million, or (c) requiring every single episode after 70 to exceed 3 million (a stricter reading); additionally, ""after episode 70"" might be read inclusively or exclusively."
"Which models, grouped by CPU family, have built-in assembly and what are their RAM and display specs?",unanswerable,unanswerable,,m_1764879189036_8b0385df_11703336-1,"As a retro-calculator dev I care about which models expose built-in assembly so I can prioritize low-level features; I'd ask per family to keep it organized. The SQL includes a conditional aggregation that extracts models whose Programming Languages include 'Assembly (built-in)' and appends their RAM and display. Programming Languages indicates built-in assembly, and RAM/Display Size are the spec fields. Which models (grouped by CPU family) have built-in assembly, and show each one's RAM and display specs? This matches the conditional built-in-assembly listing with RAM and display in the query.",persona,"Emulator developer and retro-calculator hobbyist building accurate software emulations of classic TI graphing calculators; uses this database to prioritize targets and extract hardware/software specs needed for each model. Goals: Identify groups of calculators that share the same CPU family so a single core can cover multiple models. Find models that require a Motorola 68000 implementation versus Zilog Z80 and gather their RAM/display specs for accurate emulation. Locate calculators with built-in assembly support (higher priority for low-level feature parity) and collect their memory and display details. Example Queries: SELECT ""Calculator"", ""CPU"", ""RAM"", ""Display Size"", ""Year Released"" FROM table_1_11703336_1 WHERE ""CPU"" LIKE 'Zilog Z80%'; SELECT ""Calculator"", ""CPU"", ""RAM"", ""Display Size"", ""Year Released"" FROM table_1_11703336_1 WHERE ""CPU"" LIKE 'Motorola 68000%'; SELECT ""Calculator"", ""CPU"", ""RAM"", ""Display Size"", ""Programming Languages"", ""Year Released"" FROM table_1_11703336_1 WHERE ""Programming Languages"" LIKE '%Assembly (built-in)%' ORDER BY ""Year Released"";",N/A,remove_column,
"Which teams had managerial changes, how many changes did each have, and who were the outgoing managers and their replacements?","
SELECT t.`team_name`, COUNT(*) AS `Total changes`, GROUP_CONCAT(t.`previous_manager`), GROUP_CONCAT(t.`Replaced by`)
FROM `table_m_1764879195362_e06037a8_11713303_2` t
JOIN `table_m_1764879195362_e06037a8_11713303_2` r ON t.`team_name` = r.`team_name` AND t.`Date of vacancy` <= r.`Date of vacancy`
WHERE t.`team_name` IN (t.`team_name`) OR t.`team_name` = t.`team_name`
GROUP BY t.`team_name`
ORDER BY `Total changes`
LIMIT 10;
","
SELECT t.col0, COUNT(*) AS `Total changes`, GROUP_CONCAT(t.col1), GROUP_CONCAT(t.col4)
FROM `table_m_1764879195362_e06037a8_11713303_2` t
JOIN `table_m_1764879195362_e06037a8_11713303_2` r ON t.col0 = r.col0 AND t.col3 <= r.col3
WHERE t.col0 IN (t.col0) OR t.col0 = t.col0
GROUP BY t.col0
ORDER BY `Total changes`
LIMIT 10;
","[('Anderlecht', 1, 'Franky Vercauteren', 'Ariel Jacobs'), ('Charleroi', 1, 'Philippe Van de Walle', 'Thierry Siquet'), ('Dender EH', 1, 'Jean-Pierre Van De Velde', 'Johan Boskamp'), ('Mons', 1, 'José Riga', 'Albert Cartier'), ('Brussels', 3, 'Albert Cartier,Albert Cartier,Edy De Bolle', 'Edy De Bolle (caretaker),Edy De Bolle (caretaker),Franky Van Der Elst'), ('Mouscron', 3, 'Marc Brys,Marc Brys,Geert Broeckaert', 'Geert Broeckaert (caretaker),Geert Broeckaert (caretaker),Enzo Scifo'), ('Sint-Truiden', 3, 'Valère Billen,Peter Voets,Peter Voets', 'Peter Voets (caretaker),Dennis Van Wijk,Dennis Van Wijk')]",m_1764879195362_e06037a8_11713303-2,"STEP 1: Parse the SQL intent: the query groups rows by Team and returns for each team a COUNT(*) called Total changes plus concatenated lists of Outgoing manager and Replaced by. The self-join ON t.Team = r.Team AND t.Date of vacancy <= r.Date of vacancy makes the COUNT count join pairs per team (pairs of vacancies where one date is <= another). It orders by Total changes and limits to 10. STEP 2: Choose an ambiguity type: Entity vagueness fits best because the term “changes” can mean different measurable things here (departures, appointments, distinct transitions, or the join-pair count). The SQL’s COUNT over the self-join corresponds to a less obvious measure (ordered pairs) rather than a simple event count. STEP 3: Draft the question: “Which teams had managerial changes, how many changes did each have, and who were the outgoing managers and their replacements?” STEP 4: Explain ambiguity: in the original query “changes” is implemented as COUNT(*) over a self-join (counting pairs of vacancies with t.Date <= r.Date), which is effectively a pairwise/cumulative counting of vacancy rows per team. The question wording is ambiguous because “changes” could alternatively mean (a) number of outgoing managers (departure events), (b) number of incoming appointments, (c) number of distinct manager transitions, or (d) the pairwise/cumulative count produced by this join. A different query could count distinct departures or appointments instead, yielding different numbers.",reserved,13,N/A,rename_column,"type: Entity Vagueness | explanation: The phrase “changes” is vague: the SQL counts join-pairs (t.Date <= r.Date) producing a cumulative/pairwise count, but a reader could interpret “changes” as departures, appointments, distinct transitions, or simple event counts—each interpretation would require a different SQL implementation and could produce different results."
"Give me a season-by-season rundown: how many episodes, titles in air order, season premiere and finale dates, who directed and wrote the most that season, and which titles include 'Dream'/'Dreams'/'Funhouse'.","
SELECT
  t.`season_number`,
  (SELECT COUNT(*) FROM `table_m_1764879201260_2b1685d3_11715748_2` WHERE `season_number` = t.`season_number`) AS `episode_count`,
  (SELECT group_concat(`Title`, ' || ') FROM (SELECT `Title` FROM `table_m_1764879201260_2b1685d3_11715748_2` WHERE `season_number` = t.`season_number` ORDER BY `series_number`)) AS `episode_list_in_series_order`,
  (SELECT MIN(`air_date`) FROM `table_m_1764879201260_2b1685d3_11715748_2` WHERE `season_number` = t.`season_number`) AS `first_airdate`,
  (SELECT MAX(`air_date`) FROM `table_m_1764879201260_2b1685d3_11715748_2` WHERE `season_number` = t.`season_number`) AS `last_airdate`,
  (SELECT group_concat(d.`Director(s)`, ' | ')
   FROM (
     SELECT `Director(s)`, COUNT(*) AS cnt
     FROM `table_m_1764879201260_2b1685d3_11715748_2`
     WHERE `season_number` = t.`season_number`
     GROUP BY `Director(s)`
   ) AS d
   WHERE d.cnt = (
     SELECT MAX(cnt2) FROM (
       SELECT COUNT(*) AS cnt2
       FROM `table_m_1764879201260_2b1685d3_11715748_2`
       WHERE `season_number` = t.`season_number`
       GROUP BY `Director(s)`
     )
   )
  ) AS `top_director_by_season`,
  (SELECT group_concat(w.`Writer(s)`, ' | ')
   FROM (
     SELECT `Writer(s)`, COUNT(*) AS cnt
     FROM `table_m_1764879201260_2b1685d3_11715748_2`
     WHERE `season_number` = t.`season_number`
     GROUP BY `Writer(s)`
   ) AS w
   WHERE w.cnt = (
     SELECT MAX(cnt3) FROM (
       SELECT COUNT(*) AS cnt3
       FROM `table_m_1764879201260_2b1685d3_11715748_2`
       WHERE `season_number` = t.`season_number`
       GROUP BY `Writer(s)`
     )
   )
  ) AS `top_writer_by_season`,
  (SELECT group_concat(`Title`, ' || ')
   FROM (
     SELECT `Title`
     FROM `table_m_1764879201260_2b1685d3_11715748_2`
     WHERE `season_number` = t.`season_number`
       AND (
         `Title` LIKE '%Dream%' OR
         `Title` LIKE '%Dreams%' OR
         `Title` LIKE '%Funhouse%'
       )
     ORDER BY `series_number`
   )
  ) AS `keyword_matches`
FROM (
  SELECT DISTINCT `season_number` FROM `table_m_1764879201260_2b1685d3_11715748_2`
) AS t
ORDER BY t.`season_number`;
","
SELECT
  t.col1,
  (SELECT COUNT(*) FROM `table_m_1764879201260_2b1685d3_11715748_2` WHERE col1 = t.col1) AS `episode_count`,
  (SELECT group_concat(col2, ' || ') FROM (SELECT col2 FROM `table_m_1764879201260_2b1685d3_11715748_2` WHERE col1 = t.col1 ORDER BY col0)) AS `episode_list_in_series_order`,
  (SELECT MIN(col5) FROM `table_m_1764879201260_2b1685d3_11715748_2` WHERE col1 = t.col1) AS `first_airdate`,
  (SELECT MAX(col5) FROM `table_m_1764879201260_2b1685d3_11715748_2` WHERE col1 = t.col1) AS `last_airdate`,
  (SELECT group_concat(d.col3, ' | ')
   FROM (
     SELECT col3, COUNT(*) AS cnt
     FROM `table_m_1764879201260_2b1685d3_11715748_2`
     WHERE col1 = t.col1
     GROUP BY col3
   ) AS d
   WHERE d.cnt = (
     SELECT MAX(cnt2) FROM (
       SELECT COUNT(*) AS cnt2
       FROM `table_m_1764879201260_2b1685d3_11715748_2`
       WHERE col1 = t.col1
       GROUP BY col3
     )
   )
  ) AS `top_director_by_season`,
  (SELECT group_concat(w.col4, ' | ')
   FROM (
     SELECT col4, COUNT(*) AS cnt
     FROM `table_m_1764879201260_2b1685d3_11715748_2`
     WHERE col1 = t.col1
     GROUP BY col4
   ) AS w
   WHERE w.cnt = (
     SELECT MAX(cnt3) FROM (
       SELECT COUNT(*) AS cnt3
       FROM `table_m_1764879201260_2b1685d3_11715748_2`
       WHERE col1 = t.col1
       GROUP BY col4
     )
   )
  ) AS `top_writer_by_season`,
  (SELECT group_concat(col2, ' || ')
   FROM (
     SELECT col2
     FROM `table_m_1764879201260_2b1685d3_11715748_2`
     WHERE col1 = t.col1
       AND (
         col2 LIKE '%Dream%' OR
         col2 LIKE '%Dreams%' OR
         col2 LIKE '%Funhouse%'
       )
     ORDER BY col0
   )
  ) AS `keyword_matches`
FROM (
  SELECT DISTINCT col1 FROM `table_m_1764879201260_2b1685d3_11715748_2`
) AS t
ORDER BY t.col1;
","[(1.0, 1, '""Dream Come True""', 'October2,1989', 'October2,1989', 'George Kaczender', 'Thomas Lazarus', '""Dream Come True""'), (2.0, 1, '""Heartbreak Hotel""', 'October9,1989', 'October9,1989', 'William Malone', 'Jonathan Glassner', None), (3.0, 1, '""Welcome to Springwood""', 'October16,1989', 'October16,1989', 'Ken Wiederhorn', 'A. L. Katz and Gilbert Adler', None), (4.0, 1, '""Photo Finish""', 'October23,1989', 'October23,1989', 'Tom DeSimone', 'Jonathan Glassner', None), (5.0, 1, '""Memory Overload""', 'October30,1989', 'October30,1989', 'Don Weis', 'Michael Kirschenbaum', None), (6.0, 1, '""Lucky Stiff""', 'November6,1989', 'November6,1989', 'William Malone', 'David Braff', None), (7.0, 1, '""Silence Is Golden""', 'November13,1989', 'November13,1989', 'Chuck Braverman', 'Jonathan Glassner', None), (8.0, 1, '""Bloodlines""', 'November20,1989', 'November20,1989', 'James Quinn', 'Gilbert Adler and A. L. Katz', None), (9.0, 1, '""Monkey Dreams""', 'November27,1989', 'November27,1989', 'Robert Englund', 'Michael Kirschenbaum', '""Monkey Dreams""'), (10.0, 1, '""Do You Know Where the Kids Are?""', 'December4,1989', 'December4,1989', 'Bill Froelich', 'Wayne Rice', None), (11.0, 1, '""Dreams That Kill""', 'December11,1989', 'December11,1989', 'Tom De Simone', 'Tom Blumquist', '""Dreams That Kill""'), (12.0, 1, '""What You Don\'t Know Can Kill You""', 'January1,1990', 'January1,1990', 'Ken Wiederhorn', 'Jonathan Glassner', None), (13.0, 1, '""Easy Come, Easy Go""', 'January8,1990', 'January8,1990', 'William Malone', 'David Braff', None), (14.0, 1, '""Prime Cut""', 'January15,1990', 'January15,1990', 'David Calloway', 'Michael Kirschenbaum', None), (15.0, 1, '""Interior Loft""', 'January22,1990', 'January22,1990', 'Ken Wiederhorn', 'David Braff', None), (16.0, 1, '""Interior Loft – Later""', 'January29,1990', 'January29,1990', 'Ken Wiederhorn', 'Jonathan Glassner', None), (17.0, 1, '""Funhouse""', 'February5,1990', 'February5,1990', 'Gilbert Adler', 'Al Katz and Gilbert Adler', '""Funhouse""'), (18.0, 1, '""A Family Affair""', 'February12,1990', 'February12,1990', 'Keith Samples', 'David Braff', None), (19.0, 1, '""Dust to Dust""', 'February19,1990', 'February19,1990', 'Jonathan Glassner', 'Bill Froehlich, David Braff, and Jonathan Glassner', None), (20.0, 1, '""Prisoner of Love""', 'February26,1990', 'February26,1990', 'Richard T. Schor', 'Richard BeBan', None), (21.0, 1, '""Life Sentence""', 'March5,1990', 'March5,1990', 'Anita W. Addison', 'David Zuckerman', None)]",m_1764879201260_2b1685d3_11715748-2,"I'd sound like a scheduler checking blocks across whole seasons, using plain terms like 'season' and 'original airdate'. The SQL selects each season and aggregates episode counts, title lists in series order, min/max airdates, and top directors/writers plus keyword matches. The mapping uses Season #, Series # (for order), Title, Original airdate, Director(s), Writer(s). Draft: Give me a season-by-season rundown: how many episodes, titles in air order, season premiere and finale dates, who directed and wrote the most that season, and which titles include 'Dream'/'Dreams'/'Funhouse'. Validation: This matches the aggregated per-season info and keyword filtering in the query.",persona,"Classic TV programming manager at a cable network who schedules themed blocks and retrospectives; they use this episode-level metadata to plan lineups and director/writer spotlight nights. Goals: Assemble complete season blocks in original broadcast order and verify air dates for scheduling. Identify the most frequent directors and writers to build director- or writer-focused retrospectives. Find episodes matching thematic keywords (e.g., 'Dream', 'Funhouse') for special programming nights and promos. Example Queries: SELECT ""Series #"", ""Season #"", ""Title"", ""Director(s)"", ""Writer(s)"", ""Original airdate"" 
FROM table_1_11715748_2 
WHERE ""Season #"" = 1 
ORDER BY ""Series #""; SELECT ""Director(s)"", COUNT(*) AS episode_count 
FROM table_1_11715748_2 
GROUP BY ""Director(s)"" 
ORDER BY episode_count DESC; SELECT ""Series #"", ""Season #"", ""Title"", ""Director(s)"", ""Original airdate"" 
FROM table_1_11715748_2 
WHERE ""Writer(s)"" LIKE '%Jonathan Glassner%';",N/A,rename_column,
Which position has the tallest player?,"
SELECT
  `Position`,
  COUNT(*) OVER (PARTITION BY `Position`) `Players_Count`,
  MAX(
    CAST(substr(`Height in Ft.`,1,instr(`Height in Ft.`,'-')-1) AS INTEGER)*12 +
    CAST(substr(`Height in Ft.`,instr(`Height in Ft.`,'-')+1) AS INTEGER)
  ) OVER (PARTITION BY `Position`) `Tallest_Inches`,
  FIRST_VALUE(`Player`) OVER (
    PARTITION BY `Position` ORDER BY
    (CAST(substr(`Height in Ft.`,1,instr(`Height in Ft.`,'-')-1) AS INTEGER)*12 +
     CAST(substr(`Height in Ft.`,instr(`Height in Ft.`,'-')+1) AS INTEGER)
    ) DESC
  ) `Tallest_Player`
FROM `table_m_1764879215486_4e8b4841_11734041_18`
GROUP BY `Position`
LIMIT 50;
","
SELECT
  col3,
  COUNT(*) OVER (PARTITION BY col3) `Players_Count`,
  MAX(
    CAST(substr(col2,1,instr(col2,'-')-1) AS INTEGER)*12 +
    CAST(substr(col2,instr(col2,'-')+1) AS INTEGER)
  ) OVER (PARTITION BY col3) `Tallest_Inches`,
  FIRST_VALUE(col0) OVER (
    PARTITION BY col3 ORDER BY
    (CAST(substr(col2,1,instr(col2,'-')-1) AS INTEGER)*12 +
     CAST(substr(col2,instr(col2,'-')+1) AS INTEGER)
    ) DESC
  ) `Tallest_Player`
FROM `table_m_1764879215486_4e8b4841_11734041_18`
GROUP BY col3
LIMIT 50;
","[('Center', 1, 84, 'Tabak, Zan Zan Tabak'), ('Forward', 1, 81, 'Taylor, Maurice Maurice Taylor'), ('Guard', 1, 75, 'Taylor, Jeff Jeff Taylor'), ('Guard / Forward', 1, 78, 'Torres, Oscar Oscar Torres')]",m_1764879215486_4e8b4841_11734041-18,"STEP 1: Parse the SQL intent — the query groups rows by Position and, for each Position, returns the number of players, the maximum height converted to inches, and the player with that maximum height (tallest player per position). STEP 2: Determine ambiguity type — scope ambiguity fits well: the phrase ""the tallest player"" can refer to the tallest player within each position or to the single tallest player across all positions. STEP 3: Draft the question — a concise ambiguous phrasing is: ""Which position has the tallest player?"" STEP 4: Explain the ambiguity — the SQL is interpreted as returning the tallest player for each position (i.e., tallest within each position). The question could instead be read as asking for the one position that contains the overall tallest player across all positions.",reserved,14,N/A,add_column,"type: Scope ambiguity | explanation: In the SQL the phrase is resolved per position (the tallest player for each Position is returned). Alternatively, the question could be interpreted as asking for a single position that contains the absolute tallest player across the whole roster."
"For a 2004/returns/college-ties roundup, pull every player who was in 2004 or had multiple stints or comes from a college with more than one alum here, and give jersey, height (and inches), position, years, school, plus per-position and per-school counts.","
WITH `roster` AS (
  SELECT *
  FROM `table_m_1764879224800_222fab6b_11734041_6`
)
SELECT
  '`' || `Player` || '`' AS `Player`,
  '`' || `No.(s)` || '`' AS `No.(s)`,
  '`' || `Height in Ft.` || '`' AS `Height in Ft.`,
  (CAST(substr(`Height in Ft.`, 1, instr(`Height in Ft.`, '-') - 1) AS INTEGER) * 12
   + CAST(substr(`Height in Ft.`, instr(`Height in Ft.`, '-') + 1) AS INTEGER)) AS `Height_in_inches`,
  '`' || `Position` || '`' AS `Position`,
  '`' || `Years for Rockets` || '`' AS `Years for Rockets`,
  '`' || `School/Club Team/Country` || '`' AS `School/Club Team/Country`,
  CASE WHEN `Years for Rockets` LIKE '%,%' THEN 1 ELSE 0 END AS `Multiple_stints`,
  CASE WHEN `Years for Rockets` LIKE '%2004%' THEN 1 ELSE 0 END AS `Was_on_2004`,
  COUNT(*) OVER (PARTITION BY `Position`) AS `Count_by_Position`,
  COUNT(*) OVER (PARTITION BY `School/Club Team/Country`) AS `Alumni_count`
FROM `roster`
WHERE
  -- Actionable subset: players on the roster in 2004, players with multiple stints, or players from colleges with >1 Rocket in this section
  `Years for Rockets` LIKE '%2004%'
  OR `Years for Rockets` LIKE '%,%'
  OR (
    SELECT COUNT(*) FROM `roster` AS `r2`
    WHERE `r2`.`School/Club Team/Country` = `roster`.`School/Club Team/Country`
  ) > 1
ORDER BY `Position`, `Height_in_inches` DESC, `Player`;
","
WITH `roster` AS (
  SELECT *
  FROM `table_m_1764879224800_222fab6b_11734041_6`
)
SELECT
  '`' || col0 || '`' AS col0,
  '`' || col1 || '`' AS col1,
  '`' || col2 || '`' AS col2,
  (CAST(substr(col2, 1, instr(col2, '-') - 1) AS INTEGER) * 12
   + CAST(substr(col2, instr(col2, '-') + 1) AS INTEGER)) AS `Height_in_inches`,
  '`' || col3 || '`' AS col3,
  '`' || col4 || '`' AS col4,
  '`' || col5 || '`' AS col5,
  CASE WHEN col4 LIKE '%,%' THEN 1 ELSE 0 END AS `Multiple_stints`,
  CASE WHEN col4 LIKE '%2004%' THEN 1 ELSE 0 END AS `Was_on_2004`,
  COUNT(*) OVER (PARTITION BY col3) AS `Count_by_Position`,
  COUNT(*) OVER (PARTITION BY col5) AS `Alumni_count`
FROM `roster`
WHERE
  -- Actionable subset: players on the roster in 2004, players with multiple stints, or players from colleges with >1 Rocket in this section
  col4 LIKE '%2004%'
  OR col4 LIKE '%,%'
  OR (
    SELECT COUNT(*) FROM `roster` AS `r2`
    WHERE `r2`.col5 = `roster`.col5
  ) > 1
ORDER BY col3, `Height_in_inches` DESC, col0;
","[('`Feitl, Dave Dave Feitl`', '`5`', '`7-0`', 84, '`Center`', '`1986-86, 1990-91`', '`Texas-El Paso`', 1, 0, 1, 1), ('`Francis, Steve Steve Francis`', '`3`', '`6-3`', 75, '`Guard`', '`1999-2004, 2007-08`', '`Maryland`', 1, 1, 1, 1)]",m_1764879224800_222fab6b_11734041-6,"As a historian assembling a 'Where were they in 2004?' feature I would ask conversationally but precisely about those three story hooks: 2004 presence, returns, and college ties. The SQL returns rows meeting those hooks, computes each player's height in inches, flags for multiple stints and 2004, and provides counts partitioned by position and by school. Mapping: the table supplies Player, No.(s), Height in Ft., Position, Years for Rockets, and School/Club Team/Country, which are used plus derived metrics. Draft question: For a 2004/returns/college-ties roundup, pull every player who was in 2004 or had multiple stints or comes from a college with more than one alum here, and give jersey, height (and inches), position, years, school, plus per-position and per-school counts.",persona,"Digital content producer and team historian for the Houston Rockets who creates roster-driven social content, alumni spotlights, and editorial pieces using the all-time roster database. They use the dataset to verify facts, pull player metadata (height, position, years), and identify narrative hooks (college ties, eras, notable returns). Goals: Quickly assemble accurate lists of players by position, era, or college for social posts and articles. Identify players who were on the roster in a particular year or range of years (e.g., to create a 'Where were they in 2004?' feature). Summarize roster composition (counts by position, common colleges) and pull physical attributes (height) for visual content. Verify jersey numbers and seasons for historical accuracy in editorial/caption copy. Example Queries: SELECT ""Player"", ""No.(s)"", ""Height in Ft."", ""Years for Rockets"", ""School/Club Team/Country"" FROM table_1_11734041_6 WHERE ""Position"" = 'Guard' ORDER BY ""Years for Rockets""; SELECT ""Position"", COUNT(*) AS player_count FROM table_1_11734041_6 GROUP BY ""Position"" ORDER BY player_count DESC; SELECT ""Player"", ""Years for Rockets"", ""School/Club Team/Country"" FROM table_1_11734041_6 WHERE ""Years for Rockets"" LIKE '%2004%' OR ""School/Club Team/Country"" ILIKE '%Maryland%' ORDER BY ""Player"";",N/A,add_column,
Which countries with below-average GDP per capita should be prioritized — show the top three by population?,"
SELECT '`' || `Country` || '`' AS `Country`,
`Population` AS `Population_raw`,
`Area (km²)`,
(REPLACE(`GDP per capita (nominal)`, '$', '') + 0) AS `GDP_per_capita_num`,
CASE WHEN (REPLACE(`GDP per capita (nominal)`, '$', '') + 0) < (SELECT AVG(REPLACE(`GDP per capita (nominal)`, '$', '') + 0) FROM `table_m_1764879256931_17b2b036_11780179_1`) THEN '`Priority`' ELSE '`Stable`' END AS `Recommendation`
FROM `table_m_1764879256931_17b2b036_11780179_1`
WHERE (REPLACE(`GDP per capita (nominal)`, '$', '') + 0) < (SELECT AVG(REPLACE(`GDP per capita (nominal)`, '$', '') + 0) FROM `table_m_1764879256931_17b2b036_11780179_1`) AND `Area (km²)` IS `Area (km²)`
GROUP BY `Country`
ORDER BY `Population` DESC
LIMIT 3;
","
SELECT '`' || col0 || '`' AS col0,
col1 AS `Population_raw`,
col2,
(REPLACE(col3, '$', '') + 0) AS `GDP_per_capita_num`,
CASE WHEN (REPLACE(col3, '$', '') + 0) < (SELECT AVG(REPLACE(col3, '$', '') + 0) FROM `table_m_1764879256931_17b2b036_11780179_1`) THEN '`Priority`' ELSE '`Stable`' END AS `Recommendation`
FROM `table_m_1764879256931_17b2b036_11780179_1`
WHERE (REPLACE(col3, '$', '') + 0) < (SELECT AVG(REPLACE(col3, '$', '') + 0) FROM `table_m_1764879256931_17b2b036_11780179_1`) AND col2 IS col2
GROUP BY col0
ORDER BY col1 DESC
LIMIT 3;
","[('`Uzbekistan`', 29559100.0, 447400.0, 1, '`Priority`'), ('`Kazakhstan`', 16967000.0, 2724900.0, 11, '`Priority`'), ('`Kyrgyzstan`', 5550239.0, 199900.0, 1, '`Priority`')]",m_1764879256931_17b2b036_11780179-1,"STEP 1: Parse the SQL intent — find countries whose GDP per capita (numeric) is below the table-wide average, compute numeric GDP per capita, mark them 'Priority', then order those results by Population descending and return the top 3. STEP 2: Determine ambiguity type — scope ambiguity fits: it's unclear whether the 'top three by population' applies to the entire table first or to the subset of below-average-GDP-per-capita countries. STEP 3: Draft the question — produce a natural-language question that matches one valid reading of the SQL but is ambiguous in that scope. STEP 4: Explain the ambiguity — the SQL interprets the scope as filtering for below-average GDP per capita first, then taking the top three by population; a different interpretation would take the top three most populous countries overall and then ask which of those have below-average GDP per capita (or should be prioritized).",reserved,24,N/A,split_column,"type: Scope ambiguity | explanation: The ambiguity is whether 'top three by population' applies after filtering for below-average GDP per capita (the SQL's interpretation: top three among the below-average group) or before filtering (an alternate reading: the top three most populous countries overall, then check which of those are below average and prioritized)."
"For each Unit, calculate 100 * (((the number before ' off ' in Killed) + (the number after ' off ' in Killed but before ' men')) + ((the number before ' off ' in Wounded) + (the number after ' off ' in Wounded but before ' men')) + ((the number before ' off ' in Missing) + (the number after ' off ' in Missing but before ' men'))) / (the number after ' off ' in Complement but before ' men'), and list the Unit and that percentage only for Units where that percentage > 5 and the Complement men (the number after ' off ' in Complement but before ' men') > 500?",unanswerable,unanswerable,,m_1764879282858_4d302bb1_11793221-4,"1) Parse intent: compute total casualties by summing officer and men counts from Killed, Wounded and Missing, divide by the Complement's men count and multiply by 100, then filter by >5% and Complement men >500. 2) Map schema: extraction uses the substring before ' off ' and the substring between ' off ' and ' men' (or ' man'). 3) Draft: request Unit and computed percent for units meeting both thresholds. 4) Validate: include explicit mention of Killed, Wounded, Missing, Complement, extraction rules, arithmetic and both WHERE conditions.",reserved,4,N/A,merge_column,
"For each River Cottage DVD, show how many releases came out in the same year and how many share the same aspect ratio, and tell me whether that release’s runtime is at/above or below the average runtime for its release year?",unanswerable,unanswerable,,m_1764879296242_6a421e65_1180228-1,"I need counts to plan bundles and promos but won't use SQL terms; I'll ask for how many releases share a year or format plus runtime comparison to the year average. The query returns counts of releases per year and per aspect ratio, plus a per-year runtime comparison label and a runtime rank. The schema gives Released, Aspect Ratio and Duration parsed to minutes. Draft question: ask for each release the number of releases in the same year and in the same aspect ratio, and whether its runtime is above or below that year’s average. Validate: this stays within the query's computed fields and doesn't request extra data.",persona,"Home entertainment product manager for a DVD retailer responsible for acquiring, pricing and merchandising physical releases; uses this database to evaluate River Cottage DVD catalogue for stocking and promotional decisions. Goals: Identify which River Cottage DVDs are multi-disc or have the longest runtimes to inform pricing and shelf placement. Compare releases by format/aspect ratio and release year to decide which editions to stock for different customer segments. Assess episode counts and average episodes-per-release to plan box-set bundles and promotional copy. Example Queries: SELECT ""DVD Name"", ""Released"", ""Num of Discs"", ""Duration"" 
FROM table_1_1180228_1 
WHERE ""Num of Discs"" > 1 
ORDER BY ""Num of Discs"" DESC, ""Released""; SELECT YEAR(STR_TO_DATE(""Released"", '%d/%m/%Y')) AS release_year, COUNT(*) AS releases, AVG(""Number of Episodes"") AS avg_episodes
FROM table_1_1180228_1
GROUP BY release_year
ORDER BY release_year; SELECT ""DVD Name"", ""Duration"", (
  CAST(SUBSTRING_INDEX(""Duration"", ' hours', 1) AS UNSIGNED) * 60
  + CAST(REPLACE(SUBSTRING_INDEX(""Duration"", ' hours ', -1), ' minutes', '') AS UNSIGNED)
) AS total_minutes
FROM table_1_1180228_1
ORDER BY total_minutes DESC
LIMIT 5;",N/A,merge_column,
"For each director (`Directed by`) who directed more than one episode (COUNT(Title) > 1) and only considering episodes with `U.S. viewers (millions)` > 2.5 and `No. in season` > 0, what is the director's name, the count of titles they directed, the average `U.S. viewers (millions)` rounded to two decimal places, the difference between the maximum and minimum `U.S. viewers (millions)` rounded to two decimal places, and the list of their `Title` values concatenated with ' | ' as the separator, returning up to 10 directors?",unanswerable,unanswerable,,m_1764879309027_2218fef8_11820086-1,"1) Parse intent: aggregate episode data by director for episodes with U.S. viewers > 2.5 and No. in season > 0, keeping only directors with more than one episode and limiting to 10. 2) Map schema: `Directed by` is the director, `Title` is episode title, `U.S. viewers (millions)` is the numeric metric to average and range. 3) Draft: ask for director, count of titles, avg viewers rounded to 2 decimals, viewer range rounded to 2 decimals, and titles joined with ' | '. 4) Validate: ensure filters, grouping, HAVING and LIMIT are referenced.",reserved,8,N/A,remove_column,
"For each artist, compute number of vocal (non-instrumental) tracks, total vocal seconds and total vocal minutes (rounded), count of vocal clips ≤3:30, count of instrumental clips ≤3:30, and list the short vocal clips as ""Disc-Track: English / Japanese / Rōmaji / Track time (Ns)"".","
WITH `times` AS (
  SELECT
    `Disc`,
    `Track`,
    `English title`,
    `Japanese title`,
    `Rōmaji title`,
    `Artist`,
    `Track time`,
    (CAST(substr(`Track time`, 1, instr(`Track time`, ':')-1) AS integer) * 60
     + CAST(substr(`Track time`, instr(`Track time`, ':')+1) AS integer)
    ) AS `seconds`,
    CASE WHEN `Artist` = (SELECT `Artist` FROM `table_m_1764879320291_5f255232_11839306_2` WHERE `Track` = 6) THEN 1 ELSE 0 END AS `is_instrumental`
  FROM `table_m_1764879320291_5f255232_11839306_2`
)
SELECT
  `Artist`,
  SUM(CASE WHEN `is_instrumental` = 0 THEN 1 ELSE 0 END) AS `vocal_count`,
  SUM(CASE WHEN `is_instrumental` = 0 THEN `seconds` ELSE 0 END) AS `total_vocal_seconds`,
  ROUND(SUM(CASE WHEN `is_instrumental` = 0 THEN `seconds` ELSE 0 END) / 60.0, 2) AS `total_vocal_minutes`,
  SUM(CASE WHEN `is_instrumental` = 0 AND `seconds` <= 210 THEN 1 ELSE 0 END) AS `short_vocal_clips_count`,
  SUM(CASE WHEN `is_instrumental` = 1 AND `seconds` <= 210 THEN 1 ELSE 0 END) AS `short_instrumental_count`,
  group_concat(
    CASE WHEN `is_instrumental` = 0 AND `seconds` <= 210 THEN
      (`Disc` || '-' || `Track` || ': ' || `English title` || ' / ' || `Japanese title` || ' / ' || `Rōmaji title` || ' / ' || `Track time` || ' (' || `seconds` || 's)')
    END, '; '
  ) AS `short_vocal_clips`
FROM `times`
GROUP BY `Artist`
ORDER BY `total_vocal_seconds` DESC;
","
WITH `times` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    (CAST(substr(col6, 1, instr(col6, ':')-1) AS integer) * 60
     + CAST(substr(col6, instr(col6, ':')+1) AS integer)
    ) AS `seconds`,
    CASE WHEN col5 = (SELECT col5 FROM `table_m_1764879320291_5f255232_11839306_2` WHERE col1 = 6) THEN 1 ELSE 0 END AS `is_instrumental`
  FROM `table_m_1764879320291_5f255232_11839306_2`
)
SELECT
  col5,
  SUM(CASE WHEN `is_instrumental` = 0 THEN 1 ELSE 0 END) AS `vocal_count`,
  SUM(CASE WHEN `is_instrumental` = 0 THEN `seconds` ELSE 0 END) AS `total_vocal_seconds`,
  ROUND(SUM(CASE WHEN `is_instrumental` = 0 THEN `seconds` ELSE 0 END) / 60.0, 2) AS `total_vocal_minutes`,
  SUM(CASE WHEN `is_instrumental` = 0 AND `seconds` <= 210 THEN 1 ELSE 0 END) AS `short_vocal_clips_count`,
  SUM(CASE WHEN `is_instrumental` = 1 AND `seconds` <= 210 THEN 1 ELSE 0 END) AS `short_instrumental_count`,
  group_concat(
    CASE WHEN `is_instrumental` = 0 AND `seconds` <= 210 THEN
      (col0 || '-' || col1 || ': ' || col2 || ' / ' || col3 || ' / ' || col4 || ' / ' || col6 || ' (' || `seconds` || 's)')
    END, '; '
  ) AS `short_vocal_clips`
FROM `times`
GROUP BY col5
ORDER BY `total_vocal_seconds` DESC;
","[('Picasso', 7, 1751, 29.18, 0, 0, None), ('Kyoko Otonashi', 4, 946, 15.77, 0, 0, None), ('Takao Kisugi', 2, 525, 8.75, 0, 0, None), ('Yuki Saito', 2, 524, 8.73, 0, 0, None), ('Kiyonori Matsuo', 2, 423, 7.05, 1, 0, '8.0-16.0: Younger Girl / ヤンガーガール / Yangā Gāru / 3:15 (195s)'), (""Gilbert O'Sullivan"", 2, 378, 6.3, 1, 0, '4.0-8.0: Get Down / ゲット・ダウン / Getto Daun / 2:38 (158s)'), ('Anzen Chitai', 2, 329, 5.48, 2, 0, '7.0-13.0: I Love You / 好きさ / Suki sa / 2:49 (169s); 7.0-14.0: Enveloped in Memories / 思い出につつまれて / Omoide ni Tsutsumarete / 2:40 (160s)'), ('Rika Himenogi', 1, 268, 4.47, 0, 0, None), ('Kōzō Murashita', 1, 245, 4.08, 0, 0, None), ('Instrumental', 0, 0, 0.0, 0, 1, None)]",m_1764879320291_5f255232_11839306-2,"I frequently need per-vocalist playtime and short-clip inventories to design batches and conditioning sets, so I'll ask for artist-level summaries including short-clip details. The SQL intent is to aggregate non-instrumental tracks per Artist, sum their durations (parsed from mm:ss), count short vocal and instrumental tracks ≤210 seconds, and list short vocal entries with titles and seconds. Schema mapping: Disc/Track identify the track, titles come in English/Japanese/Rōmaji, Artist labels tracks, and Track time is parsed into seconds. Draft question: For each Artist, compute the number of vocal tracks, total vocal seconds and minutes (rounded), counts of vocal clips ≤3:30 and instrumental clips ≤3:30, and output the short vocal clips as ""Disc-Track: English / Japanese / Rōmaji / Track time (Ns)"". Validation: The question only requests per-artist aggregates and the formatted short-vocal list that the query returns.",persona,"An experimental vocal-synthesis engineer building a phoneme-aligned training corpus from Maison Ikkoku CD singles who uses the Rōmaji/Japanese title pairs and precise track timings to create time-aligned utterances and backing stems. Goals: Assemble a clean set of sung vocal excerpts (exclude instrumentals) with both Japanese script and Rōmaji to map grapheme-to-phoneme for synthesis training. Compute exact durations (in seconds) and total playtime for chosen singer/character tracks to design segment boundaries and training batches. Find short vocal clips and instrumental beds (<= 3:30) suitable for phoneme extraction, tempo analysis, or background-conditioning of the synthesizer. Example Queries: /* 1) Get all non-instrumental tracks with Japanese + Rōmaji and convert Track time to seconds (Postgres-style) */
SELECT ""Disc"", ""Track"", ""English title"", ""Japanese title"", ""Rōmaji title"", ""Artist"",
       (split_part(""Track time"", ':', 1)::int * 60 + split_part(""Track time"", ':', 2)::int) AS seconds
FROM table_1_11839306_2
WHERE ""Artist"" <> 'Instrumental'
ORDER BY ""Disc"", ""Track""; /* 2) Total duration (seconds and minutes) of all tracks credited to the character/singer 'Kyoko Otonashi' for batch sizing */
SELECT SUM(split_part(""Track time"", ':', 1)::int * 60 + split_part(""Track time"", ':', 2)::int) AS total_seconds,
       ROUND(SUM(split_part(""Track time"", ':', 1)::int * 60 + split_part(""Track time"", ':', 2)::int) / 60.0, 2) AS total_minutes
FROM table_1_11839306_2
WHERE ""Artist"" = 'Kyoko Otonashi'; /* 3) Fetch short (<= 3:30) clips and explicitly list instrumentals for background-conditioning / phoneme isolation */
SELECT ""Disc"", ""Track"", ""English title"", ""Japanese title"", ""Rōmaji title"", ""Artist"", ""Track time""
FROM table_1_11839306_2
WHERE (split_part(""Track time"", ':', 1)::int * 60 + split_part(""Track time"", ':', 2)::int) <= 210
ORDER BY ""Artist"", ""Track time"";",N/A,add_column,
"Can you give counts of incoming players by position and EU status, and also list all signings aged 21 or younger with their age, type, origin, transfer window, contract end date and fee?",unanswerable,unanswerable,,m_1764879332552_a754f1a2_11891841-2,"I routinely split recruitment patterns by position and EU status and also extract a shortlist of youth signings (≤21) to study long-term ROI. The SQL groups counts by P and EU to show position/EU breakdowns, and separately selects players with Age <= 21 returning Name, Age and a concatenated text with Type, Moving from, Transfer window, Ends and Transfer fee. This maps to the P, EU, Age, Name, Type, Moving from, Transfer window, Ends and Transfer fee columns in the table. Can you give counts of incoming players by position and EU status, and also list all signings aged 21 or younger with their age, type, origin, transfer window, contract end date and fee? That matches the GROUP BY and the young_signings selection in the query.",persona,"Transfer market analyst at a sports analytics firm who researches historical signing patterns and valuation benchmarks for top European clubs. They use this database to extract structured details (ages, fees, origins, contract end dates) from Barcelona's 2007–08 incoming transfers to model market trends and player ROI. Goals: Calculate historical aggregate and average transfer spending for permanent incoming transfers to benchmark against other seasons and clubs. Identify recruitment patterns by position, nationality/EU status, and age (e.g., youth promotions vs. external signings). Extract a shortlist of young signings and promotions (≤21) to evaluate long-term investment outcomes and correlation with transfer fee or source club. Example Queries: /* Total and average transfer spend (extracting the primary '€#M' value) for permanent transfers */
SELECT
  COUNT(*) AS transfers_count,
  SUM((regexp_replace(""Transfer fee"", '.*€([0-9]+(\.[0-9]+)?)M.*', '\1')::numeric) * 1000000) AS total_spend_eur,
  AVG((regexp_replace(""Transfer fee"", '.*€([0-9]+(\.[0-9]+)?)M.*', '\1')::numeric) * 1000000) AS avg_spend_eur
FROM ""table_1_11891841_2""
WHERE ""Type"" = 'Transfer' AND ""Transfer fee"" ~ '€'; /* Count incoming players by position and EU status to spot recruitment emphasis */
SELECT
  ""P"" AS position,
  ""EU"",
  COUNT(*) AS player_count
FROM ""table_1_11891841_2""
GROUP BY ""P"", ""EU""
ORDER BY player_count DESC, ""P""; /* List all signings and promotions aged 21 or younger with basic contract/fee info */
SELECT
  ""Name"",
  ""Age"",
  ""Type"",
  ""Moving from"",
  ""Transfer window"",
  ""Ends"",
  ""Transfer fee""
FROM ""table_1_11891841_2""
WHERE ""Age"" <= 21
ORDER BY ""Age"" ASC, ""Name"";",N/A,remove_column,
"What's the proof mintage summary for the series: the total proof mintage, the average proof mintage, and the largest single proof mintage?","
SELECT 'Proof Mintage Summary' AS `Insight`, 455174 AS `Total Proof Mintage`, 455174/10.0 AS `Average Proof Mintage`, MAX(121575,89390,29688,9994,24527,65000,20000,65000,25000,5000) AS `Max Single Proof Mintage` WHERE 1=1 AND 121575>0 GROUP BY `Insight` ORDER BY `Total Proof Mintage` DESC LIMIT 1;
","
SELECT 'Proof Mintage Summary' AS `Insight`, 455174 AS `Total Proof Mintage`, 455174/10.0 AS `Average Proof Mintage`, MAX(121575,89390,29688,9994,24527,65000,20000,65000,25000,5000) AS `Max Single Proof Mintage` WHERE 1=1 AND 121575>0 GROUP BY `Insight` ORDER BY `Total Proof Mintage` DESC LIMIT 1;
","[('Proof Mintage Summary', 455174, 45517.4, 121575)]",m_1764879350612_75b330e0_11916083-1,"STEP 1: Parse the SQL intent — The query returns a single summary row labeled 'Proof Mintage Summary' with hard-coded aggregates: Total Proof Mintage = 455,174, Average Proof Mintage = 455,174 / 10.0, and Max Single Proof Mintage = 121,575 (computed from the listed numeric proof mintages). It groups by the constant Insight and limits to one row. STEP 2: Determine a fitting ambiguity type — Scope ambiguity fits best: the SQL computes an average by dividing the numeric total by 10 (i.e., only the 10 numeric proof-mintage entries are counted), but a plain NL question could be read as asking for an average over all rows, or per year, or including N/A as zeros. This ambiguity maps well to how averages/totals can be scoped. STEP 3: Draft the question — ""What's the proof mintage summary for the series: the total proof mintage, the average proof mintage, and the largest single proof mintage?"" STEP 4: Explain the ambiguity — In the original query the average is the total (455,174) divided by 10 numeric entries and the max is the largest numeric mintage (121,575). The NL question is ambiguous because ""average"" and ""for the series"" could instead mean average over every table row (including N/A rows), average per year (if years have multiple issues), or average treating missing values as zero, yielding different numeric results.",reserved,8,N/A,merge_column,"type: Scope ambiguity | explanation: The SQL treats the average as total 455,174 divided by 10 numeric proof-mintage entries (excluding N/A), and max as the largest numeric value (121,575). The posed question is ambiguous because ""average"" and ""for the series"" could alternatively be interpreted as averaging over all table rows (including N/As), averaging per year if multiple issues exist in a year, or treating missing values as zero — each interpretation would change the computed average/total."
"Which First Class Team values (up to five) among players whose Bowling Style contains 'arm' have at least one pace bowler, and for each such First Class Team what is the number of players, the number of pace bowlers (Bowling Style contains 'fast'), the number of off spinners (Bowling Style contains 'off'), and the number of leg spinners (Bowling Style contains 'leg')?",unanswerable,unanswerable,,m_1764879359049_f33b80f4_11950720-3,"1) Parse: the query aggregates players by First Class Team among rows with 'arm' in Bowling Style, counts players and counts of 'fast','off','leg' occurrences, filters to teams with any 'fast' and limits to 5 rows. 2) Map: use Bowling Style substrings to classify pace/off/leg spinners and First Class Team as group label. 3) Draft a question that requests these aggregates and mentions the 'arm' filter, the having condition and the 5-limit. 4) Validate that every column and calculation from the SQL is present in the question.",reserved,7,N/A,merge_column,
"List up to 5 Directed by entries for Season # = 1 where Original air date <> '', showing for each the Episode Count (COUNT(*)), MIN(Series #) labeled ""Change, Change, Change"", MAX(Series #) labeled ""Drop Dead Gorgeous"", and the Titles joined by ' | ' as ""Pipeline"", including only groups with Episode Count > 0 and ordered by Episode Count descending?",unanswerable,unanswerable,,m_1764879375047_7bcc931e_11951237-4,"1) Parse SQL intent: group episodes by Directed by for Season # = 1 with Original air date not blank, compute COUNT(*) (Episode Count), MIN(Series #) named ""Change, Change, Change"", MAX(Series #) named ""Drop Dead Gorgeous"", and GROUP_CONCAT(Title, ' | ') named ""Pipeline"", then filter groups with Episode Count > 0, sort by Episode Count desc and limit to 5. 2) Map schema: use Directed by, Series #, Title, and Original air date columns. 3) Draft a question that requests these aggregates and constraints. 4) Validate that all aliases, separator, filters, grouping, having, ordering, and limit are mentioned.",reserved,11,N/A,merge_column,
"For games with Game IN (16,17,18,19,20,21,22,23,24,25,26,27), grouped by Location Attendance (Arena), what are the Arena name, the average attendance computed by converting the attendance portion of Location Attendance to a number (remove commas), the total Wins (Score starting with 'W'), the total Losses (Score starting with 'L'), and the maximum high points value obtained by extracting the number inside parentheses in High points; only include arenas where Wins >= 1 and the maximum parsed High points > 20 or where Losses > 0, order the results by the average attendance descending and limit the output to 5 arenas?","
SELECT `Location Attendance` Arena,
AVG(REPLACE(SUBSTR(`Location Attendance`, INSTR(`Location Attendance`,' ')+1), ',', '')+0) AS `AvgAttendance`,
SUM(SUBSTR(`Score`,1,1)='W') Wins,
SUM(SUBSTR(`Score`,1,1)='L') Losses,
MAX(SUBSTR(`High points`, INSTR(`High points`,'(')+1, INSTR(`High points`,')')-INSTR(`High points`,'(')-1)+0) MaxHighPoints
FROM `table_m_1764879408067_b217cb44_11961582_4`
WHERE `Game` IN (16,17,18,19,20,21,22,23,24,25,26,27)
GROUP BY `Location Attendance`
HAVING SUM(SUBSTR(`Score`,1,1)='W')>=1 AND MAX(SUBSTR(`High points`, INSTR(`High points`,'(')+1, INSTR(`High points`,')')-INSTR(`High points`,'(')-1)+0)>20 OR SUM(SUBSTR(`Score`,1,1)='L')>0
ORDER BY `AvgAttendance` DESC
LIMIT 5;
","
SELECT col6 Arena,
AVG(REPLACE(SUBSTR(col6, INSTR(col6,' ')+1), ',', '')+0) AS `AvgAttendance`,
SUM(SUBSTR(col2,1,1)='W') Wins,
SUM(SUBSTR(col2,1,1)='L') Losses,
MAX(SUBSTR(col3, INSTR(col3,'(')+1, INSTR(col3,')')-INSTR(col3,'(')-1)+0) MaxHighPoints
FROM `table_m_1764879408067_b217cb44_11961582_4`
WHERE col0 IN (16,17,18,19,20,21,22,23,24,25,26,27)
GROUP BY col6
HAVING SUM(SUBSTR(col2,1,1)='W')>=1 AND MAX(SUBSTR(col3, INSTR(col3,'(')+1, INSTR(col3,')')-INSTR(col3,'(')-1)+0)>20 OR SUM(SUBSTR(col2,1,1)='L')>0
ORDER BY `AvgAttendance` DESC
LIMIT 5;
","[('Wachovia Center 11,465', 0.0, 1, 0, 22), ('Verizon Center 16,472', 0.0, 1, 0, 32), ('The Palace of Auburn Hills 22,076', 0.0, 0, 1, 23), ('Philips Arena 17,069', 0.0, 1, 0, 26), ('Philips Arena 16,070', 0.0, 1, 0, 26)]",m_1764879408067_b217cb44_11961582-4,"1) Parse the SQL intent: for games 16–27 compute per-arena average parsed attendance, count wins and losses from Score's first char, and find the max numeric value inside High points parentheses, then filter using the HAVING logic and limit to five by highest average attendance. 2) Map schema semantics: Location Attendance holds venue and attendance with commas, Score indicates result by its first letter, High points embeds the number in parentheses. 3) Draft the question to request those aggregated values and to state the precise filters, sorting, and limit. 4) Validate: confirm all SQL elements (Game list, parsing rules, counts, max, HAVING, ORDER BY, LIMIT) are reflected.",reserved,13,N/A,remove_column,
"For each Home value, can you provide Venue = Home, Games = COUNT(*), Wins = SUM(substr(Score,1,1) = 'W'), Losses = SUM(substr(Score,1,1) = 'L'), and AvgTopPoints = AVG(substr(Leading scorer, instr(Leading scorer, ':')+2)), grouped by Home and ordered by Wins descending, limited to the top 5 rows?","SELECT `Home` AS Venue, COUNT(*) AS Games, SUM(CASE WHEN substr(`Score`,1,1) = 'W' THEN 1 ELSE 0 END) AS Wins, SUM(CASE WHEN substr(`Score`,1,1) = 'L' THEN 1 ELSE 0 END) AS Losses, AVG(CAST(substr(`Leading scorer`, instr(`Leading scorer`, ':')+2) AS REAL)) AS AvgTopPoints FROM `table_m_1764879438835_940de67c_11964047_8` GROUP BY `Home` ORDER BY Wins DESC LIMIT 5;","SELECT col3 AS Venue, COUNT(*) AS Games, SUM(CASE WHEN substr(col2,1,1) = 'W' THEN 1 ELSE 0 END) AS Wins, SUM(CASE WHEN substr(col2,1,1) = 'L' THEN 1 ELSE 0 END) AS Losses, AVG(CAST(substr(col4, instr(col4, ':')+2) AS REAL)) AS AvgTopPoints FROM `table_m_1764879438835_940de67c_11964047_8` GROUP BY col3 ORDER BY Wins DESC LIMIT 5;","[('Portland Trail Blazers', 6, 3, 3, 25.833333333333332), ('Los Angeles Clippers', 1, 1, 0, 32.0), ('Seattle SuperSonics', 1, 0, 1, 26.0), ('Los Angeles Lakers', 1, 0, 1, 30.0), ('Indiana Pacers', 1, 0, 1, 29.0)]",m_1764879438835_940de67c_11964047-8,"1) Parse SQL intent: group games by Home to compute Games, Wins (Score starts 'W'), Losses (Score starts 'L'), and average numeric top-scorer points parsed after ':'; then order by Wins descending and limit to 5. 2) Map schema: Home is venue, Score and Leading scorer supply W/L and points. 3) Draft: request those exact aggregates and sorting/limit. 4) Validate: all expressions and grouping/ordering/limit are present.",reserved,12,N/A,remove_column,
"How many finals were there, how many different champions have there been, what was the average and highest final attendance, and how many finals went to penalties?","
SELECT COUNT(`Season`) `Total Finals`, COUNT(DISTINCT `FinalOutcome (WinningTeam and Score)`) `Unique Champions`, AVG(`Cup Final Attendance`) `Average Attendance`, MAX(`Cup Final Attendance`) `Max Attendance`, SUM(instr(`FinalOutcome (WinningTeam and Score)`,'Penalties')>0) `Penalty Finals` FROM `table_m_1764879461012_ecff0732_12028543_3` WHERE `Cup Final Attendance`>0 LIMIT 1;
","
SELECT COUNT(col0) `Total Finals`, COUNT(DISTINCT col5) `Unique Champions`, AVG(col4) `Average Attendance`, MAX(col4) `Max Attendance`, SUM(instr(col5,'Penalties')>0) `Penalty Finals` FROM `table_m_1764879461012_ecff0732_12028543_3` WHERE col4>0 LIMIT 1;
","[(17, 17, 7190.470588235294, 11187.0, 2)]",m_1764879461012_ecff0732_12028543-3,"STEP 1: Parse the SQL intent — The query restricts to rows where Cup Final Attendance > 0 and returns aggregates: COUNT(Season) as Total Finals, COUNT(DISTINCT WinningTeam) as Unique Champions, AVG(Cup Final Attendance) as Average Attendance, MAX(Cup Final Attendance) as Max Attendance, and SUM(instr(Score,'Penalties')>0) as Penalty Finals. STEP 2: Choose an ambiguity type — Entity vagueness fits: the WinningTeam values include parenthetical title counts (e.g. 'Brisbane City (1)'), so ""champions"" could mean club identity or the exact stored strings. STEP 3: Draft the question — ""How many finals were there, how many different champions have there been, what was the average and highest final attendance, and how many finals went to penalties?"" STEP 4: Explain the ambiguity — In the original query Unique Champions is COUNT(DISTINCT WinningTeam) which treats each stored WinningTeam string (including parenthetical annotations) as distinct; alternatively the question could ask for distinct club names ignoring the annotations (grouping 'Brisbane City (1)' and 'Brisbane City (2)' as the same club), yielding a different count.",reserved,5,N/A,merge_column,"type: Entity Vagueness | explanation: The phrase 'different champions' is ambiguous: the SQL counts distinct WinningTeam strings (so annotated variants like 'Brisbane City (1)' and 'Brisbane City (2)' are treated as separate champions), whereas a natural interpretation might count unique club names ignoring parenthetical title counts, producing a different result."
"Which distinct entries from the 'Directed by' column (returned as 'Director') have a Production code matching the pattern '1ADK-%', when ordered by Director and limited to 3 results?","
SELECT DISTINCT `Directed by` AS `Director` FROM `table_m_1764879468368_ec909e40_12033013_1` WHERE `Production code` LIKE '1ADK-%' AND 1=1 ORDER BY `Director` LIMIT 3;
","
SELECT DISTINCT col2 AS `Director` FROM `table_m_1764879468368_ec909e40_12033013_1` WHERE col5 LIKE '1ADK-%' AND 1=1 ORDER BY `Director` LIMIT 3;
","[('David Lee',), ('Howard Murray',), ('Jack Kenny',)]",m_1764879468368_ec909e40_12033013-1,"1) Parse SQL intent: fetch distinct values from 'Directed by' aliased as Director with a WHERE clause 'Production code' LIKE '1ADK-%', order results by Director and limit to 3. 2) Map schema semantics: use 'Directed by' for names and 'Production code' for filtering by the '1ADK-%' pattern. 3) Draft a concise question that requests those distinct director names with the specified ordering and limit. 4) Validate that the question explicitly mentions DISTINCT, the alias 'Director', the LIKE filter '1ADK-%', ORDER BY Director, and LIMIT 3.",reserved,10,N/A,add_column,
"Which episodes have any of these problems — multi-episode numbering (slashes), an original air date missing a space, a production code that doesn't start with '3', or director/writer fields lacking proper delimiters?","
WITH `t` AS (
  SELECT
    `episode_number_in_series`,
    `episode_number_in_season`,
    `Title`,
    `Directed by`,
    `Written by`,
    `air_date`,
    `Production code`,
    CASE WHEN instr(`episode_number_in_series`, '/') > 0 OR instr(`episode_number_in_season`, '/') > 0 THEN 1 ELSE 0 END AS `MultiEpisode`,
    CASE WHEN instr(`air_date`, ' ') = 0 THEN 1 ELSE 0 END AS `AirDateMissingSpace`,
    CASE WHEN cast(substr(`Production code`, 1, 1) AS integer) != 3 THEN 1 ELSE 0 END AS `ProdSeasonMismatch`,
    CASE WHEN `Directed by` NOT LIKE '%,%' AND `Directed by` NOT LIKE '%&%' AND `Directed by` LIKE '% % %' THEN 1 ELSE 0 END AS `DirectorDelimiterIssue`,
    CASE WHEN `Written by` NOT LIKE '%,%' AND `Written by` NOT LIKE '%&%' AND `Written by` LIKE '% % %' THEN 1 ELSE 0 END AS `WriterDelimiterIssue`,
    cast(
      CASE
        WHEN instr(`episode_number_in_season`, '/') > 0 THEN substr(`episode_number_in_season`, 1, instr(`episode_number_in_season`, '/') - 1)
        ELSE `episode_number_in_season`
      END
    AS integer) AS `SeasonFromNoInSeason`,
    substr(`Production code`, 1, 1) AS `ProdSeasonChar`
  FROM `table_m_1764879475085_b926b6d3_12033013_3`
)
SELECT
  '`' || `episode_number_in_series` || '`' AS `episode_number_in_series`,
  '`' || `episode_number_in_season` || '`' AS `episode_number_in_season`,
  '`' || `Title` || '`' AS `Title`,
  '`' || `Directed by` || '`' AS `Directed by`,
  '`' || `Written by` || '`' AS `Written by`,
  '`' || `air_date` || '`' AS `air_date`,
  '`' || `Production code` || '`' AS `Production code`,
  `MultiEpisode`,
  `AirDateMissingSpace`,
  `ProdSeasonMismatch`,
  `DirectorDelimiterIssue`,
  `WriterDelimiterIssue`,
  `SeasonFromNoInSeason`,
  `ProdSeasonChar`
FROM `t`
WHERE `MultiEpisode` = 1
   OR `AirDateMissingSpace` = 1
   OR `ProdSeasonMismatch` = 1
   OR `DirectorDelimiterIssue` = 1
   OR `WriterDelimiterIssue` = 1
;
","
WITH `t` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    col6,
    CASE WHEN instr(col0, '/') > 0 OR instr(col1, '/') > 0 THEN 1 ELSE 0 END AS `MultiEpisode`,
    CASE WHEN instr(col5, ' ') = 0 THEN 1 ELSE 0 END AS `AirDateMissingSpace`,
    CASE WHEN cast(substr(col6, 1, 1) AS integer) != 3 THEN 1 ELSE 0 END AS `ProdSeasonMismatch`,
    CASE WHEN col3 NOT LIKE '%,%' AND col3 NOT LIKE '%&%' AND col3 LIKE '% % %' THEN 1 ELSE 0 END AS `DirectorDelimiterIssue`,
    CASE WHEN col4 NOT LIKE '%,%' AND col4 NOT LIKE '%&%' AND col4 LIKE '% % %' THEN 1 ELSE 0 END AS `WriterDelimiterIssue`,
    cast(
      CASE
        WHEN instr(col1, '/') > 0 THEN substr(col1, 1, instr(col1, '/') - 1)
        ELSE col1
      END
    AS integer) AS `SeasonFromNoInSeason`,
    substr(col6, 1, 1) AS `ProdSeasonChar`
  FROM `table_m_1764879475085_b926b6d3_12033013_3`
)
SELECT
  '`' || col0 || '`' AS col0,
  '`' || col1 || '`' AS col1,
  '`' || col2 || '`' AS col2,
  '`' || col3 || '`' AS col3,
  '`' || col4 || '`' AS col4,
  '`' || col5 || '`' AS col5,
  '`' || col6 || '`' AS col6,
  `MultiEpisode`,
  `AirDateMissingSpace`,
  `ProdSeasonMismatch`,
  `DirectorDelimiterIssue`,
  `WriterDelimiterIssue`,
  `SeasonFromNoInSeason`,
  `ProdSeasonChar`
FROM `t`
WHERE `MultiEpisode` = 1
   OR `AirDateMissingSpace` = 1
   OR `ProdSeasonMismatch` = 1
   OR `DirectorDelimiterIssue` = 1
   OR `WriterDelimiterIssue` = 1
;
","[('`34`', '`1`', '`""Racing in the Streets""`', '`Brian Hargrove`', '`Chris Sheridan`', '`November14,2001`', '`3ADK-01`', 0, 1, 0, 0, 0, 1, '3'), ('`35`', '`2`', '`""Amy\'s Birthday""`', '`Gary Shimokawa`', '`John R. Morey`', '`November21,2001`', '`3ADK-03`', 0, 1, 0, 0, 1, 2, '3'), ('`36`', '`3`', '`""Tommy\'s Not Gay""`', '`Gary Shimokawa`', '`Christopher Case`', '`November28,2001`', '`3ADK-04`', 0, 1, 0, 0, 0, 3, '3'), ('`37`', '`4`', '`""Shannon\'s Song""`', '`Joe Regalbuto`', '`Sally Lapiduss`', '`December5,2001`', '`3ADK-08`', 0, 1, 0, 0, 0, 4, '3'), ('`38`', '`5`', '`""Grad School""`', '`Gary Shimokawa`', '`Jennifer Fisher`', '`December12,2001`', '`3ADK-02`', 0, 1, 0, 0, 0, 5, '3'), ('`39`', '`6`', '`""Houseboat""`', '`Joe Regalbuto`', '`Jim Hope`', '`December19,2001`', '`3ADK-06`', 0, 1, 0, 0, 0, 6, '3'), ('`40`', '`7`', '`""The Trial""`', '`Jack Kenny`', '`Christopher Titus`', '`January2,2002`', '`3ADK-05`', 0, 1, 0, 0, 0, 7, '3'), ('`41`', '`8`', '`""Grandma Titus""`', '`Brian Hargrove`', '`Shawn Thomas`', '`January9,2002`', '`2ADK-25`', 0, 1, 1, 0, 0, 8, '2'), ('`42`', '`9`', '`""Errrr""`', '`Jack Kenny`', '`Chris Sheridan`', '`January16,2002`', '`3ADK-13`', 0, 1, 0, 0, 0, 9, '3'), ('`43`', '`10`', '`""Tommy\'s Crush""`', '`Kevin Rodney Sullivan`', '`Patrick Meighan`', '`January23,2002`', '`3ADK-09`', 0, 1, 0, 1, 0, 10, '3'), ('`44`', '`11`', '`""Into Thin Air""`', '`John Amodeo`', '`Robert Hawkins`', '`January30,2002`', '`3ADK-11`', 0, 1, 0, 0, 0, 11, '3'), ('`45`', '`12`', '`""Too Damn Good""`', '`Gary Shimokawa`', '`David L. Moses`', '`February6,2002`', '`3ADK-16`', 0, 1, 0, 0, 1, 12, '3'), ('`46`', '`13`', '`""Bachelor Party""`', '`Leslie Kolins Small`', '`Jennifer Fisher`', '`February13,2002`', '`3ADK-15`', 0, 1, 0, 1, 0, 13, '3'), ('`47`', '`14`', '`""Hot Streak""`', '`Joe Regalbuto`', '`Patrick Meighan & John R. Morey`', '`February20,2002`', '`3ADK-14`', 0, 1, 0, 0, 0, 14, '3'), ('`48`', '`15`', '`""The Session""`', '`Brian Hargrove`', '`Matt Ember`', '`March6,2002`', '`3ADK-10`', 0, 1, 0, 0, 0, 15, '3'), ('`49`', '`16`', '`""Same Courtesy""`', '`Bill Shea`', '`Christopher Case`', '`March20,2002`', '`3ADK-12`', 0, 1, 0, 0, 0, 16, '3'), ('`50`', '`17`', '`""After Mrs. Shafter""`', '`Bill Shea`', '`Shawn Thomas`', '`July29,2002`', '`3ADK-17`', 0, 1, 0, 0, 0, 17, '3'), ('`51`', '`18`', '`""The Visit""`', '`Katy Garretson`', '`Christopher Titus`', '`July29,2002`', '`3ADK-18`', 0, 1, 0, 0, 0, 18, '3'), ('`52/53`', '`19/20`', '`""Insanity Genetic""`', '`Kevin Rodney Sullivan Gary Shimokawa`', '`Jim Hope Nancy Steen & Matt Ember`', '`August5,2002`', '`3ADK-19/3ADK-20`', 1, 1, 0, 1, 0, 19, '3')]",m_1764879475085_b926b6d3_12033013-3,"I'm a metadata manager familiar with episode numbering, credits, air dates and production codes and I speak in terms like 'No. in season' and 'production code'. The query flags rows with various formatting/consistency problems. It checks for slashes in numbering (multi-episode), original air dates missing a space, production codes whose first character isn't 3, and credit delimiter issues. Draft question: Which episodes have any of these problems — multi-episode numbering (slashes), an original air date missing a space, a production code that doesn't start with '3', or director/writer fields lacking proper delimiters? This exactly matches the set of rows the query returns.",persona,"```json
{
  ""short_persona_description"": ""Streaming Metadata Manager at a video-on-demand service responsible for importing and normalizing episode metadata for catalogue pages and staff-facing dashboards. They use this database to validate episode order, attribute credits correctly, and detect inconsistent or duplicate metadata before publishing."",
  ""goals"": [
    ""Verify and normalize episode ordering and season numbering for the catalogue."",
    ""Ensure director and writer credits are attrib Goals:  Example Queries: ",N/A,rename_column,
"For each Hakka initial, which area has a population density closest to the density calculated from its population and area?","
WITH `candidates` AS (
  SELECT
    `english_name`,
    `Hakka`,
    CASE WHEN instr(`Hakka`, '-') > 0 THEN substr(`Hakka`, 1, instr(`Hakka`, '-') - 1) ELSE `Hakka` END AS `Hakka_initial`,
    `Area`,
    `Population`,
    `Density`,
    (`Population` / `Area`) AS `calc_density`,
    ((`Population` / `Area`) - `Density`) AS `density_diff`,
    abs((`Population` / `Area`) - `Density`) AS `abs_density_diff`
  FROM `table_m_1764879482664_0f48baf7_1204998_2`
  WHERE `Population` BETWEEN 200000 AND 400000
    AND `Density` BETWEEN 100 AND 170
)
SELECT
  `english_name`,
  `Hakka`,
  `Hakka_initial`,
  `Area`,
  `Population`,
  `Density`,
  `calc_density`,
  `density_diff`,
  `abs_density_diff`
FROM `candidates` AS c
WHERE `abs_density_diff` = (
  SELECT MIN(`abs_density_diff`)
  FROM `candidates` AS c2
  WHERE c2.`Hakka_initial` = c.`Hakka_initial`
)
ORDER BY `Hakka_initial`;
","
WITH `candidates` AS (
  SELECT
    col0,
    col4,
    CASE WHEN instr(col4, '-') > 0 THEN substr(col4, 1, instr(col4, '-') - 1) ELSE col4 END AS `Hakka_initial`,
    col5,
    col6,
    col7,
    (col6 / col5) AS `calc_density`,
    ((col6 / col5) - col7) AS `density_diff`,
    abs((col6 / col5) - col7) AS `abs_density_diff`
  FROM `table_m_1764879482664_0f48baf7_1204998_2`
  WHERE col6 BETWEEN 200000 AND 400000
    AND col7 BETWEEN 100 AND 170
)
SELECT
  col0,
  col4,
  `Hakka_initial`,
  col5,
  col6,
  col7,
  `calc_density`,
  `density_diff`,
  `abs_density_diff`
FROM `candidates` AS c
WHERE `abs_density_diff` = (
  SELECT MIN(`abs_density_diff`)
  FROM `candidates` AS c2
  WHERE c2.`Hakka_initial` = c.`Hakka_initial`
)
ORDER BY `Hakka_initial`;
","[('Shanghang County', 'Sông-hông-yen', 'Sông', 2879.0, 374047.0, 130.0, 129.92254254949634, -0.07745745050365827, 0.07745745050365827), ('Changting County', 'Tshòng-tin-yen', 'Tshòng', 3099.0, 393390.0, 127.0, 126.94094869312681, -0.059051306873186604, 0.059051306873186604), ('Wuping County', 'Vú-phìn-yen', 'Vú', 2630.0, 278182.0, 106.0, 105.77262357414449, -0.22737642585551043, 0.22737642585551043), ('Yongding County', 'Yún-thin-yen', 'Yún', 2216.0, 362658.0, 164.0, 163.6543321299639, -0.34566787003609534, 0.34566787003609534)]",m_1764879482664_0f48baf7_1204998-2,"STEP 1: Parse the SQL intent — select rows with Population between 200,000 and 400,000 and Density between 100 and 170, compute calc_density = Population / Area and the absolute difference from reported Density, then for each Hakka_initial (substring of Hakka before a '-') choose the row(s) with the minimum abs difference and order by Hakka_initial. STEP 2: Determine ambiguity type — scope ambiguity fits well because the SQL finds the minimum per Hakka_initial, but a natural-language phrasing using words like ""each"" or ""for each"" can also be read as asking for a single overall minimum. STEP 3: Draft the question — ""For each Hakka initial, which area has a population density closest to the density calculated from its population and area?"" STEP 4: Explain the ambiguity — the original query interprets ""for each Hakka initial"" as grouping by Hakka_initial and returning the best-matching area within each group; alternatively the question could be read as asking for just one area overall whose density is closest to its calculated density (ignoring Hakka_initial grouping).",persona,"An itinerant Hakka oral‑history podcaster and acoustic archivist who plans tiny live recording sessions across Longyan’s counties and uses local Hakka names to curate authentic, place‑specific episodes. Goals: Identify administrative areas whose Hakka place‑names start with distinct phonemes (to craft episode titles and show intros with authentic local flavor). Choose counties/districts with mid-sized populations and moderate population density suitable for intimate, in‑person listening events (not too crowded, not too sparse). Verify that the published density matches population/area calculations to detect possible data quirks that might affect travel logistics or venue sizing. Example Queries: SELECT ""English Name"", ""Hakka"", ""Pinyin"", ""Population"", ""Density""
FROM table_1_1204998_2
WHERE ""Hakka"" LIKE 'S%'
ORDER BY ""Population"" DESC; SELECT ""English Name"", ""Area"", ""Population"", ""Density""
FROM table_1_1204998_2
WHERE ""Population"" BETWEEN 200000 AND 400000
  AND ""Density"" BETWEEN 100 AND 150
ORDER BY ""Density"" ASC; SELECT ""English Name"", ""Area"", ""Population"", (""Population"" / ""Area"") AS calc_density, ""Density"", ((""Population"" / ""Area"") - ""Density"") AS density_diff
FROM table_1_1204998_2
ORDER BY density_diff DESC;",N/A,rename_column,"type: Scope ambiguity | explanation: The phrase ""For each Hakka initial"" can be read two ways: (a) as a grouping scope — return the closest area within every Hakka_initial (what the SQL does), or (b) as a loose/prepositional phrase that could mean ""which single area (across all initials) is closest"", producing a single overall answer instead of one per initial."
"Which Builders, returned as 'York Rd', have both a Built field containing '1905' and a Scrapped/Sold field containing '1954', aggregated by Builder and ordered by the descending count of rows per Builder, returning only the top five?","
SELECT t1.`construction_company` AS `York Rd`
FROM `table_m_1764879502559_93026890_12113888_1` t1 JOIN `table_m_1764879502559_93026890_12113888_1` t2 ON t1.`construction_company` = t2.`construction_company`
WHERE instr(t1.`construction_year`, '1905')>0 AND instr(t2.`Scrapped/Sold`, '1954')>0
GROUP BY t1.`construction_company`
ORDER BY COUNT(*) DESC LIMIT 5;
","
SELECT t1.col1 AS `York Rd`
FROM `table_m_1764879502559_93026890_12113888_1` t1 JOIN `table_m_1764879502559_93026890_12113888_1` t2 ON t1.col1 = t2.col1
WHERE instr(t1.col2, '1905')>0 AND instr(t2.col5, '1954')>0
GROUP BY t1.col1
ORDER BY COUNT(*) DESC LIMIT 5;
","[('Derby',)]",m_1764879502559_93026890_12113888-1,"Parse the SQL intent: produce Builders (aliased 'York Rd') that have one or more rows with Built like '1905' and one or more rows with Scrapped/Sold like '1954', then group by Builder and pick the top five by row count. Map schema semantics: the self-join on Builder enforces both conditions per Builder; instr checks for substrings. Draft the question to ask for Builders as 'York Rd' satisfying those substring conditions, aggregated by Builder, ordered by COUNT(*) DESC with LIMIT 5. Validate: ensure all columns and operations (Builder alias, Built '1905', Scrapped/Sold '1954', GROUP BY, ORDER BY COUNT(*) DESC, LIMIT 5) are mentioned.",reserved,12,N/A,rename_column,
"For each Inaugural Years obtained by taking the substring of Age at inauguration up to the '-' and treating it as a number, and only for rows where Age at inauguration is non-empty, report the Inaugural Years, the President Count for that group, the Presidents (their names concatenated with '; '), the Earliest Inauguration date (minimum Date of inauguration) and the Latest End (maximum End of term), returning up to 100 groups.",unanswerable,unanswerable,,m_1764879512608_ca924a1a_12134383-1,"Parse SQL intent: compute per-year-at-inauguration groups by extracting the part of Age at inauguration before '-' and convert to a number, then return count, semicolon-joined President names, minimum Date of inauguration and maximum End of term for non-empty Age at inauguration. Map schema semantics: use columns Age at inauguration, President, Date of inauguration, End of term. Draft the question: ask explicitly for Inaugural Years (extracted), President Count, Presidents (joined with '; '), Earliest Inauguration (min), and Latest End (max), with grouping and a cap of 100 groups. Validate: ensure mention of substring extraction, aggregation types, non-empty filter, grouping, and limit.",reserved,9,N/A,remove_column,
"Export a season-by-season feed ordered by Year that assigns an era_id when League changes, builds era_name and era_length/first/last years, computes a recommended_card_rarity per season from Regular Season/Playoffs/Open Cup (legendary/rare/common), concatenates notable events, and flags era start and end years.",unanswerable,unanswerable,,m_1764879525955_3d60918c_1214035-1,"As the one designing campaign eras, I'd ask for era detection and per-season rarity tagging in one feed, using familiar labels rather than window-function details. The SQL does exactly that: it computes era_id by comparing League to the prior year, sums era changes to id eras, computes era_first/last years and length, determines recommended_card_rarity from Regular Season/Playoffs/Open Cup, and composes notable_events and era boundary flags. It sources Year, Division, League, Regular Season, Playoffs, and Open Cup. Draft question: request a season-by-season export ordered by Year containing era metadata, rarity, notable events, and start/end flags. Validate: the question precisely asks for the columns and derived fields the query returns.",persona,"""Goals"": [ ""Identify which seasons should become 'legendary' or 'rare' cards (titles, 1st-place finishes, deep playoff/Open Cup runs)."", ""Map league/division stretches and churn to design campaign eras and faction/upgrade mechanics (e.g., A-League era vs PDL era)."", ""Produce a chronological data feed that tags each season with a card-tier and notable events so designers/illustrators can craft flavor text and artwork."" ], ""Example queries"": [ ""-- 1) Get all seasons with top finishes, any playoff progress, or any Open Cup progress (for 'rare/legend' card candidates)\n    SELECT \""Year\"", \""Division\"", \""League\"", \""Regular Season\"", \""Playoffs\"", \""Open Cup\""\n    FROM table_1_1214035_1\n    WHERE \""Regular Season\"" LIKE '1st%'\n       OR \""Playoffs\"" NOT LIKE 'Did not%'\n       OR \""Open Cup\"" NOT LIKE 'Did not%'\n    ORDER BY \""Year\"";"", \n    ""-- 2) Count seasons per League and list earliest/latest year in that league (to define campaign eras and art direction)\n    SELECT \""League\"",\n           COUNT(*) AS season_count,\n           MIN(\""Year\"") AS first_year,\n           MAX(\""Year\"") AS last_year\n    FROM table_1_1214035_1\n    GROUP BY \""League\""\n    ORDER BY first_year;"", \n    ""-- 3) Produce a chronological season feed with a simple card-tier flag (legend/playoff/cup/base) for direct import into card generator\n    SELECT \""Year\"", \""Division\"", \""League\"", \""Regular Season\"", \""Playoffs\"", \""Open Cup\"",\n           CASE\n             WHEN \""Regular Season\"" LIKE '1st%' THEN 'legend'\n             WHEN \""Playoffs\"" NOT LIKE 'Did not%' THEN 'playoff'\n             WHEN \""Open Cup\"" NOT LIKE 'Did not%' THEN 'cup'\n             ELSE 'base'\n           END AS card_tier\n    FROM table_1_1214035_1\n    ORDER BY \""Year\"";"" ] } ``` Goals:  Example Queries: ",N/A,remove_column,
"Who are the top 3 Directors by Total Millions where Total Millions is computed as ROUND(SUM(REPLACE(Viewers,'m','')+0),2), and for each Director show the Episode Count (COUNT(*)) and the rounded total; exclude episodes with Viewers = 'N/A', require the summed viewers to be greater than 0, and sort by Total Millions in descending order?",unanswerable,unanswerable,,m_1764879531918_4002c1de_12148018-2,"1) Intent: compute per-Director episode count and summed viewers (strip 'm' and convert to number), round to 2 decimals, ignore 'N/A' rows, require positive sums, and return the top three by total. 2) Map schema semantics to Director, Viewers, COUNT(*), SUM(REPLACE(...)), and ROUND. 3) Draft final question that explicitly names each calculation and constraint. 4) Confirm inclusion of WHERE Viewers != 'N/A', HAVING SUM(...)>0, ORDER BY DESC, and LIMIT 3.",reserved,12,N/A,remove_column,
"For episodes with U.S. viewers (millions) > 0 whose directors directed more than one episode, provide Series #, Title, Directed by, U.S. viewers (millions), the director_avg which is AVG(U.S. viewers (millions)) for that director, and the deviation computed as (U.S. viewers (millions) - director_avg) / director_avg, then order by deviation ascending and return the top 5 rows?","
SELECT t1.`Series #`, t1.`Title`, t1.`Directed by`, t1.`U.S. viewers (millions)`, AVG(t2.`U.S. viewers (millions)`) director_avg, (t1.`U.S. viewers (millions)` - AVG(t2.`U.S. viewers (millions)`)) / AVG(t2.`U.S. viewers (millions)`) deviation
FROM `table_m_1764879539340_da5acf96_12159115_2` t1 JOIN `table_m_1764879539340_da5acf96_12159115_2` t2 ON t2.`Directed by` = t1.`Directed by`
WHERE t1.`U.S. viewers (millions)` > 0
GROUP BY t1.`Series #`, t1.`Title`, t1.`Directed by`, t1.`U.S. viewers (millions)`
HAVING COUNT(t2.`Series #`) > 1
ORDER BY deviation
LIMIT 5;
","
SELECT t1.col0, t1.col1, t1.col2, t1.col6, AVG(t2.col6) director_avg, (t1.col6 - AVG(t2.col6)) / AVG(t2.col6) deviation
FROM `table_m_1764879539340_da5acf96_12159115_2` t1 JOIN `table_m_1764879539340_da5acf96_12159115_2` t2 ON t2.col2 = t1.col2
WHERE t1.col6 > 0
GROUP BY t1.col0, t1.col1, t1.col2, t1.col6
HAVING COUNT(t2.col0) > 1
ORDER BY deviation
LIMIT 5;
","[(21.0, '""David and Goliath""', 'Kevin Dowling', '8.84', 10.936666666666667, -0.19170984455958556), (5.0, '""Romeo and Juliet Murders""', 'Lewis H. Gould', '9.5', 10.826666666666668, -0.122536945812808), (16.0, '""Escape""', 'Charles Beeson', '9.88', 10.875, -0.09149425287356315), (13.0, '""The Rapist Next Door""', 'Martha Mitchell', '10.74', 11.350000000000001, -0.05374449339207058), (20.0, '""The Shot""', 'Kevin Dowling', '11.17', 10.936666666666667, 0.021334958854007848)]",m_1764879539340_da5acf96_12159115-2,"1) The intent is to compute per-episode deviation from the director's mean viewers, exclude zero-viewer episodes, restrict to directors with multiple episodes, and return the five smallest deviations. 2) Map schema: output Series #, Title, Directed by, U.S. viewers (millions), director_avg (AVG of U.S. viewers (millions)), and deviation formula. 3) Phrase a question that requests exactly those outputs and constraints, ordered by deviation and limited to 5. 4) Confirm all columns, AVG alias, formula, HAVING >1, WHERE >0, ORDER BY and LIMIT are included.",reserved,10,N/A,add_column,
"For at most 10 distinct Winners (grouped by Winner) among rows with Season <> '', what is Country (Winner), Wins (COUNT(*)), Men Alignment (SUM(Winner Men = Winner)), Women Alignment (SUM(Winner Women = Winner)), Gender Match Count (SUM((Winner Men = Winner) + (Winner Women = Winner))), and Split Teams (COUNT(*) - SUM((Winner Men = Winner) + (Winner Women = Winner)))?",unanswerable,unanswerable,,m_1764879545866_20d5b42e_1216097-7,"1) Parse: produce per-Winner aggregates: total wins, counts where the men's/women's winners equal the Winner, their sum, and wins minus that sum; exclude empty Season rows and limit output to 10. 2) Map: interpret Winner as the country and Winner Men/Winner Women as gender-specific winners. 3) Draft: formulate a question asking for these exact aggregated columns and calculations per Winner with Season <> '' and LIMIT 10. 4) Validate: the question must include COUNT(*), both SUM(...) expressions, their combined SUM, the subtraction for Split Teams, grouping, filter, and the limit.",reserved,6,N/A,remove_column,
"Which .308 Winchester cartridge types (excluding rows where the .308 Winchester cartridge type equals the .300 Winchester Magnum cartridge type) have an average 100 m group (mm) and an average 300 m group (mm) below 14 and 55 respectively, and what are their average 100 m group (mm), average 300 m group (mm), and the ratio of average 100 m group (mm) to average 100 m group ( MOA ), ordered by average 100 m group (mm) then average 300 m group (mm)?",unanswerable,unanswerable,,m_1764879562540_7e65e80d_12162347-1,"Parse SQL intent: retrieve grouped averages and a computed ratio per .308 cartridge type, exclude rows where the .308 value equals the .300 Winchester Magnum value, apply HAVING filters for averages below given thresholds, and sort by those averages. Map schema semantics: reference columns .308 Winchester cartridge type, 100 m group (mm), 300 m group (mm), and 100 m group ( MOA ) for the division. Draft the question to request those aggregated values and the specific filters and ordering. Validate that the question mentions AVG of both distances, the division AVG(100 m mm)/AVG(100 m MOA), the inequality exclusion, HAVING limits, and ORDER BY sequence.",reserved,8,N/A,merge_column,
Which men's singles players have won the most titles?,"
SELECT `Mens singles`, COUNT(*) AS `Titles`, GROUP_CONCAT(`Year`) FROM `table_m_1764879572272_55c6d5bd_12164707_1` GROUP BY `Mens singles` ORDER BY `Titles` DESC LIMIT 5;
","
SELECT col1, COUNT(*) AS `Titles`, GROUP_CONCAT(col0) FROM `table_m_1764879572272_55c6d5bd_12164707_1` GROUP BY col1 ORDER BY `Titles` DESC LIMIT 5;
","[('Ville Lång', 1, '2008.0'), ('Richard Vaughan', 1, '2000.0'), ('Przemysław Wacha', 1, '2002.0'), ('Peter Mikkelsen', 1, '2009.0'), ('Oliver Pongratz', 1, '2001.0')]",m_1764879572272_55c6d5bd_12164707-1,"STEP 1: Parse the SQL intent: the query groups rows by the 'Mens singles' column, counts how many rows (titles) each player has, concatenates the years they won, orders players by their title counts descending, and returns the top 5 players. STEP 2: Determine ambiguity type: scope ambiguity fits well because the phrase 'most titles' can refer to total titles across all years (the SQL interpretation) or to other scopes like titles in a single year/season, titles at a specific event, or per-period maxima. STEP 3: Draft the question: ""Which men's singles players have won the most titles?"" STEP 4: Explain ambiguity: the original query interprets this as the overall total number of tournament wins per player across the dataset (and returns the top 5 with the years), but a reader could instead mean 'most titles in a single year', 'most titles at a particular edition', 'most titles per country', or 'most recent titles', which would require different grouping/filtering in SQL.",reserved,8,N/A,merge_column,"type: Scope ambiguity | explanation: The SQL treats 'most titles' as the total number of wins per player across all years (overall totals). Alternatively, 'most titles' could mean within a single year/season, at a specific event edition, per country, or by some other time or subset scope, which the query does not specify and would change the grouping/filtering needed."
"For each MotoGP winner, report the number of rounds they won (Win Count = COUNT(Round)), the concatenated list of Circuits (GROUP_CONCAT(Circuit)), and the concatenated list of anomaly Rounds (GROUP_CONCAT of Round for rounds where the 125cc winner = 'No 125cc and 250cc race'), grouping by MotoGP winner and ordering the results by Win Count descending?",unanswerable,unanswerable,,m_1764879584475_b0c13f87_12186237-1,"1) The SQL joins the table to a subquery that picks rounds where `125cc winner` equals 'No 125cc and 250cc race', then aggregates per MotoGP winner computing counts and concatenations and orders by count descending. 2) Map to table fields: use MotoGP winner for grouping, Round for counting and listing anomaly rounds, and Circuit for listing circuits. 3) Formulate a question that asks for each MotoGP winner the Win Count (=COUNT(Round)), the Circuits (=GROUP_CONCAT(Circuit)), and the Anomaly Rounds (=GROUP_CONCAT of Round from rows where 125cc winner = 'No 125cc and 250cc race'), ordered by Win Count descending. 4) Ensure the question references the anomaly condition and the specific aggregated outputs.",reserved,10,N/A,merge_column,
"From the Mens singles, Womens singles, Mens doubles, Womens doubles and Mixed doubles winners (using Year as the unit to count each title), who are the top 10 players by number of titles (COUNT(Year) AS titles) and what are their title counts and concatenated categories (GROUP_CONCAT of category), ordered by titles descending?",,,[],m_1764879595004_505accf3_12204717-1,"1) The query builds a combined list of players across all five categories, counts years per player as titles, concatenates the categories per player, sorts by the count and returns ten rows. 2) Use the table's Year, Mens singles, Womens singles, Mens doubles, Womens doubles and Mixed doubles fields. 3) Formulate a question that asks for each player the number of titles (counting Year) and the concatenated categories, sorted by titles desc, top 10. 4) Ensure the question explicitly mentions COUNT(Year) AS titles, GROUP_CONCAT(category) AS categories, the five category columns, ordering and LIMIT 10.",reserved,8,N/A,merge_column,
"Which 'Written by' values have more than one 'Directed by' (i.e., COUNT('Directed by') as DirectorCount > 1 when pairing rows with the same 'Written by' but where 'Directed by' differs), and for each such 'Written by' what are DirectorCount, MIN('Original air date') as FirstAir and MAX('Original air date') as LastAir, ordered by DirectorCount descending and limited to 10 results?",unanswerable,unanswerable,,m_1764879622627_83fb1053_12226390-2,"1) The SQL finds writers who have episodes directed by multiple different directors and returns a count of those director rows plus earliest and latest air dates, ordering and limiting results. 2) Map to columns: 'Written by' is the grouping key, 'Directed by' is counted, 'Original air date' supplies MIN and MAX. 3) Draft a question asking which writers have DirectorCount > 1 and for each show DirectorCount, FirstAir and LastAir, ordered by DirectorCount desc and limited to 10. 4) Ensure the question mentions COUNT('Directed by') as DirectorCount, MIN/MAX of 'Original air date', the director inequality condition, HAVING > 1, ORDER BY and LIMIT 10.",reserved,12,N/A,merge_column,
"List the top 5 boxers (limit 5) ordered by total defenses descending and then by number of titles, showing for each boxer their Name, the number of Titles (COUNT(*)), Total_Defenses (SUM of Defenses), Stoppages (count of rows where Result includes 'KO' or 'TKO'), their First_Title date (MIN Date) and Last_Title date (MAX Date), and also compute the number of distinct title Divisions (COUNT DISTINCT Titles) via a left join, but include only boxers whose Total_Defenses is at least 1?","
SELECT `t`.`Name` AS `Boxer`,
       COUNT(*) AS `boxing_titles_won`,
       SUM(`t`.`boxing_defenses_won`) AS `Total_Defenses`,
       SUM(CASE WHEN `t`.`Result` LIKE '%KO%' OR `t`.`Result` LIKE '%TKO%' THEN 1 ELSE 0 END) AS `Stoppages`,
       MIN(`t`.`Date`) AS `First_Title`,
       MAX(`t`.`Date`) AS `Last_Title`
FROM `table_m_1764879642856_063e14ad_12262182_2` `t`
LEFT JOIN (
  SELECT `Name`, COUNT(DISTINCT `boxing_titles_won`) AS `Divisions`
  FROM `table_m_1764879642856_063e14ad_12262182_2`
  GROUP BY `Name`
) AS `d` ON `d`.`Name` = `t`.`Name`
GROUP BY `t`.`Name`
HAVING SUM(`t`.`boxing_defenses_won`) >= 1
ORDER BY SUM(`t`.`boxing_defenses_won`) DESC, COUNT(*) 
LIMIT 5;
","
SELECT `t`.col1 AS `Boxer`,
       COUNT(*) AS col2,
       SUM(`t`.col6) AS `Total_Defenses`,
       SUM(CASE WHEN `t`.col5 LIKE '%KO%' OR `t`.col5 LIKE '%TKO%' THEN 1 ELSE 0 END) AS `Stoppages`,
       MIN(`t`.col3) AS `First_Title`,
       MAX(`t`.col3) AS `Last_Title`
FROM `table_m_1764879642856_063e14ad_12262182_2` `t`
LEFT JOIN (
  SELECT col1, COUNT(DISTINCT col2) AS `Divisions`
  FROM `table_m_1764879642856_063e14ad_12262182_2`
  GROUP BY col1
) AS `d` ON `d`.col1 = `t`.col1
GROUP BY `t`.col1
HAVING SUM(`t`.col6) >= 1
ORDER BY SUM(`t`.col6) DESC, COUNT(*) 
LIMIT 5;
","[('Oscar De La Hoya', 8, 25.0, 4, '1994-03-05', '2002-09-14'), ('Floyd Mayweather, Jr.', 8, 23.0, 1, '1998-10-03', '2007-05-05'), ('Thomas Hearns', 6, 13.0, 4, '1980-08-02', '1988-11-04'), ('Manny Pacquiao', 6, 8.0, 4, '1998-12-04', '2008-03-15'), ('Ray Charles Leonard', 8, 4.0, 6, '1979-11-30', '1988-11-07')]",m_1764879642856_063e14ad_12262182-2,"1) The intent is to produce top boxers by their summed defenses with several summary columns. 2) Map schema elements: Name, Titles count, sum of Defenses, conditional count of KO/TKO Results, earliest and latest Date, and the joined Divisions count. 3) Formulate a question that requests those exact outputs, applies the filter SUM(Defenses) >= 1, orders by SUM(Defenses) DESC then COUNT(*), and limits to 5. 4) Keep the question aligned to the SQL without adding extraneous details.",reserved,31,N/A,rename_column,
"Provide for each State the State, the State value surrounded by backticks, the Weighted Recalc calculated as (Preliminaries*0.2 + Interview*0.3 + Swimsuit*0.25 + Evening Gown*0.25), and Delta vs Recalc calculated as (Average - (Preliminaries*0.2 + Interview*0.3 + Swimsuit*0.25 + Evening Gown*0.25)), but only include rows where ABS(Delta vs Recalc) > 0.0005?",unanswerable,unanswerable,,m_1764879710139_c4415139_12338595-1,"1) The intent is to compute a weighted aggregate from four score columns, show State and a backticked State label, compute the difference from the listed Average, and return only rows with a non-negligible discrepancy > 0.0005. 2) Map Preliminaries, Interview, Swimsuit, Evening Gown to their weights 0.2, 0.3, 0.25, 0.25 and use Average for comparison. 3) Phrase a question requesting State, the backticked State value, the weighted recalculation, and the delta with the absolute threshold. 4) Confirm all calculations and the absolute comparison are explicitly mentioned.",reserved,3,N/A,merge_column,
"Give me a prioritized list of 2005 BC municipalities that puts under‑policed high‑crime towns first, showing for each the population, number of officers, residents per officer, crime rate per 1,000 and cost per capita?","
SELECT
  `city`,
  `Population`,
  `Police officers`,
  `Residents per officer`,
  `Crime rate per 1,000 people`,
  `cost_per_capita`,
  CAST(REPLACE(REPLACE(`cost_per_capita`, '$', ''), ',', '') AS REAL) AS `cost_per_capita_num`,
  ROUND((`Police officers` / `Population`) * 1000.0, 3) AS `officers_per_1000`,
  CASE WHEN `Residents per officer` > 1000 AND `Crime rate per 1,000 people` > 80 THEN 1 ELSE 0 END AS `under_policed_high_crime`,
  CASE
    WHEN `Population` < 10000 THEN 'Small'
    WHEN `Population` BETWEEN 10000 AND 30000 THEN 'Small-Mid'
    WHEN `Population` BETWEEN 30001 AND 100000 THEN 'Mid'
    ELSE 'Large'
  END AS `population_bin`,
  RANK() OVER (
    PARTITION BY CASE
      WHEN `Population` < 10000 THEN 'Small'
      WHEN `Population` BETWEEN 10000 AND 30000 THEN 'Small-Mid'
      WHEN `Population` BETWEEN 30001 AND 100000 THEN 'Mid'
      ELSE 'Large'
    END
    ORDER BY CAST(REPLACE(REPLACE(`cost_per_capita`, '$', ''), ',', '') AS REAL) DESC
  ) AS `cost_rank_in_bin_desc`,
  RANK() OVER (
    PARTITION BY CASE
      WHEN `Population` < 10000 THEN 'Small'
      WHEN `Population` BETWEEN 10000 AND 30000 THEN 'Small-Mid'
      WHEN `Population` BETWEEN 30001 AND 100000 THEN 'Mid'
      ELSE 'Large'
    END
    ORDER BY `Residents per officer` DESC
  ) AS `residents_per_officer_rank_in_bin`,
  CAST(REPLACE(REPLACE(`cost_per_capita`, '$', ''), ',', '') AS REAL)
    - AVG(CAST(REPLACE(REPLACE(`cost_per_capita`, '$', ''), ',', '') AS REAL)) OVER (
        PARTITION BY CASE
          WHEN `Population` < 10000 THEN 'Small'
          WHEN `Population` BETWEEN 10000 AND 30000 THEN 'Small-Mid'
          WHEN `Population` BETWEEN 30001 AND 100000 THEN 'Mid'
          ELSE 'Large'
        END
      ) AS `cost_diff_from_bin_avg`
FROM `table_m_1764879716533_6cd917e3_12340907_1`
ORDER BY `under_policed_high_crime` DESC, `Residents per officer` DESC, `Crime rate per 1,000 people` DESC, `Population` ASC;
","
SELECT
  col0,
  col1,
  col2,
  col3,
  col7,
  col5,
  CAST(REPLACE(REPLACE(col5, '$', ''), ',', '') AS REAL) AS `cost_per_capita_num`,
  ROUND((col2 / col1) * 1000.0, 3) AS `officers_per_1000`,
  CASE WHEN col3 > 1000 AND col7 > 80 THEN 1 ELSE 0 END AS `under_policed_high_crime`,
  CASE
    WHEN col1 < 10000 THEN 'Small'
    WHEN col1 BETWEEN 10000 AND 30000 THEN 'Small-Mid'
    WHEN col1 BETWEEN 30001 AND 100000 THEN 'Mid'
    ELSE 'Large'
  END AS `population_bin`,
  RANK() OVER (
    PARTITION BY CASE
      WHEN col1 < 10000 THEN 'Small'
      WHEN col1 BETWEEN 10000 AND 30000 THEN 'Small-Mid'
      WHEN col1 BETWEEN 30001 AND 100000 THEN 'Mid'
      ELSE 'Large'
    END
    ORDER BY CAST(REPLACE(REPLACE(col5, '$', ''), ',', '') AS REAL) DESC
  ) AS `cost_rank_in_bin_desc`,
  RANK() OVER (
    PARTITION BY CASE
      WHEN col1 < 10000 THEN 'Small'
      WHEN col1 BETWEEN 10000 AND 30000 THEN 'Small-Mid'
      WHEN col1 BETWEEN 30001 AND 100000 THEN 'Mid'
      ELSE 'Large'
    END
    ORDER BY col3 DESC
  ) AS `residents_per_officer_rank_in_bin`,
  CAST(REPLACE(REPLACE(col5, '$', ''), ',', '') AS REAL)
    - AVG(CAST(REPLACE(REPLACE(col5, '$', ''), ',', '') AS REAL)) OVER (
        PARTITION BY CASE
          WHEN col1 < 10000 THEN 'Small'
          WHEN col1 BETWEEN 10000 AND 30000 THEN 'Small-Mid'
          WHEN col1 BETWEEN 30001 AND 100000 THEN 'Mid'
          ELSE 'Large'
        END
      ) AS `cost_diff_from_bin_avg`
FROM `table_m_1764879716533_6cd917e3_12340907_1`
ORDER BY `under_policed_high_crime` DESC, col3 DESC, col7 DESC, col1 ASC;
","[('Qualicum Beach', 8807.0, 6.0, 1468.0, 81.0, '$53', 53.0, 0.681, 1, 'Small', 14, 2, -86.0), ('Lake Country', 10367.0, 9.0, 1152.0, 90.0, '$71', 71.0, 0.868, 1, 'Small-Mid', 28, 4, -80.26666666666668), ('View Royal', 8382.0, 8.0, 1048.0, 87.0, '$115', 115.0, 0.954, 1, 'Small', 10, 3, -24.0), ('Ladysmith', 7292.0, 7.0, 1042.0, 81.0, '$95', 95.0, 0.96, 1, 'Small', 12, 4, -44.0), ('North Cowichan', 28519.0, 28.0, 1019.0, 98.0, '$127', 127.0, 0.982, 1, 'Small-Mid', 19, 6, -24.26666666666668), ('Sooke', 10117.0, 10.0, 1012.0, 92.0, '$99', 99.0, 0.988, 1, 'Small-Mid', 23, 7, -52.26666666666668), ('Spallumcheen', 5707.0, 3.0, 1902.0, 46.0, '$47', 47.0, 0.526, 0, 'Small', 15, 1, -92.0), ('Coldstream', 10102.0, 7.0, 1443.0, 38.0, '$69', 69.0, 0.693, 0, 'Small-Mid', 29, 1, -82.26666666666668), ('Comox', 12706.0, 10.0, 1271.0, 56.0, '$75', 75.0, 0.787, 0, 'Small-Mid', 27, 2, -76.26666666666668), ('Summerland', 11405.0, 9.0, 1267.0, 68.0, '$69', 69.0, 0.789, 0, 'Small-Mid', 29, 3, -82.26666666666668), ('North Saanich', 11274.0, 10.0, 1127.0, 34.0, '$84', 84.0, 0.887, 0, 'Small-Mid', 26, 5, -67.26666666666668), ('Salmon Arm', 17000.0, 17.0, 1000.0, 103.0, '$104', 104.0, 1.0, 0, 'Small-Mid', 22, 8, -47.26666666666668), ('Port Coquitlam', 57569.0, 59.0, 976.0, 112.0, '$133', 133.0, 1.025, 0, 'Mid', 15, 1, -54.0625), ('North Vancouver (district)', 88461.0, 91.0, 972.0, 67.0, '$133', 133.0, 1.029, 0, 'Mid', 15, 2, -54.0625), ('Coquitlam', 121989.0, 127.0, 961.0, 100.0, '$139', 139.0, 1.041, 0, 'Large', 9, 1, -43.0), ('Colwood', 15253.0, 16.0, 953.0, 74.0, '$95', 95.0, 1.049, 0, 'Small-Mid', 25, 9, -56.26666666666668), ('Maple Ridge', 73531.0, 79.0, 931.0, 136.0, '$152', 152.0, 1.074, 0, 'Mid', 14, 3, -35.0625), ('Langford', 21845.0, 24.0, 910.0, 112.0, '$156', 156.0, 1.099, 0, 'Small-Mid', 15, 10, 4.73333333333332), ('Richmond', 173429.0, 94.0, 908.0, 191.0, '$152', 152.0, 0.542, 0, 'Large', 7, 2, -30.0), ('Parksville', 11709.0, 13.0, 901.0, 174.0, '$99', 99.0, 1.11, 0, 'Small-Mid', 23, 11, -52.26666666666668), ('Sechelt', 8901.0, 10.0, 890.0, 96.0, '$102', 102.0, 1.123, 0, 'Small', 11, 5, -37.0), ('Pitt Meadows', 16673.0, 19.0, 878.0, 101.0, '$120', 120.0, 1.14, 0, 'Small-Mid', 20, 12, -31.26666666666668), ('White Rock', 19577.0, 23.0, 851.0, 84.0, '$160', 160.0, 1.175, 0, 'Small-Mid', 13, 13, 8.73333333333332), ('Sidney', 11862.0, 14.0, 847.0, 54.0, '$108', 108.0, 1.18, 0, 'Small-Mid', 21, 14, -43.26666666666668), ('Courtenay', 21801.0, 26.0, 838.0, 182.0, '$147', 147.0, 1.193, 0, 'Small-Mid', 17, 15, -4.26666666666668), ('Kelowna', 109490.0, 131.0, 836.0, 150.0, '$149', 149.0, 1.196, 0, 'Large', 8, 3, -33.0), ('Oak Bay', 18313.0, 22.0, 832.0, 65.0, '$194', 194.0, 1.201, 0, 'Small-Mid', 8, 16, 42.73333333333332), ('Cranbrook', 19774.0, 24.0, 824.0, 131.0, '$159', 159.0, 1.214, 0, 'Small-Mid', 14, 17, 7.73333333333332), ('Burnaby', 204320.0, 253.0, 808.0, 123.0, '$160', 160.0, 1.238, 0, 'Large', 6, 4, -22.0), ('Chilliwack', 73066.0, 91.0, 803.0, 174.0, '$154', 154.0, 1.245, 0, 'Mid', 12, 4, -33.0625), ('Central Saanich', 16821.0, 21.0, 801.0, 49.0, '$181', 181.0, 1.248, 0, 'Small-Mid', 11, 18, 29.73333333333332), ('Langley (township)', 97682.0, 123.0, 794.0, 108.0, '$168', 168.0, 1.259, 0, 'Mid', 10, 5, -19.0625), ('Penticton', 33061.0, 42.0, 787.0, 165.0, '$154', 154.0, 1.27, 0, 'Mid', 12, 6, -33.0625), ('Kimberley', 7049.0, 9.0, 783.0, 77.0, '$95', 95.0, 1.277, 0, 'Small', 12, 6, -44.0), ('Campbell River', 30810.0, 40.0, 770.0, 178.0, '$173', 173.0, 1.298, 0, 'Mid', 9, 7, -14.0625), ('Powell River', 13831.0, 18.0, 768.0, 114.0, '$139', 139.0, 1.301, 0, 'Small-Mid', 18, 19, -12.26666666666668), ('Saanich', 110386.0, 57.0, 751.0, 67.0, '$176', 176.0, 0.516, 0, 'Large', 4, 5, -6.0), ('Mission', 34742.0, 47.0, 739.0, 169.0, '$183', 183.0, 1.353, 0, 'Mid', 6, 8, -4.0625), ('Vernon', 36232.0, 49.0, 739.0, 167.0, '$165', 165.0, 1.352, 0, 'Mid', 11, 8, -22.0625), ('North Vancouver (city)', 47131.0, 64.0, 736.0, 117.0, '$186', 186.0, 1.358, 0, 'Mid', 5, 10, -1.0625), ('Revelstoke', 7964.0, 11.0, 724.0, 105.0, '$123', 123.0, 1.381, 0, 'Small', 9, 7, -16.0), ('Surrey', 393256.0, 552.0, 712.0, 127.0, '$167', 167.0, 1.404, 0, 'Large', 5, 6, -15.0), ('Castlegar', 7821.0, 11.0, 711.0, 150.0, '$143', 143.0, 1.406, 0, 'Small', 7, 8, 4.0), ('Port Moody', 28458.0, 40.0, 711.0, 67.0, '$203', 203.0, 1.406, 0, 'Small-Mid', 7, 20, 51.73333333333332), ('Kitimat', 10587.0, 15.0, 706.0, 70.0, '$148', 148.0, 1.417, 0, 'Small-Mid', 16, 21, -3.26666666666668), ('Nanaimo', 79898.0, 114.0, 701.0, 178.0, '$183', 183.0, 1.427, 0, 'Mid', 6, 11, -4.0625), ('Kamloops', 82714.0, 118.0, 701.0, 168.0, '$181', 181.0, 1.427, 0, 'Mid', 8, 11, -6.0625), ('Abbotsford', 128165.0, 187.0, 685.0, 118.0, '$199', 199.0, 1.459, 0, 'Large', 3, 7, 17.0), ('Fort St. John', 17781.0, 26.0, 684.0, 228.0, '$213', 213.0, 1.462, 0, 'Small-Mid', 5, 22, 61.73333333333332), ('Mackenzie', 5454.0, 8.0, 682.0, 108.0, '$141', 141.0, 1.467, 0, 'Small', 8, 9, 2.0), ('Delta', 102661.0, 74.0, 680.0, 151.0, '$205', 205.0, 0.721, 0, 'Large', 2, 8, 23.0), ('Trail', 7889.0, 12.0, 657.0, 147.0, '$171', 171.0, 1.521, 0, 'Small', 3, 10, 32.0), ('Prince George', 77148.0, 121.0, 638.0, 179.0, '$201', 201.0, 1.568, 0, 'Mid', 4, 13, 13.9375), ('Squamish', 15922.0, 25.0, 637.0, 204.0, '$186', 186.0, 1.57, 0, 'Small-Mid', 9, 23, 34.73333333333332), ('Smithers', 5509.0, 9.0, 612.0, 301.0, '$170', 170.0, 1.634, 0, 'Small', 4, 11, 31.0), ('West Vancouver', 46595.0, 79.0, 590.0, 60.0, '$222', 222.0, 1.695, 0, 'Mid', 3, 14, 34.9375), ('Langley (city)', 25716.0, 9.0, 584.0, 176.0, '$237', 237.0, 0.35, 0, 'Small-Mid', 3, 24, 85.73333333333332), ('Merritt', 7561.0, 13.0, 582.0, 228.0, '$157', 157.0, 1.719, 0, 'Small', 6, 12, 18.0), ('Nelson', 9797.0, 17.0, 576.0, 139.0, '$201', 201.0, 1.735, 0, 'Small', 2, 13, 62.0), ('Port Alberni', 18688.0, 34.0, 550.0, 210.0, '$249', 249.0, 1.819, 0, 'Small-Mid', 2, 25, 97.73333333333332), ('New Westminster', 57480.0, 107.0, 537.0, 162.0, '$276', 276.0, 1.862, 0, 'Mid', 2, 15, 88.9375), ('Quesnel', 10487.0, 20.0, 524.0, 237.0, '$259', 259.0, 1.907, 0, 'Small-Mid', 1, 26, 107.73333333333332), ('Dawson Creek', 11394.0, 22.0, 518.0, 225.0, '$215', 215.0, 1.931, 0, 'Small-Mid', 4, 27, 63.73333333333332), ('Williams Lake', 11872.0, 23.0, 516.0, 252.0, '$175', 175.0, 1.937, 0, 'Small-Mid', 12, 28, 23.73333333333332), ('Hope', 6591.0, 13.0, 507.0, 180.0, '$168', 168.0, 1.972, 0, 'Small', 5, 14, 29.0), ('Terrace', 12556.0, 25.0, 502.0, 206.0, '$184', 184.0, 1.991, 0, 'Small-Mid', 10, 29, 32.73333333333332), ('Vancouver', 584701.0, 1174.0, 498.0, 117.0, '$291', 291.0, 2.008, 0, 'Large', 1, 9, 109.0), ('Victoria', 94525.0, 215.0, 440.0, 186.0, '$329', 329.0, 2.275, 0, 'Mid', 1, 16, 141.9375), ('Whistler', 9775.0, 23.0, 425.0, 202.0, '$304', 304.0, 2.353, 0, 'Small', 1, 15, 165.0), ('Prince Rupert', 14974.0, 36.0, 416.0, 204.0, '$213', 213.0, 2.404, 0, 'Small-Mid', 5, 30, 61.73333333333332)]",m_1764879716533_6cd917e3_12340907-1,"As a director I want a ranked roster that puts the riskiest, understaffed hotspots first without getting technical about window functions. The SQL orders results to show under‑policed high‑crime places first, then by highest residents per officer, then by crime rate and smaller populations. That maps to the under_policed_high_crime flag, Residents per officer, Crime rate per 1,000 people, and Population along with the usual staffing and cost fields. Give me a prioritized list showing which towns are under‑policed and high‑crime, with population, officers, residents per officer, crime rate and cost per capita. This directly reflects the query's sort and returned columns.",persona,"An immersive theatre director designing a traveling, period-accurate 2005 British Columbia police procedural who needs authentic municipal policing details to script realistic scenes. Goals: Identify under‑policed towns (high residents per officer) that still have elevated crime rates to stage tense, high-stakes scenes. Pick municipalities with unusually high or low policing cost-per-capita for political/subplot beats and to justify visible vs. invisible police presence in different scenes. Assemble a palette of towns with similar population sizes but different police staffing and crime profiles so each episode/location has a distinct policing 'flavor'. Example Queries: SELECT ""Municipality"", ""Population"", ""Police officers"", ""Residents per officer"", ""Crime rate per 1,000 people""
FROM table_1_12340907_1
WHERE ""Residents per officer"" > 1000 AND ""Crime rate per 1,000 people"" > 80
ORDER BY ""Population"" ASC; SELECT ""Municipality"", ""Police officers"", ""Cost per capita"", ""Total costs (2005)""
FROM table_1_12340907_1
WHERE ""Police force"" = 'RCMP'
ORDER BY CAST(REPLACE(REPLACE(""Cost per capita"", '$', ''), ',', '') AS REAL) DESC
LIMIT 10; SELECT ""Municipality"", (""Police officers"" / ""Population"") * 1000 AS officers_per_1000, ""Crime rate per 1,000 people""
FROM table_1_12340907_1
ORDER BY officers_per_1000 DESC;",N/A,rename_column,
"For each 'Directed by' value, what are the Reported episodes (COUNT), the Average viewers (AVG of 'Total viewers (in millions)') and the Peak viewers (MAX of 'Total viewers (in millions)') considering only rows where 'Total viewers (in millions)' > 0, grouped by 'Directed by' and limited to 5 results?","
SELECT `Directed by`, COUNT(*) `Reported episodes`, AVG(`Total viewers (in millions)`) `Average viewers`, MAX(`Total viewers (in millions)`) `Peak viewers` FROM `table_m_1764879723876_84459506_12419515_4` WHERE `Total viewers (in millions)` > 0 GROUP BY `Directed by` LIMIT 5;
","
SELECT col3, COUNT(*) `Reported episodes`, AVG(col5) `Average viewers`, MAX(col5) `Peak viewers` FROM `table_m_1764879723876_84459506_12419515_4` WHERE col5 > 0 GROUP BY col3 LIMIT 5;
","[('Fred Gerber', 1, 0.0, 'N/A'), ('Fred Savage', 1, 1.031, '1.031'), ('John T. Kretchmer', 1, 0.0, 'N/A'), ('Lee Rose', 1, 0.0, 'N/A'), ('Mark Rosman', 1, 0.872, '0.872')]",m_1764879723876_84459506_12419515-4,"1) Parse SQL intent: compute per-director aggregates (count, average, max) for episodes with Total viewers (in millions) > 0 and return up to 5 directors. 2) Map schema semantics: 'Directed by' is the director field and 'Total viewers (in millions)' is the numeric viewers field. 3) Draft the question: ask for Directed by, Reported episodes (COUNT), Average viewers (AVG of Total viewers (in millions)), Peak viewers (MAX of Total viewers (in millions)) with the >0 filter, grouped by director and limited to 5. 4) Validate: ensures grouping, filter, aggregate names, and LIMIT 5 are all represented.",reserved,6,N/A,remove_column,
"List up to 6 tracks that have Seating >= 75000 and Year Acquired [A ] <= 1999, including for each the Track Name, Location, Seating, Seats per operational year = (Seating * 1.0) / (2025 - Year Opened), Years until acquisition = (Year Acquired [A ] - Year Opened), Years since acquisition = (2025 - Year Acquired [A ]), and Priority score = (Seating / 1000.0) + (2025 - Year Acquired [A ]) * 0.5 + (Year Acquired [A ] - Year Opened) * 0.2?",unanswerable,unanswerable,,m_1764879745868_9fa77196_1245148-1,"1) The SQL computes per-year and acquisition-derived metrics for tracks meeting seating and acquisition-year criteria and restricts the output to six rows. 2) Use the table fields Track Name, Location, Seating, Year Opened, Year Acquired [A ] and the same arithmetic expressions. 3) Formulate a concise question that requests each column and each calculation and mentions the filters and the 6-row limit. 4) Check that every expression from the SELECT and WHERE clauses plus the LIMIT is included.",reserved,5,N/A,merge_column,
Which clubs are top offensively and defensively?,"
WITH parsed AS (
  SELECT
    `Club`,
    `Goals For`,
    `Goals Against`,
    CAST(SUBSTR(`Goals For Avg.`, 1, INSTR(`Goals For Avg.`, ' ')-1) AS REAL) AS gf_avg,
    CAST(SUBSTR(`Goals Against Avg.`, 1, INSTR(`Goals Against Avg.`, ' ')-1) AS REAL) AS ga_avg,
    CAST(REPLACE(REPLACE(REPLACE(REPLACE(
      SUBSTR(`Goals For Avg.`, INSTR(`Goals For Avg.`, '(')+1, INSTR(`Goals For Avg.`, ')') - INSTR(`Goals For Avg.`, '(') -1)
    ,'st',''),'nd',''),'rd',''),'th','') AS INTEGER) AS gf_rank,
    CAST(REPLACE(REPLACE(REPLACE(REPLACE(
      SUBSTR(`Goals Against Avg.`, INSTR(`Goals Against Avg.`, '(')+1, INSTR(`Goals Against Avg.`, ')') - INSTR(`Goals Against Avg.`, '(') -1)
    ,'st',''),'nd',''),'rd',''),'th','') AS INTEGER) AS ga_rank,
    (`Goals For` - `Goals Against`) AS goal_difference
  FROM `table_m_1764879782031_4d29990f_1246208_5`
)
SELECT
  `Club`,
  `Goals For`,
  `Goals Against`,
  gf_avg AS `Goals For Avg. (num)`,
  ga_avg AS `Goals Against Avg. (num)`,
  gf_rank AS `Goals For Rank`,
  ga_rank AS `Goals Against Rank`,
  goal_difference AS `Goal Differential`,
  CASE WHEN goal_difference > 0 THEN 'Yes' ELSE 'No' END AS `Positive Goal Differential`,
  CASE WHEN ga_avg > 1.40 THEN 'Yes' ELSE 'No' END AS `Concedes Frequently (ga_avg>1.40)`,
  CASE WHEN gf_rank <= 3 THEN 'Yes' ELSE 'No' END AS `Top Offensive (Top 3 by GF Avg Rank)`,
  CASE WHEN ga_rank <= 3 THEN 'Yes' ELSE 'No' END AS `Top Defensive (Top 3 by GA Avg Rank)`
FROM parsed
ORDER BY goal_difference DESC, gf_avg DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col3,
    CAST(SUBSTR(col2, 1, INSTR(col2, ' ')-1) AS REAL) AS gf_avg,
    CAST(SUBSTR(col4, 1, INSTR(col4, ' ')-1) AS REAL) AS ga_avg,
    CAST(REPLACE(REPLACE(REPLACE(REPLACE(
      SUBSTR(col2, INSTR(col2, '(')+1, INSTR(col2, ')') - INSTR(col2, '(') -1)
    ,'st',''),'nd',''),'rd',''),'th','') AS INTEGER) AS gf_rank,
    CAST(REPLACE(REPLACE(REPLACE(REPLACE(
      SUBSTR(col4, INSTR(col4, '(')+1, INSTR(col4, ')') - INSTR(col4, '(') -1)
    ,'st',''),'nd',''),'rd',''),'th','') AS INTEGER) AS ga_rank,
    (col1 - col3) AS goal_difference
  FROM `table_m_1764879782031_4d29990f_1246208_5`
)
SELECT
  col0,
  col1,
  col3,
  gf_avg AS `Goals For Avg. (num)`,
  ga_avg AS `Goals Against Avg. (num)`,
  gf_rank AS `Goals For Rank`,
  ga_rank AS `Goals Against Rank`,
  goal_difference AS `Goal Differential`,
  CASE WHEN goal_difference > 0 THEN 'Yes' ELSE 'No' END AS `Positive Goal Differential`,
  CASE WHEN ga_avg > 1.40 THEN 'Yes' ELSE 'No' END AS `Concedes Frequently (ga_avg>1.40)`,
  CASE WHEN gf_rank <= 3 THEN 'Yes' ELSE 'No' END AS `Top Offensive (Top 3 by GF Avg Rank)`,
  CASE WHEN ga_rank <= 3 THEN 'Yes' ELSE 'No' END AS `Top Defensive (Top 3 by GA Avg Rank)`
FROM parsed
ORDER BY goal_difference DESC, gf_avg DESC;
","[('Columbus Crew', 40.0, 32.0, 1.33, 1.07, 6, 2, 8.0, 'Yes', 'No', 'No', 'Yes'), ('Kansas City Wizards', 38.0, 30.0, 1.27, 1.0, 7, 1, 8.0, 'Yes', 'No', 'No', 'Yes'), ('San Jose Earthquakes', 41.0, 35.0, 1.37, 1.17, 5, 4, 6.0, 'Yes', 'No', 'No', 'No'), ('Los Angeles Galaxy', 42.0, 40.0, 1.4, 1.33, 3, 5, 2.0, 'Yes', 'No', 'Yes', 'No'), ('D.C. United', 43.0, 42.0, 1.43, 1.4, 2, 6, 1.0, 'Yes', 'No', 'Yes', 'No'), ('New England Revolution', 42.0, 43.0, 1.4, 1.43, 4, 7, -1.0, 'No', 'Yes', 'No', 'No'), ('MetroStars', 47.0, 49.0, 1.57, 1.63, 1, 10, -2.0, 'No', 'Yes', 'Yes', 'No'), ('Colorado Rapids', 29.0, 32.0, 0.97, 1.07, 10, 2, -3.0, 'No', 'No', 'No', 'Yes'), ('Chicago Fire', 36.0, 44.0, 1.2, 1.47, 8, 8, -8.0, 'No', 'Yes', 'No', 'No'), ('Dallas Burn', 34.0, 45.0, 1.13, 1.5, 9, 9, -11.0, 'No', 'Yes', 'No', 'No')]",m_1764879782031_4d29990f_1246208-5,"STEP 1: Parse the SQL intent — compute numeric Goals For/Against averages and their ranks, compute goal_difference (Goals For - Goals Against), produce Yes/No flags for Positive Goal Differential, Concedes Frequently (ga_avg>1.40), Top Offensive (gf_rank<=3), Top Defensive (ga_rank<=3), and return all clubs ordered by goal_difference DESC, gf_avg DESC. STEP 2: Choose ambiguity type — scope ambiguity fits: the phrase 'top offensively and defensively' can refer to different scopes (both categories jointly, either category, or separate lists). This fits because the query produces separate Top Offensive and Top Defensive flags but does not filter or clarify a combined interpretation. STEP 3: Draft the question — ""Which clubs are top offensively and defensively?"" STEP 4: Explain the ambiguity — in the original query each club is labeled Yes/No for Top Offensive and Top Defensive and all clubs are returned; one interpretation of the question asks for clubs that are top in both categories (intersection), another asks for clubs that are top in at least one category (union), and another asks simply to list the top offensive clubs and top defensive clubs separately; the SQL's output (flags per club, sorted by goal differential) is consistent with any of these interpretations but does not resolve which scope is intended.",persona,"Performance Analyst for an MLS club who monitors team attacking and defensive metrics to inform training, scouting, and match preparation. They would use this dataset to compare clubs' goals scored/conceded and per-game averages to identify strengths, weaknesses, and tactical matchups. Goals: Quantify each opponent's offensive and defensive strengths (total goals and per-game averages) to prepare game plans. Identify teams with positive goal differential and those conceding frequently to prioritize scouting and tactical focus. Produce shortlists of top offensive teams and top defensive teams (by goals-against average/rank) for briefing coaches and analysts. Example Queries: /* Rank teams by goal differential (Goals For - Goals Against) */
SELECT
  ""Club"",
  ""Goals For"",
  ""Goals Against"",
  (""Goals For"" - ""Goals Against"") AS goal_difference
FROM table_1_1246208_5
ORDER BY goal_difference DESC; /* List teams with a goals-for average above 1.35 (extract numeric part from 'Goals For Avg.') */
SELECT
  ""Club"",
  ""Goals For"",
  ""Goals For Avg.""
FROM table_1_1246208_5
WHERE CAST(SUBSTR(""Goals For Avg."", 1, INSTR(""Goals For Avg."", ' ')-1) AS REAL) > 1.35
ORDER BY CAST(SUBSTR(""Goals For Avg."", 1, INSTR(""Goals For Avg."", ' ')-1) AS REAL) DESC; /* Select clubs that rank in the top 3 for fewest goals conceded using the textual rank in 'Goals Against Avg.' */
SELECT
  ""Club"",
  ""Goals Against"",
  ""Goals Against Avg.""
FROM table_1_1246208_5
WHERE ""Goals Against Avg."" LIKE '%(1st)%'
   OR ""Goals Against Avg."" LIKE '%(2nd)%'
   OR ""Goals Against Avg."" LIKE '%(3rd)%'
ORDER BY CAST(SUBSTR(""Goals Against Avg."", 1, INSTR(""Goals Against Avg."", ' ')-1) AS REAL);",N/A,split_column,"type: Scope ambiguity | explanation: The phrase 'top offensively and defensively' could mean clubs that are top in both categories (intersection), clubs that are top in either category (union), or a request to list top offensive clubs and top defensive clubs separately; the SQL returns per-club Top Offensive and Top Defensive flags (and all clubs), so it supports any of these readings but doesn't pick one."
"Grouped by County and excluding County 'Østfold', return County plus Total Population (SUM(Population)), Total Area km² (SUM(Area km²)), Weighted Density (ROUND(SUM(Population) * 1.0 / SUM(Area km²), 2)), Pop Above 200 (SUM((Density Population per km² > 200) * Population)), and Pct Pop Above 200 (ROUND(100.0 * SUM((Density Population per km² > 200) * Population) / SUM(Population), 2)) for counties where Pct Pop Above 200 > 50, limited to 5 counties?","
SELECT DISTINCT
  `County`,
  SUM(`Population`) `Total Population`,
  SUM(`Area km²`) `Total Area km²`,
  ROUND(SUM(`Population`) * 1.0 / SUM(`Area km²`),2) `Weighted Density`,
  SUM((`Density Population per km²`>200) * `Population`) `Pop Above 200`,
  ROUND(100.0 * SUM((`Density Population per km²`>200) * `Population`) / SUM(`Population`),2) `Pct Pop Above 200`
FROM `table_m_1764879786879_52191103_1246665_1`
WHERE `County` != '`Østfold`'
GROUP BY `County`
HAVING ROUND(100.0 * SUM((`Density Population per km²`>200) * `Population`) / SUM(`Population`),2) > 50
LIMIT 5;
","
SELECT DISTINCT
  col5,
  SUM(col1) `Total Population`,
  SUM(col2) `Total Area km²`,
  ROUND(SUM(col1) * 1.0 / SUM(col2),2) `Weighted Density`,
  SUM((col3>200) * col1) `Pop Above 200`,
  ROUND(100.0 * SUM((col3>200) * col1) / SUM(col1),2) `Pct Pop Above 200`
FROM `table_m_1764879786879_52191103_1246665_1`
WHERE col5 != '`Østfold`'
GROUP BY col5
HAVING ROUND(100.0 * SUM((col3>200) * col1) / SUM(col1),2) > 50
LIMIT 5;
","[('Akershus', 537799.0, 4571.0, 117.65, 305274.0, 56.76), ('Oslo', 590041.0, 426.0, 1385.07, 590041.0, 100.0)]",m_1764879786879_52191103_1246665-1,"Parse intent: group rows by County (excluding Østfold), sum population and area, compute weighted density and population/percentage living in places with density>200, filter to counties where that percentage exceeds 50 and cap results at 5. Map schema: reference the table's Population, Area km², Density Population per km² and County columns and the specific aggregations and rounding. Draft the question: ask for those aggregated fields and the specified predicates and limit. Validate: question mirrors SUMs, ROUND calculations, boolean density>200 multiplier, HAVING >50, and LIMIT 5.",reserved,8,N/A,add_column,
"List sectors sorted by population density (highest first) showing area, 2012 population, percentage change 2002–2012, density and a 'Rapid Growth Small Area' yes/no flag for growth over 75% with area under 100 km², and also report district total population, district average density, and district total area?","
SELECT
  `Sector`,
  `Area in sqkm`,
  `Population August 15, 2012`,
  `population_change_2002_2012_percentage`,
  `Population Density 2012 (km 2 )`,
  ROW_NUMBER() OVER (ORDER BY `Population Density 2012 (km 2 )` DESC) AS `Density Rank`,
  CASE WHEN CAST(`population_change_2002_2012_percentage` AS real) > 75 AND `Area in sqkm` < 100 THEN 'Yes' ELSE 'No' END AS `Rapid Growth Small Area`,
  (SELECT SUM(`Population August 15, 2012`) FROM `table_m_1764879795862_7209d62d_12496904_1`) AS `District Total Population`,
  (SELECT AVG(`Population Density 2012 (km 2 )`) FROM `table_m_1764879795862_7209d62d_12496904_1`) AS `District Average Density`,
  (SELECT SUM(`Area in sqkm`) FROM `table_m_1764879795862_7209d62d_12496904_1`) AS `District Total Area`
FROM `table_m_1764879795862_7209d62d_12496904_1`
ORDER BY `Density Rank`;
","
SELECT
  col1,
  col2,
  col3,
  col5,
  col6,
  ROW_NUMBER() OVER (ORDER BY col6 DESC) AS `Density Rank`,
  CASE WHEN CAST(col5 AS real) > 75 AND col2 < 100 THEN 'Yes' ELSE 'No' END AS `Rapid Growth Small Area`,
  (SELECT SUM(col3) FROM `table_m_1764879795862_7209d62d_12496904_1`) AS `District Total Population`,
  (SELECT AVG(col6) FROM `table_m_1764879795862_7209d62d_12496904_1`) AS `District Average Density`,
  (SELECT SUM(col2) FROM `table_m_1764879795862_7209d62d_12496904_1`) AS `District Total Area`
FROM `table_m_1764879795862_7209d62d_12496904_1`
ORDER BY `Density Rank`;
","[('Rukomo', 58.0, 34377.0, '64.1', 588.0, 1, 'No', 466944.0, 344.0, 1928.0), ('Mimuli', 48.0, 27366.0, '21.9', 573.0, 2, 'No', 466944.0, 344.0, 1928.0), ('Gatunda', 52.0, 27879.0, '41.4', 535.0, 3, 'No', 466944.0, 344.0, 1928.0), ('Karama', 53.0, 26727.0, '35.5', 499.0, 4, 'No', 466944.0, 344.0, 1928.0), ('Katabagemu', 98.0, 34651.0, '56.8', 354.0, 5, 'No', 466944.0, 344.0, 1928.0), ('Mukama', 64.0, 21819.0, '21.4', 339.0, 6, 'No', 466944.0, 344.0, 1928.0), ('Musheli', 96.0, 32403.0, '119.8', 338.0, 7, 'Yes', 466944.0, 344.0, 1928.0), ('Nyagatare', 164.0, 52125.0, '167.7', 317.0, 8, 'No', 466944.0, 344.0, 1928.0), ('Tabagwe', 106.0, 33322.0, '79.6', 313.0, 9, 'No', 466944.0, 344.0, 1928.0), ('Matimba', 79.0, 24168.0, '79.3', 307.0, 10, 'Yes', 466944.0, 344.0, 1928.0), ('Kiyombe', 69.0, 17061.0, '3.5', 247.0, 11, 'No', 466944.0, 344.0, 1928.0), ('Rwimiyaga', 309.0, 58847.0, '250.2', 190.0, 12, 'No', 466944.0, 344.0, 1928.0), ('Rwempasha', 169.0, 19328.0, '69.1', 115.0, 13, 'No', 466944.0, 344.0, 1928.0), ('Karangazi', 563.0, 56871.0, '167.8', 101.0, 14, 'No', 466944.0, 344.0, 1928.0)]",m_1764879795862_7209d62d_12496904-1,"As someone prioritising services I might ask for a ranked list with a simple rapid-growth flag and district summary. The SQL orders sectors by population density descending, computes a density rank, marks sectors with >75% growth and area <100 km² as 'Yes', and adds district total population, average density, and total area. The columns used are Sector, Area in sqkm, Population August 15, 2012, Population Change 2002-2012 (%), and Population Density 2012 (km 2 ), plus the aggregates. List sectors sorted by population density (highest first) showing area, 2012 population, percentage change 2002–2012, density and a 'Rapid Growth Small Area' yes/no flag for growth over 75% with area under 100 km², and also report district total population, district average density, and district total area? This keeps to the data the query provides and its ordering.",persona,"Rural Infrastructure Planner at the Nyagatare District Council responsible for prioritizing roads, water, and school investments using sector-level population and density data to target limited resources effectively. Goals: Identify sectors with the highest population density to prioritize basic services (water, sanitation, schools). Spot rapidly growing sectors (2002–2012) with small land area where infrastructure capacity may be strained. Estimate overall district population and average density to inform budget allocation and long-term planning. Example Queries: SELECT ""Sector"", ""Area in sqkm"", ""Population August 15, 2012"", ""Population Density 2012 (km 2 )"" FROM table_1_12496904_1 ORDER BY ""Population Density 2012 (km 2 )"" DESC LIMIT 5; SELECT ""Sector"", ""Area in sqkm"", ""Population August 15, 2012"", ""Population Change 2002-2012 (%)"" FROM table_1_12496904_1 WHERE CAST(""Population Change 2002-2012 (%)"" AS real) > 75 AND ""Area in sqkm"" < 100 ORDER BY CAST(""Population Change 2002-2012 (%)"" AS real) DESC; SELECT SUM(""Population August 15, 2012"") AS total_population, AVG(""Population Density 2012 (km 2 )"") AS avg_density, SUM(""Area in sqkm"") AS total_area FROM table_1_12496904_1;",N/A,rename_column,
"For players with Games Played greater than 20, who are the five players with the smallest GA per 90 (GA per 90 = ROUND((Goals Against * 1.0) / (Minutes / 90.0), 2)), and what is each Player's GA per 90 and Win Diff calculated as (Wins - Loses)?","
SELECT `Player`, ROUND((`Goals Against` * 1.0) / (`Minutes` / 90.0), 2) AS `GA per 90`, (`wins_count` - `Loses`) AS `Win Diff`
FROM `table_m_1764879805453_91da3212_1255110_7`
WHERE `Games Played` > 20
GROUP BY `Player`
ORDER BY `GA per 90`
LIMIT 5;
","
SELECT col1, ROUND((col5 * 1.0) / (col4 / 90.0), 2) AS `GA per 90`, (col7 - col8) AS `Win Diff`
FROM `table_m_1764879805453_91da3212_1255110_7`
WHERE col3 > 20
GROUP BY col1
ORDER BY `GA per 90`
LIMIT 5;
","[('Brad Friedel', 1.21, -1.0), ('Walter Zenga', 1.27, 8.0), ('Marcus Hahnemann', 1.54, 3.0), ('Mike Ammann', 1.56, 13.0), ('Mark Dodd', 1.6, -2.0)]",m_1764879805453_91da3212_1255110-7,"Parse intent: return Player plus two derived metrics (rounded GA per 90 and Wins-Loses), filtered by Games Played > 20, grouped by Player, sorted by GA per 90 ascending, limited to 5. Map schema: use Player, Goals Against, Minutes, Wins, Loses, Games Played from the table. Draft: request the five players with smallest GA per 90 including the exact formula and Win Diff. Validate: question contains formula, rounding, Win Diff definition, filter, ordering, and limit.",reserved,9,N/A,rename_column,
"For each Builder (grouped by Builder) who built ships with Laid down = 1862 and who has more than zero ships and at least one Renamed entry not equal to 'Not Applicable', what are the Builder name, Total Ships (COUNT(*)), Renamed Count (count where Renamed != 'Not Applicable'), the counts for Ajax, Canonicus, Catawba, Mahopac, Manhattan, Oneota, Saugus and Tecumseh, a comma-separated list of Ships, the Earliest Laid down (MIN Laid down), the Latest Launched (MAX Launched), and a Not Applicable column equal to 0, ordered by Renamed Count descending and limited to the top 10?","
SELECT `Builder` AS `Builder`, COUNT(*) AS `Total Ships`, SUM(CASE WHEN `Renamed` != 'Not Applicable' THEN 1 ELSE 0 END) AS `Renamed Count`, SUM(CASE WHEN `Ship` = 'Ajax' THEN 1 ELSE 0 END) AS `Ajax`, SUM(CASE WHEN `Ship` = 'Canonicus' THEN 1 ELSE 0 END) AS `Canonicus`, SUM(CASE WHEN `Ship` = 'Catawba' THEN 1 ELSE 0 END) AS `Catawba`, SUM(CASE WHEN `Ship` = 'Mahopac' THEN 1 ELSE 0 END) AS `Mahopac`, SUM(CASE WHEN `Ship` = 'Manhattan' THEN 1 ELSE 0 END) AS `Manhattan`, SUM(CASE WHEN `Ship` = 'Oneota' THEN 1 ELSE 0 END) AS `Oneota`, SUM(CASE WHEN `Ship` = 'Saugus' THEN 1 ELSE 0 END) AS `Saugus`, SUM(CASE WHEN `Ship` = 'Tecumseh' THEN 1 ELSE 0 END) AS `Tecumseh`, GROUP_CONCAT(`Ship`, ', ') AS `Ships`, MIN(`Laid down`) AS `Earliest Laid down`, MAX(`Launched`) AS `Latest Launched`, 0 AS `Not Applicable` FROM `table_m_1764879846593_ead65ace_12592074_1` WHERE `Laid down` = 1862 GROUP BY `Builder` HAVING COUNT(*) > 0 AND SUM(CASE WHEN `Renamed` != 'Not Applicable' THEN 1 ELSE 0 END) > 0 ORDER BY `Renamed Count` DESC LIMIT 10;
","
SELECT col1 AS col1, COUNT(*) AS `Total Ships`, SUM(CASE WHEN col2 != 'Not Applicable' THEN 1 ELSE 0 END) AS `Renamed Count`, SUM(CASE WHEN col0 = 'Ajax' THEN 1 ELSE 0 END) AS `Ajax`, SUM(CASE WHEN col0 = 'Canonicus' THEN 1 ELSE 0 END) AS `Canonicus`, SUM(CASE WHEN col0 = 'Catawba' THEN 1 ELSE 0 END) AS `Catawba`, SUM(CASE WHEN col0 = 'Mahopac' THEN 1 ELSE 0 END) AS `Mahopac`, SUM(CASE WHEN col0 = 'Manhattan' THEN 1 ELSE 0 END) AS `Manhattan`, SUM(CASE WHEN col0 = 'Oneota' THEN 1 ELSE 0 END) AS `Oneota`, SUM(CASE WHEN col0 = 'Saugus' THEN 1 ELSE 0 END) AS `Saugus`, SUM(CASE WHEN col0 = 'Tecumseh' THEN 1 ELSE 0 END) AS `Tecumseh`, GROUP_CONCAT(col0, ', ') AS `Ships`, MIN(col3) AS `Earliest Laid down`, MAX(col4) AS `Latest Launched`, 0 AS `Not Applicable` FROM `table_m_1764879846593_ead65ace_12592074_1` WHERE col3 = 1862 GROUP BY col1 HAVING COUNT(*) > 0 AND SUM(CASE WHEN col2 != 'Not Applicable' THEN 1 ELSE 0 END) > 0 ORDER BY `Renamed Count` DESC LIMIT 10;
","[('Alexander Swift & Company, Cincinnati, Ohio', 2, 2, 0, 0, 1, 0, 0, 1, 0, 0, 'Catawba, Oneota', 1862.0, '21 May 1864', 0), ('Snowden & Mason, Pittsburgh, Pennsylvania', 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 'Ajax', 1862.0, '18 December 1864', 0), ('Secor & Co., Jersey City, New Jersey', 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 'Mahopac', 1862.0, '17 May 1864', 0), ('Perine, Secor & Co., Jersey City, New Jersey', 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 'Manhattan', 1862.0, '14October1863', 0), ('Harrison Loring, Boston, Massachusetts', 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 'Canonicus', 1862.0, '1August1863', 0), ('Harlan & Hollingsworth , Wilmington, Delaware', 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 'Saugus', 1862.0, '8 February 1864', 0)]",m_1764879846593_ead65ace_12592074-1,"1) Parse intent: filter to Laid down = 1862, group by Builder, compute total and renamed counts, compute per-ship-name counts, concatenate ship names, find MIN Laid down and MAX Launched, include a constant 0 column, require builders to have >0 ships and >0 renamed ships, sort by renamed count and limit 10. 2) Map schema: columns Builder, Ship, Renamed, Laid down, Launched correspond to table fields. 3) Draft: convert these requirements into a single natural question listing all requested output columns and constraints. 4) Validate: ensure the question explicitly names every aggregate and the Renamed != 'Not Applicable' condition, grouping, ordering and limit.",reserved,16,N/A,merge_column,
"List the top 10 distinct Committee and Party combinations by Avg_Tenure (where Avg_Tenure = AVG(2025 - First Elected)), showing Committee, Party, Members (COUNT(*)), Avg_Tenure, Tenure_Level (CASE: 'High Tenure' if Avg_Tenure >= 20, 'Medium Tenure' if Avg_Tenure >= 10, else 'Low Tenure'), and Committee_Rank (row number partitioned by Committee ordered by Avg_Tenure DESC), including only groups with at least one member and ordering the results by Avg_Tenure descending.","
SELECT DISTINCT `Committee`, `Party`,
  COUNT(*) AS `Members`,
  AVG(2025 - `First Elected`) AS `Avg_Tenure`,
  CASE WHEN AVG(2025 - `First Elected`) >= 20 THEN 'High Tenure' WHEN AVG(2025 - `First Elected`) >= 10 THEN 'Medium Tenure' ELSE 'Low Tenure' END AS `Tenure_Level`,
  ROW_NUMBER() OVER (PARTITION BY `Committee` ORDER BY AVG(2025 - `First Elected`) DESC) AS `Committee_Rank`
FROM `table_m_1764879898706_7bf7e3d7_12679326_1`
GROUP BY `Committee`, `Party`
HAVING COUNT(*) >= 1
ORDER BY `Avg_Tenure` DESC
LIMIT 10;
","
SELECT DISTINCT col4, col2,
  COUNT(*) AS `Members`,
  AVG(2025 - col3) AS `Avg_Tenure`,
  CASE WHEN AVG(2025 - col3) >= 20 THEN 'High Tenure' WHEN AVG(2025 - col3) >= 10 THEN 'Medium Tenure' ELSE 'Low Tenure' END AS `Tenure_Level`,
  ROW_NUMBER() OVER (PARTITION BY col4 ORDER BY AVG(2025 - col3) DESC) AS `Committee_Rank`
FROM `table_m_1764879898706_7bf7e3d7_12679326_1`
GROUP BY col4, col2
HAVING COUNT(*) >= 1
ORDER BY `Avg_Tenure` DESC
LIMIT 10;
","[('Health and Government Operations', 'Republican', 2, 49.0, 'High Tenure', 1), ('Economic Matters', 'Democratic', 2, 34.0, 'High Tenure', 1), ('Environmental Matters (Vice-Chair)', 'Democratic', 1, 31.0, 'High Tenure', 1), ('Health and Government Operations', 'Democratic', 3, 28.333333333333332, 'High Tenure', 2), ('Appropriations', 'Democratic', 2, 25.5, 'High Tenure', 1), ('Appropriations', 'Republican', 1, 23.0, 'High Tenure', 2), ('Economic Matters', 'Republican', 1, 23.0, 'High Tenure', 2), ('Environmental Matters', 'Republican', 1, 23.0, 'High Tenure', 1), ('Ways and Means', 'Republican', 1, 23.0, 'High Tenure', 1), ('Ways and Means', 'Democratic', 1, 23.0, 'High Tenure', 2)]",m_1764879898706_7bf7e3d7_12679326-1,"1) Parse: the SQL produces distinct Committee/Party groups with Members count, average tenure (2025 minus First Elected), a three-tier tenure label, and a per-Committee rank, filtered by COUNT(*) >= 1 and limited to 10 ordered by average tenure. 2) Map: use table columns Committee, Party, First Elected to compute Members and Avg_Tenure; derive Tenure_Level per thresholds and Committee_Rank via row numbering partitioned by Committee. 3) Draft: ask for the top 10 committee-party combinations with these computed fields. 4) Validate: ensure the question explicitly requests the COUNT, AVG formula, CASE thresholds, ranking rule, HAVING condition, ordering, and limit.",reserved,27,N/A,split_column,
Which marine organisms have FDA-approved compounds for cancer?,unanswerable,unanswerable,,m_1764879909483_74297213_12715053-1,"STEP 1: Parse the SQL intent: the query returns up to 20 rows of Marine Organism α, Clinical Status, and Compound Name for rows where Disease Area = 'Cancer', Clinical Status = 'FDA-Approved', and Chemical Class is not empty; results are grouped by organism/status/compound and ordered by organism. STEP 2: Determine ambiguity type: scope ambiguity — asking ""which organisms have FDA-approved compounds for cancer"" can mean (a) list each organism once (distinct organisms) or (b) list each organism-compound pair (one row per approved compound). STEP 3: Draft the question: ""Which marine organisms have FDA-approved compounds for cancer?"" STEP 4: Explain the ambiguity: the original SQL produces organism + compound name rows (interpretation b). Alternatively the question could be interpreted to request only the distinct organisms that have any FDA-approved cancer compound (interpretation a), or to ask which organism has the most such compounds (a different scope).",reserved,13,N/A,merge_column,"type: Scope ambiguity | explanation: The SQL returns organism + compound name rows (each FDA-approved cancer compound and its source organism). The natural-language question could instead be read as asking only for the distinct set of organisms that have any FDA-approved cancer compound, or even as asking which organism has the most such compounds—different scopes of 'which'."
Which sequencer is the most efficient per run?,"
SELECT DISTINCT
 ((100.0+200.0)/2.0) `Ion Torrent PGM - Data output per run`,
 (0.7*1000.0) `454 GS FLX - Data output per run`,
 (600.0*1000.0) `HiSeq 2000 - Data output per run`,
 (120.0*1000.0) `SOLiDv4 - Data output per run`,
 ((1500.0+5000.0)/2.0) `PacBio - Data output per run`,
 CAST(((1.9+84.0)/2.0/1000.0) AS REAL) `Sanger 3730xl - Data output per run`,
 (350.0/(((100.0+200.0)/2.0))) `Ion Torrent PGM - Cost per run / Data output per run (Cost per Mb calc)`,
 (7000.0/(0.7*1000.0)) `454 GS FLX - Cost per run / Data output per run (Cost per Mb calc)`,
 (6000.0/(600.0*1000.0)) `HiSeq 2000 - Cost per run / Data output per run (Cost per Mb calc)`,
 (4000.0/(120.0*1000.0)) `SOLiDv4 - Cost per run / Data output per run (Cost per Mb calc)`,
 (300.0/(((1500.0+5000.0)/2.0))) `PacBio - Cost per run / Data output per run (Cost per Mb calc)`,
 (4.0/(((1.9+84.0)/2.0/1000.0))) `Sanger 3730xl - Cost per run / Data output per run (Cost per Mb calc)`,
 (99.0/(350.0/(((100.0+200.0)/2.0)))) `Ion Torrent PGM - Efficiency (Accuracy / Cost per Mb)`,
 (99.9/(7000.0/(0.7*1000.0))) `454 GS FLX - Efficiency (Accuracy / Cost per Mb)`,
 (99.9/(6000.0/(600.0*1000.0))) `HiSeq 2000 - Efficiency (Accuracy / Cost per Mb)`,
 (99.94/(4000.0/(120.0*1000.0))) `SOLiDv4 - Efficiency (Accuracy / Cost per Mb)`,
 (90.0/(300.0/(((1500.0+5000.0)/2.0)))) `PacBio - Efficiency (Accuracy / Cost per Mb)`,
 (99.999/(4.0/(((1.9+84.0)/2.0/1000.0)))) `Sanger 3730xl - Efficiency (Accuracy / Cost per Mb)`,
 CASE WHEN 1=1 THEN 1 END `Case_Check`
WHERE 1=1
GROUP BY 1
HAVING 1
LIMIT 3;
","
SELECT DISTINCT
 ((100.0+200.0)/2.0) `Ion Torrent PGM - Data output per run`,
 (0.7*1000.0) `454 GS FLX - Data output per run`,
 (600.0*1000.0) `HiSeq 2000 - Data output per run`,
 (120.0*1000.0) `SOLiDv4 - Data output per run`,
 ((1500.0+5000.0)/2.0) `PacBio - Data output per run`,
 CAST(((1.9+84.0)/2.0/1000.0) AS REAL) `Sanger 3730xl - Data output per run`,
 (350.0/(((100.0+200.0)/2.0))) `Ion Torrent PGM - Cost per run / Data output per run (Cost per Mb calc)`,
 (7000.0/(0.7*1000.0)) `454 GS FLX - Cost per run / Data output per run (Cost per Mb calc)`,
 (6000.0/(600.0*1000.0)) `HiSeq 2000 - Cost per run / Data output per run (Cost per Mb calc)`,
 (4000.0/(120.0*1000.0)) `SOLiDv4 - Cost per run / Data output per run (Cost per Mb calc)`,
 (300.0/(((1500.0+5000.0)/2.0))) `PacBio - Cost per run / Data output per run (Cost per Mb calc)`,
 (4.0/(((1.9+84.0)/2.0/1000.0))) `Sanger 3730xl - Cost per run / Data output per run (Cost per Mb calc)`,
 (99.0/(350.0/(((100.0+200.0)/2.0)))) `Ion Torrent PGM - Efficiency (Accuracy / Cost per Mb)`,
 (99.9/(7000.0/(0.7*1000.0))) `454 GS FLX - Efficiency (Accuracy / Cost per Mb)`,
 (99.9/(6000.0/(600.0*1000.0))) `HiSeq 2000 - Efficiency (Accuracy / Cost per Mb)`,
 (99.94/(4000.0/(120.0*1000.0))) `SOLiDv4 - Efficiency (Accuracy / Cost per Mb)`,
 (90.0/(300.0/(((1500.0+5000.0)/2.0)))) `PacBio - Efficiency (Accuracy / Cost per Mb)`,
 (99.999/(4.0/(((1.9+84.0)/2.0/1000.0)))) `Sanger 3730xl - Efficiency (Accuracy / Cost per Mb)`,
 CASE WHEN 1=1 THEN 1 END `Case_Check`
WHERE 1=1
GROUP BY 1
HAVING 1
LIMIT 3;
","[(150.0, 700.0, 600000.0, 120000.0, 3250.0, 0.04295, 2.3333333333333335, 10.0, 0.01, 0.03333333333333333, 0.09230769230769231, 93.13154831199068, 42.42857142857142, 9.99, 9990.0, 2998.2, 975.0, 1.0737392625, 1)]",m_1764879938166_abd9ccf4_127511-1,"STEP 1: Parse the SQL intent — the query computes, for each listed sequencer, a Data output per run (constants/averages), Cost per Mb (cost per run divided by data output), and an Efficiency measure defined as Accuracy / (Cost per Mb); it returns those computed columns (grouped/limited but effectively producing per-sequencer metrics).
STEP 2: Determine ambiguity type — scope ambiguity fits well: the natural question could ask for the efficiency value for every sequencer (a list of values) or ask for the single most efficient sequencer (a top-1 answer).
STEP 3: Draft the question — ""Which sequencer is the most efficient per run?""
STEP 4: Explain the ambiguity — the original SQL provides an efficiency number for each sequencer (so it can be read as returning per-sequencer efficiencies), but the NL question can also be read as requesting a single winner (the sequencer with the maximum efficiency), which would require ordering/aggregation; thus the question is ambiguous between returning all efficiencies and returning the top sequencer.",reserved,13,N/A,split_column,"type: Scope ambiguity | explanation: The SQL computes an efficiency value for each sequencer (accuracy divided by cost per Mb) and returns those values, so the question could mean either (a) ""show the efficiency for each sequencer"" (the per-sequencer list the query produces) or (b) ""which single sequencer has the highest efficiency"" (a top-1 selection), creating a scope ambiguity between listing all items vs selecting the best one."
"For which five celebrity partners (only those with more than one dance and an overall average > 0) list the partner name and these metrics: AvgScore = ROUND(AVG((Horwood + Phillips + Goodman + Tonioli)/4.0),2), PeakScore = ROUND(MAX((Horwood + Phillips + Goodman + Tonioli)/4.0),2), LowScore = ROUND(MIN((Horwood + Phillips + Goodman + Tonioli)/4.0),2), MaxDisagreement = ROUND(MAX(MAX(Horwood,Phillips,Goodman,Tonioli) - MIN(Horwood,Phillips,Goodman,Tonioli)),2), and DancesCount = COUNT(*), ordered by AvgScore descending and limited to 5?","
SELECT `Celebrity partner` AS `Partner`,
       ROUND(AVG((`Horwood`+`Phillips`+`Goodman`+`Tonioli`)/4.0),2) AS `AvgScore`,
       ROUND(MAX((`Horwood`+`Phillips`+`Goodman`+`Tonioli`)/4.0),2) AS `PeakScore`,
       ROUND(MIN((`Horwood`+`Phillips`+`Goodman`+`Tonioli`)/4.0),2) AS `LowScore`,
       ROUND(MAX(MAX(`Horwood`,`Phillips`,`Goodman`,`Tonioli`) - MIN(`Horwood`,`Phillips`,`Goodman`,`Tonioli`)),2) AS `MaxDisagreement`,
       COUNT(*) AS `DancesCount`
FROM `table_m_1764879955481_5ee903d1_1276219_1` AS `t`
GROUP BY `Celebrity partner`
HAVING COUNT(*) > 1 AND AVG((`Horwood`+`Phillips`+`Goodman`+`Tonioli`)/4.0) > 0
ORDER BY `AvgScore` DESC
LIMIT 5;
","
SELECT col1 AS `Partner`,
       ROUND(AVG((col4+col5+col6+col7)/4.0),2) AS `AvgScore`,
       ROUND(MAX((col4+col5+col6+col7)/4.0),2) AS `PeakScore`,
       ROUND(MIN((col4+col5+col6+col7)/4.0),2) AS `LowScore`,
       ROUND(MAX(MAX(col4,col5,col6,col7) - MIN(col4,col5,col6,col7)),2) AS `MaxDisagreement`,
       COUNT(*) AS `DancesCount`
FROM `table_m_1764879955481_5ee903d1_1276219_1` AS `t`
GROUP BY col1
HAVING COUNT(*) > 1 AND AVG((col4+col5+col6+col7)/4.0) > 0
ORDER BY `AvgScore` DESC
LIMIT 5;
","[('Emma Bunton', 8.5, 9.25, 7.5, 2.0, 13), ('Jill Halfpenny', 8.43, 10.0, 6.75, 1.0, 11), ('Letitia Dean', 7.36, 8.75, 5.75, 3.0, 11), ('Lynda Bellingham', 5.75, 6.25, 5.25, 4.0, 3), ('Jessie Wallace', 4.88, 5.0, 4.75, 3.0, 2)]",m_1764879955481_5ee903d1_1276219-1,"1) Parse intent: aggregate judge scores per celebrity to produce summary statistics and select the top five by average. 2) Map schema: use Celebrity partner as Partner and Horwood/Phillips/Goodman/Tonioli as the four judges to compute per-dance and per-partner metrics. 3) Draft: ask for Partner, rounded AvgScore of the four judges per dance, rounded PeakScore and LowScore of that per-dance average, rounded MaxDisagreement across dances, and DancesCount, applying filters COUNT>1 and Avg>0, sorted by AvgScore desc limit 5. 4) Validate: ensures rounding to 2 decimals, uses the exact calculations and filters from the query.",reserved,11,N/A,add_column,
"From records where Tamil = 1 and (Bengali = 1 OR Marathi = 1), what single Consensus value — defined as CASE WHEN Tamil = 1 AND Sanskrit = 1 THEN Tamil ELSE Hindi END — is produced after grouping by Tamil, ordering by Tamil, and limiting to one row?",unanswerable,unanswerable,,m_1764879969188_ba060641_1277350-3,"1) The intent is to return one aggregated row named Consensus choosing Tamil when both Tamil and Sanskrit equal 1, else Hindi. 2) Identify the filter Tamil=1 and the additional condition (Bengali=1 OR Marathi=1), and the grouping/ordering by Tamil with a limit of 1. 3) Phrase a question that requests that single Consensus value and explicitly includes the CASE, the involved columns, the WHERE clause, GROUP BY, ORDER BY, and LIMIT. 4) Confirm the question aligns exactly with the SQL operations and referenced columns.",reserved,18,N/A,merge_column,
"For which five Day (see Irregularities ) entries (listed as Icelandic) does the computed Any_symbol equal 1 — where Any_symbol is defined as CASE WHEN (Sunday Day One || Friday Day Six || Saturday Day Seven) LIKE '%☉%' OR (Sunday Day One || Friday Day Six || Saturday Day Seven) LIKE '%♀%' THEN 1 ELSE 0 END — considering only rows where (Sunday Day One || Friday Day Six || Saturday Day Seven) IS NOT NULL and Day (see Irregularities ) <> '', grouping by Icelandic and ordering the results by Icelandic DESC and limiting to 5?","
SELECT `day_of_week` `Icelandic`,
  CASE WHEN ((`sunday` || `Friday Day Six` || `Saturday Day Seven`) LIKE '%☉%' OR (`sunday` || `Friday Day Six` || `Saturday Day Seven`) LIKE '%♀%') THEN 1 ELSE 0 END `Any_symbol`
FROM `table_m_1764879977038_8b949535_1277350_7`
WHERE (`sunday` || `Friday Day Six` || `Saturday Day Seven`) IS NOT NULL AND `day_of_week` <> ''
GROUP BY `Icelandic`
HAVING `Any_symbol` = 1
ORDER BY `Icelandic` DESC
LIMIT 5;
","
SELECT col0 `Icelandic`,
  CASE WHEN ((col1 || col6 || col7) LIKE '%☉%' OR (col1 || col6 || col7) LIKE '%♀%') THEN 1 ELSE 0 END `Any_symbol`
FROM `table_m_1764879977038_8b949535_1277350_7`
WHERE (col1 || col6 || col7) IS NOT NULL AND col0 <> ''
GROUP BY `Icelandic`
HAVING `Any_symbol` = 1
ORDER BY `Icelandic` DESC
LIMIT 5;
","[('Vietnamese', 1), ('Sundanese', 1), ('Portuguese', 1), ('Persian', 1), ('Maltese', 1)]",m_1764879977038_8b949535_1277350-7,"1) The query tests whether any of three columns include astronomical symbols and returns a binary Any_symbol per Icelandic row, then filters to rows where Any_symbol = 1 and limits to 5 ordered descending. 2) Identify the three source columns (Sunday Day One, Friday Day Six, Saturday Day Seven) and the output column Day (see Irregularities ) aliased Icelandic. 3) Compose a question asking for the Icelandic day and the calculated Any_symbol with the exact LIKE '%☉%' OR LIKE '%♀%' check, non-NULL concatenation, grouping, HAVING and ordering/limit. 4) Ensure the question explicitly mentions all columns, the concatenation/LIKE checks, grouping and limit.",reserved,22,N/A,rename_column,
"Considering only rows where Revenues is not an empty string and only lineages whose concatenated name list is non-empty, for each Lineage what are: the Lineage, COUNT(Name), the SUM of Revenues after removing any commas and the trailing ' koku' and casting to INTEGER as TotalRevenues, the GROUP_CONCAT of Name using '; ' between names, and a value '`13,000 koku`' returned only when the minimum Revenues for that Lineage equals '13,000 koku'; then order the results by TotalRevenues in descending order and limit the output to 10 rows?","
SELECT `Lineage`,
COUNT(`Name`),
SUM(CAST(REPLACE(REPLACE(`Revenues`, ',', ''), ' koku', '') AS INTEGER) ) `TotalRevenues`,
GROUP_CONCAT(`Name`, '; '),
CASE WHEN MIN(`Revenues`) = '13,000 koku' THEN '`13,000 koku`' END
FROM `table_m_1764879984263_e326b1fa_12803263_1`
WHERE `Revenues` != ''
GROUP BY `Lineage`
HAVING GROUP_CONCAT(`Name`) != ''
ORDER BY `TotalRevenues` DESC
LIMIT 10;
","
SELECT col5,
COUNT(col1),
SUM(CAST(REPLACE(REPLACE(col4, ',', ''), ' koku', '') AS INTEGER) ) `TotalRevenues`,
GROUP_CONCAT(col1, '; '),
CASE WHEN MIN(col4) = '13,000 koku' THEN '`13,000 koku`' END
FROM `table_m_1764879984263_e326b1fa_12803263_1`
WHERE col4 != ''
GROUP BY col5
HAVING GROUP_CONCAT(col1) != ''
ORDER BY `TotalRevenues` DESC
LIMIT 10;
","[('3rd son of Ogasawara Nagamichi', 1, 13000, 'Ōoka Tadatomo (大岡忠與)', '`13,000 koku`'), ('son of Tadayori', 1, 10000, 'Ōoka Tadayoshi (2nd) (大岡忠愛)', None), ('4th son of hatamoto Ōoka Tadataka', 1, 10000, 'Ōoka Tadasuke (大岡忠相)', None), ('3rd son of Tadatsune', 1, 10000, 'Ōoka Tadayori (大岡忠移)', None), ('2nd son of Tadayoshi', 1, 10000, 'Ōoka Tadatsune (大岡忠恒)', None), ('2nd son of Tadasuke', 1, 10000, 'Ōoka Tadayoshi (大岡忠宜)', None)]",m_1764879984263_e326b1fa_12803263-1,"1) Parse intent: aggregate data by Lineage with COUNT(Name), SUM of cleaned Revenues as TotalRevenues, GROUP_CONCAT(Name, '; '), and a CASE that yields '`13,000 koku`' when MIN(Revenues) = '13,000 koku', filtering out empty Revenues and empty concatenations, ordering by total revenues descending and limiting to 10. 2) Map schema: interpret Revenues strings like '10,000 koku' that must be cleansed and cast to integer. 3) Draft: request exactly those fields, transformations, filters, ordering, and limit. 4) Validate: confirm all SQL-selected columns and calculations are mentioned and no extra details are added.",reserved,18,N/A,remove_column,
"Show distinct Barrel length and COUNT(*) as 'Model count' for non-empty Barrel length values, grouped by Barrel length but only include groups with COUNT(*) > 1, and limit the results to 10?",unanswerable,unanswerable,,m_1764879994783_d9680118_12834315-2,"1) The statement groups by Barrel length, counts models per group, removes empty barrel lengths, filters to groups with COUNT(*) > 1, and restricts output to 10. 2) Recognize 'Barrel length' and the aggregation COUNT(*) labeled 'Model count' as the required output. 3) Craft a question that requests distinct Barrel length and COUNT(*) labeled Model count with the WHERE, GROUP BY, HAVING, and LIMIT conditions. 4) Confirm all SQL components (DISTINCT Barrel length, COUNT(*) Model count, WHERE `Barrel length` <> '', HAVING COUNT(*) > 1, LIMIT 10) are represented.",reserved,8,N/A,merge_column,
"Which Clubs meet the criteria Points for < Points against and Won * 1.0 / Played < 0.5, and for each such Club return Club, (Points for - Points against), (Tries for - Tries against), ROUND(Won * 1.0 / Played * 100, 2) as the win percentage, and (Try bonus + Losing bonus) * 1.0 / Played as the per-game bonus rate, grouping by Club, Played, Won, Drawn, Lost, Points for, Points against, Tries for, Tries against, Try bonus, Losing bonus, Points and ordering the results by Points descending?","
SELECT `team_name`, (`points_for` - `Points against`), (`Tries for` - `Tries against`), ROUND(`Won` * 1.0 / `matches_played` * 100, 2), (`Try bonus` + `Losing bonus`) * 1.0 / `matches_played`
FROM `table_m_1764880012227_643be824_12886178_4`
WHERE `points_for` < `Points against` AND `Won` * 1.0 / `matches_played` < 0.5
GROUP BY `team_name`, `matches_played`, `Won`, `Drawn`, `Lost`, `points_for`, `Points against`, `Tries for`, `Tries against`, `Try bonus`, `Losing bonus`, `Points`
ORDER BY `Points` DESC;
","
SELECT col0, (col5 - col6), (col7 - col8), ROUND(col2 * 1.0 / col1 * 100, 2), (col9 + col10) * 1.0 / col1
FROM `table_m_1764880012227_643be824_12886178_4`
WHERE col5 < col6 AND col2 * 1.0 / col1 < 0.5
GROUP BY col0, col1, col2, col3, col4, col5, col6, col7, col8, col9, col10, col11
ORDER BY col11 DESC;
","[('Gwernyfed RFC', -71, -11, 36.36, 0.3181818181818182), ('Newport HSOB RFC', -205, -33, 40.91, 0.22727272727272727), ('Cwmbran RFC', -147, -26, 40.91, 0.13636363636363635), ('Abertillery RFC', -130, -21, 36.36, 0.18181818181818182), ('New Tredegar RFC', -303, -50, 4.55, 0.36363636363636365)]",m_1764880012227_643be824_12886178-4,"Parse SQL intent: identify teams with fewer points scored than conceded and a win rate less than 50%, compute point and try margins, the percent of games won rounded to two decimals, and average bonuses per match, then order by Points descending. Map schema semantics: calculations use table columns Club, Played, Won, Drawn, Lost, Points for, Points against, Tries for, Tries against, Try bonus, Losing bonus, Points. Draft the question: request the exact computed fields, apply the two filters, specify grouping by all listed columns, and order by Points DESC. Validate: confirms inclusion of all selected columns, arithmetic operations, rounding, WHERE conditions, GROUP BY, and ORDER BY.",reserved,8,N/A,rename_column,
"Which three Positions have the highest average Height (AvgHeight = average of Height cast to numeric) among players with Year born between 1975 and 1987, and for each Position report the count of players (Players) and that AvgHeight, including only Positions with Players > 1 and ordering by AvgHeight descending?","
SELECT `Position`, COUNT(*) AS `Players`, AVG(CAST(`Height` AS REAL)) AS `AvgHeight`
FROM `table_m_1764880054957_355257ca_12962773_15`
WHERE `Year born` BETWEEN 1975 AND 1987
GROUP BY `Position`
HAVING `Players` > 1
ORDER BY `AvgHeight` DESC
LIMIT 3;
","
SELECT col2, COUNT(*) AS `Players`, AVG(CAST(col1 AS REAL)) AS `AvgHeight`
FROM `table_m_1764880054957_355257ca_12962773_15`
WHERE col3 BETWEEN 1975 AND 1987
GROUP BY col2
HAVING `Players` > 1
ORDER BY `AvgHeight` DESC
LIMIT 3;
","[('Center', 2, 2.125), ('Forward', 3, 2.0566666666666666), ('Guard', 6, 1.9183333333333332)]",m_1764880054957_355257ca_12962773-15,"1) Parse intent: identify top three positions by average height for a given birth year range, reporting counts and averages only where count > 1. 2) Map schema: use Position, COUNT(*) as Players, AVG(CAST(Height AS REAL)) as AvgHeight, filter Year born BETWEEN 1975 AND 1987. 3) Draft the question to explicitly request those metrics and constraints. 4) Validate it mentions Players > 1, AvgHeight, ordering descending and LIMIT 3.",reserved,16,N/A,split_column,
"Give me each player's name, height, position, age in 2007, club, their stack rank (1 = tallest) and their scale as a decimal of the tallest player so I can size each sculpture layer?","
SELECT
  `Player`,
  `Height`,
  `Position`,
  (2007 - `Year born`) AS age_2007,
  `Current Club`,
  CAST(`Height` AS REAL) AS height_m,
  (SELECT COUNT(*) FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t2 WHERE CAST(t2.`Height` AS REAL) > CAST(t1.`Height` AS REAL)) + 1 AS stack_rank,
  ROUND((SELECT AVG(CAST(t3.`Height` AS REAL)) FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t3 WHERE t3.`Position` = t1.`Position`), 2) AS position_avg_height_m,
  ROUND(CAST(`Height` AS REAL) - (SELECT AVG(CAST(t4.`Height` AS REAL)) FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t4 WHERE t4.`Position` = t1.`Position`), 2) AS height_diff_from_position_avg_m,
  ROUND(CAST(`Height` AS REAL) / (SELECT MAX(CAST(t5.`Height` AS REAL)) FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t5), 3) AS relative_scale_to_tallest,
  (`Player` || ' — ' || (2007 - `Year born`) || ' yrs, ' || `Position` || ', ' || `Current Club`) AS plaque_text
FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t1
ORDER BY CAST(`Height` AS REAL) DESC;
","
SELECT
  col0,
  col1,
  col2,
  (2007 - col3) AS age_2007,
  col4,
  CAST(col1 AS REAL) AS height_m,
  (SELECT COUNT(*) FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t2 WHERE CAST(t2.col1 AS REAL) > CAST(t1.col1 AS REAL)) + 1 AS stack_rank,
  ROUND((SELECT AVG(CAST(t3.col1 AS REAL)) FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t3 WHERE t3.col2 = t1.col2), 2) AS position_avg_height_m,
  ROUND(CAST(col1 AS REAL) - (SELECT AVG(CAST(t4.col1 AS REAL)) FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t4 WHERE t4.col2 = t1.col2), 2) AS height_diff_from_position_avg_m,
  ROUND(CAST(col1 AS REAL) / (SELECT MAX(CAST(t5.col1 AS REAL)) FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t5), 3) AS relative_scale_to_tallest,
  (col0 || ' — ' || (2007 - col3) || ' yrs, ' || col2 || ', ' || col4) AS plaque_text
FROM `table_m_1764880058408_5f07f70b_12962773_5` AS t1
ORDER BY CAST(col1 AS REAL) DESC;
","[('Marc Gasol', '2.16', 'Center', 22.0, 'Akasvayu Girona', 2.16, 1, 2.12, 0.04, 1.0, 'Marc Gasol — 22.0 yrs, Center, Akasvayu Girona'), ('Pau Gasol', '2.13', 'Center', 27.0, 'Memphis Grizzlies', 2.13, 2, 2.12, 0.01, 0.986, 'Pau Gasol — 27.0 yrs, Center, Memphis Grizzlies'), ('Felipe Reyes', '2.06', 'Center', 27.0, 'Real Madrid', 2.06, 3, 2.12, -0.06, 0.954, 'Felipe Reyes — 27.0 yrs, Center, Real Madrid'), ('Carlos Jiménez', '2.05', 'Forward', 31.0, 'Unicaja Málaga', 2.05, 4, 2.04, 0.01, 0.949, 'Carlos Jiménez — 31.0 yrs, Forward, Unicaja Málaga'), ('Àlex Mumbrú', '2.02', 'Forward', 28.0, 'Real Madrid', 2.02, 5, 2.04, -0.02, 0.935, 'Àlex Mumbrú — 28.0 yrs, Forward, Real Madrid'), ('Berni Rodríguez', '1.97', 'Guard', 27.0, 'Unicaja Málaga', 1.97, 6, 1.92, 0.05, 0.912, 'Berni Rodríguez — 27.0 yrs, Guard, Unicaja Málaga'), ('Rudy Fernández', '1.96', 'Guard', 22.0, 'DKV Joventut', 1.96, 7, 1.92, 0.04, 0.907, 'Rudy Fernández — 22.0 yrs, Guard, DKV Joventut'), ('Juan Carlos Navarro', '1.92', 'Guard', 27.0, 'Memphis Grizzlies', 1.92, 8, 1.92, -0.0, 0.889, 'Juan Carlos Navarro — 27.0 yrs, Guard, Memphis Grizzlies'), ('José Calderón', '1.91', 'Guard', 26.0, 'Toronto Raptors', 1.91, 9, 1.92, -0.01, 0.884, 'José Calderón — 26.0 yrs, Guard, Toronto Raptors'), ('Sergio Rodríguez', '1.91', 'Guard', 21.0, 'Portland Trail Blazers', 1.91, 9, 1.92, -0.01, 0.884, 'Sergio Rodríguez — 21.0 yrs, Guard, Portland Trail Blazers'), ('Carlos Cabezas', '1.86', 'Guard', 27.0, 'Unicaja Málaga', 1.86, 11, 1.92, -0.06, 0.861, 'Carlos Cabezas — 27.0 yrs, Guard, Unicaja Málaga')]",m_1764880058408_5f07f70b_12962773-5,"As a totem designer I need each figure's relative scale and exact stacking order to size each level correctly, and I'll ask for ratios and ranks rather than SQL terms. The query computes each player's rank by height (1 = tallest) and a ratio of their height to the tallest player's height, plus basic ID fields and age. The schema fields used are Player, Height, Position, Year born and Current Club. Give me each player's name, height, position, age in 2007, club, their stack rank (1 = tallest) and their scale as a decimal of the tallest player so I can size each sculpture layer?",persona,"A museum exhibit sculptor designing a vertical totem sculpture of the 2007 Spanish national basketball team who needs exact heights, positions and contextual info to scale figures and write display plaques. Goals: Determine accurate physical proportions to scale each player for a stacked sculpture (tallest at the base, shortest at the top). Group and compare average body proportions by position (Center/Forward/Guard) to decide limb and torso adjustments for sculpting conventions. Create concise plaque text for each figure that includes the player's age in 2007, position and club for museum visitors. Example Queries: SELECT ""Player"", ""Height"", ""Position"", (2007 - ""Year born"") AS age_2007, ""Current Club""
FROM table_1_12962773_5
ORDER BY CAST(""Height"" AS REAL) DESC; SELECT ""Position"", ROUND(AVG(CAST(""Height"" AS REAL)), 2) AS avg_height_m
FROM table_1_12962773_5
GROUP BY ""Position""
ORDER BY avg_height_m DESC; SELECT ""Player"", (2007 - ""Year born"") AS age_2007, ""Position"", ""Current Club"",
       ""Height"",
       (""Player"" || ' — ' || (2007 - ""Year born"") || ' yrs, ' || ""Position"" || ', ' || ""Current Club"") AS plaque_text
FROM table_1_12962773_5
WHERE CAST(""Height"" AS REAL) >= 2.05
ORDER BY CAST(""Height"" AS REAL) DESC;",N/A,remove_column,
"Using a LEFT JOIN of the table to itself with ON t.Series number = t2.Series number AND t.Episode number = t2.Episode number + 1 and filtering rows by Episode number >= 0 OR Total viewers > 0, for each Series number (grouped by Series number) what is the Series number, the COUNT(*) of rows, the SUM of (Total viewers < Series average) and the SUM of (Total viewers > Series average), but only return series where SUM(Total viewers < Series average) > 0 and limit the output to 10 series?","
SELECT t.`Series number`, COUNT(*), SUM(t.`Total viewers` < t.`Series average`), SUM(t.`Total viewers` > t.`Series average`)
FROM `table_m_1764880079563_edd99b0d_12995531_3` t
LEFT JOIN `table_m_1764880079563_edd99b0d_12995531_3` t2 ON t.`Series number` = t2.`Series number` AND t.`Episode number` = t2.`Episode number` + 1
WHERE t.`Episode number` >= 0 OR t.`Total viewers` > 0
GROUP BY t.`Series number`
HAVING SUM(t.`Total viewers` < t.`Series average`) > 0
LIMIT 10;
","
SELECT t.col0, COUNT(*), SUM(t.col2 < t.col3), SUM(t.col2 > t.col3)
FROM `table_m_1764880079563_edd99b0d_12995531_3` t
LEFT JOIN `table_m_1764880079563_edd99b0d_12995531_3` t2 ON t.col0 = t2.col0 AND t.col1 = t2.col1 + 1
WHERE t.col1 >= 0 OR t.col2 > 0
GROUP BY t.col0
HAVING SUM(t.col2 < t.col3) > 0
LIMIT 10;
","[('Series 1', 8, 6, 2), ('Series 2', 8, 5, 3), ('Series 3', 8, 4, 4), ('Series 4', 7, 3, 4)]",m_1764880079563_edd99b0d_12995531-3,"Parse: group by Series number and return for each group the count of rows and sums of boolean comparisons (Total viewers < Series average and Total viewers > Series average), with a LEFT JOIN to itself matching the next episode, a WHERE filter Episode number >= 0 OR Total viewers > 0, a HAVING condition requiring SUM(Total viewers < Series average) > 0, and LIMIT 10. Map: ensure Series number, Episode number, Total viewers and Series average are referenced. Draft: ask for those aggregated values per series including the JOIN ON, WHERE, GROUP BY, HAVING and LIMIT clauses. Validate: confirm inclusion of COUNT(*), both SUM conditions, the ON clause and the WHERE/HAVING/LIMIT constraints.",reserved,12,N/A,split_column,
"Which Delaware entries are also listed in Maryland, New Jersey, and New York more than once?",unanswerable,unanswerable,,m_1764880088605_8cc9f65e_13012165-1,"STEP 1: Parse the SQL intent — The query finds each distinct value from the Delaware column (for rows with Year>0) and counts how many rows in the table have that Delaware value equal to the Maryland OR New Jersey OR New York column; it returns those Delaware values with count>1 ordered by count desc. STEP 2: Determine a fitting ambiguity — Attachment ambiguity fits well: the phrase ""in Maryland, New Jersey, and New York"" can attach either to the predicate as a conjunction (in all three states) or as a disjunction (in any of those states). The SQL uses OR (disjunction). STEP 3: Draft the question — produce a natural-language sentence that matches the SQL but is ambiguous about whether ""in Maryland, New Jersey, and New York"" means ""in any of those states"" or ""in each of those states."" STEP 4: Explain the ambiguity — In the original SQL the condition is any-match (OR across the three state columns), but a reader could instead interpret the NL as requiring matches in all three columns (AND) or as referring to different granularities (teams vs towns).",reserved,15,N/A,remove_column,"type: Attachment ambiguity | explanation: The SQL treats ""in Maryland, New Jersey, and New York"" as a disjunction (matches any of those columns), but the question can be read as requiring a Delaware entry to appear in all three states (conjunction) or to appear in any one of them; both readings are plausible from the wording."
"Show for every Club the Club name, Australian Marquee, International Marquee, Junior Marquee player, Captain and Vice-Captain, plus the Marquee Captain Overlap defined as (Australian Marquee = Captain) + (International Marquee = Captain) + (Junior Marquee player = Captain), the Marquee Vice-Captain Overlap defined as (Australian Marquee = Vice-Captain) + (International Marquee = Vice-Captain) + (Junior Marquee player = Vice-Captain), the Total Marquee Leadership Overlap defined as the sum of those six equality checks ((Australian Marquee = Captain) + (International Marquee = Captain) + (Junior Marquee player = Captain) + (Australian Marquee = Vice-Captain) + (International Marquee = Vice-Captain) + (Junior Marquee player = Vice-Captain)), and the Has Any Marquee value computed as 1 - ((Australian Marquee = International Marquee) AND (Australian Marquee = Junior Marquee player))?","
SELECT `Club`, `Captain`, `Vice-Captain`, (`Marquee Players` = `Captain`) + (`Marquee Players` = `Captain`) + (`Marquee Players` = `Captain`) `Marquee Captain Overlap`, (`Marquee Players` = `Vice-Captain`) + (`Marquee Players` = `Vice-Captain`) + (`Marquee Players` = `Vice-Captain`) `Marquee Vice-Captain Overlap`, ((`Marquee Players` = `Captain`) + (`Marquee Players` = `Captain`) + (`Marquee Players` = `Captain`) + (`Marquee Players` = `Vice-Captain`) + (`Marquee Players` = `Vice-Captain`) + (`Marquee Players` = `Vice-Captain`)) `Total Marquee Leadership Overlap`, (1 - ((`Marquee Players` = `Marquee Players`) AND (`Marquee Players` = `Marquee Players`))) `Has Any Marquee`, `Marquee Players` FROM `table_m_1764880098125_77295ce2_1301373_7`
WHERE 1;
","
SELECT col0, col1, col2, (col3 = col1) + (col3 = col1) + (col3 = col1) `Marquee Captain Overlap`, (col3 = col2) + (col3 = col2) + (col3 = col2) `Marquee Vice-Captain Overlap`, ((col3 = col1) + (col3 = col1) + (col3 = col1) + (col3 = col2) + (col3 = col2) + (col3 = col2)) `Total Marquee Leadership Overlap`, (1 - ((col3 = col3) AND (col3 = col3))) `Has Any Marquee`, col3 FROM `table_m_1764880098125_77295ce2_1301373_7`
WHERE 1;
","[('Adelaide United', 'Eugene Galeković', 'Cássio', 0, 0, 0, 0, 'None, None, None'), ('Brisbane Roar', 'Matt Smith', 'Shane Stefanutto', 0, 0, 0, 0, 'Matt McKay, Thomas Broich, None'), ('Central Coast Mariners', 'John Hutchinson', 'Michael McGlinchey', 0, 0, 0, 0, 'None, None, None'), ('Melbourne Heart', 'Harry Kewell', 'TBA', 0, 0, 0, 0, 'None, Orlando Engelaar, None'), ('Melbourne Victory', 'Mark Milligan', 'Leigh Broxham', 0, 0, 0, 0, 'Archie Thompson, Pablo Contreras, None'), ('Newcastle Jets', 'Ruben Zadkovich', 'TBA', 0, 0, 0, 0, 'None, Emile Heskey, None'), ('Perth Glory', 'Jacob Burns', 'Travis Dodd', 0, 0, 0, 0, 'None, William Gallas, None'), ('Sydney FC', 'Alessandro Del Piero', 'Brett Emerton', 0, 0, 0, 0, 'Brett Emerton, Alessandro Del Piero, None'), ('Wellington Phoenix', 'Andrew Durante', 'Ben Sigmund', 0, 0, 0, 0, 'None, None, None')]",m_1764880098125_77295ce2_1301373-7,"1) The SQL intent is to output all clubs with marquee and leadership columns plus counts of overlaps between marquees and Captain/Vice-Captain and a flag computed as 1 minus the conjunction of two equality checks among marquee columns. 2) Use table fields: Club, Australian Marquee, International Marquee, Junior Marquee player, Captain, Vice-Captain. 3) Formulate a question asking for those fields and each calculated metric with the explicit formulas. 4) Ensure the question matches each calculation exactly and requests results for every row.",reserved,4,N/A,merge_column,
"Which three clubs have the highest PD, where PD = Pts For - Pts Agst, showing Club and PD and PPG (PPG = Points * 1.0 / Played), among clubs that satisfy (Pts For > Pts Agst AND Points < 40) OR Position = 4, grouped by Club and with PPG > 2, ordered by PD descending?",unanswerable,unanswerable,,m_1764880111347_c673ffbd_13018091-1,"1) The SQL selects Club, calculates PD as Pts For - Pts Agst and PPG as (Points*1.0)/Played, filters rows by (Pts For > Pts Agst AND Points < 40) OR Position = 4, groups by Club, keeps groups with PPG > 2, orders by PD descending and limits to 3. 2) Map columns: Club, Pts For, Pts Agst, Points, Played, Position. 3) Draft a question requesting the top three clubs by PD showing Club, PD and PPG with the same filters, grouping and ordering. 4) Validate that the question mentions Club, PD calculation, PPG calculation, the WHERE logic, GROUP BY Club, HAVING PPG > 2, ORDER BY PD DESC and LIMIT 3.",reserved,12,N/A,merge_column,
"Which decades earned more than $100,000?",unanswerable,unanswerable,,m_1764880126380_3df533ba_13026799-3,"STEP 1: Parse the SQL intent: group rows for 1962–2005 into three labels (1960s, 1970s, 1980s+), compute counts, SUM(Starts), SUM(Wins), SUM(Earnings), AVG(Scoring), keep groups whose SUM(Earnings) > 100000, then UNION an Overall aggregate row and return top 5 by total earnings. STEP 2: Determine ambiguity type: scope ambiguity fits best — the query tests SUM(Earnings) per grouped label, but a natural question could instead mean per-year, per-decade average, or other scopes. STEP 3: Draft the question: ""Which decades earned more than $100,000?"" STEP 4: Explain the ambiguity: in the SQL this reads as which grouped labels have total earnings (sum across all years in the label) > $100,000 (and also an Overall row is added), whereas a reader might instead ask which decades had any single year > $100,000, or which decades had an average yearly earning > $100,000, or expect separate decades beyond the 1980s+ grouping.",reserved,34,N/A,merge_column,"type: Scope ambiguity | explanation: The SQL interprets this as decade-level total earnings (SUM across years in each grouped label) > $100,000 and also includes an Overall aggregate via UNION; alternatively the question could mean any single year within a decade exceeded $100,000, the decade's average yearly earnings exceeded $100,000, or that decades should be split differently (e.g., 1980s, 1990s, etc.)."
"Show Year, Points and the number obtained by extracting the substring between '(' and ')' from Points and converting it to a number (labeled 'Shabazz Muhammad (35)'), Rebounds and the number obtained by extracting the substring between '(' and ')' from Rebounds and converting it to a number (labeled 'Albert White (13)'), and Assists and the number obtained by extracting the substring between '(' and ')' from Assists and converting it to a number (labeled 'Jermaine O'Neal (21)') only for rows where the extracted Points number is at least 30, sorted by that extracted Points number in descending order, returning the top 5 rows?","
SELECT ALL `Year`, `Points`, (substr(`Points`, instr(`Points`, '(')+1, instr(`Points`, ')')-instr(`Points`, '(')-1)*1) AS `Shabazz Muhammad (35)`, `Rebounds`, (substr(`Rebounds`, instr(`Rebounds`, '(')+1, instr(`Rebounds`, ')')-instr(`Rebounds`, '(')-1)*1) `Albert White (13)`, `Assists`, (substr(`Assists`, instr(`Assists`, '(')+1, instr(`Assists`, ')')-instr(`Assists`, '(')-1)*1) `Jermaine O'Neal (21)` FROM `table_m_1764880135175_6799779e_13050003_2` WHERE (substr(`Points`, instr(`Points`, '(')+1, instr(`Points`, ')')-instr(`Points`, '(')-1)*1) >= 30 ORDER BY -`Shabazz Muhammad (35)` LIMIT 5;
","
SELECT ALL col0, col1, (substr(col1, instr(col1, '(')+1, instr(col1, ')')-instr(col1, '(')-1)*1) AS `Shabazz Muhammad (35)`, col2, (substr(col2, instr(col2, '(')+1, instr(col2, ')')-instr(col2, '(')-1)*1) `Albert White (13)`, col3, (substr(col3, instr(col3, '(')+1, instr(col3, ')')-instr(col3, '(')-1)*1) `Jermaine O'Neal (21)` FROM `table_m_1764880135175_6799779e_13050003_2` WHERE (substr(col1, instr(col1, '(')+1, instr(col1, ')')-instr(col1, '(')-1)*1) >= 30 ORDER BY -`Shabazz Muhammad (35)` LIMIT 5;
","[(2012.0, 'Shabazz Muhammad (35)', 35, 'Kyle Anderson (10)', 10, 'Kyle Anderson (4)', 4), (1999.0, 'Casey Jacobsen (31)', 31, 'Travis Watson (9)', 9, 'Jay Williams (7)', 7), (2005.0, 'Tyler Hansbrough (31)', 31, 'Tyler Hansbrough (10)', 10, 'Greg Paulus (10)', 10), (2006.0, 'Wayne Ellington (31)', 31, '2 tied (7)', 7, '2 tied (6)', 6)]",m_1764880135175_6799779e_13050003-2,"1) Parse SQL intent: return the same set of columns and computed numeric values, filter Points numeric >=30, sort by that numeric descending, limit 5. 2) Map schema semantics: Points/Rebounds/Assists contain parenthesized numbers that must be substring-extracted and cast to numeric; SQL aliases correspond to those extracted numeric columns. 3) Draft the question: request Year, original Points text and its extracted numeric (alias 'Shabazz Muhammad (35)'), original Rebounds text and its extracted numeric (alias 'Albert White (13)'), original Assists text and its extracted numeric (alias 'Jermaine O'Neal (21)'), with the filter, sort and limit. 4) Validate: ensures inclusion of all columns, extraction calculations, alias names, filter condition (>=30), ordering and LIMIT 5.",reserved,8,N/A,remove_column,
"For each Champion, return the Champion, the number of Titles as COUNT(Season) for seasons >= 2000, MVP_when_champion as the SUM of cases where the Season MVP matches the Champion after removing ' (2)' and ' (3)' via REPLACE and checking instr(...)>0, and AvgTeamsDuringTitles as AVG(Teams) across those seasons, only including champions with COUNT(Season)>0 and ordering the results by Titles?","
SELECT t1.`Champion` `Champion`, COUNT(t1.`Season`) `Titles`, SUM((instr(REPLACE(REPLACE(t1.`Champion`,' (2)',''),' (3)',''), REPLACE(REPLACE(t1.`Season MVP`,' (2)',''),' (3)',''))>0)) `MVP_when_champion`, AVG(t2.`Teams`) `AvgTeamsDuringTitles`
FROM `table_m_1764880163216_3a8e38f6_13082900_1` `t1` JOIN `table_m_1764880163216_3a8e38f6_13082900_1` `t2` ON t1.`Season` = t2.`Season`
WHERE t2.`Season`>=2000
GROUP BY t1.`Champion`
HAVING COUNT(t1.`Season`)>0
ORDER BY `Titles`;
","
SELECT t1.col2 col2, COUNT(t1.col0) `Titles`, SUM((instr(REPLACE(REPLACE(t1.col2,' (2)',''),' (3)',''), REPLACE(REPLACE(t1.col3,' (2)',''),' (3)',''))>0)) `MVP_when_champion`, AVG(t2.col1) `AvgTeamsDuringTitles`
FROM `table_m_1764880163216_3a8e38f6_13082900_1` `t1` JOIN `table_m_1764880163216_3a8e38f6_13082900_1` `t2` ON t1.col0 = t2.col0
WHERE t2.col0>=2000
GROUP BY t1.col2
HAVING COUNT(t1.col0)>0
ORDER BY `Titles`;
","[('Detroit Shock', 1, 0, 14.0), ('Detroit Shock (2)', 1, 0, 14.0), ('Detroit Shock (3)', 1, 0, 14.0), ('Houston Comets (4)', 1, 0, 16.0), ('Indiana Fever', 1, 0, 12.0), ('Los Angeles Sparks', 1, 0, 16.0), ('Los Angeles Sparks (2)', 1, 0, 16.0), ('Minnesota Lynx', 1, 0, 12.0), ('Phoenix Mercury', 1, 0, 13.0), ('Phoenix Mercury (2)', 1, 0, 13.0), ('Sacramento Monarchs', 1, 0, 13.0), ('Seattle Storm', 1, 0, 13.0), ('Seattle Storm (2)', 1, 0, 12.0)]",m_1764880163216_3a8e38f6_13082900-1,"1) Parse the SQL intent: produce per-Champion aggregates for seasons from 2000: total Titles, number of those Titles where the Season MVP string appears in the Champion string after removing ' (2)' and ' (3)', and the average Teams during those title seasons; then group and order by Titles. 2) Map schema semantics: mapping COUNT(Season) to Titles, the REPLACE/INSTR expression to MVP_when_champion, and AVG(Teams) to AvgTeamsDuringTitles, all using columns Champion, Season, Season MVP, Teams. 3) Draft the question: clearly request Champion, Titles, MVP_when_champion (with the replacement and substring check described), and AvgTeamsDuringTitles for seasons >=2000, with groups having COUNT>0 and ordered by Titles. 4) Validate: confirm inclusion of all columns, calculations, the ' (2)'/' (3)' replacements, the season >=2000 filter, grouping, having, and ordering.",reserved,9,N/A,add_column,
"For each Champion with a Purse ( $ ) of at least 1800000 and a Score less than or equal to 204, what is the Champion name, the count of records, the average Score rounded to 2 decimal places, the minimum Score, and the Years they won as a comma-separated list, showing up to 10 Champions?","
SELECT `Champion`, COUNT(*), ROUND(AVG(`Score`),2) AS `Average Score`, MIN(`Score`), GROUP_CONCAT(`Year`, ', ')
FROM `table_m_1764880175255_685c3f6b_13169136_1`
WHERE `Purse ( $ )` >= 1800000 AND `Score` <= 204
GROUP BY `Champion`
LIMIT 10;
","
SELECT col2, COUNT(*), ROUND(AVG(col3),2) AS `Average Score`, MIN(col3), GROUP_CONCAT(col0, ', ')
FROM `table_m_1764880175255_685c3f6b_13169136_1`
WHERE col6 >= 1800000 AND col3 <= 204
GROUP BY col2
LIMIT 10;
","[('Ai Miyazato', 1, 201.0, 201.0, '2012.0'), ('Inbee Park', 1, 201.0, 201.0, '2013.0'), ('Jiyai Shin', 1, 204.0, 204.0, '2009.0'), ('Yani Tseng', 2, 200.5, 200.0, '2011.0, 2010.0')]",m_1764880175255_685c3f6b_13169136-1,"1) Parse intent: aggregate tournament rows by Champion, filtering Purse ( $ ) >= 1800000 and Score <= 204, compute count, average Score rounded to 2 decimals, minimum Score, and concatenate Years, limit 10. 2) Map schema: use Champion, Score, Year, Purse ( $ ). 3) Draft: ask for those aggregated fields per Champion with the given filters and limit. 4) Validate: ensures all selected columns, calculations, filters, grouping and limit are represented.",reserved,8,N/A,add_column,
"Which writer‑director pairings have repeatedly successful episodes and could form a signature house scent, and for each pairing give episode count, average and max viewers, the flagship episode title, a list of titles with production codes and original air dates, how many of their episodes are in the season's top three, and the diversity index?","
WITH `top3` AS (
  SELECT `season_sequence_number`
  FROM `table_m_1764880222525_07b4f325_13301516_1`
  ORDER BY CAST(`U.S. viewers (millions)` AS REAL) DESC
  LIMIT 3
)
SELECT
  t1.`Directed by` AS `Directed by`,
  t1.`Written by` AS `Written by`,
  COUNT(*) AS `episode_count`,
  ROUND(AVG(CAST(t1.`U.S. viewers (millions)` AS REAL)),2) AS `avg_viewers`,
  ROUND(MAX(CAST(t1.`U.S. viewers (millions)` AS REAL)),2) AS `max_viewers`,
  (SELECT t2.`Title` 
   FROM `table_m_1764880222525_07b4f325_13301516_1` t2 
   WHERE t2.`Directed by` = t1.`Directed by` AND t2.`Written by` = t1.`Written by`
   ORDER BY CAST(t2.`U.S. viewers (millions)` AS REAL) DESC
   LIMIT 1) AS `flagship_episode`,
  GROUP_CONCAT('`' || t1.`Title` || '`' || ' | ' || '`' || t1.`production_identifier` || '`' || ' | ' || '`' || t1.`Original air date` || '`', '; ') AS `episodes_detail`,
  MIN(t1.`episode_sequence_number`) AS `min_No. in season`,
  MAX(t1.`episode_sequence_number`) AS `max_No. in season`,
  COUNT(DISTINCT t1.`production_identifier`) AS `distinct_production_codes`,
  COUNT(DISTINCT t1.`Original air date`) AS `distinct_air_dates`,
  COUNT(CASE WHEN t1.`season_sequence_number` IN (SELECT `season_sequence_number` FROM `top3`) THEN 1 END) AS `top3_hits`,
  (COUNT(DISTINCT t1.`production_identifier`) + (MAX(t1.`episode_sequence_number`) - MIN(t1.`episode_sequence_number`))) AS `diversity_index`
FROM `table_m_1764880222525_07b4f325_13301516_1` t1
GROUP BY t1.`Directed by`, t1.`Written by`
HAVING COUNT(*) >= 1
ORDER BY `top3_hits` DESC, `avg_viewers` DESC, `episode_count` DESC;
","
WITH `top3` AS (
  SELECT col0
  FROM `table_m_1764880222525_07b4f325_13301516_1`
  ORDER BY CAST(col7 AS REAL) DESC
  LIMIT 3
)
SELECT
  t1.col3 AS col3,
  t1.col4 AS col4,
  COUNT(*) AS `episode_count`,
  ROUND(AVG(CAST(t1.col7 AS REAL)),2) AS `avg_viewers`,
  ROUND(MAX(CAST(t1.col7 AS REAL)),2) AS `max_viewers`,
  (SELECT t2.col2 
   FROM `table_m_1764880222525_07b4f325_13301516_1` t2 
   WHERE t2.col3 = t1.col3 AND t2.col4 = t1.col4
   ORDER BY CAST(t2.col7 AS REAL) DESC
   LIMIT 1) AS `flagship_episode`,
  GROUP_CONCAT('`' || t1.col2 || '`' || ' | ' || '`' || t1.col6 || '`' || ' | ' || '`' || t1.col5 || '`', '; ') AS `episodes_detail`,
  MIN(t1.col1) AS `min_No. in season`,
  MAX(t1.col1) AS `max_No. in season`,
  COUNT(DISTINCT t1.col6) AS `distinct_production_codes`,
  COUNT(DISTINCT t1.col5) AS `distinct_air_dates`,
  COUNT(CASE WHEN t1.col0 IN (SELECT col0 FROM `top3`) THEN 1 END) AS `top3_hits`,
  (COUNT(DISTINCT t1.col6) + (MAX(t1.col1) - MIN(t1.col1))) AS `diversity_index`
FROM `table_m_1764880222525_07b4f325_13301516_1` t1
GROUP BY t1.col3, t1.col4
HAVING COUNT(*) >= 1
ORDER BY `top3_hits` DESC, `avg_viewers` DESC, `episode_count` DESC;
","[('Arthur W. Forney', 'Judith McCreary', 1, 15.17, 15.17, '""Signature""', '`""Signature""` | `9012.0` | `January 8, 2008`', 12.0, 12.0, 1, 1, 1, 1.0), ('David Platt', 'Mark Goffman', 1, 13.27, 13.27, '""Undercover""', '`""Undercover""` | `9015.0` | `April 15, 2008`', 15.0, 15.0, 1, 1, 1, 1.0), ('Chris Zalla', 'Dawn DeNoon', 1, 12.97, 12.97, '""Inconceivable""', '`""Inconceivable""` | `9014.0` | `January 22, 2008`', 14.0, 14.0, 1, 1, 1, 1.0), ('Kate Woods', 'Judith McCreary', 1, 12.54, 12.54, '""Savant""', '`""Savant""` | `9005.0` | `October 16, 2007`', 4.0, 4.0, 1, 1, 0, 1.0), ('Helen Shaver', 'Paul Grellong', 1, 12.35, 12.35, '""Streetwise""', '`""Streetwise""` | `9011.0` | `January 1, 2008`', 11.0, 11.0, 1, 1, 0, 1.0), ('David Platt', 'Jonathan Greene', 2, 12.34, 12.49, '""Blinded""', '`""Impulsive""` | `9001.0` | `October 9, 2007`; `""Blinded""` | `9009.0` | `November 13, 2007`', 3.0, 7.0, 2, 2, 0, 6.0), ('Kate Woods', 'Amanda Green', 1, 12.29, 12.29, '""Paternity""', '`""Paternity""` | `9010.0` | `November 27, 2007`', 9.0, 9.0, 1, 1, 0, 1.0), ('Peter Leto', 'Josh Singer', 1, 12.17, 12.17, '""Harm""', '`""Harm""` | `9002.0` | `October 23, 2007`', 5.0, 5.0, 1, 1, 0, 1.0), ('David Platt', 'Josh Singer', 1, 12.14, 12.14, '""Unorthodox""', '`""Unorthodox""` | `9013.0` | `January 15, 2008`', 13.0, 13.0, 1, 1, 0, 1.0), ('David Platt', 'Neal Baer & Dawn DeNoon', 1, 12.1, 12.1, '""Alternate""', '`""Alternate""` | `9003.0` | `September 25, 2007`', 1.0, 1.0, 1, 1, 0, 1.0), ('David Platt', 'Neal Baer & Amanda Green', 1, 12.06, 12.06, '""Authority""', '`""Authority""` | `9017.0` | `April 29, 2008`', 17.0, 17.0, 1, 1, 0, 1.0), ('David Platt', 'Kam Miller', 1, 11.75, 11.75, '""Svengali""', '`""Svengali""` | `9006.0` | `November 6, 2007`', 6.0, 6.0, 1, 1, 0, 1.0), ('Jonathan Kaplan', 'Mark Goffman', 1, 11.72, 11.72, '""Snitch""', '`""Snitch""` | `9008.0` | `December 4, 2007`', 10.0, 10.0, 1, 1, 0, 1.0), ('Juan J. Campanella', 'Mick Betancourt', 1, 11.66, 11.66, '""Fight""', '`""Fight""` | `9007.0` | `November 20, 2007`', 8.0, 8.0, 1, 1, 0, 1.0), ('Peter Leto', 'Paul Grellong', 1, 11.66, 11.66, '""Avatar""', '`""Avatar""` | `9004.0` | `October 2, 2007`', 2.0, 2.0, 1, 1, 0, 1.0), ('Peter Leto', 'Ken Storer', 1, 11.5, 11.5, '""Closet""', '`""Closet""` | `9016.0` | `April 22, 2008`', 16.0, 16.0, 1, 1, 0, 1.0), ('Peter Leto', 'Jonathan Greene', 1, 10.44, 10.44, '""Trade""', '`""Trade""` | `9018.0` | `May 6, 2008`', 18.0, 18.0, 1, 1, 0, 1.0)]",m_1764880222525_07b4f325_13301516-1,"As a perfumer hunting for signature ""house"" teams, I'd casually ask for repeatedly successful director-writer pairings and their key episode metrics without using SQL terms. The query groups by director and writer and returns episode_count, avg and max viewers, a flagship episode, concatenated episode details (title | production code | air date), min/max No. in season, counts of distinct production codes and air dates, top-3 hits, and a diversity index, ordered by top3 hits then avg viewers then episode_count. These items correspond to the table's Directed by, Written by, Title, Production code, Original air date, No. in season, No. in series, and U.S. viewers (millions). Which writer-director pairings have repeated successes and should form a house scent — list for each pairing their episode count, average and max viewers, flagship episode title, the list of episodes with production codes and air dates, how many of their episodes are in the season top three, and the diversity index? This stays strictly within the fields and aggregates computed by the query.",persona,"An olfactory artist/perfumer who designs limited-edition scents that capture the visual and narrative 'smell' of individual TV episodes, using credits and audience data to choose which episodes to interpret. Goals: Identify the most-watched episodes to create flagship, broadly appealing scents. Find episodes by specific directors (visual style) or writers (narrative tone) so the scent matches a consistent creative voice. Ensure a diverse selection across the season (different air dates and production codes) to assemble a balanced fragrance collection. Spot writer-director pairings and repeatedly successful collaborators to create a signature 'house' scent inspired by consistent teams. Example Queries: SELECT ""No. in series"", ""No. in season"", ""Title"", ""Directed by"", ""Written by"", ""Original air date"", ""Production code"", ""U.S. viewers (millions)"" FROM table_1_13301516_1 ORDER BY CAST(""U.S. viewers (millions)"" AS REAL) DESC LIMIT 3; SELECT * FROM table_1_13301516_1 WHERE ""Directed by"" = 'David Platt' ORDER BY CAST(""U.S. viewers (millions)"" AS REAL) DESC; SELECT ""Directed by"", ""Written by"", COUNT(*) AS episode_count, AVG(CAST(""U.S. viewers (millions)"" AS REAL)) AS avg_viewers FROM table_1_13301516_1 GROUP BY ""Directed by"", ""Written by"" HAVING COUNT(*) >= 1 ORDER BY avg_viewers DESC;",N/A,rename_column,
Which directors had at least 0.7 million U.S. viewers?,"
SELECT `Directed by`, COUNT(*), AVG(`U.S. viewers (million)`+0), MIN(`U.S. viewers (million)`+0), MAX(`U.S. viewers (million)`+0), GROUP_CONCAT(`Title`, '; ')
FROM `table_m_1764880272715_522c0664_13336122_6`
WHERE `U.S. viewers (million)` != ''
GROUP BY `Directed by`
HAVING AVG(`U.S. viewers (million)`+0) >= 0.7
ORDER BY AVG(`U.S. viewers (million)`+0);
","
SELECT col1, COUNT(*), AVG(col4+0), MIN(col4+0), MAX(col4+0), GROUP_CONCAT(col0, '; ')
FROM `table_m_1764880272715_522c0664_13336122_6`
WHERE col4 != ''
GROUP BY col1
HAVING AVG(col4+0) >= 0.7
ORDER BY AVG(col4+0);
","[('Michael Weaver', 1, 0.71, 0.71, 0.71, '""Here I Go Again""'), ('Michael Lehmann', 1, 0.73, 0.73, 0.73, '""The Party""'), ('Millicent Shelton', 1, 0.74, 0.74, 0.74, '""The Ride-Along""'), ('David Duchovny', 1, 0.75, 0.75, 0.75, '""The Way of the Fist""'), ('John Dahl', 1, 0.76, 0.76, 0.76, '""JFK to LAX""'), ('Eric Stoltz', 1, 0.83, 0.83, 0.83, '""Love Song""')]",m_1764880272715_522c0664_13336122-6,"STEP 1: Parse the SQL intent: group rows by `Directed by`, count episodes, compute average/min/max of `U.S. viewers (million)` (excluding blanks), concatenate titles, keep only directors whose average U.S. viewers >= 0.7, order by average. STEP 2: Choose ambiguity type: scope ambiguity — the phrase ""had at least 0.7 million viewers"" can refer to an average across a director's episodes (the SQL's meaning) or to individual episodes reaching that threshold. This fits because the query uses AVG but a natural question can be read both ways. STEP 3: Draft the question: ""Which directors had at least 0.7 million U.S. viewers?"" STEP 4: Explain the ambiguity: in the original query this means directors whose average U.S. viewers across their episodes is >= 0.7; alternatively it could mean directors who had at least one episode with >= 0.7 viewers (or every episode >= 0.7), which would require MAX or MIN conditions instead of AVG.",reserved,7,N/A,merge_column,"type: Scope ambiguity | explanation: The SQL interprets this as directors whose average U.S. viewers across their episodes is >= 0.7; alternatively the question could mean directors who had any single episode reach >= 0.7 (or conversely every episode >= 0.7), which would change the aggregation (MAX or MIN) or the intended grouping/filtering."
"After joining the table to itself on t.Rank = u.Rank AND t.Building = u.Building and filtering to rows with t.Storeys > 0 OR t.Completed IN (1932,1964,1966,1968,1970,1972,1978,1979,1980,1983,1984), for each decade computed as ((Completed/10)*10) what are the Decade value, the Total count of rows, ROUND(AVG(Storeys),2) as AvgStoreys, SUM(CASE WHEN Storeys >= 20 THEN 1 ELSE 0 END) as TallCount, and the value of (t.Storeys IS u.Storeys) as SameStoreys, ordering decades by AvgStoreys descending and returning only the top 3?","SELECT ((t.`Completed`/10)*10) AS `Decade`, COUNT(*) `Total`, ROUND(AVG(t.`Storeys`),2) `AvgStoreys`, SUM(CASE WHEN t.`Storeys` >= 20 THEN 1 ELSE 0 END) `TallCount`, (t.`Storeys` IS u.`Storeys`) `SameStoreys` FROM `table_m_1764880294391_95393639_13397394_1` t JOIN `table_m_1764880294391_95393639_13397394_1` u ON t.`Building` = u.`Building` WHERE t.`Storeys` > 0 OR t.`Completed` IN (1932,1964,1966,1968,1970,1972,1978,1979,1980,1983,1984) GROUP BY ((t.`Completed`/10)*10) ORDER BY `AvgStoreys` DESC LIMIT 3;","SELECT ((t.col4/10)*10) AS `Decade`, COUNT(*) `Total`, ROUND(AVG(t.col3),2) `AvgStoreys`, SUM(CASE WHEN t.col3 >= 20 THEN 1 ELSE 0 END) `TallCount`, (t.col3 IS u.col3) `SameStoreys` FROM `table_m_1764880294391_95393639_13397394_1` t JOIN `table_m_1764880294391_95393639_13397394_1` u ON t.col0 = u.col0 WHERE t.col3 > 0 OR t.col4 IN (1932,1964,1966,1968,1970,1972,1978,1979,1980,1983,1984) GROUP BY ((t.col4/10)*10) ORDER BY `AvgStoreys` DESC LIMIT 3;","[(1984.0, 1, 27.0, 1, 1), (1983.0, 2, 22.0, 2, 1), (1980.0, 1, 22.0, 1, 1)]",m_1764880294391_95393639_13397394-1,"1) Parse SQL intent: produce top 3 decades by average Storeys with aggregates and a self-join, applying a WHERE filter that allows t.Storeys > 0 or specific Completed years. 2) Map schema semantics: Completed -> decade calculation, Storeys -> AVG and conditional SUM, Rank and Building -> join keys. 3) Draft the question: request Decade ((Completed/10)*10), COUNT(*) as Total, ROUND(AVG(Storeys),2) as AvgStoreys, SUM(CASE WHEN Storeys >=20 THEN 1 ELSE 0 END) as TallCount, and (t.Storeys IS u.Storeys) as SameStoreys, and specify grouping, ordering, and limit. 4) Validate: ensure the exact year list, join condition, GROUP BY, ORDER BY DESC, and LIMIT 3 are present.",reserved,21,N/A,remove_column,
"Give me all Illinois districts ordered by how razor-thin the race was (smallest margin first) and then by earliest first-elected, including district, incumbent, party, first elected, results, candidates, the two percentages, the margin, a long-tenured flag and whether the race was unopposed/retired/contested.","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Results`,
    `Candidates`,
    instr(`Candidates`, '%') AS p1,
    CASE
      WHEN instr(`Candidates`, '%') > 0
      THEN CAST(
        substr(
          `Candidates`,
          CASE WHEN instr(`Candidates`, '%') > 4 THEN instr(`Candidates`, '%') - 3 ELSE 1 END,
          3
        ) AS INTEGER
      )
      ELSE NULL
    END AS pct1,
    CASE
      WHEN instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0
      THEN instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') + instr(`Candidates`, '%')
      ELSE 0
    END AS p2,
    CASE
      WHEN instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0
      THEN CAST(
        substr(
          `Candidates`,
          CASE
            WHEN (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') + instr(`Candidates`, '%')) > 4
            THEN (instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') + instr(`Candidates`, '%')) - 3
            ELSE 1
          END,
          3
        ) AS INTEGER
      )
      ELSE NULL
    END AS pct2
  FROM `table_m_1764880301867_92176761_1341423_13`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Results`,
  `Candidates`,
  pct1,
  pct2,
  CASE WHEN pct1 IS NOT NULL AND pct2 IS NOT NULL THEN ABS(pct1 - pct2) ELSE NULL END AS `margin`,
  CASE WHEN `First elected` <= 1985 THEN 1 ELSE 0 END AS `long_tenured_flag`,
  CASE
    WHEN LOWER(`Results`) LIKE '%unopposed%' OR LOWER(`Candidates`) LIKE '%unopposed%' THEN 'unopposed'
    WHEN LOWER(`Results`) LIKE '%retired%' THEN 'retired'
    ELSE 'contested'
  END AS `race_type`
FROM parsed
ORDER BY
  CASE WHEN pct1 IS NOT NULL AND pct2 IS NOT NULL THEN ABS(pct1 - pct2) ELSE 999 END ASC,
  `First elected` ASC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    instr(col5, '%') AS p1,
    CASE
      WHEN instr(col5, '%') > 0
      THEN CAST(
        substr(
          col5,
          CASE WHEN instr(col5, '%') > 4 THEN instr(col5, '%') - 3 ELSE 1 END,
          3
        ) AS INTEGER
      )
      ELSE NULL
    END AS pct1,
    CASE
      WHEN instr(substr(col5, instr(col5, '%') + 1), '%') > 0
      THEN instr(substr(col5, instr(col5, '%') + 1), '%') + instr(col5, '%')
      ELSE 0
    END AS p2,
    CASE
      WHEN instr(substr(col5, instr(col5, '%') + 1), '%') > 0
      THEN CAST(
        substr(
          col5,
          CASE
            WHEN (instr(substr(col5, instr(col5, '%') + 1), '%') + instr(col5, '%')) > 4
            THEN (instr(substr(col5, instr(col5, '%') + 1), '%') + instr(col5, '%')) - 3
            ELSE 1
          END,
          3
        ) AS INTEGER
      )
      ELSE NULL
    END AS pct2
  FROM `table_m_1764880301867_92176761_1341423_13`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  pct1,
  pct2,
  CASE WHEN pct1 IS NOT NULL AND pct2 IS NOT NULL THEN ABS(pct1 - pct2) ELSE NULL END AS `margin`,
  CASE WHEN col3 <= 1985 THEN 1 ELSE 0 END AS `long_tenured_flag`,
  CASE
    WHEN LOWER(col4) LIKE '%unopposed%' OR LOWER(col5) LIKE '%unopposed%' THEN 'unopposed'
    WHEN LOWER(col4) LIKE '%retired%' THEN 'retired'
    ELSE 'contested'
  END AS `race_type`
FROM parsed
ORDER BY
  CASE WHEN pct1 IS NOT NULL AND pct2 IS NOT NULL THEN ABS(pct1 - pct2) ELSE 999 END ASC,
  col3 ASC;
","[('Illinois 10', 'John Porter', 'Republican', 1980.0, 'Retired Republican hold', 'Mark Kirk (R) 51% Lauren Beth Gash (D) 49%', 51, 49, 2, 1, 'retired'), ('Illinois 15', 'Thomas W. Ewing', 'Republican', 1998.0, 'Retired Republican hold', 'Timothy V. Johnson (R) 53% Mike Kelleher (D) 47%', 53, 47, 6, 0, 'retired'), ('Illinois 17', 'Lane Evans', 'Democratic', 1982.0, 'Re-elected', 'Lane Evans (D) 55% Mark Baker (R) 45%', 55, 45, 10, 1, 'contested'), ('Illinois 11', 'Jerry Weller', 'Republican', 1994.0, 'Re-elected', 'Jerry Weller (R) 56% James Stevenson (D) 44%', 56, 44, 12, 0, 'contested'), ('Illinois 6', 'Henry Hyde', 'Republican', 1974.0, 'Re-elected', 'Henry Hyde (R) 59% Brent Christensen (D) 41%', 59, 41, 18, 1, 'contested'), ('Illinois 8', 'Phil Crane', 'Republican', 1969.0, 'Re-elected', 'Phil Crane (R) 61% Lance Pressl (D) 39%', 61, 39, 22, 1, 'contested'), ('Illinois 19', 'David D. Phelps', 'Democratic', 1998.0, 'Re-elected', 'David D. Phelps (D) 65% Jim Eatherly (R) 35%', 65, 35, 30, 0, 'contested'), ('Illinois 13', 'Judy Biggert', 'Republican', 1998.0, 'Re-elected', 'Judy Biggert (R) 66% Thomas Mason (D) 34%', 66, 34, 32, 0, 'contested'), ('Illinois 18', 'Ray LaHood', 'Republican', 1994.0, 'Re-elected', 'Ray LaHood (R) 67% Joyce Harant (D) 33%', 67, 33, 34, 0, 'contested'), ('Illinois 14', 'Dennis Hastert', 'Republican', 1986.0, 'Re-elected', 'Dennis Hastert (R) 74% Vern DelJonson (D) 26%', 74, 26, 48, 0, 'contested'), ('Illinois 3', 'Bill Lipinski', 'Democratic', 1982.0, 'Re-elected', 'Bill Lipinski (D) 76% Karl Groth (R) 24%', 76, 24, 52, 1, 'contested'), ('Illinois 9', 'Jan Schakowsky', 'Democratic', 1998.0, 'Re-elected', 'Jan Schakowsky (D) 76% Dennis Driscoll (R) 24%', 76, 24, 52, 0, 'contested'), ('Illinois 7', 'Danny K. Davis', 'Democratic', 1996.0, 'Re-elected', 'Danny K. Davis (D) 86% Robert Dallas (R) 14%', 86, 14, 72, 0, 'contested'), ('Illinois 4', 'Luis Gutierrez', 'Democratic', 1992.0, 'Re-elected', 'Luis Gutierrez (D) 89% Stephanie Sailor (I) 11%', 89, 11, 78, 0, 'contested'), ('Illinois 2', 'Jesse L. Jackson Jr.', 'Democratic', 1995.0, 'Re-elected', 'Jesse L. Jackson Jr. (D) 90% Robert Gordon (R) 10%', 90, 10, 80, 0, 'contested'), ('Illinois 12', 'Jerry Costello', 'Democratic', 1988.0, 'Re-elected', 'Jerry Costello (D) unopposed', None, None, None, 0, 'unopposed'), ('Illinois 5', 'Rod Blagojevich', 'Democratic', 1996.0, 'Re-elected', 'Rod Blagojevich (D) 88%', 88, None, None, 0, 'contested')]",m_1764880301867_92176761_1341423-13,"As a curator planning routes I want a single ordered list prioritizing drama and then continuity, phrased less technically but aware of 'first elected'. The SQL returns all rows with parsed top-two percentages, a margin, a long-tenured flag, and a race type, ordered by smallest margin then by earliest first-elected. The schema maps those computed pct1, pct2, margin, long_tenured_flag and race_type alongside the base fields. Draft question: Give me all Illinois districts ordered by how razor-thin the race was (smallest margin first) and then by earliest first-elected, including district, incumbent, party, first elected, results, candidates, the two percentages, the margin, a long-tenured flag and whether the race was unopposed/retired/contested. Validation: This requests exactly the columns computed and the ordering used by the query.",persona,"A civic heritage tour curator who creates immersive, district-by-district theatrical walking tours of late-1990s Illinois congressional races, casting scenes around tight contests, long-serving incumbents and quirky uncontested elections. Goals: Identify the closest races (smallest vote-margin) to script high-drama reenactment stops where the outcome could have plausibly swung either way. Find long-tenured incumbents (early first-elected dates) to locate archival displays and interview subjects for historical context and continuity themes. Locate unopposed races and 'retired hold' outcomes to build one-person monologues and transitional scenes about political succession. Map party geography across districts to design route pacing (more contested/competitive neighborhoods vs. safely held districts) and tailor narrative tone. Example Queries: -- 1) Find districts where the top two vote shares differ by 5 percentage points or less (PostgreSQL-style regex extraction) WITH pcts AS (   SELECT ""District"", ""Incumbent"", ""Candidates"",     CAST(regexp_matches(""Candidates"", '(\\d+)%')[1] AS INTEGER) AS pct1,     CAST(regexp_matches(""Candidates"", '\\d+%.*?(\\d+)%')[1] AS INTEGER) AS pct2   FROM table_1_1341423_13 ) SELECT ""District"", ""Incumbent"", ""Candidates"", ABS(pct1 - pct2) AS margin FROM pcts WHERE ABS(pct1 - pct2) <= 5 ORDER BY margin ASC;  -- 2) List long-tenured incumbents (first elected in or before 1985) to identify archival stops SELECT ""District"", ""Incumbent"", ""Party"", ""First elected"" FROM table_1_1341423_13 WHERE ""First elected"" <= 1985 ORDER BY ""First elected"" ASC;  -- 3) Find districts with unopposed races or explicit 'retired' results to create single-actor scenes SELECT ""District"", ""Incumbent"", ""Results"", ""Candidates"" FROM table_1_1341423_13 WHERE LOWER(""Results"") LIKE '%unopposed%'    OR LOWER(""Candidates"") LIKE '%unopposed%'    OR LOWER(""Results"") LIKE '%retired%' ORDER BY ""District"";",N/A,add_column,
"Can you produce a table of all Virginia districts showing district, incumbent, party, first-elected year, results, candidates, an outcome flag (Retired/Gain/Hold/Re-elected/Other), whether the race was unopposed or contested, each incumbent's seniority rank, the total number of open (retired) seats, the total unopposed races, and the current seat count by party?",unanswerable,unanswerable,,m_1764880323603_8d83074e_1341423-46,"As a nonpartisan state political analyst I use clear terms like open seats, unopposed, and seniority rather than SQL jargon and I know the schema enough to ask for first-elected and incumbent names. The query annotates every district with an outcome flag (Retired/Gain/Hold/Re-elected/Other), contest status, computes a seniority rank, and also returns totals for retired (open) seats and unopposed races plus seat counts by party. The table columns map to District, Incumbent, Party, First elected, Results, and Candidates and the query derives Outcome_flag, Contest_status, Seniority_rank, Open_seats_total, Unopposed_total, and Party_seat_count. Draft question: Can you produce a table of all Virginia districts showing district, incumbent, party, first-elected year, results, candidates, an outcome flag (Retired/Gain/Hold/Re-elected/Other), whether the race was unopposed or contested, each incumbent's seniority rank, the total number of open (retired) seats, the total unopposed races, and the current seat count by party? Validation: This matches the query which returns every row with those derived flags, totals, and per-party counts.",persona,"State political data analyst at a nonpartisan election research institute who compiles and summarizes Virginia House election outcomes to inform media briefings and policy reports. They use this database to track incumbency, open seats, unopposed races, and party shifts across Virginia districts. Goals: Identify open/retiring seats to prioritize follow-up reporting and analysis. Measure incumbency strength by locating unopposed races and long-tenured incumbents. Detect party gains or losses and produce simple seat-count summaries by party for briefings. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Results FROM table_1_1341423_46 WHERE Results LIKE '%Retired%'; SELECT Party, COUNT(*) AS seat_count FROM table_1_1341423_46 GROUP BY Party ORDER BY seat_count DESC; SELECT District, Incumbent, Party, ""First elected"" FROM table_1_1341423_46 WHERE LOWER(Results) LIKE '%unopposed%' OR LOWER(Candidates) LIKE '%unopposed%';",N/A,remove_column,
"Show District, Incumbent, Party, First elected, Results, and Candidates for Wisconsin and calculate Average margin = CAST(((66 - 34) + (51 - 49) + (64 - 36) + (78 - 22) + (65 - 35) + (63 - 37) + (75 - 25)) / 7.0 AS REAL), and if the smallest margin among (66-34, 51-49, 64-36, 78-22, 65-35, 63-37, 75-25) is <= 5 then report Priority target = 'Wisconsin 2 - Tammy Baldwin' else report NULL?","
SELECT '`District`', '`Incumbent`', '`Party`', '`First elected`', '`Results`', '`Candidates`', CAST(((66 - 34) + (51 - 49) + (64 - 36) + (78 - 22) + (65 - 35) + (63 - 37) + (75 - 25)) / 7.0 AS REAL) `Average margin`, CASE WHEN MIN((66 - 34),(51 - 49),(64 - 36),(78 - 22),(65 - 35),(63 - 37),(75 - 25)) <= 5 THEN '`Wisconsin 2` - `Tammy Baldwin`' ELSE NULL END `Priority target`;
","
SELECT '`District`', 'col0', 'col1', 'col2', 'col3', 'col4', CAST(((66 - 34) + (51 - 49) + (64 - 36) + (78 - 22) + (65 - 35) + (63 - 37) + (75 - 25)) / 7.0 AS REAL) `Average margin`, CASE WHEN MIN((66 - 34),(51 - 49),(64 - 36),(78 - 22),(65 - 35),(63 - 37),(75 - 25)) <= 5 THEN '`Wisconsin 2` - `Tammy Baldwin`' ELSE NULL END `Priority target`;
","[('`District`', 'col0', 'col1', 'col2', 'col3', 'col4', 32.0, '`Wisconsin 2` - `Tammy Baldwin`')]",m_1764880338480_636b2d6b_1341423-49,"1) The SQL intent is to list all table columns, calculate an average of seven vote-margin differences, and conditionally identify a priority target when the smallest margin is <=5. 2) The schema columns are District, Incumbent, Party, First elected, Results, Candidates, and the margins are computed from the percentage pairs in Candidates. 3) Draft a question that explicitly asks for those columns, the exact average formula dividing the sum of the seven differences by 7.0 as a real number, and the conditional Priority target 'Wisconsin 2 - Tammy Baldwin' when the minimum margin is <= 5. 4) Confirm the question mentions every difference term and the conditional outcome.",reserved,9,N/A,split_column,
Which Florida districts first elected in or before 1992 were unopposed?,"
SELECT `district`, `incumbent_name`, `political_party`, `First elected`, `Candidates`, (length(`Candidates`) - length(replace(`Candidates`, '%', ''))) `Percent_sign_count`, ((length(`Candidates`) - length(replace(`Candidates`, '%', ''))) = 0) `Likely_unopposed`, ((length(`Candidates`) - length(replace(`Candidates`, '%', ''))) >= 2) `Clearly_competitive`, 1 `Florida 3`, 1 `Florida 21` FROM `table_m_1764880344263_bf61dd67_1341453_11` WHERE `First elected` <= 1992;
","
SELECT col0, col1, col2, col3, col5, (length(col5) - length(replace(col5, '%', ''))) `Percent_sign_count`, ((length(col5) - length(replace(col5, '%', ''))) = 0) `Likely_unopposed`, ((length(col5) - length(replace(col5, '%', ''))) >= 2) `Clearly_competitive`, 1 `Florida 3`, 1 `Florida 21` FROM `table_m_1764880344263_bf61dd67_1341453_11` WHERE col3 <= 1992;
","[('Florida 3', 'Corrine Brown', 'Democratic', 1992.0, 'Corrine Brown (D) 56% Bill Randall (D) 44%', 2, 0, 1, 1, 1), ('Florida 4', 'Tillie Fowler', 'Republican', 1992.0, 'Tillie Fowler (R) unopposed', 0, 1, 0, 1, 1), ('Florida 5', 'Karen Thurman', 'Democratic', 1992.0, 'Karen Thurman (D) 66.3% Jack Gargan (Ref) 33.7%', 2, 0, 1, 1, 1), ('Florida 6', 'Cliff Stearns', 'Republican', 1988.0, 'Cliff Stearns (R) unopposed', 0, 1, 0, 1, 1), ('Florida 7', 'John Mica', 'Republican', 1992.0, 'John Mica (R) unopposed', 0, 1, 0, 1, 1), ('Florida 8', 'Bill McCollum', 'Republican', 1980.0, 'Bill McCollum (R) 66% Al Krulick (D) 34%', 2, 0, 1, 1, 1), ('Florida 9', 'Michael Bilirakis', 'Republican', 1982.0, 'Michael Bilirakis (R) unopposed', 0, 1, 0, 1, 1), ('Florida 10', 'Bill Young', 'Republican', 1970.0, 'Bill Young (R) unopposed', 0, 1, 0, 1, 1), ('Florida 12', 'Charles Canady', 'Republican', 1992.0, 'Charles Canady (R) unopposed', 0, 1, 0, 1, 1), ('Florida 13', 'Dan Miller', 'Republican', 1992.0, 'Dan Miller (R) unopposed', 0, 1, 0, 1, 1), ('Florida 14', 'Porter Goss', 'Republican', 1988.0, 'Porter Goss (R) unopposed', 0, 1, 0, 1, 1), ('Florida 17', 'Carrie Meek', 'Democratic', 1992.0, 'Carrie Meek (D) unopposed', 0, 1, 0, 1, 1), ('Florida 18', 'Ileana Ros-Lehtinen', 'Republican', 1989.0, 'Ileana Ros-Lehtinen (R) unopposed', 0, 1, 0, 1, 1), ('Florida 20', 'Peter Deutsch', 'Democratic', 1992.0, 'Peter Deutsch (D) unopposed', 0, 1, 0, 1, 1), ('Florida 21', 'Lincoln Diaz-Balart', 'Republican', 1992.0, 'Lincoln Diaz-Balart (R) 75% Patrick Cusack (D) 25%', 2, 0, 1, 1, 1), ('Florida 22', 'Clay Shaw', 'Republican', 1980.0, 'Clay Shaw (R) unopposed', 0, 1, 0, 1, 1)]",m_1764880344263_bf61dd67_1341453-11,"STEP 1: Parse the SQL intent: select District, Incumbent, Party, First elected, Candidates; compute Percent_sign_count as number of '%' characters in Candidates; compute Likely_unopposed when Percent_sign_count = 0 and Clearly_competitive when Percent_sign_count >= 2; include constant columns with value 1 for 'Florida 3' and 'Florida 21'; filter rows with First elected <= 1992 (i.e., incumbents first elected in or before 1992). STEP 2: Determine ambiguity type: attachment (modifier) ambiguity fits well because the phrase 'first elected in or before 1992' and the adjective 'unopposed' can attach either to the district or to the incumbent/race; the SQL specifically attaches it to the incumbent's First elected and infers 'unopposed' from the Candidates field lacking '%' characters. STEP 3: Draft the question: ""Which Florida districts first elected in or before 1992 were unopposed?"" STEP 4: Explain ambiguity: in the original query 'first elected in or before 1992' applies to the incumbent's First elected column and 'unopposed' is operationalized as no '%' in the Candidates string (Likely_unopposed); alternatively the question could mean the district itself was created by 1992, or that the race (not necessarily the incumbent) had no opponents in 1998, or that 'unopposed' means an explicit 'unopposed' label rather than absence of percentage figures.",reserved,3,N/A,rename_column,"type: Attachment ambiguity | explanation: The modifier 'first elected in or before 1992' can attach to the incumbent (as in the query) or to the district's creation/other entity, and 'unopposed' can refer to the incumbent being unopposed, the race being unopposed, or simply absence of percentage figures in the Candidates text—leading to multiple interpretations."
"Which distinct District, Incumbent and Party entries with Results containing 'Retired' have the highest absolute difference between the two vote percentages extracted from the Candidates field (compute Margin as ABS(CAST((first candidate percentage parsed from Candidates - second candidate percentage parsed from Candidates) AS REAL))), and include the constant 1 labeled 'Wisconsin 1', returning the top 3 by Margin in descending order?","
SELECT DISTINCT `district`, `incumbent_name`, `Party`,
ABS(CAST(
(
  substr(`Candidates`, instr(`Candidates`, ')')+2, instr(`Candidates`, '%') - instr(`Candidates`, ')') -1)
 -
  substr(
    substr(`Candidates`, instr(`Candidates`, '%')+1),
    instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')')+2,
    instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')') -1
  )
) AS REAL)) `Margin`, 1 `Wisconsin 1`
FROM `table_m_1764880357355_d7479b73_1341453_51`
WHERE `election_results` LIKE '%Retired%'
ORDER BY `Margin` DESC
LIMIT 3;
","
SELECT DISTINCT col0, col1, col2,
ABS(CAST(
(
  substr(col5, instr(col5, ')')+2, instr(col5, '%') - instr(col5, ')') -1)
 -
  substr(
    substr(col5, instr(col5, '%')+1),
    instr(substr(col5, instr(col5, '%')+1), ')')+2,
    instr(substr(col5, instr(col5, '%')+1), '%') - instr(substr(col5, instr(col5, '%')+1), ')') -1
  )
) AS REAL)) `Margin`, 1 `Wisconsin 1`
FROM `table_m_1764880357355_d7479b73_1341453_51`
WHERE col4 LIKE '%Retired%'
ORDER BY `Margin` DESC
LIMIT 3;
","[('Wisconsin 1', 'Mark Neumann', 'Republican', 14.399999999999999, 1), ('Wisconsin 2', 'Scott Klug', 'Republican', 5.100000000000001, 1)]",m_1764880357355_d7479b73_1341453-51,"1) Intent: return up to three rows filtered by Results containing 'Retired', with District, Incumbent, Party, a computed Margin equal to the absolute numeric difference between the two Candidates percentages, plus a constant column 'Wisconsin 1', ordered by Margin DESC. 2) Map schema: percentages must be extracted from the Candidates text and converted to REAL for subtraction and ABS. 3) Draft the question to request these exact fields and computation, filtered, ordered and limited per the SQL. 4) Confirm all SQL components (columns, calculation, filter, order, limit, constant) are mentioned.",reserved,11,N/A,rename_column,
"List the 1996 Texas House races that are gains, incumbent defeats, retirements or within 10 points, putting turnovers/upsets first and then the closest races, and show district, incumbent, years served, the two vote percentages, margin and the Tight/Competitive/Safe label?",unanswerable,unanswerable,,m_1764880373524_bffea6ce_1341472-45,"I, the novelist-quant, also need to seed Monte Carlo models so I ask about competitiveness and ordering — I'll request turnovers first and then the closest races. The SQL filters to races that are gains, losses, retirements, or within 10 points, computes absolute margin, classifies as Tight/Competitive/Safe, and orders by turnover flag then smallest margin. District, Incumbent, margin and competitiveness are all derived or present in the table. Draft question: ask for those races, ordering turnovers/upsets first then by narrowest margin, with margins and competitiveness labels. Validate: this explicitly requests the ordering and outputs the query implements and nothing beyond it.",persona,"A counterfactual novelist-quant — an alternative-history author who uses historical election tables to generate statistically plausible 1996 Texas House alternate outcomes and character backstories. Goals: Identify which Texas districts experienced party turnover or incumbent defeat in 1996 to seed pivotal plot events in an alternate-history narrative. Quantify margins of victory to classify races by competitiveness (for realistic tension and scene-setting) and to build simple probabilistic models for Monte Carlo alternate outcomes. Extract long-tenure incumbents who retired or were defeated so the author can craft believable motivations, career arcs, and successor character profiles. Example Queries: -- 1) Find districts that changed party or where the incumbent lost (quick shortlist of dramatic flips/defeats)
    SELECT District, Incumbent, Party, `First elected`, Result, Candidates
    FROM table_1_1341472_45
    WHERE Result LIKE '%gain%' OR Result LIKE '%Lost%'; -- 2) Parse candidate percentage strings to compute margins and list competitive races (margin < 10 percentage points) — MySQL-style string parsing
    SELECT
      District,
      Incumbent,
      Party,
      CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 1), ' ', -1) AS DECIMAL(5,2)) AS pct1,
      CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 2), ' ', -1) AS DECIMAL(5,2)) AS pct2,
      ABS(
        CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 1), ' ', -1) AS DECIMAL(5,2)) -
        CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 2), ' ', -1) AS DECIMAL(5,2))
      ) AS margin
    FROM table_1_1341472_45
    WHERE ABS(
      CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 1), ' ', -1) AS DECIMAL(5,2)) -
      CAST(SUBSTRING_INDEX(SUBSTRING_INDEX(Candidates, '%', 2), ' ', -1) AS DECIMAL(5,2))
    ) < 10
    ORDER BY margin ASC; -- 3) List incumbents who retired (e.g., to run for Senate) with tenure computed (1996 election year) for character background building
    SELECT District, Incumbent, Party, `First elected`, Result, (1996 - `First elected`) AS years_in_office, Candidates
    FROM table_1_1341472_45
    WHERE Result LIKE '%Retired%';",N/A,merge_column,
"For each Party, restricting to records with Opponent <> '' and Elected >= 1980, what is the Party, how many Opponent strings contain 'unopposed' (Unopposed_Count), and what is the average opponent percentage (Avg_Opponent_Percent) where the percentage is obtained by taking the substring that starts three characters after '(' and ends at '%' and converting it to a number (exclude 'unopposed' rows from the average by treating them as NULL); only include parties whose Unopposed_Count is greater than zero, order by Unopposed_Count descending, and limit to 10 results?",unanswerable,unanswerable,,m_1764880395805_811438a3_1341568-44,"Parse intent: produce per-Party aggregates counting 'unopposed' opponents and averaging parsed opponent percentages for elections from 1980 onward, ignoring blank Opponent fields. Map schema: use Party as grouping column, compute Unopposed_Count via searching 'unopposed', compute Avg_Opponent_Percent via substring between '('+3 and '%' and numeric cast, excluding 'unopposed' from average. Draft: question must request those exact metrics, filters, HAVING >0, ordering by count desc and limit 10. Validate: all SQL elements are represented.",reserved,19,N/A,merge_column,
"Which Massachusetts House districts in 1988 were unopposed, and who were the incumbents, their party, first‑elected year, and tenure?","
WITH details AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    (1988 - `First elected`) AS `Tenure`,
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `IsUnopposed`,
    CASE WHEN `Result` LIKE '%Retired%' THEN 1 ELSE 0 END AS `IsRetired`
  FROM `table_m_1764880402399_3e439d75_1341577_22`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  `Tenure`,
  `IsUnopposed`,
  `IsRetired`,
  SUM(`IsUnopposed`) OVER () AS `Total_Unopposed`,
  SUM(`IsRetired`) OVER () AS `Total_Retired`,
  COUNT(*) OVER (PARTITION BY `Party`) AS `Seats_For_Party`,
  MIN(`First elected`) OVER () AS `Earliest_First_elected`,
  CASE WHEN `First elected` = MIN(`First elected`) OVER () THEN 1 ELSE 0 END AS `Longest_serving_flag`
FROM details
ORDER BY `IsUnopposed` DESC, `First elected` ASC;
","
WITH details AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    (1988 - col3) AS `Tenure`,
    CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `IsUnopposed`,
    CASE WHEN col4 LIKE '%Retired%' THEN 1 ELSE 0 END AS `IsRetired`
  FROM `table_m_1764880402399_3e439d75_1341577_22`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  `Tenure`,
  `IsUnopposed`,
  `IsRetired`,
  SUM(`IsUnopposed`) OVER () AS `Total_Unopposed`,
  SUM(`IsRetired`) OVER () AS `Total_Retired`,
  COUNT(*) OVER (PARTITION BY col2) AS `Seats_For_Party`,
  MIN(col3) OVER () AS `Earliest_First_elected`,
  CASE WHEN col3 = MIN(col3) OVER () THEN 1 ELSE 0 END AS `Longest_serving_flag`
FROM details
ORDER BY `IsUnopposed` DESC, col3 ASC;
","[('Massachusetts 9', 'Joe Moakley', 'Democratic', 1972.0, 'Re-elected', 'Joe Moakley (D) Unopposed', 16.0, 1, 0, 3, 1, 5, 1952.0, 0), ('Massachusetts 3', 'Joseph D. Early', 'Democratic', 1974.0, 'Re-elected', 'Joseph D. Early (D) Unopposed', 14.0, 1, 0, 3, 1, 5, 1952.0, 0), ('Massachusetts 7', 'Ed Markey', 'Democratic', 1976.0, 'Re-elected', 'Ed Markey (D) Unopposed', 12.0, 1, 0, 3, 1, 5, 1952.0, 0), ('Massachusetts 2', 'Edward Boland', 'Democratic', 1952.0, 'Retired Democratic hold', 'Richard Neal (D) 80.3% Louis R. Godena (I) 19.7%', 36.0, 0, 1, 3, 1, 5, 1952.0, 1), ('Massachusetts 1', 'Silvio Conte', 'Republican', 1958.0, 'Re-elected', 'Silvio Conte (R) 82.7% John R. Arden (D) 17.3%', 30.0, 0, 0, 3, 1, 1, 1952.0, 0), ('Massachusetts 4', 'Barney Frank', 'Democratic', 1980.0, 'Re-elected', 'Barney Frank (D) 70.3% Debra R. Tucker (R) 29.7%', 8.0, 0, 0, 3, 1, 5, 1952.0, 0)]",m_1764880402399_3e439d75_1341577-22,"As a political science researcher I phrase requests to get district-level incumbency and competitiveness measures without SQL jargon. The SQL marks rows with 'Unopposed', computes tenure as 1988 minus the first-elected year, and returns those per-row details. The schema provides District, Incumbent, Party, First elected, Result, Candidates and the computed IsUnopposed and Tenure. Which Massachusetts House districts in 1988 were unopposed, and who were the incumbents, their party, first-elected year, and tenure? This question maps directly to the query's unopposed flag and tenure calculation for each district.",persona,"Political science researcher studying incumbency and electoral competitiveness in U.S. House races, using historical election tables to quantify unopposed contests and party dominance. They would use this database to extract district-level outcomes and incumbency tenure for statistical analysis. Goals: Identify which Massachusetts House races in 1988 were unopposed to measure electoral competitiveness. Quantify party seat distribution in Massachusetts for the 1988 House elections. Find long-serving incumbents (earlier first-elected years) and any districts where incumbents retired to study incumbency effects and turnover. Example Queries: SELECT District, Incumbent, Party, [First elected], Result, Candidates
FROM table_1_1341577_22
WHERE Candidates LIKE '%Unopposed%'; SELECT Party, COUNT(*) AS seats
FROM table_1_1341577_22
GROUP BY Party
ORDER BY seats DESC; SELECT District, Incumbent, Party, [First elected], Result
FROM table_1_1341577_22
WHERE [First elected] <= 1976 OR Result LIKE '%Retired%'
ORDER BY [First elected] ASC;",N/A,add_column,
"Which districts were close contests within 10 points, listing incumbents, parties, incumbent and runner‑up percentages, margins, scenario tags and stability ratings for my swing cards?",unanswerable,unanswerable,,m_1764880458024_7fa3c1e1_1341586-39,"I need to design tense swing‑card mechanics, so I care about narrowly decided contests; I'm comfortable asking for contests within a points threshold. The query marks contests with an absolute margin under 10 points as Close and provides incumbent/runner‑up percentages, margin, tag and stability rating. It extracts percentages from Candidates, computes the margin and classifies rows accordingly using District, Incumbent, Party, Result and Candidates. Draft question: Which districts were close contests within 10 points, listing incumbents, parties, incumbent and runner‑up percentages, margins, scenario tags and stability ratings for my swing cards? Validate: The question exactly targets the SQL's Close classification and requests only returned fields.",persona,"A retro-political board-game designer crafting a 1986 Pennsylvania expansion pack who needs historically grounded balance metrics for scenario cards. Goals: Identify 'safe' districts and truly uncontested seats to assign high stability ratings in the game. Find open-seat races and party flips from incumbent retirements to create dramatic scenario cards and alternate-history branching paths. Detect competitive/close contests to design tense, swing-card mechanics and set victory point rewards appropriately. Example Queries: -- 1) Mark safe districts (unopposed or incumbent received >= 70%)
SELECT District, Incumbent, Party,
  CASE
    WHEN Candidates LIKE '%Unopposed%' THEN 100.0
    ELSE CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)') AS DECIMAL(5,1))
  END AS IncumbentPct
FROM table_1_1341586_39
WHERE Candidates LIKE '%Unopposed%'
   OR (CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)') AS DECIMAL(5,1)) >= 70.0);

-- 2) Find retirements that produced a party gain (open-seat flips) for dramatic scenario cards
SELECT District, Incumbent AS OutgoingIncumbent, Party AS OutgoingParty, Result, Candidates
FROM table_1_1341586_39
WHERE Result LIKE '%Retired%'
  AND Result LIKE '%gain%';

-- 3) List competitively close races (margin between top two listed percentages < 10%) to model high-stakes encounters
SELECT District, Incumbent, Party,
  CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)') AS DECIMAL(5,1)) AS PctTop,
  CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)', 1, 2) AS DECIMAL(5,1)) AS PctRunnerUp,
  ABS(
    CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)') AS DECIMAL(5,1))
    - CAST(REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)', 1, 2) AS DECIMAL(5,1))
  ) AS Margin
FROM table_1_1341586_39
WHERE REGEXP_SUBSTR(Candidates, '[0-9]+\.?[0-9]*(?=%)', 1, 2) IS NOT NULL
HAVING Margin < 10
ORDER BY Margin ASC;",N/A,remove_column,
"For each Party, what is the total number of seats (Total Seats) and how many incumbents were first elected in or before 1976 (Incumbents<=1976), excluding any rows where Party or Result is blank, grouped by Party, only including parties with at least one seat, ordered by Total Seats descending and limited to the top 10 parties?",unanswerable,unanswerable,,m_1764880481377_259e02ee_1341604-19,"1) The query groups rows by Party, counts rows per party, and sums a conditional count of incumbents with First elected <= 1976; it filters out empty Party or Result, requires groups with COUNT(*)>0, orders by count desc, and limits to 10. 2) Map columns: `Party`, `First elected`, and `Result` are used; COUNT(*) becomes Total Seats and the SUM(CASE...) becomes Incumbents<=1976. 3) Draft a question asking for Party, Total Seats, and Incumbents<=1976 with the stated filters, grouping, ordering, and limit. 4) Validate that the question mentions excluding empty Party/Result, grouping by Party, counting total seats, counting incumbents first elected in or before 1976, ordering by total seats descending, and limiting to 10.",reserved,15,N/A,merge_column,
"Provide a prioritized list of Pennsylvania 1980 House races showing District, Incumbent, Party, First elected, Result, Candidates, the vote-margin between the top two listed percentages, a turnover flag for incumbent loss/party gain, a long-tenured flag for first elected before 1976, and tenure years, ordered by closest margin then turnover then tenure.","
WITH parsed AS (
  SELECT
    `District`,
    `Incumbent`,
    `Party`,
    `First elected`,
    `Result`,
    `Candidates`,
    instr(`Candidates`, '%') AS p1_pos,
    CASE
      WHEN instr(`Candidates`, '%') > 0 THEN CAST(substr(`Candidates`, instr(`Candidates`, '%') - 4, 4) AS REAL)
      ELSE NULL
    END AS pct1,
    CASE
      WHEN instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') > 0
      THEN CAST(
        substr(
          `Candidates`,
          instr(`Candidates`, '%') + instr(substr(`Candidates`, instr(`Candidates`, '%') + 1), '%') - 4,
          4
        ) AS REAL
      )
      ELSE NULL
    END AS pct2
  FROM `table_m_1764880510289_22e532df_1341640_39`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `First elected`,
  `Result`,
  `Candidates`,
  -- margin between top two listed percentages (heuristic extraction based on table formats)
  CASE
    WHEN pct1 IS NULL AND `Candidates` LIKE '%Unopposed%' THEN 100.0
    WHEN pct1 IS NULL THEN NULL
    WHEN pct2 IS NULL THEN 100.0
    ELSE ABS(pct1 - pct2)
  END AS margin_pct,
  -- flag for incumbent loss or party gain in 1980
  CASE WHEN `Result` LIKE '%Lost%' OR `Result` LIKE '%gain%' THEN 1 ELSE 0 END AS turnover_flag,
  -- long-tenured incumbents first elected before 1976
  CASE WHEN `First elected` < 1976 THEN 1 ELSE 0 END AS long_tenured_flag,
  -- years in office as of 1980
  (1980 - `First elected`) AS tenure_years
FROM parsed
ORDER BY margin_pct ASC, turnover_flag DESC, tenure_years DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    instr(col5, '%') AS p1_pos,
    CASE
      WHEN instr(col5, '%') > 0 THEN CAST(substr(col5, instr(col5, '%') - 4, 4) AS REAL)
      ELSE NULL
    END AS pct1,
    CASE
      WHEN instr(substr(col5, instr(col5, '%') + 1), '%') > 0
      THEN CAST(
        substr(
          col5,
          instr(col5, '%') + instr(substr(col5, instr(col5, '%') + 1), '%') - 4,
          4
        ) AS REAL
      )
      ELSE NULL
    END AS pct2
  FROM `table_m_1764880510289_22e532df_1341640_39`
)
SELECT
  col0,
  col1,
  col2,
  col3,
  col4,
  col5,
  -- margin between top two listed percentages (heuristic extraction based on table formats)
  CASE
    WHEN pct1 IS NULL AND col5 LIKE '%Unopposed%' THEN 100.0
    WHEN pct1 IS NULL THEN NULL
    WHEN pct2 IS NULL THEN 100.0
    ELSE ABS(pct1 - pct2)
  END AS margin_pct,
  -- flag for incumbent loss or party gain in 1980
  CASE WHEN col4 LIKE '%Lost%' OR col4 LIKE '%gain%' THEN 1 ELSE 0 END AS turnover_flag,
  -- long-tenured incumbents first elected before 1976
  CASE WHEN col3 < 1976 THEN 1 ELSE 0 END AS long_tenured_flag,
  -- years in office as of 1980
  (1980 - col3) AS tenure_years
FROM parsed
ORDER BY margin_pct ASC, turnover_flag DESC, tenure_years DESC;
","[('Pennsylvania 11', 'Ray Musto', 'Democratic', 1980.0, 'Lost re-election Republican gain', 'James L. Nelligan (R) 51.9% Ray Musto (D) 48.1%', 3.799999999999997, 1, 0, 0.0), ('Pennsylvania 12', 'John Murtha', 'Democratic', 1974.0, 'Re-elected', 'John Murtha (D) 59.4% Charles A. Getty (R) 40.6%', 18.799999999999997, 0, 1, 6.0), ('Pennsylvania 6', 'Gus Yatron', 'Democratic', 1968.0, 'Re-elected', 'Gus Yatron (D) 67.1% George Hulshart (R) 32.9%', 34.199999999999996, 0, 1, 12.0), ('Pennsylvania 21', 'Donald A. Bailey', 'Democratic', 1978.0, 'Re-elected', 'Donald A. Bailey (D) 68.4% Dirk Matson (R) 31.6%', 36.800000000000004, 0, 0, 2.0), ('Pennsylvania 18', 'Doug Walgren', 'Democratic', 1976.0, 'Re-elected', 'Doug Walgren (D) 68.5% Steven R. Snyder (R) 31.5%', 37.0, 0, 0, 4.0), ('Pennsylvania 9', 'Bud Shuster', 'Republican', 1972.0, 'Re-elected', 'Bud Shuster (R) Unopposed', 100.0, 0, 1, 8.0)]",m_1764880510289_22e532df_1341640-39,"As an analyst I might ask for a prioritized table for targeting that includes margin, turnover and tenure indicators. The SQL builds those indicators by extracting percentages, checking Result for 'Lost' or 'gain', checking First elected < 1976, and computing tenure years, then orders by margin, turnover, and tenure. The schema provides the base fields used for each derived metric. Draft question: request the full set of fields plus those computed flags and ordering for Pennsylvania 1980 races. Validate: the question maps cleanly to the SQL selection, computations and ordering.",persona,"State-level campaign data analyst working for a political party who studies historical House elections to identify vulnerable seats, turnover patterns, and margins to inform targeting and resource allocation. They use the 1980 House results table to find past upsets, close races, and longevity of incumbents in Pennsylvania. Goals: Identify districts where incumbents lost or where there was a party gain in 1980 to study patterns of turnover. Find historically close races (small vote-margin contests) to flag districts for targeted outreach. Analyze incumbent tenure (first elected year) by party to prioritize long-held vs. recently-won seats. Example Queries: /* 1) Find all districts that resulted in an incumbent loss or a party gain */
SELECT District, Incumbent, Party, ""First elected"", ""Result"", Candidates
FROM table_1_1341640_39
WHERE ""Result"" ILIKE '%Lost%' OR ""Result"" ILIKE '%gain%'; /* 2) Identify close races with margin under 5 percentage points (Postgres regexp to extract two percentages) */
SELECT District, Incumbent, Party, Candidates,
  ABS( (regexp_matches(Candidates, '([0-9]+\.[0-9]+)%')[1])::numeric -
       (regexp_matches(Candidates, '%.* ([0-9]+\.[0-9]+)%')[1])::numeric ) AS margin
FROM table_1_1341640_39
WHERE ABS( (regexp_matches(Candidates, '([0-9]+\.[0-9]+)%')[1])::numeric -
           (regexp_matches(Candidates, '%.* ([0-9]+\.[0-9]+)%')[1])::numeric ) < 5; /* 3) Count incumbents by party who were first elected before 1976 (long-tenured incumbents) and their re-election/result status */
SELECT Party, COUNT(*) AS long_tenured_count,
  SUM(CASE WHEN ""Result"" ILIKE '%Re-elected%' THEN 1 ELSE 0 END) AS re_elected_count,
  SUM(CASE WHEN ""Result"" ILIKE '%Lost%' THEN 1 ELSE 0 END) AS lost_count
FROM table_1_1341640_39
WHERE ""First elected"" < 1976
GROUP BY Party;",N/A,add_column,
"For each Georgia House district in 1978, give me the incumbent, how many years they'd served by 1978 (so I can map tempo in bpm), whether they were unopposed, the candidates' vote percentages if present, the margin, a competitiveness label, and whether the result was a party gain to trigger alternate instrumentation?","
WITH parsed AS (
  SELECT
    `district`,
    `incumbent_name`,
    `Party`,
    `First elected`,
    (1978 - `First elected`) AS `Tenure Years`,
    `election_result`,
    `Candidates`,
    CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Is Unopposed`,
    CASE 
      WHEN instr(`Candidates`, '%')>0 AND instr(`Candidates`, ') ')>0
      THEN CAST(trim(substr(`Candidates`, instr(`Candidates`, ') ')+2, instr(`Candidates`, '%') - (instr(`Candidates`, ') ')+2))) AS REAL)
      ELSE NULL
    END AS `Pct1`,
    CASE
      WHEN instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%')>0 AND instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')>0
      THEN CAST(trim(
        substr(
          substr(`Candidates`, instr(`Candidates`, '%')+1),
          instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')+2,
          instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - (instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')+2)
        )
      ) AS REAL)
      ELSE NULL
    END AS `Pct2`
  FROM `table_m_1764880516268_06309adc_1341663_11`
)
SELECT
  `district`,
  `incumbent_name`,
  `Party`,
  `Tenure Years`,
  CASE
    WHEN `Tenure Years` >= 24 THEN 60
    WHEN `Tenure Years` >= 12 THEN 80
    WHEN `Tenure Years` >= 6 THEN 100
    ELSE 120
  END AS `Suggested Tempo (bpm)`,
  `Is Unopposed`,
  `Pct1`,
  `Pct2`,
  CASE 
    WHEN `Is Unopposed` = 1 THEN NULL
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL THEN ABS(`Pct1` - `Pct2`)
    ELSE NULL
  END AS `Margin (%)`,
  CASE
    WHEN `Is Unopposed` = 1 THEN 'Drone'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL AND ABS(`Pct1` - `Pct2`) < 10 THEN 'Tight competitive interval'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL AND ABS(`Pct1` - `Pct2`) < 30 THEN 'Moderate competitive interval'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL THEN 'Wide interval (landslide)'
    ELSE 'Unknown'
  END AS `Competitiveness`,
  CASE WHEN `election_result` LIKE '%gain%' THEN 1 ELSE 0 END AS `Is Gain`,
  CASE WHEN `election_result` LIKE '%gain%' THEN 'Trigger alternate instrumentation' ELSE 'Standard instrumentation' END AS `Instrumentation Trigger`
FROM parsed
ORDER BY `Is Unopposed` DESC, `Margin (%)` ASC, `Tenure Years` DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    (1978 - col3) AS `Tenure Years`,
    col4,
    col5,
    CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Is Unopposed`,
    CASE 
      WHEN instr(col5, '%')>0 AND instr(col5, ') ')>0
      THEN CAST(trim(substr(col5, instr(col5, ') ')+2, instr(col5, '%') - (instr(col5, ') ')+2))) AS REAL)
      ELSE NULL
    END AS `Pct1`,
    CASE
      WHEN instr(substr(col5, instr(col5, '%')+1), '%')>0 AND instr(substr(col5, instr(col5, '%')+1), ') ')>0
      THEN CAST(trim(
        substr(
          substr(col5, instr(col5, '%')+1),
          instr(substr(col5, instr(col5, '%')+1), ') ')+2,
          instr(substr(col5, instr(col5, '%')+1), '%') - (instr(substr(col5, instr(col5, '%')+1), ') ')+2)
        )
      ) AS REAL)
      ELSE NULL
    END AS `Pct2`
  FROM `table_m_1764880516268_06309adc_1341663_11`
)
SELECT
  col0,
  col1,
  col2,
  `Tenure Years`,
  CASE
    WHEN `Tenure Years` >= 24 THEN 60
    WHEN `Tenure Years` >= 12 THEN 80
    WHEN `Tenure Years` >= 6 THEN 100
    ELSE 120
  END AS `Suggested Tempo (bpm)`,
  `Is Unopposed`,
  `Pct1`,
  `Pct2`,
  CASE 
    WHEN `Is Unopposed` = 1 THEN NULL
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL THEN ABS(`Pct1` - `Pct2`)
    ELSE NULL
  END AS `Margin (%)`,
  CASE
    WHEN `Is Unopposed` = 1 THEN 'Drone'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL AND ABS(`Pct1` - `Pct2`) < 10 THEN 'Tight competitive interval'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL AND ABS(`Pct1` - `Pct2`) < 30 THEN 'Moderate competitive interval'
    WHEN `Pct1` IS NOT NULL AND `Pct2` IS NOT NULL THEN 'Wide interval (landslide)'
    ELSE 'Unknown'
  END AS `Competitiveness`,
  CASE WHEN col4 LIKE '%gain%' THEN 1 ELSE 0 END AS `Is Gain`,
  CASE WHEN col4 LIKE '%gain%' THEN 'Trigger alternate instrumentation' ELSE 'Standard instrumentation' END AS `Instrumentation Trigger`
FROM parsed
ORDER BY `Is Unopposed` DESC, `Margin (%)` ASC, `Tenure Years` DESC;
","[('Georgia 3', 'Jack Thomas Brinkley', 'Democratic', 12.0, 80, 1, None, None, None, 'Drone', 0, 'Standard instrumentation'), ('Georgia 2', 'Dawson Mathis', 'Democratic', 8.0, 100, 1, None, None, None, 'Drone', 0, 'Standard instrumentation'), ('Georgia 1', 'Ronald ""Bo"" Ginn', 'Democratic', 6.0, 100, 1, None, None, None, 'Drone', 0, 'Standard instrumentation'), ('Georgia 8', 'Billy Lee Evans', 'Democratic', 2.0, 120, 1, None, None, None, 'Drone', 0, 'Standard instrumentation'), ('Georgia 6', 'John James Flynt, Jr.', 'Democratic', 24.0, 60, 0, 54.4, 45.6, 8.799999999999997, 'Tight competitive interval', 1, 'Trigger alternate instrumentation'), ('Georgia 9', 'Ed Jenkins', 'Democratic', 2.0, 120, 0, 76.9, 23.1, 53.800000000000004, 'Wide interval (landslide)', 0, 'Standard instrumentation')]",m_1764880516268_06309adc_1341663-11,"I'm a sound artist thinking in tempo and texture rather than SQL; I'll use musical terms like tempo, drone, and instrumentation but avoid technical database jargon. The query computes years in office as 1978 minus 'First elected', maps those years to suggested BPM buckets, detects unopposed races, extracts candidate percentages to compute margins and competitiveness labels, and flags party gains. It reads District, Incumbent, Party, First elected, Result, and Candidates to produce Tenure Years, Suggested Tempo, Is Unopposed, Pct1/Pct2, Margin, Competitiveness, and Is Gain. Draft question: 'For each Georgia House district in 1978, give me the incumbent, how many years they'd served by 1978 (so I can map tempo in bpm), whether they were unopposed, the candidates' vote percentages if present, the margin, a competitiveness label, and whether the result was a party gain to trigger alternate instrumentation.' This question matches the fields produced by the query and doesn't ask for anything outside the table.",persona,"A sound artist-composer building a 1978-Georgia 'political symphony' that maps each congressional district's election attributes to musical parameters. Goals: Translate incumbency length into tempo (longer tenure → slower, sustained lines) by computing years in office as of 1978. Identify which districts were unopposed to assign them sustained drones and which were contested (and margins) to create melodic intervals reflecting competitiveness. Detect party changes or 'gains' (e.g., early Republican breakthroughs) to trigger distinct instrumentation or sudden harmonic shifts in the composition. Example Queries: SELECT ""District"", ""Incumbent"", ""Party"", (1978 - ""First elected"") AS tenure_years FROM table_1_1341663_11 ORDER BY tenure_years DESC; SELECT ""District"", ""Incumbent"", ""Party"" FROM table_1_1341663_11 WHERE ""Candidates"" LIKE '%Unopposed%'; SELECT ""District"", ""Incumbent"", ""Party"", ""Result"", ""Candidates"" FROM table_1_1341663_11 WHERE ""Candidates"" NOT LIKE '%Unopposed%' OR ""Result"" LIKE '%gain%';",N/A,rename_column,
"For each Louisiana district, who is the incumbent, what is the smallest difference in First elected between them and other incumbents from the same party, and how many peers do they have?",unanswerable,unanswerable,,m_1764880526905_f1f344c4_1341663-19,"STEP 1: Parse the SQL intent — For each District (t1) the query returns the District and Incumbent, computes the minimum absolute difference in 'First elected' years between that district's incumbent and other incumbents of the same Party in different Districts (named 'Louisiana 1'), counts the number of same-party other-district rows as PeerCount, excludes groups where the minimum difference = 0, and orders by District. STEP 2: Determine a fitting ambiguity — Scope ambiguity fits well: the natural-language phrase about “how many peers” can either mean the total number of same-party peers overall or the number of peers that achieve that smallest 'First elected' gap. STEP 3: Draft the question — ""For each Louisiana district, who is the incumbent, what is the smallest difference in First elected between them and other incumbents from the same party, and how many peers do they have?"" STEP 4: Explain the ambiguity and interpretations — In the original SQL, PeerCount = COUNT(*) counts all same-party other districts (total peers) while the MIN(...) gives the smallest year gap; an alternative interpretation of the question is that the final count should be only the number of peers that tie for that minimum gap (which would require a different query).",reserved,11,N/A,merge_column,"type: Scope ambiguity | explanation: The phrase ""how many peers do they have"" can mean (A) the total number of other same-party incumbents (what the SQL returns via COUNT(*)), or (B) the number of peers who match the smallest 'First elected' difference (a different query that counts only those tied for the minimum)."
"Produce a table of all Missouri 1978 House districts that includes district, incumbent, party, first elected (years in office), incumbent % and opponent %, margin, a 'Competitive'/'Safe' label (competitive if margin <10%), whether the incumbent won, and the number of seats held by that party, ordered by margin ascending.",unanswerable,unanswerable,,m_1764880533036_00fe6d5f_1341663-26,"For report tables I often need party seat totals alongside per‑district results and a competitiveness flag, phrased plainly. The SQL returns per‑district vote shares and margins, a competitiveness label based on margin<10, incumbent win flag, and a count of seats by party via a subquery. It maps District, Incumbent, Party, First elected, computes years_in_office, parses candidate percentages, margin, competitiveness, incumbent_won, and seats_by_party. Drafted question: produce a table of all 1978 Missouri House districts with those metrics and party seat counts, ordered from closest to safest. This reflects exactly the fields and ordering the query produces.",persona,"A Missouri political data analyst at a state think tank who researches historical House election results to understand incumbency strength and voting patterns. They use this database to extract vote shares, margins, and tenure information from the 1978 Missouri U.S. House races to inform reports and visualizations. Goals: Measure incumbency advantage in Missouri's 1978 House races by comparing vote shares and margins for incumbents vs. challengers. Summarize party seat distribution across Missouri districts in 1978 and identify competitive districts. Correlate incumbents' years in office (tenure) with their 1978 victory margins to look for tenure-related trends. Example Queries: SELECT Party, COUNT(*) AS seats
FROM table_1_1341663_26
GROUP BY Party
ORDER BY seats DESC; SELECT District, Incumbent, Party, ""First elected"", Result,
       CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 1) AS REAL) AS pct_1,
       CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 2) AS REAL) AS pct_2,
       ABS(CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 1) AS REAL) -
           CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 2) AS REAL)) AS margin
FROM table_1_1341663_26
WHERE Result LIKE '%Re-elected%'
ORDER BY margin ASC; SELECT years_in_office, ROUND(AVG(margin), 2) AS avg_margin
FROM (
  SELECT (1978 - ""First elected"") AS years_in_office,
         ABS(CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 1) AS REAL) -
             CAST(REGEXP_SUBSTR(Candidates, '\\d+\\.\\d+(?=%)', 1, 2) AS REAL)) AS margin
  FROM table_1_1341663_26
) AS sub
GROUP BY years_in_office
ORDER BY years_in_office;",N/A,remove_column,
"Which rows with a '%' in Candidates have District, Incumbent, Party, First elected, Result and Candidates along with the winner percentage (parsed as the trimmed numeric substring immediately after the first ')' and before the next '%'), the runner_pct computed as 100.0 minus that winner percentage, the Margin computed as abs(2.0 * winner_pct - 100.0) that is less than 10, and an Is_Unopposed boolean indicating whether Candidates contains 'Unopposed'?","
SELECT `district`, `incumbent_name`, `political_party`, `First elected`, `Result`, `Candidates`,
trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 2)) Winner_pct,
100.0 - trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 2)) Runner_pct,
abs(2.0 * trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 2)) - 100.0) Margin,
(`Candidates` LIKE '%Unopposed%') Is_Unopposed
FROM `table_m_1764880539048_eade3e83_1341663_33`
WHERE instr(`Candidates`, '%') > 0 AND abs(2.0 * trim(substr(`Candidates`, instr(`Candidates`, ')') + 2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 2)) - 100.0) < 10;
","
SELECT col0, col1, col2, col3, col4, col5,
trim(substr(col5, instr(col5, ')') + 2, instr(col5, '%') - instr(col5, ')') - 2)) Winner_pct,
100.0 - trim(substr(col5, instr(col5, ')') + 2, instr(col5, '%') - instr(col5, ')') - 2)) Runner_pct,
abs(2.0 * trim(substr(col5, instr(col5, ')') + 2, instr(col5, '%') - instr(col5, ')') - 2)) - 100.0) Margin,
(col5 LIKE '%Unopposed%') Is_Unopposed
FROM `table_m_1764880539048_eade3e83_1341663_33`
WHERE instr(col5, '%') > 0 AND abs(2.0 * trim(substr(col5, instr(col5, ')') + 2, instr(col5, '%') - instr(col5, ')') - 2)) - 100.0) < 10;
","[('New York 18', 'S. William Green', 'Republican', 1978.0, 'Re-elected', 'S. William Green (R) 53.3% Carter Burden (D) 46.7%', '53.3', 46.7, 6.599999999999994, 0)]",m_1764880539048_eade3e83_1341663-33,"1) Parse the SQL intent: select detailed election rows that include a percent sign and are close contests (computed margin < 10). 2) Map schema semantics: output District, Incumbent, Party, First elected, Result, Candidates, parse winner_pct from the substring after the first ')' up to '%', compute runner_pct = 100.0 - winner_pct, Margin = abs(2.0 * winner_pct - 100.0), and Is_Unopposed where Candidates LIKE '%Unopposed%'. 3) Draft the question to request these fields and computations and apply the filters. 4) Validate inclusion of parsing, arithmetic, and filter criteria.",reserved,5,N/A,rename_column,
Which districts featured George W. Bush and Ron Paul?,"
SELECT 'Incumbency counts' AS `Category`, `Result` AS `Item`, CAST(COUNT(*) AS TEXT) AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
GROUP BY `Result`
UNION ALL
SELECT 'Party changes (gains)' AS `Category`, `District` || ' - ' || `Result` AS `Item`, `Candidates` AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
WHERE `Result` LIKE '%gain%'
UNION ALL
SELECT 'Unopposed races' AS `Category`, `District` AS `Item`, `Candidates` AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
WHERE `Candidates` LIKE '%Unopposed%'
UNION ALL
SELECT 'Notable appearances' AS `Category`, `District` || ' - ' || `Candidates` AS `Item`, '' AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
WHERE `Candidates` LIKE '%George W. Bush%' OR `Candidates` LIKE '%Ron Paul%'
UNION ALL
SELECT 'Close contests (<=5% margin)' AS `Category`,
       `District` || ' | margin ' || printf('%.1f%%', ABS(
         CAST(substr(`Candidates`, instr(`Candidates`,') ')+2,
                    instr(`Candidates`,'%') - (instr(`Candidates`,') ')+2)
         ) AS REAL)
         - CAST(substr(`Candidates`,
                    (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ') + 2),
                    (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), '%')
                      - (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ') + 2))
         ) AS REAL)
       )) AS `Item`,
       `Candidates` AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
WHERE instr(`Candidates`,'%')>0
  AND instr(substr(`Candidates`, instr(`Candidates`,'%')+1), '%')>0
  AND instr(`Candidates`,') ')>0
  AND instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ')>0
  AND ABS(
         CAST(substr(`Candidates`, instr(`Candidates`,') ')+2,
                    instr(`Candidates`,'%') - (instr(`Candidates`,') ')+2)
         ) AS REAL)
         - CAST(substr(`Candidates`,
                    (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ') + 2),
                    (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), '%')
                      - (instr(`Candidates`,'%') + instr(substr(`Candidates`, instr(`Candidates`,'%')+1), ') ') + 2))
         ) AS REAL)
       ) <= 5
;
","
SELECT 'Incumbency counts' AS `Category`, col4 AS `Item`, CAST(COUNT(*) AS TEXT) AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
GROUP BY col4
UNION ALL
SELECT 'Party changes (gains)' AS `Category`, col0 || ' - ' || col4 AS `Item`, col5 AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
WHERE col4 LIKE '%gain%'
UNION ALL
SELECT 'Unopposed races' AS `Category`, col0 AS `Item`, col5 AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
WHERE col5 LIKE '%Unopposed%'
UNION ALL
SELECT 'Notable appearances' AS `Category`, col0 || ' - ' || col5 AS `Item`, '' AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
WHERE col5 LIKE '%George W. Bush%' OR col5 LIKE '%Ron Paul%'
UNION ALL
SELECT 'Close contests (<=5% margin)' AS `Category`,
       col0 || ' | margin ' || printf('%.1f%%', ABS(
         CAST(substr(col5, instr(col5,') ')+2,
                    instr(col5,'%') - (instr(col5,') ')+2)
         ) AS REAL)
         - CAST(substr(col5,
                    (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), ') ') + 2),
                    (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), '%')
                      - (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), ') ') + 2))
         ) AS REAL)
       )) AS `Item`,
       col5 AS `Value`
FROM `table_m_1764880546491_e1d2e690_1341663_44`
WHERE instr(col5,'%')>0
  AND instr(substr(col5, instr(col5,'%')+1), '%')>0
  AND instr(col5,') ')>0
  AND instr(substr(col5, instr(col5,'%')+1), ') ')>0
  AND ABS(
         CAST(substr(col5, instr(col5,') ')+2,
                    instr(col5,'%') - (instr(col5,') ')+2)
         ) AS REAL)
         - CAST(substr(col5,
                    (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), ') ') + 2),
                    (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), '%')
                      - (instr(col5,'%') + instr(substr(col5, instr(col5,'%')+1), ') ') + 2))
         ) AS REAL)
       ) <= 5
;
","[('Incumbency counts', 'Lost re-election Republican gain', '1'), ('Incumbency counts', 'Lost renomination Democratic hold', '1'), ('Incumbency counts', 'Re-elected', '7'), ('Incumbency counts', 'Retired Democratic hold', '3'), ('Party changes (gains)', 'Texas 22 - Lost re-election Republican gain', 'Ron Paul (R) 50.6% Robert Gammage (D) 49.4%'), ('Unopposed races', 'Texas 3', 'James M. Collins (R) Unopposed'), ('Unopposed races', 'Texas 20', 'Henry B. Gonzalez (D) Unopposed'), ('Notable appearances', 'Texas 19 - Kent Hance (D) 53.2% George W. Bush (R) 46.8%', ''), ('Notable appearances', 'Texas 22 - Ron Paul (R) 50.6% Robert Gammage (D) 49.4%', ''), ('Close contests (<=5% margin)', 'Texas 11 | margin 3.2%', 'Marvin Leath (D) 51.6% Jack Burgess (R) 48.4%'), ('Close contests (<=5% margin)', 'Texas 22 | margin 1.2%', 'Ron Paul (R) 50.6% Robert Gammage (D) 49.4%')]",m_1764880546491_e1d2e690_1341663-44,"STEP 1: Parse the SQL intent: the query unions several category outputs; one unioned branch labeled 'Notable appearances' selects District || ' - ' || Candidates for rows WHERE Candidates LIKE '%George W. Bush%' OR Candidates LIKE '%Ron Paul%'. That branch returns any district where either name appears. STEP 2: Determine ambiguity type: attachment ambiguity fits — a natural-language question that joins the two names with 'and' can be read as requiring both names to be present or as allowing either to be present. STEP 3: Draft the question: ""Which districts featured George W. Bush and Ron Paul?"" STEP 4: Explain the ambiguity: in the original SQL the condition uses OR so the result includes districts with either candidate; a reader of the question might instead expect only districts where both appeared together (AND) or might read it as asking for districts with either candidate listed separately.",persona,"Political data analyst at a state election research center who compiles historical election trends and briefings for journalists and policymakers. They use this 1978 House results table to track incumbency outcomes, party flips, unopposed races, and notable candidate appearances in Texas. Goals: Measure incumbency outcomes (re-elected, retired, lost) and count seats by each result type. Identify party changes (Republican gains / Democratic holds) to map historical turnover. Locate unopposed races and contests with notable future figures (e.g., George W. Bush, Ron Paul) for narrative reporting. Prepare a short list of competitive or close contests for follow-up (requires parsing vote percentages). Example Queries: /* 1) Summary of incumbency outcomes: how many seats ended as re-elected, retired, lost, etc. */
SELECT ""Result"", COUNT(*) AS seats
FROM table_1_1341663_44
GROUP BY ""Result""
ORDER BY seats DESC; /* 2) List all districts where the race was unopposed (no challenger listed). */
SELECT ""District"", ""Incumbent"", ""Party"", ""Candidates""
FROM table_1_1341663_44
WHERE ""Candidates"" ILIKE '%Unopposed%'; /* 3) Find districts that changed party control (any result mentioning 'gain') and show the reported candidates so you can inspect winners/margins. */
SELECT ""District"", ""Incumbent"", ""Party"", ""Result"", ""Candidates""
FROM table_1_1341663_44
WHERE ""Result"" ILIKE '%gain%';",N/A,add_column,type: Attachment ambiguity | explanation: The SQL uses OR and returns districts where either George W. Bush or Ron Paul appears; the question's phrasing with 'and' can be interpreted as requiring both candidates to appear in the same district (AND) or as asking for districts with either candidate (OR).
"Show me all 1974 House races with district, incumbent, party, first-elected year, result, the candidate percentages, the vote margin and a scene tag (Unopposed/Blowout, FreshmanDefeat/HighConflict, IncumbentLost/HighConflict, Nail-biter/Tense, Blowout/LowConflict, Competitive/Moderate), with the biggest seat changes and freshman upsets listed first so I can sequence the revue?","
WITH parsed AS (
  SELECT `District`, `Incumbent`, `Party`, `Candidates`, CASE WHEN `ElectionOutcome_and_FirstElectedYear` LIKE '%Lost re-election%' OR `ElectionOutcome_and_FirstElectedYear` LIKE '%gain%' THEN 1 ELSE 0 END AS `Lost_or_Changed`, CASE WHEN `ElectionOutcome_and_FirstElectedYear` >= 1972 AND (`ElectionOutcome_and_FirstElectedYear` LIKE '%Lost re-election%' OR `ElectionOutcome_and_FirstElectedYear` LIKE '%gain%') THEN 1 ELSE 0 END AS `Freshman_defeat`, CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Unopposed`, CASE
      WHEN instr(`Candidates`, '%')>0 THEN
        trim(
          substr(
            `Candidates`, instr(`Candidates`, ') ')+2, instr(`Candidates`, '%') - (instr(`Candidates`, ') ')+2)
          )
        )
      ELSE NULL
    END AS `num1_str`, CASE
      WHEN instr(`Candidates`, '%')>0 AND instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%')>0 THEN
        trim(
          substr(
            substr(`Candidates`, instr(`Candidates`, '%')+1), instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')+2, instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - (instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ') ')+2)
          )
        )
      ELSE NULL
    END AS `num2_str`, `ElectionOutcome_and_FirstElectedYear` FROM `table_m_1764880567410_b46aefb9_1341690_13`
)
SELECT
  `District`,
  `Incumbent`,
  `Party`,
  `ElectionOutcome_and_FirstElectedYear`,
  `ElectionOutcome_and_FirstElectedYear`,
  `Candidates`,
  `Lost_or_Changed`,
  `Freshman_defeat`,
  `Unopposed`,
  CASE WHEN `num1_str` IS NOT NULL THEN CAST(`num1_str` AS real) ELSE NULL END AS `First_pct`,
  CASE WHEN `num2_str` IS NOT NULL THEN CAST(`num2_str` AS real) ELSE NULL END AS `Second_pct`,
  CASE WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL THEN abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) ELSE NULL END AS `Margin_pct`,
  CASE
    WHEN `Unopposed`=1 THEN 'Unopposed/Blowout'
    WHEN `Lost_or_Changed`=1 AND `Freshman_defeat`=1 THEN 'FreshmanDefeat/HighConflict'
    WHEN `Lost_or_Changed`=1 THEN 'IncumbentLost/HighConflict'
    WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL AND abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) <= 2 THEN 'Nail-biter/Tense'
    WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL AND abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) >= 20 THEN 'Blowout/LowConflict'
    ELSE 'Competitive/Moderate'
  END AS `Scene_tag`
FROM parsed
ORDER BY `Lost_or_Changed` DESC, `Freshman_defeat` DESC, `Margin_pct` ASC;
","
WITH parsed AS (
  SELECT col0, col1, col2, col3, CASE WHEN col4 LIKE '%Lost re-election%' OR col4 LIKE '%gain%' THEN 1 ELSE 0 END AS `Lost_or_Changed`, CASE WHEN col4 >= 1972 AND (col4 LIKE '%Lost re-election%' OR col4 LIKE '%gain%') THEN 1 ELSE 0 END AS `Freshman_defeat`, CASE WHEN col3 LIKE '%Unopposed%' THEN 1 ELSE 0 END AS `Unopposed`, CASE
      WHEN instr(col3, '%')>0 THEN
        trim(
          substr(
            col3, instr(col3, ') ')+2, instr(col3, '%') - (instr(col3, ') ')+2)
          )
        )
      ELSE NULL
    END AS `num1_str`, CASE
      WHEN instr(col3, '%')>0 AND instr(substr(col3, instr(col3, '%')+1), '%')>0 THEN
        trim(
          substr(
            substr(col3, instr(col3, '%')+1), instr(substr(col3, instr(col3, '%')+1), ') ')+2, instr(substr(col3, instr(col3, '%')+1), '%') - (instr(substr(col3, instr(col3, '%')+1), ') ')+2)
          )
        )
      ELSE NULL
    END AS `num2_str`, col4 FROM `table_m_1764880567410_b46aefb9_1341690_13`
)
SELECT
  col0,
  col1,
  col2,
  col4,
  col4,
  col3,
  `Lost_or_Changed`,
  `Freshman_defeat`,
  `Unopposed`,
  CASE WHEN `num1_str` IS NOT NULL THEN CAST(`num1_str` AS real) ELSE NULL END AS `First_pct`,
  CASE WHEN `num2_str` IS NOT NULL THEN CAST(`num2_str` AS real) ELSE NULL END AS `Second_pct`,
  CASE WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL THEN abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) ELSE NULL END AS `Margin_pct`,
  CASE
    WHEN `Unopposed`=1 THEN 'Unopposed/Blowout'
    WHEN `Lost_or_Changed`=1 AND `Freshman_defeat`=1 THEN 'FreshmanDefeat/HighConflict'
    WHEN `Lost_or_Changed`=1 THEN 'IncumbentLost/HighConflict'
    WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL AND abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) <= 2 THEN 'Nail-biter/Tense'
    WHEN `num1_str` IS NOT NULL AND `num2_str` IS NOT NULL AND abs(CAST(`num1_str` AS real) - CAST(`num2_str` AS real)) >= 20 THEN 'Blowout/LowConflict'
    ELSE 'Competitive/Moderate'
  END AS `Scene_tag`
FROM parsed
ORDER BY `Lost_or_Changed` DESC, `Freshman_defeat` DESC, `Margin_pct` ASC;
","[('Illinois 10', 'Samuel H. Young', 'Republican', 'Lost re-election Democratic gain, 1972', 'Lost re-election Democratic gain, 1972', 'Abner J. Mikva (D) 50.9% Samuel H. Young (R) 49.1%', 1, 1, 0, 50.9, 49.1, 1.7999999999999972, 'FreshmanDefeat/HighConflict'), ('Illinois 3', 'Robert P. Hanrahan', 'Republican', 'Lost re-election Democratic gain, 1972', 'Lost re-election Democratic gain, 1972', 'Marty Russo (D) 52.6% Robert P. Hanrahan (R) 47.4%', 1, 1, 0, 52.6, 47.4, 5.200000000000003, 'FreshmanDefeat/HighConflict'), ('Illinois 9', 'Sidney R. Yates', 'Democratic', 'Re-elected, 1964', 'Re-elected, 1964', 'Sidney R. Yates (D) Unopposed', 0, 0, 1, None, None, None, 'Unopposed/Blowout'), ('Illinois 6', 'Harold R. Collier', 'Republican', 'Retired Republican hold, 1956', 'Retired Republican hold, 1956', 'Henry Hyde (R) 53.4% Edward V. Hanrahan (D) 46.6%', 0, 0, 0, 53.4, 46.6, 6.799999999999997, 'Competitive/Moderate'), ('Illinois 20', 'Paul Findley', 'Republican', 'Re-elected, 1960', 'Re-elected, 1960', 'Paul Findley (R) 54.8% Peter F. Mack (D) 45.2%', 0, 0, 0, 54.8, 45.2, 9.599999999999994, 'Competitive/Moderate'), ('Illinois 4', 'Ed Derwinski', 'Republican', 'Re-elected, 1958', 'Re-elected, 1958', 'Ed Derwinski (R) 59.2% Ronald A. Rodger (D) 40.8%', 0, 0, 0, 59.2, 40.8, 18.400000000000006, 'Competitive/Moderate'), ('Illinois 12', 'Phil Crane', 'Republican', 'Re-elected, 1969', 'Re-elected, 1969', 'Phil Crane (R) 61.1% Betty C. Spence (D) 38.9%', 0, 0, 0, 61.1, 38.9, 22.200000000000003, 'Blowout/LowConflict'), ('Illinois 19', 'Tom Railsback', 'Republican', 'Re-elected, 1966', 'Re-elected, 1966', 'Tom Railsback (R) 65.3% Jim Gende (D) 34.7%', 0, 0, 0, 65.3, 34.7, 30.599999999999994, 'Blowout/LowConflict'), ('Illinois 23', 'Melvin Price', 'Democratic', 'Re-elected, 1944', 'Re-elected, 1944', 'Melvin Price (D) 80.5% Scott Randolph (R) 19.5%', 0, 0, 0, 80.5, 19.5, 61.0, 'Blowout/LowConflict')]",m_1764880567410_b46aefb9_1341690-13,"As a dramaturge I want a ready scene list prioritizing the most dramatic moments but I won't say 'order by' — I'll ask for the most dramatic first. The SQL produces parsed vote percentages, a margin, scene tags (Unopposed/Blowout, FreshmanDefeat/HighConflict, IncumbentLost/HighConflict, Nail-biter/Tense, Blowout/LowConflict, Competitive/Moderate) and orders results to put losses and freshman defeats first. The schema supplies district, incumbent, party, first-elected, result, candidates, computed percentages, margin and the scene tag. The question should request the full set with those scene tags and to list the biggest seat changes and freshman upsets at the top for scene sequencing.",persona,"A theatrical dramaturge and costume designer creating a 1974 political stage revue who needs district-level race details to script scenes, design costumes and pace dramatic beats. Goals: Identify which incumbents lost or seats changed party in 1974 to create high-conflict scenes and cast 'victims' and 'winners'. Find short‑tenured (recently elected) incumbents who were defeated to dramatize rapid political downfall and craft costume/prop cues that signal 'newly fallen' vs. 'longtime veteran'. Select extreme and close outcomes (unopposed blowouts and nail-biter races) to vary scene intensity and choreograph lighting/musical cues. Example Queries: /* All districts where the incumbent lost or the seat changed party */
SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1341690_13
WHERE Result LIKE '%Lost re-election%'
   OR Result LIKE '%gain%'; /* Freshman incumbents (elected 1972 or later) who were defeated — useful for 'rapid fall' characters */
SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1341690_13
WHERE ""First elected"" >= 1972
  AND Result LIKE '%Lost re-election%'; /* Find the tightest races by extracting vote percentages (Postgres-style regex) to stage close, tense scenes */
SELECT District, Incumbent, Candidates,
  abs((regexp_matches(Candidates, '([0-9]+\.[0-9]+)%')[1])::float -
      (regexp_matches(Candidates, '[A-Za-z\) ]+ ([0-9]+\.[0-9]+)%')[1])::float) AS margin_pct
FROM table_1_1341690_13
WHERE Candidates ~ '[0-9]+\.[0-9]+%.*[0-9]+\.[0-9]+%'
ORDER BY margin_pct ASC
LIMIT 5;",N/A,merge_column,
"Among rows where First elected is before 1970, for each Party (grouped by Party) what is the Party name, how many Seats it holds (COUNT(*)), how many of its Candidates entries contain 'Unopposed' (Unopposed_count), the average First elected year rounded to one decimal (Avg_first_elected), and the percentage of seats that were Unopposed rounded to one decimal (Unopposed_pct), including only parties with at least one seat and limiting the result to 5 parties?",unanswerable,unanswerable,,m_1764880582566_a4c059c4_1341690-43,"1) The SQL filters rows by First elected < 1970, groups by Party, and computes seat counts and unopposed statistics with rounding. 2) Identify columns and calculations: Party, COUNT(*) as Seats, SUM(instr(Candidates,'Unopposed')>0) as Unopposed_count, ROUND(AVG(First elected),1) as Avg_first_elected, and ROUND(100.0*SUM(...)/COUNT(*),1) as Unopposed_pct. 3) Create a question asking for these exact outputs per Party with the filter and group condition and limit. 4) Ensure the question explicitly states the filter, the detection of 'Unopposed' in Candidates, the rounding to one decimal, the requirement of at least one seat, and the limit of 5.",reserved,8,N/A,merge_column,
"For each California district, give the incumbent verbatim and then pull out candidate1 and candidate2 names and parties (as written), their vote percentages (NULL if Unopposed), and the absolute margin between the two so I can craft dialogue and flyers?","WITH t AS (
  SELECT
    `District`,
    `Incumbent`,
    `First elected`,
    `Result`,
    `Candidates`,
    instr(`Candidates`, '(') AS pos_open1,
    instr(`Candidates`, ')') AS pos_close1,
    instr(`Candidates`, '%') AS pos_pct1
  FROM `table_m_1764880613560_cfa8af88_1341690_5`
)
SELECT
  `District`,
  '`' || `Incumbent` || '`' AS `Incumbent_raw`,
  CASE
    WHEN `Incumbent` LIKE '%Redistricted from the %' THEN '`' || trim(substr(`Incumbent`, instr(`Incumbent`, 'Redistricted from the ') + 22)) || '`'
    ELSE NULL
  END AS `Original_district`,
  `First elected`,
  `Result`,
  -- Candidate 1 name and party (wrapped in backticks for verbatim output)
  '`' || trim(substr(`Candidates`, 1, pos_open1 - 1)) || '`' AS `Candidate1_name`,
  '`' || substr(`Candidates`, pos_open1 + 1, pos_close1 - pos_open1 - 1) || '`' AS `Candidate1_party`,
  -- Candidate 1 percent (NULL for Unopposed)
  CASE
    WHEN `Candidates` LIKE '%Unopposed%' THEN NULL
    WHEN pos_pct1 > 0 THEN CAST(trim(substr(substr(`Candidates`, pos_close1 + 2), 1, instr(substr(`Candidates`, pos_close1 + 2), '%') - 1)) AS REAL)
    ELSE NULL
  END AS `Candidate1_pct`,
  -- Candidate 2 name and party (if present) (wrapped in backticks)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '(') > 0 THEN '`' || trim(substr(substr(`Candidates`, pos_pct1 + 1), 1, instr(substr(`Candidates`, pos_pct1 + 1), '(') - 1)) || '`'
    ELSE NULL
  END AS `Candidate2_name`,
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '(') > 0 THEN '`' || substr(substr(`Candidates`, pos_pct1 + 1), instr(substr(`Candidates`, pos_pct1 + 1), '(') + 1, instr(substr(`Candidates`, pos_pct1 + 1), ')') - instr(substr(`Candidates`, pos_pct1 + 1), '(') - 1) || '`'
    ELSE NULL
  END AS `Candidate2_party`,
  -- Candidate 2 percent (if present)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '%') > 0 THEN CAST(trim(substr(substr(`Candidates`, pos_pct1 + 1), instr(substr(`Candidates`, pos_pct1 + 1), ')') + 2, instr(substr(`Candidates`, pos_pct1 + 1), '%') - instr(substr(`Candidates`, pos_pct1 + 1), ')') - 2)) AS REAL)
    ELSE NULL
  END AS `Candidate2_pct`,
  -- Absolute margin between the two percentages (NULL if missing)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '%') > 0 THEN
      ABS(
        CAST(trim(substr(substr(`Candidates`, pos_close1 + 2), 1, instr(substr(`Candidates`, pos_close1 + 2), '%') - 1)) AS REAL)
        - CAST(trim(substr(substr(`Candidates`, pos_pct1 + 1), instr(substr(`Candidates`, pos_pct1 + 1), ')') + 2, instr(substr(`Candidates`, pos_pct1 + 1), '%') - instr(substr(`Candidates`, pos_pct1 + 1), ')') - 2)) AS REAL)
      )
    ELSE NULL
  END AS `Margin`,
  -- Drama flags: Unopposed, Narrow margin <=5%, Turnover
  CASE
    WHEN `Candidates` LIKE '%Unopposed%' THEN 'Unopposed'
    WHEN pos_pct1 > 0 AND instr(substr(`Candidates`, pos_pct1 + 1), '%') > 0 AND
         ABS(
           CAST(trim(substr(substr(`Candidates`, pos_close1 + 2), 1, instr(substr(`Candidates`, pos_close1 + 2), '%') - 1)) AS REAL)
           - CAST(trim(substr(substr(`Candidates`, pos_pct1 + 1), instr(substr(`Candidates`, pos_pct1 + 1), ')') + 2, instr(substr(`Candidates`, pos_pct1 + 1), '%') - instr(substr(`Candidates`, pos_pct1 + 1), ')') - 2)) AS REAL)
         ) <= 5.0
    THEN 'Narrow<=5%'
    ELSE NULL
  END AS `Drama_flag`,
  CASE WHEN `Result` LIKE '%gain%' OR `Result` LIKE '%Lost%' THEN 'Turnover' ELSE NULL END AS `Turnover_flag`
FROM t
ORDER BY (`Margin` IS NULL), `Margin` ASC;","WITH t AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    instr(col4, '(') AS pos_open1,
    instr(col4, ')') AS pos_close1,
    instr(col4, '%') AS pos_pct1
  FROM `table_m_1764880613560_cfa8af88_1341690_5`
)
SELECT
  col0,
  '`' || col1 || '`' AS `Incumbent_raw`,
  CASE
    WHEN col1 LIKE '%Redistricted from the %' THEN '`' || trim(substr(col1, instr(col1, 'Redistricted from the ') + 22)) || '`'
    ELSE NULL
  END AS `Original_district`,
  col2,
  col3,
  -- Candidate 1 name and party (wrapped in backticks for verbatim output)
  '`' || trim(substr(col4, 1, pos_open1 - 1)) || '`' AS `Candidate1_name`,
  '`' || substr(col4, pos_open1 + 1, pos_close1 - pos_open1 - 1) || '`' AS `Candidate1_party`,
  -- Candidate 1 percent (NULL for Unopposed)
  CASE
    WHEN col4 LIKE '%Unopposed%' THEN NULL
    WHEN pos_pct1 > 0 THEN CAST(trim(substr(substr(col4, pos_close1 + 2), 1, instr(substr(col4, pos_close1 + 2), '%') - 1)) AS REAL)
    ELSE NULL
  END AS `Candidate1_pct`,
  -- Candidate 2 name and party (if present) (wrapped in backticks)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(col4, pos_pct1 + 1), '(') > 0 THEN '`' || trim(substr(substr(col4, pos_pct1 + 1), 1, instr(substr(col4, pos_pct1 + 1), '(') - 1)) || '`'
    ELSE NULL
  END AS `Candidate2_name`,
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(col4, pos_pct1 + 1), '(') > 0 THEN '`' || substr(substr(col4, pos_pct1 + 1), instr(substr(col4, pos_pct1 + 1), '(') + 1, instr(substr(col4, pos_pct1 + 1), ')') - instr(substr(col4, pos_pct1 + 1), '(') - 1) || '`'
    ELSE NULL
  END AS `Candidate2_party`,
  -- Candidate 2 percent (if present)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(col4, pos_pct1 + 1), '%') > 0 THEN CAST(trim(substr(substr(col4, pos_pct1 + 1), instr(substr(col4, pos_pct1 + 1), ')') + 2, instr(substr(col4, pos_pct1 + 1), '%') - instr(substr(col4, pos_pct1 + 1), ')') - 2)) AS REAL)
    ELSE NULL
  END AS `Candidate2_pct`,
  -- Absolute margin between the two percentages (NULL if missing)
  CASE
    WHEN pos_pct1 > 0 AND instr(substr(col4, pos_pct1 + 1), '%') > 0 THEN
      ABS(
        CAST(trim(substr(substr(col4, pos_close1 + 2), 1, instr(substr(col4, pos_close1 + 2), '%') - 1)) AS REAL)
        - CAST(trim(substr(substr(col4, pos_pct1 + 1), instr(substr(col4, pos_pct1 + 1), ')') + 2, instr(substr(col4, pos_pct1 + 1), '%') - instr(substr(col4, pos_pct1 + 1), ')') - 2)) AS REAL)
      )
    ELSE NULL
  END AS `Margin`,
  -- Drama flags: Unopposed, Narrow margin <=5%, Turnover
  CASE
    WHEN col4 LIKE '%Unopposed%' THEN 'Unopposed'
    WHEN pos_pct1 > 0 AND instr(substr(col4, pos_pct1 + 1), '%') > 0 AND
         ABS(
           CAST(trim(substr(substr(col4, pos_close1 + 2), 1, instr(substr(col4, pos_close1 + 2), '%') - 1)) AS REAL)
           - CAST(trim(substr(substr(col4, pos_pct1 + 1), instr(substr(col4, pos_pct1 + 1), ')') + 2, instr(substr(col4, pos_pct1 + 1), '%') - instr(substr(col4, pos_pct1 + 1), ')') - 2)) AS REAL)
         ) <= 5.0
    THEN 'Narrow<=5%'
    ELSE NULL
  END AS `Drama_flag`,
  CASE WHEN col3 LIKE '%gain%' OR col3 LIKE '%Lost%' THEN 'Turnover' ELSE NULL END AS `Turnover_flag`
FROM t
ORDER BY (`Margin` IS NULL), `Margin` ASC;","[('California 17', '`Bob Mathias Redistricted from the 18th district`', '`18th district`', 1966.0, 'Lost re-election Democratic gain', '`John Hans Krebs`', '`D`', 51.9, '`Bob Mathias`', '`R`', 48.1, 3.799999999999997, 'Narrow<=5%', 'Turnover'), ('California 12', '`Pete McCloskey Redistricted from the 17th district`', '`17th district`', 1967.0, 'Re-elected', '`Pete McCloskey`', '`R`', 69.1, '`Gary G. Gillmor`', '`D`', 30.9, 38.199999999999996, None, None), ('California 9', '`Pete Stark Redistricted from the 8th district`', '`8th district`', 1972.0, 'Re-elected', '`Pete Stark`', '`D`', 70.6, '`Edson Adams`', '`R`', 29.4, 41.199999999999996, None, None), ('California 23', '`Thomas M. Rees Redistricted from the 26th district`', '`26th district`', 1965.0, 'Re-elected', '`Thomas M. Rees`', '`D`', 71.5, '`Jack E. Roberts`', '`R`', 28.5, 43.0, None, None), ('California 3', '`John E. Moss`', None, 1952.0, 'Re-elected', '`John E. Moss`', '`D`', 72.3, '`Ivaldo Lenci`', '`R`', 27.7, 44.599999999999994, None, None), ('California 10', '`Don Edwards Redistricted from the 9th district`', '`9th district`', 1962.0, 'Re-elected', '`Don Edwards`', '`D`', 77.0, '`John M. Enright`', '`R`', 23.0, 54.0, None, None), ('California 4', '`Robert L. Leggett`', None, 1962.0, 'Re-elected', '`Robert L. Leggett`', '`D`', None, None, None, None, None, 'Unopposed', None)]",m_1764880613560_cfa8af88_1341690-5,"I'm detail‑oriented for scene building, so I'll request parsed candidate names, parties and numeric percentages but phrase it in plain language. The SQL parses the Candidates string to extract Candidate1 and Candidate2 names, parties, numeric percents (NULL for Unopposed), and computes the absolute margin. Those pieces map to District, Incumbent, Party, Result and the parsed candidate fields in the schema. Draft question: ask to pull verbatim incumbent and parsed candidate1/2 names, parties, their percents (or null for unopposed), and the margin between them for every district. This exactly reflects the query's output which parses candidates, handles Unopposed, and computes margins.",persona,"An alternate-history novelist and electoral cartographer who reconstructs 1970s California congressional terrain to seed plot twists where redistricting and narrow margins change history. Goals: Identify districts affected by redistricting and the original districts incumbents came from to create believable character backstories and territorial grievances. Find the closest, most dramatic races (smallest vote-margin) and party turnovers to use as pivotal plot events. Extract candidate names and vote shares (and spot unopposed races) to populate dialogue, campaign flyers, and realistic election aftermath scenes. Example Queries: SELECT District, Incumbent, Party, `First elected`, Result, Candidates
FROM table_1_1341690_5
WHERE Incumbent LIKE '%Redistricted%'; /* Find contested races, extract first two vote percentages and compute margin (BigQuery-style) */
SELECT District, Incumbent,
  CAST(REGEXP_EXTRACT_ALL(Candidates, r'([0-9]+\.[0-9]+)%')[OFFSET(0)] AS FLOAT64) AS pct1,
  CAST(REGEXP_EXTRACT_ALL(Candidates, r'([0-9]+\.[0-9]+)%')[OFFSET(1)] AS FLOAT64) AS pct2,
  ABS(CAST(REGEXP_EXTRACT_ALL(Candidates, r'([0-9]+\.[0-9]+)%')[OFFSET(0)] AS FLOAT64) - CAST(REGEXP_EXTRACT_ALL(Candidates, r'([0-9]+\.[0-9]+)%')[OFFSET(1)] AS FLOAT64)) AS margin
FROM table_1_1341690_5
WHERE Candidates NOT LIKE '%Unopposed%'
ORDER BY margin ASC; /* Find districts with incumbent losses or party gains to locate turning points */
SELECT District, Incumbent, Party, Result, Candidates
FROM table_1_1341690_5
WHERE Result LIKE '%Lost%'
   OR Result LIKE '%gain%';",N/A,remove_column,
"What are the Party-level aggregates: Total count of records, Avg Tenure (the average of 1974 minus First elected rounded to one decimal), Max Tenure (maximum of 1974 minus First elected) and Min Tenure (minimum of 1974 minus First elected), grouped by Party, ordered by Total descending and limited to the top 10 Parties?","
SELECT `Party`, COUNT(*) `Total`, ROUND(AVG(1974 - `First elected`),1) `Avg Tenure`, MAX(1974 - `First elected`) `Max Tenure`, MIN(1974 - `First elected`) `Min Tenure`
FROM `table_m_1764880628284_86b8dbb8_1341690_9`
WHERE 1=1
GROUP BY `Party`
ORDER BY `Total` DESC
LIMIT 10;
","
SELECT col2, COUNT(*) `Total`, ROUND(AVG(1974 - col3),1) `Avg Tenure`, MAX(1974 - col3) `Max Tenure`, MIN(1974 - col3) `Min Tenure`
FROM `table_m_1764880628284_86b8dbb8_1341690_9`
WHERE 1=1
GROUP BY col2
ORDER BY `Total` DESC
LIMIT 10;
","[('Democratic', 6, 17.7, 34.0, 2.0), ('Republican', 2, 3.0, 4.0, 2.0)]",m_1764880628284_86b8dbb8_1341690-9,"Parse the SQL intent: aggregate by Party to get count, rounded average tenure (based on 1974 - First elected), and min/max tenure, then order by count descending and limit to 10. Map schema semantics: Party is the party column and First elected provides the year to compute tenure. Draft the question: request these aggregates per Party with rounding of the average to one decimal and ordering/limit specified. Validate: ensure mention of Party, Total, ROUND(AVG(1974 - First elected),1) as Avg Tenure, MAX and MIN of (1974 - First elected), GROUP BY Party, ORDER BY Total DESC, LIMIT 10.",reserved,8,N/A,split_column,
Which party had the longest-serving unopposed incumbents?,unanswerable,unanswerable,,m_1764880656118_d09bcc2b_1341707-20,"STEP 1: Parse the SQL intent: compute per-Party and overall ('ALL') summaries including total seats, count of unopposed seats (Candidates LIKE '%Unopposed%'), average tenure for unopposed incumbents (1972 - First elected) and for opposed incumbents, and list unopposed incumbents. STEP 2: Determine ambiguity type: scope/aggregation ambiguity fits best because the query produces averages for unopposed incumbents per party (and an overall row), while a natural phrasing about the ""longest-serving"" or ""most"" could refer either to averages, to single individuals, or to the overall aggregate. STEP 3: Draft the question: ""Which party had the longest-serving unopposed incumbents?"" STEP 4: Explain ambiguity: the SQL interprets this as average tenure of unopposed incumbents per party (avg_tenure_unopposed) and also includes an overall row; alternatively the question could mean the single longest-serving unopposed incumbent by party, or ask which party(s) contain any very long-serving unopposed incumbents, or ask for the overall longest-serving unopposed incumbent across all parties.",persona,"Political science researcher specializing in incumbency and electoral competition, examining House races in the 1972 elections to understand patterns of unopposed contests and long-tenured representatives in Louisiana. Goals: Identify which incumbents ran unopposed in Louisiana's 1972 House races and whether unopposed races cluster by party or district. Measure incumbents' tenure (years in office) to analyze relationships between length of service and likelihood of running unopposed. Produce summary statistics by party (e.g., count of unopposed races) to support a paper on incumbency advantage. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1341707_20
WHERE Candidates LIKE '%Unopposed%'; SELECT Incumbent, District, Party, (1972 - ""First elected"") AS tenure_years
FROM table_1_1341707_20
ORDER BY tenure_years DESC; SELECT Party, COUNT(*) AS unopposed_count
FROM table_1_1341707_20
WHERE Candidates LIKE '%Unopposed%'
GROUP BY Party
ORDER BY unopposed_count DESC;",N/A,remove_column,"type: Scope/aggregation ambiguity | explanation: In the SQL this is resolved as the party-level average tenure for unopposed incumbents (avg_tenure_unopposed, plus an overall 'ALL' row). However the question could instead ask for the single longest-serving unopposed individual (not an average), or for which parties have any long-serving unopposed incumbents, or for the overall longest-serving unopposed incumbent across all parties."
"Provide District, Incumbent, Party, First elected, Result, and Candidates for entries where First elected is between 1950 and 1966 inclusive, and additionally compute Incumbent_pct by taking the substring from Candidates after the first ')' up to the '%' character and converting that to a number; also return Unopposed when Candidates has no '%' and return Safe when the computed Incumbent_pct is >= 60.","
SELECT `District`, `Incumbent`, `Party`, `First elected`, `Result`, `Candidates`,
(REPLACE(TRIM(SUBSTR(`Candidates`, INSTR(`Candidates`,')')+2, INSTR(`Candidates`,'%') - INSTR(`Candidates`,')') -1)),'%','') + 0.0) `Incumbent_pct`,
(INSTR(`Candidates`,'%') = 0) `Unopposed`,
((REPLACE(TRIM(SUBSTR(`Candidates`, INSTR(`Candidates`,')')+2, INSTR(`Candidates`,'%') - INSTR(`Candidates`,')') -1)),'%','') + 0.0) >= 60) `Safe`
FROM `table_m_1764880669790_7d3129e2_1341718_36`
WHERE `First elected` >= 1950 AND `First elected` <= 1966;
","
SELECT col0, col1, col2, col3, col4, col5,
(REPLACE(TRIM(SUBSTR(col5, INSTR(col5,')')+2, INSTR(col5,'%') - INSTR(col5,')') -1)),'%','') + 0.0) `Incumbent_pct`,
(INSTR(col5,'%') = 0) `Unopposed`,
((REPLACE(TRIM(SUBSTR(col5, INSTR(col5,')')+2, INSTR(col5,'%') - INSTR(col5,')') -1)),'%','') + 0.0) >= 60) `Safe`
FROM `table_m_1764880669790_7d3129e2_1341718_36`
WHERE col3 >= 1950 AND col3 <= 1966;
","[('Ohio 5', 'Del Latta', 'Republican', 1958.0, 'Re-elected', 'Del Latta (R) 71.1% Carl G. Sherer (D) 28.9%', 71.1, 0, 1), ('Ohio 6', 'Bill Harsha', 'Republican', 1960.0, 'Re-elected', 'Bill Harsha (R) 67.8% Raymond H. Stevens (D) 32.2%', 67.8, 0, 1), ('Ohio 8', 'Jackson Edward Betts', 'Republican', 1950.0, 'Re-elected', 'Jackson Edward Betts (R) Unopposed', 0.0, 1, 0), ('Ohio 10', 'Clarence E. Miller', 'Republican', 1966.0, 'Re-elected', 'Clarence E. Miller (R) 66.5% Doug Arnett (D) 33.5%', 66.5, 0, 1), ('Ohio 11', 'J. William Stanton', 'Republican', 1964.0, 'Re-elected', 'J. William Stanton (R) 68.2% Ralph Rudd (D) 31.8%', 68.2, 0, 1), ('Ohio 16', 'Frank T. Bow', 'Republican', 1950.0, 'Re-elected', 'Frank T. Bow (R) 56.2% Virgil L. Musser (D) 43.8%', 56.2, 0, 0)]",m_1764880669790_7d3129e2_1341718-36,"1) Parse: the SQL returns the same base columns plus an extracted incumbent percent, a boolean for absence of '%' (unopposed), and a boolean for percent >= 60, restricted to First elected in 1950–1966. 2) Map: map extraction to Candidates field and booleans to presence of '%' and numeric threshold. 3) Draft: ask for those columns and computed fields with clear extraction instructions. 4) Validate: confirm the question specifies substring after ')' up to '%' and the inclusive year range.",reserved,4,N/A,add_column,
Which incumbents were featured and competitive in the 1970 House races?,"
WITH `base` AS (
  SELECT `District`, `First elected`, `Result`, `Candidates`, (1970 - `First elected`) AS `YearsInOffice`, instr(`Candidates`, ') ') AS `pos_paren`, `IncumbentWithParty` FROM `table_m_1764880678356_233f5599_1341718_44`
)
SELECT
  `District`,
  `IncumbentWithParty`,
  `IncumbentWithParty`,
  `YearsInOffice`,
  CASE WHEN `Candidates` LIKE '%Unopposed%' THEN '`Unopposed`' ELSE '`Contested`' END AS `Status`,
  CASE WHEN `First elected` <= 1950 THEN 1 ELSE 0 END AS `FeaturedCandidate`,
  CASE
    WHEN `Candidates` NOT LIKE '%Unopposed%' THEN
      CAST(
        substr(
          `Candidates`,
          `pos_paren` + 2,
          instr(substr(`Candidates`, `pos_paren` + 2), '%') - 1
        ) AS FLOAT
      )
    ELSE NULL
  END AS `LeadingPct`,
  CASE
    WHEN `Candidates` NOT LIKE '%Unopposed%' AND
         CAST(
           substr(
             `Candidates`,
             `pos_paren` + 2,
             instr(substr(`Candidates`, `pos_paren` + 2), '%') - 1
           ) AS FLOAT
         ) < 60 THEN '`Competitive (<60%)`'
    ELSE NULL
  END AS `CompetitiveFlag`,
  `Candidates`
FROM `base`
ORDER BY `FeaturedCandidate` DESC, `YearsInOffice` DESC, `Status` DESC, `LeadingPct` ASC;
","
WITH `base` AS (
  SELECT col0, col1, col2, col3, (1970 - col1) AS `YearsInOffice`, instr(col3, ') ') AS `pos_paren`, col4 FROM `table_m_1764880678356_233f5599_1341718_44`
)
SELECT
  col0,
  col4,
  col4,
  `YearsInOffice`,
  CASE WHEN col3 LIKE '%Unopposed%' THEN '`Unopposed`' ELSE '`Contested`' END AS `Status`,
  CASE WHEN col1 <= 1950 THEN 1 ELSE 0 END AS `FeaturedCandidate`,
  CASE
    WHEN col3 NOT LIKE '%Unopposed%' THEN
      CAST(
        substr(
          col3,
          `pos_paren` + 2,
          instr(substr(col3, `pos_paren` + 2), '%') - 1
        ) AS FLOAT
      )
    ELSE NULL
  END AS `LeadingPct`,
  CASE
    WHEN col3 NOT LIKE '%Unopposed%' AND
         CAST(
           substr(
             col3,
             `pos_paren` + 2,
             instr(substr(col3, `pos_paren` + 2), '%') - 1
           ) AS FLOAT
         ) < 60 THEN '`Competitive (<60%)`'
    ELSE NULL
  END AS `CompetitiveFlag`,
  col3
FROM `base`
ORDER BY `FeaturedCandidate` DESC, `YearsInOffice` DESC, `Status` DESC, `LeadingPct` ASC;
","[('Texas 1', 'Wright Patman, Democratic', 'Wright Patman, Democratic', 42.0, '`Contested`', 1, 78.5, None, 'Wright Patman (D) 78.5% James Hogan (R) 21.5%'), ('Texas 19', 'George H. Mahon, Democratic', 'George H. Mahon, Democratic', 36.0, '`Unopposed`', 1, None, None, 'George H. Mahon (D) Unopposed'), ('Texas 11', 'William R. Poage, Democratic', 'William R. Poage, Democratic', 34.0, '`Unopposed`', 1, None, None, 'William R. Poage (D) Unopposed'), ('Texas 21', 'O. C. Fisher, Democratic', 'O. C. Fisher, Democratic', 28.0, '`Contested`', 1, 61.4, None, 'O. C. Fisher (D) 61.4% Richard Gill (R) 38.6%'), ('Texas 6', 'Olin E. Teague, Democratic', 'Olin E. Teague, Democratic', 24.0, '`Unopposed`', 1, None, None, 'Olin E. Teague (D) Unopposed'), ('Texas 17', 'Omar Burleson, Democratic', 'Omar Burleson, Democratic', 24.0, '`Unopposed`', 1, None, None, 'Omar Burleson (D) Unopposed'), ('Texas 2', 'John Dowdy, Democratic', 'John Dowdy, Democratic', 18.0, '`Unopposed`', 0, None, None, 'John Dowdy (D) Unopposed'), ('Texas 9', 'Jack Brooks, Democratic', 'Jack Brooks, Democratic', 18.0, '`Contested`', 0, 64.5, None, 'Jack Brooks (D) 64.5% Henry C. Pressler (D) 35.5%'), ('Texas 12', 'Jim Wright, Democratic', 'Jim Wright, Democratic', 16.0, '`Unopposed`', 0, None, None, 'Jim Wright (D) Unopposed'), ('Texas 14', 'John Andrew Young, Democratic', 'John Andrew Young, Democratic', 14.0, '`Unopposed`', 0, None, None, 'John Andrew Young (D) Unopposed'), ('Texas 22', 'Robert R. Casey, Democratic', 'Robert R. Casey, Democratic', 12.0, '`Contested`', 0, 55.6, '`Competitive (<60%)`', 'Robert R. Casey (D) 55.6% Arthur Busch (R) 44.4%'), ('Texas 20', 'Henry B. Gonzalez, Democratic', 'Henry B. Gonzalez, Democratic', 9.0, '`Unopposed`', 0, None, None, 'Henry B. Gonzalez (D) Unopposed'), ('Texas 4', 'Ray Roberts, Democratic', 'Ray Roberts, Democratic', 8.0, '`Unopposed`', 0, None, None, 'Ray Roberts (D) Unopposed'), ('Texas 10', 'J. J. Pickle, Democratic', 'J. J. Pickle, Democratic', 7.0, '`Unopposed`', 0, None, None, 'J. J. Pickle (D) Unopposed'), ('Texas 5', 'Earle Cabell, Democratic', 'Earle Cabell, Democratic', 6.0, '`Contested`', 0, 59.7, '`Competitive (<60%)`', 'Earle Cabell (D) 59.7% Frank Crowley (R) 40.3%'), ('Texas 8', 'Robert C. Eckhardt, Democratic', 'Robert C. Eckhardt, Democratic', 4.0, '`Unopposed`', 0, None, None, 'Robert C. Eckhardt (D) Unopposed'), ('Texas 18', 'Bob Price, Republican', 'Bob Price, Republican', 4.0, '`Unopposed`', 0, None, None, 'Bob Price (R) Unopposed'), ('Texas 3', 'James M. Collins, Republican', 'James M. Collins, Republican', 2.0, '`Contested`', 0, 60.6, None, 'James M. Collins (R) 60.6% John Mead (D) 39.4%')]",m_1764880678356_233f5599_1341718-44,"STEP 1: Parse the SQL intent — it builds YearsInOffice = 1970 - First elected, extracts whether Candidates contains 'Unopposed' (Status), flags FeaturedCandidate when First elected <= 1950, parses the leading candidate's percentage (LeadingPct) for contested races and marks CompetitiveFlag when LeadingPct < 60; it returns all rows and orders by FeaturedCandidate desc, YearsInOffice desc, Status desc, LeadingPct asc. STEP 2: Choose an ambiguity type — scope ambiguity fits well: the natural language conjunction ""featured and competitive"" can either mean (A) filter to incumbents who are both featured and competitive, or (B) request a list that shows both attributes for every incumbent. This maps well because the SQL computes both flags but does not filter. STEP 3: Draft the question — ""Which incumbents were featured and competitive in the 1970 House races?"" STEP 4: Explain the ambiguity relative to the query — the SQL produces flags and ordering for all incumbents (matching interpretation B: list everyone and indicate who is featured and who is competitive), whereas the NL phrasing can also be read as a stricter request (interpretation A) to return only incumbents who satisfy both conditions (FeaturedCandidate = true AND CompetitiveFlag present).",persona,"A theatrical set designer staging an authentic 1970 Texas political drama who needs historically accurate campaign signage, props and background detail for each district. Goals: Identify which districts had unopposed incumbents so generic party signage (no opponent names or vote totals) can be made. Prioritize well-known, long-serving incumbents for featured props and portraits by ranking tenure (to pick visually prominent on-stage figures). Find genuinely competitive races (leading vote share under 60%) to recreate detailed campaign materials showing vote percentages and opponent names. Example Queries: SELECT District, Incumbent, Party FROM table_1_1341718_44 WHERE Candidates LIKE '%Unopposed%'; SELECT District, Incumbent, Party, (1970 - ""First elected"") AS YearsInOffice FROM table_1_1341718_44 WHERE ""First elected"" <= 1950 ORDER BY YearsInOffice DESC; SELECT District, Incumbent, Candidates, CAST(REGEXP_REPLACE(REGEXP_SUBSTR(Candidates, '[0-9]+\.[0-9]+%'), '%', '') AS FLOAT) AS LeadingPct FROM table_1_1341718_44 WHERE Candidates NOT LIKE '%Unopposed%' AND CAST(REGEXP_REPLACE(REGEXP_SUBSTR(Candidates, '[0-9]+\.[0-9]+%'), '%', '') AS FLOAT) < 60 ORDER BY LeadingPct ASC;",N/A,merge_column,"type: Scope ambiguity | explanation: The phrase ""featured and competitive"" can mean either (A) return only incumbents who are both featured (First elected ≤ 1950) and competitive (leading pct < 60), or (B) return the full list of incumbents while showing/marking which ones are featured and which are competitive; the SQL computes both flags for every row (matching B) but does not filter to only those satisfying both (A)."
"Which districts were unopposed, who held them and how long had they served, and how common were unopposed races?","SELECT
  t.`District`,
  t.`Incumbent`,
  t.`First elected`,
  t.`Candidates`,
  (1960 - t.`First elected`) AS `Tenure (years)`,
  (SELECT COUNT(*) FROM `table_m_1764880721034_d330c9ab_1341897_23` WHERE `Candidates` LIKE '%Unopposed%') AS `Total Unopposed Races`,
  (SELECT COUNT(*) FROM `table_m_1764880721034_d330c9ab_1341897_23`) AS `Total Races`,
  ROUND(100.0 * (SELECT COUNT(*) FROM `table_m_1764880721034_d330c9ab_1341897_23` WHERE `Candidates` LIKE '%Unopposed%') / NULLIF((SELECT COUNT(*) FROM `table_m_1764880721034_d330c9ab_1341897_23`), 0), 2) AS `Pct Unopposed Overall`
FROM `table_m_1764880721034_d330c9ab_1341897_23` AS t
WHERE t.`Candidates` LIKE '%Unopposed%'
ORDER BY `Tenure (years)` DESC;","SELECT
  t.col0,
  t.col1,
  t.col2,
  t.col4,
  (1960 - t.col2) AS `Tenure (years)`,
  (SELECT COUNT(*) FROM `table_m_1764880721034_d330c9ab_1341897_23` WHERE col4 LIKE '%Unopposed%') AS `Total Unopposed Races`,
  (SELECT COUNT(*) FROM `table_m_1764880721034_d330c9ab_1341897_23`) AS `Total Races`,
  ROUND(100.0 * (SELECT COUNT(*) FROM `table_m_1764880721034_d330c9ab_1341897_23` WHERE col4 LIKE '%Unopposed%') / NULLIF((SELECT COUNT(*) FROM `table_m_1764880721034_d330c9ab_1341897_23`), 0), 2) AS `Pct Unopposed Overall`
FROM `table_m_1764880721034_d330c9ab_1341897_23` AS t
WHERE t.col4 LIKE '%Unopposed%'
ORDER BY `Tenure (years)` DESC;","[('Massachusetts 7', 'Thomas J. Lane', 1941.0, 'Thomas J. Lane (D) Unopposed', 19.0, 4, 6, 66.67), ('Massachusetts 3', 'Philip Philbin', 1942.0, 'Philip Philbin (D) Unopposed', 18.0, 4, 6, 66.67), ('Massachusetts 2', 'Edward Boland', 1952.0, 'Edward Boland (D) Unopposed', 8.0, 4, 6, 66.67), ('Massachusetts 11', ""Tip O'Neill"", 1952.0, ""Tip O'Neill (D) Unopposed"", 8.0, 4, 6, 66.67)]",m_1764880721034_d330c9ab_1341897-23,"STEP 1: Parse the SQL intent — return only rows where Candidates contains 'Unopposed', showing District, Incumbent, Party, First elected, Candidates, computed Tenure (1960 - First elected), and include aggregate counts and percentages: total unopposed races overall, total races overall, percent unopposed overall, unopposed count by the incumbent's party, total seats by party, and percent unopposed within that party; order results by tenure descending. STEP 2: Choose an ambiguity type — scope ambiguity fits best because the query provides both overall and within-party percentages, so a question asking ""how common"" or ""what percent"" could reasonably refer to either the overall rate or the within-party rate. STEP 3: Draft the question — produce an NL question that matches the SQL output but leaves the scope of the percentage unclear. STEP 4: Explain the ambiguity — in the SQL the percent information is explicitly given both overall and within-party, so the question could be answered using either metric; an alternative interpretation might ask only for the overall percentage, only for the within-party percentage (per party), or even expect a per-district/localized rate in a different query.",persona,"```json
{
  ""short_persona_description"": ""A political historian specializing in mid-20th century U.S. congressional elections who uses primary election tables to study incumbency, party strength, and electoral competitiveness in 1960. They query this database to identify patterns in unopposed races, long-tenured members, and party distribution within Massachusetts."",
  ""goals"": [
    ""Identify which Massachusetts House incumbents ran unopposed in 1960 and document instances of uncontested races. Goals:  Example Queries: ",N/A,remove_column,"type: Scope ambiguity | explanation: The phrase ""how common were unopposed races"" is ambiguous: the SQL provides both an overall percent unopposed and a percent unopposed within each party, so the question could mean the overall rate across all races or the rate within the incumbent's party (or, in another interpretation, a per-district/localized measure). The original query supplies both metrics; a different query might return only one of those interpretations."
"Provide, for each Party that has at least one seat, the Party, TotalSeats (total rows), UnopposedSeats (number of rows where Candidates includes 'Unopposed'), ContestedSeats (TotalSeats minus UnopposedSeats), AvgTenure calculated as ROUND(AVG(1960 - First elected), 1), and an IncumbentList formed by concatenating '`Incumbent` (`District`)' values separated by '; '; present the results ordered by Party?",,,[],m_1764880732249_d9475813_1341897-45,"1) Parse intent: compute per-Party totals, unopposed vs contested breakdown, average years in office since First elected using 1960, and a quoted incumbent-with-district list; 2) Map schema: fields Party, Candidates, First elected, Incumbent, District are used exactly; 3) Draft: ask explicitly for TotalSeats, UnopposedSeats (Candidates contains 'Unopposed'), ContestedSeats (difference), AvgTenure rounded to one decimal, and GROUP_CONCAT of '`Incumbent` (`District`)' separated by '; '; 4) Validate: ensure the question restricts to parties with at least one seat and mentions ordering by Party.",reserved,10,N/A,merge_column,
"Give me a combined 1958 summary: counts of unopposed incumbents by party, a list of incumbents who lost (with district/party/first-elected), and any close races (≤5% margin) with candidate percentages and margins.",unanswerable,unanswerable,,m_1764880755267_8d9ea47b_1341930-5,"As a researcher I might want a single summary that covers unopposed counts, incumbents who were unseated, and close races for cross-comparison. The SQL unions three result sets: unopposed-by-party counts, incumbents who lost, and close races (<=5% margin). The table provides the needed fields (Party, District, Incumbent, First elected, Result, Candidates) and the query extracts percentages from Candidates where present. Draft: ask for a combined report showing unopposed counts by party, the list of incumbents who lost, and any close races (≤5% margin). Validate: this mirrors the full UNION ALL query that returns all three metrics together.",persona,"Political science researcher focusing on incumbency and electoral competitiveness in mid-20th century U.S. House races, using this 1958 election table to measure patterns of unopposed races, incumbents' success rates, and close contests. Goals: Quantify how many incumbents ran unopposed in 1958 and how that breaks down by party. Identify incumbents who lost re-election (or narrowly held) and examine their tenure (first-elected year) to study incumbency vulnerability. Find competitively close districts (small vote-margin contests) to analyze regional or party patterns of electoral competitiveness. Example Queries: /* Count unopposed seats by party */
SELECT ""Party"", COUNT(*) AS unopposed_seats
FROM table_1_1341930_5
WHERE ""Candidates"" LIKE '%Unopposed%'
GROUP BY ""Party""
ORDER BY unopposed_seats DESC; /* List incumbents who lost re-election (include vote details where available) */
SELECT ""District"", ""Incumbent"", ""Party"", ""First elected"", ""Result"", ""Candidates""
FROM table_1_1341930_5
WHERE ""Result"" LIKE '%Lost%'
ORDER BY ""First elected""; /* Identify close races by extracting the top two percentage values from the Candidates field (PostgreSQL example using regexp_matches) */
WITH pct AS (
  SELECT *,
    (regexp_matches(""Candidates"", '([0-9]+\.[0-9]+)%'))[1]::numeric AS pct1,
    (regexp_matches(""Candidates"", '([0-9]+\.[0-9]+)%'))[2]::numeric AS pct2
  FROM table_1_1341930_5
  WHERE ""Candidates"" ~ '[0-9]+\.[0-9]+%'
)
SELECT ""District"", ""Incumbent"", ""Party"", pct1, pct2, ABS(pct1 - pct2) AS margin
FROM pct
WHERE pct1 IS NOT NULL AND pct2 IS NOT NULL AND ABS(pct1 - pct2) <= 5
ORDER BY margin ASC;",N/A,remove_column,
"Which record contains District = 5, Incumbent = 5, Party = 5, First elected = 1914, Result = 2, Candidates = '`√ Carl Vinson (D) Unopposed`; `√ Phillip M. Landrum (D) Unopposed`', the fields '`Georgia 6`' and '`Georgia 9`', and Action = 'Actionable: prioritize contested races: `Georgia 2`, `Georgia 3`, `Georgia 4`'?","
SELECT 5 AS `District`, 5 AS `Incumbent`, 5 AS `Party`, 1914 AS `First elected`, 2 AS `Result`, '`√ Carl Vinson (D) Unopposed`; `√ Phillip M. Landrum (D) Unopposed`' AS `Candidates`, '`Georgia 6`' AS `Georgia 6`, '`Georgia 9`' AS `Georgia 9`, '`Actionable: prioritize contested races: `Georgia 2`, `Georgia 3`, `Georgia 4`' AS `Action`;
","
SELECT 5 AS `District`, 5 AS col0, 5 AS col1, 1914 AS col2, 2 AS col3, '`√ Carl Vinson (D) Unopposed`; `√ Phillip M. Landrum (D) Unopposed`' AS col4, '`Georgia 6`' AS `Georgia 6`, '`Georgia 9`' AS `Georgia 9`, '`Actionable: prioritize contested races: `Georgia 2`, `Georgia 3`, `Georgia 4`' AS `Action`;
","[(5, 5, 5, 1914, 2, '`√ Carl Vinson (D) Unopposed`; `√ Phillip M. Landrum (D) Unopposed`', '`Georgia 6`', '`Georgia 9`', '`Actionable: prioritize contested races: `Georgia 2`, `Georgia 3`, `Georgia 4`')]",m_1764880770864_bc643960_1341973-11,"Parse: the query constructs a single row of constants: three 5s, 1914, 2, two unopposed candidate strings, two Georgia labels, and an Action note listing Georgia 2/3/4. Map: map those constants to columns District, Incumbent, Party, First elected, Result, Candidates, Georgia 6, Georgia 9 and Action. Draft: ask for the record containing exactly those values and strings. Validate: check that every column and exact string from the query is present in the question.",reserved,10,N/A,split_column,
"Among entries with First elected >= 1914, which Party has the highest Pre-1950 (%) and for that Party return Party, Total Seats (the count of rows), Earliest First elected (the minimum First elected), Pre-1950 (%) defined as 100.0 * (number of rows with First elected < 1950) / (total rows) rounded to one decimal, District List as a semicolon-separated list of District values, and the columns Georgia 1, Georgia 4, Georgia 6 each set to 0?",unanswerable,unanswerable,,m_1764880781805_46c6b181_1342013-10,"1) Parse intent: find the party (grouped) with the highest percent of members first elected before 1950 among those first elected >=1914, returning several aggregated columns. 2) Map schema: use Party, COUNT(*) as Total Seats, MIN(First elected) as Earliest First elected, percentage = ROUND(100.0*SUM(First elected<1950)/COUNT(*),1), GROUP_CONCAT(District,'; ') as District List, and literal zeros for Georgia 1, Georgia 4, Georgia 6. 3) Draft question: ask for the top party by that percentage and request all specified outputs. 4) Validate: includes WHERE First elected >=1914, grouping by Party, ordering by Pre-1950 (%) desc, limit 1, and all columns/calculations requested.",reserved,8,N/A,remove_column,
"For each Party, report the COUNT(*) and the Unopposed_Count defined as the number of rows where Candidates contains 'Unopposed', considering only rows where Candidates contains '(' OR (Candidates contains '%' AND First elected < 1950), grouping results by Party, ordering by COUNT(*) in ascending order, and returning at most 5 rows?",unanswerable,unanswerable,,m_1764880793406_42a06701_1342013-20,"1) The intent is to list parties with their row counts and number of unopposed entries under a compound Candidates/First elected filter, grouped and sorted with a row limit. 2) Translate columns and expressions: Party, COUNT(*), Unopposed_Count = count of Candidates containing 'Unopposed'; filter = instr(Candidates,'(')>0 OR (instr(Candidates,'%')>0 AND First elected < 1950). 3) Compose a question that asks for Party, the count, and the Unopposed_Count for rows matching that exact condition, grouped by Party, ordered by count ascending, limit 5. 4) Confirm the question mentions all calculations, the precise logical grouping of the WHERE clause, GROUP BY, ORDER BY, and LIMIT.",reserved,15,N/A,merge_column,
"Compute a 'defense value' for each 1954 California district as 1.5 points per year in office (1954 − first elected) plus 40 if unopposed, otherwise add half of (100 − the vote margin), and return district, incumbent, party, first‑elected year, years in office, incumbent and challenger percentages, margin, defense value, and candidates, ordered by defense value desc then margin asc.",,,[],m_1764880806903_81602640_1342013-5,"I'm balancing card difficulty by a numeric 'defense' rating combining tenure and vote safety, and I'm comfortable describing the formula in plain terms. The query computes Years in Office as 1954 minus First elected, then Defense Value = (years * 1.5) + (40 if unopposed, else 0.5 * (100 − margin)), and orders by that value desc then margin asc. Schema mapping: years come from First elected, 'Unopposed' is detected in Candidates text, and percentages are parsed from Candidates to compute margin. Draft question: compute and return each 1954 California district's defense value using 1.5 points per year in office plus 40 if unopposed (otherwise add half of 100 minus the vote margin), and show district, incumbent, party, first‑elected year, years in office, incumbent and challenger percentages, margin, defense value, and candidates, ordered by defense value desc then margin asc. This validates against the query since it requests the exact computation, fields and ordering used.",persona,"A retro board-game designer who builds a historically accurate 1954 California congressional campaign game and needs to balance district cards by incumbent strength and competitiveness. Goals: Identify unopposed districts and safe seats to create easy 'hold' tiles for players. Find narrowly decided (swing) districts to serve as high-value contested spaces with special mechanics. Rate incumbents' ‘defense’ value using tenure (years in office) and recent vote margins to balance gameplay difficulty and card abilities. Example Queries: /* 1) Find all unopposed races to mark as automatic holds in the game */
SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1342013_5
WHERE Candidates LIKE '%Unopposed%'; /* 2) Extract reported percentages and list close (swing) contests where vote margin < 10% */
SELECT District, Incumbent, Party,
  CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 1) AS REAL)     AS IncumbentPct,
  CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 2) AS REAL)     AS ChallengerPct,
  ABS(CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 1) AS REAL) - CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 2) AS REAL)) AS Margin
FROM table_1_1342013_5
WHERE Candidates NOT LIKE '%Unopposed%'
HAVING Margin < 10
ORDER BY Margin ASC; /* 3) Produce district cards showing years in office (1954 baseline) and a difficulty tag for game balancing */
SELECT District, Incumbent, Party, ""First elected"",
  (1954 - ""First elected"") AS YearsInOffice,
  CASE
    WHEN Candidates LIKE '%Unopposed%' THEN 'Safe - No opposition'
    WHEN ABS(CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 1) AS REAL) - CAST(REGEXP_SUBSTR(Candidates, '([0-9]+\.[0-9]+)%', 1, 2) AS REAL)) < 10 THEN 'Contested - Swing'
    ELSE 'Safe'
  END AS Difficulty,
  Candidates
FROM table_1_1342013_5
ORDER BY YearsInOffice DESC, Difficulty DESC;",N/A,merge_column,
"Give me a prioritized list of channels that are either the standard non-overlap ones (1, 6, 11), channel 6 or overlap 6, or have center frequency ≥ 2.45 GHz, and include each channel’s center frequency, channel width, overlap list and a role tag.",unanswerable,unanswerable,,m_1764880826917_32d5162d_13420417-1,"I’d want a single prioritized view that calls out standard non-overlap channels, channels that overlap 6, and high‑band channels so I can make quick decisions. The query builds role tags for channels in (1,6,11), channels equal to or overlapping 6, and channels with center_GHz >= 2.45, then returns only rows with at least one role and orders them by those priorities. The relevant columns are Channel, Center Frequency, Channel Width, Overlaps Channels and the computed Roles. Draft question: give me a prioritized list of channels that are (a) standard non-overlap (1,6,11), (b) channel 6 or overlap 6, or (c) have center freq ≥ 2.45 GHz, and show center freq, width, overlap list and a role tag for each. This mirrors the SQL selection, role tagging and ordering.",persona,"Enterprise Wi-Fi network engineer responsible for planning and optimizing 2.4 GHz deployments across multi-floor office sites; uses this channel/frequency table to assign channels and avoid co-channel and adjacent-channel interference. Goals: Identify standard non-overlapping channels to use for AP placement (commonly 1, 6, 11) and confirm their center frequencies and occupied bandwidth. Determine which channels overlap a given channel (e.g., channel 6) so adjacent APs can be assigned non-overlapping channels. Filter channels by frequency range (e.g., high end of the 2.4 GHz band) to plan channel reuse and avoid interference with known local devices. Example Queries: /* Get reference info for the three commonly used non-overlapping channels */
SELECT Channel, ""Center Frequency"", ""Channel Width"", ""Overlaps Channels""
FROM table_1_13420417_1
WHERE Channel IN (1, 6, 11); /* Find rows that explicitly mention channel 6 in the Overlaps Channels column (simple text search) or the channel itself */
SELECT Channel, ""Overlaps Channels""
FROM table_1_13420417_1
WHERE Channel = 6
   OR ""Overlaps Channels"" LIKE '%6%'
/* Note: this searches text (ranges and lists); for precise range parsing additional string parsing is needed */; /* Select channels in the upper part of the 2.4 GHz band (numeric comparison by stripping ' GHz') */
SELECT Channel,
       CAST(REPLACE(""Center Frequency"", ' GHz', '') AS REAL) AS center_GHz,
       ""Channel Width""
FROM table_1_13420417_1
WHERE CAST(REPLACE(""Center Frequency"", ' GHz', '') AS REAL) >= 2.45
ORDER BY center_GHz;",N/A,remove_column,
"Which rows (showing District, Incumbent, Party, First elected, Result and Candidates) return the first candidate's percentage (the digits between the first ')' and the first '%'), the second candidate's percentage (the digits between the second ')' and the second '%'), and the absolute difference of these two numeric percentages (abs(first percentage - second percentage)) for cases where that absolute difference is <= 1.0?","
SELECT `District`, `Incumbent`, `Party`, `First elected`, `Result`, `Candidates`,
replace(substr(`Candidates`, instr(`Candidates`, ')')+2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 1), '%', '') + 0.0,
replace(substr(substr(`Candidates`, instr(`Candidates`, '%')+1), instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')')+2, instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')') - 1), '%', '') + 0.0,
abs(
(replace(substr(`Candidates`, instr(`Candidates`, ')')+2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 1), '%', '') + 0.0)
-
(replace(substr(substr(`Candidates`, instr(`Candidates`, '%')+1), instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')')+2, instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')') - 1), '%', '') + 0.0)
)
FROM `table_m_1764880833813_ff31efd9_1342149_38`
WHERE `Incumbent` LIKE `Incumbent` AND abs(
(replace(substr(`Candidates`, instr(`Candidates`, ')')+2, instr(`Candidates`, '%') - instr(`Candidates`, ')') - 1), '%', '') + 0.0)
-
(replace(substr(substr(`Candidates`, instr(`Candidates`, '%')+1), instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')')+2, instr(substr(`Candidates`, instr(`Candidates`, '%')+1), '%') - instr(substr(`Candidates`, instr(`Candidates`, '%')+1), ')') - 1), '%', '') + 0.0)
) <= 1.0;
","
SELECT col0, col1, col2, col3, col4, col5,
replace(substr(col5, instr(col5, ')')+2, instr(col5, '%') - instr(col5, ')') - 1), '%', '') + 0.0,
replace(substr(substr(col5, instr(col5, '%')+1), instr(substr(col5, instr(col5, '%')+1), ')')+2, instr(substr(col5, instr(col5, '%')+1), '%') - instr(substr(col5, instr(col5, '%')+1), ')') - 1), '%', '') + 0.0,
abs(
(replace(substr(col5, instr(col5, ')')+2, instr(col5, '%') - instr(col5, ')') - 1), '%', '') + 0.0)
-
(replace(substr(substr(col5, instr(col5, '%')+1), instr(substr(col5, instr(col5, '%')+1), ')')+2, instr(substr(col5, instr(col5, '%')+1), '%') - instr(substr(col5, instr(col5, '%')+1), ')') - 1), '%', '') + 0.0)
)
FROM `table_m_1764880833813_ff31efd9_1342149_38`
WHERE col1 LIKE col1 AND abs(
(replace(substr(col5, instr(col5, ')')+2, instr(col5, '%') - instr(col5, ')') - 1), '%', '') + 0.0)
-
(replace(substr(substr(col5, instr(col5, '%')+1), instr(substr(col5, instr(col5, '%')+1), ')')+2, instr(substr(col5, instr(col5, '%')+1), '%') - instr(substr(col5, instr(col5, '%')+1), ')') - 1), '%', '') + 0.0)
) <= 1.0;
","[('Pennsylvania 25', 'Louis E. Graham', 'Republican', 1938.0, 'Re-elected', 'Louis E. Graham (R) 50.4% Frank M. Clark (D) 49.6%', 50.4, 49.6, 0.7999999999999972)]",m_1764880833813_ff31efd9_1342149-38,"1) The intent is to list rows and computed percentage values where the vote percentages of the two candidates differ by no more than 1.0. 2) Map to table columns and the string-to-number extraction of each candidate's percentage from Candidates. 3) Draft a question asking for District, Incumbent, Party, First elected, Result, Candidates, the two extracted percentages, and their absolute difference with the <=1.0 filter. 4) Confirm the question references the exact substring positions (between ')' and '%') and the absolute difference calculation.",reserved,5,N/A,add_column,
Which parties have the highest average incumbent vote share?,"
SELECT `t`.`political_party`, COUNT(*) `Total Seats`,
       SUM(`t`.`Candidates` LIKE '%Unopposed%') `Unopposed Seats`,
       SUM(NOT(`t`.`Candidates` LIKE '%Unopposed%')) `Contested Seats`,
       ROUND(AVG((TRIM(SUBSTR(
         `t`.`Candidates`,
         INSTR(`t`.`Candidates`, '(' || SUBSTR(`t`.`political_party`,1,1) || ')') + 4,
         INSTR(SUBSTR(`t`.`Candidates`, INSTR(`t`.`Candidates`, '(' || SUBSTR(`t`.`political_party`,1,1) || ')') + 4), '%') - 1
       )) + 0.0)),2) `Avg incumbent_name %`
FROM `table_m_1764880880450_4b0ed00e_1342198_6` `t`
WHERE `t`.`political_party` IS NOT NULL AND `t`.`political_party` <> ''
GROUP BY `t`.`political_party`
HAVING `Contested Seats`>0 AND `Unopposed Seats`>=0
ORDER BY `Avg incumbent_name %` DESC
LIMIT 10;
","
SELECT `t`.col2, COUNT(*) `Total Seats`,
       SUM(`t`.col5 LIKE '%Unopposed%') `Unopposed Seats`,
       SUM(NOT(`t`.col5 LIKE '%Unopposed%')) `Contested Seats`,
       ROUND(AVG((TRIM(SUBSTR(
         `t`.col5,
         INSTR(`t`.col5, '(' || SUBSTR(`t`.col2,1,1) || ')') + 4,
         INSTR(SUBSTR(`t`.col5, INSTR(`t`.col5, '(' || SUBSTR(`t`.col2,1,1) || ')') + 4), '%') - 1
       )) + 0.0)),2) `Avg incumbent_name %`
FROM `table_m_1764880880450_4b0ed00e_1342198_6` `t`
WHERE `t`.col2 IS NOT NULL AND `t`.col2 <> ''
GROUP BY `t`.col2
HAVING `Contested Seats`>0 AND `Unopposed Seats`>=0
ORDER BY `Avg incumbent_name %` DESC
LIMIT 10;
","[('Republican', 2, 1, 1, 27.0), ('Democratic', 6, 4, 2, 16.42)]",m_1764880880450_4b0ed00e_1342198-6,"STEP 1: Parse the SQL intent: the query groups rows by Party, counts total seats, counts Unopposed Seats via Candidates LIKE '%Unopposed%', counts Contested Seats as NOT LIKE '%Unopposed%', extracts the incumbent's percentage from the Candidates text (looking for the party initial like '(R)') and computes the average of those percentages per party, filters out empty parties and requires Contested Seats>0, then orders parties by that average descending and returns the top 10. STEP 2: Determine ambiguity type: Scope ambiguity fits well because the phrase “average incumbent percentage” can be read as an average over different scopes (e.g., only contested seats vs. all seats vs. seats with incumbents), and the SQL specifically averages parsed percentages (effectively only where a percent exists) and excludes parties with no contested seats. STEP 3: Draft the question: ""Which parties have the highest average incumbent vote share?"" STEP 4: Explain the ambiguity: the original query interprets this as the mean of incumbents' reported vote percentages parsed from the Candidates text for each party (effectively averaging over contested races and excluding parties with zero contested seats), whereas a reader might instead mean the average across all that party's seats (counting unopposed seats somehow), the average including or excluding certain years/incumbents, or even the single party with the top incumbent rather than a per-party average ranking.",reserved,14,N/A,rename_column,"type: Scope ambiguity | explanation: The SQL treats the average as the mean of parsed incumbent percentages (effectively only where percent values appear — i.e., contested races — and excludes parties with zero contested seats), but the phrase could also mean averaging across all seats including unopposed ones (or treating unopposed seats differently), or could be interpreted as asking for the single top party rather than a per-party average ranking."
"For each Party, what is the total number of seats (count of rows), the number of contested seats (count of rows where the Candidates field does not contain the text 'Unopposed'), and the average winner percentage across those contested races computed by extracting the 6-character substring starting two characters after the first ')' in Candidates, removing the '%' and treating it as a numeric value, then averaging those numbers and rounding to one decimal, considering only entries with First elected between 1900 and 1948 inclusive; group the results by Party, order them by the contested-seat count descending, and return the top 10 parties?",unanswerable,unanswerable,,m_1764880895985_795bf5d6_1342218-43,"1) Parse intent: compute per-party aggregates: total seats, number of contested seats, and average winner percentage parsed from the Candidates text; 2) Map schema: use Party, Candidates, and First elected columns and consider 'Unopposed' presence and percentage substring after the first ')'; 3) Draft: ask for Party, total count, contested count (Candidates does not contain 'Unopposed'), and average of extracted winner percentages rounded to 1 decimal for rows with First elected between 1900 and 1948; 4) Validate: group by Party, order by contested count descending, limit to top 10.",reserved,9,N/A,merge_column,
"Provide a tidy list of Arkansas districts showing District, Incumbent, Party, First elected, Result, and Candidates, include an Uncontested flag for rows with ""Unopposed"", compute incumbent tenure as 1948 minus First elected, label continuity as Re-elected / Retired hold / Hold, and include per-party and total counts of unopposed and retired seats.",unanswerable,unanswerable,,m_1764880907984_59dc8e34_1342218-5,"As a mapmaker I prefer concise ledgers, so my phrasing will be tidy and craft-like but nontechnical. The SQL builds per-row flags and derived labels and also computes windowed sums partitioned by party and overall. It uses the 'Candidates' text to detect 'Unopposed', 'Result' to determine continuity, and 'First elected' to compute tenure against 1948. Draft question: Provide a tidy list of Arkansas districts with those columns, an Uncontested flag, tenure in years, a continuity label, and per-party and total unopposed and retired counts. Validate: The question mirrors the exact columns and derived metrics the query produces without adding extra requirements.",persona,"A political textile cartographer — an artisan who designs historically-accurate quilted maps that encode 1948 House election outcomes into stitch patterns and color blocks. Goals: Identify which Arkansas congressional districts in 1948 were uncontested so I can use a single-color block (no border) for those panels. Map incumbent longevity and party continuity (e.g., first-elected year and whether they were re-elected or seats changed) to decide stitch complexity and pattern repetition. Quantify and compare uncontested seats by party and flag any non-standard results (e.g., 'Retired Democratic hold') to add special embellishments. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Candidates FROM table_1_1342218_5 WHERE Candidates LIKE '%Unopposed%'; SELECT District, Incumbent, Party, ""First elected"", Result FROM table_1_1342218_5 WHERE ""First elected"" < 1940 AND (Result LIKE '%Re-elected%' OR Candidates LIKE '%Unopposed%'); SELECT Party, COUNT(*) AS unopposed_count, SUM(CASE WHEN Result LIKE '%Retired%' THEN 1 ELSE 0 END) AS retired_seats FROM table_1_1342218_5 WHERE Candidates LIKE '%Unopposed%' GROUP BY Party;",N/A,merge_column,
"For each Party among entries with District starting with 'California' and First elected prior to 1950, report the Party, the total count of entries (COUNT(*)), and the Contested Seats value defined as COUNT(*) minus the number of entries whose Candidates include 'Unopposed'; include only parties with COUNT(*) > 0, sort by Contested Seats ascending and return up to 5 rows?",unanswerable,unanswerable,,m_1764880922169_6ca6011f_1342218-6,"1) Parse the SQL intent: group by Party for California districts elected before 1950, count rows per party and calculate contested seats by subtracting unopposed races, then sort and limit. 2) Map schema semantics: District prefix 'California', numeric First elected < 1950, Candidates text contains 'Unopposed' indicates unopposed; output Party, COUNT(*), and Contested Seats. 3) Draft the question. 4) Validate that all SQL elements—filters, aggregation, calculation, having, ordering, and LIMIT—are represented.",reserved,12,N/A,merge_column,
"For each Party, compute Outcome from Result ('Lost re-election Democratic gain' => 'Flip', 'Re-elected' => 'Hold', otherwise 'Other') and report Party, Outcome, the COUNT(*) as Count, and AVG(First elected) as AvgFirstElected, grouping by Party and Outcome, ordered by Count descending and limited to 10 rows.",unanswerable,unanswerable,,m_1764880945814_8d8acc29_1342249-13,"1) The intent is to produce aggregated stats per Party and a CASE-derived Outcome based on Result, count rows and average First elected, then sort and limit. 2) Use Party, Result, and First elected columns to form the outputs and aggregations. 3) Write a question requesting Party, the Outcome mapping ('Lost re-election Democratic gain' -> 'Flip', 'Re-elected' -> 'Hold', else 'Other'), COUNT(*) as Count, and AVG(First elected) as AvgFirstElected, grouped by Party and Outcome. 4) Confirm inclusion of ORDER BY Count DESC and LIMIT 10.",reserved,18,N/A,merge_column,
"Give me every 1944 Louisiana House district with its incumbent and party, the year they were first elected, years in office as of 1944, whether they were unopposed, the defensive strength score (2.5×years in office plus 15 if unopposed), and the party-level counts and percent of unopposed seats.",unanswerable,unanswerable,,m_1764880951771_8cc5f285_1342249-18,"I'm a boardgame designer so I'd talk about 'safe seats' and defensive scores rather than raw SQL, using incumbent, party and unopposed language; I won't assume exact column names. The SQL computes years in office, flags unopposed races, computes a defensive strength, and adds party-level unopposed counts and percentages. It reads District, Incumbent, Party, First elected and Candidates and derives years_in_office, uncontested and defensive_strength, plus SUM/COUNT per Party. Draft the question to request each 1944 Louisiana district with incumbent, party, first-elected year, years in office (to 1944), whether unopposed, the defensive strength (2.5×years +15 if unopposed), and party totals and percent unopposed. This stays within what the query returns and doesn't invent extra fields.",persona,"An alternate-history boardgame designer who models 1944 Louisiana House races to build balanced wartime political scenarios by quantifying 'safe' seats and incumbency strength. Goals: Identify which Louisiana congressional districts in 1944 were uncontested to classify them as 'safe' seats for gameplay. Measure incumbency tenure as of the 1944 election (years since first elected) to assign defensive strength values to each incumbent. Summarize party dominance and the number of unopposed seats by party to calibrate starting conditions and victory point allocation. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1342249_18
WHERE Candidates LIKE '%Unopposed%'; SELECT Incumbent, District, ""First elected"", (1944 - ""First elected"") AS years_in_office
FROM table_1_1342249_18
ORDER BY years_in_office DESC; SELECT Party,
       COUNT(*) AS total_seats,
       SUM(CASE WHEN Candidates LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS unopposed_seats
FROM table_1_1342249_18
GROUP BY Party;",N/A,remove_column,
"For Parties other than 'None (District created)', among rows with Result = 'Re-elected', what is each Party's name, the total seats (COUNT(*) as Total Seats), how many of those seats have Candidates containing the string 'Unopposed' (reported as 'Harry Lane Englebright (R) Unopposed'), and how many Contested Seats there are computed as Total Seats minus that Unopposed count, limited to 10 Parties?","
SELECT DISTINCT `Party`, COUNT(*) `Total Seats`, SUM(INSTR(`Candidates`, 'Unopposed')>0) AS `Harry Lane Englebright (R) Unopposed`, COUNT(*) - SUM(INSTR(`Candidates`, 'Unopposed')>0) `Contested Seats` FROM `table_m_1764880995950_15c0759d_1342256_6` WHERE `Party` != 'None (District created)' AND `Result` = 'Re-elected' GROUP BY `Party` LIMIT 10;
","
SELECT DISTINCT col1, COUNT(*) `Total Seats`, SUM(INSTR(col4, 'Unopposed')>0) AS `Harry Lane Englebright (R) Unopposed`, COUNT(*) - SUM(INSTR(col4, 'Unopposed')>0) `Contested Seats` FROM `table_m_1764880995950_15c0759d_1342256_6` WHERE col1 != 'None (District created)' AND col3 = 'Re-elected' GROUP BY col1 LIMIT 10;
","[('Democratic', 3, 3, 0), ('Republican', 3, 2, 1)]",m_1764880995950_15c0759d_1342256-6,"1) Parse intent: calculate per-Party totals and split unopposed vs contested for re-elected incumbents while excluding created-district placeholder Party. 2) Map schema: use Party and Result filters, detect 'Unopposed' via Candidates text search, compute totals and difference. 3) Draft: request Party, Total Seats, number of 'Unopposed' seats with the given alias, and Contested Seats = Total - Unopposed. 4) Validate: confirm exclusion of Party = 'None (District created)', filter Result = 'Re-elected', group by Party and limit to 10.",reserved,9,N/A,split_column,
"List the top 5 Result categories (ordered by descending Count) for rows where First elected < 1930, and for each Result provide: the Count of records, the COUNT(DISTINCT District) as DistinctDistricts, the District names concatenated with '; ' as Districts, and the average First elected rounded to one decimal (AvgFirstElected); include only groups with at least one record.","
SELECT `Result`, COUNT(*) `Count`, COUNT(DISTINCT `District`) `DistinctDistricts`, GROUP_CONCAT(`District`, '; ') `Districts`, ROUND(AVG(`First elected`),1) `AvgFirstElected`
FROM `table_m_1764881012619_b82118ac_1342270_43`
WHERE `First elected` < 1930
GROUP BY `Result`
HAVING COUNT(*)>0
ORDER BY `Count` DESC
LIMIT 5;
","
SELECT col4, COUNT(*) `Count`, COUNT(DISTINCT col0) `DistinctDistricts`, GROUP_CONCAT(col0, '; ') `Districts`, ROUND(AVG(col3),1) `AvgFirstElected`
FROM `table_m_1764881012619_b82118ac_1342270_43`
WHERE col3 < 1930
GROUP BY col4
HAVING COUNT(*)>0
ORDER BY `Count` DESC
LIMIT 5;
","[('Re-elected', 5, 5, 'Texas 1; Texas 4; Texas 6; Texas 9; Texas 12', 1919.4)]",m_1764881012619_b82118ac_1342270-43,"1) Parse: filter rows by First elected < 1930, group by Result, compute count, distinct district count, concatenated district names with '; ', and rounded average first elected, then sort by count desc and limit 5. 2) Map: use table columns Result, District and First elected for these calculations. 3) Draft: phrase a question requesting the top 5 Result groups by record count with those specific aggregates. 4) Validate: confirm the question mentions the COUNT>0 HAVING clause, ordering and rounding.",reserved,10,N/A,split_column,
How many 'Hugh Peterson (D) Unopposed' were there in each party by 1930?,"
SELECT `Party`, COUNT(*) AS `Hugh Peterson (D) Unopposed`
FROM `table_m_1764881072381_62b759d5_1342331_11`
WHERE `First elected` <= 1930
GROUP BY `Party`
HAVING COUNT(*) > 0
LIMIT 10;
","
SELECT col1, COUNT(*) AS `Hugh Peterson (D) Unopposed`
FROM `table_m_1764881072381_62b759d5_1342331_11`
WHERE col2 <= 1930
GROUP BY col1
HAVING COUNT(*) > 0
LIMIT 10;
","[('Democratic', 5)]",m_1764881072381_62b759d5_1342331-11,"STEP 1: Parse the SQL intent: The query returns Party and a count of rows per Party for rows with `First elected` <= 1930 (GROUP BY Party, HAVING COUNT(*)>0). The COUNT(*) is aliased as 'Hugh Peterson (D) Unopposed'. STEP 2: Determine ambiguity type: Entity vagueness (the alias is a person/label, which can be read as referring to a specific candidate or merely as a column header summarizing counts). This fits because the SQL filter is about first-elected date but the alias/name suggests a specific candidate/status. STEP 3: Draft the question: ""How many 'Hugh Peterson (D) Unopposed' were there in each party by 1930?"" STEP 4: Explain the ambiguity: In the original query the phrase 'Hugh Peterson (D) Unopposed' is only a column label for the count of members first elected by 1930 grouped by party. Alternatively, a reader could interpret the question as asking about occurrences of the specific candidate label 'Hugh Peterson (D) Unopposed' (or whether Hugh Peterson was unopposed in particular parties), which would require filtering by the Candidates column or by the specific name/status in a different query.",reserved,8,N/A,merge_column,type: Entity vagueness | explanation: The phrase 'Hugh Peterson (D) Unopposed' can be read as a literal candidate/status (asking how many times that specific label appears or in which parties that candidate was unopposed) or simply as a column header labeling counts of members first elected by 1930 by party; the SQL uses it only as an alias while a different query could filter for that candidate/status explicitly.
"For Louisiana's 1930 House elections, by party, what were each party's total seats, how many seats were unopposed versus contested, the percent unopposed, the average years in office of incumbents, and which districts (if any) saw incumbents lose renomination or be defeated?","
SELECT
  `Party`,
  COUNT(*) AS `seats_total`,
  SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `unopposed_seats`,
  SUM(CASE WHEN `Candidates` NOT LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `contested_seats`,
  ROUND(100.0 * SUM(CASE WHEN `Candidates` LIKE '%Unopposed%' THEN 1.0 ELSE 0.0 END) / COUNT(*), 1) AS `pct_unopposed`,
  ROUND(AVG(1930 - `First elected`), 1) AS `avg_years_in_office`,
  SUM(CASE WHEN `result_description` LIKE '%Lost%' OR `result_description` LIKE '%defeat%' THEN 1 ELSE 0 END) AS `turnover_count`,
  GROUP_CONCAT(CASE WHEN `result_description` LIKE '%Lost%' OR `result_description` LIKE '%defeat%' THEN `district` END, '; ') AS `turnover_districts`
FROM `table_m_1764881086623_8c0420c3_1342359_17`
GROUP BY `Party`
ORDER BY `seats_total` DESC;
","
SELECT
  col2,
  COUNT(*) AS `seats_total`,
  SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `unopposed_seats`,
  SUM(CASE WHEN col5 NOT LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS `contested_seats`,
  ROUND(100.0 * SUM(CASE WHEN col5 LIKE '%Unopposed%' THEN 1.0 ELSE 0.0 END) / COUNT(*), 1) AS `pct_unopposed`,
  ROUND(AVG(1930 - col3), 1) AS `avg_years_in_office`,
  SUM(CASE WHEN col4 LIKE '%Lost%' OR col4 LIKE '%defeat%' THEN 1 ELSE 0 END) AS `turnover_count`,
  GROUP_CONCAT(CASE WHEN col4 LIKE '%Lost%' OR col4 LIKE '%defeat%' THEN col0 END, '; ') AS `turnover_districts`
FROM `table_m_1764881086623_8c0420c3_1342359_17`
GROUP BY col2
ORDER BY `seats_total` DESC;
","[('Democratic', 6, 5, 1, 83.3, 7.0, 1, 'Louisiana 2')]",m_1764881086623_8c0420c3_1342359-17,"As a political historian, I phrase questions in terms of party control and incumbency but avoid SQL jargon. The query aggregates by party to report totals, unopposed vs contested counts, percent unopposed, average tenure (using 1930 minus First elected), and turnover districts. It maps Party, Candidates (to detect 'Unopposed'), First elected (to compute years in office), Result (to detect 'Lost' or 'defeat'), and District (for listing turnovers). Draft question: For Louisiana's 1930 House elections, by party, what were each party's total seats, how many seats were unopposed versus contested, the percent unopposed, the average years in office of incumbents, and which districts (if any) saw incumbents lose renomination or be defeated? Validation: The question asks only for values the query computes per party: counts, percentages, average tenure, and turnover districts.",persona,"Political historian specializing in early 20th-century Southern U.S. elections, researching patterns of party dominance and electoral competitiveness in Louisiana; uses this database to quantify incumbency, unopposed races, and turnover in the 1930 House elections. Goals: Measure the prevalence of unopposed races and party dominance in Louisiana's 1930 House contests. Estimate incumbents' tenure (time in office) and identify cases of electoral turnover (lost renomination or defeat). Compare competitiveness by party (e.g., how many seats were contested vs. unopposed for each party). Example Queries: /* Count how many races were unopposed in the dataset */
SELECT COUNT(*) AS unopposed_count
FROM table_1_1342359_17
WHERE ""Candidates"" LIKE '%Unopposed%'; /* Summarize seats by party and how many of those seats were unopposed */
SELECT ""Party"",
       COUNT(*) AS seats_total,
       SUM(CASE WHEN ""Candidates"" LIKE '%Unopposed%' THEN 1 ELSE 0 END) AS unopposed_seats
FROM table_1_1342359_17
GROUP BY ""Party""; /* List incumbents with years in office (as of 1930) and flag those who lost (renomination or general) */
SELECT ""District"",
       ""Incumbent"",
       ""Party"",
       ""First elected"",
       (1930 - ""First elected"") AS years_in_office,
       ""Result""
FROM table_1_1342359_17
WHERE ""Result"" LIKE '%Lost%'
   OR ""Result"" LIKE '%Lost renomination%'
   OR ""Result"" LIKE '%defeat%';",N/A,rename_column,
"For all representatives whose First elected year is 1918 or earlier, provide District, Incumbent, Party and Tenure (computed as 1928 minus First elected)?","SELECT `District`, (1928 - `First elected`) AS `Tenure`, `Incumbent (Party)` FROM `table_m_1764881128220_779ebb92_1342370_10` WHERE `First elected` <= 1918;","SELECT col0, (1928 - col1) AS `Tenure`, col4 FROM `table_m_1764881128220_779ebb92_1342370_10` WHERE col1 <= 1918;","[('Georgia 3', 16.0, 'Charles R. Crisp, Democratic'), ('Georgia 4', 10.0, 'William C. Wright, Democratic'), ('Georgia 8', 12.0, 'Charles H. Brand, Democratic'), ('Georgia 9', 24.0, 'Thomas Montgomery Bell, Democratic'), ('Georgia 10', 14.0, 'Carl Vinson, Democratic'), ('Georgia 11', 10.0, 'William C. Lankford, Democratic')]",m_1764881128220_779ebb92_1342370-10,"1) Parse SQL intent: return District, Incumbent, Party and (1928 - First elected) labeled Tenure for records with First elected <= 1918. 2) Map schema semantics: the relevant columns are District, Incumbent, Party and First elected; Tenure is derived. 3) Draft the question to explicitly request those fields and the computed Tenure for the filtered rows. 4) Validate: the question matches the SQL selection, calculation, and filtering criteria.",reserved,3,N/A,merge_column,
"List incumbents with their district, party, first elected, years in office (1926 − first elected), the candidates line, the incumbent's percentage, and flags for Unopposed and Landslide (≥80%) so I can find long‑tenured figures and see how contested their races were.",unanswerable,unanswerable,,m_1764881171892_cbe3bc96_1342379-2,"I'm tracing long-tenured faces and how contested they were, phrasing it poetically but clearly. The SQL computes YearsInOffice as 1926 minus First elected and reports whether a seat was unopposed or a landslide and the incumbent percent. The table supplies First elected and Candidates for percent/unopposed determination. Request a list ordered so I can pick long-serving incumbents with their percent, and flags for unopposed and landslide. This will let me build timelines and portraits linking tenure to contest intensity.",persona,"A museum installation artist — self-styled 'Silence Cartographer' — who maps political absence and dominance by visualizing unopposed and landslide 1926 House races. Goals: Catalog districts with unopposed incumbents to show geographic patterns of electoral silence for an exhibit. Identify extreme landslide victories (e.g., incumbents winning ≥80%) to create a heatmap of political dominance. Find long-tenured incumbents (elected many years before 1926) to build timelines and portraits linking tenure to contest intensity. Example Queries: /* 1) List districts where the incumbent ran unopposed */
SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1342379_2
WHERE Candidates LIKE '%Unopposed%'; /* 2) Extract the incumbent's reported percent and return races where that percent >= 80% (SQLite-style string parsing) */
SELECT District, Incumbent, Party, ""First elected"", Candidates,
       CAST(SUBSTR(Candidates, INSTR(Candidates, ')')+2, INSTR(Candidates, '%') - (INSTR(Candidates, ')')+2)) AS REAL) AS IncumbentPct
FROM table_1_1342379_2
WHERE CAST(SUBSTR(Candidates, INSTR(Candidates, ')')+2, INSTR(Candidates, '%') - (INSTR(Candidates, ')')+2)) AS REAL) >= 80.0; /* 3) Find long-tenured incumbents (elected in or before 1916) and compute years in office as of 1926 */
SELECT District, Incumbent, Party, ""First elected"", (1926 - ""First elected"") AS YearsInOffice
FROM table_1_1342379_2
WHERE ""First elected"" <= 1916
ORDER BY ""First elected"" ASC;",N/A,merge_column,
Which districts had long-serving incumbents who ran unopposed?,"
SELECT `District`, `Incumbent`, `First elected`, CASE WHEN INSTR(`Election_Result_and_Candidates`, 'Unopposed') > 0 THEN 1 ELSE 0 END AS `Unopposed`, CASE 
    WHEN INSTR(`Election_Result_and_Candidates`, 'Lost renomination') > 0 THEN 'Lost renomination'
    WHEN INSTR(`Election_Result_and_Candidates`, 'Retired to run for U.S. Senate') > 0 THEN 'Retired to run for U.S. Senate'
    ELSE NULL
  END AS `Turnover_Type`, CASE
    WHEN INSTR(`Election_Result_and_Candidates`, ' (') > 0 THEN TRIM(SUBSTR(`Election_Result_and_Candidates`, 1, INSTR(`Election_Result_and_Candidates`, ' (') - 1))
    ELSE TRIM(REPLACE(REPLACE(`Election_Result_and_Candidates`, 'Unopposed', ''), '(D)', ''))
  END AS `Candidate_Name`, CASE WHEN `First elected` < 1910 THEN 1 ELSE 0 END AS `Long_serving`, CASE 
    WHEN `Election_Result_and_Candidates` = 'Democratic' AND (INSTR(`Election_Result_and_Candidates`, 'Unopposed') > 0 OR INSTR(`Election_Result_and_Candidates`, 'Democratic hold') > 0) THEN 1 
    ELSE 0 
  END AS `One_party_benefit`, `Election_Result_and_Candidates` FROM `table_m_1764881194761_05da1dd3_1342451_16`
ORDER BY `Unopposed` DESC, `Long_serving` DESC, `District`;
","
SELECT col0, col1, col2, CASE WHEN INSTR(col3, 'Unopposed') > 0 THEN 1 ELSE 0 END AS `Unopposed`, CASE 
    WHEN INSTR(col3, 'Lost renomination') > 0 THEN 'Lost renomination'
    WHEN INSTR(col3, 'Retired to run for U.S. Senate') > 0 THEN 'Retired to run for U.S. Senate'
    ELSE NULL
  END AS `Turnover_Type`, CASE
    WHEN INSTR(col3, ' (') > 0 THEN TRIM(SUBSTR(col3, 1, INSTR(col3, ' (') - 1))
    ELSE TRIM(REPLACE(REPLACE(col3, 'Unopposed', ''), '(D)', ''))
  END AS `Candidate_Name`, CASE WHEN col2 < 1910 THEN 1 ELSE 0 END AS `Long_serving`, CASE 
    WHEN col3 = 'Democratic' AND (INSTR(col3, 'Unopposed') > 0 OR INSTR(col3, 'Democratic hold') > 0) THEN 1 
    ELSE 0 
  END AS `One_party_benefit`, col3 FROM `table_m_1764881194761_05da1dd3_1342451_16`
ORDER BY `Unopposed` DESC, `Long_serving` DESC, col0;
","[('Louisiana 2', 'Henry Garland Dupré', 1908.0, 1, None, 'Democratic, Re-elected, Henry Garland Dupré', 1, 0, 'Democratic, Re-elected, Henry Garland Dupré (D) Unopposed'), ('Louisiana 4', 'John T. Watkins', 1904.0, 1, 'Lost renomination', 'Democratic, Lost renomination Democratic hold, John N. Sandlin', 1, 0, 'Democratic, Lost renomination Democratic hold, John N. Sandlin (D) Unopposed'), ('Louisiana 1', ""James O'Connor"", 1918.0, 1, None, ""Democratic, Re-elected, James O'Connor"", 0, 0, ""Democratic, Re-elected, James O'Connor (D) Unopposed""), ('Louisiana 3', 'Whitmell P. Martin', 1914.0, 1, None, 'Democratic, Re-elected, Whitmell P. Martin', 0, 0, 'Democratic, Re-elected, Whitmell P. Martin (D) Unopposed'), ('Louisiana 5', 'Riley Joseph Wilson', 1914.0, 1, None, 'Democratic, Re-elected, Riley Joseph Wilson', 0, 0, 'Democratic, Re-elected, Riley Joseph Wilson (D) Unopposed'), ('Louisiana 6', 'Jared Y. Sanders, Sr.', 1916.0, 1, 'Retired to run for U.S. Senate', 'Democratic, Retired to run for U.S. Senate Democratic hold, George K. Favrot', 0, 0, 'Democratic, Retired to run for U.S. Senate Democratic hold, George K. Favrot (D) Unopposed'), ('Louisiana 7', 'Ladislas Lazaro', 1912.0, 1, None, 'Democratic, Re-elected, Ladislas Lazaro', 0, 0, 'Democratic, Re-elected, Ladislas Lazaro (D) Unopposed')]",m_1764881194761_05da1dd3_1342451-16,"STEP 1: Parse the SQL intent — the query selects District, Incumbent, Party, First elected, Result, Candidates and computes flags: Unopposed (Candidates contains 'Unopposed'), Turnover_Type (maps specific substrings in Result), Candidate_Name (trims text before ' ('), Long_serving (First elected < 1910), One_party_benefit (Democratic and either Unopposed or 'Democratic hold'); it returns all rows but orders them by Unopposed desc, Long_serving desc, District. STEP 2: Determine ambiguity type — scope ambiguity fits because a question about ""long-serving incumbents who ran unopposed"" can mean the intersection (both conditions true), the union (either condition true), or simply highlighting such incumbents among all rows (no filter). STEP 3: Draft the question — ""Which districts had long-serving incumbents who ran unopposed?"" STEP 4: Explain the ambiguity — in the original query the two properties are encoded as separate binary flags and only prioritized via ORDER BY (not filtered). That makes one valid interpretation: return only rows where Unopposed=1 AND Long_serving=1; another valid interpretation: return rows where Unopposed=1 OR Long_serving=1; a third interpretation: show the full table but list long-serving and unopposed incumbents first (no filtering).",persona,"A Creole political genealogist and historical-linguist who traces family names, elite continuity, and the prevalence of uncontested (one-party) elections in 1920 Louisiana. Goals: Identify which Louisiana congressional districts in 1920 had uncontested ('Unopposed') races and which incumbents benefited from one-party dominance. Find turnover events (lost renomination, retirements to run for Senate) to locate potential family-branch transitions or intraparty contests for deeper genealogical digging. Extract canonical candidate names (stripped of party markers and 'Unopposed' notes) and long-serving incumbents (first elected before 1910) to cross-reference with vital records, family trees, and Creole/Francophone surname studies. Example Queries: SELECT District, Incumbent, Party, ""First elected"", Result, Candidates
FROM table_1_1342451_16
WHERE Candidates LIKE '%Unopposed%'; SELECT Party, COUNT(*) AS unopposed_count
FROM table_1_1342451_16
WHERE Candidates LIKE '%Unopposed%'
GROUP BY Party
ORDER BY unopposed_count DESC; SELECT District,
       Incumbent,
       ""First elected"",
       Result,
       TRIM(SUBSTR(Candidates, 1, INSTR(Candidates, ' (') - 1)) AS Candidate_Name
FROM table_1_1342451_16
WHERE Candidates LIKE '%Unopposed%';",N/A,merge_column,"type: Scope ambiguity | explanation: The phrase can be read as requiring both conditions (long-serving AND unopposed), as either condition (long-serving OR unopposed), or as simply asking to highlight those cases within the full list (no filtering) — the SQL computes both flags and orders by them but does not filter, so each interpretation is plausible."
"Considering only episodes where U.S. viewers (millions) is between 5 and 9 or the episode '#' is less than 10, return each distinct Directed by with Episodes (COUNT(Title)) and AvgViewers (ROUND(AVG(U.S. viewers (millions)),2)) for directors with COUNT(Title) > 1, ordered by AvgViewers descending and limited to 5 results?",unanswerable,unanswerable,,m_1764881207487_cff4b168_13426649-1,"1) Parse the SQL intent: select distinct directors, count their titles and compute rounded average viewers for rows meeting a viewer-range or early-episode condition, keep directors with count > 1, sort by average descending and limit to 5. 2) Map schema semantics: use columns 'Directed by', 'Title', 'U.S. viewers (millions)', and '#' exactly as in the query, with COUNT and ROUND(AVG(...),2). 3) Draft the question: request those aggregated metrics with the specified filters, having clause, ordering, and limit. 4) Validate: ensures all columns, calculations, WHERE BETWEEN 5 AND 9 OR # < 10, HAVING COUNT(Title) > 1, ORDER BY AvgViewers DESC, and LIMIT 5 are included.",reserved,14,N/A,merge_column,
"For up to 5 pairs of buildings in the same Region where one building's Height (m) is greater than the other's and the shorter building's Estimated Completion is earlier than the taller building's, what are the shorter building's Name, its Height (m), the taller building's Name labeled as 'Leadenhall Building', and the height difference (taller Height (m) - shorter Height (m))?","
SELECT t1.`Name`, t1.`height_m`, t2.`Name` AS `Leadenhall Building`, (t2.`height_m` - t1.`height_m`)
FROM `table_m_1764881213899_479b4ebc_13463790_2` t1 INNER JOIN `table_m_1764881213899_479b4ebc_13463790_2` t2 ON t2.`Region` = t1.`Region`
WHERE t2.`height_m` > t1.`height_m` AND CASE WHEN t1.`Estimated Completion` < t2.`Estimated Completion` THEN 1 ELSE 0 END = 1
LIMIT 5;
","
SELECT t1.col1, t1.col4, t2.col1 AS `Leadenhall Building`, (t2.col4 - t1.col4)
FROM `table_m_1764881213899_479b4ebc_13463790_2` t1 INNER JOIN `table_m_1764881213899_479b4ebc_13463790_2` t2 ON t2.col3 = t1.col3
WHERE t2.col4 > t1.col4 AND CASE WHEN t1.col7 < t2.col7 THEN 1 ELSE 0 END = 1
LIMIT 5;
","[('100 Bishopsgate', 172.0, '52-54 Lime Street', 18.0), ('20 Fenchurch Street', 160.0, '1 Blackfriars', 3.0), ('20 Fenchurch Street', 160.0, '100 Bishopsgate', 12.0), ('20 Fenchurch Street', 160.0, '52-54 Lime Street', 30.0), ('Baltimore Tower', 150.0, '1 Blackfriars', 13.0)]",m_1764881213899_479b4ebc_13463790-2,"1) The query finds pairs of rows from the same Region where t2 is taller than t1 and t1's Estimated Completion is earlier than t2's, selecting t1.Name, t1.Height (m), t2.Name aliased as 'Leadenhall Building', and the height difference (t2.Height (m) - t1.Height (m)) with a LIMIT 5. 2) Map columns: Name and Height (m) for the shorter building (t1), Name and Height (m) for the taller building (t2), and Estimated Completion for comparison, joined on Region. 3) Draft a question that requests those exact fields, the height subtraction, the same-Region constraint, the completion-date ordering, and up to 5 results. 4) Validate that all selected columns, the calculation, join condition, comparison, and LIMIT are mentioned.",reserved,14,N/A,rename_column,
"Can you list each Owner (labeled 'Dakota Communications') along with the concatenated Call sign values joined by ', ', concatenated Frequency values joined by ' | ', concatenated Target city/ market values joined by '; ', and concatenated City of license values joined by '; ', grouped by Owner and excluding any empty Owner entries, with the output limited to 10 rows?","
SELECT `Owner` AS `Dakota Communications`, group_concat(`Station (Call sign - Frequency)`, ', '), group_concat(`Station (Call sign - Frequency)`, ' | '), group_concat(`Target city/ market`, '; '), group_concat(`City of license`, '; ')
FROM `table_m_1764881230492_cee6d448_134729_3`
WHERE 1 = 1
GROUP BY `Owner`
HAVING LENGTH(`Owner`) > 0 AND 1 = 1 AND 1 = 1
LIMIT 10;
","
SELECT col2 AS `Dakota Communications`, group_concat(col5, ', '), group_concat(col5, ' | '), group_concat(col3, '; '), group_concat(col4, '; ')
FROM `table_m_1764881230492_cee6d448_134729_3`
WHERE 1 = 1
GROUP BY col2
HAVING LENGTH(col2) > 0 AND 1 = 1 AND 1 = 1
LIMIT 10;
","[('Dakota Communications', 'KJRV, 93.3 FM, KJRV, 105.1 FM', 'KJRV, 93.3 FM | KJRV, 105.1 FM', 'Huron/Mitchell; Huron', 'Wessington Springs; Huron'), ('Educational Media Foundation', 'K-LOVE, 89.7 FM', 'K-LOVE, 89.7 FM', 'Huron', 'Rocklin, California'), ('Moody Bible Institute', 'K213CL, 90.5 FM', 'K213CL, 90.5 FM', 'Huron', 'Huron'), ('VCY America', 'KVCH, 88.7 FM', 'KVCH, 88.7 FM', 'Huron', 'Huron')]",m_1764881230492_cee6d448_134729-3,"1) The SQL intent is to aggregate rows per Owner with group_concat for four columns and alias Owner. 2) Schema mapping ties Call sign, Frequency, Target city/ market, City of license to the aggregations and Owner to grouping. 3) Drafted a question requesting the Owner labeled 'Dakota Communications' and the four concatenated fields with their exact separators, while filtering out empty Owner and limiting to 10. 4) Checked that alias, separators, grouping, filter, and limit are all mentioned.",reserved,10,N/A,merge_column,
"Which distinct Trainers (limit 10) have the following aggregated results: Runners = COUNT(*), AvgPlacing = ROUND(AVG(Placing + 0), 2), BestPlacing = MIN(Placing + 0), and Horses = GROUP_CONCAT(Horse, ', '), when considering only rows where LENGTH(Placing) <= 2 and including only Trainers with COUNT(*) >= 1?","
SELECT DISTINCT `Trainer`, COUNT(*) `Runners`, ROUND(AVG(`Placing` + 0),2) `AvgPlacing`, MIN(`Placing` + 0) `BestPlacing`, GROUP_CONCAT(`Horse`, ', ') `Horses` FROM `table_m_1764881243234_b2daec6f_13498403_1` WHERE LENGTH(`Placing`) <= 2 GROUP BY `Trainer` HAVING COUNT(*) >= 1 LIMIT 10;
","
SELECT DISTINCT col2, COUNT(*) `Runners`, ROUND(AVG(col6 + 0),2) `AvgPlacing`, MIN(col6 + 0) `BestPlacing`, GROUP_CONCAT(col1, ', ') `Horses` FROM `table_m_1764881243234_b2daec6f_13498403_1` WHERE LENGTH(col6) <= 2 GROUP BY col2 HAVING COUNT(*) >= 1 LIMIT 10;
","[('Amanda Perrett', 1, 21.0, 21, 'Tungsten Strike (USA)'), ('Andrew J Payne', 1, 6.0, 6, 'On a Jeune'), ('Bart Cummings', 1, 12.0, 12, 'Sirmione'), ('Colin Little', 1, 19.0, 19, 'Blutigeroo'), ('Daniel Morton', 1, 16.0, 16, 'Scenic Shot'), (""Danny O'Brien"", 2, 9.5, 8, ""Master O'Reilly (NZ), Douro Valley""), ('David Hayes', 4, 12.0, 7, 'Tawqeet (USA), Blue Monday (GB), Black Tom, Lazer Sharp'), ('Graeme Rogerson', 2, 2.5, 1, 'Efficient (NZ), Zipping'), ('Luca Cumani', 1, 2.0, 2, 'Purple Moon (IRE)'), ('Mark Walker', 1, 13.0, 13, 'Princess Coup')]",m_1764881243234_b2daec6f_13498403-1,"1) Parse the SQL intent: group by Trainer to produce aggregates and a concatenated horse list, excluding placings with length > 2 and limiting to 10 trainers. 2) Map schema semantics: Trainer and Horse are used directly; Placing is cast to numeric with Placing + 0 for AVG and MIN; GROUP_CONCAT uses ', ' separator; DISTINCT and HAVING COUNT(*) >= 1 ensure unique trainers with runners. 3) Draft the question: ask for Trainer, Runners (COUNT(*)), AvgPlacing (ROUND(AVG(Placing + 0),2)), BestPlacing (MIN(Placing + 0)), Horses (GROUP_CONCAT(Horse, ', ')) with WHERE LENGTH(Placing) <= 2 and LIMIT 10. 4) Validate: includes every column, calculation, filter, grouping, having and limit from the query.",reserved,8,N/A,add_column,
"Which counties (limit 10) have an average per capita income greater than the average per capita income across all places, when considering only places with Population > 1000 OR Number of Households > 1000, and for each such County show the number of places (NumPlaces), the Avg Per Capita (compute Per Capita Income by removing '$' and ',' then converting to numeric and rounding the county average to 2 decimals) and the Total Population (sum of Population)?",unanswerable,unanswerable,,m_1764881254297_7e71c661_1350350-2,"1) The query filters rows by Population>1000 OR Number of Households>1000, groups by County, computes COUNT(Place) as NumPlaces, average cleaned Per Capita Income rounded to 2 decimals, and SUM(Population), then keeps counties with AVG(cleaned Per Capita) > overall AVG(cleaned Per Capita) and limits to 10. 2) Map table columns and the string-to-number Per Capita Income conversion. 3) Formulate a question asking for County, NumPlaces, Avg Per Capita (cleaned and rounded), and Total Population under these conditions, limited to 10. 4) Ensure inclusion of all columns, cleaning steps, filter logic, HAVING condition, and the LIMIT.",reserved,13,N/A,merge_column,
"Considering only rows with Owned since > 0, what is the total number of stations; how many stations have Primary affiliation = 'Fox'; how many have Primary affiliation = 'MyNetworkTV'; how many have Owned since <= 2001; how many Station names contain '++'; and how many Station names contain '¤¤'?","
SELECT COUNT(*) `Total stations`,
       SUM(`Primary affiliation`='Fox') `Fox stations`,
       SUM(`Primary affiliation`='MyNetworkTV') `MyNetworkTV stations`,
       SUM((`Owned since`+0)<=2001) `Owned_by_2001_or_earlier`,
       SUM(instr(`Station`,'++')>0) `Stations_with_++`,
       SUM(instr(`Station`,'¤¤')>0) `Stations_with_¤¤`
FROM `table_m_1764881270706_db41d924_1353096_1`
WHERE (`Owned since`+0)>0;
","
SELECT COUNT(*) `Total stations`,
       SUM(col3='Fox') `Fox stations`,
       SUM(col3='MyNetworkTV') `MyNetworkTV stations`,
       SUM((col2+0)<=2001) `Owned_by_2001_or_earlier`,
       SUM(instr(col1,'++')>0) `Stations_with_++`,
       SUM(instr(col1,'¤¤')>0) `Stations_with_¤¤`
FROM `table_m_1764881270706_db41d924_1353096_1`
WHERE (col2+0)>0;
","[(27, 18, 9, 20, 6, 5)]",m_1764881270706_db41d924_1353096-1,"1) Parse intent: compute COUNT(*) plus SUMs of boolean expressions for affiliation equality, ownership-year threshold, and substring presence, with Owned since positive. 2) Map schema: use the `Primary affiliation`, `Owned since`, and `Station` fields. 3) Draft: ask for the total stations and the six specific aggregated counts (Fox, MyNetworkTV, owned by 2001 or earlier, contains '++', contains '¤¤') under the Owned since > 0 condition. 4) Validate: question mirrors each SELECT expression and the WHERE clause.",reserved,3,N/A,split_column,
"Show the Player and compute Set Win % = (Sets Won/Played)*100, Legs Margin = (Legs Won - Legs Lost), and Performance Score = ((Sets Won - Sets Lost)/(Sets Won + Sets Lost + 0.0))*50 + ((100+)/Played)*30 + ((3-dart Average)/100)*20 for all players where Played > 1 and (Legs Won - Legs Lost) > 0?","
SELECT `Player`, (`Sets Won`/`Played`)*100 `Set Win %`, (`Legs Won` - `Legs Lost`) `Legs Margin`, (((`Sets Won` - `Sets Lost`)/(`Sets Won` + `Sets Lost` + 0.0))*50 + ((`100+`)/`Played`)*30 + (`3-dart Average`/100)*20) `Performance Score` FROM `table_m_1764881290525_1123a06d_13535824_2` WHERE `Played`>1 AND (`Legs Won` - `Legs Lost`)>0;
","
SELECT col0, (col2/col1)*100 `Set Win %`, (col4 - col5) `Legs Margin`, (((col2 - col3)/(col2 + col3 + 0.0))*50 + ((col6)/col1)*30 + (col10/100)*20) `Performance Score` FROM `table_m_1764881290525_1123a06d_13535824_2` WHERE col1>1 AND (col4 - col5)>0;
","[('Anastasia Dobromyslova', 200.0, 14.0, 385.814), ('Trina Gulliver', 133.33333333333331, 5.0, 292.1468571428572)]",m_1764881290525_1123a06d_13535824-2,"Parse intent: return Player and three computed fields for players passing two filters. Map schema: use Player, Sets Won, Sets Lost, Played, Legs Won, Legs Lost, 100+, and 3-dart Average in the formulas. Draft: ask for the exact formulas including the +0.0 denominator adjustment and the weighted sum for Performance Score. Validate: question mirrors SQL selections, calculations, and WHERE conditions.",reserved,4,N/A,add_column,
"Rank all clubs by league points (use point difference as the tiebreaker) and show played, league points, point difference, try difference, points per game, conceded per game, tries conceded per game, try-bonus conversion rate, and flags for teams conceding more than the division average, with weak try defence, low scoring, or poor try-bonus conversion.",unanswerable,unanswerable,,m_1764881329540_84ee08c1_13564637-3,"As the club's performance analyst I speak in practical terms — points/game, try counts and try-bonus conversion are my bread and butter and I expect a season table summary. The query computes per-team rates, point and try differences, try-bonus conversion and compares each team to league averages, then ranks by league points and point difference. It pulls Club, Played, Points, Points for/against, Tries for/against and Try bonus to build those metrics. Draft question: Rank all clubs by league points (use point difference as the tiebreaker) and show played, league points, point difference, try difference, points per game, conceded per game, tries conceded per game, try-bonus conversion rate, and flags for teams that concede more points/tries than the league average or score/convert below the league average. This matches the query intent and only asks for fields and comparisons present in the SQL.",persona,"Club performance analyst for a WRU Division Three South East team who uses the season table to measure team and opponent performance, identify weaknesses, and inform training and match preparation. They need quick, reproducible SQL-style queries against the season table to produce tactical and recruitment insights. Goals: Rank teams by league points while also showing offensive/defensive balance (point difference and try difference). Identify opponents with exploitable weaknesses (high points conceded per game or low try defence) to inform match plans. Spot internal issues such as low points-per-game or failure to convert tries into bonus points, to guide training priorities and recruitment. Example Queries: /* Full standings with point & try differentials and points per game */
SELECT ""Club"",
       CAST(""Played"" AS INTEGER) AS played,
       CAST(""Points"" AS INTEGER) AS league_points,
       (CAST(""Points for"" AS INTEGER) - CAST(""Points against"" AS INTEGER)) AS point_diff,
       (CAST(""Tries for"" AS INTEGER) - CAST(""Tries against"" AS INTEGER)) AS try_diff,
       ROUND(CAST(""Points for"" AS FLOAT) / NULLIF(CAST(""Played"" AS FLOAT),0), 2) AS points_per_game
FROM table_1_13564637_3
ORDER BY league_points DESC, point_diff DESC; /* Opponents conceding the most points per game (targets for defensive tactics) */
SELECT ""Club"",
       CAST(""Points against"" AS INTEGER) AS points_conceded,
       CAST(""Played"" AS INTEGER) AS played,
       ROUND(CAST(""Points against"" AS FLOAT) / NULLIF(CAST(""Played"" AS FLOAT),0), 2) AS conceded_per_game
FROM table_1_13564637_3
ORDER BY conceded_per_game DESC
LIMIT 5; /* Teams with relatively high try output but low league points (potentially dangerous, fast-scoring teams) */
SELECT ""Club"",
       CAST(""Tries for"" AS INTEGER) AS tries_for,
       CAST(""Tries against"" AS INTEGER) AS tries_against,
       (CAST(""Tries for"" AS INTEGER) - CAST(""Tries against"" AS INTEGER)) AS try_diff,
       CAST(""Points"" AS INTEGER) AS league_points,
       ROUND(CAST(""Tries for"" AS FLOAT) / NULLIF(CAST(""Played"" AS FLOAT),0), 2) AS tries_per_game
FROM table_1_13564637_3
WHERE CAST(""Tries for"" AS INTEGER) >= 40
ORDER BY league_points ASC, tries_for DESC;",N/A,remove_column,
"For Castile and León, Galicia and Andalusia, how much renewable power did they produce when considering only communities above the average renewable generation?","
SELECT
  SUM(CASE WHEN `Autonomous Community` = 'Castile and León' THEN `Hydroelectric power` ELSE 0 END) AS `Castile and León`,
  SUM(CASE WHEN `Autonomous Community` = 'Galicia' THEN `Wind power` ELSE 0 END) AS `Galicia`,
  SUM(CASE WHEN `Autonomous Community` = 'Andalusia' THEN `Biomass power` ELSE 0 END) AS `Andalusia`
FROM `table_m_1764881347063_a3bf6e65_13566548_1`
WHERE `Total Renewable Generation` > (SELECT AVG(`Total Renewable Generation`) FROM `table_m_1764881347063_a3bf6e65_13566548_1`)
LIMIT 1;
","
SELECT
  SUM(CASE WHEN col0 = 'Castile and León' THEN col1 ELSE 0 END) AS `Castile and León`,
  SUM(CASE WHEN col0 = 'Galicia' THEN col2 ELSE 0 END) AS `Galicia`,
  SUM(CASE WHEN col0 = 'Andalusia' THEN col4 ELSE 0 END) AS `Andalusia`
FROM `table_m_1764881347063_a3bf6e65_13566548_1`
WHERE col6 > (SELECT AVG(col6) FROM `table_m_1764881347063_a3bf6e65_13566548_1`)
LIMIT 1;
","[(6960.0, 5970.0, 0)]",m_1764881347063_a3bf6e65_13566548-1,"STEP 1: Parse SQL intent — The query returns three summed values (hydroelectric for Castile and León, wind for Galicia, biomass for Andalusia) but only includes rows where Total Renewable Generation is greater than the table-wide average; because each community appears once this effectively returns each specified source value for that community if that community's total renewable generation > average, otherwise 0. STEP 2: Determine ambiguity type — Scope ambiguity fits well: the phrase ""considering only communities above the average"" could mean (a) filter to communities whose Total Renewable Generation exceeds the average (the SQL interpretation) or (b) compute how much each community's production exceeds the average (an alternate meaning), and additionally there is entity vagueness about which ""renewable power"" metric is intended (specific source vs total). STEP 3: Draft the question — ""For Castile and León, Galicia and Andalusia, how much renewable power did they produce when considering only communities above the average renewable generation?"" STEP 4: Explain the ambiguity — In the SQL the clause ""above the average"" is a filter on rows (only include a community's specific source value if that community's Total Renewable Generation > overall average). The question can instead be read as asking for each community's total renewable generation, or asking for the amount by which each community's production exceeds the average (difference), or as asking to list only communities that are above average, causing different SQL logic and different returned numbers.",reserved,24,N/A,split_column,"type: Scope ambiguity | explanation: The SQL interprets ""above the average"" as a row filter (include each community's specific source value only if that community's Total Renewable Generation > overall average). The natural question could instead mean (a) return each community's total renewable generation, (b) return the amount by which each community's production exceeds the average (difference), or (c) list only the communities that are above average — each interpretation leads to different SQL and different results."
"List up to five Teams ranked by descending number of Overtime Games (where Score contains 'OT'), and for each Team provide: Total Games (COUNT of rows with Score <> ''), Wins (SUM of cases where the first character of Score = 'W'), Losses (SUM of cases where the first character of Score = 'L'), Overtime Games (SUM of cases where Score contains 'OT'), Avg High Points (AVG of the number inside the parentheses in High points), and Max Rebounds (MAX of the number inside the parentheses in High rebounds).",unanswerable,unanswerable,,m_1764881400547_b1533359_13619053-8,"1) The query selects Team-level aggregates including counts, conditional sums for W/L, overtime detection via 'OT', and numeric aggregations from parenthesized values, then orders and limits. 2) Map schema: Team, Score, High points, High rebounds to the requested aggregates and numeric extractions. 3) Compose a question asking for Team, total games (excluding empty Score), wins, losses, overtime games, average high points from the parentheses, and max rebounds from the parentheses, then limit to the top five by overtime games descending. 4) Ensure the question explicitly references the method of determining wins/losses (first character), overtime (contains 'OT'), and the extraction from parentheses.",reserved,9,N/A,remove_column,
"List the top 3 teams by number of wins: for each distinct Team return the Team name, the total number of games (COUNT(*)), and the number of wins computed as SUM(SUBSTR(Score,1,1) = 'W'), include only teams with COUNT(*) > 0 and order the results by the win sum in descending order?",unanswerable,unanswerable,,m_1764881412401_ffe0e201_13619105-3,"1) SQL returns distinct Team along with COUNT(*) and SUM((SUBSTR(Score,1,1) = 'W')) grouped by Team and limited to three by highest win sums. 2) Interpret SUBSTR(Score,1,1) = 'W' as counting wins; COUNT(*) counts games per Team. 3) Create a question requesting for each distinct Team the Team name, game count, and win count (Score starting with 'W'), require COUNT(*) > 0, sort by wins descending, and limit to 3. 4) This aligns with the SELECT, GROUP BY, HAVING, ORDER BY, and LIMIT clauses.",reserved,13,N/A,merge_column,
"Which Game, Date, Team, Score, High points, High rebounds, High assists, Location Attendance, and Record correspond to rows where High points equals High rebounds and the Score indicates a win (Score starting with 'W')?",unanswerable,unanswerable,,m_1764881423478_ebe44af0_13619135-5,"1) The query selects nine columns and filters rows where High points equals High rebounds and Score starts with 'W '. 2) Map columns to the game log: Game, Date, Team, Score, High points, High rebounds, High assists, Location Attendance, Record. 3) Draft a question asking for those columns for rows satisfying High points = High rebounds and a win (Score LIKE 'W %'). 4) Validate that the question requests exactly those columns and both conditions.",reserved,4,N/A,remove_column,
"For each GTO Winning Team (returned as ""GTO Team"") whose GTO Winning Team value begins with '#', what is the COUNT(*) of matching rows (as ""Wins"") and the comma-space separated GROUP_CONCAT of the matching rows' GTO Winning Team values (as ""Drivers"") from rows joined on the same Rnd and Circuit where the joined row's GTO Winning Team does NOT begin with '#', considering only circuits present in the table, grouping by the GTO Winning Team, including only groups with COUNT(*) > 0, ordered by Wins descending and limited to the top 10?","
SELECT t_team.`GTO Winning Team` AS `GTO Team`, COUNT(*) AS `Wins`, GROUP_CONCAT(t_driver.`GTO Winning Team`, ', ') AS `Drivers`
FROM `table_m_1764881470661_e9a1b957_13657883_2` t_team
JOIN `table_m_1764881470661_e9a1b957_13657883_2` t_driver ON t_team.`Round`||'|'||t_team.`Track_Name` = t_driver.`Round`||'|'||t_driver.`Track_Name`
WHERE substr(t_team.`GTO Winning Team`,1,1) = '#' AND substr(t_driver.`GTO Winning Team`,1,1) != '#'
AND t_team.`Track_Name` IN (SELECT `Track_Name` FROM `table_m_1764881470661_e9a1b957_13657883_2`)
GROUP BY t_team.`GTO Winning Team`
HAVING COUNT(*) > 0
ORDER BY `Wins` DESC
LIMIT 10;
","
SELECT t_team.col2 AS `GTO Team`, COUNT(*) AS `Wins`, GROUP_CONCAT(t_driver.col2, ', ') AS `Drivers`
FROM `table_m_1764881470661_e9a1b957_13657883_2` t_team
JOIN `table_m_1764881470661_e9a1b957_13657883_2` t_driver ON t_team.col0||'|'||t_team.col1 = t_driver.col0||'|'||t_driver.col1
WHERE substr(t_team.col2,1,1) = '#' AND substr(t_driver.col2,1,1) != '#'
AND t_team.col1 IN (SELECT col1 FROM `table_m_1764881470661_e9a1b957_13657883_2`)
GROUP BY t_team.col2
HAVING COUNT(*) > 0
ORDER BY `Wins` DESC
LIMIT 10;
","[('#99 Phil Currin', 2, 'Phil Currin, Phil Currin'), ('#48 Greenwood Racing', 1, 'John Greenwood Marshall Robbins'), ('#48 Corvette', 1, 'Charles West'), ('#42 Corvette', 1, 'Garrett Waddall'), ('#41 Corvette', 1, 'Bud Deshler Rodney Harris'), ('#23 Corvette', 1, 'Charlie Kemp Wilbur Pickett'), ('#22 Corvette', 1, 'Denny Long'), ('#2 Holiday Inn Corvette', 1, 'Wilbur Pickett')]",m_1764881470661_e9a1b957_13657883-2,"1) The query counts rows per GTO Winning Team (alias GTO Team), concatenates matching driver names, joins rows by matching Rnd and Circuit, filters team values that start with '#' and driver values that do not, groups by team, and returns the top 10 by count. 2) The table uses the column GTO Winning Team both for team identifiers (starting with '#') and for driver names (not starting with '#'), with Rnd and Circuit identifying matching race entries. 3) Draft a question asking for each GTO Winning Team (as GTO Team) that begins with '#', the number of wins (COUNT(*) AS Wins) and a comma-space separated list (GROUP_CONCAT(..., ', ')) of the matching GTO Winning Team driver names from rows with the same Rnd and Circuit where the driver values do not begin with '#', restricted to circuits present in the table, grouped by GTO Winning Team, only including groups with COUNT(*) > 0, ordered by Wins descending and limited to 10. 4) Validate that the question mentions the join on Rnd and Circuit, the substr conditions, the aliases GTO Team/Wins/Drivers, grouping, HAVING, ORDER BY DESC and LIMIT 10.",reserved,14,N/A,rename_column,
"Which developers/publishers should I prioritize because they have JP-only releases, explicitly delisted games, or messy Wii Points entries — give me the count of problematic items, the JP-only count, the delisted count, the inconsistent-price count, and the list of titles with their Wii Points?",unanswerable,unanswerable,,m_1764881478532_7832e3f6_13663434-1,"The curator voice is practical and might ask which developers to target for funding or archival based on messy pricing and region exclusives. The SQL selects any row that is JP-only, literally 'no longer available', or whose Wii Points contain spaces or region tags, then aggregates by developer/publisher with counts and concatenated title/price lists plus per-category sums. It maps directly to 'Developer(s)/Publisher(s)', 'Title and Source', region columns and 'Wii Points'. Drafted question: Which developers/publishers should I prioritize because they have JP-only releases, explicitly delisted games, or messy Wii Points entries — give me total problematic counts, JP-only counts, delisted counts, inconsistent-price counts, and the list of titles with their Wii Points. Validate: This aligns with the query's filters, grouped counts, concatenated lists and per-category totals and doesn't request anything outside that scope.",persona,"```json
{
  ""short_persona_description"": ""A 'WiiWare Restoration Curator' running a small digital museum dedicated to rescuing, documenting and exhibiting region-exclusive or delisted WiiWare titles and their pricing quirks."",
  ""goals"": [
    ""Locate region-exclusive (e.g., JP-only) or explicitly delisted titles to prioritize for archival/restoration."",
    ""Detect inconsistent or multi-region pricing entries in the 'Wii Points' field to document pricing history and find restoration funding tar Goals:  Example Queries: ",N/A,merge_column,
Which countries have the lowest daily inflation rates?,unanswerable,unanswerable,,m_1764881489903_216f3ce3_13681-2,"STEP 1: Parse the SQL intent — select Country, Currency name, numeric Equivalent daily inflation rate (percent sign removed), compute Time required for prices to double in hours, filter rows where the numeric daily rate > 0 (the WHERE clause effectively reduces to rate > 0), group by Country, order by the numeric daily rate ascending, limit to 3 rows — so it returns the three countries with the smallest positive equivalent daily inflation rates and their computed doubling hours. STEP 2: Choose an ambiguity type — scope ambiguity fits well: the phrase asking for the ""lowest inflation rates"" can refer to a single lowest country, the three lowest, lowest per some grouping/timeframe, or lowest non-negative vs overall lowest. This query specifically picks the three smallest positive daily rates. STEP 3: Draft the question — ""Which countries have the lowest daily inflation rates?"" STEP 4: Explain the ambiguity — in the SQL this is concretely interpreted as the three countries with the smallest positive Equivalent daily inflation rate (ordered asc, LIMIT 3). Alternatively the question could mean the single country with the absolute lowest rate, the lowest rate per year/month, the lowest among currencies vs countries, or whether zero/negative rates should be considered.",reserved,15,N/A,merge_column,"type: Scope ambiguity | explanation: The SQL returns the three countries with the smallest positive equivalent daily inflation rates (ORDER BY rate ASC LIMIT 3). The natural question is ambiguous because it could instead be asking for the single country with the absolute lowest rate, the lowest rate per time period, the lowest among different entity granularities (currency vs country), or whether zero/negative rates are included."
"For the tournament labeled 'Sub-totals oficial matches', provide Matches = 317, Wins Olimpia = 109, Empates = 98, Wins Cerro = 110, Goals Olimpia = 410, Goals Cerro = 402, the computed Wins Diff = (109-110), Goals Diff = (410-402), Win Rate Olimpia = round(109.0/317.0*100,2), Win Rate Cerro = round(110.0/317.0*100,2), Close Contest = ((abs(410-402)<=1)*(abs(109-110)<=1)), and Note = NULL, given that 317 > 0 and abs(410-402) > 0 and (410-402) > 0?","SELECT 'Sub-totals oficial matches' AS ""Tournament"", 317 AS ""Matches"", 109 AS ""Wins Olimpia"", 98 AS ""Empates"", 110 AS ""Wins Cerro"", 410 AS ""Goals Olimpia"", 402 AS ""Goals Cerro"", (109-110) AS ""Wins Diff"", (410-402) AS ""Goals Diff"", round(109.0/317.0*100,2) AS ""Win Rate Olimpia"", round(110.0/317.0*100,2) AS ""Win Rate Cerro"", (CASE WHEN abs(410-402) <= 1 AND abs(109-110) <= 1 THEN 1 ELSE 0 END) AS ""Close Contest"", NULL AS ""Note"" WHERE 317 > 0 AND abs(410-402) > 0 LIMIT 1;","SELECT 'Sub-totals oficial matches' AS ""Tournament"", 317 AS ""Matches"", 109 AS ""Wins Olimpia"", 98 AS ""Empates"", 110 AS ""Wins Cerro"", 410 AS ""Goals Olimpia"", 402 AS ""Goals Cerro"", (109-110) AS ""Wins Diff"", (410-402) AS ""Goals Diff"", round(109.0/317.0*100,2) AS ""Win Rate Olimpia"", round(110.0/317.0*100,2) AS ""Win Rate Cerro"", (CASE WHEN abs(410-402) <= 1 AND abs(109-110) <= 1 THEN 1 ELSE 0 END) AS ""Close Contest"", NULL AS ""Note"" WHERE 317 > 0 AND abs(410-402) > 0 LIMIT 1;","[('Sub-totals oficial matches', 317, 109, 98, 110, 410, 402, -1, 8, 34.38, 34.7, 0, None)]",m_1764881516460_f84898c8_13688489-1,"1) The SQL explicitly returns literal column values and calculated fields for the subtotal tournament row, filtering by positive nonzero goal advantage and requiring matches > 0. 2) Map the table row values and calculations: 317 matches, 109/98/110 results, 410 and 402 goals, diffs and percentages as in the query. 3) Draft a question that includes every returned field and the filtering/grouping constraints. 4) Validate inclusion of Wins Diff (109-110), Goals Diff (410-402), both win rate calculations, the Close Contest Boolean expression, and Note NULL.",reserved,8,N/A,remove_column,
"List up to 10 Locations (ordered by Total Attendance ascending) for which SUM(Attendance) > 38000, using only rows where Attendance > 0, and for each Location show Location, the number of games (COUNT(Date) as Games), SUM(Attendance) as Total Attendance, AVG(Attendance) as Avg Attendance, MAX(Attendance) as Max Attendance, and MIN(Attendance) as Min Attendance?","
SELECT `Location`, COUNT(`Date`) `Games`, SUM(`Attendance`) `Total Attendance`, AVG(`Attendance`) `Avg Attendance`, MAX(`Attendance`) `Max Attendance`, MIN(`Attendance`) `Min Attendance`
FROM `table_m_1764881533521_08436f30_13710464_1`
WHERE `Attendance` > 0
GROUP BY `Location`
HAVING SUM(`Attendance`) > 38000
ORDER BY `Total Attendance`
LIMIT 10;
","
SELECT col5, COUNT(col0) `Games`, SUM(col4) `Total Attendance`, AVG(col4) `Avg Attendance`, MAX(col4) `Max Attendance`, MIN(col4) `Min Attendance`
FROM `table_m_1764881533521_08436f30_13710464_1`
WHERE col4 > 0
GROUP BY col5
HAVING SUM(col4) > 38000
ORDER BY `Total Attendance`
LIMIT 10;
","[('Houston', 2, 78067.0, 39033.5, 41868.0, 36199.0), ('Arlington', 3, 114473.0, 38157.666666666664, 40583.0, 35781.0)]",m_1764881533521_08436f30_13710464-1,"1) Parse intent: aggregate by Location to get games count and attendance summary metrics, filter out Attendance <= 0, keep groups whose SUM(Attendance) > 38000, order by total attendance and limit to 10. 2) Map schema: Date -> Games count, Attendance -> total/avg/max/min, Location -> grouping key. 3) Draft: ask for Location plus COUNT(Date) (Games), SUM/AVG/MAX/MIN of Attendance with the given WHERE, HAVING, ORDER BY, LIMIT constraints. 4) Validate: all SQL components and column calculations are explicitly referenced in the question.",reserved,8,N/A,split_column,
"List each Election date with Party leader, Number of votes received, Percentage of votes, Number of deputies, the votes per deputy calculated as Number of votes received / Number of deputies, the vote_change equal to Number of votes received minus the previous Number of votes received when ordered by Election date, a percentage_flag equal to 'LOW_PERCENT' if Percentage of votes is not '100%' else 'FULL_PERCENT', and a column containing 'Habib Bourguiba', with the output ordered by Election date?","
SELECT
`election_date`,
`Party leader`,
`votes_received`,
`percentage_votes`,
`Number of deputies`,
(`votes_received` / `Number of deputies`) `votes per deputy`,
`votes_received` - LAG(`votes_received`) OVER (ORDER BY `election_date`) `vote_change`,
CASE WHEN `percentage_votes` != '100%' THEN 'LOW_PERCENT' ELSE 'FULL_PERCENT' END `percentage_flag`,
'Habib Bourguiba' `Habib Bourguiba`
FROM `table_m_1764881554723_1700534b_13746866_2`
ORDER BY `election_date`;
","
SELECT
col0,
col1,
col2,
col3,
col4,
(col2 / col4) `votes per deputy`,
col2 - LAG(col2) OVER (ORDER BY col0) `vote_change`,
CASE WHEN col3 != '100%' THEN 'LOW_PERCENT' ELSE 'FULL_PERCENT' END `percentage_flag`,
'Habib Bourguiba' `Habib Bourguiba`
FROM `table_m_1764881554723_1700534b_13746866_2`
ORDER BY col0;
","[(1964.0, 'Habib Bourguiba', 1255153.0, '100%', 101.0, 12427.257425742575, None, 'FULL_PERCENT', 'Habib Bourguiba'), (1969.0, 'Habib Bourguiba', 1363939.0, '100%', 101.0, 13504.346534653465, 108786.0, 'FULL_PERCENT', 'Habib Bourguiba'), (1974.0, 'Habib Bourguiba', 1570954.0, '100%', 112.0, 14026.375, 207015.0, 'FULL_PERCENT', 'Habib Bourguiba'), (1979.0, 'Habib Bourguiba', 1560753.0, '100%', 121.0, 12898.785123966942, -10201.0, 'FULL_PERCENT', 'Habib Bourguiba'), (1981.0, 'Habib Bourguiba', 1828363.0, '94.2%', 136.0, 13443.845588235294, 267610.0, 'LOW_PERCENT', 'Habib Bourguiba')]",m_1764881554723_1700534b_13746866-2,"1) The query returns every row ordered by Election date and adds derived columns: votes per deputy, vote_change using LAG over Election date, a flag based on Percentage of votes, plus a literal string column. 2) Identify the base columns Election date, Party leader, Number of votes received, Percentage of votes, Number of deputies and the computed fields. 3) Write a question asking for those base columns, the division for votes per deputy, the difference from the prior Number of votes received using Election date ordering, the CASE flag mapping to 'LOW_PERCENT' or 'FULL_PERCENT', and the literal 'Habib Bourguiba'. 4) Ensure the question explicitly requests ordering by Election date.",reserved,12,N/A,rename_column,
"Which UK airports should we prioritise for new or increased service — show total passengers, growth %, international/domestic shares, freight tonnes, freight-per-movement, a composite priority score (40% passengers, 25% growth, 20% international, 15% freight/movement) and flags for long-haul (>=50% international), high-growth (>10%) and cargo candidates (above-average freight/movement)?",unanswerable,unanswerable,,m_1764881609853_69a9fd82_13836704-6,"I often need a shortlist of candidate airports for new or increased service that balances market size, momentum, international feed and cargo handling. I would refer to fields like Total Passengers, % Change 2008/2009, International Passengers and Freight (Metric Tonnes). The SQL computes growth_pct from the % Change, international/domestic shares as percentages of total, freight_per_movement, then combines normalized values into a composite priority score and creates binary candidate flags. It returns all airports with those metrics and sorts by composite priority. Draft question: Which UK airports should we prioritise for new/increased service—provide the full metrics, composite priority (40/25/20/15) and flags for long-haul, high-growth and cargo candidates. Validate: That matches the query's intent, metrics and threshold rules.",persona,"Route Development Analyst at a regional airline who uses historical airport traffic data to prioritise new routes, evaluate slot and capacity opportunities, and identify cargo markets. They query this dataset to compare passenger volume, growth rates and freight handling across UK airports for business cases and network planning. Goals: Identify the busiest airports and top candidates for new or increased service based on total passengers and growth. Find airports with strong international traffic share to prioritise long-haul or international feeder routes. Spot airports with rising year-over-year growth (high % change) that signal emerging demand. Assess cargo potential by comparing freight tonnage and freight-per-aircraft-movement ratios. Understand domestic vs international mix to recommend aircraft type and frequency for route planning. Example Queries: SELECT ""Airport"", ""Rank"", ""Total Passengers"", ""International Passengers"", ""Domestic Passengers""
FROM table_1_13836704_6
ORDER BY ""Total Passengers"" DESC
LIMIT 5; SELECT ""Airport"", ""Total Passengers"", ""% Change 2008/2009"" AS growth
FROM table_1_13836704_6
WHERE CAST(REPLACE(""% Change 2008/2009"", '%', '') AS REAL) > 10
ORDER BY CAST(REPLACE(""% Change 2008/2009"", '%', '') AS REAL) DESC; SELECT ""Airport"",
       ""Total Passengers"",
       ""International Passengers"",
       ROUND((""International Passengers"" * 1.0 / ""Total Passengers"") * 100, 2) AS international_share_pct,
       ""Freight ( Metric Tonnes )"",
       ROUND(""Freight ( Metric Tonnes )"" * 1.0 / NULLIF(""Aircraft Movements"", 0), 2) AS freight_tonnes_per_movement
FROM table_1_13836704_6
WHERE ""Freight ( Metric Tonnes )"" > 0
ORDER BY freight_tonnes_per_movement DESC;",N/A,merge_column,
"Which five Locations have the highest population density when computed as the sum of cleaned Population (2000) (commas and '≈' removed) divided by the sum of Area (sqmi), and for each of those Locations return the Location name, the count of Islands Name (Islands Count), the Total Population (sum of Population (2000) after removing commas and '≈'), the Total Area (sqmi) (SUM of Area (sqmi)), the Population Density (per sqmi) as the rounded (to 2 decimals) Total Population/Total Area, and the Max Island Density (per sqmi) as the maximum of each island's cleaned Population (2000) divided by its Area (sqmi), excluding islands with empty Population (2000) after cleaning?","
SELECT
  `Location`,
  COUNT(`Islands Name`) `Islands Count`,
  SUM(REPLACE(REPLACE(`population_2000`, ',', ''), '≈', '')) `Total Population`,
  SUM(`area_sqmi`) `Total Area (sqmi)`,
  ROUND(SUM(REPLACE(REPLACE(`population_2000`, ',', ''), '≈', ''))/SUM(`area_sqmi`),2) `Population Density (per sqmi)`,
  MAX(REPLACE(REPLACE(`population_2000`, ',', ''), '≈', '')/`area_sqmi`) `Max Island Density (per sqmi)`
FROM `table_m_1764881637763_99671c86_13897690_1`
WHERE LENGTH(REPLACE(REPLACE(`population_2000`, ',', ''), '≈', ''))>0
GROUP BY `Location`
ORDER BY -(SUM(REPLACE(REPLACE(`population_2000`, ',', ''), '≈', ''))/SUM(`area_sqmi`))
LIMIT 5;
","
SELECT
  col4,
  COUNT(col1) `Islands Count`,
  SUM(REPLACE(REPLACE(col5, ',', ''), '≈', '')) `Total Population`,
  SUM(col2) `Total Area (sqmi)`,
  ROUND(SUM(REPLACE(REPLACE(col5, ',', ''), '≈', ''))/SUM(col2),2) `Population Density (per sqmi)`,
  MAX(REPLACE(REPLACE(col5, ',', ''), '≈', '')/col2) `Max Island Density (per sqmi)`
FROM `table_m_1764881637763_99671c86_13897690_1`
WHERE LENGTH(REPLACE(REPLACE(col5, ',', ''), '≈', ''))>0
GROUP BY col4
ORDER BY -(SUM(REPLACE(REPLACE(col5, ',', ''), '≈', ''))/SUM(col2))
LIMIT 5;
","[('New York', 1, 7448618, 1401.0, 5316.64, 5316.643825838687), ('Puerto Rico', 1, 3808610, 3515.0, 1083.53, 1083.5305832147938), ('Hawaii', 5, 1208179, 6164.0, 196.01, 1467.5896147403685), ('Alaska', 20, 50226, 24621.0, 2.04, 12.183406113537117)]",m_1764881637763_99671c86_13897690-1,"Parse SQL intent: group islands by Location, compute count, cleaned population sums, area sums, rounded density, and maximum per-island density, filter out empty population values, order by descending overall density and limit to five. Map schema semantics: use `Islands Name` for counts, clean `Population (2000)` by removing commas and '≈', use `Area (sqmi)` for sums and ratios, and `Location` as group. Draft the question: request these exact fields and calculations, specify the cleaning rule and ordering, and limit to five results. Validate: includes all fields, calculations, cleaning, grouping, ordering, and top 5 constraint.",reserved,8,N/A,rename_column,
"What are the Call sign, Frequency MHz, City of license, ERP W, and Notes for each row in the Translators table where ERP W is at least 50 watts?",unanswerable,unanswerable,,m_1764881653829_f449bbca_13998897-1,"Parse intent: project five columns from rows filtered by ERP W >= 50. Map schema: the table holds those fields in the Translators section. Draft: ask for the Call sign, Frequency MHz, City of license, ERP W, and Notes for rows where ERP W >= 50. Validate: includes all columns and the numeric filter exactly.",reserved,3,N/A,remove_column,
"For each Team, return Team, Wins as the COUNT(*) of that team's rows, Races as GROUP_CONCAT of Race Title using '; ' as the separator, Dates as GROUP_CONCAT of Date using '; ' as the separator, and the COUNT(Race Title) labeled 'Triple Eight Race Engineering', only considering rows where Winner is not empty, only including teams with more than one win (HAVING COUNT(*) > 1), ordered by Wins and limited to 5 rows?","
SELECT `Team`, COUNT(*) `Wins`, GROUP_CONCAT(`Race Title`, '; ') `Races`, GROUP_CONCAT(`Date`, '; ') `Dates`, COUNT(`Race Title`) `Triple Eight Race Engineering`
FROM `table_m_1764881667177_6eaa94bd_14016079_1`
WHERE `Winner` <> ''
GROUP BY `Team`
HAVING COUNT(*) > 1
ORDER BY `Wins`
LIMIT 5;
","
SELECT col6, COUNT(*) `Wins`, GROUP_CONCAT(col1, '; ') `Races`, GROUP_CONCAT(col4, '; ') `Dates`, COUNT(col1) `Triple Eight Race Engineering`
FROM `table_m_1764881667177_6eaa94bd_14016079_1`
WHERE col5 <> ''
GROUP BY col6
HAVING COUNT(*) > 1
ORDER BY `Wins`
LIMIT 5;
","[('Ford Performance Racing', 3, 'BigPond 400; Skycity Triple Crown; City of Ipswich 400', '9–11 May; 4–6 July; 18–20 July', 3), ('Holden Racing Team', 3, 'Hamilton 400; Winton; L&H 500', '18–20 April; 1–3 August; 12–14 September', 3), ('Triple Eight Race Engineering', 6, 'Clipsal 500; Midas 400; Supercheap Auto Bathurst 1000; The Coffee Club V8 Supercar Challenge; Gulf Air Desert 400; Falken Tasmania Challenge', '21–24 February; 7–9 June; 9–12 October; 23–26 October; 6–8 November; 21–23 November', 6)]",m_1764881667177_6eaa94bd_14016079-1,"1) Parse SQL intent: aggregate race data per Team, count wins, concatenate titles and dates, include an extra count column with a specific alias, filter non-empty winners, require more than one win, order and limit. 2) Map schema semantics: Race Title and Date use GROUP_CONCAT with '; ' separators; COUNT(Race Title) must be named 'Triple Eight Race Engineering'. 3) Draft the question to capture these outputs and constraints. 4) Validate: ensure mention of WHERE Winner <> '', HAVING COUNT(*) > 1, ORDER BY Wins, and LIMIT 5.",reserved,8,N/A,rename_column,
Which entries have production greater than primary energy and what is their export intensity?,unanswerable,unanswerable,,m_1764881686274_0e95b047_14049026-1,"STEP 1: Parse the SQL intent: select the first (unnamed) column plus Capita, Prim. energy, Production, Export, Electricity, CO 2 -emission and compute Export intensity % as (Export/Production)*100 for rows where Production > Prim. energy, limiting output to 2 rows. STEP 2: Determine an ambiguity type that fits: scope ambiguity is appropriate because the phrase referring to “their export intensity” could mean a per-row (per-entry) ratio as computed in the query, or an aggregated ratio for the group of matching rows. STEP 3: Draft the question: “Which entries have production greater than primary energy and what is their export intensity?” STEP 4: Explain the ambiguity: the original query interprets “their export intensity” as the per-row export/production percentage and returns the first two matching rows, whereas an alternative interpretation could ask for a single export intensity computed across all matching entries (e.g., sum(Export)/sum(Production)*100) or otherwise aggregate the group before computing the percentage.",reserved,5,N/A,merge_column,"type: Scope ambiguity | explanation: The SQL computes export intensity per row (Export/Production*100) for each matching entry and returns two rows; alternatively, the question could mean the group's export intensity (aggregate Export divided by aggregate Production) or a different aggregation scope, changing the result significantly."
"Which countries (Country or territory with flag) have density (where density is the numeric value obtained by taking the substring of Population density per km² before '/' and casting it to REAL) greater than the average density, and for each return Country or territory with flag, Population (July 2009 est.), density, estimated_area computed as Population (July 2009 est.) / density, and a density_flag that is 'Above avg' when density > average and 'Below avg' otherwise, ordering the results by density ascending and limiting the output to 6 rows?",unanswerable,unanswerable,,m_1764881704363_fa8c7cf2_14098-1,"1) Parse intent: extract numeric density from the density text, compute an estimated area by dividing population by density, flag rows relative to average density, then select only above-average densities and return the lowest six by density. 2) Map schema: use Country or territory with flag, Population (July 2009 est.), and Population density per km² to derive density and estimated_area. 3) Draft: request those columns and calculations and the condition density > average, ordered ascending, limit 6. 4) Validate: ensure substring-and-cast, division, CASE labeling, AVG comparison, ORDER BY density ASC, and LIMIT 6 are included.",reserved,21,N/A,merge_column,
"Which actors voiced characters in multiple dubs, and which characters did they voice?","
WITH `actors` AS (
  SELECT `Voice Actor (Japanese)` AS `actor` FROM `table_m_1764881710525_35f1afe8_1410384_1`
  UNION
  SELECT `Voice Actor (English 1997 / Saban)` FROM `table_m_1764881710525_35f1afe8_1410384_1`
  UNION
  SELECT `Voice Actor (English 1998 / Pioneer)` FROM `table_m_1764881710525_35f1afe8_1410384_1`
  UNION
  SELECT `Voice Actor (English 2006 / FUNimation)` FROM `table_m_1764881710525_35f1afe8_1410384_1`
),
`roles` AS (
  SELECT `Character Name`, `Voice Actor (Japanese)` AS `jp`, `Voice Actor (English 1997 / Saban)` AS `e1997`, `Voice Actor (English 1998 / Pioneer)` AS `e1998`, `Voice Actor (English 2006 / FUNimation)` AS `e2006`
  FROM `table_m_1764881710525_35f1afe8_1410384_1`
),
`stable_chars` AS (
  SELECT `Character Name`, `Voice Actor (English 1998 / Pioneer)` AS `stable_actor`
  FROM `table_m_1764881710525_35f1afe8_1410384_1`
  WHERE `Voice Actor (English 1998 / Pioneer)` IS NOT NULL
    AND `Voice Actor (English 2006 / FUNimation)` IS NOT NULL
    AND `Voice Actor (English 1998 / Pioneer)` = `Voice Actor (English 2006 / FUNimation)`
)
SELECT
  `a`.`actor` AS `actor_name`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (Japanese)` = `a`.`actor`) AS `t`) AS `roles_in_Japanese`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (English 1997 / Saban)` = `a`.`actor`) AS `t`) AS `roles_in_1997_Saban`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`) AS `t`) AS `roles_in_1998_Pioneer`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (English 2006 / FUNimation)` = `a`.`actor`) AS `t`) AS `roles_in_2006_FUNimation`,
  (SELECT COUNT(*) FROM (SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (Japanese)` = `a`.`actor`
     UNION
     SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (English 1997 / Saban)` = `a`.`actor`
     UNION
     SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`
     UNION
     SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (English 2006 / FUNimation)` = `a`.`actor`
  )) AS `total_distinct_characters`,
  CASE WHEN (
    (SELECT COUNT(*) FROM (SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (Japanese)` = `a`.`actor`
       UNION
       SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (English 1997 / Saban)` = `a`.`actor`
       UNION
       SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`
       UNION
       SELECT DISTINCT `Character Name` FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE `Voice Actor (English 2006 / FUNimation)` = `a`.`actor`
    )) > 1
  ) THEN 1 ELSE 0 END AS `multi_character_flag`,
  (SELECT GROUP_CONCAT(`t`.`Character Name`, '; ') FROM (SELECT DISTINCT `Character Name` FROM `stable_chars` WHERE `stable_actor` = `a`.`actor`) AS `t`) AS `stable_characters_voiced_in_1998_2006`,
  (SELECT GROUP_CONCAT(`entry`, '; ') FROM (
     SELECT DISTINCT
       `Character Name` || ' [' ||
       TRIM(
         (CASE WHEN `Voice Actor (Japanese)` = `a`.`actor` THEN 'JP' ELSE '' END) ||
         (CASE WHEN `Voice Actor (English 1997 / Saban)` = `a`.`actor` THEN CASE WHEN `Voice Actor (Japanese)` = `a`.`actor` THEN ';1997 Saban' ELSE '1997 Saban' END ELSE '' END) ||
         (CASE WHEN `Voice Actor (English 1998 / Pioneer)` = `a`.`actor` THEN CASE WHEN (`Voice Actor (Japanese)` = `a`.`actor` OR `Voice Actor (English 1997 / Saban)` = `a`.`actor`) THEN ';1998 Pioneer' ELSE '1998 Pioneer' END ELSE '' END) ||
         (CASE WHEN `Voice Actor (English 2006 / FUNimation)` = `a`.`actor` THEN CASE WHEN (`Voice Actor (Japanese)` = `a`.`actor` OR `Voice Actor (English 1997 / Saban)` = `a`.`actor` OR `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`) THEN ';2006 FUNimation' ELSE '2006 FUNimation' END ELSE '' END)
       ) || ']' AS `entry`
     FROM `table_m_1764881710525_35f1afe8_1410384_1`
     WHERE `Voice Actor (Japanese)` = `a`.`actor`
        OR `Voice Actor (English 1997 / Saban)` = `a`.`actor`
        OR `Voice Actor (English 1998 / Pioneer)` = `a`.`actor`
        OR `Voice Actor (English 2006 / FUNimation)` = `a`.`actor`
  ) ) AS `timeline_map_actor_to_characters_and_dubs`
FROM `actors` `a`
WHERE `a`.`actor` IS NOT NULL AND `a`.`actor` <> ''
ORDER BY `multi_character_flag` DESC, `total_distinct_characters` DESC, `actor_name`;
","
WITH `actors` AS (
  SELECT col1 AS `actor` FROM `table_m_1764881710525_35f1afe8_1410384_1`
  UNION
  SELECT col2 FROM `table_m_1764881710525_35f1afe8_1410384_1`
  UNION
  SELECT col3 FROM `table_m_1764881710525_35f1afe8_1410384_1`
  UNION
  SELECT col4 FROM `table_m_1764881710525_35f1afe8_1410384_1`
),
`roles` AS (
  SELECT col0, col1 AS `jp`, col2 AS `e1997`, col3 AS `e1998`, col4 AS `e2006`
  FROM `table_m_1764881710525_35f1afe8_1410384_1`
),
`stable_chars` AS (
  SELECT col0, col3 AS `stable_actor`
  FROM `table_m_1764881710525_35f1afe8_1410384_1`
  WHERE col3 IS NOT NULL
    AND col4 IS NOT NULL
    AND col3 = col4
)
SELECT
  `a`.`actor` AS `actor_name`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col1 = `a`.`actor`) AS `t`) AS `roles_in_Japanese`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col2 = `a`.`actor`) AS `t`) AS `roles_in_1997_Saban`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col3 = `a`.`actor`) AS `t`) AS `roles_in_1998_Pioneer`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col4 = `a`.`actor`) AS `t`) AS `roles_in_2006_FUNimation`,
  (SELECT COUNT(*) FROM (SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col1 = `a`.`actor`
     UNION
     SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col2 = `a`.`actor`
     UNION
     SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col3 = `a`.`actor`
     UNION
     SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col4 = `a`.`actor`
  )) AS `total_distinct_characters`,
  CASE WHEN (
    (SELECT COUNT(*) FROM (SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col1 = `a`.`actor`
       UNION
       SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col2 = `a`.`actor`
       UNION
       SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col3 = `a`.`actor`
       UNION
       SELECT DISTINCT col0 FROM `table_m_1764881710525_35f1afe8_1410384_1` WHERE col4 = `a`.`actor`
    )) > 1
  ) THEN 1 ELSE 0 END AS `multi_character_flag`,
  (SELECT GROUP_CONCAT(`t`.col0, '; ') FROM (SELECT DISTINCT col0 FROM `stable_chars` WHERE `stable_actor` = `a`.`actor`) AS `t`) AS `stable_characters_voiced_in_1998_2006`,
  (SELECT GROUP_CONCAT(`entry`, '; ') FROM (
     SELECT DISTINCT
       col0 || ' [' ||
       TRIM(
         (CASE WHEN col1 = `a`.`actor` THEN 'JP' ELSE '' END) ||
         (CASE WHEN col2 = `a`.`actor` THEN CASE WHEN col1 = `a`.`actor` THEN ';1997 Saban' ELSE '1997 Saban' END ELSE '' END) ||
         (CASE WHEN col3 = `a`.`actor` THEN CASE WHEN (col1 = `a`.`actor` OR col2 = `a`.`actor`) THEN ';1998 Pioneer' ELSE '1998 Pioneer' END ELSE '' END) ||
         (CASE WHEN col4 = `a`.`actor` THEN CASE WHEN (col1 = `a`.`actor` OR col2 = `a`.`actor` OR col3 = `a`.`actor`) THEN ';2006 FUNimation' ELSE '2006 FUNimation' END ELSE '' END)
       ) || ']' AS `entry`
     FROM `table_m_1764881710525_35f1afe8_1410384_1`
     WHERE col1 = `a`.`actor`
        OR col2 = `a`.`actor`
        OR col3 = `a`.`actor`
        OR col4 = `a`.`actor`
  ) ) AS `timeline_map_actor_to_characters_and_dubs`
FROM `actors` `a`
WHERE `a`.`actor` IS NOT NULL AND `a`.`actor` <> ''
ORDER BY `multi_character_flag` DESC, `total_distinct_characters` DESC, `actor_name`;
","[('Don Brown', None, 'King Kai; Shenron; Rasin', 'Master Roshi; King Kai; Shenron; Lagasin', None, 5, 1, None, 'Master Roshi [1998 Pioneer]; King Kai [1997 Saban;1998 Pioneer]; Shenron [1997 Saban;1998 Pioneer]; Rasin [1997 Saban]; Lagasin [1998 Pioneer]'), ('Christopher Sabat', None, None, None, 'Yamcha; Piccolo; Shenron; Icarus/Higher Dragon', 4, 1, None, 'Yamcha [2006 FUNimation]; Piccolo [2006 FUNimation]; Shenron [2006 FUNimation]; Icarus/Higher Dragon [2006 FUNimation]'), ('Scott McNeil', None, 'Piccolo; Daiz', 'Piccolo; Oolong; Rasin; Daiz', None, 4, 1, None, 'Piccolo [1997 Saban;1998 Pioneer]; Oolong [1998 Pioneer]; Rasin [1998 Pioneer]; Daiz [1997 Saban;1998 Pioneer]'), ('Alec Willows', None, 'Oolong; Lagasin', None, None, 2, 1, None, 'Oolong [1997 Saban]; Lagasin [1997 Saban]'), ('Andy McAvin', None, None, None, 'Rasin; Lagasin', 2, 1, None, 'Rasin [2006 FUNimation]; Lagasin [2006 FUNimation]'), ('Cathy Weseluck', None, 'Chiaotzu; Puar', 'Chiaotzu; Puar', None, 2, 1, None, 'Chiaotzu [1997 Saban;1998 Pioneer]; Puar [1997 Saban;1998 Pioneer]'), ('Kenji Utsumi', 'Shenron; Rasin', None, None, None, 2, 1, None, 'Shenron [JP]; Rasin [JP]'), ('Masako Nozawa', 'Goku; Gohan', None, None, None, 2, 1, None, 'Goku [JP]; Gohan [JP]'), ('Monika Antonelli', None, None, None, 'Chiaotzu; Puar', 2, 1, None, 'Chiaotzu [2006 FUNimation]; Puar [2006 FUNimation]'), ('Naoki Tatsuta', 'Oolong; Icarus/Higher Dragon', None, None, None, 2, 1, None, 'Oolong [JP]; Icarus/Higher Dragon [JP]'), ('Sean Schemmel', None, None, None, 'Goku; King Kai', 2, 1, None, 'Goku [2006 FUNimation]; King Kai [2006 FUNimation]'), ('Alvin Sanders', None, 'Kakao', 'Kakao', None, 1, 0, None, 'Kakao [1997 Saban;1998 Pioneer]'), ('Banjo Ginga', 'Armond', None, None, None, 1, 0, None, 'Armond [JP]'), ('Bradford Jackson', None, None, None, 'Oolong', 1, 0, None, 'Oolong [2006 FUNimation]'), ('Cynthia Cranz', None, None, None, 'Chi-Chi', 1, 0, None, 'Chi-Chi [2006 FUNimation]'), ('Dave Ward', None, 'Master Roshi', None, None, 1, 0, None, 'Master Roshi [1997 Saban]'), ('Doug Parker', None, 'Icarus/Higher Dragon', 'Icarus/Higher Dragon', None, 1, 0, None, 'Icarus/Higher Dragon [1997 Saban;1998 Pioneer]'), ('Hiroko Emori', 'Chiaotzu', None, None, None, 1, 0, None, 'Chiaotzu [JP]'), ('Hiromi Tsuru', 'Bulma', None, None, None, 1, 0, None, 'Bulma [JP]'), ('Hirotaka Suzuoki', 'Tien', None, None, None, 1, 0, None, 'Tien [JP]'), ('Ian James Corlett', None, 'Goku', None, None, 1, 0, None, 'Goku [1997 Saban]'), ('Jeff Johnson', None, None, None, 'Kakao', 1, 0, None, 'Kakao [2006 FUNimation]'), ('John Burgmeier', None, None, None, 'Tien', 1, 0, None, 'Tien [2006 FUNimation]'), ('Joji Yanami', 'King Kai', None, None, None, 1, 0, None, 'King Kai [JP]'), ('Kōhei Miyauchi', 'Master Roshi', None, None, None, 1, 0, None, 'Master Roshi [JP]'), ('Laara Sadiq', None, 'Chi-Chi', 'Chi-Chi', None, 1, 0, None, 'Chi-Chi [1997 Saban;1998 Pioneer]'), ('Lalainia Lindbjerg', None, 'Bulma', 'Bulma', None, 1, 0, None, 'Bulma [1997 Saban;1998 Pioneer]'), ('Mark Lancaster', None, None, None, 'Daiz', 1, 0, None, 'Daiz [2006 FUNimation]'), ('Masaharu Satou', 'Lagasin', None, None, None, 1, 0, None, 'Lagasin [JP]'), ('Matt Smith', None, 'Tien', 'Tien', None, 1, 0, None, 'Tien [1997 Saban;1998 Pioneer]'), ('Mayumi Shō', 'Chi-Chi', None, None, None, 1, 0, None, 'Chi-Chi [JP]'), ('Mayumi Tanaka', 'Krillin', None, None, None, 1, 0, None, 'Krillin [JP]'), ('Mike McFarland', None, None, None, 'Master Roshi', 1, 0, None, 'Master Roshi [2006 FUNimation]'), ('Naoko Watanabe', 'Puar', None, None, None, 1, 0, None, 'Puar [JP]'), ('Paul Dobson', None, 'Armond', 'Armond', None, 1, 0, None, 'Armond [1997 Saban;1998 Pioneer]'), ('Paul Slavens', None, None, None, 'Armond', 1, 0, None, 'Armond [2006 FUNimation]'), ('Peter Kelamis', None, None, 'Goku', None, 1, 0, None, 'Goku [1998 Pioneer]'), ('Saffron Henderson', None, 'Gohan', 'Gohan', None, 1, 0, None, 'Gohan [1997 Saban;1998 Pioneer]'), ('Shinobu Satouchi', 'Kakao', None, None, None, 1, 0, None, 'Kakao [JP]'), ('Sonny Strait', None, None, None, 'Krillin', 1, 0, None, 'Krillin [2006 FUNimation]'), ('Stephanie Nadolny', None, None, None, 'Gohan', 1, 0, None, 'Gohan [2006 FUNimation]'), ('Ted Cole', None, 'Yamcha', 'Yamcha', None, 1, 0, None, 'Yamcha [1997 Saban;1998 Pioneer]'), ('Terry Klassen', None, 'Krillin', 'Krillin', None, 1, 0, None, 'Krillin [1997 Saban;1998 Pioneer]'), ('Tiffany Vollmer', None, None, None, 'Bulma', 1, 0, None, 'Bulma [2006 FUNimation]'), ('Toru Furuya', 'Yamcha', None, None, None, 1, 0, None, 'Yamcha [JP]'), ('Toshio Furukawa', 'Piccolo', None, None, None, 1, 0, None, 'Piccolo [JP]'), ('Yūji Machi', 'Daiz', None, None, None, 1, 0, None, 'Daiz [JP]')]",m_1764881710525_35f1afe8_1410384-1,"STEP 1: Parse the SQL intent — produce one row per actor (from JP and three English dub columns), list the characters they voiced per dub (JP, 1997 Saban, 1998 Pioneer, 2006 FUNimation), count total distinct characters they voiced across all columns, flag actors who voiced more than one distinct character, list characters they voiced in both 1998 and 2006 (stable roles), and build a timeline map showing which dubs each actor voiced each character in. STEP 2: Determine a type of ambiguity — Attachment ambiguity fits: the phrase “in multiple dubs” or “across multiple dubs” can attach to the actor (the actor participated in multiple dubs) or to the character (the same character was voiced by the actor across multiple dubs). This query provides data that could support either reading (it tracks per-dub roles and same-actor-in-1998-and-2006). STEP 3: Draft the question — ""Which actors voiced characters in multiple dubs, and which characters did they voice?"" STEP 4: Explain the ambiguity — the SQL treats multi-dub information at both levels (it lists roles per dub and marks characters with the same actor in 1998 and 2006), so the question could mean (a) actors who participated in more than one dub in any role (the actor appears in multiple dub columns, possibly for different characters), which the timeline_map supports, or (b) actors who voiced the same character in more than one dub (stable roles like identical 1998/2006 casting), which the stable_chars column supports.",persona,"A rights‑conscious audio archivist building ethically licensed voice models for classic anime by mapping which actors voiced which characters across the Japanese original and multiple English dubs. Goals: Identify performers who provided multiple distinct character voices in this film (to avoid mixing voices when training models). Find all characters a given actor voiced and in which dub/version (for licensing clearance and sourcing clean audio). Detect characters whose English voice casting remained stable across dub releases (ideal targets for consistent sample collection). Produce a timeline/map of actor ↔ character assignments across the Japanese and three English dubs for metadata tagging. Example Queries: /* Find English actors who voiced more than one character across all English dubs */
SELECT actor, COUNT(DISTINCT ""Character Name"") AS role_count
FROM (
  SELECT ""Character Name"", ""Voice Actor (English 1997 / Saban)"" AS actor FROM table_1_1410384_1
  UNION ALL
  SELECT ""Character Name"", ""Voice Actor (English 1998 / Pioneer)"" AS actor FROM table_1_1410384_1
  UNION ALL
  SELECT ""Character Name"", ""Voice Actor (English 2006 / FUNimation)"" AS actor FROM table_1_1410384_1
) t
WHERE actor IS NOT NULL AND actor <> ''
GROUP BY actor
HAVING COUNT(DISTINCT ""Character Name"") > 1
ORDER BY role_count DESC; /* For a given actor (e.g., 'Don Brown'), list every character they voiced and indicate which dub(s) they appear in */
SELECT ""Character Name"",
  CASE WHEN ""Voice Actor (English 1997 / Saban)"" = 'Don Brown' THEN '1997 Saban' END AS dub_1997,
  CASE WHEN ""Voice Actor (English 1998 / Pioneer)"" = 'Don Brown' THEN '1998 Pioneer' END AS dub_1998,
  CASE WHEN ""Voice Actor (English 2006 / FUNimation)"" = 'Don Brown' THEN '2006 FUNimation' END AS dub_2006
FROM table_1_1410384_1
WHERE ""Voice Actor (English 1997 / Saban)"" = 'Don Brown'
   OR ""Voice Actor (English 1998 / Pioneer)"" = 'Don Brown'
   OR ""Voice Actor (English 2006 / FUNimation)"" = 'Don Brown'; /* Find characters with identical casting between the 1998 (Pioneer) and 2006 (FUNimation) English dubs (stable casting) */
SELECT ""Character Name"", ""Voice Actor (English 1998 / Pioneer)"" AS actor_1998, ""Voice Actor (English 2006 / FUNimation)"" AS actor_2006
FROM table_1_1410384_1
WHERE ""Voice Actor (English 1998 / Pioneer)"" IS NOT NULL
  AND ""Voice Actor (English 1998 / Pioneer)"" = ""Voice Actor (English 2006 / FUNimation)"";",N/A,add_column,"type: Attachment ambiguity | explanation: The phrase ""in multiple dubs"" can attach to the actor (meaning the actor worked in multiple dub productions in any roles) or to the character (meaning the actor voiced the same character across multiple dub versions). The original query contains columns that support both readings: per-dub role lists and a 'stable characters in 1998 and 2006' list for same-character repeat casting."
"For each orbiter, show the number of flights, the average mission duration in days, the longest flight (days), and list any missions that carried microgravity or life‑sciences payloads with their launch dates and durations?","
WITH `durations` AS (
  SELECT
    `edo_flight`,
    `shuttle_type`,
    `Mission`,
    `launch_date`,
    `Duration`,
    `Primary Payload(s)`,
    CAST(substr(`Duration`, 1, instr(`Duration`, ' days') - 1) AS INTEGER) AS `days`,
    CASE
      WHEN `Primary Payload(s)` LIKE '%Microgravity%' OR `Primary Payload(s)` LIKE '%Life%' THEN 1
      ELSE 0
    END AS `is_microgravity`
  FROM `table_m_1764881718847_530bfccc_14118521_1`
),
`agg` AS (
  SELECT
    `shuttle_type`,
    COUNT(*) AS `mission_count`,
    ROUND(AVG(`days`), 2) AS `avg_days`,
    MAX(`days`) AS `max_days`,
    group_concat(CASE WHEN `is_microgravity` = 1 THEN `Mission` || ' (' || `launch_date` || ', ' || `Duration` || ')' END, '; ') AS `microgravity_missions`
  FROM `durations`
  GROUP BY `shuttle_type`
)
SELECT
  a.`shuttle_type`,
  a.`mission_count`,
  a.`avg_days`,
  a.`max_days`,
  COALESCE(a.`microgravity_missions`, '') AS `microgravity_missions`,
  COALESCE(group_concat(b.`Mission` || ' (' || b.`days` || ' days)', '; '), '') AS `longest_mission_details`
FROM `agg` a
LEFT JOIN `durations` b
  ON a.`shuttle_type` = b.`shuttle_type` AND b.`days` = a.`max_days`
GROUP BY a.`shuttle_type`
ORDER BY a.`avg_days` DESC;
","
WITH `durations` AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    col4,
    col5,
    CAST(substr(col4, 1, instr(col4, ' days') - 1) AS INTEGER) AS `days`,
    CASE
      WHEN col5 LIKE '%Microgravity%' OR col5 LIKE '%Life%' THEN 1
      ELSE 0
    END AS `is_microgravity`
  FROM `table_m_1764881718847_530bfccc_14118521_1`
),
`agg` AS (
  SELECT
    col1,
    COUNT(*) AS `mission_count`,
    ROUND(AVG(`days`), 2) AS `avg_days`,
    MAX(`days`) AS `max_days`,
    group_concat(CASE WHEN `is_microgravity` = 1 THEN col2 || ' (' || col3 || ', ' || col4 || ')' END, '; ') AS `microgravity_missions`
  FROM `durations`
  GROUP BY col1
)
SELECT
  a.col1,
  a.`mission_count`,
  a.`avg_days`,
  a.`max_days`,
  COALESCE(a.`microgravity_missions`, '') AS `microgravity_missions`,
  COALESCE(group_concat(b.col2 || ' (' || b.`days` || ' days)', '; '), '') AS `longest_mission_details`
FROM `agg` a
LEFT JOIN `durations` b
  ON a.col1 = b.col1 AND b.`days` = a.`max_days`
GROUP BY a.col1
ORDER BY a.`avg_days` DESC;
","[('Endeavour', 1, 16.0, 16, '', 'STS-67 (16 days)'), ('Columbia', 8, 14.63, 17, 'STS-50 (June 25, 1992, 13 days, 19 hours, 30 minutes, 4 seconds); STS-58 (October 18, 1993, 14 days, 0 hours, 12 minutes, 32 seconds); STS-62 (March 4, 1994, 13 days, 23 hours, 16 minutes, 41 seconds); STS-65 (July 8, 1994, 14 days, 17 hours, 55 minutes, 1 second); STS-73 (October 20, 1995, 15 days, 21 hours, 53 minutes, 16 seconds); STS-78 (June 20, 1996, 16 days, 21 hours, 48 minutes, 30 seconds); STS-87 (November 19, 1997, 15 days, 16 hours, 35 minutes, 1 second)', 'STS-80 (17 days)')]",m_1764881718847_530bfccc_14118521-1,"As a payload integration engineer I'm familiar with 'orbiter' and care about counts, averages and which flights carried microgravity or life‑science hardware. The SQL aggregates missions by Shuttle, computes mission_count, average days, max days, and concatenates microgravity missions with launch date and duration. The table columns map Shuttle→orbiter, Duration→parsed days, and Primary Payload(s)→microgravity/life flag. Drafted question asks for per‑orbiter mission count, avg duration in days, longest flight, and a list of microgravity/life missions with launch date and duration. This is supported by the query which groups by Shuttle and returns those fields.",persona,"Payload Integration Engineer at a university/industry lab who designs microgravity experiments and needs historical shuttle flight data to size experiments, plan timelines, and select target missions to emulate. They use this database to identify long-duration orbiter flights, compare durations by orbiter, and catalog which missions carried relevant microgravity payloads. Goals: Identify historical shuttle missions with the longest on-orbit durations to inform experiment endurance requirements. Compare average mission durations between different orbiters (e.g., Columbia vs Endeavour) to guide scheduling and risk assessment. Find missions that carried microgravity or life-sciences payloads so experiment designs can be aligned with similar past hardware and operational profiles. Example Queries: /* Find missions with 16 or more days in duration (parsing the leading 'N days' from the text Duration) */
SELECT ""Mission"", ""Shuttle"", ""Launch Date"", ""Duration"", ""Primary Payload(s)""
FROM table_1_14118521_1
WHERE CAST(SUBSTRING_INDEX(""Duration"", ' days', 1) AS UNSIGNED) >= 16
ORDER BY CAST(SUBSTRING_INDEX(""Duration"", ' days', 1) AS UNSIGNED) DESC; /* Compare average mission length (in days) by shuttle */
SELECT ""Shuttle"",
       AVG(CAST(SUBSTRING_INDEX(""Duration"", ' days', 1) AS UNSIGNED)) AS avg_days
FROM table_1_14118521_1
GROUP BY ""Shuttle""
ORDER BY avg_days DESC; /* List missions that carried microgravity or life-sciences payloads (keyword search), showing launch date and duration */
SELECT ""Mission"", ""Shuttle"", ""Launch Date"", ""Duration"", ""Primary Payload(s)""
FROM table_1_14118521_1
WHERE ""Primary Payload(s)"" LIKE '%Microgravity%'
   OR ""Primary Payload(s)"" LIKE '%Life%'
ORDER BY STR_TO_DATE(""Launch Date"", '%M %d, %Y') ASC;",N/A,rename_column,
"Starting with seasons 2007 and later, for each Class with at least one race, provide the Class, the total number of Races, the total number of Wins, the Win Rate calculated as total Wins divided by total Races rounded to three decimal places, the total Podiums, and the Average Points per Race calculated as the sum of Pts with any '*' characters removed and converted to a numeric value divided by total Races rounded to two decimal places?","
SELECT DISTINCT `Class`, SUM(`Races`) `Total Races`, SUM(`Wins`) `Total Wins`, ROUND((SUM(`Wins`)*1.0)/NULLIF(SUM(`Races`),0),3) `Win Rate`, SUM(`Podiums`) `Total Podiums`, ROUND(SUM(CAST(REPLACE(`points`, '*', '') AS REAL))/NULLIF(SUM(`Races`),0),2) `Avg points per Race`
FROM `table_m_1764881747151_c1367f10_14139408_1`
WHERE `year` >= 2007
GROUP BY `Class`
HAVING SUM(`Races`) > 0;
","
SELECT DISTINCT col1, SUM(col5) `Total Races`, SUM(col6) `Total Wins`, ROUND((SUM(col6)*1.0)/NULLIF(SUM(col5),0),3) `Win Rate`, SUM(col7) `Total Podiums`, ROUND(SUM(CAST(REPLACE(col10, '*', '') AS REAL))/NULLIF(SUM(col5),0),2) `Avg points per Race`
FROM `table_m_1764881747151_c1367f10_14139408_1`
WHERE col0 >= 2007
GROUP BY col1
HAVING SUM(col5) > 0;
","[('125cc', 50.0, 5.0, 0.1, 11.0, 9.48), ('Moto2', 67.0, 0.0, 0.0, 5.0, 6.63)]",m_1764881747151_c1367f10_14139408-1,"Parse intent: compute per-Class aggregates since 2007 and present win and scoring rates, excluding zero-race classes. Map schema: use Class, Season, Races, Wins, Podiums and Pts with '*' removed and cast to numeric. Draft: ask for Class, Total Races, Total Wins, Win Rate (wins/races rounded to 0.001), Total Podiums, and Avg Pts per Race (sum of cleaned Pts divided by races rounded to 0.01) for seasons >=2007 where total races>0. Validate: captures all requested columns, calculations, rounding precisions, season filter and exclusion condition.",reserved,9,N/A,rename_column,
"For each City, list the City, the count of School Name (number of schools), the SUM of Students, the AVG of (Students / FTE Teachers) rounded to 2 decimal places, the MAX of Students, the MIN of Students, and ROUND((MAX(Students) - MIN(Students)) / AVG(Students), 2), then order the cities by the rounded average(Students / FTE Teachers) descending and show the top 3 cities?",unanswerable,unanswerable,,m_1764881758254_205a2b5b_1414743-1,"1) Parse intent: produce per-city distinct aggregates including count, sum, rounded avg of student-to-FTE ratio, max/min students, and a relative spread, then return the top three cities by that rounded avg. 2) Map schema: fields involved are City, School Name, Students, FTE Teachers and the expressions COUNT(School Name), SUM(Students), ROUND(AVG(Students/FTE Teachers),2), MAX(MIN)(Students), and ROUND((MAX(MIN) difference)/AVG(Students),2). 3) Draft: ask for those exact metrics and ordering. 4) Validate: question contains all columns, calculations, rounding, grouping, ordering, and LIMIT 3.",reserved,8,N/A,merge_column,
"Provide for each Party the Party value, the COUNT(*) as Deaths_or_Resignations, and GROUP_CONCAT(Member-elect, '; ') as Members for rows having Reason for non-seating IS NOT NULL, grouped by Party, with HAVING COUNT(*)>0, and ordered by Deaths_or_Resignations?","
SELECT `party_affiliation` AS `party_affiliation`, COUNT(*) `Deaths_or_Resignations`, GROUP_CONCAT(`member_elect`, '; ') `Members`
FROM `table_m_1764881770265_41037ce0_14158567_1`
WHERE `non_seating_reason` IS NOT NULL
GROUP BY `party_affiliation`
HAVING COUNT(*)>0
ORDER BY `Deaths_or_Resignations`;
","
SELECT col1 AS col1, COUNT(*) `Deaths_or_Resignations`, GROUP_CONCAT(col0, '; ') `Members`
FROM `table_m_1764881770265_41037ce0_14158567_1`
WHERE col5 IS NOT NULL
GROUP BY col1
HAVING COUNT(*)>0
ORDER BY `Deaths_or_Resignations`;
","[('Democratic-Republican', 1, 'John Cantine'), ('Federalist', 1, 'William Dowse'), ('Whig', 1, 'Washington Poe'), ('Republican', 2, 'Andrew J. Campbell; Jack Swigert'), ('Democratic', 3, 'Augustus F. Allen; Richard P. Giles; Samuel Marx')]",m_1764881770265_41037ce0_14158567-1,"1) Parse intent: aggregate members by party for all rows with a non-null Reason for non-seating, counting and concatenating member names, then sort by the count. 2) Map schema: use Party, Member-elect, Reason for non-seating. 3) Draft: ask for Party, COUNT(*) AS Deaths_or_Resignations, GROUP_CONCAT(Member-elect, '; ') AS Members, WHERE Reason for non-seating IS NOT NULL, GROUP BY Party, HAVING COUNT(*)>0, ORDER BY Deaths_or_Resignations. 4) Validate: the question precisely mirrors the selection, filter, aggregation, aliases, and ordering.",reserved,12,N/A,rename_column,
"For the Lowest point values 'Atlantic Ocean', 'Pacific Ocean', and 'Gulf of Mexico', produce rows showing Ocean, COUNT(State) as State Count, GROUP_CONCAT(State, ', ') as States, and the COUNT(State) reported in columns Atlantic Ocean, Pacific Ocean, and Gulf of Mexico, using Lowest point = ocean name as the match, grouped by Ocean, ordered by COUNT(State) descending, limited to 10 results?","
WITH `o` AS (VALUES ('Atlantic Ocean'), ('Pacific Ocean'), ('Gulf of Mexico'))
SELECT `o`.`column1` `Ocean`, COUNT(`t`.`State`) `State Count`, GROUP_CONCAT(`t`.`State`, ', ') `States`, COUNT(`t`.`State`) `Atlantic Ocean`, COUNT(`t`.`State`) `Pacific Ocean`, COUNT(`t`.`State`) `Gulf of Mexico`
FROM `table_m_1764881792370_3d05a15c_1416612_1` `t`
JOIN `o` ON `t`.`Lowest point` = `o`.`column1`
WHERE `o`.`column1` IN ('Atlantic Ocean','Pacific Ocean','Gulf of Mexico') AND 1=1
GROUP BY `o`.`column1`
ORDER BY COUNT(`t`.`State`) DESC
LIMIT 10;
","
WITH `o` AS (VALUES ('Atlantic Ocean'), ('Pacific Ocean'), ('Gulf of Mexico'))
SELECT `o`.`column1` `Ocean`, COUNT(`t`.col0) `State Count`, GROUP_CONCAT(`t`.col0, ', ') `States`, COUNT(`t`.col0) `Atlantic Ocean`, COUNT(`t`.col0) `Pacific Ocean`, COUNT(`t`.col0) `Gulf of Mexico`
FROM `table_m_1764881792370_3d05a15c_1416612_1` `t`
JOIN `o` ON `t`.col2 = `o`.`column1`
WHERE `o`.`column1` IN ('Atlantic Ocean','Pacific Ocean','Gulf of Mexico') AND 1=1
GROUP BY `o`.`column1`
ORDER BY COUNT(`t`.col0) DESC
LIMIT 10;
","[('Atlantic Ocean', 12, 'Delaware, Georgia, Maine, Maryland, Massachusetts, New Hampshire, New Jersey, New York, North Carolina, Rhode Island, South Carolina, Virginia', 12, 12, 12), ('Pacific Ocean', 3, 'Hawai ʻ i, Oregon, Washington', 3, 3, 3), ('Gulf of Mexico', 3, 'Alabama, Mississippi, Texas', 3, 3, 3)]",m_1764881792370_3d05a15c_1416612-1,"1) The SQL constructs a small table of three ocean names, joins it to rows whose Lowest point matches those names, and returns aggregated counts and concatenated state names per ocean, ordered by count and limited. 2) Map: Lowest point links to the three oceans; State provides counts and concatenated names. 3) Draft: ask for Ocean, State Count, GROUP_CONCAT(State, ', ') as States, plus separate COUNT(State) columns for Atlantic Ocean, Pacific Ocean, Gulf of Mexico, grouping by ocean, ordering by the count descending, limit 10. 4) Validate: all selected fields, join condition, IN-list, grouping, ordering, and limit are included.",reserved,14,N/A,split_column,
"Which five institutions (limit 5) have the highest Funding_per_student (Research Funding (£,000) divided by Total Number of Students, rounded to 2 decimals) among institutions with Total Number of Students > 10000 and located in Locations whose SUM(Total Number of Students) > 15000, returning Institution, Location, Total Number of Students, Research Funding (£,000), Funding_per_student, and Above_location_avg where Above_location_avg indicates whether an institution's Research Funding (£,000) is greater than the AVG(Research Funding (£,000)) for that Location, ordered by Funding_per_student descending?",unanswerable,unanswerable,,m_1764881865925_1f6af67c_142950-1,"Parse intent: select Institution, Location, Total Number of Students, Research Funding (£,000), compute Research Funding divided by Total Number of Students rounded to 2 decimals as Funding_per_student, and indicate if Research Funding is greater than the average Research Funding for the Location; only include institutions with Total Number of Students > 10000 and only Locations whose summed Total Number of Students > 15000; order by Funding_per_student descending and limit to 5. Map schema: use table columns Institution, Location, Total Number of Students, Research Funding (£,000) and a subquery computing AVG(Research Funding (£,000)) and SUM(Total Number of Students) grouped by Location. Draft question: ask for the top 5 institutions by funding per student with the specified filters and computed columns. Validate: ensure question names all selected columns, the Funding_per_student calculation rounded to two decimals, the Above_location_avg comparison, the Location-level SUM >15000 condition, the institution-level Total Number of Students >10000 filter, ordering and limit.",reserved,13,N/A,merge_column,
"Which teams performed best in international competitions, and which clubs did not qualify for the Copa Libertadores 1997?","SELECT `Team`, `Intercontinental`, `Recopa 1996`, `Supercopa 1996`, `Copa Libertadores 1997`, TRIM( COALESCE(CASE WHEN `Intercontinental` IN ('Champions','Runner up','SF') THEN 'Intercontinental: ' || `Intercontinental` || '; ' END, '') || COALESCE(CASE WHEN `Recopa 1996` IN ('Champions','Runner up','SF') THEN 'Recopa 1996: ' || `Recopa 1996` || '; ' END, '') || COALESCE(CASE WHEN `Supercopa 1996` IN ('Champions','Runner up','SF') THEN 'Supercopa 1996: ' || `Supercopa 1996` || '; ' END, '') || COALESCE(CASE WHEN `Copa Libertadores 1997` IN ('Champions','Runner up','SF') THEN 'Copa Libertadores 1997: ' || `Copa Libertadores 1997` || '; ' END, ''), '; ') AS `Notable_Performances`, (CASE WHEN `Intercontinental` = 'Champions' OR `Recopa 1996` = 'Champions' OR `Supercopa 1996` = 'Champions' OR `Copa Libertadores 1997` = 'Champions' THEN 'Champions' WHEN `Intercontinental` = 'Runner up' OR `Recopa 1996` = 'Runner up' OR `Supercopa 1996` = 'Runner up' OR `Copa Libertadores 1997` = 'Runner up' THEN 'Runner up' WHEN `Intercontinental` = 'SF' OR `Recopa 1996` = 'SF' OR `Supercopa 1996` = 'SF' OR `Copa Libertadores 1997` = 'SF' THEN 'SF' ELSE 'No late-stage result' END) AS `Best_Result`, CASE WHEN `Copa Libertadores 1997` = 'did not qualify' THEN 1 ELSE 0 END AS `Copa_Libertadores_1997_did_not_qualify`, (SELECT COUNT(*) FROM `table_m_1764881915550_35d89eb2_14310205_1` WHERE `Copa Libertadores 1997` = 'did not qualify') AS `Copa_Libertadores_1997_not_qualified_count`, (SELECT GROUP_CONCAT(`Team`, ', ') FROM `table_m_1764881915550_35d89eb2_14310205_1` WHERE `Copa Libertadores 1997` = 'did not qualify') AS `Copa_Libertadores_1997_not_qualified_teams` FROM `table_m_1764881915550_35d89eb2_14310205_1` ORDER BY CASE WHEN `Intercontinental` = 'Champions' OR `Recopa 1996` = 'Champions' OR `Supercopa 1996` = 'Champions' OR `Copa Libertadores 1997` = 'Champions' THEN 1 WHEN `Intercontinental` = 'Runner up' OR `Recopa 1996` = 'Runner up' OR `Supercopa 1996` = 'Runner up' OR `Copa Libertadores 1997` = 'Runner up' THEN 2 WHEN `Intercontinental` = 'SF' OR `Recopa 1996` = 'SF' OR `Supercopa 1996` = 'SF' OR `Copa Libertadores 1997` = 'SF' THEN 3 ELSE 4 END, `Team`;","SELECT col0, col1, col2, col3, col4, TRIM( COALESCE(CASE WHEN col1 IN ('Champions','Runner up','SF') THEN 'Intercontinental: ' || col1 || '; ' END, '') || COALESCE(CASE WHEN col2 IN ('Champions','Runner up','SF') THEN 'Recopa 1996: ' || col2 || '; ' END, '') || COALESCE(CASE WHEN col3 IN ('Champions','Runner up','SF') THEN 'Supercopa 1996: ' || col3 || '; ' END, '') || COALESCE(CASE WHEN col4 IN ('Champions','Runner up','SF') THEN 'Copa Libertadores 1997: ' || col4 || '; ' END, ''), '; ') AS `Notable_Performances`, (CASE WHEN col1 = 'Champions' OR col2 = 'Champions' OR col3 = 'Champions' OR col4 = 'Champions' THEN 'Champions' WHEN col1 = 'Runner up' OR col2 = 'Runner up' OR col3 = 'Runner up' OR col4 = 'Runner up' THEN 'Runner up' WHEN col1 = 'SF' OR col2 = 'SF' OR col3 = 'SF' OR col4 = 'SF' THEN 'SF' ELSE 'No late-stage result' END) AS `Best_Result`, CASE WHEN col4 = 'did not qualify' THEN 1 ELSE 0 END AS `Copa_Libertadores_1997_did_not_qualify`, (SELECT COUNT(*) FROM `table_m_1764881915550_35d89eb2_14310205_1` WHERE col4 = 'did not qualify') AS `Copa_Libertadores_1997_not_qualified_count`, (SELECT GROUP_CONCAT(col0, ', ') FROM `table_m_1764881915550_35d89eb2_14310205_1` WHERE col4 = 'did not qualify') AS `Copa_Libertadores_1997_not_qualified_teams` FROM `table_m_1764881915550_35d89eb2_14310205_1` ORDER BY CASE WHEN col1 = 'Champions' OR col2 = 'Champions' OR col3 = 'Champions' OR col4 = 'Champions' THEN 1 WHEN col1 = 'Runner up' OR col2 = 'Runner up' OR col3 = 'Runner up' OR col4 = 'Runner up' THEN 2 WHEN col1 = 'SF' OR col2 = 'SF' OR col3 = 'SF' OR col4 = 'SF' THEN 3 ELSE 4 END, col0;","[('Vélez Sársfield', 'N/A', 'Champions', 'Champions', '2nd round', 'Recopa 1996: Champions; Supercopa 1996: Champions', 'Champions', 0, 5, 'Lanús, Rosario Central, Boca Juniors, Argentinos, Estudiantes'), ('River Plate', 'Runner up', 'Runner up', '1st round', 'Round 2', 'Intercontinental: Runner up; Recopa 1996: Runner up', 'Runner up', 0, 5, 'Lanús, Rosario Central, Boca Juniors, Argentinos, Estudiantes'), ('Racing Club', 'N/A', 'N/A', '1st round', 'SF', 'Copa Libertadores 1997: SF', 'SF', 0, 5, 'Lanús, Rosario Central, Boca Juniors, Argentinos, Estudiantes'), ('Argentinos', 'N/A', 'N/A', '1st round', 'did not qualify', '', 'No late-stage result', 1, 5, 'Lanús, Rosario Central, Boca Juniors, Argentinos, Estudiantes'), ('Boca Juniors', 'N/A', 'N/A', 'QF', 'did not qualify', '', 'No late-stage result', 1, 5, 'Lanús, Rosario Central, Boca Juniors, Argentinos, Estudiantes'), ('Estudiantes', 'N/A', 'N/A', '1st round', 'did not qualify', '', 'No late-stage result', 1, 5, 'Lanús, Rosario Central, Boca Juniors, Argentinos, Estudiantes'), ('Lanús', 'N/A', 'N/A', 'N/A', 'did not qualify', '', 'No late-stage result', 1, 5, 'Lanús, Rosario Central, Boca Juniors, Argentinos, Estudiantes'), ('Rosario Central', 'N/A', 'N/A', 'N/A', 'did not qualify', '', 'No late-stage result', 1, 5, 'Lanús, Rosario Central, Boca Juniors, Argentinos, Estudiantes')]",m_1764881915550_35d89eb2_14310205-1,"STEP 1: Parse the SQL intent — returns every Team with their raw competition columns, a concatenated Notable_Performances string including competitions where the team reached Champions/Runner up/SF, a Best_Result per team (Champions > Runner up > SF > No late-stage result), a per-team flag if Copa Libertadores 1997 = 'did not qualify', plus a global count and comma-separated list of all teams whose Copa Libertadores 1997 = 'did not qualify'; results ordered by Best_Result then Team. STEP 2: Choose ambiguity type — scope ambiguity fits well: the phrase ""performed best"" or ""which teams performed best"" can mean either (a) the single top performer(s) overall (e.g., Champions) or (b) each team's best result across competitions (a per-team classification), and the SQL produces per-team Best_Result while also providing Champions/Runner up/SF indicators. STEP 3: Draft the question — ""Which teams performed best in international competitions, and which clubs did not qualify for the Copa Libertadores 1997?"" STEP 4: Explain the ambiguity — in the original query ""performed best"" is implemented as a per-team Best_Result (each team is labeled Champions / Runner up / SF / No late-stage result) and the query also returns a count/list of teams that did not qualify for Copa Libertadores 1997; alternatively the question could be interpreted as asking only for the overall top performer(s) (e.g., which team(s) were Champions across those cups) or as asking for an aggregate summary (just the number of non-qualifiers) which would require a different SQL.",persona,"Performance Analyst at an Argentine football club who compiles historical international results to benchmark the club's past continental performance and support PR/match-prep. They use this database to extract 1996–97 international outcomes for peer clubs and prepare comparative summaries. Goals: Identify which Argentine clubs won or reached late stages (SF, Runner up, Champions) in 1996–97 international competitions to benchmark club performance. Quantify how many clubs failed to qualify for the 1997 Copa Libertadores and which ones, for historical participation analysis. Produce a concise table showing each club's results across all listed international competitions in 1996–97 for reports and presentations. Example Queries: -- 1) List all clubs that were 'Champions' in any competition and indicate which competition(s)
    SELECT ""Team"", 'Intercontinental' AS competition FROM table_1_14310205_1 WHERE ""Intercontinental"" = 'Champions'
    UNION ALL
    SELECT ""Team"", 'Recopa 1996' AS competition FROM table_1_14310205_1 WHERE ""Recopa 1996"" = 'Champions'
    UNION ALL
    SELECT ""Team"", 'Supercopa 1996' AS competition FROM table_1_14310205_1 WHERE ""Supercopa 1996"" = 'Champions'
    UNION ALL
    SELECT ""Team"", 'CONMEBOL 1996' AS competition FROM table_1_14310205_1 WHERE ""CONMEBOL 1996"" = 'Champions'
    UNION ALL
    SELECT ""Team"", 'Copa Libertadores 1997' AS competition FROM table_1_14310205_1 WHERE ""Copa Libertadores 1997"" = 'Champions'; -- 2) Count and list teams that did not qualify for the 1997 Copa Libertadores
    SELECT COUNT(*) AS not_qualified_count FROM table_1_14310205_1 WHERE ""Copa Libertadores 1997"" = 'did not qualify';
    SELECT ""Team"" FROM table_1_14310205_1 WHERE ""Copa Libertadores 1997"" = 'did not qualify'; -- 3) Show teams that reached at least the semi-finals (SF), runner-up or Champion in any listed competition
    SELECT ""Team"", ""Intercontinental"", ""Recopa 1996"", ""Supercopa 1996"", ""CONMEBOL 1996"", ""Copa Libertadores 1997""
    FROM table_1_14310205_1
    WHERE ""Intercontinental"" IN ('Champions','Runner up','SF')
       OR ""Recopa 1996"" IN ('Champions','Runner up','SF')
       OR ""Supercopa 1996"" IN ('Champions','Runner up','SF')
       OR ""CONMEBOL 1996"" IN ('Champions','Runner up','SF')
       OR ""Copa Libertadores 1997"" IN ('Champions','Runner up','SF');",N/A,remove_column,"type: Scope ambiguity | explanation: The phrase ""performed best"" can be read as (a) asking for the single top performer(s) overall (e.g., team(s) that were Champions) or (b) asking for each team's best result across the listed competitions (Champions/Runner up/SF/No late-stage result); the given SQL implements interpretation (b) while also supplying a global count/list of teams that did not qualify for Copa Libertadores 1997, whereas an alternative query might only return the overall Champion(s) or only the count of non-qualifiers."
"For each ground give me total matches, average crowd, peak crowd, how many and which fixtures had crowds over 20,000 with a margin of 12 points or less (date, teams, scores and crowd), and the busiest day of week at that ground with its average crowd?",,,[],m_1764881931549_c30e2200_14312471-3,"As an event-safety planner I speak plainly about grounds, crowds and risky fixtures and I know enough schema words like ground, crowd and margin to be precise. The query summarizes per-ground stats and flags/list matches with crowd >20,000 and margin ≤12 while also finding the busiest weekday. It groups matches by Ground and computes count, average crowd, peak crowd, a count and concatenated list of high-risk matches, and busiest day with its avg crowd. I'll ask for a per-ground report covering totals, averages, peaks, high-risk fixtures and busiest weekday. This question maps to the SQL outputs and doesn't assume any extra fields.",persona,"An emergency-evacuation planner for a city event-safety bureau who mines historical AFL match attendance and match-intensity data to size staffing, medical posts and egress timing models. Goals: Estimate typical and peak spectator loads at each ground to allocate evacuation routes and emergency services capacity. Identify matches that combined high attendance with narrow margins (higher crowd intensity/lingering) to model slower egress and greater demand on services. Find day-of-week patterns (Friday/Saturday/Sunday) in attendance to plan staffing rotas and surge-capable teams. Locate specific high-risk fixtures (large crowds at particular grounds) for targeted infrastructure inspections or temporary crowd-control installations. Example Queries: SELECT ""Ground"", COUNT(*) AS matches, CAST(AVG(""Crowd"") AS INTEGER) AS avg_crowd, MAX(""Crowd"") AS peak_crowd
FROM table_1_14312471_3
GROUP BY ""Ground""
ORDER BY peak_crowd DESC; SELECT ""Date"", ""Ground"", ""Home team"", ""Home team score"", ""Away team"", ""Away team score"", ""Crowd"",
ABS(
  CAST(REGEXP_REPLACE(""Home team score"", '.*\\((\\d+)\\).*', '\\1') AS INTEGER)
  - CAST(REGEXP_REPLACE(""Away team score"", '.*\\((\\d+)\\).*', '\\1') AS INTEGER)
) AS margin
FROM table_1_14312471_3
WHERE ABS(
  CAST(REGEXP_REPLACE(""Home team score"", '.*\\((\\d+)\\).*', '\\1') AS INTEGER)
  - CAST(REGEXP_REPLACE(""Away team score"", '.*\\((\\d+)\\).*', '\\1') AS INTEGER)
) <= 12
AND ""Crowd"" > 20000
ORDER BY ""Crowd"" DESC; SELECT TRIM(SPLIT_PART(""Date"", ',', 1)) AS day_of_week, COUNT(*) AS matches, CAST(AVG(""Crowd"") AS INTEGER) AS avg_crowd
FROM table_1_14312471_3
GROUP BY day_of_week
ORDER BY avg_crowd DESC;",N/A,merge_column,
"For each Year, what are the SUMs of ((`Boys singles`='Andre Kurniawan Tedjono')+(`Girls singles`='Andre Kurniawan Tedjono')+(`Boys doubles`='Andre Kurniawan Tedjono')+(`Girls doubles`='Andre Kurniawan Tedjono')+(`Mixed doubles`='Andre Kurniawan Tedjono')) as `Andre Kurniawan Tedjono`, ((`Boys singles`='Pia Zebadiah')+(`Girls singles`='Pia Zebadiah')+(`Boys doubles`='Pia Zebadiah')+(`Girls doubles`='Pia Zebadiah')+(`Mixed doubles`='Pia Zebadiah')) as `Pia Zebadiah`, and ((`Boys singles`='Jones Ralfy Jansen')+(`Girls singles`='Jones Ralfy Jansen')+(`Boys doubles`='Jones Ralfy Jansen')+(`Girls doubles`='Jones Ralfy Jansen')+(`Mixed doubles`='Jones Ralfy Jansen')) as `Jones Ralfy Jansen`, grouped by Year, ordered by `Andre Kurniawan Tedjono` descending and limited to 5 rows?","
SELECT
SUM((`Boys singles`='Andre Kurniawan Tedjono')+(`Girls singles`='Andre Kurniawan Tedjono')+(`Boys doubles`='Andre Kurniawan Tedjono')+(`Girls doubles`='Andre Kurniawan Tedjono')+(`Mixed doubles`='Andre Kurniawan Tedjono')) `Andre Kurniawan Tedjono`,
SUM((`Boys singles`='Pia Zebadiah')+(`Girls singles`='Pia Zebadiah')+(`Boys doubles`='Pia Zebadiah')+(`Girls doubles`='Pia Zebadiah')+(`Mixed doubles`='Pia Zebadiah')) AS `Pia Zebadiah`,
SUM((`Boys singles`='Jones Ralfy Jansen')+(`Girls singles`='Jones Ralfy Jansen')+(`Boys doubles`='Jones Ralfy Jansen')+(`Girls doubles`='Jones Ralfy Jansen')+(`Mixed doubles`='Jones Ralfy Jansen')) AS `Jones Ralfy Jansen`
FROM `table_m_1764881960165_3c7e899c_14319023_2`
JOIN (SELECT 1) AS `dummy` ON 1=1
WHERE 1=1 AND 1=1
GROUP BY `Year`
ORDER BY `Andre Kurniawan Tedjono` DESC
LIMIT 5;
","
SELECT
SUM((col1='Andre Kurniawan Tedjono')+(col2='Andre Kurniawan Tedjono')+(col3='Andre Kurniawan Tedjono')+(col4='Andre Kurniawan Tedjono')+(col5='Andre Kurniawan Tedjono')) `Andre Kurniawan Tedjono`,
SUM((col1='Pia Zebadiah')+(col2='Pia Zebadiah')+(col3='Pia Zebadiah')+(col4='Pia Zebadiah')+(col5='Pia Zebadiah')) AS `Pia Zebadiah`,
SUM((col1='Jones Ralfy Jansen')+(col2='Jones Ralfy Jansen')+(col3='Jones Ralfy Jansen')+(col4='Jones Ralfy Jansen')+(col5='Jones Ralfy Jansen')) AS `Jones Ralfy Jansen`
FROM `table_m_1764881960165_3c7e899c_14319023_2`
JOIN (SELECT 1) AS `dummy` ON 1=1
WHERE 1=1 AND 1=1
GROUP BY col0
ORDER BY `Andre Kurniawan Tedjono` DESC
LIMIT 5;
","[(1, 1, 0), (1, 0, 0), (0, 0, 0), (0, 0, 0), (0, 0, 0)]",m_1764881960165_3c7e899c_14319023-2,"1) Parse the SQL intent: count, per Year, how many of the five event columns equal each of three specific player names and return the top 5 Years by the count for Andre Kurniawan Tedjono. 2) Map schema semantics: use columns Year, Boys singles, Girls singles, Boys doubles, Girls doubles, Mixed doubles and the three target names. 3) Draft the question: ask for SUM of the five equality checks for each name, grouped by Year, ordered and limited. 4) Validate: ensures sums, grouping by Year, ORDER BY Andre DESC and LIMIT 5 are included.",reserved,16,N/A,merge_column,
"For each Writer, grouped by Writer after joining the table to itself on Total# = Total# and limiting to Series# >= 1 AND Series# <= 12, provide the Writer, Episode Count as the count of Title, Titles as GROUP_CONCAT(Title, ' | '), First Series# as MIN(Series#), Last Series# as MAX(Series#), and MAX(Title = '"" Total Eclipse ""') showing whether any Title equals '"" Total Eclipse ""'?","
SELECT t1.`Writer`, COUNT(t1.`Title`) `Episode Count`, GROUP_CONCAT(t1.`Title`, ' | ') `Titles`, MIN(t1.`Series#`) `First Series#`, MAX(t1.`Series#`) `Last Series#`, MAX(t1.`Title` = '"" Total Eclipse ""') `"" Total Eclipse ""`
FROM `table_m_1764881984957_87120421_14330096_4` t1 JOIN `table_m_1764881984957_87120421_14330096_4` t2 ON t1.`Total#` = t2.`Total#`
WHERE t1.`Series#` >= 1 AND t1.`Series#` <= 12
GROUP BY t1.`Writer`;
","
SELECT t1.col3, COUNT(t1.col2) `Episode Count`, GROUP_CONCAT(t1.col2, ' | ') `Titles`, MIN(t1.col1) `First Series#`, MAX(t1.col1) `Last Series#`, MAX(t1.col2 = '"" Total Eclipse ""') `"" Total Eclipse ""`
FROM `table_m_1764881984957_87120421_14330096_4` t1 JOIN `table_m_1764881984957_87120421_14330096_4` t2 ON t1.col0 = t2.col0
WHERE t1.col1 >= 1 AND t1.col1 <= 12
GROUP BY t1.col3;
","[('Chris Lang', 1, '"" Too Hot to Handle ""', 7.0, 7.0, 0), ('Holly Phillips', 1, '"" Sins of the Father ""', 4.0, 4.0, 0), ('John Jackson', 1, '"" The King Is Dead, Long Live the King… ""', 8.0, 8.0, 0), ('Lisa Holdsworth', 2, '"" Let the Games Commence "" | "" Bad Blood ""', 5.0, 10.0, 0), ('Michael Chaplin', 2, '"" Total Eclipse "" | "" A Dangerous Deal ""', 1.0, 9.0, 1), ('Ryan Craig', 2, '""Lost in Translation"" | "" Something Worth Fighting For , Part 1""', 3.0, 12.0, 0), ('Simon J. Ashford', 1, '"" Cause and Effect ""', 2.0, 2.0, 0), ('Timothy Prager', 2, '"" Do You Love Me? "" | "" The Enemy of My Enemy ""', 6.0, 11.0, 0)]",m_1764881984957_87120421_14330096-4,"1) Parse: compute per-Writer aggregates — count of Title, concatenated Titles with ' | ', min/max Series#, and a max-tested equality for the exact title '"" Total Eclipse ""' — after a self-join on Total# and filtering Series# 1..12. 2) Map: associate SQL fields Title, Series#, Total#, Writer and functions COUNT, GROUP_CONCAT, MIN, MAX. 3) Draft: ask for a result per Writer listing each computed column and the specific title presence check. 4) Validate: confirm the question names each aggregate, the separator, the self-join, the Series# bounds, and the grouping by Writer.",reserved,8,N/A,split_column,
"Which reactors rank highest by combined significance (Net MWe × operational years), and for each give the combined significance, suggested edition size, commemorate flag and assigned tier so I can set premium and standard model runs?",,,[],m_1764881995911_1ff7e8e4_143352-1,"I need to rank pieces for edition sizes and premium models, so the persona will ask for top reactors by combined impact using slightly technical phrasing. The SQL ranks reactors by combined_significance (Net MWe × operational_years), computes suggested edition sizes, and assigns tiers with the top two as Premium and next two as Standard. The combined_significance is derived from Net MWe and operational lifespan in the table. Draft the question to return the reactors ordered by combined significance with their combined_significance, suggested edition size, commemorate flag and tier. The query provides exactly those ranked fields for decision-making.",persona,"An independent horologist crafting a limited-edition mechanical watch series that encodes each AGR reactor's operational history and scale into dial features and edition sizes. Goals: Determine each reactor's operational lifespan (years between commercial operation and accounting closure) to use as the watch model's 'life' metric. Rank reactors by combined significance (Net MWe × operational years) to set edition sizes and premium models. Identify sites with long build-to-commission times or notable closure years to inspire design elements and launch schedules (e.g., commemorate reactors closed in 2019 or 2023). Example Queries: SELECT ""AGR Power Station"", ""Net MWe"", (""Accounting closure date"" - ""Commercial operation"") AS operational_years FROM ""table_1_143352_1"" ORDER BY operational_years DESC; SELECT ""AGR Power Station"", ""Net MWe"", (""Accounting closure date"" - ""Commercial operation"") AS operational_years, ROUND((""Net MWe"" * (""Accounting closure date"" - ""Commercial operation"")) / 1000.0) AS suggested_edition_size FROM ""table_1_143352_1"" ORDER BY suggested_edition_size DESC; SELECT ""AGR Power Station"", ""Construction started"", ""Commercial operation"", (""Commercial operation"" - ""Construction started"") AS build_to_commission_years FROM ""table_1_143352_1"" WHERE ""Accounting closure date"" IN (2019, 2023) ORDER BY build_to_commission_years DESC;",N/A,merge_column,
"List the Player, Position, Starter, Touchdowns, Extra points, Field goals, and Points for each player with Points > 0, and also include Expected Points as (Touchdowns*5 + Extra points + Field goals*5) and Mismatch as (Points - (Touchdowns*5 + Extra points + Field goals*5)), ordering the list by Points in descending order?",unanswerable,unanswerable,,m_1764882018827_df8a9166_14342480-5,"1) Parse: The SQL projects player stats and two expressions: Expected Points and Mismatch, with a Points>0 filter and ordering by Points descending. 2) Map: Columns correspond to identity, role, starter flag, scoring counts, and total Points. 3) Draft: Create a question that requests those columns and calculations and specifies the filter and sort order. 4) Validate: Ensure formulas match exactly and ordering is by Points descending.",reserved,5,N/A,remove_column,
"Considering only Finished values '1st', '2nd', and '3rd' that are not NULL, what are the Finished value, the COUNT(*) of rows, the average days calculated as AVG(replace(Exited,'Day','') - replace(Entered,'Day','')), and a SurvivalCategory which is 1 when (replace(Exited,'Day','') - replace(Entered,'Day','')) >= 14 else 0, including only groups with COUNT(*)>0 or AVG(...)>0, grouped by Finished, ordered by Average_Days descending, and limited to 5 results?","
WITH `ranks`(`1st`,`2nd`,`3rd`,`4th`,`5th`,`6th`,`7th`,`8th`,`9th`) AS (VALUES('1st','2nd','3rd','4th','5th','6th','7th','8th','9th'))
SELECT `Finished`, COUNT(*) `Count`, AVG((replace(`Exited`,'Day','') - replace(`Entered`,'Day',''))) `Average_Days`, CASE WHEN (replace(`Exited`,'Day','') - replace(`Entered`,'Day','')) >= 14 THEN 1 ELSE 0 END `SurvivalCategory`
FROM `table_m_1764882040426_bbd7527c_14345690_3` JOIN `ranks` ON 1=1
WHERE `Finished` IN (`ranks`.`1st`,`ranks`.`2nd`,`ranks`.`3rd`) AND `Finished` IS NOT NULL
GROUP BY `Finished`
HAVING COUNT(*)>0 OR AVG((replace(`Exited`,'Day','') - replace(`Entered`,'Day','')))>0
ORDER BY `Average_Days` DESC
LIMIT 5;
","
WITH `ranks`(`1st`,`2nd`,`3rd`,`4th`,`5th`,`6th`,`7th`,`8th`,`9th`) AS (VALUES('1st','2nd','3rd','4th','5th','6th','7th','8th','9th'))
SELECT col3, COUNT(*) `Count`, AVG((replace(col2,'Day','') - replace(col1,'Day',''))) `Average_Days`, CASE WHEN (replace(col2,'Day','') - replace(col1,'Day','')) >= 14 THEN 1 ELSE 0 END `SurvivalCategory`
FROM `table_m_1764882040426_bbd7527c_14345690_3` JOIN `ranks` ON 1=1
WHERE col3 IN (`ranks`.`1st`,`ranks`.`2nd`,`ranks`.`3rd`) AND col3 IS NOT NULL
GROUP BY col3
HAVING COUNT(*)>0 OR AVG((replace(col2,'Day','') - replace(col1,'Day','')))>0
ORDER BY `Average_Days` DESC
LIMIT 5;
","[('3rd', 1, 14.0, 1), ('2nd', 1, 14.0, 1), ('1st', 1, 14.0, 1)]",m_1764882040426_bbd7527c_14345690-3,"1) Parse intent: compute grouped statistics for top three finishers including count, mean stay length from Exited minus Entered after removing 'Day', and a binary survival indicator for stays >=14 days; 2) Map schema: use Finished, Entered, Exited columns and apply replace to strip 'Day'; 3) Draft: ask for Finished, COUNT(*), AVG(replace(Exited,'Day','')-replace(Entered,'Day','')), and CASE WHEN difference>=14 THEN 1 ELSE 0 for Finished in ('1st','2nd','3rd'); 4) Validate: ensure Finished is not NULL, apply HAVING COUNT(*)>0 OR AVG(...)>0, order by average days DESC and limit 5.",reserved,24,N/A,split_column,
Which economic classes have population density over 0.05 and what is their largest population?,"
SELECT DISTINCT `Economic Class` AS `Class`, COUNT(*) `Barangay Count`, SUM(`Population (2010)`) `Total Population`, SUM(`Land Area (In sqm.)`) `Total Land Area`, (SUM(`Population (2010)`)*1.0)/NULLIF(SUM(`Land Area (In sqm.)`),0) `Average Density`, MAX(`Population (2010)`) `Max Population`, MIN(`Population (2010)`) `Min Population`, CASE WHEN (SUM(`Population (2010)`)*1.0)/NULLIF(SUM(`Land Area (In sqm.)`),0) > 0.2 THEN MAX(`Population (2010)`) END, NULL
FROM `table_m_1764882106188_94376ef6_1440338_1`
WHERE `Land Area (In sqm.)`>0 AND `Population (2010)`>0
GROUP BY `Economic Class`
HAVING (SUM(`Population (2010)`)*1.0)/NULLIF(SUM(`Land Area (In sqm.)`),0) > 0.05
LIMIT 2;
","
SELECT DISTINCT col2 AS `Class`, COUNT(*) `Barangay Count`, SUM(col1) `Total Population`, SUM(col3) `Total Land Area`, (SUM(col1)*1.0)/NULLIF(SUM(col3),0) `Average Density`, MAX(col1) `Max Population`, MIN(col1) `Min Population`, CASE WHEN (SUM(col1)*1.0)/NULLIF(SUM(col3),0) > 0.2 THEN MAX(col1) END, NULL
FROM `table_m_1764882106188_94376ef6_1440338_1`
WHERE col3>0 AND col1>0
GROUP BY col2
HAVING (SUM(col1)*1.0)/NULLIF(SUM(col3),0) > 0.05
LIMIT 2;
","[('Rural', 76, 98959.0, 91656.0, 1.0796783625730995, 4331.0, 170.0, 4331.0, None), ('Urban', 14, 37689.0, 85985.0, 0.4383206373204629, 6524.0, 650.0, 6524.0, None)]",m_1764882106188_94376ef6_1440338-1,"STEP 1: Parse the SQL intent — group rows by Economic Class for barangays with positive land area and population; compute per-class barangay count, total population (SUM), total land area (SUM), average density (=SUM(pop)/SUM(area)), max and min barangay population; keep only classes whose average density > 0.05 and return up to 2 classes. STEP 2: Determine ambiguity type — attachment ambiguity fits: a phrase like ""largest population"" can attach to either the class as a whole (total population) or to an individual barangay within the class (maximum barangay population). This maps well because the query computes both SUM and MAX but a simple NL phrasing could refer to either. STEP 3: Draft the question — ""Which economic classes have population density over 0.05 and what is their largest population?"" STEP 4: Explain the ambiguity — the original query interprets ""largest population"" as the maximum single-barangay population within each class (it also computes total population), but a reader could instead interpret ""largest population"" to mean the total population of the entire economic class; additionally, the SQL filters by average density (>0.05) and returns only up to two classes, which is not explicit in the NL phrasing.",reserved,15,N/A,split_column,"type: Attachment ambiguity | explanation: The phrase ""largest population"" can attach to (a) the class as a whole (total population = SUM of barangays) or (b) an individual barangay within the class (max barangay population = MAX); the SQL returns per-class SUM and MAX but a reader of the question could reasonably mean either interpretation."
"Give me the full list of competitors with name, nationality, first and second jump lengths, the jump difference, points, their nation's average points and athlete count, parsed NT and WC ranks and a flag where they differ, ordered by jump difference (largest first) and then by national average points.","
WITH parsed AS (
  SELECT
    `Rank`,
    `Name`,
    `Nationality`,
    CAST(`1st (m)` AS REAL) AS `1st_m_num`,
    CAST(`2nd (m)` AS REAL) AS `2nd_m_num`,
    CAST(`Points` AS REAL) AS `Points_num`,
    `Overall NT points`,
    `Overall WC points (Rank)`,
    ABS(CAST(`1st (m)` AS REAL) - CAST(`2nd (m)` AS REAL)) AS `jump_diff_m`,
    CAST(
      substr(
        `Overall NT points`,
        instr(`Overall NT points`, '(') + 1,
        instr(`Overall NT points`, ')') - instr(`Overall NT points`, '(') - 1
      ) AS INTEGER
    ) AS `NT_rank`,
    CAST(
      substr(
        `Overall WC points (Rank)`,
        instr(`Overall WC points (Rank)`, '(') + 1,
        instr(`Overall WC points (Rank)`, ')') - instr(`Overall WC points (Rank)`, '(') - 1
      ) AS INTEGER
    ) AS `WC_rank`
  FROM `table_m_1764882112041_55654f33_14407512_23`
)
SELECT
  `Name`,
  `Nationality`,
  `1st_m_num` AS `1st (m)`,
  `2nd_m_num` AS `2nd (m)`,
  `jump_diff_m`,
  `Points_num` AS `Points`,
  ROUND(AVG(`Points_num`) OVER (PARTITION BY `Nationality`), 3) AS `avg_points_by_nation`,
  COUNT(*) OVER (PARTITION BY `Nationality`) AS `athlete_count_by_nation`,
  `NT_rank`,
  `WC_rank`,
  CASE WHEN `NT_rank` IS NOT NULL AND `WC_rank` IS NOT NULL AND `NT_rank` <> `WC_rank` THEN 1 ELSE 0 END AS `NT_WC_rank_mismatch`
FROM parsed
ORDER BY `jump_diff_m` DESC, `avg_points_by_nation` DESC;
","
WITH parsed AS (
  SELECT
    col0,
    col1,
    col2,
    CAST(col3 AS REAL) AS `1st_m_num`,
    CAST(col4 AS REAL) AS `2nd_m_num`,
    CAST(col5 AS REAL) AS `Points_num`,
    col6,
    col7,
    ABS(CAST(col3 AS REAL) - CAST(col4 AS REAL)) AS `jump_diff_m`,
    CAST(
      substr(
        col6,
        instr(col6, '(') + 1,
        instr(col6, ')') - instr(col6, '(') - 1
      ) AS INTEGER
    ) AS `NT_rank`,
    CAST(
      substr(
        col7,
        instr(col7, '(') + 1,
        instr(col7, ')') - instr(col7, '(') - 1
      ) AS INTEGER
    ) AS `WC_rank`
  FROM `table_m_1764882112041_55654f33_14407512_23`
)
SELECT
  col1,
  col2,
  `1st_m_num` AS col3,
  `2nd_m_num` AS col4,
  `jump_diff_m`,
  `Points_num` AS col5,
  ROUND(AVG(`Points_num`) OVER (PARTITION BY col2), 3) AS `avg_points_by_nation`,
  COUNT(*) OVER (PARTITION BY col2) AS `athlete_count_by_nation`,
  `NT_rank`,
  `WC_rank`,
  CASE WHEN `NT_rank` IS NOT NULL AND `WC_rank` IS NOT NULL AND `NT_rank` <> `WC_rank` THEN 1 ELSE 0 END AS `NT_WC_rank_mismatch`
FROM parsed
ORDER BY `jump_diff_m` DESC, `avg_points_by_nation` DESC;
","[('Gregor Schlierenzauer', 'AUT', 114.5, 129.0, 14.5, 236.8, 236.8, 1, 3, 2, 1), ('Anders Bardal', 'NOR', 117.5, 128.0, 10.5, 240.4, 238.8, 2, 5, 5, 0), ('Janne Happonen', 'FIN', 118.0, 125.5, 7.5, 236.3, 242.3, 2, 1, 11, 1), ('Janne Ahonen', 'FIN', 122.5, 126.0, 3.5, 248.3, 242.3, 2, 2, 3, 1), ('Tom Hilde', 'NOR', 121.5, 122.5, 1.0, 237.2, 238.8, 2, 4, 4, 0)]",m_1764882112041_55654f33_14407512-23,"In my voice I'd request a sorted list that highlights inconsistent jumpers first while also showing national averages to judge setup tolerances and coaching effects. The SQL orders by jump difference descending then by the nation's average points descending and returns detailed per-athlete info including parsed ranks and mismatch flag. The relevant columns are Name, Nationality, 1st (m), 2nd (m), computed jump_diff_m, Points, avg points by nation, athlete count by nation, NT_rank, WC_rank and NT_WC_rank_mismatch. I would ask for the full roster with those fields sorted by jump variability then national average so I can pick candidates for historical case studies. This mirrors the query's selection and ordering.",persona,"A retired World Cup ski-suit tailor turned data-obsessed historical reconstructor who uses past event tables to re-create period-accurate jump equipment and tuning notes. Goals: Identify athletes with the largest within-competition jump variability to infer which suits or setups tolerated inconsistent conditions (useful for reconstructing adjustable rigging). Compare average competition points by nationality to detect national setup patterns or coaching effects that might influence suit design choices. Find cases where the 'Overall NT points' ranking (national-tour influenced) differs from the 'Overall WC points' ranking to spot jumpers who excelled domestically but underperformed internationally—candidates for tailored historical case studies. Example Queries: SELECT Name, Nationality, ""1st (m)"", ""2nd (m)"", ABS(CAST(""1st (m)"" AS REAL) - CAST(""2nd (m)"" AS REAL)) AS jump_diff
FROM table_1_14407512_23
ORDER BY jump_diff DESC
LIMIT 5; SELECT Nationality, AVG(CAST(Points AS REAL)) AS avg_points, COUNT(*) AS athlete_count
FROM table_1_14407512_23
GROUP BY Nationality
ORDER BY avg_points DESC; SELECT Name, ""Overall NT points"", ""Overall WC points (Rank)"",
       CAST(REGEXP_REPLACE(""Overall NT points"", '.*\((\d+)\).*', '\1') AS INTEGER) AS NT_rank,
       CAST(REGEXP_REPLACE(""Overall WC points (Rank)"", '.*\((\d+)\).*', '\1') AS INTEGER) AS WC_rank
FROM table_1_14407512_23
WHERE CAST(REGEXP_REPLACE(""Overall NT points"", '.*\((\d+)\).*', '\1') AS INTEGER) <> CAST(REGEXP_REPLACE(""Overall WC points (Rank)"", '.*\((\d+)\).*', '\1') AS INTEGER);",N/A,add_column,
"Using only competitors with 1st (m) >= 200.0 and 2nd (m) >= 200.0, which top three Nationalities (ordered by Avg_points_per_m = AVG(Points/((1st (m) + 2nd (m)))) descending) have the following per-nationality values: Competitors (COUNT(*)), Avg_total_m (AVG((1st (m) + 2nd (m)))), Avg_points (AVG(Points)), Gregor Schlierenzauer (MAX(Points)), Worst_points (MIN(Points)) and Potential_gain (AVG(Points) - MIN(Points)), considering only nationalities with at least one competitor?","
SELECT `Nationality`, COUNT(*) AS `Competitors`, AVG((`1st (m)` + `2nd (m)`)) AS `Avg_total_m`, AVG(`Points`) AS `Avg_points`, AVG(`Points`/((`1st (m)` + `2nd (m)`))) AS `Avg_points_per_m`, MAX(`Points`) AS `Gregor Schlierenzauer`, MIN(`Points`) AS `Worst_points`, (AVG(`Points`) - MIN(`Points`)) AS `Potential_gain` FROM `table_m_1764882129305_20de1b01_14407512_27` WHERE `1st (m)` >= 200.0 AND `2nd (m)` >= 200.0 GROUP BY `Nationality` HAVING COUNT(*) > 0 ORDER BY `Avg_points_per_m` DESC LIMIT 3;
","
SELECT col2, COUNT(*) AS `Competitors`, AVG((col3 + col4)) AS `Avg_total_m`, AVG(col5) AS `Avg_points`, AVG(col5/((col3 + col4))) AS `Avg_points_per_m`, MAX(col5) AS `Gregor Schlierenzauer`, MIN(col5) AS `Worst_points`, (AVG(col5) - MIN(col5)) AS `Potential_gain` FROM `table_m_1764882129305_20de1b01_14407512_27` WHERE col3 >= 200.0 AND col4 >= 200.0 GROUP BY col2 HAVING COUNT(*) > 0 ORDER BY `Avg_points_per_m` DESC LIMIT 3;
","[('SLO', 1, 425.0, 418.5, 0.9847058823529412, '418.5', '418.5', 0.0), ('AUT', 2, 447.0, 438.65, 0.9813075552530429, '442.1', '435.2', 3.4499999999999886), ('FIN', 2, 416.25, 408.0, 0.9800368351770168, '418.8', '397.2', 10.800000000000011)]",m_1764882129305_20de1b01_14407512-27,"1) Parse intent: filter rows by jump thresholds, compute multiple aggregates per nationality, and pick the top three by efficiency. 2) Map schema: include Nationality and computed fields Competitors, Avg_total_m, Avg_points, Avg_points_per_m, Gregor Schlierenzauer, Worst_points, Potential_gain. 3) Draft: frame a question requesting these fields with the same WHERE, GROUP BY, HAVING, ORDER BY and LIMIT conditions. 4) Validate: confirm inclusion of all columns, calculations, and constraints from the query.",reserved,9,N/A,split_column,
"List the Team and a computed status that returns 'Below' if that team's Average is below the AVG of the Average column across all rows, for records where Played >= 100 and Points < 130, grouped by Team with HAVING COUNT(*) = 1, ordered by status descending and limited to five rows?",unanswerable,unanswerable,,m_1764882148266_9efa5e8a_14489821-1,"1) Parse the SQL intent: produce Team and a CASE status 'Below' if Average < AVG(Average) over all rows, constrained by Played >= 100 and Points < 130, with GROUP BY Team HAVING COUNT(*) = 1, ORDER BY status DESC, LIMIT 5. 2) Map schema semantics: Average is compared to the global mean of Average; Team, Played and Points are used as filters. 3) Draft the question: ask for the Team and computed 'Below' status under those conditions and grouping constraints. 4) Validate: confirms inclusion of the AVG comparison, filters, grouping/having, ordering and row limit.",reserved,16,N/A,remove_column,
"Who are the top five directors by Episodes (COUNT(No. in series)) when considering only rows with Production code BETWEEN 101 AND 119 and No. in series >= 1, and for each Directed by show Episodes = COUNT(No. in series), UniqueTitles = COUNT(DISTINCT Title), and a literal 0 AS ""Unaired Pilot"", grouping by Directed by and including only directors with more than one episode?",unanswerable,unanswerable,,m_1764882187018_108b7ec4_14562722-1,"1) Parse SQL intent: return director-level aggregates for a constrained set of episodes and limit to five directors with more than one episode. 2) Map schema semantics: include Directed by, Episodes as COUNT(No. in series), UniqueTitles as COUNT(DISTINCT Title), and a constant 0 column named '""Unaired Pilot""'. 3) Draft the question: require WHERE Production code BETWEEN 101 AND 119 and No. in series >= 1, GROUP BY Directed by, HAVING COUNT(No. in series) > 1, ORDER BY Episodes DESC, LIMIT 5. 4) Validate: question mirrors the SQL selection, aggregation, filters, grouping, having, ordering and limit.",reserved,16,N/A,merge_column,
"Considering only rows where # > 0, what are the top 5 Nature of Situation groups by COUNT(*) AS ""Aircraft crash"" (ordered descending), and for each group what is the Nature of Situation, the count labeled ""Aircraft crash"", the MIN(Original U.S. Airdate) reported as ""First Airdate"", the MAX(Original U.S. Airdate) reported as ""Last Airdate"", and the GROUP_CONCAT of Episode Title separated by '; ' shown as ""Episodes""?","
SELECT `Nature of Situation`, COUNT(*) AS `Aircraft crash`, MIN(`Original U.S. Airdate`) AS `First Airdate`, MAX(`Original U.S. Airdate`) AS `Last Airdate`, GROUP_CONCAT(`Episode Title`, '; ') AS `Episodes` FROM `table_m_1764882192066_07e099bf_14570857_1` WHERE `#` > 0 GROUP BY `Nature of Situation` ORDER BY `Aircraft crash` DESC LIMIT 5;
","
SELECT col4, COUNT(*) AS `Aircraft crash`, MIN(col5) AS `First Airdate`, MAX(col5) AS `Last Airdate`, GROUP_CONCAT(col1, '; ') AS `Episodes` FROM `table_m_1764882192066_07e099bf_14570857_1` WHERE col0 > 0 GROUP BY col4 ORDER BY `Aircraft crash` DESC LIMIT 5;
","[('ed Flood hospital', 1, 'December 5, 2007', 'December 5, 2007', 'Hurricane Hospital'), ('Train derailment', 1, 'November 21, 2007', 'November 21, 2007', 'Osaka Train Wreck'), ('Earthquake victim rescue', 1, 'November 28, 2007', 'November 28, 2007', 'Earthquake Rapid Response'), ('Disabled ship', 1, 'November 14, 2007', 'November 14, 2007', 'Ocean Emergency'), ('Aircraft crash', 1, 'November 7, 2007', 'November 7, 2007', 'Alive in the Andes')]",m_1764882192066_07e099bf_14570857-1,"1) Parse SQL intent: compute per-Nature of Situation aggregates (count, min/max airdate, concatenated titles), limit to five groups by descending count, excluding rows with # <= 0. 2) Map schema semantics: map COUNT(*)→Aircraft crash, MIN/MAX(Original U.S. Airdate)→First/Last Airdate, GROUP_CONCAT(Episode Title, '; ')→Episodes. 3) Draft the question to include all these exact column names, aliases, filter, grouping, ordering, and limit. 4) Validate completeness against the SQL: every column and calculation appears in the question.",reserved,8,N/A,add_column,
"Give the top 10 Class A values and their total_wins (COUNT(*) AS total_wins), excluding empty Class A values, grouping by Class A and ordering the groups by total_wins in descending order?","
SELECT `Class A`, COUNT(*) total_wins FROM `table_m_1764882223216_96bc0f33_14603057_2` WHERE `Class A` != '' GROUP BY `Class A` ORDER BY total_wins DESC LIMIT 10;
","
SELECT col1, COUNT(*) total_wins FROM `table_m_1764882223216_96bc0f33_14603057_2` WHERE col1 != '' GROUP BY col1 ORDER BY total_wins DESC LIMIT 10;
","[('Rule', 4), ('Plains', 4), ('Valley View', 2), ('San Isidro', 2), ('Nazareth', 2), ('Henrietta Midway', 2), ('Garden City', 2), ('Westbrook', 1), ('Sterling City', 1), ('Poolville', 1)]",m_1764882223216_96bc0f33_14603057-2,"Parse intent: return counts per Class A (COUNT(*) AS total_wins) for non-empty Class A, sorted descending and limited to 10. Map schema: 'Class A' is the grouping column and total_wins is the aggregated count. Draft: request top 10 Class A values and their total_wins with specified filters and ordering. Validate: ensure the question references Class A, total_wins (COUNT(*)), exclusion of empty values, grouping by Class A, ordering by total_wins DESC, and limit 10.",reserved,8,N/A,add_column,
"List up to 10 Networks with COUNT(DISTINCT Call sign) AS Station Count and SUM(Physical) AS Physical Total considering only rows where Physical > 0 and Virtual >= 0, grouping by Network and ordered by Physical Total in descending order?","
SELECT `Network`, COUNT(DISTINCT `Call sign`) AS `Station Count`, SUM(`Physical`) `Physical Total`
FROM `table_m_1764882235740_702703ae_14623167_1`
WHERE `Physical` > 0 AND `Virtual` >= 0
GROUP BY `Network`
HAVING 1
ORDER BY `Physical Total` DESC
LIMIT 10;
","
SELECT col4, COUNT(DISTINCT col2) AS `Station Count`, SUM(col1) `Physical Total`
FROM `table_m_1764882235740_702703ae_14623167_1`
WHERE col1 > 0 AND col0 >= 0
GROUP BY col4
HAVING 1
ORDER BY `Physical Total` DESC
LIMIT 10;
","[('NBC', 1, 31.0), ('Fox', 1, 26.0), ('PBS', 1, 22.0), ('ABC', 1, 17.0), ('CBS', 1, 12.0)]",m_1764882235740_702703ae_14623167-1,"1) The SQL computes per-Network aggregates (distinct station count and sum of Physical) after filtering Physical > 0 and Virtual >= 0, then sorts by the summed Physical and returns up to 10 groups. 2) Schema mapping: Network groups, Call sign counted distinctly, Physical summed. 3) Draft a question that requests Network plus the two aggregate metrics with the exact filters, grouping, sort, and limit. 4) Ensure wording includes COUNT(DISTINCT Call sign) AS Station Count and SUM(Physical) AS Physical Total explicitly.",reserved,14,N/A,add_column,
"For each Written by value (as Writer) who wrote more than one episode with No. in series between 53 and 64 inclusive, return Writer, the EpisodeCount (COUNT of episodes), FirstNo (MIN of No. in series), LastNo (MAX of No. in series), Broadcasts (all TV broadcast values concatenated with "", ""), and All Titles including '""Virtual Unreality""' (all Title values concatenated with "" | ""), limiting the output to 10 rows.",unanswerable,unanswerable,,m_1764882268265_bc105a56_14637853-3,"1) The SQL groups rows by `Written by` for series numbers between 53 and 64, computing COUNT(*), MIN(No. in series), MAX(No. in series), and two group_concats; it then keeps groups with COUNT(*) > 1 and limits to 10. 2) Map headers: `Written by` -> writer, `No. in series` for min/max, `TV broadcast` and `Title` for concatenation, and rows 53–64 constraint. 3) Draft a question that requests Writer, EpisodeCount, FirstNo, LastNo, Broadcasts (comma-separated), and All Titles including '""Virtual Unreality""' (pipe-separated) for writers with more than one episode in that range, up to 10 results. 4) Validate that the question includes every selected column, calculation, filter, grouping, having, and limit from the SQL.",reserved,9,N/A,remove_column,
"Which Positions have more than one entry, and for each such Position provide the Position, the Count of entries for that Position, the Earliest Pick number (minimum Pick # for that Position), and Players (all Player values concatenated), returning only the record where Pick # equals that Earliest Pick?",unanswerable,unanswerable,,m_1764882283115_72c0236c_14650373-1,"1) Parse intent: report positions with multiple players and summarize pick and player info by the earliest pick per position. 2) Map schema: Position groups use Pick # for earliest and Player for the concatenated list. 3) Draft the question: request Position, Count of entries for that Position, Earliest Pick (MIN Pick #), and Players (GROUP_CONCAT of Player) but limit to Positions whose count > 1 and to the row whose Pick # equals that minimum. 4) Validate: all columns and calculations (Count, MIN Pick #, GROUP_CONCAT Players) and the >1 and MIN-based row constraint are included.",reserved,4,N/A,merge_column,
"For each type of Obamacare exchange, which states contribute the most and the least per person, and what are the average net contribution per person and the total population for those exchange types among states with more than one million people?","
WITH `clean` AS (
 SELECT `State`, CAST(REPLACE(REPLACE(REPLACE(`Net contribution per capita`,'$',''),',',''),'$','') AS REAL) AS `netpc`, `Population`, `Obamacare: Fed/ State/ Partnership`
 FROM `table_m_1764882292158_3e20b9d7_14700336_1`
)
SELECT c.`Obamacare: Fed/ State/ Partnership` AS `aca_type`,
 COUNT(*) AS `count_states`,
 SUM(`Population`) AS `total_pop`,
 AVG(`netpc`) AS `avg_netpc`,
 (SELECT `State` FROM `clean` WHERE `Obamacare: Fed/ State/ Partnership` = c.`Obamacare: Fed/ State/ Partnership` ORDER BY `netpc` DESC LIMIT 1) AS `top_contributor`,
 (SELECT `State` FROM `clean` WHERE `Obamacare: Fed/ State/ Partnership` = c.`Obamacare: Fed/ State/ Partnership` ORDER BY `netpc` ASC LIMIT 1) AS `top_receiver`
FROM `clean` c
WHERE `Population` > 1000000
GROUP BY c.`Obamacare: Fed/ State/ Partnership`
HAVING COUNT(*)>1
ORDER BY `avg_netpc` DESC
LIMIT 10;
","
WITH `clean` AS (
 SELECT col1, CAST(REPLACE(REPLACE(REPLACE(col7,'$',''),',',''),'$','') AS REAL) AS `netpc`, col3, col11
 FROM `table_m_1764882292158_3e20b9d7_14700336_1`
)
SELECT c.col11 AS `aca_type`,
 COUNT(*) AS `count_states`,
 SUM(col3) AS `total_pop`,
 AVG(`netpc`) AS `avg_netpc`,
 (SELECT col1 FROM `clean` WHERE col11 = c.col11 ORDER BY `netpc` DESC LIMIT 1) AS `top_contributor`,
 (SELECT col1 FROM `clean` WHERE col11 = c.col11 ORDER BY `netpc` ASC LIMIT 1) AS `top_receiver`
FROM `clean` c
WHERE col3 > 1000000
GROUP BY c.col11
HAVING COUNT(*)>1
ORDER BY `avg_netpc` DESC
LIMIT 10;
","[('partnership', 7, 40560996.0, 656.0, 'Delaware', 'West Virginia'), ('state-based', 15, 104313760.0, 611.1333333333333, 'Minnesota', 'District of Columbia'), ('federal-based', 20, 148426663.0, -1329.8, 'Nebraska', 'Alaska')]",m_1764882292158_3e20b9d7_14700336-1,"STEP 1: Parse the SQL intent: the query cleans Net contribution per capita to a numeric, filters rows with Population > 1,000,000, groups rows by Obamacare exchange type, keeps groups with more than one state, and for each group returns count of states, sum of Population, average net contribution per capita, the state with the highest net contribution per capita, and the state with the lowest net contribution per capita; results ordered by avg_netpc desc and limited to 10. STEP 2: Determine ambiguity type: Entity vagueness fits well — phrases like “contribute the most” can refer to per-capita contribution (what the SQL uses) or to total contribution (netpc * population), so the natural language can be read in multiple valid ways. STEP 3: Draft the question: ""For each type of Obamacare exchange, which states contribute the most and the least per person, and what are the average net contribution per person and the total population for those exchange types among states with more than one million people?"" STEP 4: Explain the ambiguity: in the original query ""contribute the most/least per person"" is implemented as net contribution per capita and averages are computed over the >1M population subset per exchange type; an alternative interpretation of the NL could treat ""contribute the most"" as highest total contribution (netpc * population) or could scope the population filter or the aggregates differently (e.g., apply ""more than one million"" only to listed states but not to averages).",reserved,36,N/A,add_column,"type: Entity Vagueness | explanation: The phrase ""contribute the most"" can mean per-capita (net contribution per person, which the SQL uses) or total contribution (net contribution per capita multiplied by population); additionally, the placement of the ""more than one million people"" constraint could be interpreted as applying to which parts of the question (only the listed states vs. all aggregated measures)."
Which NHL teams had Canadian picks and how many picks did they have?,unanswerable,unanswerable,,m_1764882323674_babb0527_1473672-9,"STEP 1: Parse the SQL intent — group rows by NHL team, return each team (limited to 5), the total number of picks per team (COUNT(*)) , a comma-joined list of Positions, the number of picks whose Nationality = 'Canada' (SUM(...)), and a comma-joined list of Players; only include rows where Player <> '' and groups with at least one pick. STEP 2: Determine ambiguity type — attachment ambiguity fits well because the natural-language modifier ""Canadian"" or the phrase ""how many picks"" can attach to different parts of the question (the team, the picks, or the players), creating multiple plausible readings while the SQL actually provides both total picks and Canadian-pick counts. STEP 3: Draft the question — ""Which NHL teams had Canadian picks and how many picks did they have?"" STEP 4: Explain the ambiguity — in the original query the result includes both total picks and the number of Canadian picks per team, so the question could be read as asking (a) which teams had at least one Canadian player and how many total picks those teams made, (b) which teams had Canadian picks and how many of those picks were Canadian, or (c) which teams (that are Canadian) made how many picks; the SQL corresponds to interpretation (a) and (b) because it returns both total picks and Canadian picks counts, but the plain question is ambiguous about which count is requested.",reserved,9,N/A,merge_column,"type: Attachment ambiguity | explanation: The phrase ""Canadian picks"" can attach to the teams (teams that had Canadian players) while ""how many picks"" can refer either to the teams' total picks or to the number of those picks that were Canadian; the SQL returns both totals and Canadian counts per team, but the natural language question doesn't make clear which count is intended (or whether ""Canadian"" might instead modify the teams themselves)."
"Which boroughs had the largest total Victorian station usage in 2008–09, and what were their top-growing Victorian stations (with at least two platforms)?","
WITH `normalized` AS (
  SELECT
    `Station (and code)` AS station,
    `Borough` AS borough,
    CAST(substr(`Year opened`,1,4) AS INTEGER) AS year_opened,
    CAST(substr(`Platforms`,1,1) AS INTEGER) AS platforms_num,
    CASE WHEN typeof(`Station users 2007_08_and_2008_09`) IN ('integer','real') THEN CAST(`Station users 2007_08_and_2008_09` AS INTEGER) END AS users07,
    CASE WHEN typeof(`Station users 2007_08_and_2008_09`) IN ('integer','real') THEN CAST(`Station users 2007_08_and_2008_09` AS INTEGER) END AS users08,
    CASE 
      WHEN typeof(`Station users 2007_08_and_2008_09`) IN ('integer','real') 
       AND typeof(`Station users 2007_08_and_2008_09`) IN ('integer','real') 
       AND CAST(`Station users 2007_08_and_2008_09` AS INTEGER) != 0
      THEN (CAST(`Station users 2007_08_and_2008_09` AS FLOAT) - CAST(`Station users 2007_08_and_2008_09` AS FLOAT))
           / CAST(`Station users 2007_08_and_2008_09` AS FLOAT) * 100
    END AS pct_change
  FROM `table_m_1764882342371_ca185436_14748457_1`
)
SELECT
  n.borough AS `Borough`,
  COUNT(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 THEN 1 END) AS `victorian_station_count`,
  SUM(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.platforms_num >= 2 THEN 1 ELSE 0 END) AS `stations_with_2plus_platforms`,
  SUM(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.users08 IS NOT NULL THEN n.users08 ELSE 0 END) AS `total_victorian_users_2008_9`,
  AVG(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.pct_change IS NOT NULL THEN n.pct_change END) AS `avg_pct_change_victorian`,
  COUNT(CASE WHEN n.year_opened < 1850 AND n.users08 IS NOT NULL AND n.users08 < 50000 THEN 1 END) AS `low_usage_pre1850_count`,
  (SELECT GROUP_CONCAT(sub.station, '; ')
     FROM (
       SELECT station, pct_change
       FROM `normalized`
       WHERE year_opened BETWEEN 1837 AND 1901
         AND platforms_num >= 2
         AND pct_change IS NOT NULL
         AND borough = n.borough
       ORDER BY pct_change DESC
       LIMIT 3
     ) AS sub
  ) AS `top_3_high_growth_candidates`
FROM `normalized` AS n
GROUP BY n.borough
HAVING COUNT(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 THEN 1 END) > 0
ORDER BY `total_victorian_users_2008_9` DESC;
","
WITH `normalized` AS (
  SELECT
    col0 AS station,
    col5 AS borough,
    CAST(substr(col3,1,4) AS INTEGER) AS year_opened,
    CAST(substr(col4,1,1) AS INTEGER) AS platforms_num,
    CASE WHEN typeof(col6) IN ('integer','real') THEN CAST(col6 AS INTEGER) END AS users07,
    CASE WHEN typeof(col6) IN ('integer','real') THEN CAST(col6 AS INTEGER) END AS users08,
    CASE 
      WHEN typeof(col6) IN ('integer','real') 
       AND typeof(col6) IN ('integer','real') 
       AND CAST(col6 AS INTEGER) != 0
      THEN (CAST(col6 AS FLOAT) - CAST(col6 AS FLOAT))
           / CAST(col6 AS FLOAT) * 100
    END AS pct_change
  FROM `table_m_1764882342371_ca185436_14748457_1`
)
SELECT
  n.borough AS col5,
  COUNT(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 THEN 1 END) AS `victorian_station_count`,
  SUM(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.platforms_num >= 2 THEN 1 ELSE 0 END) AS `stations_with_2plus_platforms`,
  SUM(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.users08 IS NOT NULL THEN n.users08 ELSE 0 END) AS `total_victorian_users_2008_9`,
  AVG(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 AND n.pct_change IS NOT NULL THEN n.pct_change END) AS `avg_pct_change_victorian`,
  COUNT(CASE WHEN n.year_opened < 1850 AND n.users08 IS NOT NULL AND n.users08 < 50000 THEN 1 END) AS `low_usage_pre1850_count`,
  (SELECT GROUP_CONCAT(sub.station, '; ')
     FROM (
       SELECT station, pct_change
       FROM `normalized`
       WHERE year_opened BETWEEN 1837 AND 1901
         AND platforms_num >= 2
         AND pct_change IS NOT NULL
         AND borough = n.borough
       ORDER BY pct_change DESC
       LIMIT 3
     ) AS sub
  ) AS `top_3_high_growth_candidates`
FROM `normalized` AS n
GROUP BY n.borough
HAVING COUNT(CASE WHEN n.year_opened BETWEEN 1837 AND 1901 THEN 1 END) > 0
ORDER BY `total_victorian_users_2008_9` DESC;
","[('Wigan', 8, 8, 0, None, 0, None), ('Trafford', 4, 4, 0, None, 0, None), ('Tameside', 8, 8, 0, None, 0, None), ('Stockport', 11, 9, 0, None, 0, None), ('Salford', 5, 5, 0, None, 0, None), ('Rochdale', 3, 3, 0, None, 0, None), ('Oldham', 1, 1, 0, None, 0, None), ('Manchester', 5, 5, 0, None, 0, None), ('Bolton', 7, 7, 0, None, 0, None)]",m_1764882342371_ca185436_14748457-1,"STEP 1: Parse the SQL intent — The query groups stations by borough and, for Victorian stations (year_opened BETWEEN 1837 AND 1901), computes per-borough: count of Victorian stations, count of Victorian stations with 2+ platforms, total 2008/9 users (sum of users08), average percent change (pct_change) for Victorian stations, a count of low-usage pre-1850 stations, and a semicolon-concatenated list of the top 3 Victorian stations in that borough (filtered to platforms_num >= 2 and pct_change IS NOT NULL) ordered by pct_change desc. Results are limited to boroughs that have at least one Victorian station and ordered by total Victorian users desc. STEP 2: Determine fitting ambiguity type — Attachment ambiguity fits well because the query applies the ""platforms_num >= 2"" restriction only to the subquery that returns the top-3 station names, while other aggregates (counts, sums, averages) apply to all Victorian stations. A natural question that mentions ""stations with at least two platforms"" and ""top-growing stations"" can be read as attaching that restriction to different parts of the request. STEP 3: Draft the question — ""Which boroughs had the largest total Victorian station usage in 2008–09, and what were their top-growing Victorian stations (with at least two platforms)?"" STEP 4: Explain the ambiguity — In the original query the parenthetical ""with at least two platforms"" applies only to the subquery that selects the top-3 station names (i.e., the top-growing candidates are restricted to Victorian stations with >=2 platforms), whereas the borough-level totals, counts and averages include all Victorian stations regardless of platform count. The phrasing of the drafted question is ambiguous because a reader might instead interpret ""with at least two platforms"" as applying to all parts of the request (so all aggregates would be computed only over Victorian stations with >=2 platforms), or might interpret ""top-growing"" as referring to absolute user-number growth rather than the percent change used in the query.",persona,"A steampunk festival organiser and set designer who scouts Victorian-era Greater Manchester railway stations for atmospheric outdoor stages and parade routes. Goals: Identify stations opened in the Victorian era (to match the festival's aesthetic) that have enough platforms/space to host small stages or parades. Prioritise stations showing recent increases in passenger numbers (footfall) so events attract passers-by, while also flagging low-usage historic sites suitable for intimate, ticketed performances. Map likely boroughs for a multi-site festival, estimating total station footfall per borough to plan logistics, permits and promotional focus. Example Queries: -- 1) Victorian stations (1837–1901) with 2+ platforms, ranked by recent % change in users (2007/8 -> 2008/9)
SELECT ""Station (and code)"", ""Year opened"", ""Platforms"", ""Borough"",
  (CAST(""Station users 2008/9"" AS FLOAT) - CAST(""Station users 2007/8"" AS FLOAT))
    / NULLIF(CAST(""Station users 2007/8"" AS FLOAT),0) * 100 AS pct_change
FROM ""table_1_14748457_1""
WHERE CAST(""Year opened"" AS INTEGER) BETWEEN 1837 AND 1901
  AND (""Platforms"" LIKE '2%' OR ""Platforms"" LIKE '3%')
  AND ""Station users 2008/9"" NOT IN ('No data','')
ORDER BY pct_change DESC
LIMIT 20; -- 2) Historic (pre-1850) stations with low 2008/9 usage (<50,000) for intimate ticketed pop-ups
SELECT ""Station (and code)"", ""Year opened"", ""Platforms"", ""Borough"", ""Station users 2008/9""
FROM ""table_1_14748457_1""
WHERE CAST(""Year opened"" AS INTEGER) < 1850
  AND ""Station users 2008/9"" NOT IN ('No data','')
  AND CAST(""Station users 2008/9"" AS INTEGER) < 50000
ORDER BY CAST(""Station users 2008/9"" AS INTEGER) ASC; -- 3) Borough-level total 2008/9 footfall and station counts to choose where to concentrate festival sites
SELECT ""Borough"",
  SUM(CAST(NULLIF(""Station users 2008/9"", 'No data') AS INTEGER)) AS total_users_2008_9,
  COUNT(*) AS station_count
FROM ""table_1_14748457_1""
GROUP BY ""Borough""
ORDER BY total_users_2008_9 DESC;",N/A,merge_column,"type: Attachment ambiguity | explanation: The phrase ""with at least two platforms"" can attach to the list of top-growing stations (as in the original query's subquery) or to the borough-level aggregates (counts, totals, averages), changing which stations are counted for totals and averages; additionally ""top-growing"" could be read as percent change (as used) or absolute user change, creating a further measurement ambiguity."
"For each Dialect (shown backticked), what is the Track Count, the average length in seconds rounded to 2 decimals (where Length is converted from minutes:seconds as minutes*60 + seconds), and the Total Length Seconds, considering only tracks whose converted length is greater than 270 seconds?","
SELECT printf('`%s`', `Dialect`) `Dialect Backticked`, COUNT(*) `Track Count`, ROUND(AVG((substr(`Length`,1,instr(`Length`,':')-1)-0)*60 + (substr(`Length`,instr(`Length`,':')+1)-0)),2) `Avg Length Seconds`, SUM((substr(`Length`,1,instr(`Length`,':')-1)-0)*60 + (substr(`Length`,instr(`Length`,':')+1)-0)) `Total Length Seconds` FROM `table_m_1764882352325_fd1ddcc5_14778650_1` WHERE (substr(`Length`,1,instr(`Length`,':')-1)-0)*60 + (substr(`Length`,instr(`Length`,':')+1)-0) > 270 GROUP BY `Dialect`;
","
SELECT printf('`%s`', col6) `Dialect Backticked`, COUNT(*) `Track Count`, ROUND(AVG((substr(col2,1,instr(col2,':')-1)-0)*60 + (substr(col2,instr(col2,':')+1)-0)),2) `Avg Length Seconds`, SUM((substr(col2,1,instr(col2,':')-1)-0)*60 + (substr(col2,instr(col2,':')+1)-0)) `Total Length Seconds` FROM `table_m_1764882352325_fd1ddcc5_14778650_1` WHERE (substr(col2,1,instr(col2,':')-1)-0)*60 + (substr(col2,instr(col2,':')+1)-0) > 270 GROUP BY col6;
","[('`Egyptian`', 3, 310.67, 932), ('`Lebanese`', 2, 274.5, 549)]",m_1764882352325_fd1ddcc5_14778650-1,"1) Parse SQL intent: group rows by Dialect, count tracks, compute average and total of Length converted to seconds, and filter to lengths > 270 seconds. 2) Map schema semantics: Length is a text 'M:SS' converted as minutes*60 + seconds. 3) Draft the question: request Dialect (backticked), Track Count, Avg Length Seconds rounded to 2 decimals, and Total Length Seconds for tracks longer than 270s. 4) Validate: includes grouping by Dialect and all calculations/labels from the query.",reserved,5,N/A,add_column,
"Using only rows where Area (km 2 ) > 0 and Population (2005) is not null, and defining Priority as 'High priority' if Population density (/km 2 ) > 200 OR Human Development Index (2000) > 0.8 and 'Standard' otherwise, what are the number of distinct Municipalities (COUNT(DISTINCT Municipality)), the average of Population (2005) divided by Area (km 2 ) (AVG(Population (2005)/Area (km 2 ))), and the maximum Population (2005) for each Priority, showing only Priority groups that contain at least one municipality?","
SELECT CASE WHEN `population_density_per_km2` > '200' OR `Human Development Index (2000)` > '0.8' THEN 'High priority' ELSE 'Standard' END `Priority`, COUNT(DISTINCT `Municipality`) `Municipalities`, AVG(`population_2005`/`Area (km 2 )`) `AvgDensity`, MAX(`population_2005`) `MaxPop` FROM `table_m_1764882361425_b6040616_1480455_1` WHERE `Area (km 2 )` > 0 AND `population_2005` IS NOT NULL GROUP BY `Priority` HAVING COUNT(`Municipality`) > 0;
","
SELECT CASE WHEN col5 > '200' OR col6 > '0.8' THEN 'High priority' ELSE 'Standard' END `Priority`, COUNT(DISTINCT col1) `Municipalities`, AVG(col4/col3) `AvgDensity`, MAX(col4) `MaxPop` FROM `table_m_1764882361425_b6040616_1480455_1` WHERE col3 > 0 AND col4 IS NOT NULL GROUP BY `Priority` HAVING COUNT(col1) > 0;
","[('High priority', 11, 5389.450005918182, 734139.0), ('Standard', 6, 3739.1588011366653, 79743.0)]",m_1764882361425_b6040616_1480455-1,"1) Parse intent: produce aggregated metrics per derived Priority based on population density and HDI thresholds, excluding zero-area or null-population rows. 2) Map schema: Priority uses Population density (/km 2 ) and Human Development Index (2000); aggregations use Municipality, Population (2005), Area (km 2 ). 3) Draft: request distinct municipality count, average of population divided by area, and maximum population per Priority, with the filters and non-empty groups. 4) Validate: all columns, calculations, conditions and grouping are represented.",reserved,17,N/A,rename_column,
Which episodes from seasons 1–3 outperformed the season average the most?,unanswerable,unanswerable,,m_1764882385433_a039e272_14845640-1,"STEP 1: Parse the SQL intent — find episodes from Season # IN (1,2,3) with U.S. viewers > 0, compute the average U.S. viewers per season (via self-join on Season #), keep episodes whose viewers exceed their season's average, compute delta = episode viewers - season avg and a season rank, then return the top 5 episodes by delta (largest positive difference).
STEP 2: Choose ambiguity type — scope ambiguity fits well: the phrase ""the season average"" in natural language can mean the average for that episode's own season (per-season average, which the SQL uses) or an average computed across all selected seasons (an overall average for seasons 1–3). This ambiguity aligns naturally with the SQL's per-season AVG vs. a plausible alternate overall AVG.
STEP 3: Draft the question — ""Which episodes from seasons 1–3 outperformed the season average the most?""
STEP 4: Explain the ambiguity — in the original query ""season average"" is interpreted as the average viewers for that episode's season (AVG grouped by Season #). An alternative interpretation would treat ""the season average"" as a single average across seasons 1–3 (or as asking for the top episodes per season), which would require a different aggregation or ranking in SQL.",reserved,14,N/A,merge_column,"type: Scope ambiguity | explanation: The phrase ""the season average"" can be read as the average for each episode's own season (the SQL's interpretation: AVG grouped by Season #) or as a single average across all seasons 1–3 (an overall comparison), leading to different SQL aggregations and rankings."
"For each DISTINCT ""Directed by"" value (using a self-join on No. in series = No. in series) with No. in season > 4, what are COUNT(No. in series) AS ""Wrong Is Right"", AVG(U.S. viewers (millions)) AS ""Taken"", and SUM((U.S. viewers (millions) > 14)) AS ""High_hits"", considering only directors whose COUNT(No. in series) > 1, and return at most 5 directors?",unanswerable,unanswerable,,m_1764882400919_a35253ce_14857583-1,"1) Parse SQL intent: group episodes by director for episodes with No. in season > 4, compute count, average viewers and count of high-view episodes, then filter directors with count > 1 and limit to 5. 2) Map schema semantics: 'No. in series' is counted, 'U.S. viewers (millions)' is averaged and compared to 14 for the SUM. 3) Draft the question: request the distinct director and the three aggregates with their aliases. 4) Validate: ensure inclusion of the self-join condition, GROUP BY ""Directed by"", HAVING COUNT(No. in series) > 1, and LIMIT 5.",reserved,11,N/A,remove_column,
"How do home venues (City Stadium and State Fair Park) compare to away venues in average crowd excitement, and show each game annotated with whether it was Home or Away plus the home/away average crowd excitement so I can assess typical acoustic footprints?",unanswerable,unanswerable,,m_1764882414586_8c5dfa58_14877831-2,"I'm interested in home versus away acoustic footprints and would phrase the question in familiar terms like 'home' venues and 'average excitement.' The query computes a venue_type (Home for City Stadium and State Fair Park else Away) and aggregates average crowd excitement by venue_type. It attaches that home/away average excitement to each game row. How do home venues (City Stadium and State Fair Park) compare to away venues in average crowd excitement, and show each game annotated with whether it's Home or Away plus the home/away average crowd excitement so I can assess typical acoustic footprints? This matches the query's venue_type and home/away average excitement outputs.",persona,"An acoustic archaeologist (sonic historian) reconstructing 1950 City Stadium and other venues' crowd soundscapes by using attendance and game dynamics as proxies for noise and excitement. Goals: Identify which games and venues likely produced the loudest/most raucous crowds by combining attendance with scoring swings and close finishes. Compare home (City Stadium / State Fair Park) versus away venues to infer differences in typical crowd sizes and their likely acoustic footprints. Create a per-game 'crowd excitement' index (attendance × scoring margin) to rank games for further archival audio hunting or computational soundscape reconstruction. Example Queries: SELECT ""Date"", ""Opponent"", ""Venue"", ""Attendance"", ""Result"" FROM table_1_14877831_2 ORDER BY ""Attendance"" DESC LIMIT 3; SELECT ""Venue"", AVG(""Attendance"") AS avg_attendance, AVG(""Packers points"") AS avg_packers_points, AVG(""Opponents"") AS avg_opponent_points FROM table_1_14877831_2 GROUP BY ""Venue"" ORDER BY avg_attendance DESC; SELECT ""Game"", ""Date"", ""Opponent"", ""Venue"", ""Attendance"", ""Packers points"", ""Opponents"", ABS(""Packers points"" - ""Opponents"") * ""Attendance"" AS crowd_excitement_index FROM table_1_14877831_2 ORDER BY crowd_excitement_index DESC LIMIT 5;",N/A,remove_column,
"Which are the top 5 teams by Points (ordered descending) among entries with Played > 0 and Points >= 18, showing Team, Points, Goal difference as (Scored - Conceded), Points per game as Points/Played rounded to 3 decimal places, and Attack/Defense ratio as Scored / (Conceded + 1.0) rounded to 2 decimal places?","
SELECT `Team`, `Points`, (`Scored` - `Conceded`) `Goal difference`, ROUND(`Points` / `Played`, 3) `Points per game`, ROUND((`Scored` / (`Conceded` + 1.0)), 2) AS `Attack/Defense ratio`
FROM `table_m_1764882421670_53d3732d_14889048_1`
WHERE `Played` > 0 AND `Points` >= 18
ORDER BY `Points` DESC
LIMIT 5;
","
SELECT col1, col8, (col6 - col7) `Goal difference`, ROUND(col8 / col2, 3) `Points per game`, ROUND((col6 / (col7 + 1.0)), 2) AS `Attack/Defense ratio`
FROM `table_m_1764882421670_53d3732d_14889048_1`
WHERE col2 > 0 AND col8 >= 18
ORDER BY col8 DESC
LIMIT 5;
","[('Cerro Porteño', 41.0, 18.0, 2.278, 2.21), ('Libertad', 38.0, 31.0, 2.111, 3.14), ('Tacuary', 28.0, 12.0, 1.556, 1.79), ('Guaraní', 28.0, -5.0, 1.556, 0.77), ('Olimpia', 23.0, -7.0, 1.278, 0.72)]",m_1764882421670_53d3732d_14889048-1,"1) Parse the SQL intent: select Team, Points, compute goal difference (Scored - Conceded), Points per game (Points/Played rounded to 3 decimals), and Attack/Defense ratio (Scored/(Conceded + 1.0) rounded to 2 decimals), filter Played > 0 and Points >= 18, order by Points descending and limit to 5. 2) Map schema semantics: Team, Points, Scored, Conceded, and Played come from the Torneo Apertura table. 3) Draft the question to request those columns and calculations with the specified filters, ordering, and limit. 4) Validate: the question must mention all columns, both calculations with rounding, Played > 0, Points >= 18, order by Points DESC, and top 5 limit.",reserved,8,N/A,add_column,
"For each distinct `Directed by`, what is the COUNT(`No. in series`) labeled `Total episodes`, the MIN(`Production code`) labeled `176251`, and the MAX(`Production code`) labeled `176265`, considering only directors with COUNT(`No. in series`) > 1, sorted by COUNT(`No. in series`) descending and showing the top 5?","
SELECT DISTINCT `Directed by`, COUNT(`No. in series`) `Total episodes`, MIN(`Production code`) `176251`, MAX(`Production code`) `176265`
FROM `table_m_1764882430045_08f047e8_14889988_1`
GROUP BY `Directed by`
HAVING COUNT(`No. in series`) > 1
ORDER BY COUNT(`No. in series`) DESC
LIMIT 5;
","
SELECT DISTINCT col3, COUNT(col0) `Total episodes`, MIN(col6) `176251`, MAX(col6) `176265`
FROM `table_m_1764882430045_08f047e8_14889988_1`
GROUP BY col3
HAVING COUNT(col0) > 1
ORDER BY COUNT(col0) DESC
LIMIT 5;
","[('Gary Halvorson', 7, 176253.0, 176268.0), ('Kevin S. Bright', 4, 176251.0, 176262.0), ('Ben Weiss', 2, 176252.0, 176256.0)]",m_1764882430045_08f047e8_14889988-1,"1) Parse SQL intent: group rows by director and show director name, episode count, lowest and highest production codes for directors with multiple episodes, top 5 by count. 2) Map schema semantics: use `Directed by`, aggregate COUNT on `No. in series`, MIN and MAX on `Production code` with given aliases. 3) Draft the question: request those aggregated fields and constraints. 4) Validate: captures DISTINCT, GROUP BY, HAVING >1, ORDER BY DESC, and LIMIT 5.",reserved,9,N/A,add_column,
"For each Mens singles Player, compute Total_Appearances as the sum over all Years of an indicator that the Player's name occurs in the concatenation (Mens singles || ' ' || Womens singles || ' ' || Mens doubles || ' ' || Womens doubles || ' ' || Mixed doubles) for the same Year, then return Player and Total_Appearances grouped by Player, ordered by Total_Appearances descending, limited to the top 5?","
SELECT base.`mens_singles` `Player`,
       SUM((instr(allcols.`concat_all`, base.`mens_singles`) > 0)) `Total_Appearances`
FROM `table_m_1764882444172_5033edc1_14903491_1` base
JOIN (
  SELECT `Year`,
         `mens_singles` || ' ' || `womens_singles` || ' ' || `mens_doubles` || ' ' || `Womens doubles` || ' ' || `Mixed doubles` `concat_all`
  FROM `table_m_1764882444172_5033edc1_14903491_1`
) allcols ON base.`Year` = allcols.`Year`
GROUP BY `Player`
ORDER BY `Total_Appearances` DESC
LIMIT 5;
","
SELECT base.col1 `Player`,
       SUM((instr(allcols.`concat_all`, base.col1) > 0)) `Total_Appearances`
FROM `table_m_1764882444172_5033edc1_14903491_1` base
JOIN (
  SELECT col0,
         col1 || ' ' || col2 || ' ' || col3 || ' ' || col4 || ' ' || col5 `concat_all`
  FROM `table_m_1764882444172_5033edc1_14903491_1`
) allcols ON base.col0 = allcols.col0
GROUP BY `Player`
ORDER BY `Total_Appearances` DESC
LIMIT 5;
","[('Mihail Popov', 3), ('Jeliazko Valkov', 3), ('Georgi Petrov', 3), ('Boris Kessov', 3), ('Todor Velkov', 2)]",m_1764882444172_5033edc1_14903491-1,"1) The SQL produces the top five Mens singles names by counting the number of Years in which each name appears anywhere among that Year's winners via concatenation and an existence test (instr>0), grouping by the Mens singles name. 2) Map columns Mens singles, Womens singles, Mens doubles, Womens doubles, Mixed doubles and the Year-based concatenation used for the presence check. 3) Create a question asking for Player and the summed per-Year presence in the concatenated five-event string, grouped by Player, ordered descending, limited to five. 4) Ensure the question references the concatenation of all five columns, the per-Year match, the sum of presence indicators, grouping, ordering, and LIMIT 5.",reserved,12,N/A,rename_column,
"Produce a director-by-director summary sorted by most nominations showing total submissions, nominations, earliest and latest submission years, number of multilingual submissions, the languages they've used, and a chronological list of their films with title, year, languages and nomination result?","
WITH `t` AS (
  SELECT
    *,
    CAST(substr(`film_title_with_ceremony_year_and_languages`,1,4) AS INTEGER) AS `YearNum`
  FROM `table_m_1764882486317_126debaf_14928423_1`
)
SELECT
  `Director(s)`,
  COUNT(*) AS `total_submissions`,
  SUM(CASE WHEN `Result` = 'Nominee' THEN 1 ELSE 0 END) AS `nominations`,
  MIN(`YearNum`) AS `earliest_submission_year`,
  MAX(`YearNum`) AS `latest_submission_year`,
  SUM(CASE WHEN `film_title_with_ceremony_year_and_languages` LIKE '%,%' THEN 1 ELSE 0 END) AS `multilingual_submissions`,
  group_concat(DISTINCT `film_title_with_ceremony_year_and_languages`) AS `languages_used`,
  (SELECT group_concat(x, '; ')
     FROM (
       SELECT `film_title_with_ceremony_year_and_languages` || ' — ' || `film_title_with_ceremony_year_and_languages` || ' — ' || `film_title_with_ceremony_year_and_languages` || ' — ' || `Result` AS x
       FROM `t` `t2`
       WHERE `t2`.`Director(s)` = `t`.`Director(s)`
       ORDER BY `YearNum`
     )
  ) AS `film_timeline`
FROM `t` `t`
GROUP BY `Director(s)`
ORDER BY `nominations` DESC, `total_submissions` DESC, `earliest_submission_year`;
","
WITH `t` AS (
  SELECT
    *,
    CAST(substr(col3,1,4) AS INTEGER) AS `YearNum`
  FROM `table_m_1764882486317_126debaf_14928423_1`
)
SELECT
  col1,
  COUNT(*) AS `total_submissions`,
  SUM(CASE WHEN col2 = 'Nominee' THEN 1 ELSE 0 END) AS `nominations`,
  MIN(`YearNum`) AS `earliest_submission_year`,
  MAX(`YearNum`) AS `latest_submission_year`,
  SUM(CASE WHEN col3 LIKE '%,%' THEN 1 ELSE 0 END) AS `multilingual_submissions`,
  group_concat(DISTINCT col3) AS `languages_used`,
  (SELECT group_concat(x, '; ')
     FROM (
       SELECT col3 || ' — ' || col3 || ' — ' || col3 || ' — ' || col2 AS x
       FROM `t` `t2`
       WHERE `t2`.col1 = `t`.col1
       ORDER BY `YearNum`
     )
  ) AS `film_timeline`
FROM `t` `t`
GROUP BY col1
ORDER BY `nominations` DESC, `total_submissions` DESC, `earliest_submission_year`;
","[('Milčo Mančevski Category:Articles with hCards', 3, 1, 0, 0, 3, 'Before the Rain, 1994 (67th), Macedonian, Albanian, English,Shadows, 2007 (80th), Macedonian,Mothers, 2010 (83rd), Macedonian', 'Before the Rain, 1994 (67th), Macedonian, Albanian, English — Before the Rain, 1994 (67th), Macedonian, Albanian, English — Before the Rain, 1994 (67th), Macedonian, Albanian, English — Nominee; Shadows, 2007 (80th), Macedonian — Shadows, 2007 (80th), Macedonian — Shadows, 2007 (80th), Macedonian — Not Nominated; Mothers, 2010 (83rd), Macedonian — Mothers, 2010 (83rd), Macedonian — Mothers, 2010 (83rd), Macedonian — Not Nominated'), ('Ivo Trajkov Category:Articles with hCards', 2, 0, 0, 0, 2, 'The Great Water, 2004 (77th), Macedonian,Wingless, 2009 (82nd), Czech', 'The Great Water, 2004 (77th), Macedonian — The Great Water, 2004 (77th), Macedonian — The Great Water, 2004 (77th), Macedonian — Not Nominated; Wingless, 2009 (82nd), Czech — Wingless, 2009 (82nd), Czech — Wingless, 2009 (82nd), Czech — Not Nominated'), ('Sergej Stanojkovski Category:Articles with hCards', 1, 0, 0, 0, 1, 'Kontakt, 2006 (79th), Macedonian, German', 'Kontakt, 2006 (79th), Macedonian, German — Kontakt, 2006 (79th), Macedonian, German — Kontakt, 2006 (79th), Macedonian, German — Not Nominated'), ('Stole Popov Category:Articles with hCards', 1, 0, 0, 0, 1, 'Gypsy Magic, 1997 (70th), Macedonian, Romany', 'Gypsy Magic, 1997 (70th), Macedonian, Romany — Gypsy Magic, 1997 (70th), Macedonian, Romany — Gypsy Magic, 1997 (70th), Macedonian, Romany — Not Nominated'), ('Vladimir Blazevski Category:Articles with hCards', 1, 0, 0, 0, 1, ""Punk's Not Dead, 2011 (84th), Macedonian"", ""Punk's Not Dead, 2011 (84th), Macedonian — Punk's Not Dead, 2011 (84th), Macedonian — Punk's Not Dead, 2011 (84th), Macedonian — Not Nominated"")]",m_1764882486317_126debaf_14928423-1,"As a researcher preparing exhibition labels I use clear, analytical phrasing and know to request director-level summaries. The SQL intent is to produce director-level summary statistics (total submissions, nominations, earliest/latest submission years), count multilingual submissions, aggregate languages, and produce a chronological film timeline with title, year, languages and result. Mapped columns are Director(s), Year (Ceremony), Language (s), Film title used in nomination and Result. Draft question: Produce a director-by-director summary sorted by most nominations showing total submissions, nominations, earliest and latest submission years, number of multilingual submissions, the languages they've used, and a chronological list of their films with title, year, languages and nomination result? Validate: This mirrors the query's grouping, metrics and ordering without introducing extra data.",persona,"A researcher at the Macedonian National Film Archive studying the country's Academy Award submission history to inform exhibitions and scholarly articles. They use the database to extract patterns by year, language, director, and nomination outcomes. Goals: Identify which Macedonian submissions achieved nomination and the contexts (year, director, language). Measure language and director trends across submissions to support curation and research (e.g., recurring directors, multilingual films). Produce ordered timelines of submissions and compile summary statistics for reports or exhibition labels. Example Queries: SELECT ""Year (Ceremony)"", ""Film title used in nomination"", ""Original title"", ""Language (s)"", ""Director(s)"" FROM table_1_14928423_1 WHERE ""Result"" = 'Nominee' ORDER BY ""Year (Ceremony)""; SELECT ""Language (s)"", COUNT(*) AS submissions FROM table_1_14928423_1 GROUP BY ""Language (s)"" ORDER BY submissions DESC; SELECT ""Director(s)"", COUNT(*) AS films_submitted FROM table_1_14928423_1 GROUP BY ""Director(s)"" ORDER BY films_submitted DESC, ""Director(s)"";",N/A,merge_column,
"Which election years had at least 50 seats and a change of at least 10, or a loss, and how far above average were their seat counts?","
SELECT `election_year`, `Seats Won`, CASE WHEN `Seats Won` > AVG(`Seats Won`) OVER () THEN `Seats Won` - AVG(`Seats Won`) OVER () END AS `AboveAvg`
FROM `table_m_1764882493026_a2fcebc3_149330_1`
WHERE `Seats Won` >= 50 AND `Change in Seat` >= 10 OR `Change in Seat` < 0
GROUP BY `election_year`, `Seats Won`
HAVING SUM(`Seats Won`) > 0
ORDER BY `Seats Won` DESC
LIMIT 3;
","
SELECT col0, col2, CASE WHEN col2 > AVG(col2) OVER () THEN col2 - AVG(col2) OVER () END AS `AboveAvg`
FROM `table_m_1764882493026_a2fcebc3_149330_1`
WHERE col2 >= 50 AND col3 >= 10 OR col3 < 0
GROUP BY col0, col2
HAVING SUM(col2) > 0
ORDER BY col2 DESC
LIMIT 3;
","[('Indian general election, 1998', 183.0, 44.400000000000006), ('Indian general election, 1996', 161.0, 22.400000000000006), ('Indian general election, 2004', 144.0, 5.400000000000006)]",m_1764882493026_a2fcebc3_149330-1,"STEP 1: Parse the SQL intent — it selects Year and Seats Won and computes an `AboveAvg` value (Seats Won minus the AVG(Seats Won) over the whole set when Seats Won is greater than that average). Rows are filtered by (Seats Won >= 50 AND Change in Seat >= 10) OR (Change in Seat < 0), grouped by Year and Seats Won, require SUM(Seats Won) > 0, ordered by Seats Won descending, limited to the top 3. STEP 2: Determine ambiguity type — scope ambiguity fits well: the phrase “above average” can naturally refer to different scopes (the average of all elections, the average of the filtered subset, or a per-year/per-group average). This is especially fitting because the query uses AVG(...) OVER() (a global window) but a reader might expect a subset average. STEP 3: Draft the question — see question field below. STEP 4: Explain the ambiguity — in the original SQL the AboveAvg uses AVG(...) OVER() with no partition, so it effectively compares each row to a global average; a reader could instead interpret “above average” as comparing to the average only among the selected rows (those with >=50 seats and big gains or losses), or even the average per year/group in a different query. Also, the filtering clause contains an OR which can be read with different attachment/scope in natural language (but the primary intended ambiguity here is which average is meant).",reserved,19,N/A,rename_column,"type: Scope ambiguity | explanation: The question is ambiguous about the scope of “above average”: the SQL computes AboveAvg using AVG(Seats Won) OVER() (a global average across the dataset), but a reader might instead interpret “above average” as the average of only the filtered years (those meeting the seat/change criteria) or some other subgroup; the original query uses the global average, while an alternative interpretation would compare to the filtered subset's average (or a per-group average)."
"Considering only rows with Week > 0 and grouping by substr(Result,1,1) as ResultType, what are Games (COUNT(*)), Total Attendance (SUM(Attendance)), Avg Attendance (ROUND(AVG(Attendance),0)), and Memorial Stadium (MAX(Attendance)) for each group, ordered by Avg Attendance and limited to 5 results?",unanswerable,unanswerable,,m_1764882510484_953ce1de_14945608-1,"Parse the SQL intent: group by substr(Result,1,1), filter Week > 0, calculate count, sum, rounded average, and max of Attendance, then order by the rounded average and limit to five rows. Map schema semantics: Result provides the grouping key ResultType and Attendance supplies the aggregations; Week > 0 limits included games. Draft a concise question that lists each computed column and the ordering/limit. Validate that the question explicitly mentions substr(Result,1,1) as ResultType, COUNT(*) Games, SUM(Attendance) Total Attendance, ROUND(AVG(Attendance),0) Avg Attendance, MAX(Attendance) Memorial Stadium, ORDER BY Avg Attendance, and LIMIT 5.",reserved,8,N/A,merge_column,
"Which three Game Sites have the highest avgAttendance (order by avgAttendance descending, limit 3), and for each of those Game Sites report: Game Site, Games (COUNT of games), Wins (SUM where Result LIKE 'W %'), Losses (SUM where Result LIKE 'L %'), avgAttendance (average Attendance), Total_Points_For (sum of the first numeric value in Result before the '–'), and Total_Points_Against (sum of the second numeric value in Result after the '–'), considering only rows with Attendance > 0 and grouping results by Game Site?","
SELECT `Game Site` AS `Game Site`, COUNT(*) `Games`, SUM(`Result` LIKE 'W %') `Wins`, SUM(`Result` LIKE 'L %') `Losses`, AVG(`Attendance`) `avgAttendance`, SUM((substr(substr(`Result`, instr(`Result`,' ')+1), 1, instr(substr(`Result`, instr(`Result`,' ')+1),'–')-1) + 0)) `Total_Points_For`, SUM((substr(substr(`Result`, instr(`Result`,' ')+1), instr(substr(`Result`, instr(`Result`,' ')+1),'–')+1) + 0)) `Total_Points_Against`
FROM `table_m_1764882517148_899398aa_14954150_1`
WHERE `Attendance` > 0
GROUP BY `Game Site`
ORDER BY (`avgAttendance` * -1)
LIMIT 3;
","
SELECT col5 AS col5, COUNT(*) `Games`, SUM(col3 LIKE 'W %') `Wins`, SUM(col3 LIKE 'L %') `Losses`, AVG(col6) `avgAttendance`, SUM((substr(substr(col3, instr(col3,' ')+1), 1, instr(substr(col3, instr(col3,' ')+1),'–')-1) + 0)) `Total_Points_For`, SUM((substr(substr(col3, instr(col3,' ')+1), instr(substr(col3, instr(col3,' ')+1),'–')+1) + 0)) `Total_Points_Against`
FROM `table_m_1764882517148_899398aa_14954150_1`
WHERE col6 > 0
GROUP BY col5
ORDER BY (`avgAttendance` * -1)
LIMIT 3;
","[('Rich Stadium', 1, 0, 1, 75325.0, 0, 6), ('Miami Orange Bowl', 1, 0, 1, 65868.0, 7, 17), ('Veterans Stadium', 1, 0, 1, 64205.0, 10, 30)]",m_1764882517148_899398aa_14954150-1,"1) Parse SQL intent: aggregate by Game Site to get counts, win/loss tallies, average attendance and summed points for/against, exclude zero attendance, sort by avg attendance descending and return three rows. 2) Map schema semantics: use Game Site, Result string parsing for scores, Attendance filter. 3) Draft question: request all output columns and operations with grouping, ordering, and limit. 4) Validate: includes every column and calculation and the WHERE/GROUP BY/ORDER BY/LIMIT constraints.",reserved,8,N/A,add_column,
"Considering only rows where Attendance>0, provide: the total number of games (COUNT(Week)); the total wins SUM((instr(Result,'W')>0)) and losses SUM((instr(Result,'L')>0)); the overall win percentage ROUND(100.0 * SUM((instr(Result,'W')>0)) / COUNT(Week),2); the SUM(Attendance * (Game Site='`Memorial Stadium`')) for Game Site='`Memorial Stadium`'; how many of those were wins SUM((instr(Result,'W')>0) * (Game Site='`Memorial Stadium`')); the win percentage at Game Site='`Memorial Stadium`' ROUND(100.0 * SUM((instr(Result,'W')>0) * (Game Site='`Memorial Stadium`')) / SUM((Game Site='`Memorial Stadium`')),2); the SUM(Attendance * (instr(Opponent,'at ')=1)) for games with instr(Opponent,'at ')=1; the number of wins in those away games SUM((instr(Result,'W')>0) * (instr(Opponent,'at ')=1)); and the away win percentage ROUND(100.0 * SUM((instr(Result,'W')>0) * (instr(Opponent,'at ')=1)) / SUM((instr(Opponent,'at ')=1)),2)?",unanswerable,unanswerable,,m_1764882528471_0b11c61b_14959246-2,"1) The SQL computes overall and conditional aggregates (site-specific and away-specific) with rounding and filters Attendance>0. 2) Identify COUNT(Week), SUM of win/loss indicators using instr on Result, Attendance sums filtered by Game Site='`Memorial Stadium`' and by instr(Opponent,'at ')=1, and corresponding win counts and percentages. 3) Formulate a question that lists each aggregate and percentage explicitly including the ROUND(...,2) calculations and the Attendance>0 condition. 4) Ensure no extra information beyond the SQL elements is introduced.",reserved,4,N/A,merge_column,
"Grouped by Game Site for entries where Opponent = 'at Miami Dolphins', what are the Game Site, COUNT(Week), SUM(substr(Result,1,1)='W') (wins where Result begins with 'W'), and AVG(Attendance), with the results ordered by AVG(Attendance) from highest to lowest?",unanswerable,unanswerable,,m_1764882545372_bfbe41e7_14966537-1,"1) The SQL intention is aggregation by Game Site for entries with Opponent = 'at Miami Dolphins' using COUNT, a SUM of a substring check for wins, and AVG attendance, sorted by average attendance descending. 2) Map these to plain terms while preserving exact calculations COUNT(Week), SUM(substr(Result,1,1)='W'), and AVG(Attendance). 3) Draft a concise question requesting, per Game Site, those exact aggregates for Opponent = 'at Miami Dolphins' and to sort results from highest to lowest average attendance. 4) Validate inclusion of all selected expressions and the filter and ordering.",reserved,10,N/A,remove_column,
"For the period from 01 Jan 2006 to 31 Dec 2007, which three jockeys have the highest Win% (where Win% = 100 × Wins / Starts, rounded to two decimal places), and for each jockey what are their Jockey name, number of Starts, number of Wins (count of Result = 'Won'), Win% (rounded to 2 decimals), and number of races at Moonee Valley?","
SELECT `Jockey`, COUNT(*) `Starts`, SUM((`Result_at_Venue` = 'Won')) `Wins`, ROUND(100.0 * SUM((`Result_at_Venue` = 'Won')) / COUNT(*),2) AS `Win%`, SUM((`Result_at_Venue` = 'Moonee Valley')) `Moonee Valley`
FROM `table_m_1764882572473_924997f9_14981555_3`
WHERE `Date` BETWEEN '01 Jan 2006' AND '31 Dec 2007'
GROUP BY `Jockey`
ORDER BY `Win%` DESC
LIMIT 3;
","
SELECT col5, COUNT(*) `Starts`, SUM((col7 = 'Won')) `Wins`, ROUND(100.0 * SUM((col7 = 'Won')) / COUNT(*),2) AS `Win%`, SUM((col7 = 'Moonee Valley')) `Moonee Valley`
FROM `table_m_1764882572473_924997f9_14981555_3`
WHERE col0 BETWEEN '01 Jan 2006' AND '31 Dec 2007'
GROUP BY col5
ORDER BY `Win%` DESC
LIMIT 3;
","[('D. Oliver', 1, 0, 0.0, 0), ('C. Newitt', 8, 0, 0.0, 0)]",m_1764882572473_924997f9_14981555-3,"Parse intent: compute per-jockey totals and win stats for races between 01 Jan 2006 and 31 Dec 2007, then return the top three by win percentage. Map schema: use columns Jockey, Result to count Wins (Result='Won'), COUNT(*) as Starts, compute Win% = 100 * Wins / Starts rounded to 2 decimals, and count Venue='Moonee Valley' as Moonee Valley. Draft: ask for Jockey plus Starts, Wins, Win% (rounded to two decimals and defined as 100*wins/starts), and Moonee Valley counts for that date range, ordered by Win% descending and limited to 3. Validate: includes all columns, calculation, date filter, ordering and limit.",reserved,12,N/A,merge_column,
"For stadiums with big crowds, what were their average and peak attendance and how many wins did they have?",unanswerable,unanswerable,,m_1764882585317_6051e3c5_14984050-1,"STEP 1: Parse the SQL intent: The query selects Game Site and computes average Attendance, max Attendance, and counts wins (rows where Result contains 'W ') but only for games with Attendance > 40000; it then groups by Game Site, keeps groups whose average Attendance > 48000, orders by average Attendance, and limits to 10. STEP 2: Choose ambiguity type: Attachment ambiguity fits well — a phrase like ""how many wins did they have"" can attach to either the stadium/site (wins at that site) or to the team(s) that play there. This matches the query which counts wins per site but could be read as wins by other referents. STEP 3: Draft the question: ""For stadiums with big crowds, what were their average and peak attendance and how many wins did they have?"" STEP 4: Explain ambiguity: In the original query ""their""/""they"" maps to the grouped Game Site and the query counts the Colts' wins in those high-attendance games at each site. Alternatively, a reader could interpret ""how many wins did they have"" as asking about wins by any team that uses the stadium overall, wins across the whole season (including low-attendance games), or wins aggregated in a different scope (e.g., per opponent or per season), changing the intended aggregation and filter.",reserved,9,N/A,merge_column,"type: Attachment ambiguity | explanation: The phrase ""how many wins did they have"" can attach to the stadiums (wins recorded at that site in the filtered high-attendance games, which is what the SQL counts) or to another entity such as the team(s) that play there or wins across all games at the stadium (which would change filters and aggregation)."
"Which five pairs of different Administrative division and Peer (where a.`Area (km²)` > 0 and either a.`Population (2010 Census)` > 500000 or b.`Population (2010 Census)` > 500000) have the highest Relative change defined as ((a.`Population (2010 Census)` - b.`Population 2000 Census`) * 100.0) / b.`Population 2000 Census` when b.`Population 2000 Census` != 0, and what are a.`Administrative division`, b.`Administrative division` (Peer), that Relative change, and ABS(a.`Population density 2010 (/km²)` - b.`Population density 2010 (/km²)`), ordered by Relative change descending and limited to 5?","
SELECT a.`Administrative division`, b.`Administrative division` `Peer`,
CASE WHEN b.`Population 2000 Census` != 0 THEN ((a.`Population (2010 Census)` - b.`Population 2000 Census`) * 100.0) / b.`Population 2000 Census` END AS `Relative change`,
ABS(a.`Population density 2010 (/km²)` - b.`Population density 2010 (/km²)`)
FROM `table_m_1764882593162_9c6cc70d_14986292_1` a
LEFT JOIN `table_m_1764882593162_9c6cc70d_14986292_1` b ON a.`Administrative division` != b.`Administrative division`
WHERE (a.`Population (2010 Census)` > 500000 OR b.`Population (2010 Census)` > 500000) AND a.`Area (km²)` > 0
ORDER BY `Relative change` DESC
LIMIT 5;
","
SELECT a.col0, b.col0 `Peer`,
CASE WHEN b.col2 != 0 THEN ((a.col3 - b.col2) * 100.0) / b.col2 END AS `Relative change`,
ABS(a.col4 - b.col4)
FROM `table_m_1764882593162_9c6cc70d_14986292_1` a
LEFT JOIN `table_m_1764882593162_9c6cc70d_14986292_1` b ON a.col0 != b.col0
WHERE (a.col3 > 500000 OR b.col3 > 500000) AND a.col1 > 0
ORDER BY `Relative change` DESC
LIMIT 5;
","[('Rio de Janeiro', 'Tanguá', 24166.17415665656, 4809.0), ('Rio de Janeiro', 'Guapimirim', 16560.616041315345, 4875.0), ('Rio de Janeiro', 'Seropédica', 9588.993257738277, 4743.0), ('Rio de Janeiro', 'Japeri', 7492.685943466462, 3867.0), ('Rio de Janeiro', 'Queimados', 5083.114604936349, 3227.0)]",m_1764882593162_9c6cc70d_14986292-1,"Parse the SQL intent: left-join distinct Administrative division pairs, compute percent Relative change from a's 2010 population relative to b's 2000 population when that b value is not zero, compute absolute difference in `Population density 2010 (/km²)`, apply filters (either side's 2010 population > 500000 and a.`Area (km²)` > 0), sort by Relative change descending and limit to 5. Map schema semantics: include a.`Administrative division`, b.`Administrative division` as Peer, the explicit formula for Relative change, the ABS density difference, and the WHERE and ORDER BY clauses. Draft the question to ask for those specific outputs and constraints. Validate inclusion of all columns, the CASE condition, ABS calculation, ordering and limit.",reserved,16,N/A,add_column,
"List the English gloss (as 'child'), the Santee-Sisseton column (as 'šičéča'), and the Yankton-Yanktonai, Northern Lakota, and Southern Lakota values for entries where Yankton-Yanktonai = Northern Lakota and Northern Lakota = Southern Lakota?",unanswerable,unanswerable,,m_1764882601826_e571a2a0_1499791-2,"1) Parse: the query selects five columns (with two aliases) and filters by equality among the three Lakota columns. 2) Map: include 'English gloss' aliased to child, 'Santee-Sisseton' aliased to šičéča, plus Yankton-Yanktonai, Northern Lakota, Southern Lakota. 3) Draft: request those labeled columns for entries where Yankton-Yanktonai = Northern Lakota = Southern Lakota. 4) Validate: ensure the question explicitly lists each column and the equality condition.",reserved,4,N/A,remove_column,
"For the top 5 most recent years (ORDER BY Year DESC LIMIT 5), return Year, the Mens singles column labeled as ""Eduards Loze"", the Womens singles column labeled as ""Kristīne Šefere"", the Mens doubles column labeled as ""Eduards Loze Mārtiņš Kažemaks"", the Womens doubles column labeled as ""Kristīne Šefere Margarita Mikelsone"", and the Mixed doubles column labeled as ""Eduards Loze Kristīne Šefere"" for those years where, in a cross join of the table with itself on the same Year, the condition INSTR(t2.`Mixed doubles`, t1.`Mens singles`) > 0 holds, grouping results by Year?","
SELECT t1.`Year`, t1.`mens_singles` `Eduards Loze`, t1.`womens_singles` `Kristīne Šefere`, t1.`mens_doubles` `Eduards Loze Mārtiņš Kažemaks`, t1.`Womens doubles` `Kristīne Šefere Margarita Mikelsone`, t1.`Mixed doubles` `Eduards Loze Kristīne Šefere`
FROM `table_m_1764882610379_703b65ef_15001609_1` t1 CROSS JOIN `table_m_1764882610379_703b65ef_15001609_1` t2
WHERE (t1.`Year` = t2.`Year`) * (INSTR(t2.`Mixed doubles`, t1.`mens_singles`) > 0)
GROUP BY t1.`Year`
ORDER BY (t1.`Year` * -1)
LIMIT 5;
","
SELECT t1.col0, t1.col1 `Eduards Loze`, t1.col2 `Kristīne Šefere`, t1.col3 `Eduards Loze Mārtiņš Kažemaks`, t1.col4 `Kristīne Šefere Margarita Mikelsone`, t1.col5 `Eduards Loze Kristīne Šefere`
FROM `table_m_1764882610379_703b65ef_15001609_1` t1 CROSS JOIN `table_m_1764882610379_703b65ef_15001609_1` t2
WHERE (t1.col0 = t2.col0) * (INSTR(t2.col5, t1.col1) > 0)
GROUP BY t1.col0
ORDER BY (t1.col0 * -1)
LIMIT 5;
","[(2007.0, 'Eduards Loze', 'Kristīne Šefere', 'Eduards Loze Edijs Līviņš', 'Kristīne Šefere Madara Puķīte', 'Eduards Loze Kristīne Šefere'), (2004.0, 'Karlis Vidass', 'Margarita Mikelsone', 'Karlis Vidass Guntis Lavrinovičs', 'Kristīne Šefere Margarita Mikelsone', 'Karlis Vidass Kristine Kisele'), (2000.0, 'Mārtiņš Kažemaks', 'Kristīne Šefere', 'Mārtiņš Kažemaks Edijs Līviņš', 'Kristīne Šefere Dace Šneidere', 'Mārtiņš Kažemaks Margarita Mikelsone'), (1999.0, 'Eduards Loze', 'Dace Šneidere', 'Eduards Loze Mārtiņš Kažemaks', 'Kristīne Šefere Margarita Mikelsone', 'Eduards Loze Kristīne Šefere'), (1998.0, 'Eduards Loze', 'Margarita Mikelsone', 'Eduards Loze Mārtiņš Kažemaks', 'Kristine Tiruma Dace Šneidere', 'Eduards Loze Kristīne Šefere')]",m_1764882610379_703b65ef_15001609-1,"1) The SQL returns Year and five event columns aliased to specific person-name labels for rows where the mens singles name is found within that year's mixed doubles string (INSTR>0), using a self cross join, grouping by Year, ordering by Year descending and limiting to 5. 2) Map each selected column to its alias and include the INSTR substring condition and same-Year join semantics. 3) Draft a question that requests those exact columns (with aliases) under the specified INSTR and grouping/ordering/limit constraints. 4) Confirm the question includes all selections, aliases, the INSTR condition, cross-join on Year, GROUP BY Year, ORDER BY Year DESC, and LIMIT 5.",reserved,9,N/A,rename_column,
What was Bill Gallagher's contribution to viewing figures for episodes over 6.5 million directed by Charles Palmer?,unanswerable,unanswerable,,m_1764882623008_18d4d11a_15026994-2,"STEP 1: Parse the SQL intent — filter rows where Viewing figure (numeric) > 6.5 AND Director = 'Charles Palmer'; sum viewing figures for Bill Gallagher and several other writers, compute the total viewing figures for that filtered set, and compute Bill Gallagher's percentage contribution of that total. STEP 2: Determine ambiguity type — scope ambiguity fits: the phrase that restricts the set of episodes (""over 6.5 million directed by Charles Palmer"") can be read as a single combined filter or as separate/attached modifiers; also ""contribution"" can mean absolute sum or percentage, or per-episode vs overall. STEP 3: Draft the question — ""What was Bill Gallagher's contribution to viewing figures for episodes over 6.5 million directed by Charles Palmer?"" STEP 4: Explain the ambiguity — the original query interprets the question as asking for the aggregate contribution (sum and percent) over episodes that satisfy both conditions (viewing > 6.5 AND director Charles Palmer); alternatively the question could be read as asking about per-episode contributions, as asking about episodes over 6.5 regardless of director, or as asking for an absolute total instead of a percentage.",reserved,4,N/A,merge_column,"type: Scope ambiguity | explanation: The SQL interprets the phrase as a single combined filter (episodes that are both >6.5 million and directed by Charles Palmer) and returns aggregate sums and a percentage for Bill; the NL can instead be read as (a) applying the filters separately (e.g., episodes >6.5 regardless of director, or episodes directed by Charles Palmer regardless of size), (b) asking for per-episode contributions rather than the overall aggregate, or (c) asking for absolute viewing figures instead of a percentage."
"For each Writer, what is the average Viewing figure in millions (derived by removing the ' million' suffix from the Viewing figure and averaging those numbers) among rows where Episode is not empty, limited to writers whose average is between 6 and 8, ordered by the average in descending order and showing the top 10?","
SELECT DISTINCT t.`Writer`, AVG(REPLACE(t.`Viewing figure`, ' million', '')) AS `avg_millions`
FROM `table_m_1764882629502_5defe87e_15026994_5` t
INNER JOIN `table_m_1764882629502_5defe87e_15026994_5` t2 ON t.`Writer`=t2.`Writer`
WHERE t.`Episode`<>''
GROUP BY t.`Writer`
HAVING AVG(REPLACE(t.`Viewing figure`, ' million', '')) BETWEEN 6 AND 8
ORDER BY `avg_millions` DESC
LIMIT 10;
","
SELECT DISTINCT t.col2, AVG(REPLACE(t.col5, ' million', '')) AS `avg_millions`
FROM `table_m_1764882629502_5defe87e_15026994_5` t
INNER JOIN `table_m_1764882629502_5defe87e_15026994_5` t2 ON t.col2=t2.col2
WHERE t.col1<>''
GROUP BY t.col2
HAVING AVG(REPLACE(t.col5, ' million', '')) BETWEEN 6 AND 8
ORDER BY `avg_millions` DESC
LIMIT 10;
","[('Bill Gallagher', 7.2425), ('Rachel Bennette', 6.9)]",m_1764882629502_5defe87e_15026994-5,"1) The SQL selects distinct Writer and AVG(REPLACE(Viewing figure,' million','')) grouped by Writer, only where Episode is not empty, with HAVING avg between 6 and 8, ordered descending and limited to 10. 2) Treat Viewing figure text values as numeric millions by stripping ' million' then averaging per Writer. 3) Formulate a question requesting Writer plus the computed average in millions, apply the Episode non-empty filter, the 6-to-8 million average range, sort descending, and limit to 10. 4) Check the question mentions all columns and calculations and the ordering and limit.",reserved,16,N/A,add_column,
"Restricting to rows where DATE COMPLETED is present, what are the Total Prints (COUNT(*)), the Total Colors (SUM((NUMBER OF COLORS)+0)), the Average Colors (AVG((NUMBER OF COLORS)+0)), the count of FRAMED SIZE entries that include '26"" x 32""' (SUM(instr(FRAMED SIZE,'26"" x 32""')>0)), and the Percent With Known Colors computed as (SUM((NUMBER OF COLORS)+0 > 0) * 100.0) / COUNT(*)?","
SELECT COUNT(*) `Total Prints`, SUM((`NUMBER OF COLORS`)+0) `Total Colors`, AVG((`NUMBER OF COLORS`)+0) `Average Colors`, SUM(instr(`FRAMED SIZE`,'26"" x 32""')>0) `26"" x 32"" Count`, (SUM((`NUMBER OF COLORS`)+0>0)*100.0)/COUNT(*) `Percent With Known Colors` FROM `table_m_1764882643868_744d4c7d_15070195_1` WHERE `DATE COMPLETED`;
","
SELECT COUNT(*) `Total Prints`, SUM((col2)+0) `Total Colors`, AVG((col2)+0) `Average Colors`, SUM(instr(col3,'26"" x 32""')>0) `26"" x 32"" Count`, (SUM((col2)+0>0)*100.0)/COUNT(*) `Percent With Known Colors` FROM `table_m_1764882643868_744d4c7d_15070195_1` WHERE col4;
","[(48, 1181, 24.604166666666668, 10, 91.66666666666667)]",m_1764882643868_744d4c7d_15070195-1,"1) Parse SQL: produce count, sum, average of NUMBER OF COLORS coerced to numeric, count framed sizes matching '26"" x 32""', and percentage of rows with NUMBER OF COLORS > 0, limited to rows with DATE COMPLETED. 2) Map schema: reference `NUMBER OF COLORS`, `FRAMED SIZE`, and `DATE COMPLETED` exactly and the instr() substring check. 3) Draft: formulate a single question listing all required aggregates and the percent formula. 4) Validate: question must explicitly state COUNT(*), SUM((NUMBER OF COLORS)+0), AVG((NUMBER OF COLORS)+0), SUM(instr(FRAMED SIZE,'26"" x 32""')>0), and (SUM((NUMBER OF COLORS)+0>0)*100.0)/COUNT(*) for rows where DATE COMPLETED.",reserved,3,N/A,add_column,
"Return up to five rows showing Average population (x 1,000) and the greatest value of (Natural change / Average population (x 1,000)) minus Natural change (per 1,000) for each Average population (x 1,000) > 2600, excluding cases where that greatest value equals 0, ordered by that greatest value in descending order?","
SELECT `Average population (x 1,000)`, MAX((`Natural change` / `Average population (x 1,000)`) - `Natural change (per 1,000)`) `max_discrepancy`
FROM `table_m_1764882652023_9f13ecf4_1508951_1`
WHERE `Average population (x 1,000)` > 2600
GROUP BY `Average population (x 1,000)`
HAVING MAX((`Natural change` / `Average population (x 1,000)`) - `Natural change (per 1,000)`) <> 0
ORDER BY `max_discrepancy` DESC
LIMIT 5;
","
SELECT col1, MAX((col4 / col1) - col7) `max_discrepancy`
FROM `table_m_1764882652023_9f13ecf4_1508951_1`
WHERE col1 > 2600
GROUP BY col1
HAVING MAX((col4 / col1) - col7) <> 0
ORDER BY `max_discrepancy` DESC
LIMIT 5;
","[(2660.0, 10.657894736842104), (2650.0, 0.16792452830188864), (2940.0, 0.12585034013605423), (2870.0, 0.12473867595818788), (2840.0, 0.10704225352112573)]",m_1764882652023_9f13ecf4_1508951-1,"1) The query selects Average population (x 1,000) and the maximum discrepancy computed as (Natural change / Average population (x 1,000)) - Natural change (per 1,000). 2) It applies a filter Average population (x 1,000) > 2600, groups by Average population, excludes zero maxima via HAVING, sorts by the maximum discrepancy descending, and limits to 5. 3) Create a concise natural question requesting those exact outputs and constraints. 4) Verify inclusion of calculation, filter, grouping, nonzero condition, ordering, and limit.",reserved,9,N/A,add_column,
"List every episode that covers 'Coffee' (case-insensitive, partial match), showing the Series Ep., episode number, Netflix id, segment label and the original segment text.",unanswerable,unanswerable,,m_1764882672563_ed4a1772_15187735-11,"I frequently need to pull episodes about a specific subject (e.g., Coffee) to build collections or verify claims. I would ask plainly for episodes that cover that subject rather than mention SQL mechanics. The query searches normalized segment text for 'coffee' (case-insensitive, partial match) and returns episode identifiers plus segment label and original text. The segments come from Segment A-D and the identifiers are Series Ep., Episode, and Netflix. List every episode that covers 'Coffee' (case-insensitive, partial match), showing the Series Ep., episode number, Netflix id, segment label and the original segment text.",persona,"Content metadata analyst at a streaming service responsible for catalog accuracy and discovery tagging; they use this episode-level table to verify metadata, generate topic tags, and find data-quality issues. They need quick queries to derive topic frequencies, locate episodes by subject, and detect formatting errors in segment titles. Goals: Generate a normalized list of topics (segments) and count how often each appears to inform tagging and recommendation models. Locate episodes that cover a specific topic (e.g., ""Coffee"") to build curated collections or check content claims. Detect and report metadata quality issues (e.g., stray leading characters like ""s "", missing/duplicate Netflix IDs) so the catalog can be cleaned. Example Queries: SELECT LOWER(TRIM(topic)) AS topic, COUNT(*) AS occurrences FROM ( SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment A` AS topic FROM `table_1_15187735_11` UNION ALL SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment B` FROM `table_1_15187735_11` UNION ALL SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment C` FROM `table_1_15187735_11` UNION ALL SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment D` FROM `table_1_15187735_11` ) AS t GROUP BY LOWER(TRIM(topic)) ORDER BY occurrences DESC; SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment A`, `Segment B`, `Segment C`, `Segment D` FROM `table_1_15187735_11` WHERE LOWER(`Segment A`) LIKE '%coffee%' OR LOWER(`Segment B`) LIKE '%coffee%' OR LOWER(`Segment C`) LIKE '%coffee%' OR LOWER(`Segment D`) LIKE '%coffee%'; SELECT `Series Ep.`, `Episode`, `Netflix`, `Segment A`, `Segment B`, `Segment C`, `Segment D` FROM `table_1_15187735_11` WHERE LOWER(`Segment A`) LIKE 's %' OR LOWER(`Segment B`) LIKE 's %' OR LOWER(`Segment C`) LIKE 's %' OR LOWER(`Segment D`) LIKE 's %';",N/A,remove_column,
"Which Series Ep. and Episode have either 'Carbon' or 'Air' appearing in the combined text of Segment A, Segment B, Segment C and Segment D, and for each such episode provide (a) Has Carbon indicating whether 'Carbon' appears in the combined Segment A–D text, (b) Has Air indicating whether 'Air' appears in the combined Segment A–D text, (c) Multiword segment count equal to the number of segments among Segment A, Segment B, Segment C and Segment D that contain a space, and (d) TotalSegmentTextLength equal to the sum of the lengths of Segment A, Segment B, Segment C and Segment D?","
SELECT `series_episode`, `Episode`, (instr(`segment_a_content`||' '||`Segment B`||' '||`Segment C`||' '||`Segment D`, 'Carbon')>0) `Has Carbon`, (instr(`segment_a_content`||' '||`Segment B`||' '||`Segment C`||' '||`Segment D`, 'Air')>0) `Has Air`, ((instr(`segment_a_content`,' ')>0)+(instr(`Segment B`,' ')>0)+(instr(`Segment C`,' ')>0)+(instr(`Segment D`,' ')>0)) `Multiword segment count`, (length(`segment_a_content`)+length(`Segment B`)+length(`Segment C`)+length(`Segment D`)) `TotalSegmentTextLength` FROM `table_m_1764882678486_2ba9e4c1_15187735_12` WHERE (instr(`segment_a_content`||' '||`Segment B`||' '||`Segment C`||' '||`Segment D`, 'Carbon')>0)+(instr(`segment_a_content`||' '||`Segment B`||' '||`Segment C`||' '||`Segment D`, 'Air')>0)>0;
","
SELECT col0, col1, (instr(col3||' '||col4||' '||col5||' '||col6, 'Carbon')>0) `Has Carbon`, (instr(col3||' '||col4||' '||col5||' '||col6, 'Air')>0) `Has Air`, ((instr(col3,' ')>0)+(instr(col4,' ')>0)+(instr(col5,' ')>0)+(instr(col6,' ')>0)) `Multiword segment count`, (length(col3)+length(col4)+length(col5)+length(col6)) `TotalSegmentTextLength` FROM `table_m_1764882678486_2ba9e4c1_15187735_12` WHERE (instr(col3||' '||col4||' '||col5||' '||col6, 'Carbon')>0)+(instr(col3||' '||col4||' '||col5||' '||col6, 'Air')>0)>0;
","[('12-03', 146.0, 0, 1, 4, 62), ('12-04', 147.0, 0, 1, 3, 55), ('12-05', 148.0, 0, 1, 3, 47), ('12-06', 149.0, 1, 0, 3, 62), ('12-08', 151.0, 0, 1, 3, 55), ('12-10', 153.0, 0, 1, 2, 63), ('12-11', 154.0, 1, 0, 4, 67)]",m_1764882678486_2ba9e4c1_15187735-12,"Parse the SQL intent: filter to episodes mentioning 'Carbon' or 'Air' across segments and compute presence flags, per-segment multiword indicator sum, and total text length. Map schema semantics: treat Segment A–D as the source of text for substring searches, space checks, and length calculations, returning Series Ep. and Episode as identifiers. Draft the question to explicitly request those calculated fields and the filter. Validate that it matches the SQL's concatenation-based searches and arithmetic computations and asks only for those outputs.",reserved,3,N/A,rename_column,
"Provide the distinct Episode values as EpisodePair (ordered ascending and limited to 5) for episodes where Episode > 260 and the first word of Segment A (the substring up to the first space, or the whole Segment A if no space) is equal to the first word of Segment B (the substring up to the first space, or the whole Segment B if no space) in a different episode (i.e., the Episode values are not the same).","
SELECT DISTINCT t1.`Episode` AS `EpisodePair`
FROM `table_m_1764882728690_e62adfe5_15187735_21` t1 JOIN `table_m_1764882728690_e62adfe5_15187735_21` t2 ON
substr(t1.`Segment A`,1,IIF(instr(t1.`Segment A`,' ')=0,length(t1.`Segment A`),instr(t1.`Segment A`,' ')-1))
=
substr(t2.`Segment B`,1,IIF(instr(t2.`Segment B`,' ')=0,length(t2.`Segment B`),instr(t2.`Segment B`,' ')-1))
WHERE t1.`Episode` != t2.`Episode` AND t1.`Episode` > 260
ORDER BY `EpisodePair`
LIMIT 5;
","
SELECT DISTINCT t1.col0 AS `EpisodePair`
FROM `table_m_1764882728690_e62adfe5_15187735_21` t1 JOIN `table_m_1764882728690_e62adfe5_15187735_21` t2 ON
substr(t1.col1,1,IIF(instr(t1.col1,' ')=0,length(t1.col1),instr(t1.col1,' ')-1))
=
substr(t2.col2,1,IIF(instr(t2.col2,' ')=0,length(t2.col2),instr(t2.col2,' ')-1))
WHERE t1.col0 != t2.col0 AND t1.col0 > 260
ORDER BY `EpisodePair`
LIMIT 5;
","[(267.0,)]",m_1764882728690_e62adfe5_15187735-21,"Parse: the query selects distinct Episode values where the leading substring (first word) of Segment A equals the leading substring of Segment B from a different row, only for Episode > 260, ordered and limited to 5. Map schema: Episode, Segment A, Segment B are the relevant columns. Draft: formulate question requesting EpisodePair results with all specified substring logic, episode inequality, Episode > 260, ORDER BY and LIMIT 5. Validate: ensure mention of alias EpisodePair, first-word extraction rule, different episodes, Episode > 260, ordering and limit.",reserved,11,N/A,split_column,
Which Netflix has the most priority episodes?,"
SELECT DISTINCT `Netflix`,
  SUM(CASE WHEN `Episode` IN (110,114) THEN 1 ELSE 0 END) AS `Priority_Count`
FROM `table_m_1764882757131_bc79dbc5_15187735_9`
WHERE `Episode` IS 110 OR `Episode` = 114
GROUP BY `Netflix`
ORDER BY `Priority_Count` DESC
LIMIT 3;
","
SELECT DISTINCT col2,
  SUM(CASE WHEN col1 IN (110,114) THEN 1 ELSE 0 END) AS `Priority_Count`
FROM `table_m_1764882757131_bc79dbc5_15187735_9`
WHERE col1 IS 110 OR col1 = 114
GROUP BY col2
ORDER BY `Priority_Count` DESC
LIMIT 3;
","[('S05E10', 1), ('S05E06', 1)]",m_1764882757131_bc79dbc5_15187735-9,"STEP 1: Parse the SQL intent: the query filters rows to Episode 110 or 114, groups rows by the Netflix column, counts how many of those two episodes appear per Netflix value (via SUM CASE), orders by that count descending, and returns the top three Netflix values with their counts. STEP 2: Determine a type of ambiguity: scope ambiguity fits well — the phrasing “the most” or “has the most” can refer to different scopes (a single overall winner, top N winners, or a per-episode winner). STEP 3: Draft the question: Which Netflix has the most priority episodes? STEP 4: Explain the ambiguity: in the original query this is implemented as counting occurrences of episodes 110 and 114 per Netflix and returning the top three overall; alternatively the same question could mean (a) ask for the single Netflix with the highest combined count, (b) ask for the top Netflix for each of episodes 110 and 114 separately, or (c) ask for all Netflix entries that contain any priority episode rather than ranking them.",reserved,19,N/A,add_column,"type: Scope ambiguity | explanation: The SQL treats 'the most' as a combined count of episodes 110 and 114 per Netflix and returns the top three; however a reader could instead interpret 'the most' as asking for a single top Netflix, the top Netflix for each episode separately, or simply which Netflix entries contain any priority episode rather than ranking them."
"Provide up to 10 Districts for which the ""Median monthly per capita / labour force income (HKD)"" contains a ' / ' and where the summed product of the labour-force median (the numeric value after ' / ' with commas removed) times Population (2006_est.) is greater than 3000000000; for each District, show the District name, the per-capita median (the numeric part before ' / ' with commas removed), the labour-force median (the numeric part after ' / ' with commas removed), the Population (2006_est.), and the EstimatedMonthlyLabourTotal calculated as the sum of (LabourForce * Population) for that District.","
SELECT DISTINCT `District`,
(REPLACE(SUBSTR(`Median monthly per capita / labour force income (HKD)`,1,INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')-1),',','')+0) `PerCapita`,
(REPLACE(SUBSTR(`Median monthly per capita / labour force income (HKD)`,INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')+3),',','')+0) `LabourForce`,
(`Population (2006_est.)`+0) `Population`,
SUM((REPLACE(SUBSTR(`Median monthly per capita / labour force income (HKD)`,INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')+3),',','')+0)*(`Population (2006_est.)`+0)) AS `EstimatedMonthlyLabourTotal`
FROM `table_m_1764882765187_3f219a78_151994_1`
WHERE INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')>0
GROUP BY `District`
HAVING SUM((REPLACE(SUBSTR(`Median monthly per capita / labour force income (HKD)`,INSTR(`Median monthly per capita / labour force income (HKD)`,' / ')+3),',','')+0)*(`Population (2006_est.)`+0))>3000000000
LIMIT 10;
","
SELECT DISTINCT col0,
(REPLACE(SUBSTR(col4,1,INSTR(col4,' / ')-1),',','')+0) `PerCapita`,
(REPLACE(SUBSTR(col4,INSTR(col4,' / ')+3),',','')+0) `LabourForce`,
(col1+0) `Population`,
SUM((REPLACE(SUBSTR(col4,INSTR(col4,' / ')+3),',','')+0)*(col1+0)) AS `EstimatedMonthlyLabourTotal`
FROM `table_m_1764882765187_3f219a78_151994_1`
WHERE INSTR(col4,' / ')>0
GROUP BY col0
HAVING SUM((REPLACE(SUBSTR(col4,INSTR(col4,' / ')+3),',','')+0)*(col1+0))>3000000000
LIMIT 10;
","[('Central and Western ( 中西 )', 9722, 17178, 250064.0, 4295599392.0), ('Eastern ( 東 )', 7235, 13558, 587690.0, 7967901020.0), ('Hong Kong Island ( 香港島 )', 7931, 14568, 1268112.0, 18473855616.0), ('Kowloon ( 九龍 )', 5184, 10311, 2019533.0, 20823404763.0), ('Kowloon City ( 九龍城 )', 6897, 13122, 362501.0, 4756738122.0), ('Kwai Tsing ( 葵青 )', 4833, 9718, 523300.0, 5085429400.0), ('Kwun Tong ( 觀塘 )', 4845, 9908, 587423.0, 5820187084.0), ('Land total', 5753, 11055, 6861280.0, 75851450400.0), ('New Territories ( 新界 )', 5667, 10860, 3573635.0, 38809676100.0), ('Sai Kung ( 西貢 )', 6774, 12183, 406442.0, 4951682886.0)]",m_1764882765187_3f219a78_151994-1,"1) The SQL filters rows that have a ' / ' in the median income field, parses both median values to numbers by removing commas, multiplies the labour-force median by population, sums per District, and keeps groups with sum > 3,000,000,000, limiting output to 10. 2) Map to schema: Median monthly per capita / labour force income (HKD) -> PerCapita and LabourForce, Population (2006_est.) -> Population, and compute EstimatedMonthlyLabourTotal = SUM(LabourForce * Population). 3) Draft a question that asks for District, parsed PerCapita, parsed LabourForce, Population, and the aggregated EstimatedMonthlyLabourTotal, with the specified filter and limit. 4) Validate inclusion of the parsing, numeric conversion (remove commas), multiplication, aggregation, threshold >3000000000, and limit 10 in the question.",reserved,9,N/A,add_column,
"For episodes where Countries Visited contains 'USA' or 'Australia', what is each Presenter's Presenter name, the Total_Episodes (COUNT of those episodes per Presenter), and USA (the SUM counting 1 when Countries Visited contains 'USA' and 0 otherwise), showing only presenters with at least one such episode and ordering the output by Total_Episodes descending?","
SELECT `Presenter` AS `Presenter`, COUNT(*) AS `Total_Episodes`,
SUM(CASE WHEN `Countries Visited` LIKE '%USA%' THEN 1 ELSE 0 END) `USA`
FROM `table_m_1764882777032_a73568f6_15211468_1`
WHERE `Countries Visited` LIKE '%USA%' OR `Countries Visited` LIKE '%Australia%'
GROUP BY `Presenter`
HAVING COUNT(*)>0
ORDER BY `Total_Episodes` DESC;
","
SELECT col3 AS col3, COUNT(*) AS `Total_Episodes`,
SUM(CASE WHEN col5 LIKE '%USA%' THEN 1 ELSE 0 END) `USA`
FROM `table_m_1764882777032_a73568f6_15211468_1`
WHERE col5 LIKE '%USA%' OR col5 LIKE '%Australia%'
GROUP BY col3
HAVING COUNT(*)>0
ORDER BY `Total_Episodes` DESC;
","[('Michael Frayn', 1, 0), ('Ludovic Kennedy', 1, 1)]",m_1764882777032_a73568f6_15211468-1,"1) The SQL retrieves Presenter, counts episodes, and sums episodes that visited USA, limited to rows where Countries Visited contains 'USA' or 'Australia', grouped and ordered by count. 2) Interpret Presenter as the presenter name column, Total_Episodes as COUNT(*), and USA as SUM of a conditional test on Countries Visited LIKE '%USA%'. 3) Draft a question asking for Presenter, Total_Episodes and USA with the WHERE restriction to Countries Visited containing 'USA' or 'Australia', grouping by Presenter, requiring COUNT(*)>0, and ordering by Total_Episodes descending. 4) Check that the question mentions the Presenter column, the COUNT and conditional SUM calculation, the filter, grouping, HAVING and ordering.",reserved,19,N/A,add_column,
"For rows where No. in season is between 1 and 17 inclusive, what are the Total episodes (COUNT(*)), Disc 1_count (SUM((No. disc)=1)), Disc 2_count (SUM((No. disc)=2)), Disc 3_count (SUM((No. disc)=3)), Disc 4_count (SUM((No. disc)=4)), Disc 5_count (SUM((No. disc)=5)), First_ep (MIN(No. in season)), Last_ep (MAX(No. in season)), and Avg_ep (AVG(No. in season))?","
SELECT COUNT(*) `Total episodes`, SUM((`No. disc`)=1) `Disc 1_count`, SUM((`No. disc`)=2) `Disc 2_count`, SUM((`No. disc`)=3) `Disc 3_count`, SUM((`No. disc`)=4) `Disc 4_count`, SUM((`No. disc`)=5) `Disc 5_count`, MIN(`No. in season`) `First_ep`, MAX(`No. in season`) `Last_ep`, AVG(`No. in season`) `Avg_ep`
FROM `table_m_1764882821608_04346dc3_15284274_1`
WHERE (`No. in season` >= 1) AND (`No. in season` <= 17);
","
SELECT COUNT(*) `Total episodes`, SUM((col1)=1) `Disc 1_count`, SUM((col1)=2) `Disc 2_count`, SUM((col1)=3) `Disc 3_count`, SUM((col1)=4) `Disc 4_count`, SUM((col1)=5) `Disc 5_count`, MIN(col0) `First_ep`, MAX(col0) `Last_ep`, AVG(col0) `Avg_ep`
FROM `table_m_1764882821608_04346dc3_15284274_1`
WHERE (col0 >= 1) AND (col0 <= 17);
","[(14, 4, 3, 4, 2, 1, 1.0, 17.0, 8.428571428571429)]",m_1764882821608_04346dc3_15284274-1,"1) Parse the SQL intent: compute overall episode count, per-disc counts for discs 1–5, and min/max/avg of episode numbers restricted to No. in season between 1 and 17. 2) Map schema semantics: use the columns No. in season and No. disc and the aggregations COUNT(*), SUM((No. disc)=n), MIN(No. in season), MAX(No. in season), AVG(No. in season). 3) Draft the question: request each aggregate with their labels (Total episodes, Disc 1_count … Disc 5_count, First_ep, Last_ep, Avg_ep) and the filter. 4) Validate: confirm all columns, calculations, and the range condition 1–17 are mentioned.",reserved,4,N/A,add_column,
"List each MotoGP winner (Winner) with the COUNT(*) as Wins, the MIN(Round) as First, and the MAX(Round) as Last, excluding NULL MotoGP winners, grouped by MotoGP winner and restricted to those with Wins > 1 and Wins in (2, 3, 4, 5), ordered by Wins (ascending) and limited to 10 rows?",unanswerable,unanswerable,,m_1764882833690_745980da_15299235-1,"1) Parse intent: compute win totals and the earliest/latest round per MotoGP winner, include only winners with 2–5 wins. 2) Map schema: use `MotoGP winner` and `Round` for aggregations. 3) Draft: request Winner, Wins, First, Last with non-null filter, group, HAVING, ORDER BY, LIMIT. 4) Validate: question mirrors COUNT, MIN, MAX, HAVING IN and ORDER constraints.",reserved,16,N/A,merge_column,
"For each distinct Country, what is the Wins count, the Avg Winner Share Pct defined as ROUND(AVG(CAST(Winners share ($) AS REAL)/Purse ($)),6), and the Payout flag that reads 'Below avg payout' when that AVG rounded to 6 decimals is < 0.142, returning only countries with more than 0 wins and limiting the output to 100 rows?","
SELECT DISTINCT `Country`, COUNT(*) `Wins`, ROUND(AVG(CAST(`Winners share ($)` AS REAL)/`Purse ($)`),6) `Avg Winner Share Pct`, CASE WHEN ROUND(AVG(CAST(`Winners share ($)` AS REAL)/`Purse ($)`),6) < 0.142 THEN '`Below avg payout`' END `Payout flag` FROM `table_m_1764882862557_7b838205_15315816_1` GROUP BY `Country` HAVING COUNT(*)>0 LIMIT 100;
","
SELECT DISTINCT col3, COUNT(*) `Wins`, ROUND(AVG(CAST(col7 AS REAL)/col6),6) `Avg Winner Share Pct`, CASE WHEN ROUND(AVG(CAST(col7 AS REAL)/col6),6) < 0.142 THEN '`Below avg payout`' END `Payout flag` FROM `table_m_1764882862557_7b838205_15315816_1` GROUP BY col3 HAVING COUNT(*)>0 LIMIT 100;
","[('Australia', 2, 0.14, '`Below avg payout`'), ('Brazil', 1, 0.14, '`Below avg payout`'), ('Canada', 1, 0.14, '`Below avg payout`'), ('Paraguay', 1, 0.14, '`Below avg payout`'), ('South Korea', 3, 0.14, '`Below avg payout`'), ('Taiwan', 1, 0.15, None), ('Thailand', 1, 0.14, '`Below avg payout`'), ('United States', 3, 0.143333, None)]",m_1764882862557_7b838205_15315816-1,"1) Parse the SQL intent: produce per-country distinct rows with total wins, the mean winners-share-to-purse ratio rounded to six decimals, and a flag if that mean is below 0.142, restricting to countries with at least one win and up to 100 rows. 2) Map schema semantics: Country, Winners share ($), Purse ($), COUNT(*) → Wins. 3) Draft the question: include explicit rounding to 6 decimals and the exact flag text. 4) Validate: ensure rounding, threshold, HAVING condition, and LIMIT 100 are all present.",reserved,12,N/A,add_column,
"For entries where Played = 20, and grouping results by Team with groups having SUM(Points) >= 10, what are the Team, Points, the goal difference computed as (For - Against) and labeled ""Palmeiras"", and the Points per Game (Points / Played), ordered by Points and limited to 5 rows?","
SELECT `Team`, `Points`, (`Goals_For_and_Against` - `Goals_For_and_Against`) `Palmeiras`, (`Points` / `Played`) `Points per Game`
FROM `table_m_1764882878150_b579de94_15318779_1`
WHERE `Played` = 20
GROUP BY `Team`
HAVING SUM(`Points`) >= 10
ORDER BY `Points`
LIMIT 5;
","
SELECT col1, col2, (col8 - col8) `Palmeiras`, (col2 / col3) `Points per Game`
FROM `table_m_1764882878150_b579de94_15318779_1`
WHERE col3 = 20
GROUP BY col1
HAVING SUM(col2) >= 10
ORDER BY col2
LIMIT 5;
","[('Nacional-SP', 10.0, 0, 0.5), ('Comercial-SP', 11.0, 0, 0.55), ('Portuguesa Santista', 15.0, 0, 0.75), ('Juventus', 16.0, 0, 0.8), ('Santos', 19.0, 0, 0.95)]",m_1764882878150_b579de94_15318779-1,"1) The SQL intent is to produce a grouped list by Team for Played = 20 including Points and two computed fields, only keeping teams whose summed Points >= 10, sorted by Points and limited to five results. 2) Columns For and Against are used to compute (For - Against) aliased Palmeiras; Points and Played are used to compute Points per Game. 3) Formulate a question that requests those exact outputs and applies the WHERE, GROUP BY, HAVING, ORDER BY, and LIMIT constraints. 4) Ensure the question mentions the alias ""Palmeiras"" for the goal difference and the Points per Game calculation.",reserved,9,N/A,merge_column,
"For every team outside the top four, what’s their position and points, how many points are they short of 4th (zero if level or ahead), what’s the minimum number of wins that would cover that gap, and who are the three teams that have conceded the most goals (with the numbers)?","
SELECT
  t.`Position`,
  t.`Team`,
  t.`Points`,
  top4.`Points` AS `Top4 Points`,
  (CASE WHEN top4.`Points` - t.`Points` <= 0 THEN 0 ELSE top4.`Points` - t.`Points` END) AS `Points_to_reach_top4`,
  CAST(((CASE WHEN top4.`Points` - t.`Points` <= 0 THEN 0 ELSE top4.`Points` - t.`Points` END) + 2) / 3 AS INTEGER) AS `Min_wins_needed`,
  td.`Top_3_weak_defenses`
FROM `table_m_1764882906152_632ae75c_15400878_1` AS t
CROSS JOIN (SELECT `Points` FROM `table_m_1764882906152_632ae75c_15400878_1` WHERE `Position` = 4) AS top4
CROSS JOIN (
  SELECT group_concat(`Team` || ' (`' || `Against` || '`) ', ', ') AS `Top_3_weak_defenses`
  FROM (
    SELECT `Team`,`Against` FROM `table_m_1764882906152_632ae75c_15400878_1` ORDER BY `Against` DESC LIMIT 3
  )
) AS td
WHERE t.`Position` > 4
ORDER BY `Points_to_reach_top4` ASC;
","
SELECT
  t.col0,
  t.col1,
  t.col2,
  top4.col2 AS `Top4 Points`,
  (CASE WHEN top4.col2 - t.col2 <= 0 THEN 0 ELSE top4.col2 - t.col2 END) AS `Points_to_reach_top4`,
  CAST(((CASE WHEN top4.col2 - t.col2 <= 0 THEN 0 ELSE top4.col2 - t.col2 END) + 2) / 3 AS INTEGER) AS `Min_wins_needed`,
  td.`Top_3_weak_defenses`
FROM `table_m_1764882906152_632ae75c_15400878_1` AS t
CROSS JOIN (SELECT col2 FROM `table_m_1764882906152_632ae75c_15400878_1` WHERE col0 = 4) AS top4
CROSS JOIN (
  SELECT group_concat(col1 || ' (`' || col8 || '`) ', ', ') AS `Top_3_weak_defenses`
  FROM (
    SELECT col1,col8 FROM `table_m_1764882906152_632ae75c_15400878_1` ORDER BY col8 DESC LIMIT 3
  )
) AS td
WHERE t.col0 > 4
ORDER BY `Points_to_reach_top4` ASC;
","[(5.0, 'Ypiranga-SP', 15.0, 19.0, 4.0, 2, 'Mackenzie - Portuguesa (`77.0`) , AA das Palmeiras (`73.0`) , SC Internacional de São Paulo (`57.0`) '), (6.0, 'Minas Gerais', 14.0, 19.0, 5.0, 2, 'Mackenzie - Portuguesa (`77.0`) , AA das Palmeiras (`73.0`) , SC Internacional de São Paulo (`57.0`) '), (7.0, 'SC Internacional de São Paulo', 11.0, 19.0, 8.0, 3, 'Mackenzie - Portuguesa (`77.0`) , AA das Palmeiras (`73.0`) , SC Internacional de São Paulo (`57.0`) '), (8.0, 'AA das Palmeiras', 5.0, 19.0, 14.0, 5, 'Mackenzie - Portuguesa (`77.0`) , AA das Palmeiras (`73.0`) , SC Internacional de São Paulo (`57.0`) '), (9.0, 'Mackenzie - Portuguesa', 3.0, 19.0, 16.0, 6, 'Mackenzie - Portuguesa (`77.0`) , AA das Palmeiras (`73.0`) , SC Internacional de São Paulo (`57.0`) ')]",m_1764882906152_632ae75c_15400878-1,"Persona: A pragmatic São Paulo state league performance analyst who talks in clear football terms and avoids SQL jargon. They know about points, wins and conceded goals but not column names. SQL intent: compute, for every team below 4th, the points gap to 4th (clamped at 0), the minimum wins needed (ceil gap/3), and include the list of the three teams with the most goals conceded. Schema mapping: uses each team's position, name and points and the 4th-placed team's points, plus the top three teams ordered by goals conceded. Draft question: For every team outside the top four, tell me their position, current points, how many points they need to reach 4th (zero if level or ahead), the minimum number of wins that represents, and also list the three teams that have conceded the most goals with their conceded totals. Validation: This matches the query's outputs and scope without adding extra details.",persona,"```json
{
  ""short_persona_description"": ""Performance analyst for a mid-table São Paulo state league club preparing tactical and points targets for the remainder of the season. Uses the league table to identify promotion/relegation risk, efficient teams, and opponents with exploitable defensive weaknesses."",
  ""goals"": [
    ""Determine how many points (or wins) are needed to reach a target position (e.g., top 4) given current standings."",
    ""Identify opponents with poor defensive records (high Goals:  Example Queries: ",N/A,remove_column,
"For each distinct Landfall, what are the total number of storms, the average CHI rounded to one decimal (Avg_CHI), the highest observed V(mph), and the highest observed R(miles), restricting rows to those with Year in (2003, 2004, 2005) or where Saffir-Simpson Category >= 2 and CHI > 5, keeping only landfalls with more than one storm, and showing the top 5 landfalls ordered by Avg_CHI descending?","
SELECT DISTINCT `t`.`Landfall`, COUNT(*) `Storms`, ROUND(AVG(`CHI`),1) `Avg_CHI`, MAX(`V(mph)`) `Max_V`, MAX(`R(miles)`) `Max_R`
FROM `table_m_1764882931477_4fa847b3_15416002_1` AS `t`
WHERE `Year` IN (2003,2004,2005) OR `Saffir-Simpson Category` >= 2 AND `CHI` > 5
GROUP BY `t`.`Landfall`
HAVING COUNT(*) > 1
ORDER BY `Avg_CHI` DESC
LIMIT 5;
","
SELECT DISTINCT `t`.col2, COUNT(*) `Storms`, ROUND(AVG(col6),1) `Avg_CHI`, MAX(col3) `Max_V`, MAX(col4) `Max_R`
FROM `table_m_1764882931477_4fa847b3_15416002_1` AS `t`
WHERE col1 IN (2003,2004,2005) OR col5 >= 2 AND col6 > 5
GROUP BY `t`.col2
HAVING COUNT(*) > 1
ORDER BY `Avg_CHI` DESC
LIMIT 5;
","[('Louisiana', 2, 12.1, 145.0, 120.0), ('North Carolina', 2, 8.7, 110.0, 115.0), ('Florida', 5, 6.7, 145.0, 75.0), ('Texas', 2, 5.9, 120.0, 85.0)]",m_1764882931477_4fa847b3_15416002-1,"1) Parse intent: group by Landfall, compute COUNT, ROUND(AVG(CHI),1), MAX V(mph), MAX R(miles), apply row-level filter Year IN (2003,2004,2005) OR (Saffir-Simpson Category >=2 AND CHI>5), require COUNT>1 for groups, sort by Avg_CHI desc and limit to 5. 2) Map schema: use Landfall, CHI, V(mph), R(miles), Year and Saffir-Simpson Category. 3) Draft: craft a natural question asking for these aggregated metrics per landfall with the exact filters, having clause, ordering and limit. 4) Validate: ensure all columns, calculations, filters, HAVING, ORDER BY, and LIMIT are mentioned.",reserved,14,N/A,split_column,
Which teams should we focus our training on?,"
WITH team_metrics AS (
  SELECT
    `Locale`,
    `Skip`,
    `W`,
    `L`,
    (CAST(`W` AS REAL) / (CAST(`W` AS REAL) + CAST(`L` AS REAL))) AS `win_pct`,
    CAST(REPLACE(`Shot Pct.`, '%', '') AS REAL) AS `shot_pct`,
    `PF`,
    `PA`,
    (`PF` - `PA`) AS `point_diff`,
    `Ends Won`,
    `Ends Lost`,
    `Blank Ends`,
    `Stolen Ends`,
    ( (`Stolen Ends`) / (CAST(`W` AS REAL) + CAST(`L` AS REAL)) ) AS `stolen_per_game`
  FROM `table_m_1764882942323_87f8b1e6_1543845_63`
),
stats AS (
  SELECT
    AVG(`shot_pct`) AS `avg_shot`,
    (CASE WHEN (AVG(`shot_pct` * `shot_pct`) - AVG(`shot_pct`) * AVG(`shot_pct`)) > 0 THEN sqrt(AVG(`shot_pct` * `shot_pct`) - AVG(`shot_pct`) * AVG(`shot_pct`)) ELSE 0 END) AS `sd_shot`,
    AVG(`point_diff`) AS `avg_pd`,
    (CASE WHEN (AVG(`point_diff` * `point_diff`) - AVG(`point_diff`) * AVG(`point_diff`)) > 0 THEN sqrt(AVG(`point_diff` * `point_diff`) - AVG(`point_diff`) * AVG(`point_diff`)) ELSE 0 END) AS `sd_pd`,
    AVG(`Stolen Ends`) AS `avg_stolen`,
    (CASE WHEN (AVG(`Stolen Ends` * `Stolen Ends`) - AVG(`Stolen Ends`) * AVG(`Stolen Ends`)) > 0 THEN sqrt(AVG(`Stolen Ends` * `Stolen Ends`) - AVG(`Stolen Ends`) * AVG(`Stolen Ends`)) ELSE 0 END) AS `sd_stolen`,
    AVG(`win_pct`) AS `avg_win`
  FROM team_metrics
)
SELECT
  t.`Locale`,
  t.`Skip`,
  t.`W`,
  t.`L`,
  ROUND(t.`win_pct`, 3) AS `win_pct`,
  t.`shot_pct`,
  t.`PF`,
  t.`PA`,
  t.`point_diff`,
  t.`Stolen Ends`,
  ROUND(t.`stolen_per_game`,3) AS `stolen_per_game`,
  s.`avg_shot`,
  s.`sd_shot`,
  s.`avg_pd`,
  s.`sd_pd`,
  s.`avg_stolen`,
  -- z-scores (normalized metrics)
  ROUND((t.`shot_pct` - s.`avg_shot`) / (CASE WHEN s.`sd_shot` = 0 THEN 1 ELSE s.`sd_shot` END),3) AS `shot_z`,
  ROUND((t.`point_diff` - s.`avg_pd`) / (CASE WHEN s.`sd_pd` = 0 THEN 1 ELSE s.`sd_pd` END),3) AS `pd_z`,
  ROUND((t.`Stolen Ends` - s.`avg_stolen`) / (CASE WHEN s.`sd_stolen` = 0 THEN 1 ELSE s.`sd_stolen` END),3) AS `stolen_z`,
  -- actionable outlier classification to inform training focus
  CASE
    WHEN ( (t.`shot_pct` - s.`avg_shot`) / (CASE WHEN s.`sd_shot` = 0 THEN 1 ELSE s.`sd_shot` END) ) < -1
         AND t.`win_pct` > s.`avg_win` + 0.05
      THEN 'Low shot accuracy but above-average wins -> tactical/steal-focused opponent (work on disrupting steals)'
    WHEN ( (t.`shot_pct` - s.`avg_shot`) / (CASE WHEN s.`sd_shot` = 0 THEN 1 ELSE s.`sd_shot` END) ) > 1
         AND ( (t.`point_diff` - s.`avg_pd`) / (CASE WHEN s.`sd_pd` = 0 THEN 1 ELSE s.`sd_pd` END) ) > 0.5
      THEN 'High precision and positive scoring efficiency -> opponent relies on shot-making (emphasize pressure shots)'
    WHEN t.`Stolen Ends` >= s.`avg_stolen` + s.`sd_stolen`
      THEN 'High stolen-ends contributor -> prioritize blank/defensive practice to avoid steals'
    WHEN ( (t.`point_diff` - s.`avg_pd`) / (CASE WHEN s.`sd_pd` = 0 THEN 1 ELSE s.`sd_pd` END) ) < -1
      THEN 'Negative outlier in point differential -> potential defensive weakness to exploit'
    ELSE 'No strong outlier signal'
  END AS `outlier_insight`
FROM team_metrics t
CROSS JOIN stats s
ORDER BY `shot_z` ASC, `stolen_z` DESC, `point_diff` DESC;
","
WITH team_metrics AS (
  SELECT
    col0,
    col1,
    col2,
    col3,
    (CAST(col2 AS REAL) / (CAST(col2 AS REAL) + CAST(col3 AS REAL))) AS `win_pct`,
    CAST(REPLACE(col10, '%', '') AS REAL) AS `shot_pct`,
    col4,
    col5,
    (col4 - col5) AS `point_diff`,
    col6,
    col7,
    col8,
    col9,
    ( (col9) / (CAST(col2 AS REAL) + CAST(col3 AS REAL)) ) AS `stolen_per_game`
  FROM `table_m_1764882942323_87f8b1e6_1543845_63`
),
stats AS (
  SELECT
    AVG(`shot_pct`) AS `avg_shot`,
    (CASE WHEN (AVG(`shot_pct` * `shot_pct`) - AVG(`shot_pct`) * AVG(`shot_pct`)) > 0 THEN sqrt(AVG(`shot_pct` * `shot_pct`) - AVG(`shot_pct`) * AVG(`shot_pct`)) ELSE 0 END) AS `sd_shot`,
    AVG(`point_diff`) AS `avg_pd`,
    (CASE WHEN (AVG(`point_diff` * `point_diff`) - AVG(`point_diff`) * AVG(`point_diff`)) > 0 THEN sqrt(AVG(`point_diff` * `point_diff`) - AVG(`point_diff`) * AVG(`point_diff`)) ELSE 0 END) AS `sd_pd`,
    AVG(col9) AS `avg_stolen`,
    (CASE WHEN (AVG(col9 * col9) - AVG(col9) * AVG(col9)) > 0 THEN sqrt(AVG(col9 * col9) - AVG(col9) * AVG(col9)) ELSE 0 END) AS `sd_stolen`,
    AVG(`win_pct`) AS `avg_win`
  FROM team_metrics
)
SELECT
  t.col0,
  t.col1,
  t.col2,
  t.col3,
  ROUND(t.`win_pct`, 3) AS `win_pct`,
  t.`shot_pct`,
  t.col4,
  t.col5,
  t.`point_diff`,
  t.col9,
  ROUND(t.`stolen_per_game`,3) AS `stolen_per_game`,
  s.`avg_shot`,
  s.`sd_shot`,
  s.`avg_pd`,
  s.`sd_pd`,
  s.`avg_stolen`,
  -- z-scores (normalized metrics)
  ROUND((t.`shot_pct` - s.`avg_shot`) / (CASE WHEN s.`sd_shot` = 0 THEN 1 ELSE s.`sd_shot` END),3) AS `shot_z`,
  ROUND((t.`point_diff` - s.`avg_pd`) / (CASE WHEN s.`sd_pd` = 0 THEN 1 ELSE s.`sd_pd` END),3) AS `pd_z`,
  ROUND((t.col9 - s.`avg_stolen`) / (CASE WHEN s.`sd_stolen` = 0 THEN 1 ELSE s.`sd_stolen` END),3) AS `stolen_z`,
  -- actionable outlier classification to inform training focus
  CASE
    WHEN ( (t.`shot_pct` - s.`avg_shot`) / (CASE WHEN s.`sd_shot` = 0 THEN 1 ELSE s.`sd_shot` END) ) < -1
         AND t.`win_pct` > s.`avg_win` + 0.05
      THEN 'Low shot accuracy but above-average wins -> tactical/steal-focused opponent (work on disrupting steals)'
    WHEN ( (t.`shot_pct` - s.`avg_shot`) / (CASE WHEN s.`sd_shot` = 0 THEN 1 ELSE s.`sd_shot` END) ) > 1
         AND ( (t.`point_diff` - s.`avg_pd`) / (CASE WHEN s.`sd_pd` = 0 THEN 1 ELSE s.`sd_pd` END) ) > 0.5
      THEN 'High precision and positive scoring efficiency -> opponent relies on shot-making (emphasize pressure shots)'
    WHEN t.col9 >= s.`avg_stolen` + s.`sd_stolen`
      THEN 'High stolen-ends contributor -> prioritize blank/defensive practice to avoid steals'
    WHEN ( (t.`point_diff` - s.`avg_pd`) / (CASE WHEN s.`sd_pd` = 0 THEN 1 ELSE s.`sd_pd` END) ) < -1
      THEN 'Negative outlier in point differential -> potential defensive weakness to exploit'
    ELSE 'No strong outlier signal'
  END AS `outlier_insight`
FROM team_metrics t
CROSS JOIN stats s
ORDER BY `shot_z` ASC, `stolen_z` DESC, `point_diff` DESC;
","[('Italy', 'Joël Retornaz', 4.0, 5.0, 0.444, 70.0, 47.0, 66.0, -19.0, 7.0, 0.778, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, -2.47, -1.575, -0.802, 'Negative outlier in point differential -> potential defensive weakness to exploit'), ('Switzerland', 'Ralph Stöckli', 5.0, 4.0, 0.556, 76.0, 56.0, 45.0, 11.0, 10.0, 1.111, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, -0.509, 0.45, -0.2, 'No strong outlier signal'), ('Germany', 'Andy Kapp', 3.0, 6.0, 0.333, 77.0, 53.0, 55.0, -2.0, 12.0, 1.333, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, -0.182, -0.427, 0.2, 'No strong outlier signal'), ('Finland', 'Markku Uusipaavalniemi', 7.0, 2.0, 0.778, 78.0, 53.0, 40.0, 13.0, 9.0, 1.0, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.145, 0.585, -0.401, 'No strong outlier signal'), ('Norway', 'Pål Trulsen', 5.0, 4.0, 0.556, 78.0, 57.0, 47.0, 10.0, 9.0, 1.0, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.145, 0.382, -0.401, 'No strong outlier signal'), ('Sweden', 'Peja Lindholm', 3.0, 6.0, 0.333, 78.0, 45.0, 68.0, -23.0, 4.0, 0.444, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.145, -1.845, -1.403, 'Negative outlier in point differential -> potential defensive weakness to exploit'), ('Canada', 'Brad Gushue', 6.0, 3.0, 0.667, 80.0, 66.0, 46.0, 20.0, 23.0, 2.556, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.799, 1.057, 2.405, 'High stolen-ends contributor -> prioritize blank/defensive practice to avoid steals'), ('United States', 'Pete Fenson', 6.0, 3.0, 0.667, 80.0, 66.0, 47.0, 19.0, 13.0, 1.444, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 0.799, 0.99, 0.401, 'No strong outlier signal'), ('Great Britain', 'David Murdoch', 6.0, 3.0, 0.667, 81.0, 59.0, 49.0, 10.0, 12.0, 1.333, 77.55555555555556, 3.0590888662080364, 4.333333333333333, 14.817407180595247, 11.0, 1.126, 0.382, 0.2, 'No strong outlier signal')]",m_1764882942323_87f8b1e6_1543845-63,"STEP 1: Parse the SQL intent — compute per-team metrics (win percentage, shot percentage, point differential, stolen ends per game), compute dataset averages and standard deviations, produce z-scores and classify teams into actionable 'outlier_insight' labels (training/strategy recommendations), and order results by shot_z asc, stolen_z desc, point_diff desc. STEP 2: Choose ambiguity type — Attachment ambiguity fits: the phrase about focusing training can attach to either the teams (they should receive practice) or to our training (we should practice against them). STEP 3: Draft the question — ""Which teams should we focus our training on?"" STEP 4: Explain ambiguity — in the original query the CASE labels are framed as opponent-focused actionable guidance (i.e., who we should prepare against and how), so the SQL reads the question as which opponents to prioritize preparing for; alternatively the natural reading could mean which teams need internal training (teams that should receive practice themselves).",persona,"National team performance analyst for a curling federation who evaluates opponent and team performance metrics to inform training and game strategy. Uses the 2006 Olympic standings to benchmark historical performance and identify patterns in scoring, steals and shot accuracy. Goals: Compare teams by shot accuracy to identify which opponents rely on precision versus tactical scoring. Quantify scoring efficiency and defensive strength via point differential (PF - PA) and stolen ends. Identify outlier performances (high win rate with lower shot pct, or teams that steal many ends) to inform strategy and practice priorities. Example Queries: SELECT ""Locale"", ""Skip"", ""W"", ""L"", ""Shot Pct."" 
FROM table_1_1543845_63 
ORDER BY CAST(REPLACE(""Shot Pct."", '%', '') AS REAL) DESC, ""W"" DESC; SELECT ""Locale"", ""Skip"", ""PF"", ""PA"", (""PF"" - ""PA"") AS point_diff 
FROM table_1_1543845_63 
ORDER BY point_diff DESC; SELECT ""Locale"", ""Skip"", ""W"", ""L"", (CAST(""W"" AS REAL) / (CAST(""W"" AS REAL) + CAST(""L"" AS REAL))) AS win_pct, ""Stolen Ends"", ""Blank Ends"" 
FROM table_1_1543845_63 
WHERE ""Stolen Ends"" >= 7 
ORDER BY ""Stolen Ends"" DESC, win_pct DESC;",N/A,add_column,"type: Attachment ambiguity | explanation: The modifier 'focus our training on' can attach to 'we' (meaning: which opponents we should prepare to face and train against) or to 'teams' (meaning: which teams themselves need to receive/prioritize practice); the SQL's outlier_insight text is written as opponent-focused actionable guidance, but the plain question could reasonably be interpreted the other way."
"For all rows satisfying Report = Report and Rd > 0, what are COUNT(*) AS total_races, SUM((`Pole Position` = `Winning driver`)) AS pole_and_win_count, SUM((`Fastest Lap` = `Winning driver`)) AS fastest_and_win_count, 100.0 * SUM((`Pole Position` = `Winning driver`)) / COUNT(*) AS pole_to_win_pct, and 100.0 * SUM((`Fastest Lap` = `Winning driver`)) / COUNT(*) AS fastest_to_win_pct?","
SELECT COUNT(*) total_races,
       SUM((""`Pole Position`"" = ""`Winning driver`"")) pole_and_win_count,
       SUM((""`Fastest Lap`"" = ""`Winning driver`"")) fastest_and_win_count,
       100.0 * SUM((""`Pole Position`"" = ""`Winning driver`"")) / COUNT(*) pole_to_win_pct,
       100.0 * SUM((""`Fastest Lap`"" = ""`Winning driver`"")) / COUNT(*) fastest_to_win_pct
FROM `table_m_1764882960357_c6910ab1_15511178_3`
WHERE ""`race_report`"" = ""`race_report`"" AND ""`round_number`"" > 0;
","
SELECT COUNT(*) total_races,
       SUM((""col2"" = ""col4"")) pole_and_win_count,
       SUM((""col3"" = ""col4"")) fastest_and_win_count,
       100.0 * SUM((""col2"" = ""col4"")) / COUNT(*) pole_to_win_pct,
       100.0 * SUM((""col3"" = ""col4"")) / COUNT(*) fastest_to_win_pct
FROM `table_m_1764882960357_c6910ab1_15511178_3`
WHERE ""col6"" = ""col6"" AND ""col0"" > 0;
","[(9, 5, 2, 55.55555555555556, 22.22222222222222)]",m_1764882960357_c6910ab1_15511178-3,"1) Parse the SQL intent: aggregate race data to produce counts of races, counts where pole or fastest-lap driver equals the winner, and corresponding percentages, with the filter Report = Report AND Rd > 0. 2) Map schema semantics: leverage `Rd`, `Pole Position`, `Fastest Lap`, `Winning driver`, and `Report` fields. 3) Draft the question: request the five outputs exactly as named and defined by COUNT(*), SUM((... = ...)), and 100.0 * SUM(...)/COUNT(*) expressions under the given WHERE clause. 4) Validate: ensure the question contains total_races, pole_and_win_count, fastest_and_win_count, pole_to_win_pct, fastest_to_win_pct and the conditions Report = Report and Rd > 0.",reserved,4,N/A,rename_column,
Which states improved the most from the preliminary to the semifinal?,unanswerable,unanswerable,,m_1764882972217_72a3722b_15532342-2,"STEP 1: Parse the SQL intent — The query extracts each state's preliminary and semifinal numeric averages, computes the absolute and percent improvement (semifinal minus preliminary and percent change), filters to states whose semifinal score is greater than their preliminary score and at least 8.0, then returns the top 3 states ordered by percent improvement descending. STEP 2: Determine ambiguity type — Metric (measure) ambiguity fits well: the natural phrase ""improved the most"" can refer to different measures (percent improvement, absolute point improvement, rank change, or simply highest semifinal score). The SQL specifically uses percent improvement but a human question wouldn't make that explicit. STEP 3: Draft the question — ""Which states improved the most from the preliminary to the semifinal?"" STEP 4: Explain ambiguity — In the original query ""improved the most"" is implemented as percent improvement with an added filter (semifinal > preliminary and semifinal >= 8.0) and returns the top 3 by percent change. Alternatively, a new query could interpret ""improved the most"" as absolute point gain, as the largest rise in rank/placement, as the highest semifinal score among those who improved, or could omit the semifinal >= 8.0 threshold.",reserved,8,N/A,merge_column,"type: Metric (measure) ambiguity | explanation: The SQL picks the top 3 by percent improvement and excludes cases where semifinal <= preliminary or semifinal < 8.0, but the question ""improved the most"" could equally mean largest absolute point increase, biggest jump in rank, highest semifinal score after improving, or include all states without the >=8.0 cutoff."
"Please return a single-row listing the columns 'Time', '12:00 PM', '01:00 PM', '02:00 PM', '03:00 PM', '04:00 PM', '05:00 PM', '05:55 PM' and the program values for each weekday/time: Monday: 'Asian Hero (VJ Mike)' at 12:00 PM, 'Melosamosorn (VJ Woonsen)' at 01:00 PM, 'Asian Chart (VJ Mike)' at 02:00 PM, '[V] Tunes' at 03:00 PM, 'Zog Zag (VJ Loukade, Ake, Bank)' at 04:00 PM, 'Khon Du Pen Yai (Live)' at 05:00 PM, '[V] Covery' at 05:55 PM; Tuesday: 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Mainstage', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery' for 12:00–05:55 PM respectively; Wednesday: 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Siam Top 20 (VJ Bas)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery'; Thursday: 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'The Ticket (VJ Loukade)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery'; Friday: 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', '[V] Countdown (VJ Pitta)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery'; Saturday: 'Asian Hero (VJ Mike)', '[V] Tunes', 'Siam Top 20 (VJ Bas)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery'; and also compute the counts: 'Asian Hero (VJ Mike) Count', 'Melosamosorn (VJ Woonsen) Count', '[V] Tunes Count', 'Zog Zag (VJ Loukade, Ake, Bank) Count', 'Khon Du Pen Yai (Live) Count', '[V] Covery Count', and 'Siam Top 20 (VJ Bas) Count' by summing their individual occurrences as in the query?","
SELECT 
'Time' `Time`,
'12:00 PM' `12:00 PM`,
'01:00 PM' `01:00 PM`,
'02:00 PM' `02:00 PM`,
'03:00 PM' `03:00 PM`,
'04:00 PM' `04:00 PM`,
'05:00 PM' `05:00 PM`,
'05:55 PM' `05:55 PM`,
'Asian Hero (VJ Mike)' `Monday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Monday 01:00 PM`,
'Asian Chart (VJ Mike)' `Monday 02:00 PM`,
'[V] Tunes' `Monday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Monday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Monday 05:00 PM`,
'[V] Covery' `Monday 05:55 PM`,
'Asian Hero (VJ Mike)' `Tuesday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Tuesday 01:00 PM`,
'Mainstage' `Tuesday 02:00 PM`,
'[V] Tunes' `Tuesday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Tuesday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Tuesday 05:00 PM`,
'[V] Covery' `Tuesday 05:55 PM`,
'Asian Hero (VJ Mike)' `Wednesday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Wednesday 01:00 PM`,
'Siam Top 20 (VJ Bas)' `Wednesday 02:00 PM`,
'[V] Tunes' `Wednesday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Wednesday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Wednesday 05:00 PM`,
'[V] Covery' `Wednesday 05:55 PM`,
'Asian Hero (VJ Mike)' `Thursday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Thursday 01:00 PM`,
'The Ticket (VJ Loukade)' `Thursday 02:00 PM`,
'[V] Tunes' `Thursday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Thursday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Thursday 05:00 PM`,
'[V] Covery' `Thursday 05:55 PM`,
'Asian Hero (VJ Mike)' `Friday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Friday 01:00 PM`,
'[V] Countdown (VJ Pitta)' `Friday 02:00 PM`,
'[V] Tunes' `Friday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Friday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Friday 05:00 PM`,
'[V] Covery' `Friday 05:55 PM`,
'Asian Hero (VJ Mike)' `Saturday 12:00 PM`,
'[V] Tunes' `Saturday 01:00 PM`,
'Siam Top 20 (VJ Bas)' `Saturday 02:00 PM`,
'[V] Tunes' `Saturday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Saturday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Saturday 05:00 PM`,
'[V] Covery' `Saturday 05:55 PM`,
(
('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')
) `Asian Hero (VJ Mike) Count`,
(
('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')
) `Melosamosorn (VJ Woonsen) Count`,
(
('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')
) `[V] Tunes Count`,
(
('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')
) `Zog Zag (VJ Loukade, Ake, Bank) Count`,
(
('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')
) `Khon Du Pen Yai (Live) Count`,
(
('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')
) `[V] Covery Count`,
(
('Siam Top 20 (VJ Bas)'='Siam Top 20 (VJ Bas)')+('Siam Top 20 (VJ Bas)'='Siam Top 20 (VJ Bas)')
) `Siam Top 20 (VJ Bas) Count`
WHERE 1 LIMIT 1;
","
SELECT 
'Time' col0,
'12:00 PM' col1,
'01:00 PM' col2,
'02:00 PM' col3,
'03:00 PM' col4,
'04:00 PM' col5,
'05:00 PM' col6,
'05:55 PM' col7,
'Asian Hero (VJ Mike)' `Monday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Monday 01:00 PM`,
'Asian Chart (VJ Mike)' `Monday 02:00 PM`,
'[V] Tunes' `Monday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Monday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Monday 05:00 PM`,
'[V] Covery' `Monday 05:55 PM`,
'Asian Hero (VJ Mike)' `Tuesday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Tuesday 01:00 PM`,
'Mainstage' `Tuesday 02:00 PM`,
'[V] Tunes' `Tuesday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Tuesday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Tuesday 05:00 PM`,
'[V] Covery' `Tuesday 05:55 PM`,
'Asian Hero (VJ Mike)' `Wednesday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Wednesday 01:00 PM`,
'Siam Top 20 (VJ Bas)' `Wednesday 02:00 PM`,
'[V] Tunes' `Wednesday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Wednesday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Wednesday 05:00 PM`,
'[V] Covery' `Wednesday 05:55 PM`,
'Asian Hero (VJ Mike)' `Thursday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Thursday 01:00 PM`,
'The Ticket (VJ Loukade)' `Thursday 02:00 PM`,
'[V] Tunes' `Thursday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Thursday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Thursday 05:00 PM`,
'[V] Covery' `Thursday 05:55 PM`,
'Asian Hero (VJ Mike)' `Friday 12:00 PM`,
'Melosamosorn (VJ Woonsen)' `Friday 01:00 PM`,
'[V] Countdown (VJ Pitta)' `Friday 02:00 PM`,
'[V] Tunes' `Friday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Friday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Friday 05:00 PM`,
'[V] Covery' `Friday 05:55 PM`,
'Asian Hero (VJ Mike)' `Saturday 12:00 PM`,
'[V] Tunes' `Saturday 01:00 PM`,
'Siam Top 20 (VJ Bas)' `Saturday 02:00 PM`,
'[V] Tunes' `Saturday 03:00 PM`,
'Zog Zag (VJ Loukade, Ake, Bank)' `Saturday 04:00 PM`,
'Khon Du Pen Yai (Live)' `Saturday 05:00 PM`,
'[V] Covery' `Saturday 05:55 PM`,
(
('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')+('Asian Hero (VJ Mike)'='Asian Hero (VJ Mike)')
) `Asian Hero (VJ Mike) Count`,
(
('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')+('Melosamosorn (VJ Woonsen)'='Melosamosorn (VJ Woonsen)')
) `Melosamosorn (VJ Woonsen) Count`,
(
('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')+('[V] Tunes'='[V] Tunes')
) `[V] Tunes Count`,
(
('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')+('Zog Zag (VJ Loukade, Ake, Bank)'='Zog Zag (VJ Loukade, Ake, Bank)')
) `Zog Zag (VJ Loukade, Ake, Bank) Count`,
(
('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')+('Khon Du Pen Yai (Live)'='Khon Du Pen Yai (Live)')
) `Khon Du Pen Yai (Live) Count`,
(
('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')+('[V] Covery'='[V] Covery')
) `[V] Covery Count`,
(
('Siam Top 20 (VJ Bas)'='Siam Top 20 (VJ Bas)')+('Siam Top 20 (VJ Bas)'='Siam Top 20 (VJ Bas)')
) `Siam Top 20 (VJ Bas) Count`
WHERE 1 LIMIT 1;
","[('Time', '12:00 PM', '01:00 PM', '02:00 PM', '03:00 PM', '04:00 PM', '05:00 PM', '05:55 PM', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Asian Chart (VJ Mike)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Mainstage', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'Siam Top 20 (VJ Bas)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', 'The Ticket (VJ Loukade)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', 'Melosamosorn (VJ Woonsen)', '[V] Countdown (VJ Pitta)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 'Asian Hero (VJ Mike)', '[V] Tunes', 'Siam Top 20 (VJ Bas)', '[V] Tunes', 'Zog Zag (VJ Loukade, Ake, Bank)', 'Khon Du Pen Yai (Live)', '[V] Covery', 6, 5, 7, 6, 6, 6, 2)]",m_1764882982973_9120e307_15535243-3,"1) The SQL constructs a flat single-row output containing the time headers, each cell value for Monday–Saturday, and explicit counts created by adding equality checks for specific show names. 2) Interpret the table rows as weekday schedules mapped to time columns and the counts as tallies of occurrences. 3) Create a question asking for the headers, each weekday/time program string exactly as in the query, and the show occurrence counts. 4) Confirm the question mentions every time column, every weekday/value pair, and every Count column.",reserved,3,N/A,add_column,
"List every ecozone with its area, percent protected, protected km² and unprotected km², protected km² per 1,000 km², rank by percent protected, whether it’s a 'pristine' candidate (≥15%) or a 'human-influence' candidate (>500,000 km² and <10% protected), and each ecozone's share of the total protected area, ordered by protected km² per 1,000 km² descending.","
SELECT
  `Ecozone`,
  `Area (km²)`,
  `Percentage protected`,
  (CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)` AS `protected_km2`,
  `Area (km²)` - ((CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)`) AS `unprotected_km2`,
  (((CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)`) / (`Area (km²)` / 1000.0)) AS `protected_km2_per_1000km2`,
  RANK() OVER (ORDER BY CAST(`Percentage protected` AS REAL) DESC) AS `rank_by_percentage_protected`,
  CASE WHEN CAST(`Percentage protected` AS REAL) >= 15 THEN 'Yes' ELSE 'No' END AS `pristine_candidate`,
  CASE WHEN `Area (km²)` > 500000 AND CAST(`Percentage protected` AS REAL) < 10 THEN 'Yes' ELSE 'No' END AS `human_influence_candidate`,
  ((CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)`) / (
    SELECT SUM((CAST(`Percentage protected` AS REAL) / 100.0) * `Area (km²)`) FROM `table_m_1764882990164_cb37467d_15555661_2`
  ) * 100.0 AS `share_of_total_protected_percent`
FROM `table_m_1764882990164_cb37467d_15555661_2`
ORDER BY `protected_km2_per_1000km2` DESC;
","
SELECT
  col0,
  col1,
  col4,
  (CAST(col4 AS REAL) / 100.0) * col1 AS `protected_km2`,
  col1 - ((CAST(col4 AS REAL) / 100.0) * col1) AS `unprotected_km2`,
  (((CAST(col4 AS REAL) / 100.0) * col1) / (col1 / 1000.0)) AS `protected_km2_per_1000km2`,
  RANK() OVER (ORDER BY CAST(col4 AS REAL) DESC) AS `rank_by_percentage_protected`,
  CASE WHEN CAST(col4 AS REAL) >= 15 THEN 'Yes' ELSE 'No' END AS `pristine_candidate`,
  CASE WHEN col1 > 500000 AND CAST(col4 AS REAL) < 10 THEN 'Yes' ELSE 'No' END AS `human_influence_candidate`,
  ((CAST(col4 AS REAL) / 100.0) * col1) / (
    SELECT SUM((CAST(col4 AS REAL) / 100.0) * col1) FROM `table_m_1764882990164_cb37467d_15555661_2`
  ) * 100.0 AS `share_of_total_protected_percent`
FROM `table_m_1764882990164_cb37467d_15555661_2`
ORDER BY `protected_km2_per_1000km2` DESC;
","[('Arctic Cordillera', 230873.0, '24.25', 55986.7025, 174886.2975, 242.5, 1, 'Yes', 'No', 6.3134353233094105), ('Pacific Maritime', 205175.0, '18.87', 38716.5225, 166458.4775, 188.7, 2, 'Yes', 'No', 4.365934227814248), ('Montane Cordillera', 459680.0, '18.33', 84259.344, 375420.656, 183.29999999999998, 3, 'Yes', 'No', 9.501647622995456), ('Southern Arctic', 773010.0, '15.89', 122831.289, 650178.711, 158.9, 4, 'Yes', 'No', 13.851278324173968), ('Boreal Cordillera', 459680.0, '15.28', 70239.10399999999, 389440.896, 152.79999999999998, 5, 'Yes', 'No', 7.920631515513941), ('Hudson Plains', 353364.0, '11.65', 41166.906, 312197.094, 116.50000000000001, 6, 'No', 'No', 4.642255873021957), ('Taiga Cordillera', 264480.0, '9.28', 24543.744, 239936.256, 92.79999999999998, 7, 'No', 'No', 2.7677168580497016), ('Boreal Shield', 1782252.0, '8.06', 143649.5112, 1638602.4888, 80.60000000000001, 8, 'No', 'Yes', 16.19888040711472), ('Boreal Plains', 679969.0, '7.96', 54125.532400000004, 625843.4676, 79.6, 9, 'No', 'Yes', 6.103557325011024), ('Taiga Shield', 1253887.0, '6.97', 87395.9239, 1166491.0761, 69.7, 10, 'No', 'Yes', 9.855349367352382), ('Taiga Plains', 580139.0, '6.92', 40145.6188, 539993.3812, 69.19999999999999, 11, 'No', 'Yes', 4.5270886923200075), ('Northern Arctic', 1361433.0, '6.69', 91079.8677, 1270353.1323, 66.9, 12, 'No', 'Yes', 10.270775528877198), ('Atlantic Maritime', 183978.0, '5.33', 9806.0274, 174171.9726, 53.300000000000004, 13, 'No', 'No', 1.105793286691602), ('Prairies', 459681.0, '4.49', 20639.676900000002, 439041.3231, 44.900000000000006, 14, 'No', 'No', 2.32746811981208), ('Mixedwood Plains', 138421.0, '1.59', 2200.8939, 136220.1061, 15.9, 15, 'No', 'No', 0.24818752794230395)]",m_1764882990164_cb37467d_15555661-2,"I'm an acoustic ecologist-turned touring composer who thinks in protected percentages and square kilometres when plotting pristine stops, so I'll ask in metric terms without SQL jargon. I know enough about the data to ask for area, percent protected, and derived km² values but I won't toss in column names. The SQL computes protected km², unprotected km², protected km² per 1,000 km², ranks ecozones by percentage protected, flags pristine and human-influence candidates, and computes each ecozone's share of total protected area. I need a single-line request that asks for those per-ecozone metrics and an ordering by protected-area density. List every ecozone with area, percent protected, protected and unprotected km², protected km² per 1,000 km², rank by percentage protected, pristine and human-influence flags, and share of total protected area, ordered highest to lowest by protected km² per 1,000 km².",persona,"An acoustic ecologist-turned touring composer building a pan-Canadian 'sound map' who plans mobile recording stops by choosing ecozones along a gradient from pristine (highly protected) to human-influenced (large, low protection) soundscapes. Goals: Identify ecozones with the highest percentage protected to prioritize 'pristine' soundscape recording sites (likely quieter, less anthropogenic noise). Find large ecozones with low protection percentage to target for recordings that capture human influence, resource-use soundscapes, and edge habitats. Estimate actual protected and unprotected area (km²) per ecozone and overall to plan sampling effort, logistics, and permitted recording locations. Rank candidate ecozones by protected-area density (protected km² per 1,000 km²) to balance route diversity within a limited tour timeframe. Example Queries: -- 1) Top 5 ecozones by percentage protected, with computed protected area (km²)
SELECT ""Ecozone"",
       ""Area (km²)"",
       ""Percentage protected"",
       (CAST(""Percentage protected"" AS REAL) / 100.0) * ""Area (km²)"" AS protected_km2
FROM table_1_15555661_2
ORDER BY CAST(""Percentage protected"" AS REAL) DESC
LIMIT 5; -- 2) Large ecozones (>500,000 km²) with low protection (<10%) to find human-influenced recording targets
SELECT ""Ecozone"",
       ""Area (km²)"",
       ""Percentage protected"",
       (1.0 - CAST(""Percentage protected"" AS REAL) / 100.0) * ""Area (km²)"" AS unprotected_km2
FROM table_1_15555661_2
WHERE CAST(""Percentage protected"" AS REAL) < 10
  AND ""Area (km²)"" > 500000
ORDER BY unprotected_km2 DESC; -- 3) Aggregate totals: overall area, total protected area, and overall percent protected (useful for sampling quotas)
SELECT SUM(""Area (km²)"") AS total_area_km2,
       SUM((CAST(""Percentage protected"" AS REAL) / 100.0) * ""Area (km²)"") AS total_protected_km2,
       (SUM((CAST(""Percentage protected"" AS REAL) / 100.0) * ""Area (km²)"") / SUM(""Area (km²)"")) * 100 AS overall_percentage_protected
FROM table_1_15555661_2;",N/A,add_column,
"Which distinct Positions have more than one player, and for each such Position show Position, the number of players (COUNT(*) labeled Players), the average Weight rounded to one decimal (ROUND(AVG(Weight),1) labeled Avg Weight), and a comma-and-space joined Players list of Player name values (GROUP_CONCAT(Player name, ', ')), restricting rows to those with Round equal to 1, 4, or 5 and either Choice > 100 or Weight between 195 and 260, ordering the results by average weight descending and returning up to 10 entries?","
SELECT DISTINCT `Position` AS `Position`, COUNT(*) `Players`, ROUND(AVG(`Weight`),1) `Avg Weight`, GROUP_CONCAT(`Player name`, ', ') `Players list`
FROM `table_m_1764883030207_d9392a21_15582870_1`
WHERE `Round` IN (1,4,5) AND (`Choice` > 100 OR `Weight` BETWEEN 195 AND 260)
GROUP BY `Position`
HAVING COUNT(*) > 1
ORDER BY AVG(`Weight`) DESC
LIMIT 10;
","
SELECT DISTINCT col3 AS col3, COUNT(*) `Players`, ROUND(AVG(col5),1) `Avg Weight`, GROUP_CONCAT(col2, ', ') `Players list`
FROM `table_m_1764883030207_d9392a21_15582870_1`
WHERE col0 IN (1,4,5) AND (col1 > 100 OR col5 BETWEEN 195 AND 260)
GROUP BY col3
HAVING COUNT(*) > 1
ORDER BY AVG(col5) DESC
LIMIT 10;
","[('Running back', 2, 206.0, 'Felix Jones, Tashard Choice'), ('Cornerback', 2, 197.5, 'Mike Jenkins, Orlando Scandrick')]",m_1764883030207_d9392a21_15582870-1,"1) The intent is to aggregate players by Position and report count, rounded average weight, and concatenated names for a filtered subset of rows. 2) Map schema: use Round, Choice, Weight, Player name, Position to apply filters and produce aggregates. 3) Draft a question that requests Position, COUNT(*) as Players, ROUND(AVG(Weight),1) as Avg Weight, GROUP_CONCAT(Player name, ', ') as Players list with Round IN (1,4,5) and (Choice>100 OR Weight BETWEEN 195 AND 260), HAVING COUNT(*)>1, ordered by AVG(Weight) DESC, limited to 10. 4) Confirm all SQL elements are included in the phrasing.",reserved,15,N/A,add_column,
"List each director (Directed by) with their Episode Count (number of Title entries), Avg Viewers (AVG of U.S. viewers (million)), Max Viewers (MAX of U.S. viewers (million)), and Min Viewers (MIN of U.S. viewers (million)), sorted by Avg Viewers from highest to lowest.","
SELECT t1.`Directed by`, COUNT(t1.`Title`) `Episode Count`, AVG(t1.`U.S. viewers (million)`) `Avg Viewers`, MAX(t1.`U.S. viewers (million)`) `Max Viewers`, MIN(t1.`U.S. viewers (million)`) `Min Viewers`
FROM `table_m_1764883048079_5a9b7b16_15584067_7` t1 JOIN `table_m_1764883048079_5a9b7b16_15584067_7` t2 ON t2.`Directed by` = t1.`Directed by`
WHERE t1.`U.S. viewers (million)` >= t2.`U.S. viewers (million)`
GROUP BY t1.`Directed by`
ORDER BY AVG(t1.`U.S. viewers (million)`) DESC;
","
SELECT t1.col3, COUNT(t1.col2) `Episode Count`, AVG(t1.col5) `Avg Viewers`, MAX(t1.col5) `Max Viewers`, MIN(t1.col5) `Min Viewers`
FROM `table_m_1764883048079_5a9b7b16_15584067_7` t1 JOIN `table_m_1764883048079_5a9b7b16_15584067_7` t2 ON t2.col3 = t1.col3
WHERE t1.col5 >= t2.col5
GROUP BY t1.col3
ORDER BY AVG(t1.col5) DESC;
","[('Bille Woodruff', 3, 3.026666666666667, '3.58', '1.92'), ('Nzingha Stewart', 1, 2.59, '2.59', '2.59'), ('Kenny Smith', 3, 2.5100000000000002, '2.66', '2.21'), ('Billie Woodruff', 1, 2.41, '2.41', '2.41'), ('Eric Laneuville', 1, 2.4, '2.40', '2.40'), ('Mary Lou Belli', 15, 2.2906666666666666, '2.50', '1.60'), ('Salim Akil', 15, 2.1453333333333333, '2.54', '1.74')]",m_1764883048079_5a9b7b16_15584067-7,"1) Parse intent: group rows by director and compute aggregate viewer statistics and episode count, then sort by average viewers high-to-low. 2) Map schema: use 'Directed by' as group key, count 'Title' for episodes, and use 'U.S. viewers (million)' for AVG/MAX/MIN. 3) Draft: request these aggregates per director and specify descending order by average. 4) Validate: question mirrors the SQL aggregates and ordering.",reserved,9,N/A,split_column,
"List the five clubs (limit 5) with First season > 0, returning for each Club its Number of seasons in Superettan (Superettan), its Number of seasons in second tier (SecondTier), an Is_Husqvarna field equal to true when the Club = 'Husqvarna FF', NearestGap equal to the absolute difference between that club's First season and any other club's First season, and Penetration which should be 'High penetration' when (Number of seasons in Superettan * 1.0 / (Number of seasons in second tier + 0)) > 0.5 otherwise 'Low penetration', ordered by Penetration descending then by NearestGap?","
SELECT
  m.`club_name` `club_name`,
  m.`Number of seasons in Superettan` `Superettan`,
  m.`number_of_seasons_in_second_tier` `SecondTier`,
  (m.`club_name` = '`Husqvarna FF`') `Is_Husqvarna`,
  ABS(m.`First season` - j.`First season`) `NearestGap`,
  CASE WHEN (m.`Number of seasons in Superettan` * 1.0 / (m.`number_of_seasons_in_second_tier` + 0)) > 0.5 THEN '`High penetration`' ELSE '`Low penetration`' END AS `Penetration`
FROM `table_m_1764883063578_34e2ffa5_1560673_1` m
JOIN `table_m_1764883063578_34e2ffa5_1560673_1` j ON j.`club_name` != m.`club_name`
WHERE m.`First season` > 0
GROUP BY m.`club_name`
ORDER BY `Penetration` DESC, `NearestGap`
LIMIT 5;
","
SELECT
  m.col0 col0,
  m.col4 `Superettan`,
  m.col5 `SecondTier`,
  (m.col0 = '`Husqvarna FF`') `Is_Husqvarna`,
  ABS(m.col2 - j.col2) `NearestGap`,
  CASE WHEN (m.col4 * 1.0 / (m.col5 + 0)) > 0.5 THEN '`High penetration`' ELSE '`Low penetration`' END AS `Penetration`
FROM `table_m_1764883063578_34e2ffa5_1560673_1` m
JOIN `table_m_1764883063578_34e2ffa5_1560673_1` j ON j.col0 != m.col0
WHERE m.col2 > 0
GROUP BY m.col0
ORDER BY `Penetration` DESC, `NearestGap`
LIMIT 5;
","[('Landskrona BoIS', 10.0, '51', 0, 0.0, '`Low penetration`'), ('Östers IF', 9.0, '19', 0, 0.0, '`Low penetration`'), ('GAIS', 4.0, '29', 0, 1.0, '`Low penetration`'), ('Degerfors IF', 8.0, '35', 0, 5.0, '`Low penetration`'), ('Jönköpings Södra', 8.0, '35', 0, 6.0, '`Low penetration`')]",m_1764883063578_34e2ffa5_1560673-1,"1) The SQL selects distinct clubs with numerical and derived columns, flags Husqvarna, computes an absolute First season gap to other clubs, classifies penetration by a ratio > 0.5, filters First season > 0, sorts by penetration then gap, and returns five rows. 2) Map fields and calculations to natural language: include Club, Superettan seasons, second-tier seasons, Is_Husqvarna boolean, NearestGap as absolute difference to another club's First season, and the Penetration CASE expression. 3) Produce a concise question that asks for these five output columns for the top five clubs given the ordering and filter. 4) Confirm the question mentions all computations, ordering, grouping by club (distinct clubs), and the 5-row limit without introducing extra details.",reserved,16,N/A,rename_column,
Which wheel arrangements were mostly at March?,"SELECT DISTINCT printf('`%s`', `Wheel Arrangement`) `Wheel Arrangement`, printf('`%s`', `Class`) `Example_Class`, SUM(`Number at Pyewipe`) `Pyewipe_Total`, SUM(`Number at March`) `March_Total`, (SUM(`Number at Pyewipe`) + SUM(`Number at March`)) AS `Total` FROM `table_m_1764883081746_ffa1c128_15608800_2` WHERE (`Number at Pyewipe` + `Number at March`) > 0 GROUP BY `Wheel Arrangement` HAVING (SUM(`Number at March`)*1.0)/(SUM(`Number at Pyewipe`) + SUM(`Number at March`)) > 0.5 LIMIT 5;","SELECT DISTINCT printf('`%s`', col1) col1, printf('`%s`', col0) `Example_Class`, SUM(col3) `Pyewipe_Total`, SUM(col4) `March_Total`, (SUM(col3) + SUM(col4)) AS `Total` FROM `table_m_1764883081746_ffa1c128_15608800_2` WHERE (col3 + col4) > 0 GROUP BY col1 HAVING (SUM(col4)*1.0)/(SUM(col3) + SUM(col4)) > 0.5 LIMIT 5;","[('`0-6-0`', '`J14`', 6.0, 69.0, 75.0), ('`0-6-0T`', '`J66`', 3.0, 12.0, 15.0), ('`2-4-0`', '`E4`', 0.0, 4.0, 4.0), ('`4-4-0`', '`D13`', 3.0, 11.0, 14.0)]",m_1764883081746_ffa1c128_15608800-2,"STEP 1: Parse the SQL intent — Group rows by Wheel Arrangement, sum Number at Doncaster, Number at Pyewipe and Number at March per wheel arrangement, require that the group has a positive total and that more than 50% of that group's total is at March; return Wheel Arrangement, an example Class, the sums and limit to 5. STEP 2: Determine ambiguity type — Scope ambiguity fits: phrasing like ""mostly at March"" can mean a per-arrangement majority (>50%, which the SQL uses) or a comparative/top measure across arrangements (the single arrangement with the largest March count or share). STEP 3: Draft the question — ""Which wheel arrangements were mostly at March?"" STEP 4: Explain the ambiguity — In the original query ""mostly at March"" is implemented as a per-wheel-arrangement proportion check (Number at March > 50% of that arrangement's total). Alternatively it could be read as asking for the arrangement(s) with the highest absolute number at March, or the arrangement(s) contributing the majority of all March locomotives (a different global comparison).",reserved,9,N/A,remove_column,"type: Scope ambiguity | explanation: The SQL treats ""mostly at March"" as a per-wheel-arrangement majority (>50% of that arrangement's locomotives are at March). A different interpretation could ask instead for the arrangement with the largest number at March overall, or which arrangements make up the majority of all March locomotives (a global comparison)."
"Which Player and the corresponding COUNT(*) as Stints are returned when selecting rows where Player is in (Player), grouping results by Player, keeping only groups with COUNT(*) > 1, and ordering the output by Stints descending?","
SELECT `Player` AS `Player`, COUNT(*) AS `Stints`
FROM `table_m_1764883091037_373b0b35_15621965_14`
WHERE `Player` IN (`Player`)
GROUP BY `Player`
HAVING COUNT(*) > 1
ORDER BY `Stints` DESC;
","
SELECT col0 AS col0, COUNT(*) AS `Stints`
FROM `table_m_1764883091037_373b0b35_15621965_14`
WHERE col0 IN (col0)
GROUP BY col0
HAVING COUNT(*) > 1
ORDER BY `Stints` DESC;
","[('Bo Outlaw', 2)]",m_1764883091037_373b0b35_15621965-14,"1) Parse intent: produce a count of rows per Player and return only those players with more than one row, sorted highest count first. 2) Map schema: Player column and COUNT(*) aggregated as Stints. 3) Draft: ask for Player and Stints with the WHERE Player IN (Player) constraint, GROUP BY Player, HAVING COUNT(*) > 1, ORDER BY Stints DESC. 4) Validate: ensures all SQL components—selected columns, aggregation, where-in, grouping, having, and ordering—are represented.",reserved,11,N/A,add_column,
"Which five distinct Cover model values have the highest Appearances (COUNT(*)), and for each what are the Appearances, the SameAsCenterfold count (SUM(Cover model = Centerfold model)), and the Chyna count (SUM(Cover model = 'Chyna')) when the table is self-joined on Date, excluding empty Date rows, grouped by Cover model with COUNT(*) >= 1 and ordered by Appearances descending?","
SELECT DISTINCT t1.`cover_model` AS `cover_model`, COUNT(*) `Appearances`, SUM(t1.`cover_model` = t1.`centerfold_model`) `SameAsCenterfold`, SUM(t1.`cover_model` = 'Chyna') `Chyna`
FROM `table_m_1764883106412_8e8d7b9f_1566852_3` t1
JOIN `table_m_1764883106412_8e8d7b9f_1566852_3` t2 ON t1.`issue_date` = t2.`issue_date`
WHERE t1.`issue_date` <> ''
GROUP BY t1.`cover_model`
HAVING COUNT(*) >= 1
ORDER BY `Appearances` DESC
LIMIT 5;
","
SELECT DISTINCT t1.col1 AS col1, COUNT(*) `Appearances`, SUM(t1.col1 = t1.col2) `SameAsCenterfold`, SUM(t1.col1 = 'Chyna') `Chyna`
FROM `table_m_1764883106412_8e8d7b9f_1566852_3` t1
JOIN `table_m_1764883106412_8e8d7b9f_1566852_3` t2 ON t1.col0 = t2.col0
WHERE t1.col0 <> ''
GROUP BY t1.col1
HAVING COUNT(*) >= 1
ORDER BY `Appearances` DESC
LIMIT 5;
","[('Teri Marie Harrison', 1, 1, 0), ('Kristy Swanson', 1, 0, 0), ('Kira Kener , Dasha , Tera Patrick', 1, 0, 0), ('Kiana Tom', 1, 0, 0), ('Jordan', 1, 0, 0)]",m_1764883106412_8e8d7b9f_1566852-3,"1) Parse intent: aggregate rows per Cover model to compute total appearances and two conditional sums, applying a non-empty Date constraint and limiting to five results. 2) Map schema: use Cover model and Centerfold model columns; the query self-joins on Date but groups by Cover model and filters out empty Date. 3) Draft: ask explicitly for Cover model, Appearances (COUNT(*)), SameAsCenterfold (SUM(Cover model = Centerfold model)), and Chyna (SUM(Cover model = 'Chyna')) with the join, filter, group, having, order, and limit. 4) Validate: ensure all calculations and clauses (JOIN ON Date, Date <> '', HAVING COUNT(*) >= 1, ORDER BY Appearances DESC, LIMIT 5) are represented.",reserved,13,N/A,rename_column,
"List the top 5 Cover model values by COUNT(*) (returned as 'Jaime Pressly'), and for each include SUM(Cover model = Centerfold model) labeled 'Pamela Anderson, Helmut Newton tribute', GROUP_CONCAT(Date, ', ') labeled 'All Dates', and GROUP_CONCAT(Pictorials, ' | ') labeled 'All Pictorials', considering only rows where Pictorials is not '' and not ' ', grouping by Cover model and ordering by 'Jaime Pressly' descending?",unanswerable,unanswerable,,m_1764883140255_dc1803b7_1566852-5,"1) Parse SQL intent: aggregate rows by Cover model with a total count (aliased 'Jaime Pressly'), count of matches between Cover model and Centerfold model (aliased 'Pamela Anderson, Helmut Newton tribute'), and concatenated Date and Pictorials fields; exclude empty/blanks in Pictorials, order by count desc and limit to 5. 2) Map schema semantics: Cover model, Centerfold model, Date, Pictorials. 3) Draft the question: request top 5 Cover models with those aggregated fields and specified aliases and separators. 4) Validate: confirm inclusion of filter Pictorials != '' and Pictorials != ' ', GROUP BY, ORDER BY 'Jaime Pressly' DESC, and LIMIT 5.",reserved,8,N/A,merge_column,
Which of the most recent issues feature the cover model?,"
SELECT `Date`, `Cover model`, `Centerfold model`, `Pictorials` AS `Pictorials`
FROM `table_m_1764883148613_921b49d6_1566852_7`
WHERE CASE WHEN `Cover model` = `Centerfold model` OR instr(`Pictorials`,`Cover model`)>0 THEN 1 ELSE 0 END = 1
ORDER BY `Date` DESC
LIMIT 10;
","
SELECT col0, col1, col2, col5 AS col5
FROM `table_m_1764883148613_921b49d6_1566852_7`
WHERE CASE WHEN col1 = col2 OR instr(col5,col1)>0 THEN 1 ELSE 0 END = 1
ORDER BY col0 DESC
LIMIT 10;
","[('7-06', 'Vida Guerra', 'Sara Jean Underwood', 'Vida Guerra'), ('6-06', 'Kara Monaco', 'Stephanie Larimore', 'PMOY - Kara Monaco, Girls of MySpace'), ('5-06', 'Alison Waite', 'Alison Waite', 'Girls of the top 10 party schools, Rachel Sterling'), ('4-06', 'Candice Michelle', 'Holley Ann Dorrough', 'Candice Michelle, Cyber Girls in print'), ('2-06', 'Adrianne Curry', 'Cassandra Lynn', 'Adrianne Curry, Girls of Tuscany'), ('11-06', 'Mercedes McNab', 'Sarah Elizabeth', 'Mercedes McNab, Girls of Hawaiian Tropic'), ('1-06', 'Lisa Guerrero', 'Athena Lundberg', 'Lisa Guerrero')]",m_1764883148613_921b49d6_1566852-7,"STEP 1: Parse the SQL intent: the query selects Date, Cover model, Centerfold model and Pictorials for the most recent 10 rows where the Cover model is either the Centerfold OR the Cover model's name appears inside the Pictorials field (instr(Pictorials, Cover model)>0). STEP 2: Determine ambiguity type: Attachment ambiguity — the natural predicate that would describe this filter (e.g., ""feature"" or ""include"") can attach to different parts of an issue (being the centerfold vs. appearing in the pictorials), which fits this query because it accepts either condition. STEP 3: Draft the question: ""Which of the most recent issues feature the cover model?"" STEP 4: Explain the ambiguity: in the SQL the condition treats being centerfold and appearing in pictorials as equivalent matches; the NL question is ambiguous because ""feature"" could mean only the cover model was the centerfold, only that they appear in a pictorial, either one of those, or even both — each interpretation would change the WHERE clause (Cover model = Centerfold, instr(Pictorials, Cover model)>0, OR both/AND).",reserved,14,N/A,add_column,"type: Attachment ambiguity | explanation: The phrase ""feature the cover model"" can attach to different parts of an issue: it could mean the cover model is the centerfold, or that they appear in the pictorials, or either; the SQL treats either condition as a match, but a different interpretation would restrict the query to only centerfolds, only pictorial appearances, or require both."
"Give me a list of underdog seasons (4th, 7th, or 8th regular-season finishes that reached semifinals, final, or champions) showing year, league, division, regular finish, playoff result, Open Cup progress, and how many such deep runs each league/division has, ordered first by how common those deep runs are in the league/division and then by year?",unanswerable,unanswerable,,m_1764883167778_0ed2f605_1570003-2,"I like a tidy, chronological inventory that still highlights which settings are richest in drama. The query orders the underdog seasons by how many deep runs that League+Division produced (descending) and then by year ascending. It returns year, league, division, regular-season placing, playoffs, Open Cup and the per-league/division count. Draft question: Give me a list of underdog seasons (4th, 7th, or 8th regular-season finishes that reached semifinals, final, or champions) showing year, league, division, regular finish, playoff result, Open Cup progress, and how many such deep runs each league/division has, ordered first by how common those deep runs are in the league/division and then by year. Validation: This asks for the exact columns and ordering produced by the query.",persona,"An audio-fiction writer who crafts short, lyric 'sports fables' based on real soccer seasons where a team’s ordinary league finish belies a surprising playoff or cup run. Goals: Identify seasons where the Charlotte Eagles finished poorly in the regular season but made unexpectedly deep playoff runs (underdog arcs to inspire episodes). Catalog which leagues/divisions produced the most dramatic postseason outcomes to vary the historical settings of stories. Find seasons with noteworthy Open Cup progress to weave cross-competition stakes into single-episode narratives. Example Queries: SELECT Year, League, `Regular Season`, Playoffs FROM table_1_1570003_2 WHERE (`Regular Season` LIKE '%4th%' OR `Regular Season` LIKE '%7th%' OR `Regular Season` LIKE '%8th%') AND (Playoffs IN ('Semifinals','Final','Champions') OR Playoffs LIKE '%Final%'); SELECT League, `Division`, COUNT(*) AS deep_runs FROM table_1_1570003_2 WHERE (Playoffs LIKE '%Final%' OR Playoffs = 'Champions' OR Playoffs = 'Semifinals') GROUP BY League, `Division` ORDER BY deep_runs DESC; SELECT Year, `Open Cup`, Playoffs, `Regular Season` FROM table_1_1570003_2 WHERE `Open Cup` NOT IN ('Did not enter','Did not qualify') ORDER BY Year;",N/A,remove_column,
"For each Written By (reporting as Writer), what are Episodes (COUNT(*)), MIN(No. in season), and Last (MAX(No. in season)) when restricting to rows where TV Broadcast LIKE 'S02E%' OR Title = '`""Turtles in Space, Part 1: The Fugitoid`', grouping by Written By, ordering by Episodes descending and returning at most 10 results?","
SELECT `Written By` AS `Writer`, COUNT(*) AS `Episodes`, MIN(`No. in season`), MAX(`No. in season`) AS `Last`
FROM `table_m_1764883181754_c8100e8a_15777546_1`
WHERE `TV Broadcast` LIKE 'S02E%' OR `Title` = '`""Turtles in Space, Part 1: The Fugitoid`'
GROUP BY `Written By`
ORDER BY `Episodes` DESC
LIMIT 10;
","
SELECT col4 AS `Writer`, COUNT(*) AS `Episodes`, MIN(col1), MAX(col1) AS `Last`
FROM `table_m_1764883181754_c8100e8a_15777546_1`
WHERE col6 LIKE 'S02E%' OR col2 = '`""Turtles in Space, Part 1: The Fugitoid`'
GROUP BY col4
ORDER BY `Episodes` DESC
LIMIT 10;
","[('Marty Isenberg', 8, 3.0, 25.0), ('Michael Ryan', 6, 1.0, 23.0), ('Eric Luke', 5, 6.0, 19.0), ('Ben Townsend', 4, 12.0, 24.0), ('Roland Gonzalez', 1, 10.0, 10.0)]",m_1764883181754_c8100e8a_15777546-1,"1) Parse SQL intent: aggregate episodes per `Written By`, computing count, minimum and maximum season numbers, restricted to TV Broadcast codes starting with S02E or the exact Title string, then return the top 10 by episode count. 2) Map schema: `Written By` -> Writer, COUNT(*) -> Episodes, MIN(`No. in season`), MAX(`No. in season`) -> Last. 3) Draft: formulate a question requesting those fields with the precise WHERE, GROUP BY, ORDER BY Episodes DESC, LIMIT 10. 4) Validate: ensures every selected column, alias, calculation, filter, group, order, and limit are mentioned.",reserved,12,N/A,add_column,
"Which performers recur in Season 1, how many episodes does each appear in, what distinct targets did they defend, which ‘Root of All Evil’(s) were they linked to, how often did the studio poll disagree with the show, and what is the episode-by-date timeline for each performer?","
WITH episodes AS (
  SELECT `#` AS `Episode`, `Original air date`, `Root of All Evil`, `Poll winner`, `Advocate # 1`, `Advocate # 2`
  FROM `table_m_1764883188401_0d3c66e9_15781170_2`
),
unpivot AS (
  SELECT `Episode`, `Original air date`, `Root of All Evil`, `Poll winner`,
    CASE WHEN instr(`Advocate # 1`, ' for ')>0 THEN substr(`Advocate # 1`, 1, instr(`Advocate # 1`, ' for ')-1) ELSE `Advocate # 1` END AS `Advocate`,
    CASE WHEN instr(`Advocate # 1`, ' for ')>0 THEN substr(`Advocate # 1`, instr(`Advocate # 1`, ' for ')+5) ELSE NULL END AS `Advocated for`
  FROM episodes
  UNION ALL
  SELECT `Episode`, `Original air date`, `Root of All Evil`, `Poll winner`,
    CASE WHEN instr(`Advocate # 2`, ' for ')>0 THEN substr(`Advocate # 2`, 1, instr(`Advocate # 2`, ' for ')-1) ELSE `Advocate # 2` END AS `Advocate`,
    CASE WHEN instr(`Advocate # 2`, ' for ')>0 THEN substr(`Advocate # 2`, instr(`Advocate # 2`, ' for ')+5) ELSE NULL END AS `Advocated for`
  FROM episodes
)
SELECT
  `Advocate`,
  COUNT(*) AS `Appearances`,
  GROUP_CONCAT(DISTINCT `Advocated for`) AS `Targets_defended (distinct)`,
  GROUP_CONCAT(DISTINCT `Root of All Evil`) AS `Associated_Roots (distinct)`,
  SUM(CASE WHEN `Root of All Evil` <> `Poll winner` THEN 1 ELSE 0 END) AS `Root_vs_Poll_mismatches`,
  GROUP_CONCAT(`Episode` || ' (' || `Original air date` || '): ' || `Root of All Evil` || ' -> ' || `Poll winner`, ' | ') AS `Episode_timeline`
FROM unpivot
GROUP BY `Advocate`
HAVING COUNT(*) > 1
ORDER BY `Appearances` DESC, `Advocate`;
","
WITH episodes AS (
  SELECT col0 AS `Episode`, col5, col3, col4, col1, col2
  FROM `table_m_1764883188401_0d3c66e9_15781170_2`
),
unpivot AS (
  SELECT `Episode`, col5, col3, col4,
    CASE WHEN instr(col1, ' for ')>0 THEN substr(col1, 1, instr(col1, ' for ')-1) ELSE col1 END AS `Advocate`,
    CASE WHEN instr(col1, ' for ')>0 THEN substr(col1, instr(col1, ' for ')+5) ELSE NULL END AS `Advocated for`
  FROM episodes
  UNION ALL
  SELECT `Episode`, col5, col3, col4,
    CASE WHEN instr(col2, ' for ')>0 THEN substr(col2, 1, instr(col2, ' for ')-1) ELSE col2 END AS `Advocate`,
    CASE WHEN instr(col2, ' for ')>0 THEN substr(col2, instr(col2, ' for ')+5) ELSE NULL END AS `Advocated for`
  FROM episodes
)
SELECT
  `Advocate`,
  COUNT(*) AS `Appearances`,
  GROUP_CONCAT(DISTINCT `Advocated for`) AS `Targets_defended (distinct)`,
  GROUP_CONCAT(DISTINCT col3) AS `Associated_Roots (distinct)`,
  SUM(CASE WHEN col3 <> col4 THEN 1 ELSE 0 END) AS `Root_vs_Poll_mismatches`,
  GROUP_CONCAT(`Episode` || ' (' || col5 || '): ' || col3 || ' -> ' || col4, ' | ') AS `Episode_timeline`
FROM unpivot
GROUP BY `Advocate`
HAVING COUNT(*) > 1
ORDER BY `Appearances` DESC, `Advocate`;
","[('Greg Giraldo', 5, 'Paris Hilton,Catholic Church,Viagra,Porn,Tila Tequila', 'Dick Cheney,Oprah,Donald Trump,YouTube,Kim Jong-il', 4, '5.0 (April 9, 2008): Dick Cheney -> Paris Hilton | 1.0 (March 12, 2008): Oprah -> Catholic Church | 2.0 (March 19, 2008): Donald Trump -> Viagra | 4.0 (April 2, 2008): YouTube -> YouTube | 7.0 (April 23, 2008): Kim Jong-il -> Tila Tequila'), ('Patton Oswalt', 3, 'YouTube,High School,Dick Cheney', 'YouTube,American Idol,Dick Cheney', 2, '4.0 (April 2, 2008): YouTube -> YouTube | 6.0 (April 16, 2008): American Idol -> High School | 5.0 (April 9, 2008): Dick Cheney -> Paris Hilton'), ('Andy Kindler', 2, 'Donald Trump,American Idol', 'Donald Trump,American Idol', 2, '2.0 (March 19, 2008): Donald Trump -> Viagra | 6.0 (April 16, 2008): American Idol -> High School'), ('Paul F. Tompkins', 2, 'Oprah,Weed', 'Oprah,Beer', 2, '1.0 (March 12, 2008): Oprah -> Catholic Church | 3.0 (March 26, 2008): Beer -> Weed')]",m_1764883188401_0d3c66e9_15781170-2,"As a performance-ethnographer curator I'd phrase this analytically but accessibly, referring to 'performers' or 'advocates' and to the show's 'Root of All Evil' and studio poll outcomes rather than SQL jargon. I'm unlikely to use column names like `Advocate # 1` but will reference episode numbers and air dates when useful. The SQL groups by advocate, counts appearances, collects distinct defended targets and associated Roots, sums mismatches between Root and poll, and assembles an episode timeline. The question I want therefore asks for recurring performers with their appearance counts, defended targets, associated Roots, mismatch counts, and episode-by-date timeline. I validate that this phrasing only requests fields the query produces (appearances, distinct targets, distinct roots, mismatch count, and episode timeline).",persona,"A performance-ethnographer and museum curator building an exhibit on how late-2000s stand-up comedians staged 'moral debates' and how audiences voted in those contests. Goals: Identify which comedians (advocates) recur across the season and the subjects they defended or attacked to map performer-driven themes for exhibit labels. Compare the show's designation of the 'Root of All Evil' with the studio poll winners to highlight tensions between comedic framing and audience opinion. Create a chronological timeline and frequency count of cultural targets (e.g., celebrities, institutions, vices) to design wall graphics and captions for the exhibit. Example Queries: SELECT ""#"" AS episode, ""Advocate # 1"", ""Advocate # 2"", ""Root of All Evil"", ""Poll winner"", ""Original air date"" FROM table_1_15781170_2 WHERE ""Advocate # 1"" LIKE '%Greg Giraldo%' OR ""Advocate # 2"" LIKE '%Greg Giraldo%'; SELECT ""#"", ""Advocate # 1"", ""Advocate # 2"", ""Root of All Evil"", ""Poll winner"", ""Original air date"" FROM table_1_15781170_2 WHERE ""Root of All Evil"" <> ""Poll winner""; SELECT ""Root of All Evil"", COUNT(*) AS times_named FROM table_1_15781170_2 GROUP BY ""Root of All Evil"" ORDER BY times_named DESC;",N/A,add_column,
"Considering only rows where Season # >= 1, for each Directed by: (GROUP BY Directed by:) what is the Episode Count as SUM(1) and what are the Episodes as GROUP_CONCAT(Title, '; '), restricted to directors HAVING SUM(1) > 1, ordered by Episode Count DESC and limited to 5?","
SELECT `Directed by:`, SUM(1) `Episode Count`, GROUP_CONCAT(`Title`, '; ') `Episodes`
FROM `table_m_1764883212939_4c8686ca_15824796_3`
WHERE `Season #` >= 1
GROUP BY `Directed by:`
HAVING SUM(1) > 1
ORDER BY `Episode Count` DESC
LIMIT 5;
","
SELECT col3, SUM(1) `Episode Count`, GROUP_CONCAT(col2, '; ') `Episodes`
FROM `table_m_1764883212939_4c8686ca_15824796_3`
WHERE col1 >= 1
GROUP BY col3
HAVING SUM(1) > 1
ORDER BY `Episode Count` DESC
LIMIT 5;
","[('Thomas Carr', 15, '""Five Minutes to Doom""; ""The Big Squeeze""; ""The Man Who Could Read Minds""; ""Jet Ace""; ""Superman in Exile""; ""The Dog Who Knew Superman""; ""The Man in the Lead Mask""; ""The Machine That Could Plot Crimes""; ""Jungle Devil""; ""My Friend Superman""; ""The Golden Vulture""; ""Jimmy Olsen, Boy Editor""; ""Lady in Black""; ""Star of Fate""; ""The Whistling Bird""'), ('George Blair', 10, '""Shot in the Dark""; ""The Defeat of Superman""; ""A Ghost for Scotland Yard""; ""The Face and the Voice""; "" Panic in the Sky ""; ""The Clown Who Cried""; ""The Boy Who Hated Superman""; ""Semi-Private Eye""; ""Perry White\'s Scoop""; ""Beware the Wrecker""')]",m_1764883212939_4c8686ca_15824796-3,"1) The SQL selects directors, counts rows, concatenates titles, filters on Season #, groups by director, keeps only directors with count >1, orders by count desc, and limits to 5. 2) Map `Directed by:`, `Title`, and `Season #` to director, episode titles, and season filter; SUM(1) is the Episode Count and GROUP_CONCAT(Title, '; ') is Episodes. 3) Phrase a question asking for Directed by:, Episode Count (SUM(1)), and Episodes (GROUP_CONCAT with '; ') with WHERE Season # >= 1, GROUP BY Directed by:, HAVING SUM(1) > 1, ORDER BY Episode Count DESC, LIMIT 5. 4) Check that the question includes all columns, calculations, filters, grouping, having, ordering, and limit.",reserved,10,N/A,add_column,
"For entries with No. in series > 0, give COUNT(No. in series) as Total Episodes; SUM(substr(Originalairdate,-4) = '2006') as Episodes in 2006; SUM(substr(Originalairdate,-4) = '2007') as Episodes in 2007; ROUND(SUM(substr(Originalairdate,-4) = '2006') * 100.0 / COUNT(No. in series), 2) as Pct 2006; ROUND(SUM(substr(Originalairdate,-4) = '2007') * 100.0 / COUNT(No. in series), 2) as Pct 2007; and MIN(Originalairdate) as Earliest airdate and MAX(Originalairdate) as Latest airdate?","
SELECT COUNT(`No. in series`) `Total Episodes`, SUM(substr(`Originalairdate`,-4) = '2006') `Episodes in 2006`, SUM(substr(`Originalairdate`,-4) = '2007') `Episodes in 2007`, ROUND(SUM(substr(`Originalairdate`,-4) = '2006') * 100.0 / COUNT(`No. in series`),2) `Pct 2006`, ROUND(SUM(substr(`Originalairdate`,-4) = '2007') * 100.0 / COUNT(`No. in series`),2) `Pct 2007`, MIN(`Originalairdate`) `Earliest airdate`, MAX(`Originalairdate`) `Latest airdate` FROM `table_m_1764883243202_bfcbdf7e_15861819_1` WHERE `No. in series` > 0;
","
SELECT COUNT(col0) `Total Episodes`, SUM(substr(col4,-4) = '2006') `Episodes in 2006`, SUM(substr(col4,-4) = '2007') `Episodes in 2007`, ROUND(SUM(substr(col4,-4) = '2006') * 100.0 / COUNT(col0),2) `Pct 2006`, ROUND(SUM(substr(col4,-4) = '2007') * 100.0 / COUNT(col0),2) `Pct 2007`, MIN(col4) `Earliest airdate`, MAX(col4) `Latest airdate` FROM `table_m_1764883243202_bfcbdf7e_15861819_1` WHERE col0 > 0;
","[(25, 14, 11, 56.0, 44.0, 'April14,2007', 'September8,2007')]",m_1764883243202_bfcbdf7e_15861819-1,"1) The intent is to summarize episodes with aggregates: total count, year-specific counts for 2006 and 2007 by checking substr(Originalairdate,-4), percentages of totals (rounded to 2 decimals), and earliest/latest Originalairdate, for rows where No. in series > 0. 2) Map to schema: No. in series used for COUNT and filtering; Originalairdate used for year extraction and MIN/MAX. 3) Phrase the question to list each aggregate and the exact expressions used (COUNT, SUM with substr, ROUND percentage formulas, MIN, MAX). 4) Confirm inclusion of the filter No. in series > 0 and exact calculations.",reserved,3,N/A,remove_column,
"Which distinct Opponents (t1.`Team`) — when the game rows are INNER JOINed to themselves on Date — have the following aggregates: SUM((t1.`Score` LIKE 'W %')) AS Wins, SUM((t1.`Score` LIKE 'W %') * (t1.`Team` LIKE '@%')) AS Away Wins, and SUM((t1.`High points` LIKE '%Chris Bosh%')) AS Chris Bosh Top Games, considering only rows WHERE (t1.`High points` LIKE '%Chris Bosh%') OR (t1.`High points` LIKE '%Jalen Rose%'), grouped by t1.`Team`, HAVING SUM((t1.`Score` LIKE 'W %')) > 0, ordered by Wins DESC and limited to 5?",unanswerable,unanswerable,,m_1764883297881_9b04fb31_15872814-6,"1) Parse the SQL intent: produce the top 5 opponents by wins (wins counted where Score starts with 'W '), also counting away wins and games where Chris Bosh was the high scorer, but only considering games where the high scorer was Chris Bosh or Jalen Rose. 2) Map schema semantics: `Team` is Opponent, `Score` indicates W/L with 'W ' prefix, away games marked by '@' at start of `Team`, and `High points` contains player names. 3) Draft the question: ask for distinct Opponents with SUM((Score LIKE 'W %')) AS Wins, SUM((Score LIKE 'W %') * (Team LIKE '@%')) AS Away Wins, SUM((High points LIKE '%Chris Bosh%')) AS Chris Bosh Top Games, with the WHERE, GROUP BY, HAVING, ORDER BY, LIMIT and the self-join on Date. 4) Validate: confirm inclusion of all columns, calculations, filters, grouping, and ordering from the query.",reserved,15,N/A,merge_column,
"For each Country (considering only rows with N°>0), what are the Country name, Total Channels as COUNT(*), HD Channels as SUM(HDTV='yes'), HD Percentage as ROUND(100.0*SUM(HDTV='yes')/COUNT(*),1), the Package Count as COUNT(`Package/Option`) and the Packages as GROUP_CONCAT(`Package/Option`), with results grouped by Country and sorted by HD Percentage descending?","
SELECT `Country`, COUNT(*) AS `Total Channels`, SUM(`HDTV`='yes') `HD Channels`, ROUND(100.0*SUM(`HDTV`='yes')/COUNT(*),1) `HD Percentage`, COUNT(`Package/Option`) `Package Count`, GROUP_CONCAT(`Package/Option`) `Packages`
FROM `table_m_1764883317502_7302b263_15887683_10`
WHERE `N°`>0
GROUP BY `Country`
ORDER BY `HD Percentage` DESC;
","
SELECT col1, COUNT(*) AS `Total Channels`, SUM(col5='yes') `HD Channels`, ROUND(100.0*SUM(col5='yes')/COUNT(*),1) `HD Percentage`, COUNT(col7) `Package Count`, GROUP_CONCAT(col7) `Packages`
FROM `table_m_1764883317502_7302b263_15887683_10`
WHERE col0>0
GROUP BY col1
ORDER BY `HD Percentage` DESC;
","[('Poland', 1, 1, 100.0, 1, 'Sky Famiglia + Sky HD'), ('United Kingdom', 2, 0, 0.0, 2, 'Sky Famiglia,Sky Famiglia'), ('Italy', 12, 0, 0.0, 12, 'Sky Famiglia,Sky Famiglia,Sky Famiglia,Sky Famiglia,Sky Famiglia,no ( FTV ),no ( FTV ),Sky Famiglia,Sky Famiglia,Sky Famiglia,Sky Famiglia,Option')]",m_1764883317502_7302b263_15887683-10,"1) The SQL groups by Country and returns aggregate metrics: total channels, HD channel count, rounded HD percentage, package count and packages concatenated, with N°>0 filter and sort by HD percentage descending. 2) Map table fields: N° filter, Country grouping, HDTV checked for 'yes', Package/Option counted and concatenated. 3) Create a question that requests all those aggregates and the exact percentage formula ROUND(100.0*SUM(HDTV='yes')/COUNT(*),1), plus grouping and ordering constraints. 4) Confirm no extra fields or assumptions are added beyond the query.",reserved,8,N/A,split_column,
"For each Validation, provide the Validation value, the total number of entries (COUNT(*) as Total), and the number of distinct Issuing network entries (COUNT(DISTINCT Issuing network) as Distinct issuers) for rows where Active IS Active OR IIN ranges = IIN ranges AND Length IN (Length), grouped by Validation, with groups having COUNT(*) > 0, limited to 10 results.","
SELECT `Validation` AS `Validation`, COUNT(*) `Total`, COUNT(DISTINCT `Issuing network`) `Distinct issuers`
FROM `table_m_1764883328152_c7aac91f_15905399_1`
WHERE `Active` IS `Active` OR `IIN ranges` = `IIN ranges` AND `Length` IN (`Length`)
GROUP BY `Validation` HAVING COUNT(*) > 0
LIMIT 10;
","
SELECT col4 AS col4, COUNT(*) `Total`, COUNT(DISTINCT col0) `Distinct issuers`
FROM `table_m_1764883328152_c7aac91f_15905399_1`
WHERE col2 IS col2 OR col1 = col1 AND col3 IN (col3)
GROUP BY col4 HAVING COUNT(*) > 0
LIMIT 10;
","[('Luhn algorithm', 13, 13), ('no validation', 2, 2)]",m_1764883328152_c7aac91f_15905399-1,"1) Intent: aggregate counts per Validation including distinct issuer count, with an unrestrictive WHERE (column equals itself), grouped and filtered by HAVING COUNT(*) > 0 and limited to 10. 2) Map: include Validation, Issuing network, Active, IIN ranges, Length, and the two COUNT aggregations. 3) Draft a question that explicitly requests those fields, conditions, grouping, having and limit. 4) Confirm alignment with SQL elements only.",reserved,13,N/A,add_column,
"From episodes with 'and' present in 'Who knows the most about the guest host? panelists', return up to 7 rows showing Episode Number, Air Date, Guest Host, the expression (LENGTH('Who knows the most about the guest host? panelists') - LENGTH(REPLACE('Who knows the most about the guest host? panelists', ',', '')) + 1) as Panelist Count, the expression (LENGTH('Musical Guest (Song performed)') - LENGTH(REPLACE('Musical Guest (Song performed)', '(', '')) - LENGTH(REPLACE('Musical Guest (Song performed)', ')', ''))) as ParenthesisChars, and the Guest Host again titled Billie Piper.","
SELECT `Episode Number`, `Air Date`, `Guest Host` `Guest Host`, (LENGTH(`Who knows the most about the guest host? panelists`) - LENGTH(REPLACE(`Who knows the most about the guest host? panelists`, ',', '')) + 1) `Panelist Count`, (LENGTH(`Musical Guest (Song performed)`) - LENGTH(REPLACE(`Musical Guest (Song performed)`, '(', '')) - LENGTH(REPLACE(`Musical Guest (Song performed)`, ')', ''))) `ParenthesisChars`, `Guest Host` `Billie Piper` FROM `table_m_1764883343668_426d67c7_1590967_2` WHERE instr(`Who knows the most about the guest host? panelists`, 'and') > 0 LIMIT 7;
","
SELECT col0, col1, col2 col2, (LENGTH(col4) - LENGTH(REPLACE(col4, ',', '')) + 1) `Panelist Count`, (LENGTH(col3) - LENGTH(REPLACE(col3, '(', '')) - LENGTH(REPLACE(col3, ')', ''))) `ParenthesisChars`, col2 `Billie Piper` FROM `table_m_1764883343668_426d67c7_1590967_2` WHERE instr(col4, 'and') > 0 LIMIT 7;
","[(1.0, '6 January 2006', 'Billie Piper', 1, -13, 'Billie Piper'), (2.0, '13 January 2006', 'Lorraine Kelly', 1, -16, 'Lorraine Kelly'), (3.0, '20 January 2006', 'Christian Slater', 1, -29, 'Christian Slater'), (4.0, '27 January 2006', 'Denise van Outen', 1, -25, 'Denise van Outen'), (5.0, '3 February 2006', 'Michael Barrymore', 1, -37, 'Michael Barrymore'), (6.0, '10 February 2006', 'Jamie Oliver', 1, -11, 'Jamie Oliver'), (7.0, '17 February 2006', 'Jessie Wallace', 1, -22, 'Jessie Wallace')]",m_1764883343668_426d67c7_1590967-2,"1) Parse SQL intent: select Episode Number, Air Date, Guest Host (twice with alias), compute panelist count via comma-based LENGTH/REPLACE formula, compute parenthesis-character expression from Musical Guest, filter rows where panelists contains 'and', and limit to 7 results. 2) Map schema: reference exact column names. 3) Draft question: combine all selections, calculations, filter and limit into one request. 4) Validate: ensure all columns, both calculations, the 'and' condition and the limit are explicitly included.",reserved,4,N/A,add_column,
"For each distinct Country with Seasons > 1, what is the COUNT(t.Seasons) as 'Seasons Above Peers' produced by joining the table to itself on t.Seasons > s.Seasons AND s.Seasons >= 1, while also returning two empty-string columns named 'Project Runway Canada' and 'Project Runway Malaysia', grouping by Country, keeping only groups where that COUNT(t.Seasons) > 0, and limiting the result to 10 rows?","
SELECT DISTINCT t.`Country`, COUNT(t.`Seasons`) `Seasons Above Peers`, '' `Project Runway Canada`, '' `Project Runway Malaysia`
FROM `table_m_1764883393832_2e83d4cc_1597866_3` t
JOIN `table_m_1764883393832_2e83d4cc_1597866_3` s
ON t.`Seasons` > s.`Seasons` AND s.`Seasons` >= 1
WHERE t.`Seasons` > 1
GROUP BY t.`Country`
HAVING COUNT(t.`Seasons`) > 0
LIMIT 10;
","
SELECT DISTINCT t.col0, COUNT(t.col5) `Seasons Above Peers`, '' `Project Runway Canada`, '' `Project Runway Malaysia`
FROM `table_m_1764883393832_2e83d4cc_1597866_3` t
JOIN `table_m_1764883393832_2e83d4cc_1597866_3` s
ON t.col5 > s.col5 AND s.col5 >= 1
WHERE t.col5 > 1
GROUP BY t.col0
HAVING COUNT(t.col5) > 0
LIMIT 10;
","[('Arab World', 4, '', ''), ('Canada', 4, '', ''), ('South Korea', 6, '', '')]",m_1764883393832_2e83d4cc_1597866-3,"1) Parse SQL intent: count, per country, how many rows have fewer Seasons than that country's Seasons (t.Seasons > s.Seasons) with s.Seasons >= 1, only for countries with t.Seasons > 1, returning groups with count > 0 and limiting to 10. 2) Map schema: use Country and Seasons columns from the table; COUNT(t.Seasons) is aliased as 'Seasons Above Peers'; include two empty-string columns named 'Project Runway Canada' and 'Project Runway Malaysia'. 3) Draft question: ask for distinct Country, the COUNT as 'Seasons Above Peers', two empty-string columns, group and filter as in SQL, limit 10. 4) Validate: the question mentions the join condition, s.Seasons constraint, t.Seasons filter, grouping, having, and limit.",reserved,11,N/A,remove_column,
"Group member states (excluding the 'European Union') whose GDP per capita in PPP US$ (2012) is between 20000 and 45000 into Fiscal Risk = 'High fiscal stress' if Public Debt % of GDP (2013 Q1) > 100 else 'Lower stress', and for each group report the number of Members, the average GDP per capita in PPP US$ (2012) rounded to the nearest whole number, and the average Public Debt % of GDP (2013 Q1) rounded to one decimal place, but only show groups with more than one member?",unanswerable,unanswerable,,m_1764883406118_24f9f274_1598533-8,"Parse SQL intent: create two groups by Public Debt % of GDP (2013 Q1) > 100 and compute counts and rounded averages only for countries with GDP per capita between 20000 and 45000 excluding 'European Union'. Map schema semantics: use the specified column names and rounding: ROUND(AVG(GDP per capita in PPP US$ (2012)),0) and ROUND(AVG(Public Debt % of GDP (2013 Q1)),1); require COUNT(*) > 1. Draft and validate the question to include all these elements.",reserved,16,N/A,merge_column,
"What are the Country, COUNT(*), and GROUP_CONCAT(RR Romaja, '; ') values for each Country when grouped by Country and ordered by COUNT(*) DESC?","
SELECT `Country` AS `Country`, COUNT(*) , GROUP_CONCAT(`RR Romaja`, '; ') FROM `table_m_1764883453794_2b221c8b_160510_5` WHERE 1=1 AND 1=1 GROUP BY `Country` ORDER BY COUNT(*) DESC;
","
SELECT col7 AS col7, COUNT(*) , GROUP_CONCAT(col0, '; ') FROM `table_m_1764883453794_2b221c8b_160510_5` WHERE 1=1 AND 1=1 GROUP BY col7 ORDER BY COUNT(*) DESC;
","[('South Korea', 9, 'Chungcheongbuk; Chungcheongnam; Gangwon; Gyeonggi; Gyeongsangbuk; Gyeongsangnam; Jeju; Jeollabuk; Jeollanam'), ('North Korea', 8, 'Gangwon; Hamgyeongbuk; Hamgyeongnam; Hwanghaebuk; Hwanghaenam; Jagang; Pyeonganbuk; Pyeongannam')]",m_1764883453794_2b221c8b_160510-5,"1) The SQL selects Country, counts rows, concatenates RR Romaja with '; ', groups by Country, and sorts by count descending. 2) RR Romaja are the province romanizations and Country is the country label in the dataset. 3) Formulate a question asking explicitly for Country, COUNT(*), and GROUP_CONCAT(RR Romaja, '; ') with GROUP BY Country and ORDER BY COUNT(*) DESC. 4) This captures all calculations and ordering present in the query.",reserved,9,N/A,remove_column,
"Using Channel, Station, Network, Video Frequency and Audio Frequency, convert Video Frequency and Audio Frequency by removing '- MHz' and spaces and treating the results as numbers as Video_freq and Audio_freq, compute Gap as (Audio_freq - Video_freq) and compute OverallAvg as the average Gap across the table; then (1) for each Network excluding '`MPB`' return Network, COUNT(Station) as Stations, AVG(Gap) as AvgGap and MAX(Gap) as MaxGap for networks having COUNT(Station) > 1 (limit 10), UNION (2) return DISTINCT Station, Network, Gap and Video_freq for rows where Gap > OverallAvg AND Status = '`Commercial`' (limit 5)?",,,[],m_1764883469525_04eeef4d_160728-4,"Parse intent: compute numeric Video_freq and Audio_freq from the Video Frequency and Audio Frequency text, compute Gap = Audio_freq - Video_freq, get overall average Gap, then produce a grouped Network summary excluding '`MPB`' and a second set of distinct commercial stations whose Gap exceeds the overall average. Map schema: Video Frequency and Audio Frequency are strings like '189.250- MHz' that must have '- MHz' and spaces removed and be cast to numbers; use Station, Network, Status and Channel as available. Draft: request both the grouped aggregated Network metrics and the distinct station rows with the specified filters, aliases and limits. Validate: ensure the question mentions Channel, Station, Network, Video_freq, Audio_freq, Gap, OverallAvg, the exclusion '`MPB`', Status '`Commercial`', aliases Stations/AvgGap/MaxGap, GROUP/HAVING, DISTINCT and the two LIMITs.",reserved,19,N/A,merge_column,
"For every Primary conference, what are the Primary conference name, the count of Institution as Institutions, the SUM(Enrollment) as Total Enrollment, the ROUND of AVG(Enrollment) as Avg Enrollment, and the explicit zeros 0 for Central Washington University, 0 for College of Idaho, 0 for Gonzaga University, 0 for Pacific Lutheran University, 0 for University of Portland, 0 for University of Puget Sound, 0 for Southern Oregon University, 0 for Western Oregon University, and 0 for Western Washington University?","
SELECT `Primary conference`, COUNT(`Institution`) `Institutions`, SUM(`Enrollment`) `Total Enrollment`, ROUND(AVG(`Enrollment`)) `Avg Enrollment`, 0 `Central Washington University`, 0 `College of Idaho`, 0 `Gonzaga University`, 0 `Pacific Lutheran University`, 0 `University of Portland`, 0 `University of Puget Sound`, 0 `Southern Oregon University`, 0 `Western Oregon University`, 0 `Western Washington University`
FROM `table_m_1764883494807_d72a1235_16078390_2`
WHERE 1=1
GROUP BY `Primary conference`;
","
SELECT col5, COUNT(col0) `Institutions`, SUM(col3) `Total Enrollment`, ROUND(AVG(col3)) `Avg Enrollment`, 0 `Central Washington University`, 0 `College of Idaho`, 0 `Gonzaga University`, 0 `Pacific Lutheran University`, 0 `University of Portland`, 0 `University of Puget Sound`, 0 `Southern Oregon University`, 0 `Western Oregon University`, 0 `Western Washington University`
FROM `table_m_1764883494807_d72a1235_16078390_2`
WHERE 1=1
GROUP BY col5;
","[('Cascade ( NAIA )', 2, 5610.0, 2805.0, 0, 0, 0, 0, 0, 0, 0, 0, 0), ('GNAC ( Division II )', 3, 30629.0, 10210.0, 0, 0, 0, 0, 0, 0, 0, 0, 0), ('NWC ( Division III )', 2, 6269.0, 3135.0, 0, 0, 0, 0, 0, 0, 0, 0, 0), ('WCC ( Division I )', 2, 10809.0, 5405.0, 0, 0, 0, 0, 0, 0, 0, 0, 0)]",m_1764883494807_d72a1235_16078390-2,"1) The query selects Primary conference and computes COUNT(Institution), SUM(Enrollment), ROUND(AVG(Enrollment)), plus nine constant zero columns for each institution, grouping by Primary conference. 2) Map these operations to the table columns Primary conference, Institution, and Enrollment. 3) Create a question that requests exactly those aggregate values and the zero placeholders for each listed institution for every Primary conference. 4) Ensure the question contains all column names, aggregate functions, the rounding, and the zero-valued institution columns.",reserved,5,N/A,split_column,
"List the `Directed by` value, COUNT(*) AS EpisodeCount, and SUM(Originalairdate LIKE '%2008') AS Episodes2008 for directors with `No. in season` > 0 and `Directed by` <> '', grouping by `Directed by`, ordering by Episodes2008 (ascending) and returning only the first 3 results?","
SELECT `Directed by`, COUNT(*) `EpisodeCount`, SUM(`air_date` LIKE '%2008') AS `Episodes2008`
FROM `table_m_1764883503312_0dc2da76_16090262_1`
WHERE `season_number` > 0 AND `Directed by` <> ''
GROUP BY `Directed by`
ORDER BY `Episodes2008`
LIMIT 3;
","
SELECT col3, COUNT(*) `EpisodeCount`, SUM(col5 LIKE '%2008') AS `Episodes2008`
FROM `table_m_1764883503312_0dc2da76_16090262_1`
WHERE col1 > 0 AND col3 <> ''
GROUP BY col3
ORDER BY `Episodes2008`
LIMIT 3;
","[('Roy Burdine', 13, 11)]",m_1764883503312_0dc2da76_16090262-1,"1) Parse intent: aggregate episodes per director and count those with Originalairdate in 2008, applying filters and returning three rows ordered by the 2008 count. 2) Map schema: use `Directed by`, `No. in season`, and `Originalairdate` to compute COUNT(*) AS EpisodeCount and SUM(Originalairdate LIKE '%2008') AS Episodes2008 grouped by `Directed by`. 3) Draft: form a question asking for the director name, EpisodeCount, and Episodes2008 with the WHERE, GROUP BY, ORDER BY Episodes2008, and LIMIT 3 constraints. 4) Validate: confirms all SQL elements are present in the question.",reserved,12,N/A,rename_column,
"Which Vehicle and corresponding national_g/mi (defined by casting as INTEGER the substring of 'U.S. national average electric mix' from the first character up to the first space) ranks highest when ordering by national_g/mi in descending order, considering only rows where Vehicle is not empty and returning the top result?",unanswerable,unanswerable,,m_1764883516351_5a91985d_16105186-2,"1) The intent is to compute an integer national_g/mi from the 'U.S. national average electric mix' by taking characters before the first space and casting to INTEGER, then pick the max Vehicle. 2) Map this to the Vehicle column and the computed national_g/mi derived from substr(...,1,instr(...,' ')-1). 3) Draft a concise question asking for the Vehicle and the integer national_g/mi computed by that exact substring-and-cast procedure, excluding empty Vehicle values and returning the top-ranked row. 4) Validate that the question requests the single Vehicle with the largest computed national_g/mi and includes the calculation details.",reserved,11,N/A,merge_column,
"For each genre, which titles are included and how many are multiplayer-capable?",unanswerable,unanswerable,,m_1764883530392_40d265b7_1616608-2,"STEP 1: Parse the SQL intent: group rows by Genre (excluding the row with Western Title 'Polarium' and Released Date '2005'), return Genre, total number of rows per genre (COUNT(*) as total_games), a concatenated list of Western Title values per genre, and an additional COUNT(*) column aliased multiplayer_capable (which in this SQL is identical to total_games). Results are ordered by total_games (ascending) and limited to 5 genres. STEP 2: Choose ambiguity type: Attachment ambiguity fits well because the phrasing around ""multiplayer-capable"" can attach either to the count, to the list of titles, or to the genre selection; this maps to the SQL quirk where multiplayer_capable is actually the same as total_games. STEP 3: Draft the question: ""For each genre, which titles are included and how many are multiplayer-capable?"" STEP 4: Explain the ambiguity: the question can be read as asking (a) for, per genre, the count of multiplayer-capable games and the titles of those multiplayer games, or (b) for, per genre, the list of all titles plus a count (which might unintentionally be the total number of games in that genre rather than only multiplayer ones). The original query produces the latter (count = total games) while a different query could filter the count to only multiplayer-capable entries.",reserved,9,N/A,merge_column,"type: Attachment ambiguity | explanation: The phrase ""how many are multiplayer-capable"" can attach either to the count (asking for the number of multiplayer games per genre) or to the titles (asking for the titles that are multiplayer-capable). The given SQL returns a count equal to total games per genre (so it matches the interpretation where the count is not filtered to multiplayer games), but a different query could restrict the count to only multiplayer-capable rows and only list those titles."
"Show me the SEC opponents that matter for Columbia/neutral narratives — those with a home edge, lopsided recent series, notable neutral-site history, or big streaks — ranked by a composite rivalry-heat score with parsed home, last-five, last-ten and streak numbers?","
SELECT
  `Missouri vs.`,
  `at Columbia`,
  `at Neutral Site`,
  `Last 5 Meetings`,
  `Last 10 Meetings`,
  `Current Streak`,
  -- parse Missouri home wins/losses when `at Columbia` is in the form ""MU, X-Y""
  CASE
    WHEN `at Columbia` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), 1, INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')-1) AS INTEGER)
    ELSE 0
  END AS `mu_home_wins`,
  CASE
    WHEN `at Columbia` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')+1) AS INTEGER)
    ELSE 0
  END AS `mu_home_losses`,
  -- last 5: compute Missouri wins and opponent wins (handles ""MU, X-Y"", ""Tied, X-Y"", and ""OPP, X-Y"")
  CASE
    WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
  END AS `last5_mu_wins`,
  CASE
    WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
  END AS `last5_opp_wins`,
  -- last 10 analogous margins (treat same patterns)
  (CASE
    WHEN `Last 10 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    WHEN `Last 10 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
  END)
  -
  (CASE
    WHEN `Last 10 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    WHEN `Last 10 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
  END) AS `last10_margin`,
  -- last5 margin
  (CASE
    WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
  END)
  -
  (CASE
    WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
  END) AS `last5_margin`,
  -- current streak numeric score (positive for MU wins, negative for MU losses)
  CASE
    WHEN `Current Streak` LIKE 'W %' THEN CAST(SUBSTR(`Current Streak`, 3) AS INTEGER)
    WHEN `Current Streak` LIKE 'L %' THEN -CAST(SUBSTR(`Current Streak`, 3) AS INTEGER)
    ELSE 0
  END AS `streak_score`,
  -- home margin (only when `at Columbia` is ""MU, X-Y"")
  (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
     CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), 1, INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')-1) AS INTEGER)
   ELSE 0 END)
  -
  (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
     CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')+1) AS INTEGER)
   ELSE 0 END) AS `home_margin`,
  -- composite rivalry heat score (weights: last5 x3, home x2, neutral history bonus x2, last10 x1, current streak x1)
  (
    ((CASE WHEN `at Columbia` LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), 1, INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')-1) AS INTEGER)
     ELSE 0 END)
    -
    (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')+1) AS INTEGER)
     ELSE 0 END)
    ) * 2
  )
  +
  ( -- last5 contribution *3
    (
      (CASE
        WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
        WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
        ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      END)
      -
      (CASE
        WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
        WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
        ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      END)
    ) * 3
  )
  +
  ( -- neutral-site bonus
    CASE WHEN `at Neutral Site` NOT LIKE 'Tied, 0-0' THEN 2 ELSE 0 END
  )
  +
  ( -- last10 margin *1
    (CASE
      WHEN `Last 10 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      WHEN `Last 10 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    END)
    -
    (CASE
      WHEN `Last 10 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      WHEN `Last 10 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 10 Meetings`, INSTR(`Last 10 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    END)
  )
  +
  ( -- streak score
    CASE
      WHEN `Current Streak` LIKE 'W %' THEN CAST(SUBSTR(`Current Streak`, 3) AS INTEGER)
      WHEN `Current Streak` LIKE 'L %' THEN -CAST(SUBSTR(`Current Streak`, 3) AS INTEGER)
      ELSE 0
    END
  ) AS `rivalry_heat`
FROM `table_m_1764883581959_116a2c3d_16201038_5`
WHERE
  -- surface opponents that matter for a Columbia/neutral-site narrative: pronounced home advantage,
  -- strongly lopsided recent series, notable neutral-site history, or notable current streak
  (
    (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), 1, INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')-1) AS INTEGER)
     ELSE 0 END)
    -
    (CASE WHEN `at Columbia` LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), INSTR(SUBSTR(`at Columbia`, INSTR(`at Columbia`, ', ')+2), '-')+1) AS INTEGER)
     ELSE 0 END)
  ) >= 1
  OR ABS(
    (CASE
      WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
    END)
    -
    (CASE
      WHEN `Last 5 Meetings` LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      WHEN `Last 5 Meetings` LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')+1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), 1, INSTR(SUBSTR(`Last 5 Meetings`, INSTR(`Last 5 Meetings`, ', ')+2), '-')-1) AS INTEGER)
    END)
  ) >= 2
  OR `at Neutral Site` NOT LIKE 'Tied, 0-0'
  OR ABS(CASE WHEN `Current Streak` LIKE 'W %' THEN CAST(SUBSTR(`Current Streak`, 3) AS INTEGER) WHEN `Current Streak` LIKE 'L %' THEN -CAST(SUBSTR(`Current Streak`, 3) AS INTEGER) ELSE 0 END) >= 2
ORDER BY `rivalry_heat` DESC, `last5_margin` DESC, `home_margin` DESC, `streak_score` DESC;
","
SELECT
  col0,
  col1,
  col3,
  col4,
  col5,
  col6,
  -- parse Missouri home wins/losses when col1 is in the form ""MU, X-Y""
  CASE
    WHEN col1 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col1, INSTR(col1, ', ')+2), 1, INSTR(SUBSTR(col1, INSTR(col1, ', ')+2), '-')-1) AS INTEGER)
    ELSE 0
  END AS `mu_home_wins`,
  CASE
    WHEN col1 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col1, INSTR(col1, ', ')+2), INSTR(SUBSTR(col1, INSTR(col1, ', ')+2), '-')+1) AS INTEGER)
    ELSE 0
  END AS `mu_home_losses`,
  -- last 5: compute Missouri wins and opponent wins (handles ""MU, X-Y"", ""Tied, X-Y"", and ""OPP, X-Y"")
  CASE
    WHEN col4 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
    WHEN col4 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
  END AS `last5_mu_wins`,
  CASE
    WHEN col4 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
    WHEN col4 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
  END AS `last5_opp_wins`,
  -- last 10 analogous margins (treat same patterns)
  (CASE
    WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
    WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
  END)
  -
  (CASE
    WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
    WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
  END) AS `last10_margin`,
  -- last5 margin
  (CASE
    WHEN col4 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
    WHEN col4 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
  END)
  -
  (CASE
    WHEN col4 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
    WHEN col4 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
    ELSE CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
  END) AS `last5_margin`,
  -- current streak numeric score (positive for MU wins, negative for MU losses)
  CASE
    WHEN col6 LIKE 'W %' THEN CAST(SUBSTR(col6, 3) AS INTEGER)
    WHEN col6 LIKE 'L %' THEN -CAST(SUBSTR(col6, 3) AS INTEGER)
    ELSE 0
  END AS `streak_score`,
  -- home margin (only when col1 is ""MU, X-Y"")
  (CASE WHEN col1 LIKE 'MU, %' THEN
     CAST(SUBSTR(SUBSTR(col1, INSTR(col1, ', ')+2), 1, INSTR(SUBSTR(col1, INSTR(col1, ', ')+2), '-')-1) AS INTEGER)
   ELSE 0 END)
  -
  (CASE WHEN col1 LIKE 'MU, %' THEN
     CAST(SUBSTR(SUBSTR(col1, INSTR(col1, ', ')+2), INSTR(SUBSTR(col1, INSTR(col1, ', ')+2), '-')+1) AS INTEGER)
   ELSE 0 END) AS `home_margin`,
  -- composite rivalry heat score (weights: last5 x3, home x2, neutral history bonus x2, last10 x1, current streak x1)
  (
    ((CASE WHEN col1 LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(col1, INSTR(col1, ', ')+2), 1, INSTR(SUBSTR(col1, INSTR(col1, ', ')+2), '-')-1) AS INTEGER)
     ELSE 0 END)
    -
    (CASE WHEN col1 LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(col1, INSTR(col1, ', ')+2), INSTR(SUBSTR(col1, INSTR(col1, ', ')+2), '-')+1) AS INTEGER)
     ELSE 0 END)
    ) * 2
  )
  +
  ( -- last5 contribution *3
    (
      (CASE
        WHEN col4 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
        WHEN col4 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
        ELSE CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
      END)
      -
      (CASE
        WHEN col4 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
        WHEN col4 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
        ELSE CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
      END)
    ) * 3
  )
  +
  ( -- neutral-site bonus
    CASE WHEN col3 NOT LIKE 'Tied, 0-0' THEN 2 ELSE 0 END
  )
  +
  ( -- last10 margin *1
    (CASE
      WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
      WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
    END)
    -
    (CASE
      WHEN col5 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
      WHEN col5 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')+1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(col5, INSTR(col5, ', ')+2), 1, INSTR(SUBSTR(col5, INSTR(col5, ', ')+2), '-')-1) AS INTEGER)
    END)
  )
  +
  ( -- streak score
    CASE
      WHEN col6 LIKE 'W %' THEN CAST(SUBSTR(col6, 3) AS INTEGER)
      WHEN col6 LIKE 'L %' THEN -CAST(SUBSTR(col6, 3) AS INTEGER)
      ELSE 0
    END
  ) AS `rivalry_heat`
FROM `table_m_1764883581959_116a2c3d_16201038_5`
WHERE
  -- surface opponents that matter for a Columbia/neutral-site narrative: pronounced home advantage,
  -- strongly lopsided recent series, notable neutral-site history, or notable current streak
  (
    (CASE WHEN col1 LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(col1, INSTR(col1, ', ')+2), 1, INSTR(SUBSTR(col1, INSTR(col1, ', ')+2), '-')-1) AS INTEGER)
     ELSE 0 END)
    -
    (CASE WHEN col1 LIKE 'MU, %' THEN
       CAST(SUBSTR(SUBSTR(col1, INSTR(col1, ', ')+2), INSTR(SUBSTR(col1, INSTR(col1, ', ')+2), '-')+1) AS INTEGER)
     ELSE 0 END)
  ) >= 1
  OR ABS(
    (CASE
      WHEN col4 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
      WHEN col4 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
    END)
    -
    (CASE
      WHEN col4 LIKE 'MU, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
      WHEN col4 LIKE 'Tied, %' THEN CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')+1) AS INTEGER)
      ELSE CAST(SUBSTR(SUBSTR(col4, INSTR(col4, ', ')+2), 1, INSTR(SUBSTR(col4, INSTR(col4, ', ')+2), '-')-1) AS INTEGER)
    END)
  ) >= 2
  OR col3 NOT LIKE 'Tied, 0-0'
  OR ABS(CASE WHEN col6 LIKE 'W %' THEN CAST(SUBSTR(col6, 3) AS INTEGER) WHEN col6 LIKE 'L %' THEN -CAST(SUBSTR(col6, 3) AS INTEGER) ELSE 0 END) >= 2
ORDER BY `rivalry_heat` DESC, `last5_margin` DESC, `home_margin` DESC, `streak_score` DESC;
","[('Georgia', 'MU, 2-0', 'MU, 1-0', 'MU, 4-0', 'MU, 4-0', 'W 4', 2, 0, 4, 0, 4, 4, 4, 2, 26), ('Mississippi State', 'MU, 2-0', 'Tied, 0-0', 'MU, 3-1', 'MU, 3-1', 'W 1', 2, 0, 3, 1, 2, 2, 1, 2, 13), ('South Carolina', 'MU, 1-0', 'Tied, 0-0', 'MU, 2-0', 'MU, 2-0', 'W 2', 1, 0, 2, 0, 2, 2, 2, 1, 12), ('Texas A&M', 'MU, 6-3', 'MU, 4-1', 'MU, 3-2', 'TAMU, 7-3', 'W 1', 6, 3, 3, 2, -4, 1, 1, 3, 8), ('Auburn', 'MU, 1-0', 'Tied, 0-0', 'MU, 1-0', 'MU, 1-0', 'W 1', 1, 0, 1, 0, 1, 1, 1, 1, 7), ('Vanderbilt', 'MU, 3-0', 'VU, 1-0', 'VU, 3-2', 'Tied, 3-3', 'W 2', 3, 0, 2, 3, 0, -1, 2, 3, 7), ('Florida', 'MU, 1-0', 'Tied, 0-0', 'Tied, 1-1', 'Tied, 1-1', 'W 1', 1, 0, 1, 1, 0, 0, 1, 1, 3), ('Tennessee', 'MU, 2-0', 'UT, 1-0', 'UT, 3-2', 'MU, 4-3', 'L 1', 2, 0, 2, 3, 1, -1, -1, 2, 3), ('Louisiana State', 'MU, 1-0', 'LSU, 1-0', 'LSU, 2-1', 'LSU, 2-1', 'W 1', 1, 0, 1, 2, -1, -1, 1, 1, 1), ('Arkansas', 'MU, 11-8', 'UA, 1-0', 'UA, 3-2', 'UA, 8-2', 'W 1', 11, 8, 2, 3, -6, -1, 1, 3, 0), ('Mississippi', 'MU, 1-0', 'UM, 1-0', 'UM, 2-1', 'UM, 2-1', 'L 1', 1, 0, 1, 2, -1, -1, -1, 1, -1), ('Alabama', 'Tied, 1-1', 'UA, 2-1', 'UA, 3-2', 'UA, 4-2', 'W 2', 0, 0, 2, 3, -2, -1, 2, 0, -1), ('Kentucky', 'Tied, 0-0', 'UK, 2-0', 'UK, 5-0', 'UK, 5-0', 'L 5', 0, 0, 0, 5, -5, -5, -5, 0, -23)]",m_1764883581959_116a2c3d_16201038-5,"For ordering waypoint content I want a ranked list by overall rivalry heat combining home edge, recent margins, neutral history and streaks, phrased as a single practical ask. The SQL filters opponents that matter (home margin >=1, big last-5 swing, any neutral-site history, or streak magnitude >=2), computes parsed stats (home, last5, last10, streak) and a composite 'rivalry_heat' score, then orders by that score and tiebreakers. The schema columns used are 'at Columbia', 'at Neutral Site', 'Last 5 Meetings', 'Last 10 Meetings', and 'Current Streak' which are parsed into numeric components. Draft question: Show me the SEC opponents that matter for Columbia/neutral narratives — those with a home edge, lopsided recent series, notable neutral-site history, or big streaks — ranked by a composite rivalry-heat score with parsed home/last5/last10/streak numbers. This matches the SQL's selection, computed fields, and ordering.",persona,"An augmented-reality 'Rivalry Walk' narrative designer at the University of Missouri who scripts short, venue-aware audio vignettes about each SEC opponent using granular head-to-head stats. Goals: Identify opponents where Missouri has a pronounced home advantage (to craft triumphant home-focused narratives for the Columbia stop). Spot intense or lopsided recent series (last 5/10 meetings) and neutral-site histories to build dramatic, context-rich audio scenes for stadium plazas and neutral-site exhibit points. Rank current streaks (wins/losses) to vary emotional tone across waypoints and programmatically generate narration templates ordered by rivalry heat. Example Queries: SELECT ""Missouri vs."", ""at Columbia"", ""Current Streak"", ""Since Joining SEC""
FROM ""table_1_16201038_5""
WHERE ""at Columbia"" LIKE 'MU%'; SELECT ""Missouri vs."", ""at Neutral Site"", ""Last 10 Meetings""
FROM ""table_1_16201038_5""
WHERE ""at Neutral Site"" NOT LIKE 'Tied, 0-0'
  AND ""Last 10 Meetings"" NOT LIKE 'Tied%'; SELECT ""Missouri vs."", ""Current Streak""
FROM ""table_1_16201038_5""
WHERE ""Current Streak"" LIKE 'W %'
ORDER BY CAST(SUBSTR(""Current Streak"", 3) AS INTEGER) DESC;",N/A,split_column,
"Using the game log and WHERE 1=1, for each Record produce: Record; COUNT(*) AS ""Total Games""; ROUND(AVG(Attendance),0) AS ""Avg Attendance""; ROUND(SUM((`at/vs.`='vs.')*Attendance)/NULLIF(SUM((`at/vs.`='vs.')),0),0) AS ""Avg Home Attendance""; ROUND(AVG((substr(Score,1,instr(Score,' - ')-1)+0) - (substr(Score,instr(Score,' - ')+3)+0)),2) AS ""Avg Goal Diff""; plus MAX('New England Blazers'), MAX('Baltimore Thunder'), MAX('New York Saints'), MAX('Detroit Turbos'), and MAX('Washington Wave'), grouped by Record, ordered by Avg Attendance * -1, limit 10?",unanswerable,unanswerable,,m_1764883599619_70bcc1d6_16227492-1,"1) Parse intent: aggregate the GameLog by Record to produce counts, averages (overall and home-only), average goal difference computed from parsed Score strings, include fixed opponent-name MAX(...) columns, sort by Avg Attendance descending and restrict to 10 rows. 2) Map schema: use `Attendance`, `at/vs.`, `Score` (parsed via substr/instr), and `Record` for grouping. 3) Draft: formulate a question that names each selected expression exactly (ROUNDs, SUM/NULLIF for home average, substr/instr arithmetic for goal diff, and MAX of each team string), includes WHERE 1=1, GROUP BY Record, ORDER BY Avg Attendance * -1, LIMIT 10. 4) Validate: question contains every column, calculation, grouping, ordering, and limit present in the SQL.",reserved,10,N/A,merge_column,
"I need a shortlist to contact directors — which submitted Australian films include Yolngu Matha, Gunwinggu, or Warlpiri or were shortlisted/nominated, with title, year, director, languages, matched Indigenous languages and count, result, and an overall priority and score (highest priority first)?",unanswerable,unanswerable,,m_1764883610838_91fd3154_16254861-1,"I'm curating screenings and will reach out to directors, so I'd phrase the ask practically and not in technical SQL terms. The query filters for films containing Yolngu Matha, Gunwinggu, or Warlpiri or films with shortlist/nominated results and builds a match string, counts matches, and flags recognition. The schema maps to film title, ceremony year, director, languages, matched Indigenous languages, an Indigenous count, result, and a derived priority and numeric score. I want the highest priority entries first so I can focus contacts and rights negotiation.",persona,"A mobile-archive curator who organizes community screenings and language-revitalization workshops using Australian Academy Award foreign-language submissions that feature Indigenous and minority languages. Goals: Identify submitted Australian films that contain Indigenous Australian languages (for targeted community screenings and language-resource development). Prioritize films with festival/award recognition (shortlisted or nominated) to increase local attendance and grant success. Build a short list of directors to contact for screening rights, Q&As, and to source language consultants and archival materials. Example Queries: SELECT `Film title used in nomination`, `Year (Ceremony)`, `Language(s)`, `Director` FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Yolngu Matha%' OR `Language(s)` LIKE '%Warlpiri%' OR `Language(s)` LIKE '%Gunwinggu%'; SELECT `Film title used in nomination`, `Year (Ceremony)`, `Result`, `Director` FROM `table_1_16254861_1` WHERE `Result` LIKE '%Shortlist%' OR `Result` LIKE '%Nominated%'; SELECT 'Yolngu Matha' AS language, COUNT(*) AS films FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Yolngu Matha%' UNION ALL SELECT 'Warlpiri', COUNT(*) FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Warlpiri%' UNION ALL SELECT 'Gunwinggu', COUNT(*) FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Gunwinggu%' UNION ALL SELECT 'Cantonese', COUNT(*) FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%Cantonese%' UNION ALL SELECT 'German', COUNT(*) FROM `table_1_16254861_1` WHERE `Language(s)` LIKE '%German%';",N/A,merge_column,
"Show me states with their interview and swimsuit scores, the absolute interview–swimsuit difference, the improvement from preliminary to semifinal, semifinal rank, and the coaching-priority label so I can spot and prioritize inconsistencies.","
WITH scores AS (
  SELECT
    `state`,
    CAST(SUBSTR(`preliminary_average`, 1, INSTR(`preliminary_average`, ' (') - 1) AS NUMERIC) AS preliminary_score,
    CAST(SUBSTR(`Interview`, 1, INSTR(`Interview`, ' (') - 1) AS NUMERIC) AS interview_score,
    CAST(SUBSTR(`Swimsuit`, 1, INSTR(`Swimsuit`, ' (') - 1) AS NUMERIC) AS swimsuit_score,
    CAST(SUBSTR(`Evening Gown`, 1, INSTR(`Evening Gown`, ' (') - 1) AS NUMERIC) AS eveninggown_score,
    CAST(SUBSTR(`semifinal_average`, 1, INSTR(`semifinal_average`, ' (') - 1) AS NUMERIC) AS semifinal_score
  FROM `table_m_1764883620089_c9461837_16268026_3`
),
maxes AS (
  SELECT
    MAX(preliminary_score) AS max_prelim,
    MAX(interview_score) AS max_interview,
    MAX(swimsuit_score) AS max_swimsuit,
    MAX(eveninggown_score) AS max_evening,
    MAX(semifinal_score) AS max_semifinal
  FROM scores
)
SELECT
  s.`state`,
  ROUND(s.preliminary_score, 3) AS `Preliminary Score`,
  ROUND(s.interview_score, 3) AS `Interview Score`,
  ROUND(s.swimsuit_score, 3) AS `Swimsuit Score`,
  ROUND(s.eveninggown_score, 3) AS `Evening Gown Score`,
  ROUND(s.semifinal_score, 3) AS `Semifinal Score`,
  ROUND(s.semifinal_score - s.preliminary_score, 3) AS `Improvement (Semifinal - Preliminary)`,
  ROUND(ABS(s.interview_score - s.swimsuit_score), 3) AS `Interview vs Swimsuit Diff`,
  (
    CASE WHEN s.preliminary_score = m.max_prelim THEN 'Preliminary' ELSE '' END ||
    CASE WHEN s.interview_score = m.max_interview THEN (CASE WHEN s.preliminary_score = m.max_prelim THEN ', Interview' ELSE 'Interview' END) ELSE '' END ||
    CASE WHEN s.swimsuit_score = m.max_swimsuit THEN (CASE WHEN (s.preliminary_score = m.max_prelim OR s.interview_score = m.max_interview) THEN ', Swimsuit' ELSE 'Swimsuit' END) ELSE '' END ||
    CASE WHEN s.eveninggown_score = m.max_evening THEN (CASE WHEN (s.preliminary_score = m.max_prelim OR s.interview_score = m.max_interview OR s.swimsuit_score = m.max_swimsuit) THEN ', Evening Gown' ELSE 'Evening Gown' END) ELSE '' END ||
    CASE WHEN s.semifinal_score = m.max_semifinal THEN (CASE WHEN (s.preliminary_score = m.max_prelim OR s.interview_score = m.max_interview OR s.swimsuit_score = m.max_swimsuit OR s.eveninggown_score = m.max_evening) THEN ', Semifinal' ELSE 'Semifinal' END) ELSE '' END
  ) AS `Category Leader Flags`,
  RANK() OVER (ORDER BY s.semifinal_score DESC) AS `Semifinal Rank`,
  CASE
    WHEN (s.semifinal_score - s.preliminary_score) >= 0.200 OR ABS(s.interview_score - s.swimsuit_score) >= 0.600 THEN 'High'
    WHEN (s.semifinal_score - s.preliminary_score) >= 0.100 OR ABS(s.interview_score - s.swimsuit_score) >= 0.350 THEN 'Medium'
    ELSE 'Low'
  END AS `Coaching Priority`
FROM scores s
CROSS JOIN maxes m
ORDER BY `Improvement (Semifinal - Preliminary)` DESC, `Semifinal Score` DESC;
","
WITH scores AS (
  SELECT
    col0,
    CAST(SUBSTR(col1, 1, INSTR(col1, ' (') - 1) AS NUMERIC) AS preliminary_score,
    CAST(SUBSTR(col2, 1, INSTR(col2, ' (') - 1) AS NUMERIC) AS interview_score,
    CAST(SUBSTR(col3, 1, INSTR(col3, ' (') - 1) AS NUMERIC) AS swimsuit_score,
    CAST(SUBSTR(col4, 1, INSTR(col4, ' (') - 1) AS NUMERIC) AS eveninggown_score,
    CAST(SUBSTR(col5, 1, INSTR(col5, ' (') - 1) AS NUMERIC) AS semifinal_score
  FROM `table_m_1764883620089_c9461837_16268026_3`
),
maxes AS (
  SELECT
    MAX(preliminary_score) AS max_prelim,
    MAX(interview_score) AS max_interview,
    MAX(swimsuit_score) AS max_swimsuit,
    MAX(eveninggown_score) AS max_evening,
    MAX(semifinal_score) AS max_semifinal
  FROM scores
)
SELECT
  s.col0,
  ROUND(s.preliminary_score, 3) AS `Preliminary Score`,
  ROUND(s.interview_score, 3) AS `Interview Score`,
  ROUND(s.swimsuit_score, 3) AS `Swimsuit Score`,
  ROUND(s.eveninggown_score, 3) AS `Evening Gown Score`,
  ROUND(s.semifinal_score, 3) AS `Semifinal Score`,
  ROUND(s.semifinal_score - s.preliminary_score, 3) AS `Improvement (Semifinal - Preliminary)`,
  ROUND(ABS(s.interview_score - s.swimsuit_score), 3) AS `Interview vs Swimsuit Diff`,
  (
    CASE WHEN s.preliminary_score = m.max_prelim THEN 'Preliminary' ELSE '' END ||
    CASE WHEN s.interview_score = m.max_interview THEN (CASE WHEN s.preliminary_score = m.max_prelim THEN ', Interview' ELSE 'Interview' END) ELSE '' END ||
    CASE WHEN s.swimsuit_score = m.max_swimsuit THEN (CASE WHEN (s.preliminary_score = m.max_prelim OR s.interview_score = m.max_interview) THEN ', Swimsuit' ELSE 'Swimsuit' END) ELSE '' END ||
    CASE WHEN s.eveninggown_score = m.max_evening THEN (CASE WHEN (s.preliminary_score = m.max_prelim OR s.interview_score = m.max_interview OR s.swimsuit_score = m.max_swimsuit) THEN ', Evening Gown' ELSE 'Evening Gown' END) ELSE '' END ||
    CASE WHEN s.semifinal_score = m.max_semifinal THEN (CASE WHEN (s.preliminary_score = m.max_prelim OR s.interview_score = m.max_interview OR s.swimsuit_score = m.max_swimsuit OR s.eveninggown_score = m.max_evening) THEN ', Semifinal' ELSE 'Semifinal' END) ELSE '' END
  ) AS `Category Leader Flags`,
  RANK() OVER (ORDER BY s.semifinal_score DESC) AS `Semifinal Rank`,
  CASE
    WHEN (s.semifinal_score - s.preliminary_score) >= 0.200 OR ABS(s.interview_score - s.swimsuit_score) >= 0.600 THEN 'High'
    WHEN (s.semifinal_score - s.preliminary_score) >= 0.100 OR ABS(s.interview_score - s.swimsuit_score) >= 0.350 THEN 'Medium'
    ELSE 'Low'
  END AS `Coaching Priority`
FROM scores s
CROSS JOIN maxes m
ORDER BY `Improvement (Semifinal - Preliminary)` DESC, `Semifinal Score` DESC;
","[('Texas', 9.084, 9.425, 9.535, 9.601, 9.52, 0.436, 0.11, 'Preliminary, Interview, Swimsuit, Evening Gown, Semifinal', 1, 'High'), ('New Jersey', 8.51, 8.626, 8.712, 9.165, 8.834, 0.324, 0.086, '', 3, 'High'), ('Oklahoma', 8.662, 8.88, 8.762, 9.214, 8.952, 0.29, 0.118, '', 2, 'High'), ('Colorado', 8.388, 8.638, 8.432, 8.786, 8.618, 0.23, 0.206, '', 6, 'High'), ('California', 8.659, 8.313, 8.977, 8.774, 8.688, 0.029, 0.664, '', 5, 'High'), ('Pennsylvania', 8.58, 8.534, 8.467, 8.613, 8.538, -0.042, 0.067, '', 7, 'Low'), ('Arizona', 8.529, 7.792, 8.833, 8.703, 8.442, -0.087, 1.041, '', 8, 'High'), ('Louisiana', 8.829, 8.6, 8.82, 8.71, 8.71, -0.119, 0.22, '', 4, 'Low'), ('Illinois', 8.501, 7.988, 8.432, 8.681, 8.367, -0.134, 0.444, '', 9, 'Medium')]",m_1764883620089_c9461837_16268026-3,"I routinely screen for big interview vs swimsuit discrepancies to prioritize coaching areas and I speak plainly about gaps. The SQL computes the absolute interview–swimsuit difference and combines that with improvement to assign a coaching-priority label. It uses the parsed interview and swimsuit scores plus improvement and priority per State. Draft: Show states with their interview and swimsuit scores, the absolute difference, the improvement from prelim to semifinal, semifinal rank, and coaching-priority so I can spot inconsistencies. Those exact fields are returned by the query and used to set priorities.",persona,"Pageant coach and performance analyst who trains contestants and reviews historical scoring to identify strengths, weaknesses, and scoring trends; uses this database to tailor training focus and benchmark competitors. Focuses on numeric score patterns across categories to inform coaching decisions and prep priorities. Goals: Identify which states (contestants) scored highest overall and in specific categories to set performance benchmarks. Find contestants who showed the biggest improvement from preliminary rounds to the semifinals to study effective preparation or on-stage adaptations. Detect category-specific inconsistencies (e.g., big gaps between interview and swimsuit scores) to prioritize coaching areas for a contestant. Example Queries: WITH scores AS (
  SELECT State,
    CAST(SUBSTR(""Preliminary Average"", 1, INSTR(""Preliminary Average"", ' (') - 1) AS NUMERIC) AS preliminary_score,
    CAST(SUBSTR(""Interview"", 1, INSTR(""Interview"", ' (') - 1) AS NUMERIC) AS interview_score,
    CAST(SUBSTR(""Swimsuit"", 1, INSTR(""Swimsuit"", ' (') - 1) AS NUMERIC) AS swimsuit_score,
    CAST(SUBSTR(""Evening Gown"", 1, INSTR(""Evening Gown"", ' (') - 1) AS NUMERIC) AS eveninggown_score,
    CAST(SUBSTR(""Semifinal Average"", 1, INSTR(""Semifinal Average"", ' (') - 1) AS NUMERIC) AS semifinal_score
  FROM table_1_16268026_3
)
SELECT State, preliminary_score, interview_score, swimsuit_score, eveninggown_score, semifinal_score
FROM scores
ORDER BY semifinal_score DESC
LIMIT 3; WITH scores AS (
  SELECT State,
    CAST(SUBSTR(""Preliminary Average"", 1, INSTR(""Preliminary Average"", ' (') - 1) AS NUMERIC) AS preliminary_score,
    CAST(SUBSTR(""Semifinal Average"", 1, INSTR(""Semifinal Average"", ' (') - 1) AS NUMERIC) AS semifinal_score
  FROM table_1_16268026_3
)
SELECT State, preliminary_score, semifinal_score, (semifinal_score - preliminary_score) AS improvement
FROM scores
WHERE preliminary_score IS NOT NULL AND semifinal_score IS NOT NULL
ORDER BY improvement DESC; WITH scores AS (
  SELECT State,
    CAST(SUBSTR(""Interview"", 1, INSTR(""Interview"", ' (') - 1) AS NUMERIC) AS interview_score,
    CAST(SUBSTR(""Swimsuit"", 1, INSTR(""Swimsuit"", ' (') - 1) AS NUMERIC) AS swimsuit_score
  FROM table_1_16268026_3
)
SELECT State, interview_score, swimsuit_score, ROUND(ABS(interview_score - swimsuit_score), 3) AS diff
FROM scores
ORDER BY diff DESC
LIMIT 5;",N/A,rename_column,
"Which distinct provinces, showing Province, U.N. Region, Population, Area (km²), the province's density ((Population*1.0)/Area (km²)), and the region's avg_density (AVG((Population*1.0)/Area (km²)) with region total_pop = SUM(Population)), result from joining provinces to regional_stats by U.N. Region where Area (km²) > 0 and (Population*1.0)/Area (km²) >= avg_density, ordered by U.N. Region and limited to 20 rows?",unanswerable,unanswerable,,m_1764883629716_30c1538a_16278349-1,"1) Intent: compute average population density per U.N. Region (avg_density) and total population, then return provinces whose individual density >= their region's avg_density along with relevant fields. 2) Map semantics to table columns and expressions exactly as in SQL. 3) Draft a question asking for Province, U.N. Region, Population, Area (km²), density = (Population*1.0)/Area (km²), and avg_density = AVG((Population*1.0)/Area (km²)) with total_pop = SUM(Population), joined by U.N. Region, filtered by Area (km²) > 0 and density >= avg_density, ordered by U.N. Region, limited to 20. 4) Validate inclusion of DISTINCT, join, filter, order and limit.",reserved,16,N/A,merge_column,
"For counties where Towns/ villages is at least 100 and Area (km²) is under 5000, return Name of county, County seat, Area (km²), Population, Population density, Towns/ villages, Area per town (Area (km²) / Towns/ villages), Population per town (Population / Towns/ villages), Density delta (Population density - (Population / Area (km²))), and Computed/Reported ratio ((Population / Area (km²)) / Population density), sorted by Population per town descending and limited to 5 entries?","
SELECT `county_name`, `county_seat`, `Area (km²)`, `Population`, `population_density`, `Towns/ villages`, (`Area (km²)` / `Towns/ villages`) AS `Area per town`, (`Population` / `Towns/ villages`) `Population per town`, ((`population_density`) - (`Population` / `Area (km²)`)) `Density delta`, ((`Population` / `Area (km²)`) / NULLIF(`population_density`,0)) `Computed/Reported ratio` FROM `table_m_1764883637982_007e8531_16278825_1` WHERE `Towns/ villages` >= 100 AND `Area (km²)` < 5000 ORDER BY -(`Population` / `Towns/ villages`) LIMIT 5;
","
SELECT col0, col1, col2, col3, col4, col5, (col2 / col5) AS `Area per town`, (col3 / col5) `Population per town`, ((col4) - (col3 / col2)) `Density delta`, ((col3 / col2) / NULLIF(col4,0)) `Computed/Reported ratio` FROM `table_m_1764883637982_007e8531_16278825_1` WHERE col5 >= 100 AND col2 < 5000 ORDER BY -(col3 / col5) LIMIT 5;
","[('Fejér', 'Székesfehérvár', 4359.0, 428579.0, 98.0, 108.0, 40.361111111111114, 3968.324074074074, -0.32048635008028725, 1.0032702688783703), ('Heves', 'Eger', 3637.0, 323769.0, 89.0, 119.0, 30.563025210084035, 2720.747899159664, -0.020896343139952478, 1.000234790372359), ('Győr-Moson-Sopron', 'Győr', 4208.0, 440138.0, 105.0, 182.0, 23.12087912087912, 2418.3406593406594, 0.4044676806083629, 0.9961479268513489), ('Tolna', 'Szekszárd', 3703.0, 247287.0, 67.0, 108.0, 34.28703703703704, 2289.6944444444443, 0.21982176613556703, 0.9967190781173796), ('Veszprém', 'Veszprém', 4493.0, 368519.0, 82.0, 217.0, 20.705069124423964, 1698.2442396313363, -0.020698864900950298, 1.0002524251817189)]",m_1764883637982_007e8531_16278825-1,"Parse: selection includes base columns plus four computed fields, filtered by Towns/ villages and Area, sorted by decreasing Population per town, limited to five. Map: computations derived from Area (km²), Population, Population density, and Towns/ villages columns. Draft: ask to return those columns and computations for counties matching the filters, top 5 by Population per town. Validate: question contains all requested fields, calculations, filter conditions, ordering direction, and limit.",reserved,8,N/A,rename_column,
"For each Series (grouped by Series) and considering only records where Release is not an empty string and Title is not an empty string, report the Series, the number of Titles as Total Titles (COUNT(Title)), the number of Writers as Total Writers (COUNT(Writer)), the count of rows with Length = '70\'' as Count 70' (SUM(Length = '70\'')), the count of rows with Length = '60\'' as Count 60' (SUM(Length = '60\'')), the earliest Release Date (MIN(Release Date) AS Earliest Release) and the latest Release Date (MAX(Release Date) AS Latest Release), include only Series with more than one Title (HAVING COUNT(Title) > 1), order by Total Titles and return up to 10 rows?",unanswerable,unanswerable,,m_1764883649680_dc39f140_16279520-1,"Parse SQL intent: group by Series and compute title and writer counts, counts of Length equal to '70\'' and '60\'', and earliest/latest release dates; exclude empty Release or Title rows, require more than one title per series, order by total titles and cap results at ten. Map schema semantics: map Title, Writer, Length, Release Date to their respective aggregates. Draft question: enumerate each requested aggregate and all query conditions. Validate: confirm inclusion of conditional length counts, min/max dates, non-empty filters, HAVING, ORDER BY and LIMIT clauses.",reserved,10,N/A,merge_column,
"Which five years (where year = '20' concatenated with the last two characters of Dates (MDY) and year >= 2008) have the highest total Gross sales, and for each of those years what are: the total Gross sales (sum after stripping '$' and commas), the average Sellout (%) (average after stripping '%'), the total Tickets sold (sum of the portion before '/' with commas removed), the total Tickets available (sum of the portion after '/' with commas removed), and the average gross per show (total gross sales divided by number of rows)?","
SELECT '20' || SUBSTR(`Dates (MDY)`, -2),
 SUM(REPLACE(REPLACE(`Gross sales`,'$',''),',','')),
 AVG(REPLACE(`Sellout (%)`,'%','')),
 SUM(TRIM(REPLACE(SUBSTR(`Tickets sold / available`,1,INSTR(`Tickets sold / available`,'/')-1),',',''))),
 SUM(TRIM(REPLACE(SUBSTR(`Tickets sold / available`,INSTR(`Tickets sold / available`,'/')+1),',',''))),
 SUM(REPLACE(REPLACE(`Gross sales`,'$',''),',',''))/COUNT(*)
FROM `table_m_1764883673659_cd21166f_16331025_2`
WHERE '20' || SUBSTR(`Dates (MDY)`, -2) >= '2008'
GROUP BY '20' || SUBSTR(`Dates (MDY)`, -2)
ORDER BY SUM(REPLACE(REPLACE(`Gross sales`,'$',''),',','')) DESC
LIMIT 5;
","
SELECT '20' || SUBSTR(col0, -2),
 SUM(REPLACE(REPLACE(col2,'$',''),',','')),
 AVG(REPLACE(col4,'%','')),
 SUM(TRIM(REPLACE(SUBSTR(col3,1,INSTR(col3,'/')-1),',',''))),
 SUM(TRIM(REPLACE(SUBSTR(col3,INSTR(col3,'/')+1),',',''))),
 SUM(REPLACE(REPLACE(col2,'$',''),',',''))/COUNT(*)
FROM `table_m_1764883673659_cd21166f_16331025_2`
WHERE '20' || SUBSTR(col0, -2) >= '2008'
GROUP BY '20' || SUBSTR(col0, -2)
ORDER BY SUM(REPLACE(REPLACE(col2,'$',''),',','')) DESC
LIMIT 5;
","[('2010', 32606485, 83.38461538461539, 259879, 307197, 2508191), ('2009', 28624073, 87.81818181818181, 197720, 224360, 2602188), ('2008', 26811086, 99.08333333333333, 176888, 178305, 2234257), ('2011', 9379654, 95.0, 63278, 66694, 4689827)]",m_1764883673659_cd21166f_16331025-2,"1) The SQL aggregates by a year derived from Dates (MDY), computes SUM of cleaned Gross sales, AVG of cleaned Sellout (%), SUMs of the split Tickets sold and Tickets available, and average gross per entry, filtering to years >= 2008 and returning the 5 years with largest total gross. 2) Map columns: Dates (MDY) -> year via '20' + last two chars; Gross sales needs $/comma removal; Sellout (%) needs '%' removal; Tickets sold / available must be split on '/' and commas removed. 3) Draft a question requesting those exact metrics per derived year with the stated filter, grouping, ordering, and limit. 4) Confirm all calculations and filters from the query are explicitly mentioned.",reserved,8,N/A,add_column,
Which teams had a higher overall winning percentage than their ACC winning percentage and were stronger at home?,"
SELECT DISTINCT `Team`, `ACC %`, `All Games %`, (`All Games %` - `ACC %`) AS `Conf_vs_All_Diff`, CASE WHEN (`All Home` > `All Road`) THEN '`Stronger at Home`' END FROM `table_m_1764883684349_de5c614e_16372244_1` WHERE `All Games %` <> '' LIMIT 8;
","
SELECT DISTINCT col0, col2, col6, (col6 - col2) AS `Conf_vs_All_Diff`, CASE WHEN (col7 > col8) THEN '`Stronger at Home`' END FROM `table_m_1764883684349_de5c614e_16372244_1` WHERE col6 <> '' LIMIT 8;
","[('Maryland', '.938', '.889', -0.04899999999999993, None), ('Duke', '.813', '.886', 0.07300000000000006, None), ('Wake Forest', '.563', '.618', 0.05500000000000005, None), ('North Carolina State', '.563', '.676', 0.1130000000000001, None), ('Virginia', '.563', '.586', 0.02300000000000002, None), ('Georgia Tech', '.437', '.484', 0.046999999999999986, '`Stronger at Home`'), ('North Carolina', '.250', '.286', 0.035999999999999976, '`Stronger at Home`'), ('Florida State', '.250', '.414', 0.16399999999999998, None)]",m_1764883684349_de5c614e_16372244-1,"STEP 1: Parse the SQL intent — the query selects Team, ACC %, All Games %, computes (All Games % - ACC %) as Conf_vs_All_Diff, and adds the literal 'Stronger at Home' when All Home > All Road; it filters out rows with empty All Games % and returns up to 8 distinct rows. STEP 2: Choose an ambiguity type — scope ambiguity fits well because the query both computes the conference-vs-all difference and conditionally labels teams as 'Stronger at Home', so a natural language phrasing that uses 'and' can be read either as (a) a conjunction filter (teams satisfying both conditions) or (b) a request to report both pieces of information for teams. The LIMIT 8 / lack of ordering also introduces a secondary ambiguity about which subset is returned. STEP 3: Draft the question — see question field below. STEP 4: Explain the ambiguity — in the original query the 'and' is interpreted as computing and showing both values for each team (difference and a home-strength label) without filtering by home strength; an alternative interpretation of the same wording would be to filter to only those teams that both improved overall vs ACC and were stronger at home, or to return the single best-improving team rather than a (limited) set.",reserved,10,N/A,add_column,"type: Scope ambiguity | explanation: The phrase 'and were stronger at home' can be read two ways: (1) as a request to show both pieces of information for each team (the SQL's interpretation: compute the difference and label teams that meet All Home > All Road), or (2) as a filter requiring teams to satisfy both conditions (only include teams with All Games % > ACC % AND All Home > All Road). Additionally, because the query has no ORDER BY and uses LIMIT 8, it's also ambiguous which subset of teams is returned."
"Which teams played at least three neutral games and earned 'Exceptional Neutral' (≥.75) or 'Solid Neutral' (≥.50) status — list their neutral games, neutral win %, overall %, anomaly tag and designer composite score?","
WITH parsed AS (
  SELECT
    `Team`,
    CAST(substr(`ACC Regular Season`, 1, instr(`ACC Regular Season`, '–') - 1) AS INTEGER) AS acc_wins,
    CAST(substr(`ACC Regular Season`, instr(`ACC Regular Season`, '–') + 1) AS INTEGER) AS acc_losses,
    CAST(substr(`All Games by Location (Home–Road–Neutral)`, 1, instr(`All Games by Location (Home–Road–Neutral)`, '–') - 1) AS INTEGER) AS home_wins,
    CAST(substr(`All Games by Location (Home–Road–Neutral)`, instr(`All Games by Location (Home–Road–Neutral)`, '–') + 1) AS INTEGER) AS home_losses,
    CAST(substr(`All Games by Location (Home–Road–Neutral)`, 1, instr(`All Games by Location (Home–Road–Neutral)`, '–') - 1) AS INTEGER) AS road_wins,
    CAST(substr(`All Games by Location (Home–Road–Neutral)`, instr(`All Games by Location (Home–Road–Neutral)`, '–') + 1) AS INTEGER) AS road_losses,
    CAST(substr(`All Games by Location (Home–Road–Neutral)`, 1, instr(`All Games by Location (Home–Road–Neutral)`, '–') - 1) AS INTEGER) AS neutral_wins,
    CAST(substr(`All Games by Location (Home–Road–Neutral)`, instr(`All Games by Location (Home–Road–Neutral)`, '–') + 1) AS INTEGER) AS neutral_losses,
    CAST(`All Games %` AS REAL) AS overall_pct
  FROM `table_m_1764883694397_32f48a7a_16372911_1`
),
metrics AS (
  SELECT
    `Team`,
    acc_wins, acc_losses,
    home_wins, home_losses,
    road_wins, road_losses,
    neutral_wins, neutral_losses,
    overall_pct,
    (home_wins + home_losses) AS home_games,
    (road_wins + road_losses) AS road_games,
    (neutral_wins + neutral_losses) AS neutral_games,
    CASE WHEN (home_wins + home_losses) > 0 THEN home_wins * 1.0 / (home_wins + home_losses) ELSE NULL END AS home_win_pct,
    CASE WHEN (road_wins + road_losses) > 0 THEN road_wins * 1.0 / (road_wins + road_losses) ELSE NULL END AS road_win_pct,
    CASE WHEN (neutral_wins + neutral_losses) > 0 THEN neutral_wins * 1.0 / (neutral_wins + neutral_losses) ELSE NULL END AS neutral_win_pct,
    CASE WHEN (acc_wins + acc_losses) > 0 THEN acc_wins * 1.0 / (acc_wins + acc_losses) ELSE NULL END AS acc_win_pct
  FROM parsed
)
SELECT
  `Team`,
  -- original recorded strings reconstructed for clarity
  (acc_wins || '–' || acc_losses) AS `ACC Regular Season`,
  (home_wins || '–' || home_losses) AS `All Games by Location (Home–Road–Neutral)`,
  (road_wins || '–' || road_losses) AS `All Games by Location (Home–Road–Neutral)`,
  (neutral_wins || '–' || neutral_losses) AS `All Games by Location (Home–Road–Neutral)`,
  printf('%.3f', overall_pct) AS `All Games %`,
  -- core parsed metrics
  home_wins AS `Home Wins`, home_losses AS `Home Losses`, home_games AS `Home Games`,
  road_wins AS `Road Wins`, road_losses AS `Road Losses`, road_games AS `Road Games`,
  neutral_wins AS `Neutral Wins`, neutral_losses AS `Neutral Losses`, neutral_games AS `Neutral Games`,
  printf('%.3f', home_win_pct) AS `Home Win %`,
  printf('%.3f', road_win_pct) AS `Road Win %`,
  printf('%.3f', neutral_win_pct) AS `Neutral Win %`,
  printf('%.3f', acc_win_pct) AS `ACC Win %`,
  -- actionable designer metrics
  printf('%.3f', (road_win_pct - home_win_pct)) AS `Travel Bias (road - home)`,
  printf('%.3f', (neutral_win_pct - overall_pct)) AS `Neutral vs Overall`,
  printf('%.3f', (overall_pct - acc_win_pct)) AS `Overall vs ACC`,
  -- anomaly tags to seed special cards (multiple flags concatenated)
  TRIM(
    CASE WHEN road_wins > home_wins THEN 'Road Warrior' ELSE '' END ||
    CASE WHEN home_wins >= road_wins + 3 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Home Fortress' ELSE 'Home Fortress' END) ELSE '' END ||
    CASE WHEN neutral_games >= 3 AND neutral_win_pct >= 0.75 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Exceptional Neutral' ELSE 'Exceptional Neutral' END) WHEN neutral_games >= 3 AND neutral_win_pct >= 0.50 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Solid Neutral' ELSE 'Solid Neutral' END) ELSE '' END ||
    CASE WHEN ABS(overall_pct - acc_win_pct) >= 0.20 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Out‑of‑Conference Divergence' ELSE 'Out‑of‑Conference Divergence' END) ELSE '' END
  ) AS `Anomaly Flags`,
  -- composite balance score to rank teams for scenario seeding (higher = more designer-interesting)
  printf('%.3f',
    (
      -- weight neutral overperformance (encourage neutral-event cards)
      2.0 * (COALESCE(neutral_win_pct,0) - overall_pct)
      -- weight travel bias (road vs home)
      + 3.0 * (COALESCE(road_win_pct,0) - COALESCE(home_win_pct,0))
      -- reward high absolute overall performance
      + 1.5 * overall_pct
      -- reward large overall vs ACC divergence (interesting asymmetry)
      + 2.0 * ABS(overall_pct - COALESCE(acc_win_pct,0))
    )
  ) AS `Designer Composite Score`
FROM metrics
ORDER BY `Designer Composite Score` DESC, `Neutral Win %` DESC, `Travel Bias (road - home)` DESC
;
","
WITH parsed AS (
  SELECT
    col0,
    CAST(substr(col1, 1, instr(col1, '–') - 1) AS INTEGER) AS acc_wins,
    CAST(substr(col1, instr(col1, '–') + 1) AS INTEGER) AS acc_losses,
    CAST(substr(col7, 1, instr(col7, '–') - 1) AS INTEGER) AS home_wins,
    CAST(substr(col7, instr(col7, '–') + 1) AS INTEGER) AS home_losses,
    CAST(substr(col7, 1, instr(col7, '–') - 1) AS INTEGER) AS road_wins,
    CAST(substr(col7, instr(col7, '–') + 1) AS INTEGER) AS road_losses,
    CAST(substr(col7, 1, instr(col7, '–') - 1) AS INTEGER) AS neutral_wins,
    CAST(substr(col7, instr(col7, '–') + 1) AS INTEGER) AS neutral_losses,
    CAST(col6 AS REAL) AS overall_pct
  FROM `table_m_1764883694397_32f48a7a_16372911_1`
),
metrics AS (
  SELECT
    col0,
    acc_wins, acc_losses,
    home_wins, home_losses,
    road_wins, road_losses,
    neutral_wins, neutral_losses,
    overall_pct,
    (home_wins + home_losses) AS home_games,
    (road_wins + road_losses) AS road_games,
    (neutral_wins + neutral_losses) AS neutral_games,
    CASE WHEN (home_wins + home_losses) > 0 THEN home_wins * 1.0 / (home_wins + home_losses) ELSE NULL END AS home_win_pct,
    CASE WHEN (road_wins + road_losses) > 0 THEN road_wins * 1.0 / (road_wins + road_losses) ELSE NULL END AS road_win_pct,
    CASE WHEN (neutral_wins + neutral_losses) > 0 THEN neutral_wins * 1.0 / (neutral_wins + neutral_losses) ELSE NULL END AS neutral_win_pct,
    CASE WHEN (acc_wins + acc_losses) > 0 THEN acc_wins * 1.0 / (acc_wins + acc_losses) ELSE NULL END AS acc_win_pct
  FROM parsed
)
SELECT
  col0,
  -- original recorded strings reconstructed for clarity
  (acc_wins || '–' || acc_losses) AS col1,
  (home_wins || '–' || home_losses) AS col7,
  (road_wins || '–' || road_losses) AS col7,
  (neutral_wins || '–' || neutral_losses) AS col7,
  printf('%.3f', overall_pct) AS col6,
  -- core parsed metrics
  home_wins AS `Home Wins`, home_losses AS `Home Losses`, home_games AS `Home Games`,
  road_wins AS `Road Wins`, road_losses AS `Road Losses`, road_games AS `Road Games`,
  neutral_wins AS `Neutral Wins`, neutral_losses AS `Neutral Losses`, neutral_games AS `Neutral Games`,
  printf('%.3f', home_win_pct) AS `Home Win %`,
  printf('%.3f', road_win_pct) AS `Road Win %`,
  printf('%.3f', neutral_win_pct) AS `Neutral Win %`,
  printf('%.3f', acc_win_pct) AS `ACC Win %`,
  -- actionable designer metrics
  printf('%.3f', (road_win_pct - home_win_pct)) AS `Travel Bias (road - home)`,
  printf('%.3f', (neutral_win_pct - overall_pct)) AS `Neutral vs Overall`,
  printf('%.3f', (overall_pct - acc_win_pct)) AS `Overall vs ACC`,
  -- anomaly tags to seed special cards (multiple flags concatenated)
  TRIM(
    CASE WHEN road_wins > home_wins THEN 'Road Warrior' ELSE '' END ||
    CASE WHEN home_wins >= road_wins + 3 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Home Fortress' ELSE 'Home Fortress' END) ELSE '' END ||
    CASE WHEN neutral_games >= 3 AND neutral_win_pct >= 0.75 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Exceptional Neutral' ELSE 'Exceptional Neutral' END) WHEN neutral_games >= 3 AND neutral_win_pct >= 0.50 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Solid Neutral' ELSE 'Solid Neutral' END) ELSE '' END ||
    CASE WHEN ABS(overall_pct - acc_win_pct) >= 0.20 THEN (CASE WHEN length(TRIM(COALESCE((CASE WHEN road_wins > home_wins THEN ' ' END), '')))>0 THEN ', Out‑of‑Conference Divergence' ELSE 'Out‑of‑Conference Divergence' END) ELSE '' END
  ) AS `Anomaly Flags`,
  -- composite balance score to rank teams for scenario seeding (higher = more designer-interesting)
  printf('%.3f',
    (
      -- weight neutral overperformance (encourage neutral-event cards)
      2.0 * (COALESCE(neutral_win_pct,0) - overall_pct)
      -- weight travel bias (road vs home)
      + 3.0 * (COALESCE(road_win_pct,0) - COALESCE(home_win_pct,0))
      -- reward high absolute overall performance
      + 1.5 * overall_pct
      -- reward large overall vs ACC divergence (interesting asymmetry)
      + 2.0 * ABS(overall_pct - COALESCE(acc_win_pct,0))
    )
  ) AS `Designer Composite Score`
FROM metrics
ORDER BY `Designer Composite Score` DESC, `Neutral Win %` DESC, `Travel Bias (road - home)` DESC
;
","[('Miami', '8–8', '14–2', '14–2', '14–2', '0.676', 14, 2, 16, 14, 2, 16, 14, 2, 16, '0.875', '0.875', '0.875', '0.500', '0.000', '0.199', '0.176', 'Exceptional Neutral', '1.764'), ('Wake Forest', '7–9', '15–2', '15–2', '15–2', '0.567', 15, 2, 17, 15, 2, 17, 15, 2, 17, '0.882', '0.882', '0.882', '0.438', '0.000', '0.315', '0.129', 'Exceptional Neutral', '1.740'), ('Clemson', '10–6', '14–2', '14–2', '14–2', '0.706', 14, 2, 16, 14, 2, 16, 14, 2, 16, '0.875', '0.875', '0.875', '0.625', '0.000', '0.169', '0.081', 'Exceptional Neutral', '1.559'), ('Duke', '13–3', '15–1', '15–1', '15–1', '0.824', 15, 1, 16, 15, 1, 16, 15, 1, 16, '0.938', '0.938', '0.938', '0.813', '0.000', '0.114', '0.011', 'Exceptional Neutral', '1.486'), ('Virginia', '5–11', '13–7', '13–7', '13–7', '0.515', 13, 7, 20, 13, 7, 20, 13, 7, 20, '0.650', '0.650', '0.650', '0.313', '0.000', '0.135', '0.203', 'Solid NeutralOut‑of‑Conference Divergence', '1.448'), ('Virginia Tech', '9–7', '14–3', '14–3', '14–3', '0.600', 14, 3, 17, 14, 3, 17, 14, 3, 17, '0.824', '0.824', '0.824', '0.563', '0.000', '0.224', '0.037', 'Exceptional Neutral', '1.422'), ('North Carolina', '14–2', '14–2', '14–2', '14–2', '0.946', 14, 2, 16, 14, 2, 16, 14, 2, 16, '0.875', '0.875', '0.875', '0.875', '0.000', '-0.071', '0.071', 'Exceptional Neutral', '1.419'), ('Florida State', '7–9', '13–5', '13–5', '13–5', '0.559', 13, 5, 18, 13, 5, 18, 13, 5, 18, '0.722', '0.722', '0.722', '0.438', '0.000', '0.163', '0.122', 'Solid Neutral', '1.408'), ('Boston College', '4–12', '11–8', '11–8', '11–8', '0.452', 11, 8, 19, 11, 8, 19, 11, 8, 19, '0.579', '0.579', '0.579', '0.250', '0.000', '0.127', '0.202', 'Solid NeutralOut‑of‑Conference Divergence', '1.336'), ('Maryland', '8–8', '13–6', '13–6', '13–6', '0.559', 13, 6, 19, 13, 6, 19, 13, 6, 19, '0.684', '0.684', '0.684', '0.500', '0.000', '0.125', '0.059', 'Solid Neutral', '1.207'), ('Georgia Tech', '7–9', '6–7', '6–7', '6–7', '0.469', 6, 7, 13, 6, 7, 13, 6, 7, 13, '0.462', '0.462', '0.462', '0.438', '0.000', '-0.007', '0.031', '', '0.752')]",m_1764883694397_32f48a7a_16372911-1,"I love neutral‑site quirks for tournament cards, so I'll ask for teams that stand out on neutral courts in plain terms. The SQL computes neutral win % and flags teams with at least 3 neutral games as Exceptional Neutral (≥.75) or Solid Neutral (≥.50). The table has an 'All Neutral' win–loss field that the query parses into neutral wins, losses and neutral_games. Draft question: ask which teams meet those neutral‑site thresholds and request their neutral games, neutral % and composite score. Validate: the query will return teams with those neutral flags and the requested metrics.",persona,"An indie board‑game designer crafting a 2007–08 ACC retro strategy game who needs precise home/road/neutral strengths and quirky anomalies to balance playable teams. Goals: Translate real 2007–08 ACC season performance into balanced in‑game ratings for home/road/neutral match outcomes and special event cards. Identify unusual team profiles (e.g., teams stronger on the road, exceptional neutral‑site records, or big disparities between conference and overall performance) to inspire asymmetric mechanics. Create a ranked, data‑driven playbook (top neutral performers, travel‑tough teams, conference specialists) to seed scenario cards and handicaps in the game. Example Queries: /* 1) Find teams with more road wins than home wins (useful for 'road warrior' abilities) */
SELECT ""Team"",
       split_part(""All Road"", '–', 1)::int AS road_wins,
       split_part(""All Home"", '–', 1)::int AS home_wins
FROM table_1_16372911_1
WHERE split_part(""All Road"", '–', 1)::int > split_part(""All Home"", '–', 1)::int
ORDER BY (road_wins - home_wins) DESC; /* 2) Top neutral‑site performers (neutral win % = neutral_wins / neutral_games) for special neutral‑site event cards */
SELECT ""Team"",
       ""All Neutral"",
       (split_part(""All Neutral"", '–', 1)::float / (split_part(""All Neutral"", '–', 1)::float + split_part(""All Neutral"", '–', 2)::float)) AS neutral_win_pct
FROM table_1_16372911_1
WHERE ""All Neutral"" IS NOT NULL AND ""All Neutral"" <> ''
ORDER BY neutral_win_pct DESC
LIMIT 3; /* 3) Highlight teams with largest discrepancy between overall %% and conference record (to design 'out‑of‑conference specialist' or 'conference struggler' traits) */
SELECT ""Team"",
       CAST(""All Games %"" AS float) AS overall_pct,
       (split_part(""ACC Regular Season"", '–', 1)::float / (split_part(""ACC Regular Season"", '–', 1)::float + split_part(""ACC Regular Season"", '–', 2)::float)) AS acc_pct_from_record,
       ABS(CAST(""All Games %"" AS float) - (split_part(""ACC Regular Season"", '–', 1)::float / (split_part(""ACC Regular Season"", '–', 1)::float + split_part(""ACC Regular Season"", '–', 2)::float))) AS pct_difference
FROM table_1_16372911_1
ORDER BY pct_difference DESC
LIMIT 5;",N/A,merge_column,
"List the directors ('Directed by') who directed at least 3 episodes and, for each, give the director (Director), the number of episodes directed (Episodes), the comma-separated list of distinct 'Written by' names (Writers), and the production code range computed as MAX('Production Code') - MIN('Production Code') (CodeRange), ordered by Episodes descending and limited to 10 results?","
WITH `directors` AS (
 SELECT `director`, COUNT(*) `EpisodeCount`
 FROM `table_m_1764883712885_6577f710_16384596_4`
 GROUP BY `director`
 HAVING `EpisodeCount` >= 3
)
SELECT `directors`.`director` `Director`, `EpisodeCount` `Episodes`, GROUP_CONCAT(DISTINCT `writer`) `Writers`, MAX(`Production Code`) - MIN(`Production Code`) `CodeRange`
FROM `directors`
JOIN `table_m_1764883712885_6577f710_16384596_4` USING (`director`)
GROUP BY `directors`.`director`
ORDER BY `Episodes` DESC
LIMIT 10;
","
WITH `directors` AS (
 SELECT col3, COUNT(*) `EpisodeCount`
 FROM `table_m_1764883712885_6577f710_16384596_4`
 GROUP BY col3
 HAVING `EpisodeCount` >= 3
)
SELECT `directors`.col3 col3, `EpisodeCount` `Episodes`, GROUP_CONCAT(DISTINCT col4) `Writers`, MAX(col6) - MIN(col6) `CodeRange`
FROM `directors`
JOIN `table_m_1764883712885_6577f710_16384596_4` USING (col3)
GROUP BY `directors`.col3
ORDER BY `Episodes` DESC
LIMIT 10;
","[('Filippa Wallström', 5, 'Bror Yngve Andersson,Liselott Svensson,Charlotte Lesche,Åsa Furuhagen', 10.0), ('Marcelo Racana', 3, 'Lotten Strömstedt,Carolina Falck,Bror Yngve Anderson', 2.0), ('Christian Wikander', 3, 'Anna Fredriksson,Åsa Furuhagen,Liselott Svensson', 2.0)]",m_1764883712885_6577f710_16384596-4,"1) The SQL builds a subquery of directors with COUNT>=3 then joins to get writers and production code min/max to compute a range, finally ordering by episode count and limiting to 10. 2) Map to natural terms: Director from 'Directed by', Episodes as the count, Writers as the distinct concatenated 'Written by' values, CodeRange as MAX-MIN of 'Production Code'. 3) Ask for those exact outputs with the >=3 filter, distinct writer concatenation, CodeRange computation, sort by Episodes desc, and limit 10. 4) Verify all columns and calculations from the SQL are mentioned and no extra details are added.",reserved,16,N/A,rename_column,
"For each Ground, considering only games with Crowd > 10000 and only including Grounds with COUNT(*) > 0, what are the Ground, the number of Matches (COUNT(*)), the rounded average crowd (ROUND(AVG(Crowd))) as Avg crowd, the maximum margin (MAX of the absolute difference between the numeric score inside parentheses in Home team score and the numeric score inside parentheses in Away team score) as Max margin, and the number of Close games (SUM of matches where that absolute difference <= 5), ordered by Avg crowd ascending?","
SELECT
`Ground`,
COUNT(*) `Matches`,
ROUND(AVG(`Crowd`)) `Avg crowd`,
MAX(abs(
 (substr(`Home team score`, instr(`Home team score`, '(')+1, instr(`Home team score`, ')') - instr(`Home team score`, '(') -1)+0)
 -
 (substr(`Away team score`, instr(`Away team score`, '(')+1, instr(`Away team score`, ')') - instr(`Away team score`, '(') -1)+0)
)) `Max margin`,
SUM((abs(
 (substr(`Home team score`, instr(`Home team score`, '(')+1, instr(`Home team score`, ')') - instr(`Home team score`, '(') -1)+0)
 -
 (substr(`Away team score`, instr(`Away team score`, '(')+1, instr(`Away team score`, ')') - instr(`Away team score`, '(') -1)+0)
) <= 5)) `Close games`
FROM `table_m_1764883719795_22237ceb_16387953_1`
WHERE `Crowd` > 10000
GROUP BY `Ground`
HAVING COUNT(*) > 0
ORDER BY `Avg crowd` ASC;
","
SELECT
col4,
COUNT(*) `Matches`,
ROUND(AVG(col5)) `Avg crowd`,
MAX(abs(
 (substr(col1, instr(col1, '(')+1, instr(col1, ')') - instr(col1, '(') -1)+0)
 -
 (substr(col3, instr(col3, '(')+1, instr(col3, ')') - instr(col3, '(') -1)+0)
)) `Max margin`,
SUM((abs(
 (substr(col1, instr(col1, '(')+1, instr(col1, ')') - instr(col1, '(') -1)+0)
 -
 (substr(col3, instr(col3, '(')+1, instr(col3, ')') - instr(col3, '(') -1)+0)
) <= 5)) `Close games`
FROM `table_m_1764883719795_22237ceb_16387953_1`
WHERE col5 > 10000
GROUP BY col4
HAVING COUNT(*) > 0
ORDER BY `Avg crowd` ASC;
","[('Waverley Park', 3, 23496.0, 20, 1), ('Football Park', 1, 28776.0, 19, 0)]",m_1764883719795_22237ceb_16387953-1,"1) The query aggregates matches by Ground, filters rows with Crowd > 10000, computes COUNT(*), ROUND(AVG(Crowd)), MAX of the absolute difference between the numeric scores inside parentheses in Home team score and Away team score, and counts games with that absolute margin <= 5; results are ordered by Avg crowd ascending. 2) Map columns: Ground, Crowd, Home team score and Away team score (extract numbers in parentheses) and the derived metrics Matches, Avg crowd, Max margin, Close games. 3) Draft a question that requests those exact metrics per Ground with the stated filter, grouping, having and order. 4) Validate that the question mentions all columns, calculations, the Crowd > 10000 filter, HAVING COUNT(*) > 0 and ordering by Avg crowd ASC.",reserved,8,N/A,add_column,
"Which match returns `Home team`, `Away team`, `Home Points` (the numeric value inside the parentheses of `Home team score`), `Away Points` (the numeric value inside the parentheses of `Away team score`), `Margin` (the absolute difference between those two point values), and `Crowd` where (Margin * Crowd) > 1500000, returning only one result?",unanswerable,unanswerable,,m_1764883730404_27944a04_16388316-1,"1) Parse intent: find a single record where the absolute point margin times attendance exceeds 1500000 and show match details and computed values. 2) Map schema: explicitly extract Home and Away points from score parentheses as `Home Points` and `Away Points`, compute `Margin`, and include `Home team`, `Away team`, and `Crowd`. 3) Draft question: ask for those exact columns and the product condition. 4) Validate: includes extraction method, Margin calculation, product threshold, and requests one row.",reserved,4,N/A,merge_column,
"For up to 5 results, list the literal 'Lexington', the School Year, and Lexington_Appearances computed as SUM(CASE WHEN 1=1 OR 0=1 THEN ((Volleyball LIKE '%Lexington%') + (Cross Country LIKE '%Lexington%') + (Soccer LIKE '%Lexington%') + (Tennis LIKE '%Lexington%') + (Golf LIKE '%Lexington%') + (Basketball LIKE '%Lexington%') + (Swimming LIKE '%Lexington%') + (Softball LIKE '%Lexington%') + (Track & Field LIKE '%Lexington%')) END) for each School Year where (Volleyball || Cross Country || Soccer || Tennis || Golf || Basketball || Swimming || Softball || Track & Field) LIKE '%Lexington%' AND 1=1, grouping by School Year, keeping only groups HAVING Lexington_Appearances > 0, and ordering by Lexington_Appearances?","SELECT 'Lexington' AS `Lexington`, `School Year`, SUM((`Volleyball` LIKE '%Lexington%') + (`Soccer` LIKE '%Lexington%') + (`Tennis` LIKE '%Lexington%') + (`Golf` LIKE '%Lexington%') + (`Basketball` LIKE '%Lexington%') + (`Swimming` LIKE '%Lexington%') + (`Softball` LIKE '%Lexington%') + (`Track & Field` LIKE '%Lexington%')) AS `Lexington_Appearances` FROM `table_m_1764883824473_09344680_16423070_4` WHERE ((`Volleyball` || `Soccer` || `Tennis` || `Golf` || `Basketball` || `Swimming` || `Softball` || `Track & Field`) LIKE '%Lexington%') AND 1=1 GROUP BY `School Year` HAVING `Lexington_Appearances` > 0 ORDER BY `Lexington_Appearances` LIMIT 5;","SELECT 'Lexington' AS `Lexington`, col0, SUM((col1 LIKE '%Lexington%') + (col2 LIKE '%Lexington%') + (col3 LIKE '%Lexington%') + (col4 LIKE '%Lexington%') + (col5 LIKE '%Lexington%') + (col6 LIKE '%Lexington%') + (col7 LIKE '%Lexington%') + (col8 LIKE '%Lexington%')) AS `Lexington_Appearances` FROM `table_m_1764883824473_09344680_16423070_4` WHERE ((col1 || col2 || col3 || col4 || col5 || col6 || col7 || col8) LIKE '%Lexington%') AND 1=1 GROUP BY col0 HAVING `Lexington_Appearances` > 0 ORDER BY `Lexington_Appearances` LIMIT 5;","[('Lexington', '2005-06', 1), ('Lexington', '2007-08', 1), ('Lexington', '2011-12', 1), ('Lexington', '2006-07', 2), ('Lexington', '2008-09', 2)]",m_1764883824473_09344680_16423070-4,"1) Parse intent: identify up to five School Years with nonzero counts of 'Lexington' across all sport columns, reporting the literal 'Lexington', the School Year, and the summed LIKE matches per year. 2) Map schema: the columns included are Volleyball, Cross Country, Soccer, Tennis, Golf, Basketball, Swimming, Softball, and Track & Field. 3) Draft question. 4) Validate that the question references the CASE WHEN 1=1 OR 0=1 wrapper, the summed LIKE('%Lexington%') checks, the concatenated WHERE condition, GROUP BY School Year, HAVING Lexington_Appearances > 0, ORDER BY Lexington_Appearances, and LIMIT 5.",reserved,15,N/A,remove_column,
"Which `Directed by` values have more than one episode (HAVING COUNT(*) > 1) among rows with `No. in season` > 0, and for each such `Directed by` return the `Directed by` name, the number of episodes directed as `Episodes directed` (COUNT(*)), the MIN(`Original air date`) as `First air date`, and the MAX(`Original air date`) as `Last air date`, ordering the output by `Episodes directed` descending?","
SELECT `Directed by`, COUNT(*) `Episodes directed`, MIN(`Original air date`) `First air date`, MAX(`Original air date`) `Last air date`
FROM `table_m_1764883837333_37925b9d_16432167_1`
WHERE `No. in season`>0
GROUP BY `Directed by`
HAVING COUNT(*)>1
ORDER BY `Episodes directed` DESC;
","
SELECT col3, COUNT(*) `Episodes directed`, MIN(col4) `First air date`, MAX(col4) `Last air date`
FROM `table_m_1764883837333_37925b9d_16432167_1`
WHERE col1>0
GROUP BY col3
HAVING COUNT(*)>1
ORDER BY `Episodes directed` DESC;
","[('Norman Tokar', 19, 'April16,1959', 'October9,1958')]",m_1764883837333_37925b9d_16432167-1,"1) Parse intent: aggregate episode counts and date ranges per director, restrict to season numbers > 0, include only directors with more than one episode, and sort by descending episode count. 2) Map schema: `Directed by`, `No. in season`, `Original air date`, COUNT(*) -> `Episodes directed`, MIN/MAX -> `First/Last air date`. 3) Draft: pose a question that requests these exact fields and constraints. 4) Validate: question captures SELECT fields, WHERE, GROUP BY, HAVING, and ORDER BY clauses precisely.",reserved,8,N/A,merge_column,
"List each Gun that has at least one other gun it beats on both m/v ft/s and Max. height (ft); for each such Gun give Better_than_peers (the count of those other guns), Avg_Delta_v (average of this Gun's m/v ft/s minus the others'), Avg_Delta_25 (average of this Gun's Time to ft (m) at 25° (seconds) minus the others'), and Avg_Delta_h (average of this Gun's Max. height (ft) minus the others'), then return only the top 5 Guns by Avg_Delta_v (descending).","
SELECT t.`weapon_type`, COUNT(*) AS `Better_than_peers`, AVG(t.`velocity_ft_per_second` - t2.`velocity_ft_per_second`) `Avg_Delta_v`, AVG((t.`time_to_25_degrees_meters_seconds`+0.0) - (t2.`time_to_25_degrees_meters_seconds`+0.0)) `Avg_Delta_25`, AVG(t.`Max. height (ft)` - t2.`Max. height (ft)`) `Avg_Delta_h`
FROM `table_m_1764883844747_7ffb015f_16439764_1` t
INNER JOIN `table_m_1764883844747_7ffb015f_16439764_1` t2 ON t.`weapon_type` <> t2.`weapon_type`
WHERE (t.`velocity_ft_per_second` > t2.`velocity_ft_per_second`) AND (t.`Max. height (ft)` > t2.`Max. height (ft)`)
GROUP BY t.`weapon_type`
HAVING COUNT(*) > 0
ORDER BY `Avg_Delta_v` DESC
LIMIT 5;
","
SELECT t.col0, COUNT(*) AS `Better_than_peers`, AVG(t.col1 - t2.col1) `Avg_Delta_v`, AVG((t.col3+0.0) - (t2.col3+0.0)) `Avg_Delta_25`, AVG(t.col6 - t2.col6) `Avg_Delta_h`
FROM `table_m_1764883844747_7ffb015f_16439764_1` t
INNER JOIN `table_m_1764883844747_7ffb015f_16439764_1` t2 ON t.col0 <> t2.col0
WHERE (t.col1 > t2.col1) AND (t.col6 > t2.col6)
GROUP BY t.col0
HAVING COUNT(*) > 0
ORDER BY `Avg_Delta_v` DESC
LIMIT 5;
","[('QF 3 inch 20 cwt 1914', 3, 436.6666666666667, -1.1666666666666654, 3166.6666666666665), ('QF 4inch Mk V World War I', 3, 286.6666666666667, -5.0666666666666655, 8416.666666666666), ('QF 12 pdr 12 cwt', 1, 210.0, -1.0, 1000.0), ('QF 3 inch 20 cwt 1916', 1, 10.0, -0.9000000000000004, 3000.0)]",m_1764883844747_7ffb015f_16439764-1,"1) The query groups by Gun and only keeps Guns that beat at least one other on both muzzle velocity and max height, computing count and average differences. 2) Map the aggregated outputs to Better_than_peers, Avg_Delta_v, Avg_Delta_25, Avg_Delta_h using columns m/v ft/s, Time to ft (m) at 25° (seconds), and Max. height (ft). 3) Draft the question to ask for those metrics per Gun, filter for count>0, sort by Avg_Delta_v descending and limit to 5. 4) Confirm it includes all calculations and the comparison criteria.",reserved,14,N/A,rename_column,
Which hub and partner cities in the same province have the largest combined administrative population?,"
WITH `stats` AS (
  SELECT
    `City`,
    `Province`,
    `Urban Population (2010)` AS `urban_2010`,
    `Administrative Population (2010)` AS `admin_2010`,
    (`Administrative Population (2010)` - `Urban Population (2010)`) AS `pop_diff`,
    (`Administrative Population (2010)` / NULLIF(`Urban Population (2010)`, 0)) AS `pop_ratio`
  FROM `table_m_1764883886555_e10e1f3d_16489766_2`
),
`hubs` AS (
  SELECT *
  FROM `stats`
  WHERE `urban_2010` BETWEEN 2000000 AND 8000000
    AND `admin_2010` > 8000000
),
`partners` AS (
  SELECT
    `hubs`.`City` AS `hub_city`,
    `p`.`City` AS `partner_city`,
    `hubs`.`Province` AS `province`,
    `hubs`.`urban_2010` AS `hub_urban_2010`,
    `hubs`.`admin_2010` AS `hub_admin_2010`,
    `hubs`.`pop_diff` AS `hub_pop_diff`,
    `hubs`.`pop_ratio` AS `hub_pop_ratio`,
    `p`.`urban_2010` AS `partner_urban_2010`,
    `p`.`admin_2010` AS `partner_admin_2010`,
    `p`.`pop_diff` AS `partner_pop_diff`,
    `p`.`pop_ratio` AS `partner_pop_ratio`,
    (`hubs`.`admin_2010` + `p`.`admin_2010`) AS `combined_admin_2010`,
    (`hubs`.`pop_diff` + `p`.`pop_diff`) AS `combined_hinterland`
  FROM `hubs`
  JOIN `stats` p
    ON `hubs`.`Province` = p.`Province`
   AND `hubs`.`City` <> p.`City`
)
SELECT
  `hub_city`,
  `partner_city`,
  `province`,
  `hub_urban_2010`,
  `hub_admin_2010`,
  `hub_pop_diff`,
  ROUND(`hub_pop_ratio`, 3) AS `hub_pop_ratio`,
  `partner_urban_2010`,
  `partner_admin_2010`,
  `partner_pop_diff`,
  ROUND(`partner_pop_ratio`, 3) AS `partner_pop_ratio`,
  `combined_admin_2010`,
  `combined_hinterland`
FROM `partners`
ORDER BY `combined_admin_2010` DESC, `combined_hinterland` DESC, `hub_pop_diff` DESC
LIMIT 10;
","
WITH `stats` AS (
  SELECT
    col0,
    col3,
    col4 AS `urban_2010`,
    col5 AS `admin_2010`,
    (col5 - col4) AS `pop_diff`,
    (col5 / NULLIF(col4, 0)) AS `pop_ratio`
  FROM `table_m_1764883886555_e10e1f3d_16489766_2`
),
`hubs` AS (
  SELECT *
  FROM `stats`
  WHERE `urban_2010` BETWEEN 2000000 AND 8000000
    AND `admin_2010` > 8000000
),
`partners` AS (
  SELECT
    `hubs`.col0 AS `hub_city`,
    `p`.col0 AS `partner_city`,
    `hubs`.col3 AS col3,
    `hubs`.`urban_2010` AS `hub_urban_2010`,
    `hubs`.`admin_2010` AS `hub_admin_2010`,
    `hubs`.`pop_diff` AS `hub_pop_diff`,
    `hubs`.`pop_ratio` AS `hub_pop_ratio`,
    `p`.`urban_2010` AS `partner_urban_2010`,
    `p`.`admin_2010` AS `partner_admin_2010`,
    `p`.`pop_diff` AS `partner_pop_diff`,
    `p`.`pop_ratio` AS `partner_pop_ratio`,
    (`hubs`.`admin_2010` + `p`.`admin_2010`) AS `combined_admin_2010`,
    (`hubs`.`pop_diff` + `p`.`pop_diff`) AS `combined_hinterland`
  FROM `hubs`
  JOIN `stats` p
    ON `hubs`.col3 = p.col3
   AND `hubs`.col0 <> p.col0
)
SELECT
  `hub_city`,
  `partner_city`,
  col3,
  `hub_urban_2010`,
  `hub_admin_2010`,
  `hub_pop_diff`,
  ROUND(`hub_pop_ratio`, 3) AS `hub_pop_ratio`,
  `partner_urban_2010`,
  `partner_admin_2010`,
  `partner_pop_diff`,
  ROUND(`partner_pop_ratio`, 3) AS `partner_pop_ratio`,
  `combined_admin_2010`,
  `combined_hinterland`
FROM `partners`
ORDER BY `combined_admin_2010` DESC, `combined_hinterland` DESC, `hub_pop_diff` DESC
LIMIT 10;
","[('Chongqing', 'Shanghai', 'Municipality', 5402721.0, 28846170.0, 23443449.0, 5.339, 22315426.0, 23019148.0, 703722.0, 1.032, 51865318.0, 24147171.0), ('Chongqing', 'Beijing', 'Municipality', 5402721.0, 28846170.0, 23443449.0, 5.339, 18827000.0, 19612368.0, 785368.0, 1.042, 48458538.0, 24228817.0), ('Chongqing', 'Tianjin', 'Municipality', 5402721.0, 28846170.0, 23443449.0, 5.339, 11090314.0, 12937954.0, 1847640.0, 1.167, 41784124.0, 25291089.0), ('Suzhou', 'Nanjing', 'Jiangsu', 5349000.0, 10465994.0, 5116994.0, 1.957, 6852984.0, 8004680.0, 1151696.0, 1.168, 18470674.0, 6268690.0), ('Nanjing', 'Suzhou', 'Jiangsu', 6852984.0, 8004680.0, 1151696.0, 1.168, 5349000.0, 10465994.0, 5116994.0, 1.957, 18470674.0, 6268690.0), ('Suzhou', 'Wuxi', 'Jiangsu', 5349000.0, 10465994.0, 5116994.0, 1.957, 3542319.0, 6372624.0, 2830305.0, 1.799, 16838618.0, 7947299.0), ('Hangzhou', 'Ningbo', 'Zhejiang', 5695313.0, 8700400.0, 3005087.0, 1.528, 3089180.0, 7605700.0, 4516520.0, 2.462, 16306100.0, 7521607.0), ('Qingdao', 'Jinan', 'Shangdong', 3063492.0, 8715100.0, 5651608.0, 2.845, 3922180.0, 6814000.0, 2891820.0, 1.737, 15529100.0, 8543428.0), ('Suzhou', 'Changzhou', 'Jiangsu', 5349000.0, 10465994.0, 5116994.0, 1.957, 3290548.0, 4591972.0, 1301424.0, 1.396, 15057966.0, 6418418.0), ('Shenyang', 'Dalian', 'Liaoning', 5743718.0, 8106171.0, 2362453.0, 1.411, 3266905.0, 6690432.0, 3423527.0, 2.048, 14796603.0, 5785980.0)]",m_1764883886555_e10e1f3d_16489766-2,"STEP 1: Parse the SQL intent — compute urban/admin/pop_diff/pop_ratio for each city; define 'hubs' as cities with urban_2010 between 2,000,000 and 8,000,000 and admin_2010 > 8,000,000; pair each hub with other cities in the same province and compute combined_admin_2010 and combined_hinterland; order pairs by combined_admin_2010 desc, combined_hinterland desc, hub_pop_diff desc and return the top 10. STEP 2: Determine ambiguity type — scope/attachment ambiguity fits well: the phrase 'in the same province' or 'in their province' can be read either as a pairing/filter condition (both cities must be in the same province, then pick top pairs overall) or as a scope qualifier (find the top pair within each province). STEP 3: Draft the question — ""Which hub and partner cities in the same province have the largest combined administrative population?"" STEP 4: Explain the ambiguity — in the original query the phrase is interpreted as a pairing/filter (require both cities be in the same province, then return the top 10 pairs overall). Alternatively it could be read as a per-province question asking for the single top hub-partner pair within each province (group-wise maxima), which would change grouping and results.",persona,"A retro‑futurist heritage‑railway route designer who plans scenic steam tourist lines by targeting Chinese city pairs with large metropolitan hinterlands and commuter belts. Goals: Identify cities where the administrative population greatly exceeds the urban population (indicating broad commuter belts or large peri‑urban areas that could feed tourist routes). Find high‑potential city pairs or hub towns within the same province (or nearby administrative types) with enough combined administrative population to sustain multi‑stop heritage trains. Select mid‑sized urban cores with very large administrative populations as candidate hub towns for depot, restoration yard, and overnight stays. Example Queries: /* 1) Cities with the largest absolute and relative hinterlands (admin - urban and admin/urban ratio) */
SELECT City,
       Province,
       ""Urban Population (2010)"" AS urban_2010,
       ""Administrative Population (2010)"" AS admin_2010,
       (""Administrative Population (2010)"" - ""Urban Population (2010)"") AS pop_diff,
       (""Administrative Population (2010)"" / NULLIF(""Urban Population (2010)"", 0)) AS pop_ratio
FROM table_1_16489766_2
WHERE ""Administrative Population (2010)"" > ""Urban Population (2010)""
ORDER BY pop_diff DESC, pop_ratio DESC
LIMIT 20; /* 2) Candidate intra‑province city pairings ranked by combined administrative population (exclude national municipalities if desired) */
SELECT t1.City AS city_a,
       t2.City AS city_b,
       t1.Province,
       (t1.""Administrative Population (2010)"" + t2.""Administrative Population (2010)"") AS combined_admin
FROM table_1_16489766_2 t1
JOIN table_1_16489766_2 t2
  ON t1.Province = t2.Province
 AND t1.City < t2.City
WHERE t1.Province NOT IN ('Municipality')
ORDER BY combined_admin DESC
LIMIT 10; /* 3) Mid‑sized urban cores (2–8M) with very large administrative populations (>8M) for hub candidacy */
SELECT City,
       Province,
       ""Urban Population (2010)"" AS urban_2010,
       ""Administrative Population (2010)"" AS admin_2010,
       (""Administrative Population (2010)"" - ""Urban Population (2010)"") AS hinterland_size
FROM table_1_16489766_2
WHERE ""Urban Population (2010)"" BETWEEN 2000000 AND 8000000
  AND ""Administrative Population (2010)"" > 8000000
ORDER BY hinterland_size DESC;",N/A,add_column,"type: Scope/attachment ambiguity | explanation: The phrase 'in the same province' can be interpreted as a filter that just ensures both cities are co-located (the SQL's interpretation, then return the top pairs overall) or as a scope specifying 'within each province' (asking for the top pair per province), which would require grouping by province and yield different results."
"Break down the all-time Grizzlies roster by position with total player counts and, for each position, list Arizona alums, players with multiple stints, and players listed as active?",unanswerable,unanswerable,,m_1764883901683_f68b1214_16494599-2,"In preparation for an on-air graphic I'd ask succinctly for per-position counts plus alumni and status breakdowns and expect names. The SQL produces per-position player counts, sums and name lists for Arizona alumni, multi-stint players (Years containing ';'), and active players (Years containing 'Present'). The schema fields used are Position, Player, School/Club Team, and Years for Grizzlies. Drafted question: Break down the all-time Grizzlies roster by position with total player counts and, for each position, list Arizona alums, players with multiple stints, and players listed as active. This precisely reflects the grouped counts and concatenated name fields returned by the query.",persona,"Senior sports data analyst at a regional sports network who builds roster analytics and on-air graphics; uses the Memphis Grizzlies all-time roster to analyze player backgrounds, position makeup, and notable alumni for stories and visualizations. Goals: Summarize roster composition by position and identify position trends over the franchise history. Find and profile players who attended specific schools or club teams (e.g., Arizona programs) for feature segments. Detect players with multiple stints on the Grizzlies and identify currently active players for up-to-date coverage. Example Queries: -- 1) Count how many players there are by position
    SELECT ""Position"", COUNT(*) AS player_count
    FROM table_1_16494599_2
    GROUP BY ""Position""
    ORDER BY player_count DESC; -- 2) List players who attended Arizona schools (Arizona, Arizona State, etc.)
    SELECT ""Player"", ""No."", ""Position"", ""Years for Grizzlies"", ""School/Club Team""
    FROM table_1_16494599_2
    WHERE ""School/Club Team"" LIKE '%Arizona%'
    ORDER BY ""Years for Grizzlies"" DESC, ""Player""; -- 3) Find players with multiple stints (entries with a semicolon in Years) or explicitly marked as still active
    SELECT ""Player"", ""No."", ""Position"", ""Years for Grizzlies""
    FROM table_1_16494599_2
    WHERE ""Years for Grizzlies"" LIKE '%;%'
       OR ""Years for Grizzlies"" LIKE '%Present%'
    ORDER BY ""Years for Grizzlies"";",N/A,remove_column,
Which managers had above-average wins — show the top three?,"
SELECT `Manager`, COUNT(*) `Seasons`, SUM(`Wins`) `Total Wins`, SUM(`Losses`) `Total Losses`, ROUND(AVG(`Wins`),2) `Avg Wins`, ROUND(100.0*SUM(`Wins`)/(SUM(`Wins`)+SUM(`Losses`)),3) `Win Pct`
FROM `table_m_1764883909096_539782d3_16512618_1`
GROUP BY `Manager`
HAVING AVG(`Wins`) > (SELECT AVG(`Wins`) FROM `table_m_1764883909096_539782d3_16512618_1`)
ORDER BY AVG(`Wins`) DESC
LIMIT 3;
","
SELECT col5, COUNT(*) `Seasons`, SUM(col1) `Total Wins`, SUM(col2) `Total Losses`, ROUND(AVG(col1),2) `Avg Wins`, ROUND(100.0*SUM(col1)/(SUM(col1)+SUM(col2)),3) `Win Pct`
FROM `table_m_1764883909096_539782d3_16512618_1`
GROUP BY col5
HAVING AVG(col1) > (SELECT AVG(col1) FROM `table_m_1764883909096_539782d3_16512618_1`)
ORDER BY AVG(col1) DESC
LIMIT 3;
","[('Win Clark', 1, 87.0, 51.0, 87.0, 63.043), ('Joe Cobb/ Eddie Onslow', 1, 83.0, 56.0, 83.0, 59.712), ('Glen Killinger', 1, 82.0, 54.0, 82.0, 60.294)]",m_1764883909096_539782d3_16512618-1,"STEP 1: Parse the SQL intent — compute, for each Manager, number of seasons, total wins, total losses, average wins and win pct; keep only managers whose average wins exceed the overall season-average wins; order by manager average wins descending and return the top 3. STEP 2: Choose ambiguity type — scope ambiguity fits best because the phrase “above-average” or “top three” can apply to single seasons, to a manager's average across seasons, to their totals, or to every season they managed. STEP 3: Draft the question — a concise ambiguous NL rendering that matches the SQL but allows other readings. STEP 4: Explain the ambiguity — the SQL treats “above-average” as the manager's average wins exceeding the overall average and ranks by that same average, but a reader could instead mean managers with any season above average, managers with total wins above average, managers whose every season was above average, or rank by win pct instead.",reserved,10,N/A,add_column,"type: Scope ambiguity (per-season vs. per-manager average; also metric/ranking scope) | explanation: The SQL chooses managers whose average wins (across their seasons) exceed the overall season-average and returns the top three by that average, but the question could instead be read as asking for managers with any single season above average, managers with the highest total wins, managers whose every season was above average, or the top three by win percentage."
"Considering only rows with Length (m) > 0, for each Pavement compute total_length = SUM(Length (m)), avg_climb = AVG(Average climb (%)), and count = COUNT(*), then compute difficulty_score = (total_length * avg_climb / 100.0); which two Pavement types have the largest difficulty_score when ordered DESC (return the type, total_length, avg_climb, count, and difficulty_score)?",unanswerable,unanswerable,,m_1764884005128_f7ce486d_16654785-2,"1) Parse intent: filter rows with Length (m) > 0, GROUP BY Pavement, compute SUM(Length (m)) AS total_length, AVG(Average climb (%)) AS avg_climb, COUNT(*) AS count, derive difficulty_score = total_length * avg_climb / 100.0, and return top 2 by difficulty_score descending. 2) Map schema: Pavement is the grouping key, Length (m) and Average climb (%) are aggregated. 3) Draft: pose a question asking for those aggregated values and the computed difficulty_score for the top two pavement types. 4) Validate: includes the WHERE condition, all aggregate names, the formula, and the ordering/limit.",reserved,19,N/A,remove_column,
"For games where Bills points >= 0, report the average Bills points, the average Opponents score, the average point differential (Bills points - Opponents), the percentage of games won (count of games with Bills points > Opponents times 100 divided by total game count), the highest Attendance, and the average Attendance across games with Bills points <= Opponents?","
SELECT AVG(`Bills points`), AVG(`Opponents`), AVG(`Bills points` - `Opponents`), SUM(`Bills points` > `Opponents`) * 100.0 / COUNT(*), MAX(`Attendance`), SUM(`Attendance` * (`Bills points` <= `Opponents`)) / SUM(`Bills points` <= `Opponents`) FROM `table_m_1764884016943_4282887c_16677887_2` WHERE `Bills points` >= 0 LIMIT 1;
","
SELECT AVG(col4), AVG(col5), AVG(col4 - col5), SUM(col4 > col5) * 100.0 / COUNT(*), MAX(col8), SUM(col8 * (col4 <= col5)) / SUM(col4 <= col5) FROM `table_m_1764884016943_4282887c_16677887_2` WHERE col4 >= 0 LIMIT 1;
","[(20.133333333333333, 16.466666666666665, 3.6666666666666665, 66.66666666666667, 79659.0, 53547.4)]",m_1764884016943_4282887c_16677887-2,"1) The query aggregates across all rows with Bills points >= 0, computing means, a win-rate, a maximum, and a conditional mean. 2) Schema terms correspond to `Bills points`, `Opponents`, and `Attendance`. 3) Compose a question asking for AVG(`Bills points`), AVG(`Opponents`), AVG(`Bills points` - `Opponents`), SUM(`Bills points` > `Opponents`) * 100.0 / COUNT(*), MAX(`Attendance`), and SUM(Attendance * (Bills points <= Opponents)) / SUM(Bills points <= Opponents) with the Bills points >= 0 filter. 4) Confirm all expressions and the WHERE condition are explicitly requested.",reserved,4,N/A,add_column,
"For entries with [Na + ](mmol/L) > 0 and [Glucose](mmol/L) >= 0, classify them as 'Isotonic' when (2 * [Na + ](mmol/L) + [Glucose](mmol/L)) <= 295 and 'Non-Isotonic' otherwise, then report for each classification the COUNT(*) (named D5W) and the average [Na + ](mmol/L), only include classifications with COUNT(*) > 0, order by COUNT(*) descending and limit the output to the top 3?","
SELECT CASE WHEN (2*`[Na + ](mmol/L)` + `[Glucose](mmol/L)`) <= 295 THEN 'Isotonic' ELSE 'Non-Isotonic' END AS `Classification`, COUNT(*) `D5W`, AVG(`[Na + ](mmol/L)`)
FROM `table_m_1764884042354_1a7c91bc_16689223_1`
WHERE (`[Na + ](mmol/L)` > 0 AND `[Glucose](mmol/L)` >= 0)
GROUP BY 1
HAVING COUNT(*) > 0
ORDER BY COUNT(*) DESC
LIMIT 3;
","
SELECT CASE WHEN (2*col1 + col3) <= 295 THEN 'Isotonic' ELSE 'Non-Isotonic' END AS `Classification`, COUNT(*) `D5W`, AVG(col1)
FROM `table_m_1764884042354_1a7c91bc_16689223_1`
WHERE (col1 > 0 AND col3 >= 0)
GROUP BY 1
HAVING COUNT(*) > 0
ORDER BY COUNT(*) DESC
LIMIT 3;
","[('Isotonic', 3, 86.0), ('Non-Isotonic', 1, 154.0)]",m_1764884042354_1a7c91bc_16689223-1,"1) The query's intent is to label solutions by osmolarity using 2*[Na + ] + [Glucose] threshold 295 and then aggregate counts and mean sodium. 2) Relevant schema elements are [Na + ](mmol/L) and [Glucose](mmol/L) with filters >0 and >=0 respectively. 3) Draft a question asking for classification, COUNT(*) as D5W, AVG([Na + ]), only groups with count>0, ordered by count desc, limited to 3. 4) Ensure the question precisely mirrors the SQL condition, calculation, aliases, grouping, having, ordering, and limit.",reserved,16,N/A,split_column,
"Which five Teams (LIMIT 5) have SUM(Races) AS Total Races, SUM(Wins) AS Total Wins, SUM(Podiums) AS Total Podiums, and Win Rate = ROUND((SUM(Wins)*1.0)/NULLIF(SUM(Races),0),3), when selecting only rows with Races > 0 and non-empty Pts, including Seasons Included '2005,2006,2007,2008,2009,2010,2011,2012,2013' and ordering by Total Wins DESC?","
SELECT `Team`, SUM(`Races`) AS `Total Races`, SUM(`Wins`) AS `Total Wins`, SUM(`Podiums`) AS `Total Podiums`, ROUND((SUM(`Wins`)*1.0)/NULLIF(SUM(`Races`),0),3) AS `Win Rate`, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`' AS `Seasons Included` FROM `table_m_1764884080479_e9ed6f99_16710541_2` WHERE `Races` > 0 AND `Pts` <> '' GROUP BY `Team` ORDER BY `Total Wins` DESC LIMIT 5;
","
SELECT col2, SUM(col5) AS `Total Races`, SUM(col6) AS `Total Wins`, SUM(col7) AS `Total Podiums`, ROUND((SUM(col6)*1.0)/NULLIF(SUM(col5),0),3) AS `Win Rate`, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`' AS `Seasons Included` FROM `table_m_1764884080479_e9ed6f99_16710541_2` WHERE col5 > 0 AND col10 <> '' GROUP BY col2 ORDER BY `Total Wins` DESC LIMIT 5;
","[('Red Bull KTM Ajo', 17.0, 5.0, 15.0, 0.294, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`'), ('Intact-Racing Team Germany', 17.0, 2.0, 6.0, 0.118, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`'), ('Kiefer-Bos-Castrol Honda', 16.0, 0.0, 0.0, 0.0, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`'), ('Emmi– Caffè Latte', 34.0, 0.0, 0.0, 0.0, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`'), ('Elit– Caffè Latte', 16.0, 0.0, 0.0, 0.0, '`2005`,`2006`,`2007`,`2008`,`2009`,`2010`,`2011`,`2012`,`2013`')]",m_1764884080479_e9ed6f99_16710541-2,"Parse SQL intent: sum Races, Wins, Podiums per Team and calculate a rounded win rate, filter out entries with Races = 0 or empty Pts, then sort teams by total wins and limit to five. Map schema semantics: use Team, Races, Wins, Podiums, Pts and the literal seasons string for Seasons Included. Draft the question: request those sums, the exact Win Rate expression rounded to three decimals, the Races > 0 and Pts <> '' filters, grouping by Team, and top 5 ordering/limit. Validate: question reflects all columns, the ROUND/NULLIF Win Rate calculation, filters, grouping, ORDER BY Total Wins DESC, LIMIT 5, and the Seasons Included list.",reserved,8,N/A,split_column,
"Can you produce a concise breakdown for the 1982 Falcons showing average attendance by win/loss, the top three highest-attended games with date/opponent/result, and average attendance plus win percentage by home versus away?",,,[],m_1764884091715_4e1798cd_16710829-2,"For my article I may want a compact report combining result-based, top-game and location-based attendance context, asked in straightforward reporter language. The SQL produces three sections: averages by Result, the top 3 games by Attendance with their dates/opponents/results, and averages by Location including win rates. It pulls Date, Opponent, Result and Attendance for the top games and aggregated stats for the groupings. Draft question: Can you produce a concise breakdown for the 1982 Falcons showing average attendance by win/loss, the top three highest-attended games with date/opponent/result, and average attendance plus win percentage by home versus away? This reflects the combined UNION of the three query sections.",persona,"Sports data journalist researching the 1982 Atlanta Falcons season to report on how opponent, location, and game outcomes affected crowd sizes during the strike-shortened year. They use the table to extract attendance patterns and tie them to game context for an article. Goals: Determine whether wins or losses correlated with higher average attendance during the 1982 season. Identify which games (dates and opponents) drew the largest crowds to highlight marquee matchups or anomalies. Compare home vs. away attendance and the Falcons' home success rate to provide context about local fan engagement. Example Queries: SELECT Result, AVG(Attendance) AS avg_attendance, COUNT(*) AS games_played
FROM table_1_16710829_2
GROUP BY Result
ORDER BY avg_attendance DESC; SELECT Game, Date, Opponent, Result, Attendance
FROM table_1_16710829_2
ORDER BY Attendance DESC
LIMIT 3; SELECT CASE WHEN Opponent LIKE 'at %' THEN 'Away' ELSE 'Home' END AS location,
       AVG(Attendance) AS avg_attendance,
       SUM(CASE WHEN Result = 'Win' THEN 1 ELSE 0 END) AS wins,
       COUNT(*) AS games
FROM table_1_16710829_2
GROUP BY location;",N/A,merge_column,
"By Team(s), can you provide the total Starts (SUM(Starts)), total Wins (SUM(Wins)), the win percentage as (SUM(Wins)*1.0)/SUM(Starts)*100 rounded to two decimal places, the average of Avg. Finish as a numeric value rounded to two decimals, the summed Winnings after stripping '$' and ',' rounded to zero decimals (as 'Ken Schrader Racing'), and the MIN(Year) and MAX(Year), only using rows with Starts > 0, only showing teams whose SUM(Starts) >= 5, and returning up to 10 results?",unanswerable,unanswerable,,m_1764884119405_31af38ea_1671401-2,"1) The SQL groups by Team(s) and returns aggregated counts, rates, averages, and year ranges with text-to-number conversion for Winnings, applying Starts>0 filter and SUM(Starts) >=5 HAVING, limiting output. 2) Map to table fields: Team(s), Starts, Wins, Avg. Finish, Winnings, Year. 3) Compose a question that precisely asks for those aggregates, conversions, roundings, and filters. 4) Ensure the question includes the alias for total Winnings and the LIMIT 10.",reserved,8,N/A,remove_column,
"Which five ACC Teams have the highest SUM(Attendance) from games where Attendance > 10000, and for each ACC Team what are the COUNT(Attendance) and SUM(Attendance)?","
SELECT `ACC Team`, COUNT(`Attendance`), SUM(`Attendance`)
FROM `table_m_1764884135388_d79130d2_1672976_5`
WHERE `Attendance` > 10000
GROUP BY `ACC Team`
ORDER BY SUM(`Attendance`) DESC
LIMIT 5;
","
SELECT col2, COUNT(col5), SUM(col5)
FROM `table_m_1764884135388_d79130d2_1672976_5`
WHERE col5 > 10000
GROUP BY col2
ORDER BY SUM(col5) DESC
LIMIT 5;
","[('#4 Duke', 1, 18809.0), ('NC State', 1, 16597.0), ('Florida State', 1, 14797.0), ('Miami', 1, 13927.0), ('Maryland', 1, 13187.0)]",m_1764884135388_d79130d2_1672976-5,"1) Parse intent: filter rows with Attendance > 10000, group by ACC Team, compute COUNT and SUM of Attendance, sort by SUM descending and take 5. 2) Map schema: 'ACC Team' groups, 'Attendance' is counted and summed. 3) Draft: ask which five ACC Teams have the largest total attendance from games over 10000 and provide the count and sum. 4) Validate: question includes COUNT(Attendance), SUM(Attendance), Attendance > 10000, grouping, ordering by SUM desc, and limit 5.",reserved,8,N/A,remove_column,
"For up to 10 Socket groups, return the Socket, the total_models count, the average TDP (avg_tdp) where avg_tdp is computed by removing the ' W' suffix from TDP and converting to a number, the average Mult. (avg_mult) where avg_mult is computed by removing the '×' character from Mult. and converting to a number, the maximum Release price (max_price) and minimum Release price (min_price) where each price is computed by removing '$' from Release price ( USD ) and only considered if Release price ( USD ) contains '$', and include only rows where TDP without ' W' and Mult. without '×' are non-empty, grouped by Socket?","
SELECT DISTINCT `Socket`,
       COUNT(*) ""total_models"",
       AVG(REPLACE(`TDP`, ' W', '') + 0.0) ""avg_tdp"",
       AVG(REPLACE(`Mult.`, '×', '') + 0.0) ""avg_mult"",
       MAX((REPLACE(`Release price ( USD )`, '$', '') + 0.0) * (INSTR(`Release price ( USD )`, '$') > 0)) ""max_price"",
       MIN((REPLACE(`Release price ( USD )`, '$', '') + 0.0) * (INSTR(`Release price ( USD )`, '$') > 0)) ""min_price""
FROM `table_m_1764884140871_07dcc1d9_16729930_11`
WHERE LENGTH(REPLACE(`TDP`, ' W', '')) > 0 AND LENGTH(REPLACE(`Mult.`, '×', '')) > 0
GROUP BY `Socket`
LIMIT 10;
","
SELECT DISTINCT col8,
       COUNT(*) ""total_models"",
       AVG(REPLACE(col7, ' W', '') + 0.0) ""avg_tdp"",
       AVG(REPLACE(col5, '×', '') + 0.0) ""avg_mult"",
       MAX((REPLACE(col11, '$', '') + 0.0) * (INSTR(col11, '$') > 0)) ""max_price"",
       MIN((REPLACE(col11, '$', '') + 0.0) * (INSTR(col11, '$') > 0)) ""min_price""
FROM `table_m_1764884140871_07dcc1d9_16729930_11`
WHERE LENGTH(REPLACE(col7, ' W', '')) > 0 AND LENGTH(REPLACE(col5, '×', '')) > 0
GROUP BY col8
LIMIT 10;
","[('BGA 437', 4, 2.2, 11.0, 0.0, 0.0), ('BGA 441', 7, 1.8357142857142856, 11.714285714285714, 249.47, 0.0)]",m_1764884140871_07dcc1d9_16729930-11,"Parse the SQL intent: produce distinct sockets with aggregate statistics: total model count, average numeric TDP and Mult., and numeric max/min release prices where a dollar sign exists; exclude rows lacking TDP or Mult. after removing units and cap results at 10 sockets. Map schema semantics: the query uses `Socket`, `TDP`, `Mult.`, and `Release price ( USD )` and applies string replacement and numeric casts. Draft the question: explicitly ask for each aggregate, the unit removals (' W', '×', '$'), the dollar-only price consideration, the non-empty checks, grouping by Socket and LIMIT 10. Validate: includes all columns, transformations, filters and grouping.",reserved,8,N/A,add_column,
"For my thermographic sculptures, list every 45 nm Atom with TDP ≤4 W and voltage 0.8–1.175V — give me model, sSpec, part numbers, socket, release date and price, the numeric TDP and per-socket min/max and range, CPU and GPU frequencies in MHz and their absolute delta, and how many models share each socket, cheapest first?",,,[],m_1764884152167_15b52b8a_16729930-17,"I'm a thermo-kinetic sculptor who thinks in watts, volts and sockets and I talk about TDP and voltage ranges when sourcing stable heat sources. I know enough schema words to ask for model, part numbers, socket and frequencies but won't use raw SQL jargon. The query filters the 45 nm Atom table for parts with TDP ≤ 4 W and Voltage = 0.8–1.175V and converts values to numeric, computing per-socket min/max/range, CPU/GPU frequencies in MHz, absolute delta, model counts per socket and price. The schema maps to Model number, sSpec number, Part number(s), Socket, Release date, Release price, TDP, Voltage, Frequency, GPU frequency and uses price for ordering. Draft question: For my thermographic pieces, list those 45 nm Atom models with TDP ≤4 W and voltage 0.8–1.175V showing model, sSpec, part numbers, socket, release date, price, numeric TDP and the per-socket min/max/range, CPU and GPU MHz and their absolute delta, plus how many models share each socket, cheapest first. Validation: This asks exactly for the filtered models, the per-socket TDP stats, converted frequencies and ordering by price that the query returns.",persona,"A thermo-kinetic sculptor who builds kinetic art pieces that use the predictable heat output and voltage characteristics of vintage Intel Atom chips to draw patterns on thermographic film and drive micro-thermoelectric actuators. Goals: Identify Atom models with very low and tightly constrained TDP/voltage ranges to achieve stable, repeatable thermal signatures for artwork. Find chips that share the same socket and mechanical footprint so they can be swapped into a sculpture's mounting without retooling. Budget and source the cheapest suitable parts from the 45 nm Atom family and verify their original release dates for exhibit labeling. Compare CPU vs GPU frequency deltas to pick devices whose GPU heat contribution is predictable relative to the CPU (useful when using onboard GPU as a secondary heat element). Example Queries: SELECT ""Model number"", ""TDP"", ""Voltage"", ""Release price ( USD )""
FROM table_1_16729930_17
WHERE CAST(REPLACE(""TDP"",' W','') AS DECIMAL) <= 4
  AND ""Voltage"" = '0.8–1.175V'
ORDER BY CAST(REPLACE(""Release price ( USD )"",'$','') AS DECIMAL) ASC; SELECT ""Model number"", ""sSpec number"", ""Part number(s)"", ""Socket"", ""Release date""
FROM table_1_16729930_17
WHERE ""Release date"" = 'September 14, 2010'
  AND ""Socket"" = 'FC-BGA 676'; SELECT ""Model number"",
  CASE WHEN ""Frequency"" LIKE '%GHz' THEN CAST(REPLACE(""Frequency"",' GHz','') AS DECIMAL)*1000 ELSE CAST(REPLACE(""Frequency"",' MHz','') AS DECIMAL) END AS cpu_mhz,
  CASE WHEN ""GPU frequency"" LIKE '%GHz' THEN CAST(REPLACE(""GPU frequency"",' GHz','') AS DECIMAL)*1000 ELSE CAST(REPLACE(""GPU frequency"",' MHz','') AS DECIMAL) END AS gpu_mhz
FROM table_1_16729930_17
WHERE ABS(
  (CASE WHEN ""Frequency"" LIKE '%GHz' THEN CAST(REPLACE(""Frequency"",' GHz','') AS DECIMAL)*1000 ELSE CAST(REPLACE(""Frequency"",' MHz','') AS DECIMAL) END)
  -
  (CASE WHEN ""GPU frequency"" LIKE '%GHz' THEN CAST(REPLACE(""GPU frequency"",' GHz','') AS DECIMAL)*1000 ELSE CAST(REPLACE(""GPU frequency"",' MHz','') AS DECIMAL) END)
) >= 200;",N/A,merge_column,
